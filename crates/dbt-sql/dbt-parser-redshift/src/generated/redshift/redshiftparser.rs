// Generated from Redshift.g4 by ANTLR 4.8
#![allow(dead_code)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(nonstandard_style)]
#![allow(unused_imports)]
#![allow(unused_mut)]
#![allow(unused_braces)]
use antlr_rust::PredictionContextCache;
use antlr_rust::error_listener::ErrorListener;
use antlr_rust::parser::{Parser, BaseParser, ParserRecog, ParserNodeType};
use antlr_rust::token_stream::TokenStream;
use antlr_rust::TokenSource;
use antlr_rust::parser_atn_simulator::ParserATNSimulator;
use antlr_rust::errors::*;
use antlr_rust::rule_context::{BaseRuleContext, CustomRuleContext, RuleContext};
use antlr_rust::recognizer::{Recognizer,Actions};
use antlr_rust::atn_deserializer::ATNDeserializer;
use antlr_rust::dfa::DFA;
use antlr_rust::atn::{ATN, INVALID_ALT};
use antlr_rust::error_strategy::{ErrorStrategy, DefaultErrorStrategy};
use antlr_rust::parser_rule_context::{BaseParserRuleContext, ParserRuleContext,cast,cast_mut};
use antlr_rust::tree::*;
use antlr_rust::token::{TOKEN_EOF,OwningToken,Token};
use antlr_rust::int_stream::EOF;
use antlr_rust::vocabulary::{Vocabulary,VocabularyImpl};
use antlr_rust::token_factory::{CommonTokenFactory,TokenFactory, TokenAware};
use super::redshiftlistener::*;
use super::redshiftvisitor::*;

use antlr_rust::{TidAble,TidExt};

use std::marker::PhantomData;
use std::rc::Rc;
use std::convert::TryFrom;
use std::cell::RefCell;
use std::ops::{DerefMut, Deref};
use std::borrow::{Borrow,BorrowMut};
use std::any::{Any,TypeId};

		pub const T__0:isize=1; 
		pub const T__1:isize=2; 
		pub const T__2:isize=3; 
		pub const T__3:isize=4; 
		pub const T__4:isize=5; 
		pub const T__5:isize=6; 
		pub const T__6:isize=7; 
		pub const T__7:isize=8; 
		pub const T__8:isize=9; 
		pub const ABORT:isize=10; 
		pub const ABSENT:isize=11; 
		pub const ADD:isize=12; 
		pub const ADMIN:isize=13; 
		pub const AFTER:isize=14; 
		pub const ALL:isize=15; 
		pub const ALTER:isize=16; 
		pub const ANALYZE:isize=17; 
		pub const AND:isize=18; 
		pub const ANTI:isize=19; 
		pub const ANY:isize=20; 
		pub const APPROXIMATE:isize=21; 
		pub const ARRAY:isize=22; 
		pub const AS:isize=23; 
		pub const ASC:isize=24; 
		pub const AT:isize=25; 
		pub const ATTACH:isize=26; 
		pub const AUTHORIZATION:isize=27; 
		pub const AUTO:isize=28; 
		pub const BACKUP:isize=29; 
		pub const BEGIN:isize=30; 
		pub const BERNOULLI:isize=31; 
		pub const BETWEEN:isize=32; 
		pub const BINARY:isize=33; 
		pub const BINDING:isize=34; 
		pub const BOTH:isize=35; 
		pub const BY:isize=36; 
		pub const BZIP2:isize=37; 
		pub const CALL:isize=38; 
		pub const CANCEL:isize=39; 
		pub const CASCADE:isize=40; 
		pub const CASE:isize=41; 
		pub const CASE_SENSITIVE:isize=42; 
		pub const CASE_INSENSITIVE:isize=43; 
		pub const CAST:isize=44; 
		pub const CATALOGS:isize=45; 
		pub const CHARACTER:isize=46; 
		pub const CLONE:isize=47; 
		pub const CLOSE:isize=48; 
		pub const CLUSTER:isize=49; 
		pub const COLLATE:isize=50; 
		pub const COLUMN:isize=51; 
		pub const COLUMNS:isize=52; 
		pub const COMMA:isize=53; 
		pub const COMMENT:isize=54; 
		pub const COMMIT:isize=55; 
		pub const COMMITTED:isize=56; 
		pub const COMPOUND:isize=57; 
		pub const COMPRESSION:isize=58; 
		pub const CONDITIONAL:isize=59; 
		pub const CONNECT:isize=60; 
		pub const CONNECTION:isize=61; 
		pub const CONSTRAINT:isize=62; 
		pub const CONVERT:isize=63; 
		pub const COPARTITION:isize=64; 
		pub const COPY:isize=65; 
		pub const COUNT:isize=66; 
		pub const CREATE:isize=67; 
		pub const CROSS:isize=68; 
		pub const CUBE:isize=69; 
		pub const CURRENT:isize=70; 
		pub const CURRENT_ROLE:isize=71; 
		pub const DATA:isize=72; 
		pub const DATABASE:isize=73; 
		pub const DATASHARE:isize=74; 
		pub const DATE:isize=75; 
		pub const DAY:isize=76; 
		pub const DAYS:isize=77; 
		pub const DEALLOCATE:isize=78; 
		pub const DECLARE:isize=79; 
		pub const DEFAULT:isize=80; 
		pub const DEFAULTS:isize=81; 
		pub const DEFINE:isize=82; 
		pub const DEFINER:isize=83; 
		pub const DELETE:isize=84; 
		pub const DELIMITED:isize=85; 
		pub const DELIMITER:isize=86; 
		pub const DENY:isize=87; 
		pub const DESC:isize=88; 
		pub const DESCRIBE:isize=89; 
		pub const DESCRIPTOR:isize=90; 
		pub const DISTINCT:isize=91; 
		pub const DISTKEY:isize=92; 
		pub const DISTRIBUTED:isize=93; 
		pub const DISTSTYLE:isize=94; 
		pub const DETACH:isize=95; 
		pub const DOUBLE:isize=96; 
		pub const DROP:isize=97; 
		pub const ELSE:isize=98; 
		pub const EMPTY:isize=99; 
		pub const ENCODE:isize=100; 
		pub const ENCODING:isize=101; 
		pub const END:isize=102; 
		pub const ERROR:isize=103; 
		pub const ESCAPE:isize=104; 
		pub const EVEN:isize=105; 
		pub const EXCEPT:isize=106; 
		pub const EXCLUDE:isize=107; 
		pub const EXCLUDING:isize=108; 
		pub const EXECUTE:isize=109; 
		pub const EXISTS:isize=110; 
		pub const EXPLAIN:isize=111; 
		pub const EXTERNAL:isize=112; 
		pub const EXTRACT:isize=113; 
		pub const FALSE:isize=114; 
		pub const FETCH:isize=115; 
		pub const FIELDS:isize=116; 
		pub const FILTER:isize=117; 
		pub const FINAL:isize=118; 
		pub const FIRST:isize=119; 
		pub const FIRST_VALUE:isize=120; 
		pub const FOLLOWING:isize=121; 
		pub const FOR:isize=122; 
		pub const FOREIGN:isize=123; 
		pub const FORMAT:isize=124; 
		pub const FROM:isize=125; 
		pub const FULL:isize=126; 
		pub const FUNCTION:isize=127; 
		pub const FUNCTIONS:isize=128; 
		pub const GENERATED:isize=129; 
		pub const GRACE:isize=130; 
		pub const GRANT:isize=131; 
		pub const GRANTED:isize=132; 
		pub const GRANTS:isize=133; 
		pub const GRAPHVIZ:isize=134; 
		pub const GROUP:isize=135; 
		pub const GROUPING:isize=136; 
		pub const GROUPS:isize=137; 
		pub const GZIP:isize=138; 
		pub const HAVING:isize=139; 
		pub const HEADER:isize=140; 
		pub const HOUR:isize=141; 
		pub const HOURS:isize=142; 
		pub const IAM_ROLE:isize=143; 
		pub const IDENTITY:isize=144; 
		pub const IF:isize=145; 
		pub const IGNORE:isize=146; 
		pub const IMMUTABLE:isize=147; 
		pub const IN:isize=148; 
		pub const INCLUDE:isize=149; 
		pub const INCLUDING:isize=150; 
		pub const INITIAL:isize=151; 
		pub const INNER:isize=152; 
		pub const INPUT:isize=153; 
		pub const INPUTFORMAT:isize=154; 
		pub const INOUT:isize=155; 
		pub const INTERLEAVED:isize=156; 
		pub const INSERT:isize=157; 
		pub const INTERSECT:isize=158; 
		pub const INTERVAL:isize=159; 
		pub const INTO:isize=160; 
		pub const INVOKER:isize=161; 
		pub const IO:isize=162; 
		pub const IS:isize=163; 
		pub const ISOLATION:isize=164; 
		pub const ISNULL:isize=165; 
		pub const ILIKE:isize=166; 
		pub const JOIN:isize=167; 
		pub const JSON:isize=168; 
		pub const JSON_ARRAY:isize=169; 
		pub const JSON_EXISTS:isize=170; 
		pub const JSON_OBJECT:isize=171; 
		pub const JSON_QUERY:isize=172; 
		pub const JSON_VALUE:isize=173; 
		pub const KB:isize=174; 
		pub const KEEP:isize=175; 
		pub const KEY:isize=176; 
		pub const KEYS:isize=177; 
		pub const LAG:isize=178; 
		pub const LAMBDA:isize=179; 
		pub const LANGUAGE:isize=180; 
		pub const LAST:isize=181; 
		pub const LAST_VALUE:isize=182; 
		pub const LATERAL:isize=183; 
		pub const LEADING:isize=184; 
		pub const LEFT:isize=185; 
		pub const LEVEL:isize=186; 
		pub const LIBRARY:isize=187; 
		pub const LIKE:isize=188; 
		pub const LIMIT:isize=189; 
		pub const LINES:isize=190; 
		pub const LISTAGG:isize=191; 
		pub const LISTAGGDISTINCT:isize=192; 
		pub const LOCAL:isize=193; 
		pub const LOCATION:isize=194; 
		pub const LOCK:isize=195; 
		pub const LOGICAL:isize=196; 
		pub const M:isize=197; 
		pub const MAP:isize=198; 
		pub const MASKING:isize=199; 
		pub const MATCH:isize=200; 
		pub const MATCHED:isize=201; 
		pub const MATCHES:isize=202; 
		pub const MATCH_RECOGNIZE:isize=203; 
		pub const MATERIALIZED:isize=204; 
		pub const MAX:isize=205; 
		pub const MAX_BATCH_ROWS:isize=206; 
		pub const MAX_BATCH_SIZE:isize=207; 
		pub const MB:isize=208; 
		pub const MEASURES:isize=209; 
		pub const MERGE:isize=210; 
		pub const MIN:isize=211; 
		pub const MINUS_KW:isize=212; 
		pub const MINUTE:isize=213; 
		pub const MINUTES:isize=214; 
		pub const MODEL:isize=215; 
		pub const MONTH:isize=216; 
		pub const MONTHS:isize=217; 
		pub const NATURAL:isize=218; 
		pub const NEXT:isize=219; 
		pub const NFC:isize=220; 
		pub const NFD:isize=221; 
		pub const NFKC:isize=222; 
		pub const NFKD:isize=223; 
		pub const NO:isize=224; 
		pub const NONE:isize=225; 
		pub const NORMALIZE:isize=226; 
		pub const NOT:isize=227; 
		pub const NOTNULL:isize=228; 
		pub const NULL:isize=229; 
		pub const NULLS:isize=230; 
		pub const OBJECT:isize=231; 
		pub const OF:isize=232; 
		pub const OFFSET:isize=233; 
		pub const OMIT:isize=234; 
		pub const ON:isize=235; 
		pub const ONE:isize=236; 
		pub const ONLY:isize=237; 
		pub const OPTION:isize=238; 
		pub const OPTIONS:isize=239; 
		pub const OR:isize=240; 
		pub const ORDER:isize=241; 
		pub const ORDINALITY:isize=242; 
		pub const OUT:isize=243; 
		pub const OUTER:isize=244; 
		pub const OUTPUT:isize=245; 
		pub const OUTPUTFORMAT:isize=246; 
		pub const OVER:isize=247; 
		pub const OVERFLOW:isize=248; 
		pub const PARTITION:isize=249; 
		pub const PARTITIONED:isize=250; 
		pub const PARTITIONS:isize=251; 
		pub const PASSING:isize=252; 
		pub const PAST:isize=253; 
		pub const PATH:isize=254; 
		pub const PATTERN:isize=255; 
		pub const PER:isize=256; 
		pub const PERCENTILE_CONT:isize=257; 
		pub const PERCENTILE_DISC:isize=258; 
		pub const PERIOD:isize=259; 
		pub const PERMUTE:isize=260; 
		pub const PG_CATALOG:isize=261; 
		pub const PIVOT:isize=262; 
		pub const POSITION:isize=263; 
		pub const PRECEDING:isize=264; 
		pub const PRECISION:isize=265; 
		pub const PREPARE:isize=266; 
		pub const PRIOR:isize=267; 
		pub const PROCEDURE:isize=268; 
		pub const PRIMARY:isize=269; 
		pub const PRIVILEGES:isize=270; 
		pub const PROPERTIES:isize=271; 
		pub const PRUNE:isize=272; 
		pub const QUALIFY:isize=273; 
		pub const QUOTES:isize=274; 
		pub const RANGE:isize=275; 
		pub const READ:isize=276; 
		pub const RECURSIVE:isize=277; 
		pub const REFERENCES:isize=278; 
		pub const REFRESH:isize=279; 
		pub const RENAME:isize=280; 
		pub const REPEATABLE:isize=281; 
		pub const REPLACE:isize=282; 
		pub const RESET:isize=283; 
		pub const RESPECT:isize=284; 
		pub const RESTRICT:isize=285; 
		pub const RETRY_TIMEOUT:isize=286; 
		pub const RETURNING:isize=287; 
		pub const RETURNS:isize=288; 
		pub const REVOKE:isize=289; 
		pub const RIGHT:isize=290; 
		pub const RLS:isize=291; 
		pub const ROLE:isize=292; 
		pub const ROLES:isize=293; 
		pub const ROLLBACK:isize=294; 
		pub const ROLLUP:isize=295; 
		pub const ROW:isize=296; 
		pub const ROWS:isize=297; 
		pub const RUNNING:isize=298; 
		pub const S:isize=299; 
		pub const SAGEMAKER:isize=300; 
		pub const SCALAR:isize=301; 
		pub const SEC:isize=302; 
		pub const SECOND:isize=303; 
		pub const SECONDS:isize=304; 
		pub const SCHEMA:isize=305; 
		pub const SCHEMAS:isize=306; 
		pub const SECURITY:isize=307; 
		pub const SEEK:isize=308; 
		pub const SELECT:isize=309; 
		pub const SEMI:isize=310; 
		pub const SERDE:isize=311; 
		pub const SERDEPROPERTIES:isize=312; 
		pub const SERIALIZABLE:isize=313; 
		pub const SESSION:isize=314; 
		pub const SET:isize=315; 
		pub const SETS:isize=316; 
		pub const SHOW:isize=317; 
		pub const SIMILAR:isize=318; 
		pub const SNAPSHOT:isize=319; 
		pub const SOME:isize=320; 
		pub const SORTKEY:isize=321; 
		pub const SQL:isize=322; 
		pub const STABLE:isize=323; 
		pub const START:isize=324; 
		pub const STATS:isize=325; 
		pub const STORED:isize=326; 
		pub const STRUCT:isize=327; 
		pub const SUBSET:isize=328; 
		pub const SUBSTRING:isize=329; 
		pub const SYSTEM:isize=330; 
		pub const SYSTEM_TIME:isize=331; 
		pub const TABLE:isize=332; 
		pub const TABLES:isize=333; 
		pub const TABLESAMPLE:isize=334; 
		pub const TEMP:isize=335; 
		pub const TEMPORARY:isize=336; 
		pub const TERMINATED:isize=337; 
		pub const TEXT:isize=338; 
		pub const STRING_KW:isize=339; 
		pub const THEN:isize=340; 
		pub const TIES:isize=341; 
		pub const TIME:isize=342; 
		pub const TIMESTAMP:isize=343; 
		pub const TO:isize=344; 
		pub const TOP:isize=345; 
		pub const TRAILING:isize=346; 
		pub const TRANSACTION:isize=347; 
		pub const TRIM:isize=348; 
		pub const TRUE:isize=349; 
		pub const TRUNCATE:isize=350; 
		pub const TRY_CAST:isize=351; 
		pub const TUPLE:isize=352; 
		pub const TYPE:isize=353; 
		pub const UESCAPE:isize=354; 
		pub const UNBOUNDED:isize=355; 
		pub const UNCOMMITTED:isize=356; 
		pub const UNCONDITIONAL:isize=357; 
		pub const UNION:isize=358; 
		pub const UNIQUE:isize=359; 
		pub const UNKNOWN:isize=360; 
		pub const UNLOAD:isize=361; 
		pub const UNMATCHED:isize=362; 
		pub const UNNEST:isize=363; 
		pub const UNPIVOT:isize=364; 
		pub const UNSIGNED:isize=365; 
		pub const UPDATE:isize=366; 
		pub const USE:isize=367; 
		pub const USER:isize=368; 
		pub const USING:isize=369; 
		pub const UTF16:isize=370; 
		pub const UTF32:isize=371; 
		pub const UTF8:isize=372; 
		pub const VACUUM:isize=373; 
		pub const VALIDATE:isize=374; 
		pub const VALUE:isize=375; 
		pub const VALUES:isize=376; 
		pub const VARYING:isize=377; 
		pub const VARIADIC:isize=378; 
		pub const VERBOSE:isize=379; 
		pub const VERSION:isize=380; 
		pub const VIEW:isize=381; 
		pub const VOLATILE:isize=382; 
		pub const WEEK:isize=383; 
		pub const WHEN:isize=384; 
		pub const WHERE:isize=385; 
		pub const WINDOW:isize=386; 
		pub const WITH:isize=387; 
		pub const WITHIN:isize=388; 
		pub const WITHOUT:isize=389; 
		pub const WORK:isize=390; 
		pub const WRAPPER:isize=391; 
		pub const WRITE:isize=392; 
		pub const XZ:isize=393; 
		pub const YEAR:isize=394; 
		pub const YEARS:isize=395; 
		pub const YES:isize=396; 
		pub const ZONE:isize=397; 
		pub const ZSTD:isize=398; 
		pub const LPAREN:isize=399; 
		pub const RPAREN:isize=400; 
		pub const LBRACKET:isize=401; 
		pub const RBRACKET:isize=402; 
		pub const DOT:isize=403; 
		pub const EQ:isize=404; 
		pub const NEQ:isize=405; 
		pub const LT:isize=406; 
		pub const LTE:isize=407; 
		pub const GT:isize=408; 
		pub const GTE:isize=409; 
		pub const PLUS:isize=410; 
		pub const MINUS:isize=411; 
		pub const ASTERISK:isize=412; 
		pub const SLASH:isize=413; 
		pub const PERCENT:isize=414; 
		pub const CONCAT:isize=415; 
		pub const QUESTION_MARK:isize=416; 
		pub const SEMI_COLON:isize=417; 
		pub const COLON:isize=418; 
		pub const DOLLAR:isize=419; 
		pub const BITWISE_AND:isize=420; 
		pub const BITWISE_OR:isize=421; 
		pub const BITWISE_XOR:isize=422; 
		pub const BINARY_EXP:isize=423; 
		pub const BITWISE_SHIFT_LEFT:isize=424; 
		pub const BITWISE_SHIFT_RIGHT:isize=425; 
		pub const POSIX:isize=426; 
		pub const POSIX_LIKE:isize=427; 
		pub const POSIX_ILIKE:isize=428; 
		pub const POSIX_NOT_LIKE:isize=429; 
		pub const POSIX_NOT_ILIKE:isize=430; 
		pub const POSIX_STAR:isize=431; 
		pub const ESCAPE_SEQUENCE:isize=432; 
		pub const STRING:isize=433; 
		pub const UNICODE_STRING:isize=434; 
		pub const DOLLAR_QUOTED_STRING:isize=435; 
		pub const BINARY_LITERAL:isize=436; 
		pub const INTEGER_VALUE:isize=437; 
		pub const DECIMAL_VALUE:isize=438; 
		pub const DOUBLE_VALUE:isize=439; 
		pub const IDENTIFIER:isize=440; 
		pub const DIGIT_IDENTIFIER:isize=441; 
		pub const DOLLAR_HASH_IDENTIFIER:isize=442; 
		pub const QUOTED_IDENTIFIER:isize=443; 
		pub const VARIABLE:isize=444; 
		pub const SIMPLE_COMMENT:isize=445; 
		pub const BRACKETED_COMMENT:isize=446; 
		pub const WS:isize=447; 
		pub const UNPAIRED_TOKEN:isize=448; 
		pub const UNRECOGNIZED:isize=449;
	pub const RULE_multipleStatement:usize = 0; 
	pub const RULE_singleStatement:usize = 1; 
	pub const RULE_standaloneExpression:usize = 2; 
	pub const RULE_standaloneQualifiedName:usize = 3; 
	pub const RULE_standaloneType:usize = 4; 
	pub const RULE_statement:usize = 5; 
	pub const RULE_tableElements:usize = 6; 
	pub const RULE_unpivotNullClause:usize = 7; 
	pub const RULE_redshiftCreateExternalTableClauses:usize = 8; 
	pub const RULE_redshiftCreateExternalTableAsClauses:usize = 9; 
	pub const RULE_locationSpec:usize = 10; 
	pub const RULE_partitionedByNameSpec:usize = 11; 
	pub const RULE_partitionedByFieldSpec:usize = 12; 
	pub const RULE_createFileFormat:usize = 13; 
	pub const RULE_rowFormatedSpec:usize = 14; 
	pub const RULE_rowFormatedAndSerdeSpec:usize = 15; 
	pub const RULE_tableProperties:usize = 16; 
	pub const RULE_functionPropertySpec:usize = 17; 
	pub const RULE_query:usize = 18; 
	pub const RULE_with:usize = 19; 
	pub const RULE_tableElement:usize = 20; 
	pub const RULE_tableConstraint:usize = 21; 
	pub const RULE_columnDefinition:usize = 22; 
	pub const RULE_fieldDefinition:usize = 23; 
	pub const RULE_columnName:usize = 24; 
	pub const RULE_columnNameComponent:usize = 25; 
	pub const RULE_columnSchemaWithMetadata:usize = 26; 
	pub const RULE_columnOptionList:usize = 27; 
	pub const RULE_columnOption:usize = 28; 
	pub const RULE_columnSchema:usize = 29; 
	pub const RULE_columnAttributes:usize = 30; 
	pub const RULE_columnConstraints:usize = 31; 
	pub const RULE_likeClause:usize = 32; 
	pub const RULE_redshiftTableAttributes:usize = 33; 
	pub const RULE_properties:usize = 34; 
	pub const RULE_propertyAssignments:usize = 35; 
	pub const RULE_property:usize = 36; 
	pub const RULE_propertyKey:usize = 37; 
	pub const RULE_propertyValue:usize = 38; 
	pub const RULE_queryNoWith:usize = 39; 
	pub const RULE_queryLimit:usize = 40; 
	pub const RULE_queryLimitTarget:usize = 41; 
	pub const RULE_limitRowCount:usize = 42; 
	pub const RULE_rowCount:usize = 43; 
	pub const RULE_queryTerm:usize = 44; 
	pub const RULE_setOperation:usize = 45; 
	pub const RULE_setOperator:usize = 46; 
	pub const RULE_setOperationIntersect:usize = 47; 
	pub const RULE_setIntersectOperator:usize = 48; 
	pub const RULE_setQuantifier:usize = 49; 
	pub const RULE_inlineTable:usize = 50; 
	pub const RULE_queryPrimary:usize = 51; 
	pub const RULE_sortItem:usize = 52; 
	pub const RULE_querySpecification:usize = 53; 
	pub const RULE_querySelectItems:usize = 54; 
	pub const RULE_aggregationClause:usize = 55; 
	pub const RULE_groupBy:usize = 56; 
	pub const RULE_groupingElement:usize = 57; 
	pub const RULE_groupingSet:usize = 58; 
	pub const RULE_windowDefinition:usize = 59; 
	pub const RULE_windowSpecification:usize = 60; 
	pub const RULE_windowSpecificationPartitionBy:usize = 61; 
	pub const RULE_orderBy:usize = 62; 
	pub const RULE_namedQuery:usize = 63; 
	pub const RULE_selectItemAlias:usize = 64; 
	pub const RULE_selectItem:usize = 65; 
	pub const RULE_multiSelect:usize = 66; 
	pub const RULE_selectStar:usize = 67; 
	pub const RULE_relation:usize = 68; 
	pub const RULE_joinedRelation:usize = 69; 
	pub const RULE_joinType:usize = 70; 
	pub const RULE_joinCriteria:usize = 71; 
	pub const RULE_noJoinRelation:usize = 72; 
	pub const RULE_trimsSpecification:usize = 73; 
	pub const RULE_listAggOverflowBehavior:usize = 74; 
	pub const RULE_listaggCountIndication:usize = 75; 
	pub const RULE_variableDefinition:usize = 76; 
	pub const RULE_pivotedRelationTarget:usize = 77; 
	pub const RULE_pivotedRelation:usize = 78; 
	pub const RULE_pivotAggregates:usize = 79; 
	pub const RULE_pivotFrom:usize = 80; 
	pub const RULE_pivotInto:usize = 81; 
	pub const RULE_pivotAsAlias:usize = 82; 
	pub const RULE_singleColumnUnpivot:usize = 83; 
	pub const RULE_columnsToUnpivot:usize = 84; 
	pub const RULE_columnUnpivot:usize = 85; 
	pub const RULE_pivotIntos:usize = 86; 
	pub const RULE_pivotOperator:usize = 87; 
	pub const RULE_aliasedRelationTarget:usize = 88; 
	pub const RULE_aliasedRelation:usize = 89; 
	pub const RULE_columnAliases:usize = 90; 
	pub const RULE_partitionColumn:usize = 91; 
	pub const RULE_partitionColumns:usize = 92; 
	pub const RULE_relationPrimary:usize = 93; 
	pub const RULE_tableFunctionCall:usize = 94; 
	pub const RULE_tableFunctionArgumentCopartition:usize = 95; 
	pub const RULE_tableFunctionArgumentName:usize = 96; 
	pub const RULE_tableFunctionArgument:usize = 97; 
	pub const RULE_tableArgument:usize = 98; 
	pub const RULE_tableArgumentRelation:usize = 99; 
	pub const RULE_descriptorArgument:usize = 100; 
	pub const RULE_descriptorField:usize = 101; 
	pub const RULE_copartitionTables:usize = 102; 
	pub const RULE_expression:usize = 103; 
	pub const RULE_booleanExpression:usize = 104; 
	pub const RULE_comparisonPredicate:usize = 105; 
	pub const RULE_nonComparisonExpression:usize = 106; 
	pub const RULE_predicate:usize = 107; 
	pub const RULE_valueExpression:usize = 108; 
	pub const RULE_primaryExpression:usize = 109; 
	pub const RULE_functionCallHead:usize = 110; 
	pub const RULE_functionCallTail:usize = 111; 
	pub const RULE_callArgument:usize = 112; 
	pub const RULE_functionExtraArguments:usize = 113; 
	pub const RULE_functionName:usize = 114; 
	pub const RULE_namedParameter:usize = 115; 
	pub const RULE_field:usize = 116; 
	pub const RULE_jsonPathInvocation:usize = 117; 
	pub const RULE_jsonValueExpression:usize = 118; 
	pub const RULE_jsonRepresentation:usize = 119; 
	pub const RULE_jsonArgument:usize = 120; 
	pub const RULE_jsonExistsErrorBehavior:usize = 121; 
	pub const RULE_jsonValueBehavior:usize = 122; 
	pub const RULE_jsonQueryWrapperBehavior:usize = 123; 
	pub const RULE_jsonQueryBehavior:usize = 124; 
	pub const RULE_jsonObjectMember:usize = 125; 
	pub const RULE_processingMode:usize = 126; 
	pub const RULE_nullTreatment:usize = 127; 
	pub const RULE_string:usize = 128; 
	pub const RULE_timeZoneSpecifier:usize = 129; 
	pub const RULE_comparisonOperator:usize = 130; 
	pub const RULE_comparisonQuantifier:usize = 131; 
	pub const RULE_booleanValue:usize = 132; 
	pub const RULE_interval:usize = 133; 
	pub const RULE_intervalField:usize = 134; 
	pub const RULE_normalForm:usize = 135; 
	pub const RULE_typeIdentifier:usize = 136; 
	pub const RULE_type_:usize = 137; 
	pub const RULE_rowField:usize = 138; 
	pub const RULE_typeParameter:usize = 139; 
	pub const RULE_whenClause:usize = 140; 
	pub const RULE_filter:usize = 141; 
	pub const RULE_over:usize = 142; 
	pub const RULE_windowFrame:usize = 143; 
	pub const RULE_frameExtent:usize = 144; 
	pub const RULE_frameBound:usize = 145; 
	pub const RULE_rowPattern:usize = 146; 
	pub const RULE_patternPrimary:usize = 147; 
	pub const RULE_patternQuantifier:usize = 148; 
	pub const RULE_transactionMode:usize = 149; 
	pub const RULE_levelOfIsolation:usize = 150; 
	pub const RULE_privilege:usize = 151; 
	pub const RULE_qualifiedName:usize = 152; 
	pub const RULE_pathExpression:usize = 153; 
	pub const RULE_queryPeriod:usize = 154; 
	pub const RULE_rangeType:usize = 155; 
	pub const RULE_principal:usize = 156; 
	pub const RULE_identifier:usize = 157; 
	pub const RULE_quotedIdentifier:usize = 158; 
	pub const RULE_pathComponent:usize = 159; 
	pub const RULE_standaloneIdentifier:usize = 160; 
	pub const RULE_number:usize = 161; 
	pub const RULE_strictNonReserved:usize = 162; 
	pub const RULE_nonReserved:usize = 163;
	pub const ruleNames: [&'static str; 164] =  [
		"multipleStatement", "singleStatement", "standaloneExpression", "standaloneQualifiedName", 
		"standaloneType", "statement", "tableElements", "unpivotNullClause", "redshiftCreateExternalTableClauses", 
		"redshiftCreateExternalTableAsClauses", "locationSpec", "partitionedByNameSpec", 
		"partitionedByFieldSpec", "createFileFormat", "rowFormatedSpec", "rowFormatedAndSerdeSpec", 
		"tableProperties", "functionPropertySpec", "query", "with", "tableElement", 
		"tableConstraint", "columnDefinition", "fieldDefinition", "columnName", 
		"columnNameComponent", "columnSchemaWithMetadata", "columnOptionList", 
		"columnOption", "columnSchema", "columnAttributes", "columnConstraints", 
		"likeClause", "redshiftTableAttributes", "properties", "propertyAssignments", 
		"property", "propertyKey", "propertyValue", "queryNoWith", "queryLimit", 
		"queryLimitTarget", "limitRowCount", "rowCount", "queryTerm", "setOperation", 
		"setOperator", "setOperationIntersect", "setIntersectOperator", "setQuantifier", 
		"inlineTable", "queryPrimary", "sortItem", "querySpecification", "querySelectItems", 
		"aggregationClause", "groupBy", "groupingElement", "groupingSet", "windowDefinition", 
		"windowSpecification", "windowSpecificationPartitionBy", "orderBy", "namedQuery", 
		"selectItemAlias", "selectItem", "multiSelect", "selectStar", "relation", 
		"joinedRelation", "joinType", "joinCriteria", "noJoinRelation", "trimsSpecification", 
		"listAggOverflowBehavior", "listaggCountIndication", "variableDefinition", 
		"pivotedRelationTarget", "pivotedRelation", "pivotAggregates", "pivotFrom", 
		"pivotInto", "pivotAsAlias", "singleColumnUnpivot", "columnsToUnpivot", 
		"columnUnpivot", "pivotIntos", "pivotOperator", "aliasedRelationTarget", 
		"aliasedRelation", "columnAliases", "partitionColumn", "partitionColumns", 
		"relationPrimary", "tableFunctionCall", "tableFunctionArgumentCopartition", 
		"tableFunctionArgumentName", "tableFunctionArgument", "tableArgument", 
		"tableArgumentRelation", "descriptorArgument", "descriptorField", "copartitionTables", 
		"expression", "booleanExpression", "comparisonPredicate", "nonComparisonExpression", 
		"predicate", "valueExpression", "primaryExpression", "functionCallHead", 
		"functionCallTail", "callArgument", "functionExtraArguments", "functionName", 
		"namedParameter", "field", "jsonPathInvocation", "jsonValueExpression", 
		"jsonRepresentation", "jsonArgument", "jsonExistsErrorBehavior", "jsonValueBehavior", 
		"jsonQueryWrapperBehavior", "jsonQueryBehavior", "jsonObjectMember", "processingMode", 
		"nullTreatment", "string", "timeZoneSpecifier", "comparisonOperator", 
		"comparisonQuantifier", "booleanValue", "interval", "intervalField", "normalForm", 
		"typeIdentifier", "type_", "rowField", "typeParameter", "whenClause", 
		"filter", "over", "windowFrame", "frameExtent", "frameBound", "rowPattern", 
		"patternPrimary", "patternQuantifier", "transactionMode", "levelOfIsolation", 
		"privilege", "qualifiedName", "pathExpression", "queryPeriod", "rangeType", 
		"principal", "identifier", "quotedIdentifier", "pathComponent", "standaloneIdentifier", 
		"number", "strictNonReserved", "nonReserved"
	];


	pub const _LITERAL_NAMES: [Option<&'static str>;432] = [
		None, Some("'$$'"), Some("'=>'"), Some("'(+)'"), Some("'->'"), Some("'::'"), 
		Some("'{-'"), Some("'-}'"), Some("'{'"), Some("'}'"), Some("'ABORT'"), 
		Some("'ABSENT'"), Some("'ADD'"), Some("'ADMIN'"), Some("'AFTER'"), Some("'ALL'"), 
		Some("'ALTER'"), Some("'ANALYZE'"), Some("'AND'"), Some("'ANTI'"), Some("'ANY'"), 
		Some("'APPROXIMATE'"), Some("'ARRAY'"), Some("'AS'"), Some("'ASC'"), Some("'AT'"), 
		Some("'ATTACH'"), Some("'AUTHORIZATION'"), Some("'AUTO'"), Some("'BACKUP'"), 
		Some("'BEGIN'"), Some("'BERNOULLI'"), Some("'BETWEEN'"), Some("'BINARY'"), 
		Some("'BINDING'"), Some("'BOTH'"), Some("'BY'"), Some("'BZIP2'"), Some("'CALL'"), 
		Some("'CANCEL'"), Some("'CASCADE'"), Some("'CASE'"), Some("'CASE_SENSITIVE'"), 
		Some("'CASE_INSENSITIVE'"), Some("'CAST'"), Some("'CATALOGS'"), Some("'CHARACTER'"), 
		Some("'CLONE'"), Some("'CLOSE'"), Some("'CLUSTER'"), Some("'COLLATE'"), 
		Some("'COLUMN'"), Some("'COLUMNS'"), Some("','"), Some("'COMMENT'"), Some("'COMMIT'"), 
		Some("'COMMITTED'"), Some("'COMPOUND'"), Some("'COMPRESSION'"), Some("'CONDITIONAL'"), 
		Some("'CONNECT'"), Some("'CONNECTION'"), Some("'CONSTRAINT'"), Some("'CONVERT'"), 
		Some("'COPARTITION'"), Some("'COPY'"), Some("'COUNT'"), Some("'CREATE'"), 
		Some("'CROSS'"), Some("'CUBE'"), Some("'CURRENT'"), Some("'CURRENT_ROLE'"), 
		Some("'DATA'"), Some("'DATABASE'"), Some("'DATASHARE'"), Some("'DATE'"), 
		Some("'DAY'"), Some("'DAYS'"), Some("'DEALLOCATE'"), Some("'DECLARE'"), 
		Some("'DEFAULT'"), Some("'DEFAULTS'"), Some("'DEFINE'"), Some("'DEFINER'"), 
		Some("'DELETE'"), Some("'DELIMITED'"), Some("'DELIMITER'"), Some("'DENY'"), 
		Some("'DESC'"), Some("'DESCRIBE'"), Some("'DESCRIPTOR'"), Some("'DISTINCT'"), 
		Some("'DISTKEY'"), Some("'DISTRIBUTED'"), Some("'DISTSTYLE'"), Some("'DETACH'"), 
		Some("'DOUBLE'"), Some("'DROP'"), Some("'ELSE'"), Some("'EMPTY'"), Some("'ENCODE'"), 
		Some("'ENCODING'"), Some("'END'"), Some("'ERROR'"), Some("'ESCAPE'"), 
		Some("'EVEN'"), Some("'EXCEPT'"), Some("'EXCLUDE'"), Some("'EXCLUDING'"), 
		Some("'EXECUTE'"), Some("'EXISTS'"), Some("'EXPLAIN'"), Some("'EXTERNAL'"), 
		Some("'EXTRACT'"), Some("'FALSE'"), Some("'FETCH'"), Some("'FIELDS'"), 
		Some("'FILTER'"), Some("'FINAL'"), Some("'FIRST'"), Some("'FIRST_VALUE'"), 
		Some("'FOLLOWING'"), Some("'FOR'"), Some("'FOREIGN'"), Some("'FORMAT'"), 
		Some("'FROM'"), Some("'FULL'"), Some("'FUNCTION'"), Some("'FUNCTIONS'"), 
		Some("'GENERATED'"), Some("'GRACE'"), Some("'GRANT'"), Some("'GRANTED'"), 
		Some("'GRANTS'"), Some("'GRAPHVIZ'"), Some("'GROUP'"), Some("'GROUPING'"), 
		Some("'GROUPS'"), Some("'GZIP'"), Some("'HAVING'"), Some("'HEADER'"), 
		Some("'HOUR'"), Some("'HOURS'"), Some("'IAM_ROLE'"), Some("'IDENTITY'"), 
		Some("'IF'"), Some("'IGNORE'"), Some("'IMMUTABLE'"), Some("'IN'"), Some("'INCLUDE'"), 
		Some("'INCLUDING'"), Some("'INITIAL'"), Some("'INNER'"), Some("'INPUT'"), 
		Some("'INPUTFORMAT'"), Some("'INOUT'"), Some("'INTERLEAVED'"), Some("'INSERT'"), 
		Some("'INTERSECT'"), Some("'INTERVAL'"), Some("'INTO'"), Some("'INVOKER'"), 
		Some("'IO'"), Some("'IS'"), Some("'ISOLATION'"), Some("'ISNULL'"), Some("'ILIKE'"), 
		Some("'JOIN'"), Some("'JSON'"), Some("'JSON_ARRAY'"), Some("'JSON_EXISTS'"), 
		Some("'JSON_OBJECT'"), Some("'JSON_QUERY'"), Some("'JSON_VALUE'"), Some("'KB'"), 
		Some("'KEEP'"), Some("'KEY'"), Some("'KEYS'"), Some("'LAG'"), Some("'LAMBDA'"), 
		Some("'LANGUAGE'"), Some("'LAST'"), Some("'LAST_VALUE'"), Some("'LATERAL'"), 
		Some("'LEADING'"), Some("'LEFT'"), Some("'LEVEL'"), Some("'LIBRARY'"), 
		Some("'LIKE'"), Some("'LIMIT'"), Some("'LINES'"), Some("'LISTAGG'"), Some("'LISTAGGDISTINCT'"), 
		Some("'LOCAL'"), Some("'LOCATION'"), Some("'LOCK'"), Some("'LOGICAL'"), 
		Some("'M'"), Some("'MAP'"), Some("'MASKING'"), Some("'MATCH'"), Some("'MATCHED'"), 
		Some("'MATCHES'"), Some("'MATCH_RECOGNIZE'"), Some("'MATERIALIZED'"), 
		Some("'MAX'"), Some("'MAX_BATCH_ROWS'"), Some("'MAX_BATCH_SIZE'"), Some("'MB'"), 
		Some("'MEASURES'"), Some("'MERGE'"), Some("'MIN'"), Some("'MINUS'"), Some("'MINUTE'"), 
		Some("'MINUTES'"), Some("'MODEL'"), Some("'MONTH'"), Some("'MONTHS'"), 
		Some("'NATURAL'"), Some("'NEXT'"), Some("'NFC'"), Some("'NFD'"), Some("'NFKC'"), 
		Some("'NFKD'"), Some("'NO'"), Some("'NONE'"), Some("'NORMALIZE'"), Some("'NOT'"), 
		Some("'NOTNULL'"), Some("'NULL'"), Some("'NULLS'"), Some("'OBJECT'"), 
		Some("'OF'"), Some("'OFFSET'"), Some("'OMIT'"), Some("'ON'"), Some("'ONE'"), 
		Some("'ONLY'"), Some("'OPTION'"), Some("'OPTIONS'"), Some("'OR'"), Some("'ORDER'"), 
		Some("'ORDINALITY'"), Some("'OUT'"), Some("'OUTER'"), Some("'OUTPUT'"), 
		Some("'OUTPUTFORMAT'"), Some("'OVER'"), Some("'OVERFLOW'"), Some("'PARTITION'"), 
		Some("'PARTITIONED'"), Some("'PARTITIONS'"), Some("'PASSING'"), Some("'PAST'"), 
		Some("'PATH'"), Some("'PATTERN'"), Some("'PER'"), Some("'PERCENTILE_CONT'"), 
		Some("'PERCENTILE_DISC'"), Some("'PERIOD'"), Some("'PERMUTE'"), Some("'PG_CATALOG'"), 
		Some("'PIVOT'"), Some("'POSITION'"), Some("'PRECEDING'"), Some("'PRECISION'"), 
		Some("'PREPARE'"), Some("'PRIOR'"), Some("'PROCEDURE'"), Some("'PRIMARY'"), 
		Some("'PRIVILEGES'"), Some("'PROPERTIES'"), Some("'PRUNE'"), Some("'QUALIFY'"), 
		Some("'QUOTES'"), Some("'RANGE'"), Some("'READ'"), Some("'RECURSIVE'"), 
		Some("'REFERENCES'"), Some("'REFRESH'"), Some("'RENAME'"), Some("'REPEATABLE'"), 
		Some("'REPLACE'"), Some("'RESET'"), Some("'RESPECT'"), Some("'RESTRICT'"), 
		Some("'RETRY_TIMEOUT'"), Some("'RETURNING'"), Some("'RETURNS'"), Some("'REVOKE'"), 
		Some("'RIGHT'"), Some("'RLS'"), Some("'ROLE'"), Some("'ROLES'"), Some("'ROLLBACK'"), 
		Some("'ROLLUP'"), Some("'ROW'"), Some("'ROWS'"), Some("'RUNNING'"), Some("'S'"), 
		Some("'SAGEMAKER'"), Some("'SCALAR'"), Some("'SEC'"), Some("'SECOND'"), 
		Some("'SECONDS'"), Some("'SCHEMA'"), Some("'SCHEMAS'"), Some("'SECURITY'"), 
		Some("'SEEK'"), Some("'SELECT'"), Some("'SEMI'"), Some("'SERDE'"), Some("'SERDEPROPERTIES'"), 
		Some("'SERIALIZABLE'"), Some("'SESSION'"), Some("'SET'"), Some("'SETS'"), 
		Some("'SHOW'"), Some("'SIMILAR'"), Some("'SNAPSHOT'"), Some("'SOME'"), 
		Some("'SORTKEY'"), Some("'SQL'"), Some("'STABLE'"), Some("'START'"), Some("'STATS'"), 
		Some("'STORED'"), Some("'STRUCT'"), Some("'SUBSET'"), Some("'SUBSTRING'"), 
		Some("'SYSTEM'"), Some("'SYSTEM_TIME'"), Some("'TABLE'"), Some("'TABLES'"), 
		Some("'TABLESAMPLE'"), Some("'TEMP'"), Some("'TEMPORARY'"), Some("'TERMINATED'"), 
		Some("'TEXT'"), Some("'STRING'"), Some("'THEN'"), Some("'TIES'"), Some("'TIME'"), 
		Some("'TIMESTAMP'"), Some("'TO'"), Some("'TOP'"), Some("'TRAILING'"), 
		Some("'TRANSACTION'"), Some("'TRIM'"), Some("'TRUE'"), Some("'TRUNCATE'"), 
		Some("'TRY_CAST'"), Some("'TUPLE'"), Some("'TYPE'"), Some("'UESCAPE'"), 
		Some("'UNBOUNDED'"), Some("'UNCOMMITTED'"), Some("'UNCONDITIONAL'"), Some("'UNION'"), 
		Some("'UNIQUE'"), Some("'UNKNOWN'"), Some("'UNLOAD'"), Some("'UNMATCHED'"), 
		Some("'UNNEST'"), Some("'UNPIVOT'"), Some("'UNSIGNED'"), Some("'UPDATE'"), 
		Some("'USE'"), Some("'USER'"), Some("'USING'"), Some("'UTF16'"), Some("'UTF32'"), 
		Some("'UTF8'"), Some("'VACUUM'"), Some("'VALIDATE'"), Some("'VALUE'"), 
		Some("'VALUES'"), Some("'VARYING'"), Some("'VARIADIC'"), Some("'VERBOSE'"), 
		Some("'VERSION'"), Some("'VIEW'"), Some("'VOLATILE'"), Some("'WEEK'"), 
		Some("'WHEN'"), Some("'WHERE'"), Some("'WINDOW'"), Some("'WITH'"), Some("'WITHIN'"), 
		Some("'WITHOUT'"), Some("'WORK'"), Some("'WRAPPER'"), Some("'WRITE'"), 
		Some("'XZ'"), Some("'YEAR'"), Some("'YEARS'"), Some("'YES'"), Some("'ZONE'"), 
		Some("'ZSTD'"), Some("'('"), Some("')'"), Some("'['"), Some("']'"), Some("'.'"), 
		Some("'='"), None, Some("'<'"), Some("'<='"), Some("'>'"), Some("'>='"), 
		Some("'+'"), Some("'-'"), Some("'*'"), Some("'/'"), Some("'%'"), Some("'||'"), 
		Some("'?'"), Some("';'"), Some("':'"), Some("'$'"), Some("'&'"), Some("'|'"), 
		Some("'#'"), Some("'^'"), Some("'<<'"), Some("'>>'"), Some("'~'"), Some("'~~'"), 
		Some("'~~*'"), Some("'!~~'"), Some("'!~~*'"), Some("'~*'")
	];
	pub const _SYMBOLIC_NAMES: [Option<&'static str>;450]  = [
		None, None, None, None, None, None, None, None, None, None, Some("ABORT"), 
		Some("ABSENT"), Some("ADD"), Some("ADMIN"), Some("AFTER"), Some("ALL"), 
		Some("ALTER"), Some("ANALYZE"), Some("AND"), Some("ANTI"), Some("ANY"), 
		Some("APPROXIMATE"), Some("ARRAY"), Some("AS"), Some("ASC"), Some("AT"), 
		Some("ATTACH"), Some("AUTHORIZATION"), Some("AUTO"), Some("BACKUP"), Some("BEGIN"), 
		Some("BERNOULLI"), Some("BETWEEN"), Some("BINARY"), Some("BINDING"), Some("BOTH"), 
		Some("BY"), Some("BZIP2"), Some("CALL"), Some("CANCEL"), Some("CASCADE"), 
		Some("CASE"), Some("CASE_SENSITIVE"), Some("CASE_INSENSITIVE"), Some("CAST"), 
		Some("CATALOGS"), Some("CHARACTER"), Some("CLONE"), Some("CLOSE"), Some("CLUSTER"), 
		Some("COLLATE"), Some("COLUMN"), Some("COLUMNS"), Some("COMMA"), Some("COMMENT"), 
		Some("COMMIT"), Some("COMMITTED"), Some("COMPOUND"), Some("COMPRESSION"), 
		Some("CONDITIONAL"), Some("CONNECT"), Some("CONNECTION"), Some("CONSTRAINT"), 
		Some("CONVERT"), Some("COPARTITION"), Some("COPY"), Some("COUNT"), Some("CREATE"), 
		Some("CROSS"), Some("CUBE"), Some("CURRENT"), Some("CURRENT_ROLE"), Some("DATA"), 
		Some("DATABASE"), Some("DATASHARE"), Some("DATE"), Some("DAY"), Some("DAYS"), 
		Some("DEALLOCATE"), Some("DECLARE"), Some("DEFAULT"), Some("DEFAULTS"), 
		Some("DEFINE"), Some("DEFINER"), Some("DELETE"), Some("DELIMITED"), Some("DELIMITER"), 
		Some("DENY"), Some("DESC"), Some("DESCRIBE"), Some("DESCRIPTOR"), Some("DISTINCT"), 
		Some("DISTKEY"), Some("DISTRIBUTED"), Some("DISTSTYLE"), Some("DETACH"), 
		Some("DOUBLE"), Some("DROP"), Some("ELSE"), Some("EMPTY"), Some("ENCODE"), 
		Some("ENCODING"), Some("END"), Some("ERROR"), Some("ESCAPE"), Some("EVEN"), 
		Some("EXCEPT"), Some("EXCLUDE"), Some("EXCLUDING"), Some("EXECUTE"), Some("EXISTS"), 
		Some("EXPLAIN"), Some("EXTERNAL"), Some("EXTRACT"), Some("FALSE"), Some("FETCH"), 
		Some("FIELDS"), Some("FILTER"), Some("FINAL"), Some("FIRST"), Some("FIRST_VALUE"), 
		Some("FOLLOWING"), Some("FOR"), Some("FOREIGN"), Some("FORMAT"), Some("FROM"), 
		Some("FULL"), Some("FUNCTION"), Some("FUNCTIONS"), Some("GENERATED"), 
		Some("GRACE"), Some("GRANT"), Some("GRANTED"), Some("GRANTS"), Some("GRAPHVIZ"), 
		Some("GROUP"), Some("GROUPING"), Some("GROUPS"), Some("GZIP"), Some("HAVING"), 
		Some("HEADER"), Some("HOUR"), Some("HOURS"), Some("IAM_ROLE"), Some("IDENTITY"), 
		Some("IF"), Some("IGNORE"), Some("IMMUTABLE"), Some("IN"), Some("INCLUDE"), 
		Some("INCLUDING"), Some("INITIAL"), Some("INNER"), Some("INPUT"), Some("INPUTFORMAT"), 
		Some("INOUT"), Some("INTERLEAVED"), Some("INSERT"), Some("INTERSECT"), 
		Some("INTERVAL"), Some("INTO"), Some("INVOKER"), Some("IO"), Some("IS"), 
		Some("ISOLATION"), Some("ISNULL"), Some("ILIKE"), Some("JOIN"), Some("JSON"), 
		Some("JSON_ARRAY"), Some("JSON_EXISTS"), Some("JSON_OBJECT"), Some("JSON_QUERY"), 
		Some("JSON_VALUE"), Some("KB"), Some("KEEP"), Some("KEY"), Some("KEYS"), 
		Some("LAG"), Some("LAMBDA"), Some("LANGUAGE"), Some("LAST"), Some("LAST_VALUE"), 
		Some("LATERAL"), Some("LEADING"), Some("LEFT"), Some("LEVEL"), Some("LIBRARY"), 
		Some("LIKE"), Some("LIMIT"), Some("LINES"), Some("LISTAGG"), Some("LISTAGGDISTINCT"), 
		Some("LOCAL"), Some("LOCATION"), Some("LOCK"), Some("LOGICAL"), Some("M"), 
		Some("MAP"), Some("MASKING"), Some("MATCH"), Some("MATCHED"), Some("MATCHES"), 
		Some("MATCH_RECOGNIZE"), Some("MATERIALIZED"), Some("MAX"), Some("MAX_BATCH_ROWS"), 
		Some("MAX_BATCH_SIZE"), Some("MB"), Some("MEASURES"), Some("MERGE"), Some("MIN"), 
		Some("MINUS_KW"), Some("MINUTE"), Some("MINUTES"), Some("MODEL"), Some("MONTH"), 
		Some("MONTHS"), Some("NATURAL"), Some("NEXT"), Some("NFC"), Some("NFD"), 
		Some("NFKC"), Some("NFKD"), Some("NO"), Some("NONE"), Some("NORMALIZE"), 
		Some("NOT"), Some("NOTNULL"), Some("NULL"), Some("NULLS"), Some("OBJECT"), 
		Some("OF"), Some("OFFSET"), Some("OMIT"), Some("ON"), Some("ONE"), Some("ONLY"), 
		Some("OPTION"), Some("OPTIONS"), Some("OR"), Some("ORDER"), Some("ORDINALITY"), 
		Some("OUT"), Some("OUTER"), Some("OUTPUT"), Some("OUTPUTFORMAT"), Some("OVER"), 
		Some("OVERFLOW"), Some("PARTITION"), Some("PARTITIONED"), Some("PARTITIONS"), 
		Some("PASSING"), Some("PAST"), Some("PATH"), Some("PATTERN"), Some("PER"), 
		Some("PERCENTILE_CONT"), Some("PERCENTILE_DISC"), Some("PERIOD"), Some("PERMUTE"), 
		Some("PG_CATALOG"), Some("PIVOT"), Some("POSITION"), Some("PRECEDING"), 
		Some("PRECISION"), Some("PREPARE"), Some("PRIOR"), Some("PROCEDURE"), 
		Some("PRIMARY"), Some("PRIVILEGES"), Some("PROPERTIES"), Some("PRUNE"), 
		Some("QUALIFY"), Some("QUOTES"), Some("RANGE"), Some("READ"), Some("RECURSIVE"), 
		Some("REFERENCES"), Some("REFRESH"), Some("RENAME"), Some("REPEATABLE"), 
		Some("REPLACE"), Some("RESET"), Some("RESPECT"), Some("RESTRICT"), Some("RETRY_TIMEOUT"), 
		Some("RETURNING"), Some("RETURNS"), Some("REVOKE"), Some("RIGHT"), Some("RLS"), 
		Some("ROLE"), Some("ROLES"), Some("ROLLBACK"), Some("ROLLUP"), Some("ROW"), 
		Some("ROWS"), Some("RUNNING"), Some("S"), Some("SAGEMAKER"), Some("SCALAR"), 
		Some("SEC"), Some("SECOND"), Some("SECONDS"), Some("SCHEMA"), Some("SCHEMAS"), 
		Some("SECURITY"), Some("SEEK"), Some("SELECT"), Some("SEMI"), Some("SERDE"), 
		Some("SERDEPROPERTIES"), Some("SERIALIZABLE"), Some("SESSION"), Some("SET"), 
		Some("SETS"), Some("SHOW"), Some("SIMILAR"), Some("SNAPSHOT"), Some("SOME"), 
		Some("SORTKEY"), Some("SQL"), Some("STABLE"), Some("START"), Some("STATS"), 
		Some("STORED"), Some("STRUCT"), Some("SUBSET"), Some("SUBSTRING"), Some("SYSTEM"), 
		Some("SYSTEM_TIME"), Some("TABLE"), Some("TABLES"), Some("TABLESAMPLE"), 
		Some("TEMP"), Some("TEMPORARY"), Some("TERMINATED"), Some("TEXT"), Some("STRING_KW"), 
		Some("THEN"), Some("TIES"), Some("TIME"), Some("TIMESTAMP"), Some("TO"), 
		Some("TOP"), Some("TRAILING"), Some("TRANSACTION"), Some("TRIM"), Some("TRUE"), 
		Some("TRUNCATE"), Some("TRY_CAST"), Some("TUPLE"), Some("TYPE"), Some("UESCAPE"), 
		Some("UNBOUNDED"), Some("UNCOMMITTED"), Some("UNCONDITIONAL"), Some("UNION"), 
		Some("UNIQUE"), Some("UNKNOWN"), Some("UNLOAD"), Some("UNMATCHED"), Some("UNNEST"), 
		Some("UNPIVOT"), Some("UNSIGNED"), Some("UPDATE"), Some("USE"), Some("USER"), 
		Some("USING"), Some("UTF16"), Some("UTF32"), Some("UTF8"), Some("VACUUM"), 
		Some("VALIDATE"), Some("VALUE"), Some("VALUES"), Some("VARYING"), Some("VARIADIC"), 
		Some("VERBOSE"), Some("VERSION"), Some("VIEW"), Some("VOLATILE"), Some("WEEK"), 
		Some("WHEN"), Some("WHERE"), Some("WINDOW"), Some("WITH"), Some("WITHIN"), 
		Some("WITHOUT"), Some("WORK"), Some("WRAPPER"), Some("WRITE"), Some("XZ"), 
		Some("YEAR"), Some("YEARS"), Some("YES"), Some("ZONE"), Some("ZSTD"), 
		Some("LPAREN"), Some("RPAREN"), Some("LBRACKET"), Some("RBRACKET"), Some("DOT"), 
		Some("EQ"), Some("NEQ"), Some("LT"), Some("LTE"), Some("GT"), Some("GTE"), 
		Some("PLUS"), Some("MINUS"), Some("ASTERISK"), Some("SLASH"), Some("PERCENT"), 
		Some("CONCAT"), Some("QUESTION_MARK"), Some("SEMI_COLON"), Some("COLON"), 
		Some("DOLLAR"), Some("BITWISE_AND"), Some("BITWISE_OR"), Some("BITWISE_XOR"), 
		Some("BINARY_EXP"), Some("BITWISE_SHIFT_LEFT"), Some("BITWISE_SHIFT_RIGHT"), 
		Some("POSIX"), Some("POSIX_LIKE"), Some("POSIX_ILIKE"), Some("POSIX_NOT_LIKE"), 
		Some("POSIX_NOT_ILIKE"), Some("POSIX_STAR"), Some("ESCAPE_SEQUENCE"), 
		Some("STRING"), Some("UNICODE_STRING"), Some("DOLLAR_QUOTED_STRING"), 
		Some("BINARY_LITERAL"), Some("INTEGER_VALUE"), Some("DECIMAL_VALUE"), 
		Some("DOUBLE_VALUE"), Some("IDENTIFIER"), Some("DIGIT_IDENTIFIER"), Some("DOLLAR_HASH_IDENTIFIER"), 
		Some("QUOTED_IDENTIFIER"), Some("VARIABLE"), Some("SIMPLE_COMMENT"), Some("BRACKETED_COMMENT"), 
		Some("WS"), Some("UNPAIRED_TOKEN"), Some("UNRECOGNIZED")
	];
	thread_local!{
	    static _shared_context_cache: Rc<PredictionContextCache> = Rc::new(PredictionContextCache::new());
		static VOCABULARY: Box<dyn Vocabulary> = Box::new(VocabularyImpl::new(_LITERAL_NAMES.iter(), _SYMBOLIC_NAMES.iter(), None));
	}


type BaseParserType<'input, I> =
	BaseParser<'input,RedshiftParserExt<'input>, I, RedshiftParserContextType , dyn RedshiftListener<'input> + 'input >;

type TokenType<'input> = <LocalTokenFactory<'input> as TokenFactory<'input>>::Tok;

pub type LocalTokenFactory<'input> = antlr_rust::token_factory::ArenaCommonFactory<'input>;

pub type RedshiftTreeWalker<'input,'a> =
	ParseTreeWalker<'input, 'a, RedshiftParserContextType , dyn RedshiftListener<'input> + 'a>;

/// Parser for Redshift grammar
pub struct RedshiftParser<'input,I,H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	base:BaseParserType<'input,I>,
	interpreter:Rc<ParserATNSimulator>,
	_shared_context_cache: Box<PredictionContextCache>,
    pub err_handler: H,
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn get_serialized_atn() -> &'static str { _serializedATN }

    pub fn set_error_strategy(&mut self, strategy: H) {
        self.err_handler = strategy
    }

    pub fn with_strategy(input: I, strategy: H) -> Self {
		antlr_rust::recognizer::check_version("0","3");
        let interpreter = Rc::new(ParserATNSimulator::new(
            _ATN.with(|atn| atn.clone()),
            _decision_to_DFA.with(|decision| decision.clone()),
            _shared_context_cache.with(|ctx| ctx.clone()),
        ));
		Self {
			base: BaseParser::new_base_parser(
				input,
				Rc::clone(&interpreter),
				RedshiftParserExt{
					_pd: Default::default(),
				}
			),
			interpreter,
            _shared_context_cache: Box::new(PredictionContextCache::new()),
            err_handler: strategy,
        }
    }

    pub fn add_error_listener(&mut self, listener: Box<(dyn ErrorListener<'input, BaseParser<'input, RedshiftParserExt<'input>, I, RedshiftParserContextType, (dyn RedshiftListener<'input> + 'input)>> + 'static)>) {
        self.base.add_error_listener(listener)
    }

	pub fn remove_error_listeners(&mut self) {
        self.base.remove_error_listeners()
    }
}

type DynStrategy<'input,I> = Box<dyn ErrorStrategy<'input,BaseParserType<'input,I>> + 'input>;

impl<'input, I> RedshiftParser<'input, I, DynStrategy<'input,I>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn with_dyn_strategy(input: I) -> Self{
    	Self::with_strategy(input,Box::new(DefaultErrorStrategy::new()))
    }
}

impl<'input, I> RedshiftParser<'input, I, DefaultErrorStrategy<'input,RedshiftParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn new(input: I) -> Self{
    	Self::with_strategy(input,DefaultErrorStrategy::new())
    }
}

/// Trait for monomorphized trait object that corresponds to the nodes of parse tree generated for RedshiftParser
pub trait RedshiftParserContext<'input>:
	for<'x> Listenable<dyn RedshiftListener<'input> + 'x > + 
	for<'x> Visitable<dyn RedshiftVisitor<'input> + 'x > + 
	ParserRuleContext<'input, TF=LocalTokenFactory<'input>, Ctx=RedshiftParserContextType>
{}

antlr_rust::coerce_from!{ 'input : RedshiftParserContext<'input> }

impl<'input, 'x, T> VisitableDyn<T> for dyn RedshiftParserContext<'input> + 'input
where
    T: RedshiftVisitor<'input> + 'x,
{
    fn accept_dyn(&self, visitor: &mut T) {
        self.accept(visitor as &mut (dyn RedshiftVisitor<'input> + 'x))
    }
}

impl<'input> RedshiftParserContext<'input> for TerminalNode<'input,RedshiftParserContextType> {}
impl<'input> RedshiftParserContext<'input> for ErrorNode<'input,RedshiftParserContextType> {}

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn RedshiftParserContext<'input> + 'input }

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn RedshiftListener<'input> + 'input }

pub struct RedshiftParserContextType;
antlr_rust::tid!{RedshiftParserContextType}

impl<'input> ParserNodeType<'input> for RedshiftParserContextType{
	type TF = LocalTokenFactory<'input>;
	type Type = dyn RedshiftParserContext<'input> + 'input;
}

impl<'input, I, H> Deref for RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    type Target = BaseParserType<'input,I>;

    fn deref(&self) -> &Self::Target {
        &self.base
    }
}

impl<'input, I, H> DerefMut for RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.base
    }
}

pub struct RedshiftParserExt<'input>{
	_pd: PhantomData<&'input str>,
}

impl<'input> RedshiftParserExt<'input>{
}
antlr_rust::tid! { RedshiftParserExt<'a> }

impl<'input> TokenAware<'input> for RedshiftParserExt<'input>{
	type TF = LocalTokenFactory<'input>;
}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> ParserRecog<'input, BaseParserType<'input,I>> for RedshiftParserExt<'input>{}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> Actions<'input, BaseParserType<'input,I>> for RedshiftParserExt<'input>{
	fn get_grammar_file_name(&self) -> & str{ "Redshift.g4"}

   	fn get_rule_names(&self) -> &[& str] {&ruleNames}

   	fn get_vocabulary(&self) -> &dyn Vocabulary { VOCABULARY.with(|v| unsafe { std::mem::transmute(&**v) }) }
	fn sempred(_localctx: Option<&(dyn RedshiftParserContext<'input> + 'input)>, rule_index: isize, pred_index: isize,
			   recog:&mut BaseParserType<'input,I>
	)->bool{
		match rule_index {
					69 => RedshiftParser::<'input,I,_>::joinedRelation_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					104 => RedshiftParser::<'input,I,_>::booleanExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					108 => RedshiftParser::<'input,I,_>::valueExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					109 => RedshiftParser::<'input,I,_>::primaryExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					146 => RedshiftParser::<'input,I,_>::rowPattern_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
			_ => true
		}
	}
}

impl<'input, I> RedshiftParser<'input, I, DefaultErrorStrategy<'input,RedshiftParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
	fn joinedRelation_sempred(_localctx: Option<&JoinedRelationContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				0=>{
					recog.precpred(None, 2)
				}
			_ => true
		}
	}
	fn booleanExpression_sempred(_localctx: Option<&BooleanExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				1=>{
					recog.precpred(None, 2)
				}
				2=>{
					recog.precpred(None, 1)
				}
				3=>{
					recog.precpred(None, 5)
				}
			_ => true
		}
	}
	fn valueExpression_sempred(_localctx: Option<&ValueExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				4=>{
					recog.precpred(None, 7)
				}
				5=>{
					recog.precpred(None, 6)
				}
				6=>{
					recog.precpred(None, 5)
				}
				7=>{
					recog.precpred(None, 4)
				}
				8=>{
					recog.precpred(None, 3)
				}
				9=>{
					recog.precpred(None, 2)
				}
				10=>{
					recog.precpred(None, 1)
				}
				11=>{
					recog.precpred(None, 9)
				}
			_ => true
		}
	}
	fn primaryExpression_sempred(_localctx: Option<&PrimaryExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				12=>{
					recog.precpred(None, 19)
				}
				13=>{
					recog.precpred(None, 18)
				}
				14=>{
					recog.precpred(None, 17)
				}
				15=>{
					recog.precpred(None, 16)
				}
			_ => true
		}
	}
	fn rowPattern_sempred(_localctx: Option<&RowPatternContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				16=>{
					recog.precpred(None, 2)
				}
				17=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
}
//------------------- multipleStatement ----------------
pub type MultipleStatementContextAll<'input> = MultipleStatementContext<'input>;


pub type MultipleStatementContext<'input> = BaseParserRuleContext<'input,MultipleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct MultipleStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for MultipleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for MultipleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multipleStatement(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_multipleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for MultipleStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_multipleStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multipleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multipleStatement }
}
antlr_rust::tid!{MultipleStatementContextExt<'a>}

impl<'input> MultipleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultipleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultipleStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultipleStatementContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<MultipleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement_all(&self) ->  Vec<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn statement(&self, i: usize) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SEMI_COLON, i)
}

}

impl<'input> MultipleStatementContextAttrs<'input> for MultipleStatementContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multipleStatement(&mut self,)
	-> Result<Rc<MultipleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultipleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 0, RULE_multipleStatement);
        let mut _localctx: Rc<MultipleStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(329);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 10)) & !0x3f) == 0 && ((1usize << (_la - 10)) & ((1usize << (ABORT - 10)) | (1usize << (ALTER - 10)) | (1usize << (ANALYZE - 10)) | (1usize << (ATTACH - 10)) | (1usize << (BEGIN - 10)) | (1usize << (CALL - 10)) | (1usize << (CANCEL - 10)))) != 0) || ((((_la - 48)) & !0x3f) == 0 && ((1usize << (_la - 48)) & ((1usize << (CLOSE - 48)) | (1usize << (COMMENT - 48)) | (1usize << (COMMIT - 48)) | (1usize << (COPY - 48)) | (1usize << (CREATE - 48)) | (1usize << (DEALLOCATE - 48)) | (1usize << (DECLARE - 48)))) != 0) || ((((_la - 84)) & !0x3f) == 0 && ((1usize << (_la - 84)) & ((1usize << (DELETE - 84)) | (1usize << (DENY - 84)) | (1usize << (DESCRIBE - 84)) | (1usize << (DETACH - 84)) | (1usize << (DROP - 84)) | (1usize << (END - 84)) | (1usize << (EXECUTE - 84)) | (1usize << (EXPLAIN - 84)) | (1usize << (FETCH - 84)))) != 0) || _la==GRANT || _la==INSERT || _la==LOCK || _la==MERGE || ((((_la - 266)) & !0x3f) == 0 && ((1usize << (_la - 266)) & ((1usize << (PREPARE - 266)) | (1usize << (REFRESH - 266)) | (1usize << (RESET - 266)) | (1usize << (REVOKE - 266)) | (1usize << (ROLLBACK - 266)))) != 0) || ((((_la - 309)) & !0x3f) == 0 && ((1usize << (_la - 309)) & ((1usize << (SELECT - 309)) | (1usize << (SET - 309)) | (1usize << (SHOW - 309)) | (1usize << (START - 309)) | (1usize << (TABLE - 309)))) != 0) || ((((_la - 350)) & !0x3f) == 0 && ((1usize << (_la - 350)) & ((1usize << (TRUNCATE - 350)) | (1usize << (UNLOAD - 350)) | (1usize << (UPDATE - 350)) | (1usize << (USE - 350)) | (1usize << (VACUUM - 350)) | (1usize << (VALUES - 350)))) != 0) || _la==WITH || _la==LPAREN {
				{
				/*InvokeRule statement*/
				recog.base.set_state(328);
				recog.statement()?;

				}
			}

			recog.base.set_state(337);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==SEMI_COLON {
				{
				{
				recog.base.set_state(331);
				recog.base.match_token(SEMI_COLON,&mut recog.err_handler)?;

				recog.base.set_state(333);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if ((((_la - 10)) & !0x3f) == 0 && ((1usize << (_la - 10)) & ((1usize << (ABORT - 10)) | (1usize << (ALTER - 10)) | (1usize << (ANALYZE - 10)) | (1usize << (ATTACH - 10)) | (1usize << (BEGIN - 10)) | (1usize << (CALL - 10)) | (1usize << (CANCEL - 10)))) != 0) || ((((_la - 48)) & !0x3f) == 0 && ((1usize << (_la - 48)) & ((1usize << (CLOSE - 48)) | (1usize << (COMMENT - 48)) | (1usize << (COMMIT - 48)) | (1usize << (COPY - 48)) | (1usize << (CREATE - 48)) | (1usize << (DEALLOCATE - 48)) | (1usize << (DECLARE - 48)))) != 0) || ((((_la - 84)) & !0x3f) == 0 && ((1usize << (_la - 84)) & ((1usize << (DELETE - 84)) | (1usize << (DENY - 84)) | (1usize << (DESCRIBE - 84)) | (1usize << (DETACH - 84)) | (1usize << (DROP - 84)) | (1usize << (END - 84)) | (1usize << (EXECUTE - 84)) | (1usize << (EXPLAIN - 84)) | (1usize << (FETCH - 84)))) != 0) || _la==GRANT || _la==INSERT || _la==LOCK || _la==MERGE || ((((_la - 266)) & !0x3f) == 0 && ((1usize << (_la - 266)) & ((1usize << (PREPARE - 266)) | (1usize << (REFRESH - 266)) | (1usize << (RESET - 266)) | (1usize << (REVOKE - 266)) | (1usize << (ROLLBACK - 266)))) != 0) || ((((_la - 309)) & !0x3f) == 0 && ((1usize << (_la - 309)) & ((1usize << (SELECT - 309)) | (1usize << (SET - 309)) | (1usize << (SHOW - 309)) | (1usize << (START - 309)) | (1usize << (TABLE - 309)))) != 0) || ((((_la - 350)) & !0x3f) == 0 && ((1usize << (_la - 350)) & ((1usize << (TRUNCATE - 350)) | (1usize << (UNLOAD - 350)) | (1usize << (UPDATE - 350)) | (1usize << (USE - 350)) | (1usize << (VACUUM - 350)) | (1usize << (VALUES - 350)))) != 0) || _la==WITH || _la==LPAREN {
					{
					/*InvokeRule statement*/
					recog.base.set_state(332);
					recog.statement()?;

					}
				}

				}
				}
				recog.base.set_state(339);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(340);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleStatement ----------------
pub type SingleStatementContextAll<'input> = SingleStatementContext<'input>;


pub type SingleStatementContext<'input> = BaseParserRuleContext<'input,SingleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SingleStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SingleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SingleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleStatement(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_singleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SingleStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_singleStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleStatement }
}
antlr_rust::tid!{SingleStatementContextExt<'a>}

impl<'input> SingleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleStatementContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SingleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SEMI_COLON
/// Returns `None` if there is no child corresponding to token SEMI_COLON
fn SEMI_COLON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SEMI_COLON, 0)
}

}

impl<'input> SingleStatementContextAttrs<'input> for SingleStatementContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleStatement(&mut self,)
	-> Result<Rc<SingleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 2, RULE_singleStatement);
        let mut _localctx: Rc<SingleStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(343);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 10)) & !0x3f) == 0 && ((1usize << (_la - 10)) & ((1usize << (ABORT - 10)) | (1usize << (ALTER - 10)) | (1usize << (ANALYZE - 10)) | (1usize << (ATTACH - 10)) | (1usize << (BEGIN - 10)) | (1usize << (CALL - 10)) | (1usize << (CANCEL - 10)))) != 0) || ((((_la - 48)) & !0x3f) == 0 && ((1usize << (_la - 48)) & ((1usize << (CLOSE - 48)) | (1usize << (COMMENT - 48)) | (1usize << (COMMIT - 48)) | (1usize << (COPY - 48)) | (1usize << (CREATE - 48)) | (1usize << (DEALLOCATE - 48)) | (1usize << (DECLARE - 48)))) != 0) || ((((_la - 84)) & !0x3f) == 0 && ((1usize << (_la - 84)) & ((1usize << (DELETE - 84)) | (1usize << (DENY - 84)) | (1usize << (DESCRIBE - 84)) | (1usize << (DETACH - 84)) | (1usize << (DROP - 84)) | (1usize << (END - 84)) | (1usize << (EXECUTE - 84)) | (1usize << (EXPLAIN - 84)) | (1usize << (FETCH - 84)))) != 0) || _la==GRANT || _la==INSERT || _la==LOCK || _la==MERGE || ((((_la - 266)) & !0x3f) == 0 && ((1usize << (_la - 266)) & ((1usize << (PREPARE - 266)) | (1usize << (REFRESH - 266)) | (1usize << (RESET - 266)) | (1usize << (REVOKE - 266)) | (1usize << (ROLLBACK - 266)))) != 0) || ((((_la - 309)) & !0x3f) == 0 && ((1usize << (_la - 309)) & ((1usize << (SELECT - 309)) | (1usize << (SET - 309)) | (1usize << (SHOW - 309)) | (1usize << (START - 309)) | (1usize << (TABLE - 309)))) != 0) || ((((_la - 350)) & !0x3f) == 0 && ((1usize << (_la - 350)) & ((1usize << (TRUNCATE - 350)) | (1usize << (UNLOAD - 350)) | (1usize << (UPDATE - 350)) | (1usize << (USE - 350)) | (1usize << (VACUUM - 350)) | (1usize << (VALUES - 350)))) != 0) || _la==WITH || _la==LPAREN {
				{
				/*InvokeRule statement*/
				recog.base.set_state(342);
				recog.statement()?;

				}
			}

			recog.base.set_state(346);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SEMI_COLON {
				{
				recog.base.set_state(345);
				recog.base.match_token(SEMI_COLON,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(348);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneExpression ----------------
pub type StandaloneExpressionContextAll<'input> = StandaloneExpressionContext<'input>;


pub type StandaloneExpressionContext<'input> = BaseParserRuleContext<'input,StandaloneExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for StandaloneExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StandaloneExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneExpression(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_standaloneExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StandaloneExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_standaloneExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneExpression }
}
antlr_rust::tid!{StandaloneExpressionContextExt<'a>}

impl<'input> StandaloneExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneExpressionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<StandaloneExpressionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneExpressionContextAttrs<'input> for StandaloneExpressionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneExpression(&mut self,)
	-> Result<Rc<StandaloneExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 4, RULE_standaloneExpression);
        let mut _localctx: Rc<StandaloneExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(350);
			recog.expression()?;

			recog.base.set_state(351);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneQualifiedName ----------------
pub type StandaloneQualifiedNameContextAll<'input> = StandaloneQualifiedNameContext<'input>;


pub type StandaloneQualifiedNameContext<'input> = BaseParserRuleContext<'input,StandaloneQualifiedNameContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneQualifiedNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for StandaloneQualifiedNameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StandaloneQualifiedNameContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneQualifiedName(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_standaloneQualifiedName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StandaloneQualifiedNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_standaloneQualifiedName(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneQualifiedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneQualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneQualifiedName }
}
antlr_rust::tid!{StandaloneQualifiedNameContextExt<'a>}

impl<'input> StandaloneQualifiedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneQualifiedNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneQualifiedNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneQualifiedNameContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<StandaloneQualifiedNameContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneQualifiedNameContextAttrs<'input> for StandaloneQualifiedNameContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneQualifiedName(&mut self,)
	-> Result<Rc<StandaloneQualifiedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneQualifiedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 6, RULE_standaloneQualifiedName);
        let mut _localctx: Rc<StandaloneQualifiedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(353);
			recog.qualifiedName()?;

			recog.base.set_state(354);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneType ----------------
pub type StandaloneTypeContextAll<'input> = StandaloneTypeContext<'input>;


pub type StandaloneTypeContext<'input> = BaseParserRuleContext<'input,StandaloneTypeContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for StandaloneTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StandaloneTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneType(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_standaloneType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StandaloneTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_standaloneType(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneType }
}
antlr_rust::tid!{StandaloneTypeContextExt<'a>}

impl<'input> StandaloneTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneTypeContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<StandaloneTypeContextExt<'input>>{

fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneTypeContextAttrs<'input> for StandaloneTypeContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneType(&mut self,)
	-> Result<Rc<StandaloneTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 8, RULE_standaloneType);
        let mut _localctx: Rc<StandaloneTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule type_*/
			recog.base.set_state(356);
			recog.type_()?;

			recog.base.set_state(357);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- statement ----------------
#[derive(Debug)]
pub enum StatementContextAll<'input>{
	CancelContext(CancelContext<'input>),
	ExplainContext(ExplainContext<'input>),
	CreateFooContext(CreateFooContext<'input>),
	PrepareContext(PrepareContext<'input>),
	RedshiftCreateViewContext(RedshiftCreateViewContext<'input>),
	SetMaterializedViewPropertiesContext(SetMaterializedViewPropertiesContext<'input>),
	DeclareContext(DeclareContext<'input>),
	UseContext(UseContext<'input>),
	DeallocateContext(DeallocateContext<'input>),
	RenameTableContext(RenameTableContext<'input>),
	CommitContext(CommitContext<'input>),
	RedshiftCreateTableAsSelectContext(RedshiftCreateTableAsSelectContext<'input>),
	CreateRoleContext(CreateRoleContext<'input>),
	DropViewContext(DropViewContext<'input>),
	DropColumnContext(DropColumnContext<'input>),
	SetViewAuthorizationContext(SetViewAuthorizationContext<'input>),
	MergeContext(MergeContext<'input>),
	RenameColumnContext(RenameColumnContext<'input>),
	UnloadContext(UnloadContext<'input>),
	RedshiftCreateTableContext(RedshiftCreateTableContext<'input>),
	LockContext(LockContext<'input>),
	ShowColumnsContext(ShowColumnsContext<'input>),
	AlterContext(AlterContext<'input>),
	AddColumnContext(AddColumnContext<'input>),
	DenyContext(DenyContext<'input>),
	CreateGroupContext(CreateGroupContext<'input>),
	CreateExternalSchemaContext(CreateExternalSchemaContext<'input>),
	InsertIntoContext(InsertIntoContext<'input>),
	CreateSchemaContext(CreateSchemaContext<'input>),
	ExecuteContext(ExecuteContext<'input>),
	RenameSchemaContext(RenameSchemaContext<'input>),
	RedshiftCreateMaterializedViewContext(RedshiftCreateMaterializedViewContext<'input>),
	AbortContext(AbortContext<'input>),
	RedshiftCreateExternalTableAsContext(RedshiftCreateExternalTableAsContext<'input>),
	AnalyzeContext(AnalyzeContext<'input>),
	CreateFunctionContext(CreateFunctionContext<'input>),
	ResetContext(ResetContext<'input>),
	DropSchemaContext(DropSchemaContext<'input>),
	BeginContext(BeginContext<'input>),
	SetTableAuthorizationContext(SetTableAuthorizationContext<'input>),
	CreateIdentityContext(CreateIdentityContext<'input>),
	DropContext(DropContext<'input>),
	StartTransactionContext(StartTransactionContext<'input>),
	ShowContext(ShowContext<'input>),
	RevokeContext(RevokeContext<'input>),
	UpdateContext(UpdateContext<'input>),
	TableExecuteContext(TableExecuteContext<'input>),
	DeleteContext(DeleteContext<'input>),
	DescribeInputContext(DescribeInputContext<'input>),
	CreateProcedureContext(CreateProcedureContext<'input>),
	SetColumnTypeContext(SetColumnTypeContext<'input>),
	VacuumContext(VacuumContext<'input>),
	StatementDefaultContext(StatementDefaultContext<'input>),
	TruncateTableContext(TruncateTableContext<'input>),
	EndContext(EndContext<'input>),
	AttachContext(AttachContext<'input>),
	CopyContext(CopyContext<'input>),
	CloseContext(CloseContext<'input>),
	RenameMaterializedViewContext(RenameMaterializedViewContext<'input>),
	DropTableContext(DropTableContext<'input>),
	SetSchemaAuthorizationContext(SetSchemaAuthorizationContext<'input>),
	RollbackContext(RollbackContext<'input>),
	RedshiftCreateExternalTableContext(RedshiftCreateExternalTableContext<'input>),
	SetContext(SetContext<'input>),
	RenameViewContext(RenameViewContext<'input>),
	CallContext(CallContext<'input>),
	RefreshMaterializedViewContext(RefreshMaterializedViewContext<'input>),
	FetchContext(FetchContext<'input>),
	DetachContext(DetachContext<'input>),
	CommentContext(CommentContext<'input>),
	CreateUserContext(CreateUserContext<'input>),
	DescribeOutputContext(DescribeOutputContext<'input>),
	GrantContext(GrantContext<'input>),
	SetTablePropertiesContext(SetTablePropertiesContext<'input>),
Error(StatementContext<'input>)
}
antlr_rust::tid!{StatementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StatementContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for StatementContextAll<'input>{}

impl<'input> Deref for StatementContextAll<'input>{
	type Target = dyn StatementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StatementContextAll::*;
		match self{
			CancelContext(inner) => inner,
			ExplainContext(inner) => inner,
			CreateFooContext(inner) => inner,
			PrepareContext(inner) => inner,
			RedshiftCreateViewContext(inner) => inner,
			SetMaterializedViewPropertiesContext(inner) => inner,
			DeclareContext(inner) => inner,
			UseContext(inner) => inner,
			DeallocateContext(inner) => inner,
			RenameTableContext(inner) => inner,
			CommitContext(inner) => inner,
			RedshiftCreateTableAsSelectContext(inner) => inner,
			CreateRoleContext(inner) => inner,
			DropViewContext(inner) => inner,
			DropColumnContext(inner) => inner,
			SetViewAuthorizationContext(inner) => inner,
			MergeContext(inner) => inner,
			RenameColumnContext(inner) => inner,
			UnloadContext(inner) => inner,
			RedshiftCreateTableContext(inner) => inner,
			LockContext(inner) => inner,
			ShowColumnsContext(inner) => inner,
			AlterContext(inner) => inner,
			AddColumnContext(inner) => inner,
			DenyContext(inner) => inner,
			CreateGroupContext(inner) => inner,
			CreateExternalSchemaContext(inner) => inner,
			InsertIntoContext(inner) => inner,
			CreateSchemaContext(inner) => inner,
			ExecuteContext(inner) => inner,
			RenameSchemaContext(inner) => inner,
			RedshiftCreateMaterializedViewContext(inner) => inner,
			AbortContext(inner) => inner,
			RedshiftCreateExternalTableAsContext(inner) => inner,
			AnalyzeContext(inner) => inner,
			CreateFunctionContext(inner) => inner,
			ResetContext(inner) => inner,
			DropSchemaContext(inner) => inner,
			BeginContext(inner) => inner,
			SetTableAuthorizationContext(inner) => inner,
			CreateIdentityContext(inner) => inner,
			DropContext(inner) => inner,
			StartTransactionContext(inner) => inner,
			ShowContext(inner) => inner,
			RevokeContext(inner) => inner,
			UpdateContext(inner) => inner,
			TableExecuteContext(inner) => inner,
			DeleteContext(inner) => inner,
			DescribeInputContext(inner) => inner,
			CreateProcedureContext(inner) => inner,
			SetColumnTypeContext(inner) => inner,
			VacuumContext(inner) => inner,
			StatementDefaultContext(inner) => inner,
			TruncateTableContext(inner) => inner,
			EndContext(inner) => inner,
			AttachContext(inner) => inner,
			CopyContext(inner) => inner,
			CloseContext(inner) => inner,
			RenameMaterializedViewContext(inner) => inner,
			DropTableContext(inner) => inner,
			SetSchemaAuthorizationContext(inner) => inner,
			RollbackContext(inner) => inner,
			RedshiftCreateExternalTableContext(inner) => inner,
			SetContext(inner) => inner,
			RenameViewContext(inner) => inner,
			CallContext(inner) => inner,
			RefreshMaterializedViewContext(inner) => inner,
			FetchContext(inner) => inner,
			DetachContext(inner) => inner,
			CommentContext(inner) => inner,
			CreateUserContext(inner) => inner,
			DescribeOutputContext(inner) => inner,
			GrantContext(inner) => inner,
			SetTablePropertiesContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StatementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StatementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StatementContext<'input> = BaseParserRuleContext<'input,StatementContextExt<'input>>;

#[derive(Clone)]
pub struct StatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for StatementContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StatementContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StatementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}
antlr_rust::tid!{StatementContextExt<'a>}

impl<'input> StatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StatementContextAll<'input>> {
		Rc::new(
		StatementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StatementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StatementContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<StatementContextExt<'input>>{


}

impl<'input> StatementContextAttrs<'input> for StatementContext<'input>{}

pub type CancelContext<'input> = BaseParserRuleContext<'input,CancelContextExt<'input>>;

pub trait CancelContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CANCEL
	/// Returns `None` if there is no child corresponding to token CANCEL
	fn CANCEL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CANCEL, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CancelContextAttrs<'input> for CancelContext<'input>{}

pub struct CancelContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CancelContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CancelContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CancelContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_cancel(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_cancel(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CancelContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_cancel(self);
	}
}

impl<'input> CustomRuleContext<'input> for CancelContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CancelContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CancelContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CancelContext<'input> {}

impl<'input> CancelContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CancelContext(
				BaseParserRuleContext::copy_from(ctx,CancelContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExplainContext<'input> = BaseParserRuleContext<'input,ExplainContextExt<'input>>;

pub trait ExplainContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXPLAIN
	/// Returns `None` if there is no child corresponding to token EXPLAIN
	fn EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXPLAIN, 0)
	}
	fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token VERBOSE
	/// Returns `None` if there is no child corresponding to token VERBOSE
	fn VERBOSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VERBOSE, 0)
	}
}

impl<'input> ExplainContextAttrs<'input> for ExplainContext<'input>{}

pub struct ExplainContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExplainContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ExplainContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ExplainContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_explain(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_explain(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ExplainContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_explain(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExplainContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ExplainContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ExplainContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ExplainContext<'input> {}

impl<'input> ExplainContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ExplainContext(
				BaseParserRuleContext::copy_from(ctx,ExplainContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateFooContext<'input> = BaseParserRuleContext<'input,CreateFooContextExt<'input>>;

pub trait CreateFooContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATABASE
	/// Returns `None` if there is no child corresponding to token DATABASE
	fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DATABASE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
	/// Retrieves first TerminalNode corresponding to token DATASHARE
	/// Returns `None` if there is no child corresponding to token DATASHARE
	fn DATASHARE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DATASHARE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LIBRARY
	/// Returns `None` if there is no child corresponding to token LIBRARY
	fn LIBRARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LIBRARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MASKING
	/// Returns `None` if there is no child corresponding to token MASKING
	fn MASKING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MASKING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MODEL
	/// Returns `None` if there is no child corresponding to token MODEL
	fn MODEL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MODEL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RLS
	/// Returns `None` if there is no child corresponding to token RLS
	fn RLS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RLS, 0)
	}
}

impl<'input> CreateFooContextAttrs<'input> for CreateFooContext<'input>{}

pub struct CreateFooContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateFooContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateFooContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateFooContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createFoo(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createFoo(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateFooContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createFoo(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateFooContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateFooContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateFooContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateFooContext<'input> {}

impl<'input> CreateFooContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateFooContext(
				BaseParserRuleContext::copy_from(ctx,CreateFooContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrepareContext<'input> = BaseParserRuleContext<'input,PrepareContextExt<'input>>;

pub trait PrepareContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PREPARE
	/// Returns `None` if there is no child corresponding to token PREPARE
	fn PREPARE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PREPARE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> PrepareContextAttrs<'input> for PrepareContext<'input>{}

pub struct PrepareContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrepareContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PrepareContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PrepareContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_prepare(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_prepare(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PrepareContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_prepare(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrepareContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for PrepareContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for PrepareContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for PrepareContext<'input> {}

impl<'input> PrepareContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::PrepareContext(
				BaseParserRuleContext::copy_from(ctx,PrepareContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RedshiftCreateViewContext<'input> = BaseParserRuleContext<'input,RedshiftCreateViewContextExt<'input>>;

pub trait RedshiftCreateViewContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMENT
	/// Returns `None` if there is no child corresponding to token COMMENT
	fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SECURITY
	/// Returns `None` if there is no child corresponding to token SECURITY
	fn SECURITY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SECURITY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NO
	/// Returns `None` if there is no child corresponding to token NO
	fn NO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NO, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BINDING
	/// Returns `None` if there is no child corresponding to token BINDING
	fn BINDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BINDING, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DEFINER
	/// Returns `None` if there is no child corresponding to token DEFINER
	fn DEFINER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DEFINER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INVOKER
	/// Returns `None` if there is no child corresponding to token INVOKER
	fn INVOKER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INVOKER, 0)
	}
}

impl<'input> RedshiftCreateViewContextAttrs<'input> for RedshiftCreateViewContext<'input>{}

pub struct RedshiftCreateViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub comment: Option<Rc<StringContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RedshiftCreateViewContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RedshiftCreateViewContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftCreateViewContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_redshiftCreateView(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_redshiftCreateView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftCreateViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftCreateView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftCreateViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RedshiftCreateViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RedshiftCreateViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RedshiftCreateViewContext<'input> {}

impl<'input> RedshiftCreateViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RedshiftCreateViewContext(
				BaseParserRuleContext::copy_from(ctx,RedshiftCreateViewContextExt{
        			dest:None, comment:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetMaterializedViewPropertiesContext<'input> = BaseParserRuleContext<'input,SetMaterializedViewPropertiesContextExt<'input>>;

pub trait SetMaterializedViewPropertiesContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROPERTIES
	/// Returns `None` if there is no child corresponding to token PROPERTIES
	fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PROPERTIES, 0)
	}
	fn propertyAssignments(&self) -> Option<Rc<PropertyAssignmentsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetMaterializedViewPropertiesContextAttrs<'input> for SetMaterializedViewPropertiesContext<'input>{}

pub struct SetMaterializedViewPropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetMaterializedViewPropertiesContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SetMaterializedViewPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetMaterializedViewPropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setMaterializedViewProperties(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_setMaterializedViewProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetMaterializedViewPropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setMaterializedViewProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetMaterializedViewPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetMaterializedViewPropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetMaterializedViewPropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetMaterializedViewPropertiesContext<'input> {}

impl<'input> SetMaterializedViewPropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetMaterializedViewPropertiesContext(
				BaseParserRuleContext::copy_from(ctx,SetMaterializedViewPropertiesContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DeclareContext<'input> = BaseParserRuleContext<'input,DeclareContextExt<'input>>;

pub trait DeclareContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DECLARE
	/// Returns `None` if there is no child corresponding to token DECLARE
	fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DECLARE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DeclareContextAttrs<'input> for DeclareContext<'input>{}

pub struct DeclareContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeclareContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DeclareContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DeclareContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_declare(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_declare(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DeclareContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_declare(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclareContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DeclareContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DeclareContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DeclareContext<'input> {}

impl<'input> DeclareContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DeclareContext(
				BaseParserRuleContext::copy_from(ctx,DeclareContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UseContext<'input> = BaseParserRuleContext<'input,UseContextExt<'input>>;

pub trait UseContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token USE
	/// Returns `None` if there is no child corresponding to token USE
	fn USE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(USE, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
}

impl<'input> UseContextAttrs<'input> for UseContext<'input>{}

pub struct UseContextExt<'input>{
	base:StatementContextExt<'input>,
	pub schema: Option<Rc<IdentifierContextAll<'input>>>,
	pub catalog: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UseContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UseContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UseContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_use(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_use(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UseContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_use(self);
	}
}

impl<'input> CustomRuleContext<'input> for UseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UseContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UseContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UseContext<'input> {}

impl<'input> UseContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UseContext(
				BaseParserRuleContext::copy_from(ctx,UseContextExt{
        			schema:None, catalog:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DeallocateContext<'input> = BaseParserRuleContext<'input,DeallocateContextExt<'input>>;

pub trait DeallocateContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DEALLOCATE
	/// Returns `None` if there is no child corresponding to token DEALLOCATE
	fn DEALLOCATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DEALLOCATE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DeallocateContextAttrs<'input> for DeallocateContext<'input>{}

pub struct DeallocateContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeallocateContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DeallocateContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DeallocateContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_deallocate(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_deallocate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DeallocateContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_deallocate(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeallocateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DeallocateContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DeallocateContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DeallocateContext<'input> {}

impl<'input> DeallocateContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DeallocateContext(
				BaseParserRuleContext::copy_from(ctx,DeallocateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameTableContext<'input> = BaseParserRuleContext<'input,RenameTableContextExt<'input>>;

pub trait RenameTableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> RenameTableContextAttrs<'input> for RenameTableContext<'input>{}

pub struct RenameTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub to: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameTableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RenameTableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RenameTableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameTable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_renameTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RenameTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_renameTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameTableContext<'input> {}

impl<'input> RenameTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameTableContext(
				BaseParserRuleContext::copy_from(ctx,RenameTableContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommitContext<'input> = BaseParserRuleContext<'input,CommitContextExt<'input>>;

pub trait CommitContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMIT
	/// Returns `None` if there is no child corresponding to token COMMIT
	fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMIT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CommitContextAttrs<'input> for CommitContext<'input>{}

pub struct CommitContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommitContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CommitContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CommitContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_commit(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_commit(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CommitContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_commit(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommitContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommitContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommitContext<'input> {}

impl<'input> CommitContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommitContext(
				BaseParserRuleContext::copy_from(ctx,CommitContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RedshiftCreateTableAsSelectContext<'input> = BaseParserRuleContext<'input,RedshiftCreateTableAsSelectContextExt<'input>>;

pub trait RedshiftCreateTableAsSelectContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn redshiftTableAttributes(&self) -> Option<Rc<RedshiftTableAttributesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LOCAL
	/// Returns `None` if there is no child corresponding to token LOCAL
	fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LOCAL, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token BACKUP
	/// Returns `None` if there is no child corresponding to token BACKUP
	fn BACKUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BACKUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token NO in current rule
	fn NO_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token NO, starting from 0.
	/// Returns `None` if number of children corresponding to token NO is less or equal than `i`.
	fn NO(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NO, i)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BINDING
	/// Returns `None` if there is no child corresponding to token BINDING
	fn BINDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BINDING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMP
	/// Returns `None` if there is no child corresponding to token TEMP
	fn TEMP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TEMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token YES
	/// Returns `None` if there is no child corresponding to token YES
	fn YES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(YES, 0)
	}
}

impl<'input> RedshiftCreateTableAsSelectContextAttrs<'input> for RedshiftCreateTableAsSelectContext<'input>{}

pub struct RedshiftCreateTableAsSelectContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RedshiftCreateTableAsSelectContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RedshiftCreateTableAsSelectContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftCreateTableAsSelectContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_redshiftCreateTableAsSelect(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_redshiftCreateTableAsSelect(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftCreateTableAsSelectContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftCreateTableAsSelect(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftCreateTableAsSelectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RedshiftCreateTableAsSelectContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RedshiftCreateTableAsSelectContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RedshiftCreateTableAsSelectContext<'input> {}

impl<'input> RedshiftCreateTableAsSelectContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RedshiftCreateTableAsSelectContext(
				BaseParserRuleContext::copy_from(ctx,RedshiftCreateTableAsSelectContextExt{
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateRoleContext<'input> = BaseParserRuleContext<'input,CreateRoleContextExt<'input>>;

pub trait CreateRoleContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROLE
	/// Returns `None` if there is no child corresponding to token ROLE
	fn ROLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ROLE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateRoleContextAttrs<'input> for CreateRoleContext<'input>{}

pub struct CreateRoleContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateRoleContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateRoleContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateRoleContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createRole(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createRole(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateRoleContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createRole(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateRoleContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateRoleContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateRoleContext<'input> {}

impl<'input> CreateRoleContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateRoleContext(
				BaseParserRuleContext::copy_from(ctx,CreateRoleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropViewContext<'input> = BaseParserRuleContext<'input,DropViewContextExt<'input>>;

pub trait DropViewContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DropViewContextAttrs<'input> for DropViewContext<'input>{}

pub struct DropViewContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropViewContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DropViewContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DropViewContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropView(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_dropView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DropViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_dropView(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropViewContext<'input> {}

impl<'input> DropViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropViewContext(
				BaseParserRuleContext::copy_from(ctx,DropViewContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropColumnContext<'input> = BaseParserRuleContext<'input,DropColumnContextExt<'input>>;

pub trait DropColumnContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
}

impl<'input> DropColumnContextAttrs<'input> for DropColumnContext<'input>{}

pub struct DropColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub column: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropColumnContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DropColumnContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DropColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropColumn(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_dropColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DropColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_dropColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropColumnContext<'input> {}

impl<'input> DropColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropColumnContext(
				BaseParserRuleContext::copy_from(ctx,DropColumnContextExt{
        			tableName:None, column:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetViewAuthorizationContext<'input> = BaseParserRuleContext<'input,SetViewAuthorizationContextExt<'input>>;

pub trait SetViewAuthorizationContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetViewAuthorizationContextAttrs<'input> for SetViewAuthorizationContext<'input>{}

pub struct SetViewAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetViewAuthorizationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SetViewAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetViewAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setViewAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_setViewAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetViewAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setViewAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetViewAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetViewAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetViewAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetViewAuthorizationContext<'input> {}

impl<'input> SetViewAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetViewAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetViewAuthorizationContextExt{
        			from:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MergeContext<'input> = BaseParserRuleContext<'input,MergeContextExt<'input>>;

pub trait MergeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MERGE
	/// Returns `None` if there is no child corresponding to token MERGE
	fn MERGE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MERGE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> MergeContextAttrs<'input> for MergeContext<'input>{}

pub struct MergeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MergeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for MergeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for MergeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_merge(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_merge(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for MergeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_merge(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for MergeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for MergeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for MergeContext<'input> {}

impl<'input> MergeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::MergeContext(
				BaseParserRuleContext::copy_from(ctx,MergeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameColumnContext<'input> = BaseParserRuleContext<'input,RenameColumnContextExt<'input>>;

pub trait RenameColumnContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
}

impl<'input> RenameColumnContextAttrs<'input> for RenameColumnContext<'input>{}

pub struct RenameColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub from: Option<Rc<IdentifierContextAll<'input>>>,
	pub to: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameColumnContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RenameColumnContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RenameColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameColumn(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_renameColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RenameColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_renameColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameColumnContext<'input> {}

impl<'input> RenameColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameColumnContext(
				BaseParserRuleContext::copy_from(ctx,RenameColumnContextExt{
        			tableName:None, from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnloadContext<'input> = BaseParserRuleContext<'input,UnloadContextExt<'input>>;

pub trait UnloadContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNLOAD
	/// Returns `None` if there is no child corresponding to token UNLOAD
	fn UNLOAD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UNLOAD, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> UnloadContextAttrs<'input> for UnloadContext<'input>{}

pub struct UnloadContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnloadContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UnloadContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UnloadContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unload(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_unload(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UnloadContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_unload(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnloadContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UnloadContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UnloadContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UnloadContext<'input> {}

impl<'input> UnloadContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UnloadContext(
				BaseParserRuleContext::copy_from(ctx,UnloadContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RedshiftCreateTableContext<'input> = BaseParserRuleContext<'input,RedshiftCreateTableContextExt<'input>>;

pub trait RedshiftCreateTableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn redshiftTableAttributes(&self) -> Option<Rc<RedshiftTableAttributesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LOCAL
	/// Returns `None` if there is no child corresponding to token LOCAL
	fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LOCAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn tableElements(&self) -> Option<Rc<TableElementsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BACKUP
	/// Returns `None` if there is no child corresponding to token BACKUP
	fn BACKUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BACKUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMP
	/// Returns `None` if there is no child corresponding to token TEMP
	fn TEMP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TEMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token YES
	/// Returns `None` if there is no child corresponding to token YES
	fn YES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(YES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NO
	/// Returns `None` if there is no child corresponding to token NO
	fn NO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NO, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
}

impl<'input> RedshiftCreateTableContextAttrs<'input> for RedshiftCreateTableContext<'input>{}

pub struct RedshiftCreateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RedshiftCreateTableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RedshiftCreateTableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftCreateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_redshiftCreateTable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_redshiftCreateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftCreateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftCreateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftCreateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RedshiftCreateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RedshiftCreateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RedshiftCreateTableContext<'input> {}

impl<'input> RedshiftCreateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RedshiftCreateTableContext(
				BaseParserRuleContext::copy_from(ctx,RedshiftCreateTableContextExt{
					tail:None, 
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LockContext<'input> = BaseParserRuleContext<'input,LockContextExt<'input>>;

pub trait LockContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LOCK
	/// Returns `None` if there is no child corresponding to token LOCK
	fn LOCK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LOCK, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> LockContextAttrs<'input> for LockContext<'input>{}

pub struct LockContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LockContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for LockContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LockContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_lock(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_lock(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LockContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_lock(self);
	}
}

impl<'input> CustomRuleContext<'input> for LockContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for LockContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for LockContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for LockContext<'input> {}

impl<'input> LockContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::LockContext(
				BaseParserRuleContext::copy_from(ctx,LockContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowColumnsContext<'input> = BaseParserRuleContext<'input,ShowColumnsContextExt<'input>>;

pub trait ShowColumnsContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ShowColumnsContextAttrs<'input> for ShowColumnsContext<'input>{}

pub struct ShowColumnsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowColumnsContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ShowColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ShowColumnsContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showColumns(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_showColumns(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ShowColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_showColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowColumnsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowColumnsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowColumnsContext<'input> {}

impl<'input> ShowColumnsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowColumnsContext(
				BaseParserRuleContext::copy_from(ctx,ShowColumnsContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AlterContext<'input> = BaseParserRuleContext<'input,AlterContextExt<'input>>;

pub trait AlterContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> AlterContextAttrs<'input> for AlterContext<'input>{}

pub struct AlterContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AlterContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AlterContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AlterContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_alter(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_alter(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AlterContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_alter(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AlterContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AlterContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AlterContext<'input> {}

impl<'input> AlterContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AlterContext(
				BaseParserRuleContext::copy_from(ctx,AlterContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AddColumnContext<'input> = BaseParserRuleContext<'input,AddColumnContextExt<'input>>;

pub trait AddColumnContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ADD
	/// Returns `None` if there is no child corresponding to token ADD
	fn ADD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn columnDefinition(&self) -> Option<Rc<ColumnDefinitionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> AddColumnContextAttrs<'input> for AddColumnContext<'input>{}

pub struct AddColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub column: Option<Rc<ColumnDefinitionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AddColumnContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AddColumnContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AddColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_addColumn(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_addColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AddColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_addColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for AddColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AddColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AddColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AddColumnContext<'input> {}

impl<'input> AddColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AddColumnContext(
				BaseParserRuleContext::copy_from(ctx,AddColumnContextExt{
        			tableName:None, column:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DenyContext<'input> = BaseParserRuleContext<'input,DenyContextExt<'input>>;

pub trait DenyContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DENY
	/// Returns `None` if there is no child corresponding to token DENY
	fn DENY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DENY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn privilege_all(&self) ->  Vec<Rc<PrivilegeContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn privilege(&self, i: usize) -> Option<Rc<PrivilegeContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ALL
	/// Returns `None` if there is no child corresponding to token ALL
	fn ALL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PRIVILEGES
	/// Returns `None` if there is no child corresponding to token PRIVILEGES
	fn PRIVILEGES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PRIVILEGES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> DenyContextAttrs<'input> for DenyContext<'input>{}

pub struct DenyContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	pub grantee: Option<Rc<PrincipalContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DenyContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DenyContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DenyContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_deny(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_deny(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DenyContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_deny(self);
	}
}

impl<'input> CustomRuleContext<'input> for DenyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DenyContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DenyContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DenyContext<'input> {}

impl<'input> DenyContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DenyContext(
				BaseParserRuleContext::copy_from(ctx,DenyContextExt{
					tail:None, 
        			grantee:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateGroupContext<'input> = BaseParserRuleContext<'input,CreateGroupContextExt<'input>>;

pub trait CreateGroupContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateGroupContextAttrs<'input> for CreateGroupContext<'input>{}

pub struct CreateGroupContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateGroupContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateGroupContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateGroupContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createGroup(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createGroup(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateGroupContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createGroup(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateGroupContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateGroupContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateGroupContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateGroupContext<'input> {}

impl<'input> CreateGroupContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateGroupContext(
				BaseParserRuleContext::copy_from(ctx,CreateGroupContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateExternalSchemaContext<'input> = BaseParserRuleContext<'input,CreateExternalSchemaContextExt<'input>>;

pub trait CreateExternalSchemaContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTERNAL
	/// Returns `None` if there is no child corresponding to token EXTERNAL
	fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXTERNAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateExternalSchemaContextAttrs<'input> for CreateExternalSchemaContext<'input>{}

pub struct CreateExternalSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateExternalSchemaContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateExternalSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateExternalSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createExternalSchema(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createExternalSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateExternalSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createExternalSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateExternalSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateExternalSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateExternalSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateExternalSchemaContext<'input> {}

impl<'input> CreateExternalSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateExternalSchemaContext(
				BaseParserRuleContext::copy_from(ctx,CreateExternalSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertIntoContext<'input> = BaseParserRuleContext<'input,InsertIntoContextExt<'input>>;

pub trait InsertIntoContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InsertIntoContextAttrs<'input> for InsertIntoContext<'input>{}

pub struct InsertIntoContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertIntoContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for InsertIntoContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for InsertIntoContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertInto(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_insertInto(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for InsertIntoContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_insertInto(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertIntoContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for InsertIntoContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for InsertIntoContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for InsertIntoContext<'input> {}

impl<'input> InsertIntoContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::InsertIntoContext(
				BaseParserRuleContext::copy_from(ctx,InsertIntoContextExt{
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateSchemaContext<'input> = BaseParserRuleContext<'input,CreateSchemaContextExt<'input>>;

pub trait CreateSchemaContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateSchemaContextAttrs<'input> for CreateSchemaContext<'input>{}

pub struct CreateSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateSchemaContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createSchema(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateSchemaContext<'input> {}

impl<'input> CreateSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateSchemaContext(
				BaseParserRuleContext::copy_from(ctx,CreateSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExecuteContext<'input> = BaseParserRuleContext<'input,ExecuteContextExt<'input>>;

pub trait ExecuteContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXECUTE
	/// Returns `None` if there is no child corresponding to token EXECUTE
	fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXECUTE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ExecuteContextAttrs<'input> for ExecuteContext<'input>{}

pub struct ExecuteContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExecuteContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ExecuteContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ExecuteContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_execute(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_execute(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ExecuteContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_execute(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExecuteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ExecuteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ExecuteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ExecuteContext<'input> {}

impl<'input> ExecuteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ExecuteContext(
				BaseParserRuleContext::copy_from(ctx,ExecuteContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameSchemaContext<'input> = BaseParserRuleContext<'input,RenameSchemaContextExt<'input>>;

pub trait RenameSchemaContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RenameSchemaContextAttrs<'input> for RenameSchemaContext<'input>{}

pub struct RenameSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameSchemaContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RenameSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RenameSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameSchema(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_renameSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RenameSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_renameSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameSchemaContext<'input> {}

impl<'input> RenameSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameSchemaContext(
				BaseParserRuleContext::copy_from(ctx,RenameSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RedshiftCreateMaterializedViewContext<'input> = BaseParserRuleContext<'input,RedshiftCreateMaterializedViewContextExt<'input>>;

pub trait RedshiftCreateMaterializedViewContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn redshiftTableAttributes(&self) -> Option<Rc<RedshiftTableAttributesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BACKUP
	/// Returns `None` if there is no child corresponding to token BACKUP
	fn BACKUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BACKUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTO
	/// Returns `None` if there is no child corresponding to token AUTO
	fn AUTO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AUTO, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REFRESH
	/// Returns `None` if there is no child corresponding to token REFRESH
	fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REFRESH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GRACE
	/// Returns `None` if there is no child corresponding to token GRACE
	fn GRACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(GRACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PERIOD
	/// Returns `None` if there is no child corresponding to token PERIOD
	fn PERIOD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PERIOD, 0)
	}
	fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMENT
	/// Returns `None` if there is no child corresponding to token COMMENT
	fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMENT, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token YES in current rule
	fn YES_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token YES, starting from 0.
	/// Returns `None` if number of children corresponding to token YES is less or equal than `i`.
	fn YES(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(YES, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token NO in current rule
	fn NO_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token NO, starting from 0.
	/// Returns `None` if number of children corresponding to token NO is less or equal than `i`.
	fn NO(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NO, i)
	}
}

impl<'input> RedshiftCreateMaterializedViewContextAttrs<'input> for RedshiftCreateMaterializedViewContext<'input>{}

pub struct RedshiftCreateMaterializedViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RedshiftCreateMaterializedViewContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RedshiftCreateMaterializedViewContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftCreateMaterializedViewContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_redshiftCreateMaterializedView(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_redshiftCreateMaterializedView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftCreateMaterializedViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftCreateMaterializedView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftCreateMaterializedViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RedshiftCreateMaterializedViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RedshiftCreateMaterializedViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RedshiftCreateMaterializedViewContext<'input> {}

impl<'input> RedshiftCreateMaterializedViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RedshiftCreateMaterializedViewContext(
				BaseParserRuleContext::copy_from(ctx,RedshiftCreateMaterializedViewContextExt{
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AbortContext<'input> = BaseParserRuleContext<'input,AbortContextExt<'input>>;

pub trait AbortContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ABORT
	/// Returns `None` if there is no child corresponding to token ABORT
	fn ABORT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ABORT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WORK
	/// Returns `None` if there is no child corresponding to token WORK
	fn WORK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WORK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRANSACTION
	/// Returns `None` if there is no child corresponding to token TRANSACTION
	fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TRANSACTION, 0)
	}
}

impl<'input> AbortContextAttrs<'input> for AbortContext<'input>{}

pub struct AbortContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AbortContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AbortContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AbortContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_abort(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_abort(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AbortContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_abort(self);
	}
}

impl<'input> CustomRuleContext<'input> for AbortContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AbortContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AbortContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AbortContext<'input> {}

impl<'input> AbortContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AbortContext(
				BaseParserRuleContext::copy_from(ctx,AbortContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RedshiftCreateExternalTableAsContext<'input> = BaseParserRuleContext<'input,RedshiftCreateExternalTableAsContextExt<'input>>;

pub trait RedshiftCreateExternalTableAsContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTERNAL
	/// Returns `None` if there is no child corresponding to token EXTERNAL
	fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXTERNAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn redshiftCreateExternalTableAsClauses(&self) -> Option<Rc<RedshiftCreateExternalTableAsClausesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> RedshiftCreateExternalTableAsContextAttrs<'input> for RedshiftCreateExternalTableAsContext<'input>{}

pub struct RedshiftCreateExternalTableAsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RedshiftCreateExternalTableAsContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RedshiftCreateExternalTableAsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftCreateExternalTableAsContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_redshiftCreateExternalTableAs(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_redshiftCreateExternalTableAs(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftCreateExternalTableAsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftCreateExternalTableAs(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftCreateExternalTableAsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RedshiftCreateExternalTableAsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RedshiftCreateExternalTableAsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RedshiftCreateExternalTableAsContext<'input> {}

impl<'input> RedshiftCreateExternalTableAsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RedshiftCreateExternalTableAsContext(
				BaseParserRuleContext::copy_from(ctx,RedshiftCreateExternalTableAsContextExt{
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AnalyzeContext<'input> = BaseParserRuleContext<'input,AnalyzeContextExt<'input>>;

pub trait AnalyzeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ANALYZE
	/// Returns `None` if there is no child corresponding to token ANALYZE
	fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ANALYZE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> AnalyzeContextAttrs<'input> for AnalyzeContext<'input>{}

pub struct AnalyzeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AnalyzeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AnalyzeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AnalyzeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_analyze(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_analyze(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AnalyzeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_analyze(self);
	}
}

impl<'input> CustomRuleContext<'input> for AnalyzeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AnalyzeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AnalyzeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AnalyzeContext<'input> {}

impl<'input> AnalyzeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AnalyzeContext(
				BaseParserRuleContext::copy_from(ctx,AnalyzeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateFunctionContext<'input> = BaseParserRuleContext<'input,CreateFunctionContextExt<'input>>;

pub trait CreateFunctionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNS
	/// Returns `None` if there is no child corresponding to token RETURNS
	fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RETURNS, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTERNAL
	/// Returns `None` if there is no child corresponding to token EXTERNAL
	fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXTERNAL, 0)
	}
	fn namedParameter_all(&self) ->  Vec<Rc<NamedParameterContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn namedParameter(&self, i: usize) -> Option<Rc<NamedParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn functionPropertySpec_all(&self) ->  Vec<Rc<FunctionPropertySpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn functionPropertySpec(&self, i: usize) -> Option<Rc<FunctionPropertySpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> CreateFunctionContextAttrs<'input> for CreateFunctionContext<'input>{}

pub struct CreateFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub name: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	pub return_type: Option<Rc<Type_ContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateFunctionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createFunction(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateFunctionContext<'input> {}

impl<'input> CreateFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateFunctionContext(
				BaseParserRuleContext::copy_from(ctx,CreateFunctionContextExt{
					tail:None, 
        			name:None, return_type:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ResetContext<'input> = BaseParserRuleContext<'input,ResetContextExt<'input>>;

pub trait ResetContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RESET
	/// Returns `None` if there is no child corresponding to token RESET
	fn RESET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RESET, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ResetContextAttrs<'input> for ResetContext<'input>{}

pub struct ResetContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ResetContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ResetContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ResetContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_reset(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_reset(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ResetContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_reset(self);
	}
}

impl<'input> CustomRuleContext<'input> for ResetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ResetContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ResetContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ResetContext<'input> {}

impl<'input> ResetContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ResetContext(
				BaseParserRuleContext::copy_from(ctx,ResetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropSchemaContext<'input> = BaseParserRuleContext<'input,DropSchemaContextExt<'input>>;

pub trait DropSchemaContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DropSchemaContextAttrs<'input> for DropSchemaContext<'input>{}

pub struct DropSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropSchemaContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DropSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DropSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropSchema(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_dropSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DropSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_dropSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropSchemaContext<'input> {}

impl<'input> DropSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropSchemaContext(
				BaseParserRuleContext::copy_from(ctx,DropSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BeginContext<'input> = BaseParserRuleContext<'input,BeginContextExt<'input>>;

pub trait BeginContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BEGIN
	/// Returns `None` if there is no child corresponding to token BEGIN
	fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BEGIN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> BeginContextAttrs<'input> for BeginContext<'input>{}

pub struct BeginContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BeginContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for BeginContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BeginContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_begin(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_begin(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BeginContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_begin(self);
	}
}

impl<'input> CustomRuleContext<'input> for BeginContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BeginContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BeginContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BeginContext<'input> {}

impl<'input> BeginContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BeginContext(
				BaseParserRuleContext::copy_from(ctx,BeginContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTableAuthorizationContext<'input> = BaseParserRuleContext<'input,SetTableAuthorizationContextExt<'input>>;

pub trait SetTableAuthorizationContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTableAuthorizationContextAttrs<'input> for SetTableAuthorizationContext<'input>{}

pub struct SetTableAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTableAuthorizationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SetTableAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetTableAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_setTableAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetTableAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setTableAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTableAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTableAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTableAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTableAuthorizationContext<'input> {}

impl<'input> SetTableAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTableAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetTableAuthorizationContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateIdentityContext<'input> = BaseParserRuleContext<'input,CreateIdentityContextExt<'input>>;

pub trait CreateIdentityContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IDENTITY
	/// Returns `None` if there is no child corresponding to token IDENTITY
	fn IDENTITY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IDENTITY, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateIdentityContextAttrs<'input> for CreateIdentityContext<'input>{}

pub struct CreateIdentityContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateIdentityContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateIdentityContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateIdentityContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createIdentity(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createIdentity(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateIdentityContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createIdentity(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateIdentityContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateIdentityContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateIdentityContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateIdentityContext<'input> {}

impl<'input> CreateIdentityContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateIdentityContext(
				BaseParserRuleContext::copy_from(ctx,CreateIdentityContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropContext<'input> = BaseParserRuleContext<'input,DropContextExt<'input>>;

pub trait DropContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DropContextAttrs<'input> for DropContext<'input>{}

pub struct DropContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DropContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DropContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_drop(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_drop(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DropContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_drop(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropContext<'input> {}

impl<'input> DropContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropContext(
				BaseParserRuleContext::copy_from(ctx,DropContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StartTransactionContext<'input> = BaseParserRuleContext<'input,StartTransactionContextExt<'input>>;

pub trait StartTransactionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token START
	/// Returns `None` if there is no child corresponding to token START
	fn START(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(START, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRANSACTION
	/// Returns `None` if there is no child corresponding to token TRANSACTION
	fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TRANSACTION, 0)
	}
	fn transactionMode_all(&self) ->  Vec<Rc<TransactionModeContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn transactionMode(&self, i: usize) -> Option<Rc<TransactionModeContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> StartTransactionContextAttrs<'input> for StartTransactionContext<'input>{}

pub struct StartTransactionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StartTransactionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for StartTransactionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StartTransactionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_startTransaction(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_startTransaction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StartTransactionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_startTransaction(self);
	}
}

impl<'input> CustomRuleContext<'input> for StartTransactionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for StartTransactionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for StartTransactionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for StartTransactionContext<'input> {}

impl<'input> StartTransactionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::StartTransactionContext(
				BaseParserRuleContext::copy_from(ctx,StartTransactionContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowContext<'input> = BaseParserRuleContext<'input,ShowContextExt<'input>>;

pub trait ShowContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ShowContextAttrs<'input> for ShowContext<'input>{}

pub struct ShowContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ShowContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ShowContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_show(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_show(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ShowContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_show(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowContext<'input> {}

impl<'input> ShowContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowContext(
				BaseParserRuleContext::copy_from(ctx,ShowContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RevokeContext<'input> = BaseParserRuleContext<'input,RevokeContextExt<'input>>;

pub trait RevokeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REVOKE
	/// Returns `None` if there is no child corresponding to token REVOKE
	fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REVOKE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> RevokeContextAttrs<'input> for RevokeContext<'input>{}

pub struct RevokeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RevokeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RevokeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RevokeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_revoke(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_revoke(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RevokeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_revoke(self);
	}
}

impl<'input> CustomRuleContext<'input> for RevokeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RevokeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RevokeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RevokeContext<'input> {}

impl<'input> RevokeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RevokeContext(
				BaseParserRuleContext::copy_from(ctx,RevokeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UpdateContext<'input> = BaseParserRuleContext<'input,UpdateContextExt<'input>>;

pub trait UpdateContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UPDATE
	/// Returns `None` if there is no child corresponding to token UPDATE
	fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UPDATE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> UpdateContextAttrs<'input> for UpdateContext<'input>{}

pub struct UpdateContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UpdateContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UpdateContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UpdateContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_update(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_update(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UpdateContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_update(self);
	}
}

impl<'input> CustomRuleContext<'input> for UpdateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UpdateContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UpdateContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UpdateContext<'input> {}

impl<'input> UpdateContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UpdateContext(
				BaseParserRuleContext::copy_from(ctx,UpdateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableExecuteContext<'input> = BaseParserRuleContext<'input,TableExecuteContextExt<'input>>;

pub trait TableExecuteContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXECUTE
	/// Returns `None` if there is no child corresponding to token EXECUTE
	fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXECUTE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WHERE
	/// Returns `None` if there is no child corresponding to token WHERE
	fn WHERE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WHERE, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> TableExecuteContextAttrs<'input> for TableExecuteContext<'input>{}

pub struct TableExecuteContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub procedureName: Option<Rc<IdentifierContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	pub where_: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableExecuteContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TableExecuteContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableExecuteContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableExecute(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_tableExecute(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableExecuteContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableExecute(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableExecuteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for TableExecuteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for TableExecuteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for TableExecuteContext<'input> {}

impl<'input> TableExecuteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::TableExecuteContext(
				BaseParserRuleContext::copy_from(ctx,TableExecuteContextExt{
					tail:None, 
        			tableName:None, procedureName:None, where_:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DeleteContext<'input> = BaseParserRuleContext<'input,DeleteContextExt<'input>>;

pub trait DeleteContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DELETE
	/// Returns `None` if there is no child corresponding to token DELETE
	fn DELETE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DELETE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DeleteContextAttrs<'input> for DeleteContext<'input>{}

pub struct DeleteContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeleteContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DeleteContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DeleteContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_delete(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_delete(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DeleteContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_delete(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeleteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DeleteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DeleteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DeleteContext<'input> {}

impl<'input> DeleteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DeleteContext(
				BaseParserRuleContext::copy_from(ctx,DeleteContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeInputContext<'input> = BaseParserRuleContext<'input,DescribeInputContextExt<'input>>;

pub trait DescribeInputContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INPUT
	/// Returns `None` if there is no child corresponding to token INPUT
	fn INPUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INPUT, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DescribeInputContextAttrs<'input> for DescribeInputContext<'input>{}

pub struct DescribeInputContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeInputContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DescribeInputContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DescribeInputContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeInput(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_describeInput(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DescribeInputContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_describeInput(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeInputContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeInputContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeInputContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeInputContext<'input> {}

impl<'input> DescribeInputContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeInputContext(
				BaseParserRuleContext::copy_from(ctx,DescribeInputContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateProcedureContext<'input> = BaseParserRuleContext<'input,CreateProcedureContextExt<'input>>;

pub trait CreateProcedureContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROCEDURE
	/// Returns `None` if there is no child corresponding to token PROCEDURE
	fn PROCEDURE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PROCEDURE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DOLLAR_QUOTED_STRING
	/// Returns `None` if there is no child corresponding to token DOLLAR_QUOTED_STRING
	fn DOLLAR_QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR_QUOTED_STRING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateProcedureContextAttrs<'input> for CreateProcedureContext<'input>{}

pub struct CreateProcedureContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateProcedureContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateProcedureContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateProcedureContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createProcedure(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createProcedure(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateProcedureContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createProcedure(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateProcedureContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateProcedureContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateProcedureContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateProcedureContext<'input> {}

impl<'input> CreateProcedureContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateProcedureContext(
				BaseParserRuleContext::copy_from(ctx,CreateProcedureContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetColumnTypeContext<'input> = BaseParserRuleContext<'input,SetColumnTypeContextExt<'input>>;

pub trait SetColumnTypeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token ALTER in current rule
	fn ALTER_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ALTER, starting from 0.
	/// Returns `None` if number of children corresponding to token ALTER is less or equal than `i`.
	fn ALTER(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, i)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATA
	/// Returns `None` if there is no child corresponding to token DATA
	fn DATA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DATA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TYPE
	/// Returns `None` if there is no child corresponding to token TYPE
	fn TYPE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TYPE, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> SetColumnTypeContextAttrs<'input> for SetColumnTypeContext<'input>{}

pub struct SetColumnTypeContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub setColumnName: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetColumnTypeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SetColumnTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetColumnTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setColumnType(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_setColumnType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetColumnTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setColumnType(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetColumnTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetColumnTypeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetColumnTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetColumnTypeContext<'input> {}

impl<'input> SetColumnTypeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetColumnTypeContext(
				BaseParserRuleContext::copy_from(ctx,SetColumnTypeContextExt{
        			tableName:None, setColumnName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type VacuumContext<'input> = BaseParserRuleContext<'input,VacuumContextExt<'input>>;

pub trait VacuumContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token VACUUM
	/// Returns `None` if there is no child corresponding to token VACUUM
	fn VACUUM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VACUUM, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> VacuumContextAttrs<'input> for VacuumContext<'input>{}

pub struct VacuumContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{VacuumContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for VacuumContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for VacuumContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_vacuum(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_vacuum(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for VacuumContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_vacuum(self);
	}
}

impl<'input> CustomRuleContext<'input> for VacuumContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for VacuumContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for VacuumContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for VacuumContext<'input> {}

impl<'input> VacuumContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::VacuumContext(
				BaseParserRuleContext::copy_from(ctx,VacuumContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StatementDefaultContext<'input> = BaseParserRuleContext<'input,StatementDefaultContextExt<'input>>;

pub trait StatementDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StatementDefaultContextAttrs<'input> for StatementDefaultContext<'input>{}

pub struct StatementDefaultContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StatementDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for StatementDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StatementDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_statementDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_statementDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StatementDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_statementDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for StatementDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for StatementDefaultContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for StatementDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for StatementDefaultContext<'input> {}

impl<'input> StatementDefaultContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::StatementDefaultContext(
				BaseParserRuleContext::copy_from(ctx,StatementDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TruncateTableContext<'input> = BaseParserRuleContext<'input,TruncateTableContextExt<'input>>;

pub trait TruncateTableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRUNCATE
	/// Returns `None` if there is no child corresponding to token TRUNCATE
	fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TRUNCATE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> TruncateTableContextAttrs<'input> for TruncateTableContext<'input>{}

pub struct TruncateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TruncateTableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TruncateTableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TruncateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_truncateTable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_truncateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TruncateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_truncateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for TruncateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for TruncateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for TruncateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for TruncateTableContext<'input> {}

impl<'input> TruncateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::TruncateTableContext(
				BaseParserRuleContext::copy_from(ctx,TruncateTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type EndContext<'input> = BaseParserRuleContext<'input,EndContextExt<'input>>;

pub trait EndContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> EndContextAttrs<'input> for EndContext<'input>{}

pub struct EndContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{EndContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for EndContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for EndContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_end(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_end(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for EndContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_end(self);
	}
}

impl<'input> CustomRuleContext<'input> for EndContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for EndContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for EndContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for EndContext<'input> {}

impl<'input> EndContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::EndContext(
				BaseParserRuleContext::copy_from(ctx,EndContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AttachContext<'input> = BaseParserRuleContext<'input,AttachContextExt<'input>>;

pub trait AttachContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ATTACH
	/// Returns `None` if there is no child corresponding to token ATTACH
	fn ATTACH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ATTACH, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> AttachContextAttrs<'input> for AttachContext<'input>{}

pub struct AttachContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AttachContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AttachContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AttachContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_attach(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_attach(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AttachContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_attach(self);
	}
}

impl<'input> CustomRuleContext<'input> for AttachContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AttachContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AttachContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AttachContext<'input> {}

impl<'input> AttachContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AttachContext(
				BaseParserRuleContext::copy_from(ctx,AttachContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CopyContext<'input> = BaseParserRuleContext<'input,CopyContextExt<'input>>;

pub trait CopyContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COPY
	/// Returns `None` if there is no child corresponding to token COPY
	fn COPY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COPY, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CopyContextAttrs<'input> for CopyContext<'input>{}

pub struct CopyContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CopyContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CopyContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CopyContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_copy(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_copy(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CopyContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_copy(self);
	}
}

impl<'input> CustomRuleContext<'input> for CopyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CopyContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CopyContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CopyContext<'input> {}

impl<'input> CopyContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CopyContext(
				BaseParserRuleContext::copy_from(ctx,CopyContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CloseContext<'input> = BaseParserRuleContext<'input,CloseContextExt<'input>>;

pub trait CloseContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CLOSE
	/// Returns `None` if there is no child corresponding to token CLOSE
	fn CLOSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CLOSE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CloseContextAttrs<'input> for CloseContext<'input>{}

pub struct CloseContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CloseContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CloseContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CloseContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_close(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_close(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CloseContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_close(self);
	}
}

impl<'input> CustomRuleContext<'input> for CloseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CloseContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CloseContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CloseContext<'input> {}

impl<'input> CloseContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CloseContext(
				BaseParserRuleContext::copy_from(ctx,CloseContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameMaterializedViewContext<'input> = BaseParserRuleContext<'input,RenameMaterializedViewContextExt<'input>>;

pub trait RenameMaterializedViewContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> RenameMaterializedViewContextAttrs<'input> for RenameMaterializedViewContext<'input>{}

pub struct RenameMaterializedViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub to: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameMaterializedViewContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RenameMaterializedViewContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RenameMaterializedViewContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameMaterializedView(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_renameMaterializedView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RenameMaterializedViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_renameMaterializedView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameMaterializedViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameMaterializedViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameMaterializedViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameMaterializedViewContext<'input> {}

impl<'input> RenameMaterializedViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameMaterializedViewContext(
				BaseParserRuleContext::copy_from(ctx,RenameMaterializedViewContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropTableContext<'input> = BaseParserRuleContext<'input,DropTableContextExt<'input>>;

pub trait DropTableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DropTableContextAttrs<'input> for DropTableContext<'input>{}

pub struct DropTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropTableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DropTableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DropTableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropTable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_dropTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DropTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_dropTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropTableContext<'input> {}

impl<'input> DropTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropTableContext(
				BaseParserRuleContext::copy_from(ctx,DropTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetSchemaAuthorizationContext<'input> = BaseParserRuleContext<'input,SetSchemaAuthorizationContextExt<'input>>;

pub trait SetSchemaAuthorizationContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetSchemaAuthorizationContextAttrs<'input> for SetSchemaAuthorizationContext<'input>{}

pub struct SetSchemaAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetSchemaAuthorizationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SetSchemaAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetSchemaAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setSchemaAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_setSchemaAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetSchemaAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setSchemaAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetSchemaAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetSchemaAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetSchemaAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetSchemaAuthorizationContext<'input> {}

impl<'input> SetSchemaAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetSchemaAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetSchemaAuthorizationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RollbackContext<'input> = BaseParserRuleContext<'input,RollbackContextExt<'input>>;

pub trait RollbackContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLLBACK
	/// Returns `None` if there is no child corresponding to token ROLLBACK
	fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ROLLBACK, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> RollbackContextAttrs<'input> for RollbackContext<'input>{}

pub struct RollbackContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RollbackContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RollbackContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RollbackContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rollback(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_rollback(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RollbackContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rollback(self);
	}
}

impl<'input> CustomRuleContext<'input> for RollbackContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RollbackContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RollbackContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RollbackContext<'input> {}

impl<'input> RollbackContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RollbackContext(
				BaseParserRuleContext::copy_from(ctx,RollbackContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RedshiftCreateExternalTableContext<'input> = BaseParserRuleContext<'input,RedshiftCreateExternalTableContextExt<'input>>;

pub trait RedshiftCreateExternalTableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTERNAL
	/// Returns `None` if there is no child corresponding to token EXTERNAL
	fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXTERNAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn redshiftCreateExternalTableClauses(&self) -> Option<Rc<RedshiftCreateExternalTableClausesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn tableElements(&self) -> Option<Rc<TableElementsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
}

impl<'input> RedshiftCreateExternalTableContextAttrs<'input> for RedshiftCreateExternalTableContext<'input>{}

pub struct RedshiftCreateExternalTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RedshiftCreateExternalTableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RedshiftCreateExternalTableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftCreateExternalTableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_redshiftCreateExternalTable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_redshiftCreateExternalTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftCreateExternalTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftCreateExternalTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftCreateExternalTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RedshiftCreateExternalTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RedshiftCreateExternalTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RedshiftCreateExternalTableContext<'input> {}

impl<'input> RedshiftCreateExternalTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RedshiftCreateExternalTableContext(
				BaseParserRuleContext::copy_from(ctx,RedshiftCreateExternalTableContextExt{
					COMMA:None, 
        			tail:Vec::new(), 
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetContext<'input> = BaseParserRuleContext<'input,SetContextExt<'input>>;

pub trait SetContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> SetContextAttrs<'input> for SetContext<'input>{}

pub struct SetContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SetContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_set(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_set(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_set(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetContext<'input> {}

impl<'input> SetContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetContext(
				BaseParserRuleContext::copy_from(ctx,SetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameViewContext<'input> = BaseParserRuleContext<'input,RenameViewContextExt<'input>>;

pub trait RenameViewContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> RenameViewContextAttrs<'input> for RenameViewContext<'input>{}

pub struct RenameViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub to: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameViewContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RenameViewContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RenameViewContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameView(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_renameView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RenameViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_renameView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameViewContext<'input> {}

impl<'input> RenameViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameViewContext(
				BaseParserRuleContext::copy_from(ctx,RenameViewContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CallContext<'input> = BaseParserRuleContext<'input,CallContextExt<'input>>;

pub trait CallContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CALL
	/// Returns `None` if there is no child corresponding to token CALL
	fn CALL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CALL, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CallContextAttrs<'input> for CallContext<'input>{}

pub struct CallContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CallContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CallContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CallContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_call(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_call(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CallContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_call(self);
	}
}

impl<'input> CustomRuleContext<'input> for CallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CallContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CallContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CallContext<'input> {}

impl<'input> CallContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CallContext(
				BaseParserRuleContext::copy_from(ctx,CallContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RefreshMaterializedViewContext<'input> = BaseParserRuleContext<'input,RefreshMaterializedViewContextExt<'input>>;

pub trait RefreshMaterializedViewContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REFRESH
	/// Returns `None` if there is no child corresponding to token REFRESH
	fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REFRESH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RefreshMaterializedViewContextAttrs<'input> for RefreshMaterializedViewContext<'input>{}

pub struct RefreshMaterializedViewContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RefreshMaterializedViewContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RefreshMaterializedViewContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RefreshMaterializedViewContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_refreshMaterializedView(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_refreshMaterializedView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RefreshMaterializedViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_refreshMaterializedView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RefreshMaterializedViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RefreshMaterializedViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RefreshMaterializedViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RefreshMaterializedViewContext<'input> {}

impl<'input> RefreshMaterializedViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RefreshMaterializedViewContext(
				BaseParserRuleContext::copy_from(ctx,RefreshMaterializedViewContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FetchContext<'input> = BaseParserRuleContext<'input,FetchContextExt<'input>>;

pub trait FetchContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FETCH
	/// Returns `None` if there is no child corresponding to token FETCH
	fn FETCH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FETCH, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> FetchContextAttrs<'input> for FetchContext<'input>{}

pub struct FetchContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FetchContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FetchContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FetchContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_fetch(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_fetch(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FetchContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_fetch(self);
	}
}

impl<'input> CustomRuleContext<'input> for FetchContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for FetchContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for FetchContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for FetchContext<'input> {}

impl<'input> FetchContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::FetchContext(
				BaseParserRuleContext::copy_from(ctx,FetchContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DetachContext<'input> = BaseParserRuleContext<'input,DetachContextExt<'input>>;

pub trait DetachContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DETACH
	/// Returns `None` if there is no child corresponding to token DETACH
	fn DETACH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DETACH, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DetachContextAttrs<'input> for DetachContext<'input>{}

pub struct DetachContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DetachContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DetachContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DetachContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_detach(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_detach(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DetachContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_detach(self);
	}
}

impl<'input> CustomRuleContext<'input> for DetachContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DetachContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DetachContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DetachContext<'input> {}

impl<'input> DetachContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DetachContext(
				BaseParserRuleContext::copy_from(ctx,DetachContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommentContext<'input> = BaseParserRuleContext<'input,CommentContextExt<'input>>;

pub trait CommentContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMENT
	/// Returns `None` if there is no child corresponding to token COMMENT
	fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMENT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CommentContextAttrs<'input> for CommentContext<'input>{}

pub struct CommentContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommentContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CommentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CommentContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_comment(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_comment(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CommentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_comment(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommentContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommentContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommentContext<'input> {}

impl<'input> CommentContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommentContext(
				BaseParserRuleContext::copy_from(ctx,CommentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateUserContext<'input> = BaseParserRuleContext<'input,CreateUserContextExt<'input>>;

pub trait CreateUserContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USER
	/// Returns `None` if there is no child corresponding to token USER
	fn USER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(USER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateUserContextAttrs<'input> for CreateUserContext<'input>{}

pub struct CreateUserContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateUserContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CreateUserContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateUserContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createUser(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_createUser(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateUserContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createUser(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateUserContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateUserContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateUserContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateUserContext<'input> {}

impl<'input> CreateUserContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateUserContext(
				BaseParserRuleContext::copy_from(ctx,CreateUserContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeOutputContext<'input> = BaseParserRuleContext<'input,DescribeOutputContextExt<'input>>;

pub trait DescribeOutputContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OUTPUT
	/// Returns `None` if there is no child corresponding to token OUTPUT
	fn OUTPUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OUTPUT, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DescribeOutputContextAttrs<'input> for DescribeOutputContext<'input>{}

pub struct DescribeOutputContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeOutputContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DescribeOutputContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DescribeOutputContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeOutput(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_describeOutput(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DescribeOutputContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_describeOutput(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeOutputContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeOutputContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeOutputContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeOutputContext<'input> {}

impl<'input> DescribeOutputContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeOutputContext(
				BaseParserRuleContext::copy_from(ctx,DescribeOutputContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GrantContext<'input> = BaseParserRuleContext<'input,GrantContextExt<'input>>;

pub trait GrantContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token GRANT
	/// Returns `None` if there is no child corresponding to token GRANT
	fn GRANT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(GRANT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> GrantContextAttrs<'input> for GrantContext<'input>{}

pub struct GrantContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrantContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for GrantContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for GrantContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grant(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_grant(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for GrantContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_grant(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrantContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for GrantContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for GrantContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for GrantContext<'input> {}

impl<'input> GrantContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::GrantContext(
				BaseParserRuleContext::copy_from(ctx,GrantContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTablePropertiesContext<'input> = BaseParserRuleContext<'input,SetTablePropertiesContextExt<'input>>;

pub trait SetTablePropertiesContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROPERTIES
	/// Returns `None` if there is no child corresponding to token PROPERTIES
	fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PROPERTIES, 0)
	}
	fn propertyAssignments(&self) -> Option<Rc<PropertyAssignmentsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTablePropertiesContextAttrs<'input> for SetTablePropertiesContext<'input>{}

pub struct SetTablePropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTablePropertiesContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SetTablePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetTablePropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableProperties(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_setTableProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetTablePropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setTableProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTablePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTablePropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTablePropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTablePropertiesContext<'input> {}

impl<'input> SetTablePropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTablePropertiesContext(
				BaseParserRuleContext::copy_from(ctx,SetTablePropertiesContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn statement(&mut self,)
	-> Result<Rc<StatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 10, RULE_statement);
        let mut _localctx: Rc<StatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1156);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(114,&mut recog.base)? {
				1 =>{
					let tmp = StatementDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule query*/
					recog.base.set_state(359);
					recog.query()?;

					}
				}
			,
				2 =>{
					let tmp = UseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(360);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(361);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.schema = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				3 =>{
					let tmp = UseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(362);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(363);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.catalog = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(364);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(365);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.schema = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				4 =>{
					let tmp = DropSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(367);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(368);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					recog.base.set_state(371);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(5,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(369);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(370);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(373);
					recog.qualifiedName()?;

					recog.base.set_state(377);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(374);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(379);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				5 =>{
					let tmp = RenameSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(380);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(381);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(382);
					recog.qualifiedName()?;

					recog.base.set_state(383);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(384);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(385);
					recog.identifier()?;

					}
				}
			,
				6 =>{
					let tmp = SetSchemaAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(387);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(388);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(389);
					recog.qualifiedName()?;

					recog.base.set_state(390);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(391);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(392);
					recog.principal()?;

					}
				}
			,
				7 =>{
					let tmp = DropTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(394);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(395);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(396);
					recog.qualifiedName()?;

					}
				}
			,
				8 =>{
					let tmp = DropViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(397);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(398);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(399);
					recog.qualifiedName()?;

					}
				}
			,
				9 =>{
					let tmp = RedshiftCreateExternalTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(400);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(401);
					recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

					recog.base.set_state(402);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(403);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RedshiftCreateExternalTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(411);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(404);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule tableElements*/
						recog.base.set_state(405);
						recog.tableElements()?;

						recog.base.set_state(407);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(406);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::RedshiftCreateExternalTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

							let temp = if let StatementContextAll::RedshiftCreateExternalTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let StatementContextAll::RedshiftCreateExternalTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail.push(temp); } else {unreachable!("cant cast");}  
							}
						}

						recog.base.set_state(409);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule redshiftCreateExternalTableClauses*/
					recog.base.set_state(413);
					recog.redshiftCreateExternalTableClauses()?;

					}
				}
			,
				10 =>{
					let tmp = RedshiftCreateExternalTableAsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(415);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(416);
					recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

					recog.base.set_state(417);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(418);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RedshiftCreateExternalTableAsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					/*InvokeRule redshiftCreateExternalTableAsClauses*/
					recog.base.set_state(419);
					recog.redshiftCreateExternalTableAsClauses()?;

					recog.base.set_state(420);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(426);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(9,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule query*/
							recog.base.set_state(421);
							recog.query()?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(422);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(423);
							recog.query()?;

							recog.base.set_state(424);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				11 =>{
					let tmp = RedshiftCreateTableAsSelectContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(428);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(430);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LOCAL {
						{
						recog.base.set_state(429);
						recog.base.match_token(LOCAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(433);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TEMP || _la==TEMPORARY {
						{
						recog.base.set_state(432);
						_la = recog.base.input.la(1);
						if { !(_la==TEMP || _la==TEMPORARY) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(435);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(436);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RedshiftCreateTableAsSelectContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(438);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(12,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(437);
							recog.columnAliases()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(442);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BACKUP {
						{
						recog.base.set_state(440);
						recog.base.match_token(BACKUP,&mut recog.err_handler)?;

						recog.base.set_state(441);
						_la = recog.base.input.la(1);
						if { !(_la==NO || _la==YES) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					/*InvokeRule redshiftTableAttributes*/
					recog.base.set_state(444);
					recog.redshiftTableAttributes()?;

					recog.base.set_state(445);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(451);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(14,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule query*/
							recog.base.set_state(446);
							recog.query()?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(447);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(448);
							recog.query()?;

							recog.base.set_state(449);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(457);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						recog.base.set_state(453);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						recog.base.set_state(454);
						recog.base.match_token(NO,&mut recog.err_handler)?;

						recog.base.set_state(455);
						recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

						recog.base.set_state(456);
						recog.base.match_token(BINDING,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				12 =>{
					let tmp = RedshiftCreateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 12);
					_localctx = tmp;
					{
					recog.base.set_state(459);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(461);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LOCAL {
						{
						recog.base.set_state(460);
						recog.base.match_token(LOCAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(464);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TEMP || _la==TEMPORARY {
						{
						recog.base.set_state(463);
						_la = recog.base.input.la(1);
						if { !(_la==TEMP || _la==TEMPORARY) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(466);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(470);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(18,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(467);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(468);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(469);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(472);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RedshiftCreateTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(480);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(473);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule tableElements*/
						recog.base.set_state(474);
						recog.tableElements()?;

						recog.base.set_state(476);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(475);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::RedshiftCreateTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						recog.base.set_state(478);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(484);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BACKUP {
						{
						recog.base.set_state(482);
						recog.base.match_token(BACKUP,&mut recog.err_handler)?;

						recog.base.set_state(483);
						_la = recog.base.input.la(1);
						if { !(_la==NO || _la==YES) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					/*InvokeRule redshiftTableAttributes*/
					recog.base.set_state(486);
					recog.redshiftTableAttributes()?;

					}
				}
			,
				13 =>{
					let tmp = InsertIntoContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 13);
					_localctx = tmp;
					{
					recog.base.set_state(488);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(489);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(490);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::InsertIntoContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(492);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(22,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(491);
							recog.columnAliases()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(499);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(23,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule query*/
							recog.base.set_state(494);
							recog.query()?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(495);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(496);
							recog.query()?;

							recog.base.set_state(497);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				14 =>{
					let tmp = RedshiftCreateMaterializedViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 14);
					_localctx = tmp;
					{
					recog.base.set_state(501);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(504);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(502);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(503);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(506);
					recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(507);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(510);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(25,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(508);
							recog.base.match_token(BACKUP,&mut recog.err_handler)?;

							recog.base.set_state(509);
							_la = recog.base.input.la(1);
							if { !(_la==NO || _la==YES) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(515);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(26,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(512);
							recog.base.match_token(AUTO,&mut recog.err_handler)?;

							recog.base.set_state(513);
							recog.base.match_token(REFRESH,&mut recog.err_handler)?;

							recog.base.set_state(514);
							_la = recog.base.input.la(1);
							if { !(_la==NO || _la==YES) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(520);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(27,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(517);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(518);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(519);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(522);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RedshiftCreateMaterializedViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					/*InvokeRule redshiftTableAttributes*/
					recog.base.set_state(523);
					recog.redshiftTableAttributes()?;

					recog.base.set_state(527);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==GRACE {
						{
						recog.base.set_state(524);
						recog.base.match_token(GRACE,&mut recog.err_handler)?;

						recog.base.set_state(525);
						recog.base.match_token(PERIOD,&mut recog.err_handler)?;

						/*InvokeRule interval*/
						recog.base.set_state(526);
						recog.interval()?;

						}
					}

					recog.base.set_state(531);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMENT {
						{
						recog.base.set_state(529);
						recog.base.match_token(COMMENT,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(530);
						recog.string()?;

						}
					}

					recog.base.set_state(535);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						recog.base.set_state(533);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(534);
						recog.properties()?;

						}
					}

					recog.base.set_state(537);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(538);
					recog.query()?;

					}
				}
			,
				15 =>{
					let tmp = RedshiftCreateViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 15);
					_localctx = tmp;
					{
					recog.base.set_state(540);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(543);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(541);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(542);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(545);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(546);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RedshiftCreateViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(548);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(32,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(547);
							recog.columnAliases()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(552);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMENT {
						{
						recog.base.set_state(550);
						recog.base.match_token(COMMENT,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(551);
						let tmp = recog.string()?;
						if let StatementContextAll::RedshiftCreateViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.comment = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(556);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==SECURITY {
						{
						recog.base.set_state(554);
						recog.base.match_token(SECURITY,&mut recog.err_handler)?;

						recog.base.set_state(555);
						_la = recog.base.input.la(1);
						if { !(_la==DEFINER || _la==INVOKER) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(558);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(564);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(35,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule query*/
							recog.base.set_state(559);
							recog.query()?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(560);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(561);
							recog.query()?;

							recog.base.set_state(562);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(570);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						recog.base.set_state(566);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						recog.base.set_state(567);
						recog.base.match_token(NO,&mut recog.err_handler)?;

						recog.base.set_state(568);
						recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

						recog.base.set_state(569);
						recog.base.match_token(BINDING,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				16 =>{
					let tmp = ShowColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 16);
					_localctx = tmp;
					{
					recog.base.set_state(572);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(573);
					recog.base.match_token(COLUMNS,&mut recog.err_handler)?;

					recog.base.set_state(574);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					recog.base.set_state(575);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(576);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::ShowColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				17 =>{
					let tmp = CreateFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 17);
					_localctx = tmp;
					{
					recog.base.set_state(577);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(580);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(578);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(579);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(583);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EXTERNAL {
						{
						recog.base.set_state(582);
						recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(585);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(586);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::CreateFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(587);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(599);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LBRACKET - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)))) != 0) {
						{
						/*InvokeRule namedParameter*/
						recog.base.set_state(588);
						recog.namedParameter()?;

						recog.base.set_state(593);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(39,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(589);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule namedParameter*/
								recog.base.set_state(590);
								recog.namedParameter()?;

								}
								} 
							}
							recog.base.set_state(595);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(39,&mut recog.base)?;
						}
						recog.base.set_state(597);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(596);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::CreateFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(601);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(602);
					recog.base.match_token(RETURNS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(603);
					let tmp = recog.type_()?;
					if let StatementContextAll::CreateFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.return_type = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(605); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule functionPropertySpec*/
						recog.base.set_state(604);
						recog.functionPropertySpec()?;

						}
						}
						recog.base.set_state(607); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==AS || _la==IAM_ROLE || _la==IMMUTABLE || ((((_la - 179)) & !0x3f) == 0 && ((1usize << (_la - 179)) & ((1usize << (LAMBDA - 179)) | (1usize << (LANGUAGE - 179)) | (1usize << (MAX_BATCH_ROWS - 179)) | (1usize << (MAX_BATCH_SIZE - 179)))) != 0) || _la==RETRY_TIMEOUT || _la==SAGEMAKER || _la==STABLE || _la==VOLATILE) {break}
					}
					}
				}
			,
				18 =>{
					let tmp = MergeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 18);
					_localctx = tmp;
					{
					recog.base.set_state(609);
					recog.base.match_token(MERGE,&mut recog.err_handler)?;

					recog.base.set_state(613);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(610);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(615);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				19 =>{
					let tmp = AbortContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 19);
					_localctx = tmp;
					{
					recog.base.set_state(616);
					recog.base.match_token(ABORT,&mut recog.err_handler)?;

					recog.base.set_state(618);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TRANSACTION || _la==WORK {
						{
						recog.base.set_state(617);
						_la = recog.base.input.la(1);
						if { !(_la==TRANSACTION || _la==WORK) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					}
				}
			,
				20 =>{
					let tmp = AlterContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 20);
					_localctx = tmp;
					{
					recog.base.set_state(620);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(624);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(621);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(626);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				21 =>{
					let tmp = AttachContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 21);
					_localctx = tmp;
					{
					recog.base.set_state(627);
					recog.base.match_token(ATTACH,&mut recog.err_handler)?;

					recog.base.set_state(631);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(628);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(633);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				22 =>{
					let tmp = BeginContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 22);
					_localctx = tmp;
					{
					recog.base.set_state(634);
					recog.base.match_token(BEGIN,&mut recog.err_handler)?;

					recog.base.set_state(638);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(635);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(640);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				23 =>{
					let tmp = CancelContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 23);
					_localctx = tmp;
					{
					recog.base.set_state(641);
					recog.base.match_token(CANCEL,&mut recog.err_handler)?;

					recog.base.set_state(645);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(642);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(647);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				24 =>{
					let tmp = CloseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 24);
					_localctx = tmp;
					{
					recog.base.set_state(648);
					recog.base.match_token(CLOSE,&mut recog.err_handler)?;

					recog.base.set_state(652);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(649);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(654);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				25 =>{
					let tmp = CopyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 25);
					_localctx = tmp;
					{
					recog.base.set_state(655);
					recog.base.match_token(COPY,&mut recog.err_handler)?;

					recog.base.set_state(659);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(656);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(661);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				26 =>{
					let tmp = SetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 26);
					_localctx = tmp;
					{
					recog.base.set_state(662);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(666);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(663);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(668);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				27 =>{
					let tmp = CreateSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 27);
					_localctx = tmp;
					{
					recog.base.set_state(669);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(672);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(670);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(671);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(674);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					recog.base.set_state(678);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(675);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(680);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				28 =>{
					let tmp = DropContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 28);
					_localctx = tmp;
					{
					recog.base.set_state(681);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(685);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(682);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(687);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				29 =>{
					let tmp = DeleteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 29);
					_localctx = tmp;
					{
					recog.base.set_state(688);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					recog.base.set_state(692);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(689);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(694);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				30 =>{
					let tmp = TruncateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 30);
					_localctx = tmp;
					{
					recog.base.set_state(695);
					recog.base.match_token(TRUNCATE,&mut recog.err_handler)?;

					recog.base.set_state(699);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(696);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(701);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				31 =>{
					let tmp = CommentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 31);
					_localctx = tmp;
					{
					recog.base.set_state(702);
					recog.base.match_token(COMMENT,&mut recog.err_handler)?;

					recog.base.set_state(706);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(703);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(708);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				32 =>{
					let tmp = RenameTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 32);
					_localctx = tmp;
					{
					recog.base.set_state(709);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(710);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(713);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(58,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(711);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(712);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(715);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(716);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(717);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(718);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				33 =>{
					let tmp = AddColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 33);
					_localctx = tmp;
					{
					recog.base.set_state(720);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(721);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(724);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(59,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(722);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(723);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(726);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::AddColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(727);
					recog.base.match_token(ADD,&mut recog.err_handler)?;

					recog.base.set_state(728);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(732);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(60,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(729);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(730);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(731);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule columnDefinition*/
					recog.base.set_state(734);
					let tmp = recog.columnDefinition()?;
					if let StatementContextAll::AddColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.column = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				34 =>{
					let tmp = RenameColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 34);
					_localctx = tmp;
					{
					recog.base.set_state(736);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(737);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(740);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(61,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(738);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(739);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(742);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(743);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(744);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(747);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(62,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(745);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(746);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifier*/
					recog.base.set_state(749);
					let tmp = recog.identifier()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(750);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(751);
					let tmp = recog.identifier()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				35 =>{
					let tmp = DropColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 35);
					_localctx = tmp;
					{
					recog.base.set_state(753);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(754);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(757);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(63,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(755);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(756);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(759);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::DropColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(760);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(761);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(764);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(64,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(762);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(763);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(766);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::DropColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.column = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				36 =>{
					let tmp = SetColumnTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 36);
					_localctx = tmp;
					{
					recog.base.set_state(768);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(769);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(772);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(65,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(770);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(771);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(774);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetColumnTypeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(775);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(776);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(777);
					let tmp = recog.identifier()?;
					if let StatementContextAll::SetColumnTypeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.setColumnName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(778);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(779);
					recog.base.match_token(DATA,&mut recog.err_handler)?;

					recog.base.set_state(780);
					recog.base.match_token(TYPE,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(781);
					recog.type_()?;

					}
				}
			,
				37 =>{
					let tmp = SetTableAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 37);
					_localctx = tmp;
					{
					recog.base.set_state(783);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(784);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(785);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetTableAuthorizationContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(786);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(787);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(788);
					recog.principal()?;

					}
				}
			,
				38 =>{
					let tmp = SetTablePropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 38);
					_localctx = tmp;
					{
					recog.base.set_state(790);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(791);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(792);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetTablePropertiesContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(793);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(794);
					recog.base.match_token(PROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule propertyAssignments*/
					recog.base.set_state(795);
					recog.propertyAssignments()?;

					}
				}
			,
				39 =>{
					let tmp = TableExecuteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 39);
					_localctx = tmp;
					{
					recog.base.set_state(797);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(798);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(799);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(800);
					recog.base.match_token(EXECUTE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(801);
					let tmp = recog.identifier()?;
					if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.procedureName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(817);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(802);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(811);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONVERT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOT - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RIGHT - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (POSIX - 419)) | (1usize << (STRING - 419)) | (1usize << (UNICODE_STRING - 419)) | (1usize << (DOLLAR_QUOTED_STRING - 419)) | (1usize << (BINARY_LITERAL - 419)) | (1usize << (INTEGER_VALUE - 419)) | (1usize << (DECIMAL_VALUE - 419)) | (1usize << (DOUBLE_VALUE - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)) | (1usize << (VARIABLE - 419)))) != 0) {
							{
							/*InvokeRule callArgument*/
							recog.base.set_state(803);
							recog.callArgument()?;

							recog.base.set_state(808);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(66,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(804);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule callArgument*/
									recog.base.set_state(805);
									recog.callArgument()?;

									}
									} 
								}
								recog.base.set_state(810);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(66,&mut recog.base)?;
							}
							}
						}

						recog.base.set_state(814);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(813);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						recog.base.set_state(816);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(821);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						recog.base.set_state(819);
						recog.base.match_token(WHERE,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(820);
						let tmp = recog.booleanExpression_rec(0)?;
						if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.where_ = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					}
				}
			,
				40 =>{
					let tmp = AnalyzeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 40);
					_localctx = tmp;
					{
					recog.base.set_state(823);
					recog.base.match_token(ANALYZE,&mut recog.err_handler)?;

					recog.base.set_state(827);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(824);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(829);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				41 =>{
					let tmp = RefreshMaterializedViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 41);
					_localctx = tmp;
					{
					recog.base.set_state(830);
					recog.base.match_token(REFRESH,&mut recog.err_handler)?;

					recog.base.set_state(831);
					recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(832);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(833);
					recog.qualifiedName()?;

					}
				}
			,
				42 =>{
					let tmp = RenameMaterializedViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 42);
					_localctx = tmp;
					{
					recog.base.set_state(834);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(835);
					recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(836);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(839);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(72,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(837);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(838);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(841);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameMaterializedViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(842);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(843);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(844);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameMaterializedViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				43 =>{
					let tmp = SetMaterializedViewPropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 43);
					_localctx = tmp;
					{
					recog.base.set_state(846);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(847);
					recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(848);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(849);
					recog.qualifiedName()?;

					recog.base.set_state(850);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(851);
					recog.base.match_token(PROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule propertyAssignments*/
					recog.base.set_state(852);
					recog.propertyAssignments()?;

					}
				}
			,
				44 =>{
					let tmp = RenameViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 44);
					_localctx = tmp;
					{
					recog.base.set_state(854);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(855);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(856);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(857);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(858);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(859);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				45 =>{
					let tmp = SetViewAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 45);
					_localctx = tmp;
					{
					recog.base.set_state(861);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(862);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(863);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetViewAuthorizationContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(864);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(865);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(866);
					recog.principal()?;

					}
				}
			,
				46 =>{
					let tmp = CallContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 46);
					_localctx = tmp;
					{
					recog.base.set_state(868);
					recog.base.match_token(CALL,&mut recog.err_handler)?;

					recog.base.set_state(872);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(869);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(874);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				47 =>{
					let tmp = CreateRoleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 47);
					_localctx = tmp;
					{
					recog.base.set_state(875);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(876);
					recog.base.match_token(ROLE,&mut recog.err_handler)?;

					recog.base.set_state(880);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(877);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(882);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				48 =>{
					let tmp = GrantContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 48);
					_localctx = tmp;
					{
					recog.base.set_state(883);
					recog.base.match_token(GRANT,&mut recog.err_handler)?;

					recog.base.set_state(887);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(884);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(889);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				49 =>{
					let tmp = RevokeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 49);
					_localctx = tmp;
					{
					recog.base.set_state(890);
					recog.base.match_token(REVOKE,&mut recog.err_handler)?;

					recog.base.set_state(894);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(891);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(896);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				50 =>{
					let tmp = DenyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 50);
					_localctx = tmp;
					{
					recog.base.set_state(897);
					recog.base.match_token(DENY,&mut recog.err_handler)?;

					recog.base.set_state(911);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 CREATE | DELETE | INSERT | SELECT | UPDATE 
						=> {
							{
							/*InvokeRule privilege*/
							recog.base.set_state(898);
							recog.privilege()?;

							recog.base.set_state(903);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(77,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(899);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule privilege*/
									recog.base.set_state(900);
									recog.privilege()?;

									}
									} 
								}
								recog.base.set_state(905);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(77,&mut recog.base)?;
							}
							recog.base.set_state(907);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(906);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let StatementContextAll::DenyContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							}
						}

					 ALL 
						=> {
							{
							recog.base.set_state(909);
							recog.base.match_token(ALL,&mut recog.err_handler)?;

							recog.base.set_state(910);
							recog.base.match_token(PRIVILEGES,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					recog.base.set_state(913);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					recog.base.set_state(915);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(80,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(914);
							_la = recog.base.input.la(1);
							if { !(_la==SCHEMA || _la==TABLE) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(917);
					recog.qualifiedName()?;

					recog.base.set_state(918);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(919);
					let tmp = recog.principal()?;
					if let StatementContextAll::DenyContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.grantee = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				51 =>{
					let tmp = ExplainContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 51);
					_localctx = tmp;
					{
					recog.base.set_state(921);
					recog.base.match_token(EXPLAIN,&mut recog.err_handler)?;

					recog.base.set_state(923);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==VERBOSE {
						{
						recog.base.set_state(922);
						recog.base.match_token(VERBOSE,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule statement*/
					recog.base.set_state(925);
					recog.statement()?;

					}
				}
			,
				52 =>{
					let tmp = ShowContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 52);
					_localctx = tmp;
					{
					recog.base.set_state(926);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(930);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(927);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(932);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				53 =>{
					let tmp = ResetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 53);
					_localctx = tmp;
					{
					recog.base.set_state(933);
					recog.base.match_token(RESET,&mut recog.err_handler)?;

					recog.base.set_state(937);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(934);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(939);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				54 =>{
					let tmp = StartTransactionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 54);
					_localctx = tmp;
					{
					recog.base.set_state(940);
					recog.base.match_token(START,&mut recog.err_handler)?;

					recog.base.set_state(941);
					recog.base.match_token(TRANSACTION,&mut recog.err_handler)?;

					recog.base.set_state(953);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ISOLATION || _la==READ {
						{
						/*InvokeRule transactionMode*/
						recog.base.set_state(942);
						recog.transactionMode()?;

						recog.base.set_state(947);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(84,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(943);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule transactionMode*/
								recog.base.set_state(944);
								recog.transactionMode()?;

								}
								} 
							}
							recog.base.set_state(949);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(84,&mut recog.base)?;
						}
						recog.base.set_state(951);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(950);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::StartTransactionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					}
				}
			,
				55 =>{
					let tmp = CommitContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 55);
					_localctx = tmp;
					{
					recog.base.set_state(955);
					recog.base.match_token(COMMIT,&mut recog.err_handler)?;

					recog.base.set_state(959);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(956);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(961);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				56 =>{
					let tmp = RollbackContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 56);
					_localctx = tmp;
					{
					recog.base.set_state(962);
					recog.base.match_token(ROLLBACK,&mut recog.err_handler)?;

					recog.base.set_state(966);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(963);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(968);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				57 =>{
					let tmp = PrepareContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 57);
					_localctx = tmp;
					{
					recog.base.set_state(969);
					recog.base.match_token(PREPARE,&mut recog.err_handler)?;

					recog.base.set_state(973);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(970);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(975);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				58 =>{
					let tmp = DeallocateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 58);
					_localctx = tmp;
					{
					recog.base.set_state(976);
					recog.base.match_token(DEALLOCATE,&mut recog.err_handler)?;

					recog.base.set_state(980);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(977);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(982);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				59 =>{
					let tmp = ExecuteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 59);
					_localctx = tmp;
					{
					recog.base.set_state(983);
					recog.base.match_token(EXECUTE,&mut recog.err_handler)?;

					recog.base.set_state(987);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(984);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(989);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				60 =>{
					let tmp = DescribeInputContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 60);
					_localctx = tmp;
					{
					recog.base.set_state(990);
					recog.base.match_token(DESCRIBE,&mut recog.err_handler)?;

					recog.base.set_state(991);
					recog.base.match_token(INPUT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(992);
					recog.identifier()?;

					}
				}
			,
				61 =>{
					let tmp = DescribeOutputContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 61);
					_localctx = tmp;
					{
					recog.base.set_state(993);
					recog.base.match_token(DESCRIBE,&mut recog.err_handler)?;

					recog.base.set_state(994);
					recog.base.match_token(OUTPUT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(995);
					recog.identifier()?;

					}
				}
			,
				62 =>{
					let tmp = UpdateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 62);
					_localctx = tmp;
					{
					recog.base.set_state(996);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(1000);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(997);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1002);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				63 =>{
					let tmp = CreateExternalSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 63);
					_localctx = tmp;
					{
					recog.base.set_state(1003);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1004);
					recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

					recog.base.set_state(1005);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					recog.base.set_state(1009);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1006);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1011);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				64 =>{
					let tmp = CreateGroupContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 64);
					_localctx = tmp;
					{
					recog.base.set_state(1012);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1013);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(1017);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1014);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1019);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				65 =>{
					let tmp = CreateIdentityContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 65);
					_localctx = tmp;
					{
					recog.base.set_state(1020);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1021);
					recog.base.match_token(IDENTITY,&mut recog.err_handler)?;

					recog.base.set_state(1025);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1022);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1027);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				66 =>{
					let tmp = CreateProcedureContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 66);
					_localctx = tmp;
					{
					recog.base.set_state(1028);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1031);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(1029);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(1030);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1033);
					recog.base.match_token(PROCEDURE,&mut recog.err_handler)?;

					recog.base.set_state(1037);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(97,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(1034);
							_la = recog.base.input.la(1);
							if { _la <= 0 || (_la==T__0 || _la==SEMI_COLON) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							}
							} 
						}
						recog.base.set_state(1039);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(97,&mut recog.base)?;
					}
					recog.base.set_state(1040);
					recog.base.match_token(DOLLAR_QUOTED_STRING,&mut recog.err_handler)?;

					recog.base.set_state(1044);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1041);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1046);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				67 =>{
					let tmp = CreateUserContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 67);
					_localctx = tmp;
					{
					recog.base.set_state(1047);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1048);
					recog.base.match_token(USER,&mut recog.err_handler)?;

					recog.base.set_state(1052);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1049);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1054);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				68 =>{
					let tmp = CreateFooContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 68);
					_localctx = tmp;
					{
					recog.base.set_state(1055);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1056);
					recog.base.match_token(DATABASE,&mut recog.err_handler)?;

					recog.base.set_state(1060);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1057);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1062);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				69 =>{
					let tmp = CreateFooContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 69);
					_localctx = tmp;
					{
					recog.base.set_state(1063);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1064);
					recog.base.match_token(DATASHARE,&mut recog.err_handler)?;

					recog.base.set_state(1068);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1065);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1070);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				70 =>{
					let tmp = CreateFooContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 70);
					_localctx = tmp;
					{
					recog.base.set_state(1071);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1074);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(1072);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(1073);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1076);
					recog.base.match_token(LIBRARY,&mut recog.err_handler)?;

					recog.base.set_state(1080);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1077);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1082);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				71 =>{
					let tmp = CreateFooContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 71);
					_localctx = tmp;
					{
					recog.base.set_state(1083);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1084);
					recog.base.match_token(MASKING,&mut recog.err_handler)?;

					recog.base.set_state(1088);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1085);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1090);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				72 =>{
					let tmp = CreateFooContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 72);
					_localctx = tmp;
					{
					recog.base.set_state(1091);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1092);
					recog.base.match_token(MODEL,&mut recog.err_handler)?;

					recog.base.set_state(1096);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1093);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1098);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				73 =>{
					let tmp = CreateFooContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 73);
					_localctx = tmp;
					{
					recog.base.set_state(1099);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1100);
					recog.base.match_token(RLS,&mut recog.err_handler)?;

					recog.base.set_state(1104);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1101);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1106);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				74 =>{
					let tmp = DeclareContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 74);
					_localctx = tmp;
					{
					recog.base.set_state(1107);
					recog.base.match_token(DECLARE,&mut recog.err_handler)?;

					recog.base.set_state(1111);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1108);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1113);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				75 =>{
					let tmp = DetachContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 75);
					_localctx = tmp;
					{
					recog.base.set_state(1114);
					recog.base.match_token(DETACH,&mut recog.err_handler)?;

					recog.base.set_state(1118);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1115);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1120);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				76 =>{
					let tmp = EndContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 76);
					_localctx = tmp;
					{
					recog.base.set_state(1121);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(1125);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1122);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1127);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				77 =>{
					let tmp = FetchContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 77);
					_localctx = tmp;
					{
					recog.base.set_state(1128);
					recog.base.match_token(FETCH,&mut recog.err_handler)?;

					recog.base.set_state(1132);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1129);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1134);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				78 =>{
					let tmp = LockContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 78);
					_localctx = tmp;
					{
					recog.base.set_state(1135);
					recog.base.match_token(LOCK,&mut recog.err_handler)?;

					recog.base.set_state(1139);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1136);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1141);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				79 =>{
					let tmp = UnloadContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 79);
					_localctx = tmp;
					{
					recog.base.set_state(1142);
					recog.base.match_token(UNLOAD,&mut recog.err_handler)?;

					recog.base.set_state(1146);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1143);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1148);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				80 =>{
					let tmp = VacuumContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 80);
					_localctx = tmp;
					{
					recog.base.set_state(1149);
					recog.base.match_token(VACUUM,&mut recog.err_handler)?;

					recog.base.set_state(1153);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 1)) & !0x3f) == 0 && ((1usize << (_la - 1)) & ((1usize << (T__0 - 1)) | (1usize << (T__1 - 1)) | (1usize << (T__2 - 1)) | (1usize << (T__3 - 1)) | (1usize << (T__4 - 1)) | (1usize << (T__5 - 1)) | (1usize << (T__6 - 1)) | (1usize << (T__7 - 1)) | (1usize << (T__8 - 1)) | (1usize << (ABORT - 1)) | (1usize << (ABSENT - 1)) | (1usize << (ADD - 1)) | (1usize << (ADMIN - 1)) | (1usize << (AFTER - 1)) | (1usize << (ALL - 1)) | (1usize << (ALTER - 1)) | (1usize << (ANALYZE - 1)) | (1usize << (AND - 1)) | (1usize << (ANTI - 1)) | (1usize << (ANY - 1)) | (1usize << (APPROXIMATE - 1)) | (1usize << (ARRAY - 1)) | (1usize << (AS - 1)) | (1usize << (ASC - 1)) | (1usize << (AT - 1)) | (1usize << (ATTACH - 1)) | (1usize << (AUTHORIZATION - 1)) | (1usize << (AUTO - 1)) | (1usize << (BACKUP - 1)) | (1usize << (BEGIN - 1)) | (1usize << (BERNOULLI - 1)) | (1usize << (BETWEEN - 1)))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BINARY - 33)) | (1usize << (BINDING - 33)) | (1usize << (BOTH - 33)) | (1usize << (BY - 33)) | (1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COLLATE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMA - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONVERT - 33)) | (1usize << (COPARTITION - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (COPY - 65)) | (1usize << (COUNT - 65)) | (1usize << (CREATE - 65)) | (1usize << (CROSS - 65)) | (1usize << (CUBE - 65)) | (1usize << (CURRENT - 65)) | (1usize << (CURRENT_ROLE - 65)) | (1usize << (DATA - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATASHARE - 65)) | (1usize << (DATE - 65)) | (1usize << (DAY - 65)) | (1usize << (DAYS - 65)) | (1usize << (DEALLOCATE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DEFAULTS - 65)) | (1usize << (DEFINE - 65)) | (1usize << (DEFINER - 65)) | (1usize << (DELETE - 65)) | (1usize << (DELIMITED - 65)) | (1usize << (DELIMITER - 65)) | (1usize << (DENY - 65)) | (1usize << (DESC - 65)) | (1usize << (DESCRIBE - 65)) | (1usize << (DESCRIPTOR - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (DISTKEY - 65)) | (1usize << (DISTRIBUTED - 65)) | (1usize << (DISTSTYLE - 65)) | (1usize << (DETACH - 65)) | (1usize << (DOUBLE - 65)))) != 0) || ((((_la - 97)) & !0x3f) == 0 && ((1usize << (_la - 97)) & ((1usize << (DROP - 97)) | (1usize << (ELSE - 97)) | (1usize << (EMPTY - 97)) | (1usize << (ENCODE - 97)) | (1usize << (ENCODING - 97)) | (1usize << (END - 97)) | (1usize << (ERROR - 97)) | (1usize << (ESCAPE - 97)) | (1usize << (EVEN - 97)) | (1usize << (EXCEPT - 97)) | (1usize << (EXCLUDE - 97)) | (1usize << (EXCLUDING - 97)) | (1usize << (EXECUTE - 97)) | (1usize << (EXISTS - 97)) | (1usize << (EXPLAIN - 97)) | (1usize << (EXTERNAL - 97)) | (1usize << (EXTRACT - 97)) | (1usize << (FALSE - 97)) | (1usize << (FETCH - 97)) | (1usize << (FIELDS - 97)) | (1usize << (FILTER - 97)) | (1usize << (FINAL - 97)) | (1usize << (FIRST - 97)) | (1usize << (FIRST_VALUE - 97)) | (1usize << (FOLLOWING - 97)) | (1usize << (FOR - 97)) | (1usize << (FOREIGN - 97)) | (1usize << (FORMAT - 97)) | (1usize << (FROM - 97)) | (1usize << (FULL - 97)) | (1usize << (FUNCTION - 97)) | (1usize << (FUNCTIONS - 97)))) != 0) || ((((_la - 129)) & !0x3f) == 0 && ((1usize << (_la - 129)) & ((1usize << (GENERATED - 129)) | (1usize << (GRACE - 129)) | (1usize << (GRANT - 129)) | (1usize << (GRANTED - 129)) | (1usize << (GRANTS - 129)) | (1usize << (GRAPHVIZ - 129)) | (1usize << (GROUP - 129)) | (1usize << (GROUPING - 129)) | (1usize << (GROUPS - 129)) | (1usize << (GZIP - 129)) | (1usize << (HAVING - 129)) | (1usize << (HEADER - 129)) | (1usize << (HOUR - 129)) | (1usize << (HOURS - 129)) | (1usize << (IAM_ROLE - 129)) | (1usize << (IDENTITY - 129)) | (1usize << (IF - 129)) | (1usize << (IGNORE - 129)) | (1usize << (IMMUTABLE - 129)) | (1usize << (IN - 129)) | (1usize << (INCLUDE - 129)) | (1usize << (INCLUDING - 129)) | (1usize << (INITIAL - 129)) | (1usize << (INNER - 129)) | (1usize << (INPUT - 129)) | (1usize << (INPUTFORMAT - 129)) | (1usize << (INOUT - 129)) | (1usize << (INTERLEAVED - 129)) | (1usize << (INSERT - 129)) | (1usize << (INTERSECT - 129)) | (1usize << (INTERVAL - 129)) | (1usize << (INTO - 129)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (INVOKER - 161)) | (1usize << (IO - 161)) | (1usize << (IS - 161)) | (1usize << (ISOLATION - 161)) | (1usize << (ISNULL - 161)) | (1usize << (ILIKE - 161)) | (1usize << (JOIN - 161)) | (1usize << (JSON - 161)) | (1usize << (JSON_ARRAY - 161)) | (1usize << (JSON_EXISTS - 161)) | (1usize << (JSON_OBJECT - 161)) | (1usize << (JSON_QUERY - 161)) | (1usize << (JSON_VALUE - 161)) | (1usize << (KB - 161)) | (1usize << (KEEP - 161)) | (1usize << (KEY - 161)) | (1usize << (KEYS - 161)) | (1usize << (LAG - 161)) | (1usize << (LAMBDA - 161)) | (1usize << (LANGUAGE - 161)) | (1usize << (LAST - 161)) | (1usize << (LAST_VALUE - 161)) | (1usize << (LATERAL - 161)) | (1usize << (LEADING - 161)) | (1usize << (LEFT - 161)) | (1usize << (LEVEL - 161)) | (1usize << (LIBRARY - 161)) | (1usize << (LIKE - 161)) | (1usize << (LIMIT - 161)) | (1usize << (LINES - 161)) | (1usize << (LISTAGG - 161)) | (1usize << (LISTAGGDISTINCT - 161)))) != 0) || ((((_la - 193)) & !0x3f) == 0 && ((1usize << (_la - 193)) & ((1usize << (LOCAL - 193)) | (1usize << (LOCATION - 193)) | (1usize << (LOCK - 193)) | (1usize << (LOGICAL - 193)) | (1usize << (M - 193)) | (1usize << (MAP - 193)) | (1usize << (MASKING - 193)) | (1usize << (MATCH - 193)) | (1usize << (MATCHED - 193)) | (1usize << (MATCHES - 193)) | (1usize << (MATCH_RECOGNIZE - 193)) | (1usize << (MATERIALIZED - 193)) | (1usize << (MAX - 193)) | (1usize << (MAX_BATCH_ROWS - 193)) | (1usize << (MAX_BATCH_SIZE - 193)) | (1usize << (MB - 193)) | (1usize << (MEASURES - 193)) | (1usize << (MERGE - 193)) | (1usize << (MIN - 193)) | (1usize << (MINUS_KW - 193)) | (1usize << (MINUTE - 193)) | (1usize << (MINUTES - 193)) | (1usize << (MODEL - 193)) | (1usize << (MONTH - 193)) | (1usize << (MONTHS - 193)) | (1usize << (NATURAL - 193)) | (1usize << (NEXT - 193)) | (1usize << (NFC - 193)) | (1usize << (NFD - 193)) | (1usize << (NFKC - 193)) | (1usize << (NFKD - 193)) | (1usize << (NO - 193)))) != 0) || ((((_la - 225)) & !0x3f) == 0 && ((1usize << (_la - 225)) & ((1usize << (NONE - 225)) | (1usize << (NORMALIZE - 225)) | (1usize << (NOT - 225)) | (1usize << (NOTNULL - 225)) | (1usize << (NULL - 225)) | (1usize << (NULLS - 225)) | (1usize << (OBJECT - 225)) | (1usize << (OF - 225)) | (1usize << (OFFSET - 225)) | (1usize << (OMIT - 225)) | (1usize << (ON - 225)) | (1usize << (ONE - 225)) | (1usize << (ONLY - 225)) | (1usize << (OPTION - 225)) | (1usize << (OPTIONS - 225)) | (1usize << (OR - 225)) | (1usize << (ORDER - 225)) | (1usize << (ORDINALITY - 225)) | (1usize << (OUT - 225)) | (1usize << (OUTER - 225)) | (1usize << (OUTPUT - 225)) | (1usize << (OUTPUTFORMAT - 225)) | (1usize << (OVER - 225)) | (1usize << (OVERFLOW - 225)) | (1usize << (PARTITION - 225)) | (1usize << (PARTITIONED - 225)) | (1usize << (PARTITIONS - 225)) | (1usize << (PASSING - 225)) | (1usize << (PAST - 225)) | (1usize << (PATH - 225)) | (1usize << (PATTERN - 225)) | (1usize << (PER - 225)))) != 0) || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PERCENTILE_CONT - 257)) | (1usize << (PERCENTILE_DISC - 257)) | (1usize << (PERIOD - 257)) | (1usize << (PERMUTE - 257)) | (1usize << (PG_CATALOG - 257)) | (1usize << (PIVOT - 257)) | (1usize << (POSITION - 257)) | (1usize << (PRECEDING - 257)) | (1usize << (PRECISION - 257)) | (1usize << (PREPARE - 257)) | (1usize << (PRIOR - 257)) | (1usize << (PROCEDURE - 257)) | (1usize << (PRIMARY - 257)) | (1usize << (PRIVILEGES - 257)) | (1usize << (PROPERTIES - 257)) | (1usize << (PRUNE - 257)) | (1usize << (QUALIFY - 257)) | (1usize << (QUOTES - 257)) | (1usize << (RANGE - 257)) | (1usize << (READ - 257)) | (1usize << (RECURSIVE - 257)) | (1usize << (REFERENCES - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RENAME - 257)) | (1usize << (REPEATABLE - 257)) | (1usize << (REPLACE - 257)) | (1usize << (RESET - 257)) | (1usize << (RESPECT - 257)) | (1usize << (RESTRICT - 257)) | (1usize << (RETRY_TIMEOUT - 257)) | (1usize << (RETURNING - 257)) | (1usize << (RETURNS - 257)))) != 0) || ((((_la - 289)) & !0x3f) == 0 && ((1usize << (_la - 289)) & ((1usize << (REVOKE - 289)) | (1usize << (RIGHT - 289)) | (1usize << (RLS - 289)) | (1usize << (ROLE - 289)) | (1usize << (ROLES - 289)) | (1usize << (ROLLBACK - 289)) | (1usize << (ROLLUP - 289)) | (1usize << (ROW - 289)) | (1usize << (ROWS - 289)) | (1usize << (RUNNING - 289)) | (1usize << (S - 289)) | (1usize << (SAGEMAKER - 289)) | (1usize << (SCALAR - 289)) | (1usize << (SEC - 289)) | (1usize << (SECOND - 289)) | (1usize << (SECONDS - 289)) | (1usize << (SCHEMA - 289)) | (1usize << (SCHEMAS - 289)) | (1usize << (SECURITY - 289)) | (1usize << (SEEK - 289)) | (1usize << (SELECT - 289)) | (1usize << (SEMI - 289)) | (1usize << (SERDE - 289)) | (1usize << (SERDEPROPERTIES - 289)) | (1usize << (SERIALIZABLE - 289)) | (1usize << (SESSION - 289)) | (1usize << (SET - 289)) | (1usize << (SETS - 289)) | (1usize << (SHOW - 289)) | (1usize << (SIMILAR - 289)) | (1usize << (SNAPSHOT - 289)) | (1usize << (SOME - 289)))) != 0) || ((((_la - 321)) & !0x3f) == 0 && ((1usize << (_la - 321)) & ((1usize << (SORTKEY - 321)) | (1usize << (SQL - 321)) | (1usize << (STABLE - 321)) | (1usize << (START - 321)) | (1usize << (STATS - 321)) | (1usize << (STORED - 321)) | (1usize << (STRUCT - 321)) | (1usize << (SUBSET - 321)) | (1usize << (SUBSTRING - 321)) | (1usize << (SYSTEM - 321)) | (1usize << (SYSTEM_TIME - 321)) | (1usize << (TABLE - 321)) | (1usize << (TABLES - 321)) | (1usize << (TABLESAMPLE - 321)) | (1usize << (TEMP - 321)) | (1usize << (TEMPORARY - 321)) | (1usize << (TERMINATED - 321)) | (1usize << (TEXT - 321)) | (1usize << (STRING_KW - 321)) | (1usize << (THEN - 321)) | (1usize << (TIES - 321)) | (1usize << (TIME - 321)) | (1usize << (TIMESTAMP - 321)) | (1usize << (TO - 321)) | (1usize << (TOP - 321)) | (1usize << (TRAILING - 321)) | (1usize << (TRANSACTION - 321)) | (1usize << (TRIM - 321)) | (1usize << (TRUE - 321)) | (1usize << (TRUNCATE - 321)) | (1usize << (TRY_CAST - 321)) | (1usize << (TUPLE - 321)))) != 0) || ((((_la - 353)) & !0x3f) == 0 && ((1usize << (_la - 353)) & ((1usize << (TYPE - 353)) | (1usize << (UESCAPE - 353)) | (1usize << (UNBOUNDED - 353)) | (1usize << (UNCOMMITTED - 353)) | (1usize << (UNCONDITIONAL - 353)) | (1usize << (UNION - 353)) | (1usize << (UNIQUE - 353)) | (1usize << (UNKNOWN - 353)) | (1usize << (UNLOAD - 353)) | (1usize << (UNMATCHED - 353)) | (1usize << (UNNEST - 353)) | (1usize << (UNPIVOT - 353)) | (1usize << (UNSIGNED - 353)) | (1usize << (UPDATE - 353)) | (1usize << (USE - 353)) | (1usize << (USER - 353)) | (1usize << (USING - 353)) | (1usize << (UTF16 - 353)) | (1usize << (UTF32 - 353)) | (1usize << (UTF8 - 353)) | (1usize << (VACUUM - 353)) | (1usize << (VALIDATE - 353)) | (1usize << (VALUE - 353)) | (1usize << (VALUES - 353)) | (1usize << (VARYING - 353)) | (1usize << (VARIADIC - 353)) | (1usize << (VERBOSE - 353)) | (1usize << (VERSION - 353)) | (1usize << (VIEW - 353)) | (1usize << (VOLATILE - 353)) | (1usize << (WEEK - 353)) | (1usize << (WHEN - 353)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (WHERE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (WORK - 385)) | (1usize << (WRAPPER - 385)) | (1usize << (WRITE - 385)) | (1usize << (XZ - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (YES - 385)) | (1usize << (ZONE - 385)) | (1usize << (ZSTD - 385)) | (1usize << (LPAREN - 385)) | (1usize << (RPAREN - 385)) | (1usize << (LBRACKET - 385)) | (1usize << (RBRACKET - 385)) | (1usize << (DOT - 385)) | (1usize << (EQ - 385)) | (1usize << (NEQ - 385)) | (1usize << (LT - 385)) | (1usize << (LTE - 385)) | (1usize << (GT - 385)) | (1usize << (GTE - 385)) | (1usize << (PLUS - 385)) | (1usize << (MINUS - 385)) | (1usize << (ASTERISK - 385)) | (1usize << (SLASH - 385)) | (1usize << (PERCENT - 385)) | (1usize << (CONCAT - 385)) | (1usize << (QUESTION_MARK - 385)))) != 0) || ((((_la - 418)) & !0x3f) == 0 && ((1usize << (_la - 418)) & ((1usize << (COLON - 418)) | (1usize << (DOLLAR - 418)) | (1usize << (BITWISE_AND - 418)) | (1usize << (BITWISE_OR - 418)) | (1usize << (BITWISE_XOR - 418)) | (1usize << (BINARY_EXP - 418)) | (1usize << (BITWISE_SHIFT_LEFT - 418)) | (1usize << (BITWISE_SHIFT_RIGHT - 418)) | (1usize << (POSIX - 418)) | (1usize << (POSIX_LIKE - 418)) | (1usize << (POSIX_ILIKE - 418)) | (1usize << (POSIX_NOT_LIKE - 418)) | (1usize << (POSIX_NOT_ILIKE - 418)) | (1usize << (POSIX_STAR - 418)) | (1usize << (ESCAPE_SEQUENCE - 418)) | (1usize << (STRING - 418)) | (1usize << (UNICODE_STRING - 418)) | (1usize << (DOLLAR_QUOTED_STRING - 418)) | (1usize << (BINARY_LITERAL - 418)) | (1usize << (INTEGER_VALUE - 418)) | (1usize << (DECIMAL_VALUE - 418)) | (1usize << (DOUBLE_VALUE - 418)) | (1usize << (IDENTIFIER - 418)) | (1usize << (DIGIT_IDENTIFIER - 418)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 418)) | (1usize << (QUOTED_IDENTIFIER - 418)) | (1usize << (VARIABLE - 418)) | (1usize << (SIMPLE_COMMENT - 418)) | (1usize << (BRACKETED_COMMENT - 418)) | (1usize << (WS - 418)) | (1usize << (UNPAIRED_TOKEN - 418)) | (1usize << (UNRECOGNIZED - 418)))) != 0) {
						{
						{
						recog.base.set_state(1150);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1155);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableElements ----------------
pub type TableElementsContextAll<'input> = TableElementsContext<'input>;


pub type TableElementsContext<'input> = BaseParserRuleContext<'input,TableElementsContextExt<'input>>;

#[derive(Clone)]
pub struct TableElementsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableElementsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableElementsContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableElements(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_tableElements(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableElementsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableElements(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableElementsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableElements }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableElements }
}
antlr_rust::tid!{TableElementsContextExt<'a>}

impl<'input> TableElementsContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableElementsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableElementsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableElementsContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableElementsContextExt<'input>>{

fn tableElement_all(&self) ->  Vec<Rc<TableElementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tableElement(&self, i: usize) -> Option<Rc<TableElementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableElementsContextAttrs<'input> for TableElementsContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableElements(&mut self,)
	-> Result<Rc<TableElementsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableElementsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 12, RULE_tableElements);
        let mut _localctx: Rc<TableElementsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableElement*/
			recog.base.set_state(1158);
			recog.tableElement()?;

			recog.base.set_state(1163);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(115,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1159);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule tableElement*/
					recog.base.set_state(1160);
					recog.tableElement()?;

					}
					} 
				}
				recog.base.set_state(1165);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(115,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotNullClause ----------------
pub type UnpivotNullClauseContextAll<'input> = UnpivotNullClauseContext<'input>;


pub type UnpivotNullClauseContext<'input> = BaseParserRuleContext<'input,UnpivotNullClauseContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotNullClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for UnpivotNullClauseContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UnpivotNullClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotNullClause(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_unpivotNullClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UnpivotNullClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_unpivotNullClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotNullClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotNullClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotNullClause }
}
antlr_rust::tid!{UnpivotNullClauseContextExt<'a>}

impl<'input> UnpivotNullClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotNullClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotNullClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotNullClauseContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<UnpivotNullClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}

}

impl<'input> UnpivotNullClauseContextAttrs<'input> for UnpivotNullClauseContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotNullClause(&mut self,)
	-> Result<Rc<UnpivotNullClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotNullClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 14, RULE_unpivotNullClause);
        let mut _localctx: Rc<UnpivotNullClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1166);
			_la = recog.base.input.la(1);
			if { !(_la==EXCLUDE || _la==INCLUDE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1167);
			recog.base.match_token(NULLS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- redshiftCreateExternalTableClauses ----------------
pub type RedshiftCreateExternalTableClausesContextAll<'input> = RedshiftCreateExternalTableClausesContext<'input>;


pub type RedshiftCreateExternalTableClausesContext<'input> = BaseParserRuleContext<'input,RedshiftCreateExternalTableClausesContextExt<'input>>;

#[derive(Clone)]
pub struct RedshiftCreateExternalTableClausesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RedshiftCreateExternalTableClausesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftCreateExternalTableClausesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_redshiftCreateExternalTableClauses(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_redshiftCreateExternalTableClauses(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftCreateExternalTableClausesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftCreateExternalTableClauses(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftCreateExternalTableClausesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_redshiftCreateExternalTableClauses }
	//fn type_rule_index() -> usize where Self: Sized { RULE_redshiftCreateExternalTableClauses }
}
antlr_rust::tid!{RedshiftCreateExternalTableClausesContextExt<'a>}

impl<'input> RedshiftCreateExternalTableClausesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RedshiftCreateExternalTableClausesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RedshiftCreateExternalTableClausesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RedshiftCreateExternalTableClausesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RedshiftCreateExternalTableClausesContextExt<'input>>{

fn locationSpec_all(&self) ->  Vec<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn locationSpec(&self, i: usize) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn partitionedByFieldSpec_all(&self) ->  Vec<Rc<PartitionedByFieldSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionedByFieldSpec(&self, i: usize) -> Option<Rc<PartitionedByFieldSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn rowFormatedAndSerdeSpec_all(&self) ->  Vec<Rc<RowFormatedAndSerdeSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowFormatedAndSerdeSpec(&self, i: usize) -> Option<Rc<RowFormatedAndSerdeSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn createFileFormat_all(&self) ->  Vec<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn createFileFormat(&self, i: usize) -> Option<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn tableProperties_all(&self) ->  Vec<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tableProperties(&self, i: usize) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> RedshiftCreateExternalTableClausesContextAttrs<'input> for RedshiftCreateExternalTableClausesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn redshiftCreateExternalTableClauses(&mut self,)
	-> Result<Rc<RedshiftCreateExternalTableClausesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RedshiftCreateExternalTableClausesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 16, RULE_redshiftCreateExternalTableClauses);
        let mut _localctx: Rc<RedshiftCreateExternalTableClausesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1176);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==LOCATION || _la==PARTITIONED || _la==ROW || _la==STORED || _la==TABLE {
				{
				recog.base.set_state(1174);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 LOCATION 
					=> {
						{
						/*InvokeRule locationSpec*/
						recog.base.set_state(1169);
						recog.locationSpec()?;

						}
					}

				 PARTITIONED 
					=> {
						{
						/*InvokeRule partitionedByFieldSpec*/
						recog.base.set_state(1170);
						recog.partitionedByFieldSpec()?;

						}
					}

				 ROW 
					=> {
						{
						/*InvokeRule rowFormatedAndSerdeSpec*/
						recog.base.set_state(1171);
						recog.rowFormatedAndSerdeSpec()?;

						}
					}

				 STORED 
					=> {
						{
						/*InvokeRule createFileFormat*/
						recog.base.set_state(1172);
						recog.createFileFormat()?;

						}
					}

				 TABLE 
					=> {
						{
						/*InvokeRule tableProperties*/
						recog.base.set_state(1173);
						recog.tableProperties()?;

						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
				recog.base.set_state(1178);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- redshiftCreateExternalTableAsClauses ----------------
pub type RedshiftCreateExternalTableAsClausesContextAll<'input> = RedshiftCreateExternalTableAsClausesContext<'input>;


pub type RedshiftCreateExternalTableAsClausesContext<'input> = BaseParserRuleContext<'input,RedshiftCreateExternalTableAsClausesContextExt<'input>>;

#[derive(Clone)]
pub struct RedshiftCreateExternalTableAsClausesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RedshiftCreateExternalTableAsClausesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftCreateExternalTableAsClausesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_redshiftCreateExternalTableAsClauses(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_redshiftCreateExternalTableAsClauses(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftCreateExternalTableAsClausesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftCreateExternalTableAsClauses(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftCreateExternalTableAsClausesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_redshiftCreateExternalTableAsClauses }
	//fn type_rule_index() -> usize where Self: Sized { RULE_redshiftCreateExternalTableAsClauses }
}
antlr_rust::tid!{RedshiftCreateExternalTableAsClausesContextExt<'a>}

impl<'input> RedshiftCreateExternalTableAsClausesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RedshiftCreateExternalTableAsClausesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RedshiftCreateExternalTableAsClausesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RedshiftCreateExternalTableAsClausesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RedshiftCreateExternalTableAsClausesContextExt<'input>>{

fn locationSpec_all(&self) ->  Vec<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn locationSpec(&self, i: usize) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn partitionedByNameSpec_all(&self) ->  Vec<Rc<PartitionedByNameSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionedByNameSpec(&self, i: usize) -> Option<Rc<PartitionedByNameSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn rowFormatedSpec_all(&self) ->  Vec<Rc<RowFormatedSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowFormatedSpec(&self, i: usize) -> Option<Rc<RowFormatedSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn createFileFormat_all(&self) ->  Vec<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn createFileFormat(&self, i: usize) -> Option<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn tableProperties_all(&self) ->  Vec<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tableProperties(&self, i: usize) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> RedshiftCreateExternalTableAsClausesContextAttrs<'input> for RedshiftCreateExternalTableAsClausesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn redshiftCreateExternalTableAsClauses(&mut self,)
	-> Result<Rc<RedshiftCreateExternalTableAsClausesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RedshiftCreateExternalTableAsClausesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 18, RULE_redshiftCreateExternalTableAsClauses);
        let mut _localctx: Rc<RedshiftCreateExternalTableAsClausesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1186);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==LOCATION || _la==PARTITIONED || _la==ROW || _la==STORED || _la==TABLE {
				{
				recog.base.set_state(1184);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 LOCATION 
					=> {
						{
						/*InvokeRule locationSpec*/
						recog.base.set_state(1179);
						recog.locationSpec()?;

						}
					}

				 PARTITIONED 
					=> {
						{
						/*InvokeRule partitionedByNameSpec*/
						recog.base.set_state(1180);
						recog.partitionedByNameSpec()?;

						}
					}

				 ROW 
					=> {
						{
						/*InvokeRule rowFormatedSpec*/
						recog.base.set_state(1181);
						recog.rowFormatedSpec()?;

						}
					}

				 STORED 
					=> {
						{
						/*InvokeRule createFileFormat*/
						recog.base.set_state(1182);
						recog.createFileFormat()?;

						}
					}

				 TABLE 
					=> {
						{
						/*InvokeRule tableProperties*/
						recog.base.set_state(1183);
						recog.tableProperties()?;

						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
				recog.base.set_state(1188);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- locationSpec ----------------
pub type LocationSpecContextAll<'input> = LocationSpecContext<'input>;


pub type LocationSpecContext<'input> = BaseParserRuleContext<'input,LocationSpecContextExt<'input>>;

#[derive(Clone)]
pub struct LocationSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for LocationSpecContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LocationSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_locationSpec(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_locationSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LocationSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_locationSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for LocationSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_locationSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_locationSpec }
}
antlr_rust::tid!{LocationSpecContextExt<'a>}

impl<'input> LocationSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LocationSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LocationSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LocationSpecContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<LocationSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LocationSpecContextAttrs<'input> for LocationSpecContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn locationSpec(&mut self,)
	-> Result<Rc<LocationSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LocationSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 20, RULE_locationSpec);
        let mut _localctx: Rc<LocationSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1189);
			recog.base.match_token(LOCATION,&mut recog.err_handler)?;

			/*InvokeRule string*/
			recog.base.set_state(1190);
			recog.string()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionedByNameSpec ----------------
pub type PartitionedByNameSpecContextAll<'input> = PartitionedByNameSpecContext<'input>;


pub type PartitionedByNameSpecContext<'input> = BaseParserRuleContext<'input,PartitionedByNameSpecContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionedByNameSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PartitionedByNameSpecContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PartitionedByNameSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionedByNameSpec(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_partitionedByNameSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PartitionedByNameSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_partitionedByNameSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionedByNameSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionedByNameSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionedByNameSpec }
}
antlr_rust::tid!{PartitionedByNameSpecContextExt<'a>}

impl<'input> PartitionedByNameSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionedByNameSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionedByNameSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionedByNameSpecContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PartitionedByNameSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITIONED
/// Returns `None` if there is no child corresponding to token PARTITIONED
fn PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionedByNameSpecContextAttrs<'input> for PartitionedByNameSpecContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionedByNameSpec(&mut self,)
	-> Result<Rc<PartitionedByNameSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionedByNameSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 22, RULE_partitionedByNameSpec);
        let mut _localctx: Rc<PartitionedByNameSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1192);
			recog.base.match_token(PARTITIONED,&mut recog.err_handler)?;

			recog.base.set_state(1193);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule columnAliases*/
			recog.base.set_state(1194);
			recog.columnAliases()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionedByFieldSpec ----------------
pub type PartitionedByFieldSpecContextAll<'input> = PartitionedByFieldSpecContext<'input>;


pub type PartitionedByFieldSpecContext<'input> = BaseParserRuleContext<'input,PartitionedByFieldSpecContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionedByFieldSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PartitionedByFieldSpecContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PartitionedByFieldSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionedByFieldSpec(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_partitionedByFieldSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PartitionedByFieldSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_partitionedByFieldSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionedByFieldSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionedByFieldSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionedByFieldSpec }
}
antlr_rust::tid!{PartitionedByFieldSpecContextExt<'a>}

impl<'input> PartitionedByFieldSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionedByFieldSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionedByFieldSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionedByFieldSpecContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PartitionedByFieldSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITIONED
/// Returns `None` if there is no child corresponding to token PARTITIONED
fn PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn partitionColumns(&self) -> Option<Rc<PartitionColumnsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionedByFieldSpecContextAttrs<'input> for PartitionedByFieldSpecContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionedByFieldSpec(&mut self,)
	-> Result<Rc<PartitionedByFieldSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionedByFieldSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 24, RULE_partitionedByFieldSpec);
        let mut _localctx: Rc<PartitionedByFieldSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1196);
			recog.base.match_token(PARTITIONED,&mut recog.err_handler)?;

			recog.base.set_state(1197);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule partitionColumns*/
			recog.base.set_state(1198);
			recog.partitionColumns()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createFileFormat ----------------
pub type CreateFileFormatContextAll<'input> = CreateFileFormatContext<'input>;


pub type CreateFileFormatContext<'input> = BaseParserRuleContext<'input,CreateFileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct CreateFileFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for CreateFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CreateFileFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createFileFormat(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_createFileFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CreateFileFormatContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_createFileFormat(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createFileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createFileFormat }
}
antlr_rust::tid!{CreateFileFormatContextExt<'a>}

impl<'input> CreateFileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateFileFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateFileFormatContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateFileFormatContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<CreateFileFormatContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token INPUTFORMAT
/// Returns `None` if there is no child corresponding to token INPUTFORMAT
fn INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INPUTFORMAT, 0)
}
fn string_all(&self) ->  Vec<Rc<StringContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn string(&self, i: usize) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token OUTPUTFORMAT
fn OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OUTPUTFORMAT, 0)
}

}

impl<'input> CreateFileFormatContextAttrs<'input> for CreateFileFormatContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createFileFormat(&mut self,)
	-> Result<Rc<CreateFileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateFileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 26, RULE_createFileFormat);
        let mut _localctx: Rc<CreateFileFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1200);
			recog.base.match_token(STORED,&mut recog.err_handler)?;

			recog.base.set_state(1201);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(1208);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(120,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1202);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					{
					recog.base.set_state(1203);
					recog.base.match_token(INPUTFORMAT,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1204);
					recog.string()?;

					recog.base.set_state(1205);
					recog.base.match_token(OUTPUTFORMAT,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1206);
					recog.string()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowFormatedSpec ----------------
pub type RowFormatedSpecContextAll<'input> = RowFormatedSpecContext<'input>;


pub type RowFormatedSpecContext<'input> = BaseParserRuleContext<'input,RowFormatedSpecContextExt<'input>>;

#[derive(Clone)]
pub struct RowFormatedSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RowFormatedSpecContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RowFormatedSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowFormatedSpec(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_rowFormatedSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RowFormatedSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rowFormatedSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFormatedSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormatedSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormatedSpec }
}
antlr_rust::tid!{RowFormatedSpecContextExt<'a>}

impl<'input> RowFormatedSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFormatedSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFormatedSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowFormatedSpecContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RowFormatedSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ROW
/// Returns `None` if there is no child corresponding to token ROW
fn ROW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMAT
/// Returns `None` if there is no child corresponding to token FORMAT
fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITED
/// Returns `None` if there is no child corresponding to token DELIMITED
fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DELIMITED, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token TERMINATED in current rule
fn TERMINATED_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token TERMINATED, starting from 0.
/// Returns `None` if number of children corresponding to token TERMINATED is less or equal than `i`.
fn TERMINATED(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TERMINATED, i)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
fn string_all(&self) ->  Vec<Rc<StringContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn string(&self, i: usize) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token LINES in current rule
fn LINES_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LINES, starting from 0.
/// Returns `None` if number of children corresponding to token LINES is less or equal than `i`.
fn LINES(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LINES, i)
}
/// Retrieves all `TerminalNode`s corresponding to token FIELDS in current rule
fn FIELDS_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token FIELDS, starting from 0.
/// Returns `None` if number of children corresponding to token FIELDS is less or equal than `i`.
fn FIELDS(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FIELDS, i)
}

}

impl<'input> RowFormatedSpecContextAttrs<'input> for RowFormatedSpecContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowFormatedSpec(&mut self,)
	-> Result<Rc<RowFormatedSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFormatedSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 28, RULE_rowFormatedSpec);
        let mut _localctx: Rc<RowFormatedSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1210);
			recog.base.match_token(ROW,&mut recog.err_handler)?;

			recog.base.set_state(1211);
			recog.base.match_token(FORMAT,&mut recog.err_handler)?;

			{
			recog.base.set_state(1212);
			recog.base.match_token(DELIMITED,&mut recog.err_handler)?;

			recog.base.set_state(1217); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(1213);
				_la = recog.base.input.la(1);
				if { !(_la==FIELDS || _la==LINES) } {
					recog.err_handler.recover_inline(&mut recog.base)?;

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				recog.base.set_state(1214);
				recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

				recog.base.set_state(1215);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule string*/
				recog.base.set_state(1216);
				recog.string()?;

				}
				}
				recog.base.set_state(1219); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==FIELDS || _la==LINES) {break}
			}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowFormatedAndSerdeSpec ----------------
pub type RowFormatedAndSerdeSpecContextAll<'input> = RowFormatedAndSerdeSpecContext<'input>;


pub type RowFormatedAndSerdeSpecContext<'input> = BaseParserRuleContext<'input,RowFormatedAndSerdeSpecContextExt<'input>>;

#[derive(Clone)]
pub struct RowFormatedAndSerdeSpecContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RowFormatedAndSerdeSpecContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RowFormatedAndSerdeSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowFormatedAndSerdeSpec(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_rowFormatedAndSerdeSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RowFormatedAndSerdeSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rowFormatedAndSerdeSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFormatedAndSerdeSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormatedAndSerdeSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormatedAndSerdeSpec }
}
antlr_rust::tid!{RowFormatedAndSerdeSpecContextExt<'a>}

impl<'input> RowFormatedAndSerdeSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFormatedAndSerdeSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFormatedAndSerdeSpecContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RowFormatedAndSerdeSpecContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RowFormatedAndSerdeSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ROW
/// Returns `None` if there is no child corresponding to token ROW
fn ROW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMAT
/// Returns `None` if there is no child corresponding to token FORMAT
fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITED
/// Returns `None` if there is no child corresponding to token DELIMITED
fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DELIMITED, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDE
/// Returns `None` if there is no child corresponding to token SERDE
fn SERDE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SERDE, 0)
}
fn string_all(&self) ->  Vec<Rc<StringContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn string(&self, i: usize) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token TERMINATED in current rule
fn TERMINATED_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token TERMINATED, starting from 0.
/// Returns `None` if number of children corresponding to token TERMINATED is less or equal than `i`.
fn TERMINATED(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TERMINATED, i)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SERDEPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LINES in current rule
fn LINES_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LINES, starting from 0.
/// Returns `None` if number of children corresponding to token LINES is less or equal than `i`.
fn LINES(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LINES, i)
}
/// Retrieves all `TerminalNode`s corresponding to token FIELDS in current rule
fn FIELDS_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token FIELDS, starting from 0.
/// Returns `None` if number of children corresponding to token FIELDS is less or equal than `i`.
fn FIELDS(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FIELDS, i)
}
/// Retrieves all `TerminalNode`s corresponding to token EQ in current rule
fn EQ_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token EQ, starting from 0.
/// Returns `None` if number of children corresponding to token EQ is less or equal than `i`.
fn EQ(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EQ, i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RowFormatedAndSerdeSpecContextAttrs<'input> for RowFormatedAndSerdeSpecContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowFormatedAndSerdeSpec(&mut self,)
	-> Result<Rc<RowFormatedAndSerdeSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFormatedAndSerdeSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 30, RULE_rowFormatedAndSerdeSpec);
        let mut _localctx: Rc<RowFormatedAndSerdeSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1221);
			recog.base.match_token(ROW,&mut recog.err_handler)?;

			recog.base.set_state(1222);
			recog.base.match_token(FORMAT,&mut recog.err_handler)?;

			recog.base.set_state(1258);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DELIMITED 
				=> {
					{
					recog.base.set_state(1223);
					recog.base.match_token(DELIMITED,&mut recog.err_handler)?;

					recog.base.set_state(1228); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						recog.base.set_state(1224);
						_la = recog.base.input.la(1);
						if { !(_la==FIELDS || _la==LINES) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						recog.base.set_state(1225);
						recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

						recog.base.set_state(1226);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(1227);
						recog.string()?;

						}
						}
						recog.base.set_state(1230); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==FIELDS || _la==LINES) {break}
					}
					}
				}

			 SERDE 
				=> {
					{
					recog.base.set_state(1232);
					recog.base.match_token(SERDE,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1233);
					recog.string()?;

					recog.base.set_state(1256);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						recog.base.set_state(1234);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						recog.base.set_state(1235);
						recog.base.match_token(SERDEPROPERTIES,&mut recog.err_handler)?;

						recog.base.set_state(1236);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						{
						/*InvokeRule string*/
						recog.base.set_state(1237);
						recog.string()?;

						recog.base.set_state(1238);
						recog.base.match_token(EQ,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(1239);
						recog.string()?;

						}
						recog.base.set_state(1248);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(123,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(1241);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule string*/
								recog.base.set_state(1242);
								recog.string()?;

								recog.base.set_state(1243);
								recog.base.match_token(EQ,&mut recog.err_handler)?;

								/*InvokeRule string*/
								recog.base.set_state(1244);
								recog.string()?;

								}
								} 
							}
							recog.base.set_state(1250);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(123,&mut recog.base)?;
						}
						recog.base.set_state(1252);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(1251);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							 cast_mut::<_,RowFormatedAndSerdeSpecContext >(&mut _localctx).tail = Some(tmp);
							  

							}
						}

						recog.base.set_state(1254);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableProperties ----------------
pub type TablePropertiesContextAll<'input> = TablePropertiesContext<'input>;


pub type TablePropertiesContext<'input> = BaseParserRuleContext<'input,TablePropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct TablePropertiesContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TablePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TablePropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableProperties(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_tableProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TablePropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for TablePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableProperties }
}
antlr_rust::tid!{TablePropertiesContextExt<'a>}

impl<'input> TablePropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TablePropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TablePropertiesContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TablePropertiesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TablePropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token PROPERTIES
/// Returns `None` if there is no child corresponding to token PROPERTIES
fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn string_all(&self) ->  Vec<Rc<StringContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn string(&self, i: usize) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token EQ in current rule
fn EQ_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token EQ, starting from 0.
/// Returns `None` if number of children corresponding to token EQ is less or equal than `i`.
fn EQ(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EQ, i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TablePropertiesContextAttrs<'input> for TablePropertiesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableProperties(&mut self,)
	-> Result<Rc<TablePropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TablePropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 32, RULE_tableProperties);
        let mut _localctx: Rc<TablePropertiesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1260);
			recog.base.match_token(TABLE,&mut recog.err_handler)?;

			recog.base.set_state(1261);
			recog.base.match_token(PROPERTIES,&mut recog.err_handler)?;

			recog.base.set_state(1262);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			{
			/*InvokeRule string*/
			recog.base.set_state(1263);
			recog.string()?;

			recog.base.set_state(1264);
			recog.base.match_token(EQ,&mut recog.err_handler)?;

			/*InvokeRule string*/
			recog.base.set_state(1265);
			recog.string()?;

			}
			recog.base.set_state(1274);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(127,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1267);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1268);
					recog.string()?;

					recog.base.set_state(1269);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1270);
					recog.string()?;

					}
					} 
				}
				recog.base.set_state(1276);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(127,&mut recog.base)?;
			}
			recog.base.set_state(1278);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1277);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,TablePropertiesContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			recog.base.set_state(1280);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionPropertySpec ----------------
#[derive(Debug)]
pub enum FunctionPropertySpecContextAll<'input>{
	FunctionRetryTimeoutContext(FunctionRetryTimeoutContext<'input>),
	FunctionMaxBatchRowsContext(FunctionMaxBatchRowsContext<'input>),
	FunctionSagemakerContext(FunctionSagemakerContext<'input>),
	FunctionLambdaContext(FunctionLambdaContext<'input>),
	FunctionLanguageContext(FunctionLanguageContext<'input>),
	FunctionMaxBatchSizeContext(FunctionMaxBatchSizeContext<'input>),
	FunctionBodyContext(FunctionBodyContext<'input>),
	FunctionVolatilityContext(FunctionVolatilityContext<'input>),
	FunctionIAMRoleContext(FunctionIAMRoleContext<'input>),
Error(FunctionPropertySpecContext<'input>)
}
antlr_rust::tid!{FunctionPropertySpecContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for FunctionPropertySpecContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for FunctionPropertySpecContextAll<'input>{}

impl<'input> Deref for FunctionPropertySpecContextAll<'input>{
	type Target = dyn FunctionPropertySpecContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use FunctionPropertySpecContextAll::*;
		match self{
			FunctionRetryTimeoutContext(inner) => inner,
			FunctionMaxBatchRowsContext(inner) => inner,
			FunctionSagemakerContext(inner) => inner,
			FunctionLambdaContext(inner) => inner,
			FunctionLanguageContext(inner) => inner,
			FunctionMaxBatchSizeContext(inner) => inner,
			FunctionBodyContext(inner) => inner,
			FunctionVolatilityContext(inner) => inner,
			FunctionIAMRoleContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionPropertySpecContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionPropertySpecContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type FunctionPropertySpecContext<'input> = BaseParserRuleContext<'input,FunctionPropertySpecContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionPropertySpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FunctionPropertySpecContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionPropertySpecContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionPropertySpecContext<'input>{
}

impl<'input> CustomRuleContext<'input> for FunctionPropertySpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}
antlr_rust::tid!{FunctionPropertySpecContextExt<'a>}

impl<'input> FunctionPropertySpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionPropertySpecContextAll<'input>> {
		Rc::new(
		FunctionPropertySpecContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionPropertySpecContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait FunctionPropertySpecContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FunctionPropertySpecContextExt<'input>>{


}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionPropertySpecContext<'input>{}

pub type FunctionRetryTimeoutContext<'input> = BaseParserRuleContext<'input,FunctionRetryTimeoutContextExt<'input>>;

pub trait FunctionRetryTimeoutContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RETRY_TIMEOUT
	/// Returns `None` if there is no child corresponding to token RETRY_TIMEOUT
	fn RETRY_TIMEOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RETRY_TIMEOUT, 0)
	}
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FunctionRetryTimeoutContextAttrs<'input> for FunctionRetryTimeoutContext<'input>{}

pub struct FunctionRetryTimeoutContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionRetryTimeoutContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionRetryTimeoutContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionRetryTimeoutContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionRetryTimeout(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionRetryTimeout(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionRetryTimeoutContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionRetryTimeout(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionRetryTimeoutContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionRetryTimeoutContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionRetryTimeoutContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionRetryTimeoutContext<'input> {}

impl<'input> FunctionRetryTimeoutContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionRetryTimeoutContext(
				BaseParserRuleContext::copy_from(ctx,FunctionRetryTimeoutContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionMaxBatchRowsContext<'input> = BaseParserRuleContext<'input,FunctionMaxBatchRowsContextExt<'input>>;

pub trait FunctionMaxBatchRowsContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MAX_BATCH_ROWS
	/// Returns `None` if there is no child corresponding to token MAX_BATCH_ROWS
	fn MAX_BATCH_ROWS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MAX_BATCH_ROWS, 0)
	}
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FunctionMaxBatchRowsContextAttrs<'input> for FunctionMaxBatchRowsContext<'input>{}

pub struct FunctionMaxBatchRowsContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionMaxBatchRowsContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionMaxBatchRowsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionMaxBatchRowsContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionMaxBatchRows(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionMaxBatchRows(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionMaxBatchRowsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionMaxBatchRows(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionMaxBatchRowsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionMaxBatchRowsContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionMaxBatchRowsContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionMaxBatchRowsContext<'input> {}

impl<'input> FunctionMaxBatchRowsContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionMaxBatchRowsContext(
				BaseParserRuleContext::copy_from(ctx,FunctionMaxBatchRowsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionSagemakerContext<'input> = BaseParserRuleContext<'input,FunctionSagemakerContextExt<'input>>;

pub trait FunctionSagemakerContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SAGEMAKER
	/// Returns `None` if there is no child corresponding to token SAGEMAKER
	fn SAGEMAKER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SAGEMAKER, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FunctionSagemakerContextAttrs<'input> for FunctionSagemakerContext<'input>{}

pub struct FunctionSagemakerContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionSagemakerContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionSagemakerContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionSagemakerContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionSagemaker(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionSagemaker(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionSagemakerContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionSagemaker(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionSagemakerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionSagemakerContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionSagemakerContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionSagemakerContext<'input> {}

impl<'input> FunctionSagemakerContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionSagemakerContext(
				BaseParserRuleContext::copy_from(ctx,FunctionSagemakerContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionLambdaContext<'input> = BaseParserRuleContext<'input,FunctionLambdaContextExt<'input>>;

pub trait FunctionLambdaContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LAMBDA
	/// Returns `None` if there is no child corresponding to token LAMBDA
	fn LAMBDA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LAMBDA, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FunctionLambdaContextAttrs<'input> for FunctionLambdaContext<'input>{}

pub struct FunctionLambdaContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionLambdaContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionLambdaContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionLambdaContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionLambda(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionLambda(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionLambdaContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionLambda(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionLambdaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionLambdaContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionLambdaContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionLambdaContext<'input> {}

impl<'input> FunctionLambdaContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionLambdaContext(
				BaseParserRuleContext::copy_from(ctx,FunctionLambdaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionLanguageContext<'input> = BaseParserRuleContext<'input,FunctionLanguageContextExt<'input>>;

pub trait FunctionLanguageContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LANGUAGE
	/// Returns `None` if there is no child corresponding to token LANGUAGE
	fn LANGUAGE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LANGUAGE, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FunctionLanguageContextAttrs<'input> for FunctionLanguageContext<'input>{}

pub struct FunctionLanguageContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionLanguageContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionLanguageContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionLanguageContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionLanguage(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionLanguage(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionLanguageContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionLanguage(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionLanguageContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionLanguageContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionLanguageContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionLanguageContext<'input> {}

impl<'input> FunctionLanguageContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionLanguageContext(
				BaseParserRuleContext::copy_from(ctx,FunctionLanguageContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionMaxBatchSizeContext<'input> = BaseParserRuleContext<'input,FunctionMaxBatchSizeContextExt<'input>>;

pub trait FunctionMaxBatchSizeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MAX_BATCH_SIZE
	/// Returns `None` if there is no child corresponding to token MAX_BATCH_SIZE
	fn MAX_BATCH_SIZE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MAX_BATCH_SIZE, 0)
	}
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token KB
	/// Returns `None` if there is no child corresponding to token KB
	fn KB(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(KB, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MB
	/// Returns `None` if there is no child corresponding to token MB
	fn MB(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MB, 0)
	}
}

impl<'input> FunctionMaxBatchSizeContextAttrs<'input> for FunctionMaxBatchSizeContext<'input>{}

pub struct FunctionMaxBatchSizeContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionMaxBatchSizeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionMaxBatchSizeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionMaxBatchSizeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionMaxBatchSize(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionMaxBatchSize(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionMaxBatchSizeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionMaxBatchSize(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionMaxBatchSizeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionMaxBatchSizeContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionMaxBatchSizeContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionMaxBatchSizeContext<'input> {}

impl<'input> FunctionMaxBatchSizeContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionMaxBatchSizeContext(
				BaseParserRuleContext::copy_from(ctx,FunctionMaxBatchSizeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionBodyContext<'input> = BaseParserRuleContext<'input,FunctionBodyContextExt<'input>>;

pub trait FunctionBodyContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DOLLAR_QUOTED_STRING
	/// Returns `None` if there is no child corresponding to token DOLLAR_QUOTED_STRING
	fn DOLLAR_QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR_QUOTED_STRING, 0)
	}
}

impl<'input> FunctionBodyContextAttrs<'input> for FunctionBodyContext<'input>{}

pub struct FunctionBodyContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionBodyContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionBodyContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionBodyContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionBody(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionBody(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionBodyContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionBodyContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionBodyContext<'input> {}

impl<'input> FunctionBodyContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionBodyContext(
				BaseParserRuleContext::copy_from(ctx,FunctionBodyContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionVolatilityContext<'input> = BaseParserRuleContext<'input,FunctionVolatilityContextExt<'input>>;

pub trait FunctionVolatilityContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IMMUTABLE
	/// Returns `None` if there is no child corresponding to token IMMUTABLE
	fn IMMUTABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IMMUTABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token STABLE
	/// Returns `None` if there is no child corresponding to token STABLE
	fn STABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(STABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VOLATILE
	/// Returns `None` if there is no child corresponding to token VOLATILE
	fn VOLATILE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VOLATILE, 0)
	}
}

impl<'input> FunctionVolatilityContextAttrs<'input> for FunctionVolatilityContext<'input>{}

pub struct FunctionVolatilityContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionVolatilityContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionVolatilityContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionVolatilityContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionVolatility(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionVolatility(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionVolatilityContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionVolatility(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionVolatilityContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionVolatilityContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionVolatilityContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionVolatilityContext<'input> {}

impl<'input> FunctionVolatilityContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionVolatilityContext(
				BaseParserRuleContext::copy_from(ctx,FunctionVolatilityContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionIAMRoleContext<'input> = BaseParserRuleContext<'input,FunctionIAMRoleContextExt<'input>>;

pub trait FunctionIAMRoleContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IAM_ROLE
	/// Returns `None` if there is no child corresponding to token IAM_ROLE
	fn IAM_ROLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IAM_ROLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DEFAULT
	/// Returns `None` if there is no child corresponding to token DEFAULT
	fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DEFAULT, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FunctionIAMRoleContextAttrs<'input> for FunctionIAMRoleContext<'input>{}

pub struct FunctionIAMRoleContextExt<'input>{
	base:FunctionPropertySpecContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionIAMRoleContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionIAMRoleContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionIAMRoleContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionIAMRole(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionIAMRole(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionIAMRoleContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionIAMRole(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionIAMRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionPropertySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionPropertySpec }
}

impl<'input> Borrow<FunctionPropertySpecContextExt<'input>> for FunctionIAMRoleContext<'input>{
	fn borrow(&self) -> &FunctionPropertySpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FunctionPropertySpecContextExt<'input>> for FunctionIAMRoleContext<'input>{
	fn borrow_mut(&mut self) -> &mut FunctionPropertySpecContextExt<'input> { &mut self.base }
}

impl<'input> FunctionPropertySpecContextAttrs<'input> for FunctionIAMRoleContext<'input> {}

impl<'input> FunctionIAMRoleContextExt<'input>{
	fn new(ctx: &dyn FunctionPropertySpecContextAttrs<'input>) -> Rc<FunctionPropertySpecContextAll<'input>>  {
		Rc::new(
			FunctionPropertySpecContextAll::FunctionIAMRoleContext(
				BaseParserRuleContext::copy_from(ctx,FunctionIAMRoleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionPropertySpec(&mut self,)
	-> Result<Rc<FunctionPropertySpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionPropertySpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 34, RULE_functionPropertySpec);
        let mut _localctx: Rc<FunctionPropertySpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1306);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LANGUAGE 
				=> {
					let tmp = FunctionLanguageContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1282);
					recog.base.match_token(LANGUAGE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1283);
					recog.identifier()?;

					}
				}

			 IMMUTABLE 
				=> {
					let tmp = FunctionVolatilityContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1284);
					recog.base.match_token(IMMUTABLE,&mut recog.err_handler)?;

					}
				}

			 STABLE 
				=> {
					let tmp = FunctionVolatilityContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(1285);
					recog.base.match_token(STABLE,&mut recog.err_handler)?;

					}
				}

			 VOLATILE 
				=> {
					let tmp = FunctionVolatilityContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(1286);
					recog.base.match_token(VOLATILE,&mut recog.err_handler)?;

					}
				}

			 IAM_ROLE 
				=> {
					let tmp = FunctionIAMRoleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(1287);
					recog.base.match_token(IAM_ROLE,&mut recog.err_handler)?;

					recog.base.set_state(1290);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 DEFAULT 
						=> {
							{
							recog.base.set_state(1288);
							recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

							}
						}

					 STRING | UNICODE_STRING | DOLLAR_QUOTED_STRING 
						=> {
							{
							/*InvokeRule string*/
							recog.base.set_state(1289);
							recog.string()?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

			 LAMBDA 
				=> {
					let tmp = FunctionLambdaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(1292);
					recog.base.match_token(LAMBDA,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1293);
					recog.string()?;

					}
				}

			 RETRY_TIMEOUT 
				=> {
					let tmp = FunctionRetryTimeoutContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(1294);
					recog.base.match_token(RETRY_TIMEOUT,&mut recog.err_handler)?;

					/*InvokeRule number*/
					recog.base.set_state(1295);
					recog.number()?;

					}
				}

			 MAX_BATCH_ROWS 
				=> {
					let tmp = FunctionMaxBatchRowsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(1296);
					recog.base.match_token(MAX_BATCH_ROWS,&mut recog.err_handler)?;

					/*InvokeRule number*/
					recog.base.set_state(1297);
					recog.number()?;

					}
				}

			 MAX_BATCH_SIZE 
				=> {
					let tmp = FunctionMaxBatchSizeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(1298);
					recog.base.match_token(MAX_BATCH_SIZE,&mut recog.err_handler)?;

					/*InvokeRule number*/
					recog.base.set_state(1299);
					recog.number()?;

					recog.base.set_state(1300);
					_la = recog.base.input.la(1);
					if { !(_la==KB || _la==MB) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

			 SAGEMAKER 
				=> {
					let tmp = FunctionSagemakerContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(1302);
					recog.base.match_token(SAGEMAKER,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1303);
					recog.string()?;

					}
				}

			 AS 
				=> {
					let tmp = FunctionBodyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(1304);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(1305);
					recog.base.match_token(DOLLAR_QUOTED_STRING,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- query ----------------
pub type QueryContextAll<'input> = QueryContext<'input>;


pub type QueryContext<'input> = BaseParserRuleContext<'input,QueryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QueryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_query(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_query(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_query(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_query }
	//fn type_rule_index() -> usize where Self: Sized { RULE_query }
}
antlr_rust::tid!{QueryContextExt<'a>}

impl<'input> QueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QueryContextExt<'input>>{

fn queryNoWith(&self) -> Option<Rc<QueryNoWithContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn with(&self) -> Option<Rc<WithContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryContextAttrs<'input> for QueryContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn query(&mut self,)
	-> Result<Rc<QueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 36, RULE_query);
        let mut _localctx: Rc<QueryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1309);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WITH {
				{
				/*InvokeRule with*/
				recog.base.set_state(1308);
				recog.with()?;

				}
			}

			/*InvokeRule queryNoWith*/
			recog.base.set_state(1311);
			recog.queryNoWith()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- with ----------------
pub type WithContextAll<'input> = WithContext<'input>;


pub type WithContext<'input> = BaseParserRuleContext<'input,WithContextExt<'input>>;

#[derive(Clone)]
pub struct WithContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for WithContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for WithContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_with(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_with(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for WithContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_with(self);
	}
}

impl<'input> CustomRuleContext<'input> for WithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_with }
	//fn type_rule_index() -> usize where Self: Sized { RULE_with }
}
antlr_rust::tid!{WithContextExt<'a>}

impl<'input> WithContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WithContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WithContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WithContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<WithContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn namedQuery_all(&self) ->  Vec<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedQuery(&self, i: usize) -> Option<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RECURSIVE
/// Returns `None` if there is no child corresponding to token RECURSIVE
fn RECURSIVE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RECURSIVE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WithContextAttrs<'input> for WithContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn with(&mut self,)
	-> Result<Rc<WithContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WithContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 38, RULE_with);
        let mut _localctx: Rc<WithContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1313);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(1315);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(132,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1314);
					recog.base.match_token(RECURSIVE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule namedQuery*/
			recog.base.set_state(1317);
			recog.namedQuery()?;

			recog.base.set_state(1322);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1318);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedQuery*/
				recog.base.set_state(1319);
				recog.namedQuery()?;

				}
				}
				recog.base.set_state(1324);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableElement ----------------
pub type TableElementContextAll<'input> = TableElementContext<'input>;


pub type TableElementContext<'input> = BaseParserRuleContext<'input,TableElementContextExt<'input>>;

#[derive(Clone)]
pub struct TableElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableElementContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableElementContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableElement(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_tableElement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableElementContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableElement(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableElement }
}
antlr_rust::tid!{TableElementContextExt<'a>}

impl<'input> TableElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableElementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableElementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableElementContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableElementContextExt<'input>>{

fn tableConstraint(&self) -> Option<Rc<TableConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn likeClause(&self) -> Option<Rc<LikeClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnDefinition(&self) -> Option<Rc<ColumnDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableElementContextAttrs<'input> for TableElementContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableElement(&mut self,)
	-> Result<Rc<TableElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 40, RULE_tableElement);
        let mut _localctx: Rc<TableElementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1328);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(134,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tableConstraint*/
					recog.base.set_state(1325);
					recog.tableConstraint()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule likeClause*/
					recog.base.set_state(1326);
					recog.likeClause()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule columnDefinition*/
					recog.base.set_state(1327);
					recog.columnDefinition()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableConstraint ----------------
pub type TableConstraintContextAll<'input> = TableConstraintContext<'input>;


pub type TableConstraintContext<'input> = BaseParserRuleContext<'input,TableConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct TableConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableConstraint(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_tableConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableConstraint }
}
antlr_rust::tid!{TableConstraintContextExt<'a>}

impl<'input> TableConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableConstraintContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token UNIQUE
/// Returns `None` if there is no child corresponding to token UNIQUE
fn UNIQUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNIQUE, 0)
}
fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PRIMARY
/// Returns `None` if there is no child corresponding to token PRIMARY
fn PRIMARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRIMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token FOREIGN
/// Returns `None` if there is no child corresponding to token FOREIGN
fn FOREIGN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FOREIGN, 0)
}
/// Retrieves first TerminalNode corresponding to token REFERENCES
/// Returns `None` if there is no child corresponding to token REFERENCES
fn REFERENCES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(REFERENCES, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CONSTRAINT
/// Returns `None` if there is no child corresponding to token CONSTRAINT
fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> TableConstraintContextAttrs<'input> for TableConstraintContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableConstraint(&mut self,)
	-> Result<Rc<TableConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 42, RULE_tableConstraint);
        let mut _localctx: Rc<TableConstraintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1332);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==CONSTRAINT {
				{
				recog.base.set_state(1330);
				recog.base.match_token(CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule identifier*/
				recog.base.set_state(1331);
				recog.identifier()?;

				}
			}

			recog.base.set_state(1352);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 UNIQUE 
				=> {
					{
					recog.base.set_state(1334);
					recog.base.match_token(UNIQUE,&mut recog.err_handler)?;

					/*InvokeRule columnAliases*/
					recog.base.set_state(1335);
					recog.columnAliases()?;

					}
				}

			 PRIMARY 
				=> {
					{
					recog.base.set_state(1336);
					recog.base.match_token(PRIMARY,&mut recog.err_handler)?;

					recog.base.set_state(1337);
					recog.base.match_token(KEY,&mut recog.err_handler)?;

					recog.base.set_state(1339);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)))) != 0) || ((((_la - 440)) & !0x3f) == 0 && ((1usize << (_la - 440)) & ((1usize << (IDENTIFIER - 440)) | (1usize << (DIGIT_IDENTIFIER - 440)) | (1usize << (QUOTED_IDENTIFIER - 440)))) != 0) {
						{
						/*InvokeRule columnAliases*/
						recog.base.set_state(1338);
						recog.columnAliases()?;

						}
					}

					}
				}

			 FOREIGN 
				=> {
					{
					recog.base.set_state(1341);
					recog.base.match_token(FOREIGN,&mut recog.err_handler)?;

					recog.base.set_state(1342);
					recog.base.match_token(KEY,&mut recog.err_handler)?;

					recog.base.set_state(1344);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(137,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(1343);
							recog.columnAliases()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1346);
					recog.base.match_token(REFERENCES,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1347);
					recog.qualifiedName()?;

					{
					recog.base.set_state(1348);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1349);
					recog.identifier()?;

					recog.base.set_state(1350);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnDefinition ----------------
pub type ColumnDefinitionContextAll<'input> = ColumnDefinitionContext<'input>;


pub type ColumnDefinitionContext<'input> = BaseParserRuleContext<'input,ColumnDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnDefinitionContextExt<'input>{
	pub comment: Option<Rc<StringContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnDefinition }
}
antlr_rust::tid!{ColumnDefinitionContextExt<'a>}

impl<'input> ColumnDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnDefinitionContextExt{
				comment: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnDefinitionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnDefinitionContextExt<'input>>{

fn fieldDefinition(&self) -> Option<Rc<FieldDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnAttributes_all(&self) ->  Vec<Rc<ColumnAttributesContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnAttributes(&self, i: usize) -> Option<Rc<ColumnAttributesContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn columnConstraints_all(&self) ->  Vec<Rc<ColumnConstraintsContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnConstraints(&self, i: usize) -> Option<Rc<ColumnConstraintsContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnDefinitionContextAttrs<'input> for ColumnDefinitionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnDefinition(&mut self,)
	-> Result<Rc<ColumnDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 44, RULE_columnDefinition);
        let mut _localctx: Rc<ColumnDefinitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule fieldDefinition*/
			recog.base.set_state(1354);
			recog.fieldDefinition()?;

			recog.base.set_state(1359);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 50)) & !0x3f) == 0 && ((1usize << (_la - 50)) & ((1usize << (COLLATE - 50)) | (1usize << (CONSTRAINT - 50)) | (1usize << (DEFAULT - 50)))) != 0) || _la==DISTKEY || _la==ENCODE || _la==GENERATED || _la==IDENTITY || _la==NOT || _la==NULL || _la==PRIMARY || _la==REFERENCES || _la==SORTKEY || _la==UNIQUE {
				{
				recog.base.set_state(1357);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 COLLATE | CONSTRAINT | DEFAULT | DISTKEY | ENCODE | GENERATED | IDENTITY |
				 SORTKEY 
					=> {
						{
						/*InvokeRule columnAttributes*/
						recog.base.set_state(1355);
						recog.columnAttributes()?;

						}
					}

				 NOT | NULL | PRIMARY | REFERENCES | UNIQUE 
					=> {
						{
						/*InvokeRule columnConstraints*/
						recog.base.set_state(1356);
						recog.columnConstraints()?;

						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
				recog.base.set_state(1361);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1364);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMENT {
				{
				recog.base.set_state(1362);
				recog.base.match_token(COMMENT,&mut recog.err_handler)?;

				/*InvokeRule string*/
				recog.base.set_state(1363);
				let tmp = recog.string()?;
				 cast_mut::<_,ColumnDefinitionContext >(&mut _localctx).comment = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fieldDefinition ----------------
pub type FieldDefinitionContextAll<'input> = FieldDefinitionContext<'input>;


pub type FieldDefinitionContext<'input> = BaseParserRuleContext<'input,FieldDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct FieldDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FieldDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FieldDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fieldDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_fieldDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FieldDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_fieldDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for FieldDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fieldDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fieldDefinition }
}
antlr_rust::tid!{FieldDefinitionContextExt<'a>}

impl<'input> FieldDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FieldDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FieldDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FieldDefinitionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FieldDefinitionContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnSchemaWithMetadata(&self) -> Option<Rc<ColumnSchemaWithMetadataContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictNonReserved(&self) -> Option<Rc<StrictNonReservedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FieldDefinitionContextAttrs<'input> for FieldDefinitionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fieldDefinition(&mut self,)
	-> Result<Rc<FieldDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FieldDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 46, RULE_fieldDefinition);
        let mut _localctx: Rc<FieldDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1372);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
			 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
			 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
			 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEVEL | LIBRARY | LIKE | LIMIT |
			 LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK | LOGICAL |
			 M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE | MATERIALIZED |
			 MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES | MERGE | MIN |
			 MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC | NFD | NFKC |
			 NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS | OBJECT | OF |
			 OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR | ORDER | ORDINALITY |
			 OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW | PARTITION | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENTILE_CONT |
			 PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG | PIVOT | POSITION |
			 PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIMARY | PRIVILEGES |
			 PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE | READ | RECURSIVE | REFERENCES |
			 REFRESH | RENAME | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROLLUP | ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND |
			 SECONDS | SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE |
			 SERDEPROPERTIES | SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR |
			 SOME | SORTKEY | SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET |
			 SUBSTRING | SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY |
			 TERMINATED | TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO |
			 TRAILING | TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE |
			 TYPE | UESCAPE | UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE |
			 UNKNOWN | UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER |
			 UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING |
			 VARIADIC | VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW |
			 WITH | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
			 ZSTD | LBRACKET | IDENTIFIER | DIGIT_IDENTIFIER | DOLLAR_HASH_IDENTIFIER |
			 QUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule columnName*/
					recog.base.set_state(1366);
					recog.columnName()?;

					/*InvokeRule columnSchemaWithMetadata*/
					recog.base.set_state(1367);
					recog.columnSchemaWithMetadata()?;

					}
				}

			 CONVERT | CROSS | FULL | INNER | LEFT | MINUS_KW | NATURAL | NOT | OUTER |
			 RIGHT | USING | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule strictNonReserved*/
					recog.base.set_state(1369);
					recog.strictNonReserved()?;

					/*InvokeRule columnSchemaWithMetadata*/
					recog.base.set_state(1370);
					recog.columnSchemaWithMetadata()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnName ----------------
pub type ColumnNameContextAll<'input> = ColumnNameContext<'input>;


pub type ColumnNameContext<'input> = BaseParserRuleContext<'input,ColumnNameContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnNameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnNameContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnName(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnName(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnName }
}
antlr_rust::tid!{ColumnNameContextExt<'a>}

impl<'input> ColumnNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnNameContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DOLLAR_HASH_IDENTIFIER
/// Returns `None` if there is no child corresponding to token DOLLAR_HASH_IDENTIFIER
fn DOLLAR_HASH_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DOLLAR_HASH_IDENTIFIER, 0)
}

}

impl<'input> ColumnNameContextAttrs<'input> for ColumnNameContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnName(&mut self,)
	-> Result<Rc<ColumnNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 48, RULE_columnName);
        let mut _localctx: Rc<ColumnNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1376);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
			 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
			 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
			 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEVEL | LIBRARY | LIKE | LIMIT |
			 LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK | LOGICAL |
			 M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE | MATERIALIZED |
			 MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES | MERGE | MIN |
			 MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC | NFD | NFKC |
			 NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS | OBJECT | OF |
			 OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR | ORDER | ORDINALITY |
			 OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW | PARTITION | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENTILE_CONT |
			 PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG | PIVOT | POSITION |
			 PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIMARY | PRIVILEGES |
			 PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE | READ | RECURSIVE | REFERENCES |
			 REFRESH | RENAME | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROLLUP | ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND |
			 SECONDS | SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE |
			 SERDEPROPERTIES | SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR |
			 SOME | SORTKEY | SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET |
			 SUBSTRING | SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY |
			 TERMINATED | TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO |
			 TRAILING | TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE |
			 TYPE | UESCAPE | UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE |
			 UNKNOWN | UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER |
			 UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING |
			 VARIADIC | VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW |
			 WITH | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
			 ZSTD | LBRACKET | IDENTIFIER | DIGIT_IDENTIFIER | QUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1374);
					recog.identifier()?;

					}
				}

			 DOLLAR_HASH_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1375);
					recog.base.match_token(DOLLAR_HASH_IDENTIFIER,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameComponent ----------------
pub type ColumnNameComponentContextAll<'input> = ColumnNameComponentContext<'input>;


pub type ColumnNameComponentContext<'input> = BaseParserRuleContext<'input,ColumnNameComponentContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameComponentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnNameComponentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnNameComponentContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameComponent(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnNameComponent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnNameComponentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnNameComponent(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnNameComponentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameComponent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameComponent }
}
antlr_rust::tid!{ColumnNameComponentContextExt<'a>}

impl<'input> ColumnNameComponentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameComponentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameComponentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameComponentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnNameComponentContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictNonReserved(&self) -> Option<Rc<StrictNonReservedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameComponentContextAttrs<'input> for ColumnNameComponentContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameComponent(&mut self,)
	-> Result<Rc<ColumnNameComponentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameComponentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 50, RULE_columnNameComponent);
        let mut _localctx: Rc<ColumnNameComponentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1380);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
			 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
			 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
			 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEVEL | LIBRARY | LIKE | LIMIT |
			 LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK | LOGICAL |
			 M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE | MATERIALIZED |
			 MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES | MERGE | MIN |
			 MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC | NFD | NFKC |
			 NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS | OBJECT | OF |
			 OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR | ORDER | ORDINALITY |
			 OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW | PARTITION | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENTILE_CONT |
			 PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG | PIVOT | POSITION |
			 PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIMARY | PRIVILEGES |
			 PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE | READ | RECURSIVE | REFERENCES |
			 REFRESH | RENAME | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROLLUP | ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND |
			 SECONDS | SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE |
			 SERDEPROPERTIES | SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR |
			 SOME | SORTKEY | SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET |
			 SUBSTRING | SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY |
			 TERMINATED | TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO |
			 TRAILING | TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE |
			 TYPE | UESCAPE | UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE |
			 UNKNOWN | UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER |
			 UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING |
			 VARIADIC | VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW |
			 WITH | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
			 ZSTD | LBRACKET | IDENTIFIER | DIGIT_IDENTIFIER | DOLLAR_HASH_IDENTIFIER |
			 QUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule columnName*/
					recog.base.set_state(1378);
					recog.columnName()?;

					}
				}

			 CONVERT | CROSS | FULL | INNER | LEFT | MINUS_KW | NATURAL | NOT | OUTER |
			 RIGHT | USING | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule strictNonReserved*/
					recog.base.set_state(1379);
					recog.strictNonReserved()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnSchemaWithMetadata ----------------
pub type ColumnSchemaWithMetadataContextAll<'input> = ColumnSchemaWithMetadataContext<'input>;


pub type ColumnSchemaWithMetadataContext<'input> = BaseParserRuleContext<'input,ColumnSchemaWithMetadataContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnSchemaWithMetadataContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnSchemaWithMetadataContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnSchemaWithMetadataContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnSchemaWithMetadata(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnSchemaWithMetadata(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnSchemaWithMetadataContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnSchemaWithMetadata(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaWithMetadataContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchemaWithMetadata }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchemaWithMetadata }
}
antlr_rust::tid!{ColumnSchemaWithMetadataContextExt<'a>}

impl<'input> ColumnSchemaWithMetadataContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnSchemaWithMetadataContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnSchemaWithMetadataContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnSchemaWithMetadataContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnSchemaWithMetadataContextExt<'input>>{

fn columnSchema(&self) -> Option<Rc<ColumnSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}

}

impl<'input> ColumnSchemaWithMetadataContextAttrs<'input> for ColumnSchemaWithMetadataContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnSchemaWithMetadata(&mut self,)
	-> Result<Rc<ColumnSchemaWithMetadataContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnSchemaWithMetadataContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 52, RULE_columnSchemaWithMetadata);
        let mut _localctx: Rc<ColumnSchemaWithMetadataContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnSchema*/
			recog.base.set_state(1382);
			recog.columnSchema()?;

			recog.base.set_state(1387);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(146,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1384);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(1383);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1386);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnOptionList ----------------
pub type ColumnOptionListContextAll<'input> = ColumnOptionListContext<'input>;


pub type ColumnOptionListContext<'input> = BaseParserRuleContext<'input,ColumnOptionListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnOptionListContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnOptionListContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnOptionListContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnOptionList(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnOptionList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnOptionListContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnOptionList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnOptionListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnOptionList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnOptionList }
}
antlr_rust::tid!{ColumnOptionListContextExt<'a>}

impl<'input> ColumnOptionListContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnOptionListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnOptionListContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnOptionListContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnOptionListContextExt<'input>>{

fn columnOption_all(&self) ->  Vec<Rc<ColumnOptionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnOption(&self, i: usize) -> Option<Rc<ColumnOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnOptionListContextAttrs<'input> for ColumnOptionListContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnOptionList(&mut self,)
	-> Result<Rc<ColumnOptionListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnOptionListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 54, RULE_columnOptionList);
        let mut _localctx: Rc<ColumnOptionListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnOption*/
			recog.base.set_state(1389);
			recog.columnOption()?;

			recog.base.set_state(1394);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(147,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1390);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule columnOption*/
					recog.base.set_state(1391);
					recog.columnOption()?;

					}
					} 
				}
				recog.base.set_state(1396);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(147,&mut recog.base)?;
			}
			recog.base.set_state(1398);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1397);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnOptionListContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnOption ----------------
pub type ColumnOptionContextAll<'input> = ColumnOptionContext<'input>;


pub type ColumnOptionContext<'input> = BaseParserRuleContext<'input,ColumnOptionContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnOptionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnOptionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnOption(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnOptionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnOption(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnOption }
}
antlr_rust::tid!{ColumnOptionContextExt<'a>}

impl<'input> ColumnOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnOptionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnOptionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnOptionContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnOptionContextAttrs<'input> for ColumnOptionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnOption(&mut self,)
	-> Result<Rc<ColumnOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 56, RULE_columnOption);
        let mut _localctx: Rc<ColumnOptionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1400);
			recog.identifier()?;

			recog.base.set_state(1401);
			recog.base.match_token(EQ,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1402);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnSchema ----------------
#[derive(Debug)]
pub enum ColumnSchemaContextAll<'input>{
	ColumnSchemaSimpleTypeContext(ColumnSchemaSimpleTypeContext<'input>),
Error(ColumnSchemaContext<'input>)
}
antlr_rust::tid!{ColumnSchemaContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ColumnSchemaContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for ColumnSchemaContextAll<'input>{}

impl<'input> Deref for ColumnSchemaContextAll<'input>{
	type Target = dyn ColumnSchemaContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ColumnSchemaContextAll::*;
		match self{
			ColumnSchemaSimpleTypeContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnSchemaContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnSchemaContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ColumnSchemaContext<'input> = BaseParserRuleContext<'input,ColumnSchemaContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnSchemaContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnSchemaContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnSchemaContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchema }
}
antlr_rust::tid!{ColumnSchemaContextExt<'a>}

impl<'input> ColumnSchemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnSchemaContextAll<'input>> {
		Rc::new(
		ColumnSchemaContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnSchemaContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ColumnSchemaContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnSchemaContextExt<'input>>{


}

impl<'input> ColumnSchemaContextAttrs<'input> for ColumnSchemaContext<'input>{}

pub type ColumnSchemaSimpleTypeContext<'input> = BaseParserRuleContext<'input,ColumnSchemaSimpleTypeContextExt<'input>>;

pub trait ColumnSchemaSimpleTypeContextAttrs<'input>: RedshiftParserContext<'input>{
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ColumnSchemaSimpleTypeContextAttrs<'input> for ColumnSchemaSimpleTypeContext<'input>{}

pub struct ColumnSchemaSimpleTypeContextExt<'input>{
	base:ColumnSchemaContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnSchemaSimpleTypeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ColumnSchemaSimpleTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnSchemaSimpleTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnSchemaSimpleType(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_columnSchemaSimpleType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnSchemaSimpleTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnSchemaSimpleType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaSimpleTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchema }
}

impl<'input> Borrow<ColumnSchemaContextExt<'input>> for ColumnSchemaSimpleTypeContext<'input>{
	fn borrow(&self) -> &ColumnSchemaContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnSchemaContextExt<'input>> for ColumnSchemaSimpleTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnSchemaContextExt<'input> { &mut self.base }
}

impl<'input> ColumnSchemaContextAttrs<'input> for ColumnSchemaSimpleTypeContext<'input> {}

impl<'input> ColumnSchemaSimpleTypeContextExt<'input>{
	fn new(ctx: &dyn ColumnSchemaContextAttrs<'input>) -> Rc<ColumnSchemaContextAll<'input>>  {
		Rc::new(
			ColumnSchemaContextAll::ColumnSchemaSimpleTypeContext(
				BaseParserRuleContext::copy_from(ctx,ColumnSchemaSimpleTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnSchema(&mut self,)
	-> Result<Rc<ColumnSchemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnSchemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 58, RULE_columnSchema);
        let mut _localctx: Rc<ColumnSchemaContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = ColumnSchemaSimpleTypeContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule type_*/
			recog.base.set_state(1404);
			recog.type_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnAttributes ----------------
pub type ColumnAttributesContextAll<'input> = ColumnAttributesContext<'input>;


pub type ColumnAttributesContext<'input> = BaseParserRuleContext<'input,ColumnAttributesContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnAttributesContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnAttributesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnAttributesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnAttributes(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnAttributes(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnAttributesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnAttributes(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnAttributesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnAttributes }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnAttributes }
}
antlr_rust::tid!{ColumnAttributesContextExt<'a>}

impl<'input> ColumnAttributesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnAttributesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnAttributesContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnAttributesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnAttributesContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token DISTKEY in current rule
fn DISTKEY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DISTKEY, starting from 0.
/// Returns `None` if number of children corresponding to token DISTKEY is less or equal than `i`.
fn DISTKEY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DISTKEY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token SORTKEY in current rule
fn SORTKEY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SORTKEY, starting from 0.
/// Returns `None` if number of children corresponding to token SORTKEY is less or equal than `i`.
fn SORTKEY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SORTKEY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token CONSTRAINT in current rule
fn CONSTRAINT_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token CONSTRAINT, starting from 0.
/// Returns `None` if number of children corresponding to token CONSTRAINT is less or equal than `i`.
fn CONSTRAINT(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, i)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DEFAULT in current rule
fn DEFAULT_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DEFAULT, starting from 0.
/// Returns `None` if number of children corresponding to token DEFAULT is less or equal than `i`.
fn DEFAULT(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token IDENTITY in current rule
fn IDENTITY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token IDENTITY, starting from 0.
/// Returns `None` if number of children corresponding to token IDENTITY is less or equal than `i`.
fn IDENTITY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IDENTITY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token GENERATED in current rule
fn GENERATED_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token GENERATED, starting from 0.
/// Returns `None` if number of children corresponding to token GENERATED is less or equal than `i`.
fn GENERATED(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GENERATED, i)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token AS in current rule
fn AS_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token AS, starting from 0.
/// Returns `None` if number of children corresponding to token AS is less or equal than `i`.
fn AS(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, i)
}
/// Retrieves all `TerminalNode`s corresponding to token ENCODE in current rule
fn ENCODE_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token ENCODE, starting from 0.
/// Returns `None` if number of children corresponding to token ENCODE is less or equal than `i`.
fn ENCODE(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ENCODE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token COLLATE in current rule
fn COLLATE_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COLLATE, starting from 0.
/// Returns `None` if number of children corresponding to token COLLATE is less or equal than `i`.
fn COLLATE(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COLLATE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token CASE_SENSITIVE in current rule
fn CASE_SENSITIVE_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token CASE_SENSITIVE, starting from 0.
/// Returns `None` if number of children corresponding to token CASE_SENSITIVE is less or equal than `i`.
fn CASE_SENSITIVE(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CASE_SENSITIVE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token CASE_INSENSITIVE in current rule
fn CASE_INSENSITIVE_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token CASE_INSENSITIVE, starting from 0.
/// Returns `None` if number of children corresponding to token CASE_INSENSITIVE is less or equal than `i`.
fn CASE_INSENSITIVE(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CASE_INSENSITIVE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
fn number_all(&self) ->  Vec<Rc<NumberContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn number(&self, i: usize) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}

}

impl<'input> ColumnAttributesContextAttrs<'input> for ColumnAttributesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnAttributes(&mut self,)
	-> Result<Rc<ColumnAttributesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnAttributesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 60, RULE_columnAttributes);
        let mut _localctx: Rc<ColumnAttributesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1448); 
			recog.err_handler.sync(&mut recog.base)?;
			_alt = 1;
			loop {
				match _alt {
				    x if x == 1=>
					{
					recog.base.set_state(1448);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 DEFAULT 
						=> {
							{
							{
							recog.base.set_state(1406);
							recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(1407);
							recog.expression()?;

							}
							}
						}

					 IDENTITY 
						=> {
							{
							{
							recog.base.set_state(1408);
							recog.base.match_token(IDENTITY,&mut recog.err_handler)?;

							recog.base.set_state(1418);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==LPAREN {
								{
								recog.base.set_state(1409);
								recog.base.match_token(LPAREN,&mut recog.err_handler)?;

								/*InvokeRule number*/
								recog.base.set_state(1410);
								recog.number()?;

								recog.base.set_state(1411);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule number*/
								recog.base.set_state(1412);
								recog.number()?;

								recog.base.set_state(1414);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								if _la==COMMA {
									{
									recog.base.set_state(1413);
									let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
									 cast_mut::<_,ColumnAttributesContext >(&mut _localctx).COMMA = Some(tmp);
									  

									let temp =  cast_mut::<_,ColumnAttributesContext >(&mut _localctx).COMMA.clone().unwrap()
									 ;
									 cast_mut::<_,ColumnAttributesContext >(&mut _localctx).tail.push(temp);
									  
									}
								}

								recog.base.set_state(1416);
								recog.base.match_token(RPAREN,&mut recog.err_handler)?;

								}
							}

							}
							}
						}

					 GENERATED 
						=> {
							{
							{
							recog.base.set_state(1420);
							recog.base.match_token(GENERATED,&mut recog.err_handler)?;

							recog.base.set_state(1421);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							recog.base.set_state(1422);
							recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

							recog.base.set_state(1423);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							recog.base.set_state(1424);
							recog.base.match_token(IDENTITY,&mut recog.err_handler)?;

							recog.base.set_state(1434);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==LPAREN {
								{
								recog.base.set_state(1425);
								recog.base.match_token(LPAREN,&mut recog.err_handler)?;

								/*InvokeRule number*/
								recog.base.set_state(1426);
								recog.number()?;

								recog.base.set_state(1427);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule number*/
								recog.base.set_state(1428);
								recog.number()?;

								recog.base.set_state(1430);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								if _la==COMMA {
									{
									recog.base.set_state(1429);
									let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
									 cast_mut::<_,ColumnAttributesContext >(&mut _localctx).COMMA = Some(tmp);
									  

									let temp =  cast_mut::<_,ColumnAttributesContext >(&mut _localctx).COMMA.clone().unwrap()
									 ;
									 cast_mut::<_,ColumnAttributesContext >(&mut _localctx).tail.push(temp);
									  
									}
								}

								recog.base.set_state(1432);
								recog.base.match_token(RPAREN,&mut recog.err_handler)?;

								}
							}

							}
							}
						}

					 ENCODE 
						=> {
							{
							{
							recog.base.set_state(1436);
							recog.base.match_token(ENCODE,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(1437);
							recog.identifier()?;

							}
							}
						}

					 DISTKEY 
						=> {
							{
							recog.base.set_state(1438);
							recog.base.match_token(DISTKEY,&mut recog.err_handler)?;

							}
						}

					 SORTKEY 
						=> {
							{
							recog.base.set_state(1439);
							recog.base.match_token(SORTKEY,&mut recog.err_handler)?;

							}
						}

					 COLLATE 
						=> {
							{
							recog.base.set_state(1444);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(153,&mut recog.base)? {
								1 =>{
									{
									recog.base.set_state(1440);
									recog.base.match_token(COLLATE,&mut recog.err_handler)?;

									recog.base.set_state(1441);
									recog.base.match_token(CASE_SENSITIVE,&mut recog.err_handler)?;

									}
								}
							,
								2 =>{
									{
									recog.base.set_state(1442);
									recog.base.match_token(COLLATE,&mut recog.err_handler)?;

									recog.base.set_state(1443);
									recog.base.match_token(CASE_INSENSITIVE,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							}
						}

					 CONSTRAINT 
						=> {
							{
							recog.base.set_state(1446);
							recog.base.match_token(CONSTRAINT,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(1447);
							recog.identifier()?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				recog.base.set_state(1450); 
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(155,&mut recog.base)?;
				if _alt==2 || _alt==INVALID_ALT { break }
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnConstraints ----------------
pub type ColumnConstraintsContextAll<'input> = ColumnConstraintsContext<'input>;


pub type ColumnConstraintsContext<'input> = BaseParserRuleContext<'input,ColumnConstraintsContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnConstraintsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnConstraintsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnConstraintsContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnConstraints(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnConstraints(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnConstraintsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnConstraints(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnConstraintsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnConstraints }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnConstraints }
}
antlr_rust::tid!{ColumnConstraintsContextExt<'a>}

impl<'input> ColumnConstraintsContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnConstraintsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnConstraintsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnConstraintsContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnConstraintsContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token NOT in current rule
fn NOT_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token NOT, starting from 0.
/// Returns `None` if number of children corresponding to token NOT is less or equal than `i`.
fn NOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NOT, i)
}
/// Retrieves all `TerminalNode`s corresponding to token NULL in current rule
fn NULL_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token NULL, starting from 0.
/// Returns `None` if number of children corresponding to token NULL is less or equal than `i`.
fn NULL(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULL, i)
}
/// Retrieves all `TerminalNode`s corresponding to token UNIQUE in current rule
fn UNIQUE_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token UNIQUE, starting from 0.
/// Returns `None` if number of children corresponding to token UNIQUE is less or equal than `i`.
fn UNIQUE(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNIQUE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token PRIMARY in current rule
fn PRIMARY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token PRIMARY, starting from 0.
/// Returns `None` if number of children corresponding to token PRIMARY is less or equal than `i`.
fn PRIMARY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRIMARY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KEY in current rule
fn KEY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KEY, starting from 0.
/// Returns `None` if number of children corresponding to token KEY is less or equal than `i`.
fn KEY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KEY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token REFERENCES in current rule
fn REFERENCES_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token REFERENCES, starting from 0.
/// Returns `None` if number of children corresponding to token REFERENCES is less or equal than `i`.
fn REFERENCES(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(REFERENCES, i)
}
fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}

}

impl<'input> ColumnConstraintsContextAttrs<'input> for ColumnConstraintsContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnConstraints(&mut self,)
	-> Result<Rc<ColumnConstraintsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnConstraintsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 62, RULE_columnConstraints);
        let mut _localctx: Rc<ColumnConstraintsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1468); 
			recog.err_handler.sync(&mut recog.base)?;
			_alt = 1;
			loop {
				match _alt {
				    x if x == 1=>
					{
					recog.base.set_state(1468);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 NOT | NULL 
						=> {
							{
							recog.base.set_state(1455);
							recog.err_handler.sync(&mut recog.base)?;
							match recog.base.input.la(1) {
							 NOT 
								=> {
									{
									recog.base.set_state(1452);
									recog.base.match_token(NOT,&mut recog.err_handler)?;

									recog.base.set_state(1453);
									recog.base.match_token(NULL,&mut recog.err_handler)?;

									}
								}

							 NULL 
								=> {
									{
									recog.base.set_state(1454);
									recog.base.match_token(NULL,&mut recog.err_handler)?;

									}
								}

								_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
							}
							}
						}

					 PRIMARY | UNIQUE 
						=> {
							{
							recog.base.set_state(1460);
							recog.err_handler.sync(&mut recog.base)?;
							match recog.base.input.la(1) {
							 UNIQUE 
								=> {
									{
									recog.base.set_state(1457);
									recog.base.match_token(UNIQUE,&mut recog.err_handler)?;

									}
								}

							 PRIMARY 
								=> {
									{
									recog.base.set_state(1458);
									recog.base.match_token(PRIMARY,&mut recog.err_handler)?;

									recog.base.set_state(1459);
									recog.base.match_token(KEY,&mut recog.err_handler)?;

									}
								}

								_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
							}
							}
						}

					 REFERENCES 
						=> {
							{
							{
							recog.base.set_state(1462);
							recog.base.match_token(REFERENCES,&mut recog.err_handler)?;

							/*InvokeRule qualifiedName*/
							recog.base.set_state(1463);
							recog.qualifiedName()?;

							recog.base.set_state(1464);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(1465);
							recog.identifier()?;

							recog.base.set_state(1466);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				recog.base.set_state(1470); 
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(159,&mut recog.base)?;
				if _alt==2 || _alt==INVALID_ALT { break }
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- likeClause ----------------
pub type LikeClauseContextAll<'input> = LikeClauseContext<'input>;


pub type LikeClauseContext<'input> = BaseParserRuleContext<'input,LikeClauseContextExt<'input>>;

#[derive(Clone)]
pub struct LikeClauseContextExt<'input>{
	pub optionType: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for LikeClauseContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LikeClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_likeClause(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_likeClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LikeClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_likeClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for LikeClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_likeClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_likeClause }
}
antlr_rust::tid!{LikeClauseContextExt<'a>}

impl<'input> LikeClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LikeClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LikeClauseContextExt{
				optionType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LikeClauseContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<LikeClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LIKE
/// Returns `None` if there is no child corresponding to token LIKE
fn LIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LIKE, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PROPERTIES
/// Returns `None` if there is no child corresponding to token PROPERTIES
fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULTS
/// Returns `None` if there is no child corresponding to token DEFAULTS
fn DEFAULTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DEFAULTS, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDING
/// Returns `None` if there is no child corresponding to token INCLUDING
fn INCLUDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INCLUDING, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDING
/// Returns `None` if there is no child corresponding to token EXCLUDING
fn EXCLUDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDING, 0)
}

}

impl<'input> LikeClauseContextAttrs<'input> for LikeClauseContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn likeClause(&mut self,)
	-> Result<Rc<LikeClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LikeClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 64, RULE_likeClause);
        let mut _localctx: Rc<LikeClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1472);
			recog.base.match_token(LIKE,&mut recog.err_handler)?;

			/*InvokeRule qualifiedName*/
			recog.base.set_state(1473);
			recog.qualifiedName()?;

			recog.base.set_state(1476);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EXCLUDING || _la==INCLUDING {
				{
				recog.base.set_state(1474);
				 cast_mut::<_,LikeClauseContext >(&mut _localctx).optionType = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==EXCLUDING || _la==INCLUDING) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,LikeClauseContext >(&mut _localctx).optionType = Some(tmp);
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				recog.base.set_state(1475);
				_la = recog.base.input.la(1);
				if { !(_la==DEFAULTS || _la==PROPERTIES) } {
					recog.err_handler.recover_inline(&mut recog.base)?;

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- redshiftTableAttributes ----------------
pub type RedshiftTableAttributesContextAll<'input> = RedshiftTableAttributesContext<'input>;


pub type RedshiftTableAttributesContext<'input> = BaseParserRuleContext<'input,RedshiftTableAttributesContextExt<'input>>;

#[derive(Clone)]
pub struct RedshiftTableAttributesContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RedshiftTableAttributesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftTableAttributesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_redshiftTableAttributes(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_redshiftTableAttributes(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftTableAttributesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftTableAttributes(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftTableAttributesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_redshiftTableAttributes }
	//fn type_rule_index() -> usize where Self: Sized { RULE_redshiftTableAttributes }
}
antlr_rust::tid!{RedshiftTableAttributesContextExt<'a>}

impl<'input> RedshiftTableAttributesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RedshiftTableAttributesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RedshiftTableAttributesContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait RedshiftTableAttributesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RedshiftTableAttributesContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token DISTSTYLE in current rule
fn DISTSTYLE_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DISTSTYLE, starting from 0.
/// Returns `None` if number of children corresponding to token DISTSTYLE is less or equal than `i`.
fn DISTSTYLE(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DISTSTYLE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token DISTKEY in current rule
fn DISTKEY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DISTKEY, starting from 0.
/// Returns `None` if number of children corresponding to token DISTKEY is less or equal than `i`.
fn DISTKEY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DISTKEY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token ENCODE in current rule
fn ENCODE_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token ENCODE, starting from 0.
/// Returns `None` if number of children corresponding to token ENCODE is less or equal than `i`.
fn ENCODE(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ENCODE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token AUTO in current rule
fn AUTO_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token AUTO, starting from 0.
/// Returns `None` if number of children corresponding to token AUTO is less or equal than `i`.
fn AUTO(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AUTO, i)
}
/// Retrieves all `TerminalNode`s corresponding to token EVEN in current rule
fn EVEN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token EVEN, starting from 0.
/// Returns `None` if number of children corresponding to token EVEN is less or equal than `i`.
fn EVEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EVEN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KEY in current rule
fn KEY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KEY, starting from 0.
/// Returns `None` if number of children corresponding to token KEY is less or equal than `i`.
fn KEY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KEY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token ALL in current rule
fn ALL_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token ALL, starting from 0.
/// Returns `None` if number of children corresponding to token ALL is less or equal than `i`.
fn ALL(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ALL, i)
}
/// Retrieves all `TerminalNode`s corresponding to token SORTKEY in current rule
fn SORTKEY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SORTKEY, starting from 0.
/// Returns `None` if number of children corresponding to token SORTKEY is less or equal than `i`.
fn SORTKEY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SORTKEY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMPOUND in current rule
fn COMPOUND_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMPOUND, starting from 0.
/// Returns `None` if number of children corresponding to token COMPOUND is less or equal than `i`.
fn COMPOUND(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMPOUND, i)
}
/// Retrieves all `TerminalNode`s corresponding to token INTERLEAVED in current rule
fn INTERLEAVED_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token INTERLEAVED, starting from 0.
/// Returns `None` if number of children corresponding to token INTERLEAVED is less or equal than `i`.
fn INTERLEAVED(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTERLEAVED, i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RedshiftTableAttributesContextAttrs<'input> for RedshiftTableAttributesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn redshiftTableAttributes(&mut self,)
	-> Result<Rc<RedshiftTableAttributesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RedshiftTableAttributesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 66, RULE_redshiftTableAttributes);
        let mut _localctx: Rc<RedshiftTableAttributesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1512);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMPOUND || ((((_la - 92)) & !0x3f) == 0 && ((1usize << (_la - 92)) & ((1usize << (DISTKEY - 92)) | (1usize << (DISTSTYLE - 92)) | (1usize << (ENCODE - 92)))) != 0) || _la==INTERLEAVED || _la==SORTKEY {
				{
				recog.base.set_state(1510);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 DISTSTYLE 
					=> {
						{
						recog.base.set_state(1478);
						recog.base.match_token(DISTSTYLE,&mut recog.err_handler)?;

						recog.base.set_state(1479);
						_la = recog.base.input.la(1);
						if { !(_la==ALL || _la==AUTO || _la==EVEN || _la==KEY) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

				 DISTKEY 
					=> {
						{
						recog.base.set_state(1480);
						recog.base.match_token(DISTKEY,&mut recog.err_handler)?;

						recog.base.set_state(1481);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(1482);
						recog.expression()?;

						recog.base.set_state(1483);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

				 COMPOUND | INTERLEAVED | SORTKEY 
					=> {
						{
						recog.base.set_state(1506);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(165,&mut recog.base)? {
							1 =>{
								{
								recog.base.set_state(1486);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								if _la==COMPOUND || _la==INTERLEAVED {
									{
									recog.base.set_state(1485);
									_la = recog.base.input.la(1);
									if { !(_la==COMPOUND || _la==INTERLEAVED) } {
										recog.err_handler.recover_inline(&mut recog.base)?;

									}
									else {
										if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
										recog.err_handler.report_match(&mut recog.base);
										recog.base.consume(&mut recog.err_handler);
									}
									}
								}

								recog.base.set_state(1488);
								recog.base.match_token(SORTKEY,&mut recog.err_handler)?;

								recog.base.set_state(1489);
								recog.base.match_token(LPAREN,&mut recog.err_handler)?;

								recog.base.set_state(1498);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONVERT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOT - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RIGHT - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (POSIX - 419)) | (1usize << (STRING - 419)) | (1usize << (UNICODE_STRING - 419)) | (1usize << (DOLLAR_QUOTED_STRING - 419)) | (1usize << (BINARY_LITERAL - 419)) | (1usize << (INTEGER_VALUE - 419)) | (1usize << (DECIMAL_VALUE - 419)) | (1usize << (DOUBLE_VALUE - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)) | (1usize << (VARIABLE - 419)))) != 0) {
									{
									/*InvokeRule expression*/
									recog.base.set_state(1490);
									recog.expression()?;

									recog.base.set_state(1495);
									recog.err_handler.sync(&mut recog.base)?;
									_alt = recog.interpreter.adaptive_predict(162,&mut recog.base)?;
									while { _alt!=2 && _alt!=INVALID_ALT } {
										if _alt==1 {
											{
											{
											recog.base.set_state(1491);
											recog.base.match_token(COMMA,&mut recog.err_handler)?;

											/*InvokeRule expression*/
											recog.base.set_state(1492);
											recog.expression()?;

											}
											} 
										}
										recog.base.set_state(1497);
										recog.err_handler.sync(&mut recog.base)?;
										_alt = recog.interpreter.adaptive_predict(162,&mut recog.base)?;
									}
									}
								}

								recog.base.set_state(1501);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								if _la==COMMA {
									{
									recog.base.set_state(1500);
									let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
									 cast_mut::<_,RedshiftTableAttributesContext >(&mut _localctx).COMMA = Some(tmp);
									  

									let temp =  cast_mut::<_,RedshiftTableAttributesContext >(&mut _localctx).COMMA.clone().unwrap()
									 ;
									 cast_mut::<_,RedshiftTableAttributesContext >(&mut _localctx).tail.push(temp);
									  
									}
								}

								recog.base.set_state(1503);
								recog.base.match_token(RPAREN,&mut recog.err_handler)?;

								}
							}
						,
							2 =>{
								{
								recog.base.set_state(1504);
								recog.base.match_token(SORTKEY,&mut recog.err_handler)?;

								recog.base.set_state(1505);
								recog.base.match_token(AUTO,&mut recog.err_handler)?;

								}
							}

							_ => {}
						}
						}
					}

				 ENCODE 
					=> {
						{
						recog.base.set_state(1508);
						recog.base.match_token(ENCODE,&mut recog.err_handler)?;

						recog.base.set_state(1509);
						recog.base.match_token(AUTO,&mut recog.err_handler)?;

						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
				recog.base.set_state(1514);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- properties ----------------
pub type PropertiesContextAll<'input> = PropertiesContext<'input>;


pub type PropertiesContext<'input> = BaseParserRuleContext<'input,PropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct PropertiesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_properties(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_properties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_properties(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_properties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_properties }
}
antlr_rust::tid!{PropertiesContextExt<'a>}

impl<'input> PropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertiesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertiesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn propertyAssignments(&self) -> Option<Rc<PropertyAssignmentsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertiesContextAttrs<'input> for PropertiesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn properties(&mut self,)
	-> Result<Rc<PropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 68, RULE_properties);
        let mut _localctx: Rc<PropertiesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1515);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(1517);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LBRACKET - 384)))) != 0) || ((((_la - 440)) & !0x3f) == 0 && ((1usize << (_la - 440)) & ((1usize << (IDENTIFIER - 440)) | (1usize << (DIGIT_IDENTIFIER - 440)) | (1usize << (QUOTED_IDENTIFIER - 440)))) != 0) {
				{
				/*InvokeRule propertyAssignments*/
				recog.base.set_state(1516);
				recog.propertyAssignments()?;

				}
			}

			recog.base.set_state(1519);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyAssignments ----------------
pub type PropertyAssignmentsContextAll<'input> = PropertyAssignmentsContext<'input>;


pub type PropertyAssignmentsContext<'input> = BaseParserRuleContext<'input,PropertyAssignmentsContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyAssignmentsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PropertyAssignmentsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PropertyAssignmentsContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyAssignments(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_propertyAssignments(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PropertyAssignmentsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_propertyAssignments(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyAssignmentsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyAssignments }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyAssignments }
}
antlr_rust::tid!{PropertyAssignmentsContextExt<'a>}

impl<'input> PropertyAssignmentsContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyAssignmentsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyAssignmentsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyAssignmentsContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PropertyAssignmentsContextExt<'input>>{

fn property_all(&self) ->  Vec<Rc<PropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn property(&self, i: usize) -> Option<Rc<PropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PropertyAssignmentsContextAttrs<'input> for PropertyAssignmentsContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyAssignments(&mut self,)
	-> Result<Rc<PropertyAssignmentsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyAssignmentsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 70, RULE_propertyAssignments);
        let mut _localctx: Rc<PropertyAssignmentsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule property*/
			recog.base.set_state(1521);
			recog.property()?;

			recog.base.set_state(1526);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(169,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1522);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule property*/
					recog.base.set_state(1523);
					recog.property()?;

					}
					} 
				}
				recog.base.set_state(1528);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(169,&mut recog.base)?;
			}
			recog.base.set_state(1530);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1529);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,PropertyAssignmentsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- property ----------------
#[derive(Debug)]
pub enum PropertyContextAll<'input>{
	DefaultPropertyContext(DefaultPropertyContext<'input>),
	NestedPropertyContext(NestedPropertyContext<'input>),
Error(PropertyContext<'input>)
}
antlr_rust::tid!{PropertyContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PropertyContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PropertyContextAll<'input>{}

impl<'input> Deref for PropertyContextAll<'input>{
	type Target = dyn PropertyContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PropertyContextAll::*;
		match self{
			DefaultPropertyContext(inner) => inner,
			NestedPropertyContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PropertyContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PropertyContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PropertyContext<'input> = BaseParserRuleContext<'input,PropertyContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PropertyContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PropertyContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PropertyContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}
antlr_rust::tid!{PropertyContextExt<'a>}

impl<'input> PropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyContextAll<'input>> {
		Rc::new(
		PropertyContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PropertyContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PropertyContextExt<'input>>{


}

impl<'input> PropertyContextAttrs<'input> for PropertyContext<'input>{}

pub type DefaultPropertyContext<'input> = BaseParserRuleContext<'input,DefaultPropertyContextExt<'input>>;

pub trait DefaultPropertyContextAttrs<'input>: RedshiftParserContext<'input>{
	fn propertyKey(&self) -> Option<Rc<PropertyKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn propertyValue(&self) -> Option<Rc<PropertyValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DefaultPropertyContextAttrs<'input> for DefaultPropertyContext<'input>{}

pub struct DefaultPropertyContextExt<'input>{
	base:PropertyContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultPropertyContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DefaultPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DefaultPropertyContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultProperty(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_defaultProperty(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DefaultPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_defaultProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}

impl<'input> Borrow<PropertyContextExt<'input>> for DefaultPropertyContext<'input>{
	fn borrow(&self) -> &PropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyContextExt<'input>> for DefaultPropertyContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyContextExt<'input> { &mut self.base }
}

impl<'input> PropertyContextAttrs<'input> for DefaultPropertyContext<'input> {}

impl<'input> DefaultPropertyContextExt<'input>{
	fn new(ctx: &dyn PropertyContextAttrs<'input>) -> Rc<PropertyContextAll<'input>>  {
		Rc::new(
			PropertyContextAll::DefaultPropertyContext(
				BaseParserRuleContext::copy_from(ctx,DefaultPropertyContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NestedPropertyContext<'input> = BaseParserRuleContext<'input,NestedPropertyContextExt<'input>>;

pub trait NestedPropertyContextAttrs<'input>: RedshiftParserContext<'input>{
	fn propertyKey(&self) -> Option<Rc<PropertyKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn property_all(&self) ->  Vec<Rc<PropertyContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn property(&self, i: usize) -> Option<Rc<PropertyContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> NestedPropertyContextAttrs<'input> for NestedPropertyContext<'input>{}

pub struct NestedPropertyContextExt<'input>{
	base:PropertyContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NestedPropertyContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for NestedPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NestedPropertyContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nestedProperty(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_nestedProperty(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NestedPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_nestedProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for NestedPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}

impl<'input> Borrow<PropertyContextExt<'input>> for NestedPropertyContext<'input>{
	fn borrow(&self) -> &PropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyContextExt<'input>> for NestedPropertyContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyContextExt<'input> { &mut self.base }
}

impl<'input> PropertyContextAttrs<'input> for NestedPropertyContext<'input> {}

impl<'input> NestedPropertyContextExt<'input>{
	fn new(ctx: &dyn PropertyContextAttrs<'input>) -> Rc<PropertyContextAll<'input>>  {
		Rc::new(
			PropertyContextAll::NestedPropertyContext(
				BaseParserRuleContext::copy_from(ctx,NestedPropertyContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn property(&mut self,)
	-> Result<Rc<PropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 72, RULE_property);
        let mut _localctx: Rc<PropertyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1547);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(172,&mut recog.base)? {
				1 =>{
					let tmp = NestedPropertyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule propertyKey*/
					recog.base.set_state(1532);
					recog.propertyKey()?;

					recog.base.set_state(1533);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					recog.base.set_state(1534);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1538);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LBRACKET - 384)))) != 0) || ((((_la - 440)) & !0x3f) == 0 && ((1usize << (_la - 440)) & ((1usize << (IDENTIFIER - 440)) | (1usize << (DIGIT_IDENTIFIER - 440)) | (1usize << (QUOTED_IDENTIFIER - 440)))) != 0) {
						{
						{
						/*InvokeRule property*/
						recog.base.set_state(1535);
						recog.property()?;

						}
						}
						recog.base.set_state(1540);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1541);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = DefaultPropertyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule propertyKey*/
					recog.base.set_state(1543);
					recog.propertyKey()?;

					recog.base.set_state(1544);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule propertyValue*/
					recog.base.set_state(1545);
					recog.propertyValue()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyKey ----------------
pub type PropertyKeyContextAll<'input> = PropertyKeyContext<'input>;


pub type PropertyKeyContext<'input> = BaseParserRuleContext<'input,PropertyKeyContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyKeyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PropertyKeyContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PropertyKeyContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyKey(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_propertyKey(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PropertyKeyContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_propertyKey(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyKeyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyKey }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyKey }
}
antlr_rust::tid!{PropertyKeyContextExt<'a>}

impl<'input> PropertyKeyContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyKeyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyKeyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyKeyContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PropertyKeyContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertyKeyContextAttrs<'input> for PropertyKeyContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyKey(&mut self,)
	-> Result<Rc<PropertyKeyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyKeyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 74, RULE_propertyKey);
        let mut _localctx: Rc<PropertyKeyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1549);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyValue ----------------
#[derive(Debug)]
pub enum PropertyValueContextAll<'input>{
	ExpressionPropertyValueContext(ExpressionPropertyValueContext<'input>),
	DefaultPropertyValueContext(DefaultPropertyValueContext<'input>),
	IdentifierPropertyValueContext(IdentifierPropertyValueContext<'input>),
Error(PropertyValueContext<'input>)
}
antlr_rust::tid!{PropertyValueContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PropertyValueContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PropertyValueContextAll<'input>{}

impl<'input> Deref for PropertyValueContextAll<'input>{
	type Target = dyn PropertyValueContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PropertyValueContextAll::*;
		match self{
			ExpressionPropertyValueContext(inner) => inner,
			DefaultPropertyValueContext(inner) => inner,
			IdentifierPropertyValueContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PropertyValueContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PropertyValueContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PropertyValueContext<'input> = BaseParserRuleContext<'input,PropertyValueContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PropertyValueContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PropertyValueContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}
antlr_rust::tid!{PropertyValueContextExt<'a>}

impl<'input> PropertyValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyValueContextAll<'input>> {
		Rc::new(
		PropertyValueContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyValueContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PropertyValueContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PropertyValueContextExt<'input>>{


}

impl<'input> PropertyValueContextAttrs<'input> for PropertyValueContext<'input>{}

pub type ExpressionPropertyValueContext<'input> = BaseParserRuleContext<'input,ExpressionPropertyValueContextExt<'input>>;

pub trait ExpressionPropertyValueContextAttrs<'input>: RedshiftParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExpressionPropertyValueContextAttrs<'input> for ExpressionPropertyValueContext<'input>{}

pub struct ExpressionPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExpressionPropertyValueContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ExpressionPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ExpressionPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_expressionPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_expressionPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ExpressionPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_expressionPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for ExpressionPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for ExpressionPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for ExpressionPropertyValueContext<'input> {}

impl<'input> ExpressionPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::ExpressionPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,ExpressionPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DefaultPropertyValueContext<'input> = BaseParserRuleContext<'input,DefaultPropertyValueContextExt<'input>>;

pub trait DefaultPropertyValueContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DEFAULT
	/// Returns `None` if there is no child corresponding to token DEFAULT
	fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DEFAULT, 0)
	}
}

impl<'input> DefaultPropertyValueContextAttrs<'input> for DefaultPropertyValueContext<'input>{}

pub struct DefaultPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultPropertyValueContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DefaultPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DefaultPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_defaultPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DefaultPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_defaultPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for DefaultPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for DefaultPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for DefaultPropertyValueContext<'input> {}

impl<'input> DefaultPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::DefaultPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,DefaultPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IdentifierPropertyValueContext<'input> = BaseParserRuleContext<'input,IdentifierPropertyValueContextExt<'input>>;

pub trait IdentifierPropertyValueContextAttrs<'input>: RedshiftParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IdentifierPropertyValueContextAttrs<'input> for IdentifierPropertyValueContext<'input>{}

pub struct IdentifierPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IdentifierPropertyValueContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for IdentifierPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IdentifierPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_identifierPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_identifierPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IdentifierPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_identifierPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for IdentifierPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for IdentifierPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for IdentifierPropertyValueContext<'input> {}

impl<'input> IdentifierPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::IdentifierPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,IdentifierPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyValue(&mut self,)
	-> Result<Rc<PropertyValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 76, RULE_propertyValue);
        let mut _localctx: Rc<PropertyValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1554);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(173,&mut recog.base)? {
				1 =>{
					let tmp = DefaultPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1551);
					recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = IdentifierPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1552);
					recog.identifier()?;

					}
				}
			,
				3 =>{
					let tmp = ExpressionPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(1553);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryNoWith ----------------
pub type QueryNoWithContextAll<'input> = QueryNoWithContext<'input>;


pub type QueryNoWithContext<'input> = BaseParserRuleContext<'input,QueryNoWithContextExt<'input>>;

#[derive(Clone)]
pub struct QueryNoWithContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QueryNoWithContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryNoWithContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryNoWith(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_queryNoWith(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryNoWithContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_queryNoWith(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryNoWithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryNoWith }
}
antlr_rust::tid!{QueryNoWithContextExt<'a>}

impl<'input> QueryNoWithContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryNoWithContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryNoWithContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryNoWithContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QueryNoWithContextExt<'input>>{

fn queryLimit(&self) -> Option<Rc<QueryLimitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryNoWithContextAttrs<'input> for QueryNoWithContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryNoWith(&mut self,)
	-> Result<Rc<QueryNoWithContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryNoWithContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 78, RULE_queryNoWith);
        let mut _localctx: Rc<QueryNoWithContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryLimit*/
			recog.base.set_state(1556);
			recog.queryLimit()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryLimit ----------------
pub type QueryLimitContextAll<'input> = QueryLimitContext<'input>;


pub type QueryLimitContext<'input> = BaseParserRuleContext<'input,QueryLimitContextExt<'input>>;

#[derive(Clone)]
pub struct QueryLimitContextExt<'input>{
	pub limit: Option<Rc<LimitRowCountContextAll<'input>>>,
	pub offset: Option<Rc<RowCountContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QueryLimitContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryLimitContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryLimit(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_queryLimit(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryLimitContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_queryLimit(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryLimitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimit }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimit }
}
antlr_rust::tid!{QueryLimitContextExt<'a>}

impl<'input> QueryLimitContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryLimitContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryLimitContextExt{
				limit: None, offset: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryLimitContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QueryLimitContextExt<'input>>{

fn queryLimitTarget(&self) -> Option<Rc<QueryLimitTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
fn limitRowCount(&self) -> Option<Rc<LimitRowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
fn rowCount(&self) -> Option<Rc<RowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryLimitContextAttrs<'input> for QueryLimitContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryLimit(&mut self,)
	-> Result<Rc<QueryLimitContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryLimitContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 80, RULE_queryLimit);
        let mut _localctx: Rc<QueryLimitContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryLimitTarget*/
			recog.base.set_state(1558);
			recog.queryLimitTarget()?;

			recog.base.set_state(1565);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LIMIT {
				{
				recog.base.set_state(1559);
				recog.base.match_token(LIMIT,&mut recog.err_handler)?;

				/*InvokeRule limitRowCount*/
				recog.base.set_state(1560);
				let tmp = recog.limitRowCount()?;
				 cast_mut::<_,QueryLimitContext >(&mut _localctx).limit = Some(tmp.clone());
				  

				recog.base.set_state(1563);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==OFFSET {
					{
					recog.base.set_state(1561);
					recog.base.match_token(OFFSET,&mut recog.err_handler)?;

					/*InvokeRule rowCount*/
					recog.base.set_state(1562);
					let tmp = recog.rowCount()?;
					 cast_mut::<_,QueryLimitContext >(&mut _localctx).offset = Some(tmp.clone());
					  

					}
				}

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryLimitTarget ----------------
#[derive(Debug)]
pub enum QueryLimitTargetContextAll<'input>{
	QueryLimitTargetRedshiftSnowflakeContext(QueryLimitTargetRedshiftSnowflakeContext<'input>),
Error(QueryLimitTargetContext<'input>)
}
antlr_rust::tid!{QueryLimitTargetContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QueryLimitTargetContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for QueryLimitTargetContextAll<'input>{}

impl<'input> Deref for QueryLimitTargetContextAll<'input>{
	type Target = dyn QueryLimitTargetContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QueryLimitTargetContextAll::*;
		match self{
			QueryLimitTargetRedshiftSnowflakeContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryLimitTargetContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryLimitTargetContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QueryLimitTargetContext<'input> = BaseParserRuleContext<'input,QueryLimitTargetContextExt<'input>>;

#[derive(Clone)]
pub struct QueryLimitTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QueryLimitTargetContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryLimitTargetContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryLimitTargetContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QueryLimitTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimitTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimitTarget }
}
antlr_rust::tid!{QueryLimitTargetContextExt<'a>}

impl<'input> QueryLimitTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryLimitTargetContextAll<'input>> {
		Rc::new(
		QueryLimitTargetContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryLimitTargetContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QueryLimitTargetContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QueryLimitTargetContextExt<'input>>{


}

impl<'input> QueryLimitTargetContextAttrs<'input> for QueryLimitTargetContext<'input>{}

pub type QueryLimitTargetRedshiftSnowflakeContext<'input> = BaseParserRuleContext<'input,QueryLimitTargetRedshiftSnowflakeContextExt<'input>>;

pub trait QueryLimitTargetRedshiftSnowflakeContextAttrs<'input>: RedshiftParserContext<'input>{
	fn queryTerm(&self) -> Option<Rc<QueryTermContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn orderBy(&self) -> Option<Rc<OrderByContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QueryLimitTargetRedshiftSnowflakeContextAttrs<'input> for QueryLimitTargetRedshiftSnowflakeContext<'input>{}

pub struct QueryLimitTargetRedshiftSnowflakeContextExt<'input>{
	base:QueryLimitTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QueryLimitTargetRedshiftSnowflakeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for QueryLimitTargetRedshiftSnowflakeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryLimitTargetRedshiftSnowflakeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_queryLimitTargetRedshiftSnowflake(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_queryLimitTargetRedshiftSnowflake(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryLimitTargetRedshiftSnowflakeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_queryLimitTargetRedshiftSnowflake(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryLimitTargetRedshiftSnowflakeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimitTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimitTarget }
}

impl<'input> Borrow<QueryLimitTargetContextExt<'input>> for QueryLimitTargetRedshiftSnowflakeContext<'input>{
	fn borrow(&self) -> &QueryLimitTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryLimitTargetContextExt<'input>> for QueryLimitTargetRedshiftSnowflakeContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryLimitTargetContextExt<'input> { &mut self.base }
}

impl<'input> QueryLimitTargetContextAttrs<'input> for QueryLimitTargetRedshiftSnowflakeContext<'input> {}

impl<'input> QueryLimitTargetRedshiftSnowflakeContextExt<'input>{
	fn new(ctx: &dyn QueryLimitTargetContextAttrs<'input>) -> Rc<QueryLimitTargetContextAll<'input>>  {
		Rc::new(
			QueryLimitTargetContextAll::QueryLimitTargetRedshiftSnowflakeContext(
				BaseParserRuleContext::copy_from(ctx,QueryLimitTargetRedshiftSnowflakeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryLimitTarget(&mut self,)
	-> Result<Rc<QueryLimitTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryLimitTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 82, RULE_queryLimitTarget);
        let mut _localctx: Rc<QueryLimitTargetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = QueryLimitTargetRedshiftSnowflakeContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule queryTerm*/
			recog.base.set_state(1567);
			recog.queryTerm()?;

			recog.base.set_state(1569);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				/*InvokeRule orderBy*/
				recog.base.set_state(1568);
				recog.orderBy()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- limitRowCount ----------------
pub type LimitRowCountContextAll<'input> = LimitRowCountContext<'input>;


pub type LimitRowCountContext<'input> = BaseParserRuleContext<'input,LimitRowCountContextExt<'input>>;

#[derive(Clone)]
pub struct LimitRowCountContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for LimitRowCountContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LimitRowCountContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_limitRowCount(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_limitRowCount(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LimitRowCountContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_limitRowCount(self);
	}
}

impl<'input> CustomRuleContext<'input> for LimitRowCountContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_limitRowCount }
	//fn type_rule_index() -> usize where Self: Sized { RULE_limitRowCount }
}
antlr_rust::tid!{LimitRowCountContextExt<'a>}

impl<'input> LimitRowCountContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LimitRowCountContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LimitRowCountContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LimitRowCountContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<LimitRowCountContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
fn rowCount(&self) -> Option<Rc<RowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LimitRowCountContextAttrs<'input> for LimitRowCountContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn limitRowCount(&mut self,)
	-> Result<Rc<LimitRowCountContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LimitRowCountContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 84, RULE_limitRowCount);
        let mut _localctx: Rc<LimitRowCountContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1573);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ALL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1571);
					recog.base.match_token(ALL,&mut recog.err_handler)?;

					}
				}

			 QUESTION_MARK | INTEGER_VALUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule rowCount*/
					recog.base.set_state(1572);
					recog.rowCount()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowCount ----------------
pub type RowCountContextAll<'input> = RowCountContext<'input>;


pub type RowCountContext<'input> = BaseParserRuleContext<'input,RowCountContextExt<'input>>;

#[derive(Clone)]
pub struct RowCountContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RowCountContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RowCountContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowCount(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_rowCount(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RowCountContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rowCount(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowCountContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowCount }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowCount }
}
antlr_rust::tid!{RowCountContextExt<'a>}

impl<'input> RowCountContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowCountContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowCountContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowCountContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RowCountContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token QUESTION_MARK
/// Returns `None` if there is no child corresponding to token QUESTION_MARK
fn QUESTION_MARK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(QUESTION_MARK, 0)
}

}

impl<'input> RowCountContextAttrs<'input> for RowCountContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowCount(&mut self,)
	-> Result<Rc<RowCountContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowCountContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 86, RULE_rowCount);
        let mut _localctx: Rc<RowCountContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1575);
			_la = recog.base.input.la(1);
			if { !(_la==QUESTION_MARK || _la==INTEGER_VALUE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryTerm ----------------
pub type QueryTermContextAll<'input> = QueryTermContext<'input>;


pub type QueryTermContext<'input> = BaseParserRuleContext<'input,QueryTermContextExt<'input>>;

#[derive(Clone)]
pub struct QueryTermContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QueryTermContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryTermContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryTerm(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_queryTerm(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryTermContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_queryTerm(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryTermContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryTerm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryTerm }
}
antlr_rust::tid!{QueryTermContextExt<'a>}

impl<'input> QueryTermContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryTermContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryTermContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryTermContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QueryTermContextExt<'input>>{

fn setOperation(&self) -> Option<Rc<SetOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryTermContextAttrs<'input> for QueryTermContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryTerm(&mut self,)
	-> Result<Rc<QueryTermContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryTermContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 88, RULE_queryTerm);
        let mut _localctx: Rc<QueryTermContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule setOperation*/
			recog.base.set_state(1577);
			recog.setOperation()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperation ----------------
pub type SetOperationContextAll<'input> = SetOperationContext<'input>;


pub type SetOperationContext<'input> = BaseParserRuleContext<'input,SetOperationContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperationContextExt<'input>{
	pub left: Option<Rc<SetOperationIntersectContextAll<'input>>>,
	pub setOperationIntersect: Option<Rc<SetOperationIntersectContextAll<'input>>>,
	pub right:Vec<Rc<SetOperationIntersectContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SetOperationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperation(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_setOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperation }
}
antlr_rust::tid!{SetOperationContextExt<'a>}

impl<'input> SetOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperationContextExt{
				left: None, setOperationIntersect: None, 
				right: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SetOperationContextExt<'input>>{

fn setOperationIntersect_all(&self) ->  Vec<Rc<SetOperationIntersectContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setOperationIntersect(&self, i: usize) -> Option<Rc<SetOperationIntersectContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setOperator_all(&self) ->  Vec<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setOperator(&self, i: usize) -> Option<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SetOperationContextAttrs<'input> for SetOperationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperation(&mut self,)
	-> Result<Rc<SetOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 90, RULE_setOperation);
        let mut _localctx: Rc<SetOperationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule setOperationIntersect*/
			recog.base.set_state(1579);
			let tmp = recog.setOperationIntersect()?;
			 cast_mut::<_,SetOperationContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(1585);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==EXCEPT || _la==MINUS_KW || _la==UNION {
				{
				{
				/*InvokeRule setOperator*/
				recog.base.set_state(1580);
				recog.setOperator()?;

				/*InvokeRule setOperationIntersect*/
				recog.base.set_state(1581);
				let tmp = recog.setOperationIntersect()?;
				 cast_mut::<_,SetOperationContext >(&mut _localctx).setOperationIntersect = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SetOperationContext >(&mut _localctx).setOperationIntersect.clone().unwrap()
				 ;
				 cast_mut::<_,SetOperationContext >(&mut _localctx).right.push(temp);
				  
				}
				}
				recog.base.set_state(1587);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperator ----------------
pub type SetOperatorContextAll<'input> = SetOperatorContext<'input>;


pub type SetOperatorContext<'input> = BaseParserRuleContext<'input,SetOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SetOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperator(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_setOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperator }
}
antlr_rust::tid!{SetOperatorContextExt<'a>}

impl<'input> SetOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperatorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SetOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS_KW
/// Returns `None` if there is no child corresponding to token MINUS_KW
fn MINUS_KW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MINUS_KW, 0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetOperatorContextAttrs<'input> for SetOperatorContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperator(&mut self,)
	-> Result<Rc<SetOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 92, RULE_setOperator);
        let mut _localctx: Rc<SetOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1588);
			_la = recog.base.input.la(1);
			if { !(_la==EXCEPT || _la==MINUS_KW || _la==UNION) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1590);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ALL || _la==DISTINCT {
				{
				/*InvokeRule setQuantifier*/
				recog.base.set_state(1589);
				recog.setQuantifier()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperationIntersect ----------------
pub type SetOperationIntersectContextAll<'input> = SetOperationIntersectContext<'input>;


pub type SetOperationIntersectContext<'input> = BaseParserRuleContext<'input,SetOperationIntersectContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperationIntersectContextExt<'input>{
	pub left: Option<Rc<QueryPrimaryContextAll<'input>>>,
	pub queryPrimary: Option<Rc<QueryPrimaryContextAll<'input>>>,
	pub right:Vec<Rc<QueryPrimaryContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SetOperationIntersectContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetOperationIntersectContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperationIntersect(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_setOperationIntersect(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetOperationIntersectContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setOperationIntersect(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperationIntersectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperationIntersect }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperationIntersect }
}
antlr_rust::tid!{SetOperationIntersectContextExt<'a>}

impl<'input> SetOperationIntersectContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperationIntersectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperationIntersectContextExt{
				left: None, queryPrimary: None, 
				right: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperationIntersectContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SetOperationIntersectContextExt<'input>>{

fn queryPrimary_all(&self) ->  Vec<Rc<QueryPrimaryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn queryPrimary(&self, i: usize) -> Option<Rc<QueryPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setIntersectOperator_all(&self) ->  Vec<Rc<SetIntersectOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setIntersectOperator(&self, i: usize) -> Option<Rc<SetIntersectOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SetOperationIntersectContextAttrs<'input> for SetOperationIntersectContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperationIntersect(&mut self,)
	-> Result<Rc<SetOperationIntersectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperationIntersectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 94, RULE_setOperationIntersect);
        let mut _localctx: Rc<SetOperationIntersectContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryPrimary*/
			recog.base.set_state(1592);
			let tmp = recog.queryPrimary()?;
			 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(1598);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==INTERSECT {
				{
				{
				/*InvokeRule setIntersectOperator*/
				recog.base.set_state(1593);
				recog.setIntersectOperator()?;

				/*InvokeRule queryPrimary*/
				recog.base.set_state(1594);
				let tmp = recog.queryPrimary()?;
				 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).queryPrimary = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).queryPrimary.clone().unwrap()
				 ;
				 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).right.push(temp);
				  
				}
				}
				recog.base.set_state(1600);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setIntersectOperator ----------------
pub type SetIntersectOperatorContextAll<'input> = SetIntersectOperatorContext<'input>;


pub type SetIntersectOperatorContext<'input> = BaseParserRuleContext<'input,SetIntersectOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SetIntersectOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SetIntersectOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetIntersectOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setIntersectOperator(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_setIntersectOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetIntersectOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setIntersectOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetIntersectOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setIntersectOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setIntersectOperator }
}
antlr_rust::tid!{SetIntersectOperatorContextExt<'a>}

impl<'input> SetIntersectOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetIntersectOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetIntersectOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetIntersectOperatorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SetIntersectOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetIntersectOperatorContextAttrs<'input> for SetIntersectOperatorContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setIntersectOperator(&mut self,)
	-> Result<Rc<SetIntersectOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetIntersectOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 96, RULE_setIntersectOperator);
        let mut _localctx: Rc<SetIntersectOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1601);
			recog.base.match_token(INTERSECT,&mut recog.err_handler)?;

			recog.base.set_state(1603);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ALL || _la==DISTINCT {
				{
				/*InvokeRule setQuantifier*/
				recog.base.set_state(1602);
				recog.setQuantifier()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setQuantifier ----------------
pub type SetQuantifierContextAll<'input> = SetQuantifierContext<'input>;


pub type SetQuantifierContext<'input> = BaseParserRuleContext<'input,SetQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct SetQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SetQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SetQuantifierContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setQuantifier(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_setQuantifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SetQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_setQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setQuantifier }
}
antlr_rust::tid!{SetQuantifierContextExt<'a>}

impl<'input> SetQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetQuantifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetQuantifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetQuantifierContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SetQuantifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}

}

impl<'input> SetQuantifierContextAttrs<'input> for SetQuantifierContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setQuantifier(&mut self,)
	-> Result<Rc<SetQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 98, RULE_setQuantifier);
        let mut _localctx: Rc<SetQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1605);
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==DISTINCT) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- inlineTable ----------------
pub type InlineTableContextAll<'input> = InlineTableContext<'input>;


pub type InlineTableContext<'input> = BaseParserRuleContext<'input,InlineTableContextExt<'input>>;

#[derive(Clone)]
pub struct InlineTableContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for InlineTableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for InlineTableContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_inlineTable(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_inlineTable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for InlineTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_inlineTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_inlineTable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_inlineTable }
}
antlr_rust::tid!{InlineTableContextExt<'a>}

impl<'input> InlineTableContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InlineTableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InlineTableContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait InlineTableContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<InlineTableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> InlineTableContextAttrs<'input> for InlineTableContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn inlineTable(&mut self,)
	-> Result<Rc<InlineTableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InlineTableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 100, RULE_inlineTable);
        let mut _localctx: Rc<InlineTableContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1607);
			recog.base.match_token(VALUES,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1608);
			recog.expression()?;

			recog.base.set_state(1613);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(182,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1609);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1610);
					recog.expression()?;

					}
					} 
				}
				recog.base.set_state(1615);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(182,&mut recog.base)?;
			}
			recog.base.set_state(1617);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1616);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,InlineTableContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryPrimary ----------------
#[derive(Debug)]
pub enum QueryPrimaryContextAll<'input>{
	SubqueryContext(SubqueryContext<'input>),
	QueryPrimaryDefaultContext(QueryPrimaryDefaultContext<'input>),
	InlineTableDefault1Context(InlineTableDefault1Context<'input>),
	TableContext(TableContext<'input>),
Error(QueryPrimaryContext<'input>)
}
antlr_rust::tid!{QueryPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QueryPrimaryContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for QueryPrimaryContextAll<'input>{}

impl<'input> Deref for QueryPrimaryContextAll<'input>{
	type Target = dyn QueryPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QueryPrimaryContextAll::*;
		match self{
			SubqueryContext(inner) => inner,
			QueryPrimaryDefaultContext(inner) => inner,
			InlineTableDefault1Context(inner) => inner,
			TableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QueryPrimaryContext<'input> = BaseParserRuleContext<'input,QueryPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QueryPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QueryPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}
antlr_rust::tid!{QueryPrimaryContextExt<'a>}

impl<'input> QueryPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryPrimaryContextAll<'input>> {
		Rc::new(
		QueryPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QueryPrimaryContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QueryPrimaryContextExt<'input>>{


}

impl<'input> QueryPrimaryContextAttrs<'input> for QueryPrimaryContext<'input>{}

pub type SubqueryContext<'input> = BaseParserRuleContext<'input,SubqueryContextExt<'input>>;

pub trait SubqueryContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SubqueryContextAttrs<'input> for SubqueryContext<'input>{}

pub struct SubqueryContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	pub query_: Option<Rc<QueryContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SubqueryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SubqueryContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subquery(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_subquery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SubqueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_subquery(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for SubqueryContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for SubqueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for SubqueryContext<'input> {}

impl<'input> SubqueryContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::SubqueryContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryContextExt{
        			query_:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QueryPrimaryDefaultContext<'input> = BaseParserRuleContext<'input,QueryPrimaryDefaultContextExt<'input>>;

pub trait QueryPrimaryDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn querySpecification(&self) -> Option<Rc<QuerySpecificationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QueryPrimaryDefaultContextAttrs<'input> for QueryPrimaryDefaultContext<'input>{}

pub struct QueryPrimaryDefaultContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QueryPrimaryDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for QueryPrimaryDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryPrimaryDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_queryPrimaryDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_queryPrimaryDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryPrimaryDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_queryPrimaryDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryPrimaryDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for QueryPrimaryDefaultContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for QueryPrimaryDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for QueryPrimaryDefaultContext<'input> {}

impl<'input> QueryPrimaryDefaultContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::QueryPrimaryDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QueryPrimaryDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InlineTableDefault1Context<'input> = BaseParserRuleContext<'input,InlineTableDefault1ContextExt<'input>>;

pub trait InlineTableDefault1ContextAttrs<'input>: RedshiftParserContext<'input>{
	fn inlineTable(&self) -> Option<Rc<InlineTableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InlineTableDefault1ContextAttrs<'input> for InlineTableDefault1Context<'input>{}

pub struct InlineTableDefault1ContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InlineTableDefault1ContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for InlineTableDefault1Context<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for InlineTableDefault1Context<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inlineTableDefault1(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_inlineTableDefault1(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for InlineTableDefault1Context<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_inlineTableDefault1(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableDefault1ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for InlineTableDefault1Context<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for InlineTableDefault1Context<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for InlineTableDefault1Context<'input> {}

impl<'input> InlineTableDefault1ContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::InlineTableDefault1Context(
				BaseParserRuleContext::copy_from(ctx,InlineTableDefault1ContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableContext<'input> = BaseParserRuleContext<'input,TableContextExt<'input>>;

pub trait TableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn pathExpression(&self) -> Option<Rc<PathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableContextAttrs<'input> for TableContext<'input>{}

pub struct TableContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_table(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_table(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_table(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for TableContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for TableContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for TableContext<'input> {}

impl<'input> TableContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::TableContext(
				BaseParserRuleContext::copy_from(ctx,TableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryPrimary(&mut self,)
	-> Result<Rc<QueryPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 102, RULE_queryPrimary);
        let mut _localctx: Rc<QueryPrimaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1627);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 SELECT 
				=> {
					let tmp = QueryPrimaryDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule querySpecification*/
					recog.base.set_state(1619);
					recog.querySpecification()?;

					}
				}

			 TABLE 
				=> {
					let tmp = TableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1620);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule pathExpression*/
					recog.base.set_state(1621);
					recog.pathExpression()?;

					}
				}

			 VALUES 
				=> {
					let tmp = InlineTableDefault1ContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule inlineTable*/
					recog.base.set_state(1622);
					recog.inlineTable()?;

					}
				}

			 LPAREN 
				=> {
					let tmp = SubqueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(1623);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(1624);
					let tmp = recog.query()?;
					if let QueryPrimaryContextAll::SubqueryContext(ctx) = cast_mut::<_,QueryPrimaryContextAll >(&mut _localctx){
					ctx.query_ = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1625);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sortItem ----------------
pub type SortItemContextAll<'input> = SortItemContext<'input>;


pub type SortItemContext<'input> = BaseParserRuleContext<'input,SortItemContextExt<'input>>;

#[derive(Clone)]
pub struct SortItemContextExt<'input>{
	pub ordering: Option<TokenType<'input>>,
	pub nullOrdering: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SortItemContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SortItemContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sortItem(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_sortItem(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SortItemContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_sortItem(self);
	}
}

impl<'input> CustomRuleContext<'input> for SortItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sortItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sortItem }
}
antlr_rust::tid!{SortItemContextExt<'a>}

impl<'input> SortItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SortItemContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SortItemContextExt{
				ordering: None, nullOrdering: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SortItemContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SortItemContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}

}

impl<'input> SortItemContextAttrs<'input> for SortItemContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sortItem(&mut self,)
	-> Result<Rc<SortItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SortItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 104, RULE_sortItem);
        let mut _localctx: Rc<SortItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(1629);
			recog.expression()?;

			recog.base.set_state(1631);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASC || _la==DESC {
				{
				recog.base.set_state(1630);
				 cast_mut::<_,SortItemContext >(&mut _localctx).ordering = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==ASC || _la==DESC) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,SortItemContext >(&mut _localctx).ordering = Some(tmp);
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			recog.base.set_state(1635);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==NULLS {
				{
				recog.base.set_state(1633);
				recog.base.match_token(NULLS,&mut recog.err_handler)?;

				recog.base.set_state(1634);
				 cast_mut::<_,SortItemContext >(&mut _localctx).nullOrdering = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==FIRST || _la==LAST) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,SortItemContext >(&mut _localctx).nullOrdering = Some(tmp);
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- querySpecification ----------------
pub type QuerySpecificationContextAll<'input> = QuerySpecificationContext<'input>;


pub type QuerySpecificationContext<'input> = BaseParserRuleContext<'input,QuerySpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct QuerySpecificationContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	pub where_: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub having: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub qualify: Option<Rc<BooleanExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QuerySpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QuerySpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_querySpecification(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_querySpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QuerySpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_querySpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuerySpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySpecification }
}
antlr_rust::tid!{QuerySpecificationContextExt<'a>}

impl<'input> QuerySpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuerySpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuerySpecificationContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				where_: None, having: None, qualify: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QuerySpecificationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QuerySpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
fn querySelectItems(&self) -> Option<Rc<QuerySelectItemsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token TOP
/// Returns `None` if there is no child corresponding to token TOP
fn TOP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TOP, 0)
}
fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
fn relation_all(&self) ->  Vec<Rc<RelationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relation(&self, i: usize) -> Option<Rc<RelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
/// Retrieves first TerminalNode corresponding to token CONNECT
/// Returns `None` if there is no child corresponding to token CONNECT
fn CONNECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONNECT, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn aggregationClause(&self) -> Option<Rc<AggregationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
/// Retrieves first TerminalNode corresponding to token QUALIFY
/// Returns `None` if there is no child corresponding to token QUALIFY
fn QUALIFY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(QUALIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
fn windowDefinition_all(&self) ->  Vec<Rc<WindowDefinitionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn windowDefinition(&self, i: usize) -> Option<Rc<WindowDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token PRIOR
/// Returns `None` if there is no child corresponding to token PRIOR
fn PRIOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRIOR, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token GT
/// Returns `None` if there is no child corresponding to token GT
fn GT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GT, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves all `TerminalNode`s corresponding to token START in current rule
fn START_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token START, starting from 0.
/// Returns `None` if number of children corresponding to token START is less or equal than `i`.
fn START(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(START, i)
}
/// Retrieves all `TerminalNode`s corresponding to token WITH in current rule
fn WITH_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token WITH, starting from 0.
/// Returns `None` if number of children corresponding to token WITH is less or equal than `i`.
fn WITH(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITH, i)
}

}

impl<'input> QuerySpecificationContextAttrs<'input> for QuerySpecificationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn querySpecification(&mut self,)
	-> Result<Rc<QuerySpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuerySpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 106, RULE_querySpecification);
        let mut _localctx: Rc<QuerySpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1637);
			recog.base.match_token(SELECT,&mut recog.err_handler)?;

			recog.base.set_state(1640);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==TOP {
				{
				recog.base.set_state(1638);
				recog.base.match_token(TOP,&mut recog.err_handler)?;

				/*InvokeRule number*/
				recog.base.set_state(1639);
				recog.number()?;

				}
			}

			recog.base.set_state(1643);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(188,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule setQuantifier*/
					recog.base.set_state(1642);
					recog.setQuantifier()?;

					}
				}

				_ => {}
			}
			/*InvokeRule querySelectItems*/
			recog.base.set_state(1645);
			recog.querySelectItems()?;

			recog.base.set_state(1658);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==FROM {
				{
				recog.base.set_state(1646);
				recog.base.match_token(FROM,&mut recog.err_handler)?;

				/*InvokeRule relation*/
				recog.base.set_state(1647);
				recog.relation()?;

				recog.base.set_state(1652);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(189,&mut recog.base)?;
				while { _alt!=2 && _alt!=INVALID_ALT } {
					if _alt==1 {
						{
						{
						recog.base.set_state(1648);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule relation*/
						recog.base.set_state(1649);
						recog.relation()?;

						}
						} 
					}
					recog.base.set_state(1654);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(189,&mut recog.base)?;
				}
				recog.base.set_state(1656);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==COMMA {
					{
					recog.base.set_state(1655);
					let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
					 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).COMMA = Some(tmp);
					  

					let temp =  cast_mut::<_,QuerySpecificationContext >(&mut _localctx).COMMA.clone().unwrap()
					 ;
					 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).tail.push(temp);
					  
					}
				}

				}
			}

			recog.base.set_state(1662);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WHERE {
				{
				recog.base.set_state(1660);
				recog.base.match_token(WHERE,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1661);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).where_ = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1688);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==CONNECT || _la==START {
				{
				recog.base.set_state(1667);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==START {
					{
					recog.base.set_state(1664);
					recog.base.match_token(START,&mut recog.err_handler)?;

					recog.base.set_state(1665);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1666);
					recog.expression()?;

					}
				}

				recog.base.set_state(1669);
				recog.base.match_token(CONNECT,&mut recog.err_handler)?;

				recog.base.set_state(1670);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(1681);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(194,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(1671);
						recog.base.match_token(PRIOR,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(1672);
						recog.identifier()?;

						recog.base.set_state(1673);
						recog.base.match_token(EQ,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(1674);
						recog.expression()?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule expression*/
						recog.base.set_state(1676);
						recog.expression()?;

						recog.base.set_state(1677);
						recog.base.match_token(GT,&mut recog.err_handler)?;

						recog.base.set_state(1678);
						recog.base.match_token(PRIOR,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(1679);
						recog.identifier()?;

						}
					}

					_ => {}
				}
				recog.base.set_state(1686);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==START {
					{
					recog.base.set_state(1683);
					recog.base.match_token(START,&mut recog.err_handler)?;

					recog.base.set_state(1684);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1685);
					recog.expression()?;

					}
				}

				}
			}

			recog.base.set_state(1691);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==GROUP {
				{
				/*InvokeRule aggregationClause*/
				recog.base.set_state(1690);
				recog.aggregationClause()?;

				}
			}

			recog.base.set_state(1695);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==HAVING {
				{
				recog.base.set_state(1693);
				recog.base.match_token(HAVING,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1694);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).having = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1699);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==QUALIFY {
				{
				recog.base.set_state(1697);
				recog.base.match_token(QUALIFY,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1698);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).qualify = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1713);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WINDOW {
				{
				recog.base.set_state(1701);
				recog.base.match_token(WINDOW,&mut recog.err_handler)?;

				/*InvokeRule windowDefinition*/
				recog.base.set_state(1702);
				recog.windowDefinition()?;

				recog.base.set_state(1707);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(200,&mut recog.base)?;
				while { _alt!=2 && _alt!=INVALID_ALT } {
					if _alt==1 {
						{
						{
						recog.base.set_state(1703);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule windowDefinition*/
						recog.base.set_state(1704);
						recog.windowDefinition()?;

						}
						} 
					}
					recog.base.set_state(1709);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(200,&mut recog.base)?;
				}
				recog.base.set_state(1711);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==COMMA {
					{
					recog.base.set_state(1710);
					let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
					 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).COMMA = Some(tmp);
					  

					let temp =  cast_mut::<_,QuerySpecificationContext >(&mut _localctx).COMMA.clone().unwrap()
					 ;
					 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).tail.push(temp);
					  
					}
				}

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- querySelectItems ----------------
pub type QuerySelectItemsContextAll<'input> = QuerySelectItemsContext<'input>;


pub type QuerySelectItemsContext<'input> = BaseParserRuleContext<'input,QuerySelectItemsContextExt<'input>>;

#[derive(Clone)]
pub struct QuerySelectItemsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QuerySelectItemsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QuerySelectItemsContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_querySelectItems(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_querySelectItems(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QuerySelectItemsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_querySelectItems(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuerySelectItemsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySelectItems }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySelectItems }
}
antlr_rust::tid!{QuerySelectItemsContextExt<'a>}

impl<'input> QuerySelectItemsContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuerySelectItemsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuerySelectItemsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QuerySelectItemsContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QuerySelectItemsContextExt<'input>>{

fn selectItem_all(&self) ->  Vec<Rc<SelectItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn selectItem(&self, i: usize) -> Option<Rc<SelectItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QuerySelectItemsContextAttrs<'input> for QuerySelectItemsContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn querySelectItems(&mut self,)
	-> Result<Rc<QuerySelectItemsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuerySelectItemsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 108, RULE_querySelectItems);
        let mut _localctx: Rc<QuerySelectItemsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule selectItem*/
			recog.base.set_state(1715);
			recog.selectItem()?;

			recog.base.set_state(1720);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(203,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1716);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule selectItem*/
					recog.base.set_state(1717);
					recog.selectItem()?;

					}
					} 
				}
				recog.base.set_state(1722);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(203,&mut recog.base)?;
			}
			recog.base.set_state(1724);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1723);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,QuerySelectItemsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aggregationClause ----------------
pub type AggregationClauseContextAll<'input> = AggregationClauseContext<'input>;


pub type AggregationClauseContext<'input> = BaseParserRuleContext<'input,AggregationClauseContextExt<'input>>;

#[derive(Clone)]
pub struct AggregationClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for AggregationClauseContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AggregationClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aggregationClause(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_aggregationClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AggregationClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_aggregationClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for AggregationClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aggregationClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aggregationClause }
}
antlr_rust::tid!{AggregationClauseContextExt<'a>}

impl<'input> AggregationClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AggregationClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AggregationClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AggregationClauseContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<AggregationClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GROUP
/// Returns `None` if there is no child corresponding to token GROUP
fn GROUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn groupBy(&self) -> Option<Rc<GroupByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AggregationClauseContextAttrs<'input> for AggregationClauseContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aggregationClause(&mut self,)
	-> Result<Rc<AggregationClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AggregationClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 110, RULE_aggregationClause);
        let mut _localctx: Rc<AggregationClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1726);
			recog.base.match_token(GROUP,&mut recog.err_handler)?;

			recog.base.set_state(1727);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule groupBy*/
			recog.base.set_state(1728);
			recog.groupBy()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupBy ----------------
#[derive(Debug)]
pub enum GroupByContextAll<'input>{
	GroupByDefaultContext(GroupByDefaultContext<'input>),
Error(GroupByContext<'input>)
}
antlr_rust::tid!{GroupByContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GroupByContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for GroupByContextAll<'input>{}

impl<'input> Deref for GroupByContextAll<'input>{
	type Target = dyn GroupByContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GroupByContextAll::*;
		match self{
			GroupByDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for GroupByContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for GroupByContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GroupByContext<'input> = BaseParserRuleContext<'input,GroupByContextExt<'input>>;

#[derive(Clone)]
pub struct GroupByContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for GroupByContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for GroupByContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for GroupByContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GroupByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}
antlr_rust::tid!{GroupByContextExt<'a>}

impl<'input> GroupByContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupByContextAll<'input>> {
		Rc::new(
		GroupByContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupByContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GroupByContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<GroupByContextExt<'input>>{


}

impl<'input> GroupByContextAttrs<'input> for GroupByContext<'input>{}

pub type GroupByDefaultContext<'input> = BaseParserRuleContext<'input,GroupByDefaultContextExt<'input>>;

pub trait GroupByDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn groupingElement_all(&self) ->  Vec<Rc<GroupingElementContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn groupingElement(&self, i: usize) -> Option<Rc<GroupingElementContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> GroupByDefaultContextAttrs<'input> for GroupByDefaultContext<'input>{}

pub struct GroupByDefaultContextExt<'input>{
	base:GroupByContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GroupByDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for GroupByDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for GroupByDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_groupByDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_groupByDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for GroupByDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_groupByDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupByDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}

impl<'input> Borrow<GroupByContextExt<'input>> for GroupByDefaultContext<'input>{
	fn borrow(&self) -> &GroupByContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupByContextExt<'input>> for GroupByDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupByContextExt<'input> { &mut self.base }
}

impl<'input> GroupByContextAttrs<'input> for GroupByDefaultContext<'input> {}

impl<'input> GroupByDefaultContextExt<'input>{
	fn new(ctx: &dyn GroupByContextAttrs<'input>) -> Rc<GroupByContextAll<'input>>  {
		Rc::new(
			GroupByContextAll::GroupByDefaultContext(
				BaseParserRuleContext::copy_from(ctx,GroupByDefaultContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupBy(&mut self,)
	-> Result<Rc<GroupByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 112, RULE_groupBy);
        let mut _localctx: Rc<GroupByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = GroupByDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			recog.base.set_state(1731);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(205,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule setQuantifier*/
					recog.base.set_state(1730);
					recog.setQuantifier()?;

					}
				}

				_ => {}
			}
			/*InvokeRule groupingElement*/
			recog.base.set_state(1733);
			recog.groupingElement()?;

			recog.base.set_state(1738);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(206,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1734);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule groupingElement*/
					recog.base.set_state(1735);
					recog.groupingElement()?;

					}
					} 
				}
				recog.base.set_state(1740);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(206,&mut recog.base)?;
			}
			recog.base.set_state(1742);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1741);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				if let GroupByContextAll::GroupByDefaultContext(ctx) = cast_mut::<_,GroupByContextAll >(&mut _localctx){
				ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingElement ----------------
#[derive(Debug)]
pub enum GroupingElementContextAll<'input>{
	MultipleGroupingSetsContext(MultipleGroupingSetsContext<'input>),
	SingleGroupingSetContext(SingleGroupingSetContext<'input>),
	CubeContext(CubeContext<'input>),
	RollupContext(RollupContext<'input>),
Error(GroupingElementContext<'input>)
}
antlr_rust::tid!{GroupingElementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GroupingElementContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for GroupingElementContextAll<'input>{}

impl<'input> Deref for GroupingElementContextAll<'input>{
	type Target = dyn GroupingElementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GroupingElementContextAll::*;
		match self{
			MultipleGroupingSetsContext(inner) => inner,
			SingleGroupingSetContext(inner) => inner,
			CubeContext(inner) => inner,
			RollupContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for GroupingElementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for GroupingElementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GroupingElementContext<'input> = BaseParserRuleContext<'input,GroupingElementContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for GroupingElementContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for GroupingElementContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for GroupingElementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GroupingElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}
antlr_rust::tid!{GroupingElementContextExt<'a>}

impl<'input> GroupingElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingElementContextAll<'input>> {
		Rc::new(
		GroupingElementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingElementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GroupingElementContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<GroupingElementContextExt<'input>>{


}

impl<'input> GroupingElementContextAttrs<'input> for GroupingElementContext<'input>{}

pub type MultipleGroupingSetsContext<'input> = BaseParserRuleContext<'input,MultipleGroupingSetsContextExt<'input>>;

pub trait MultipleGroupingSetsContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token GROUPING
	/// Returns `None` if there is no child corresponding to token GROUPING
	fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(GROUPING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SETS
	/// Returns `None` if there is no child corresponding to token SETS
	fn SETS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SETS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn groupingSet_all(&self) ->  Vec<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn groupingSet(&self, i: usize) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> MultipleGroupingSetsContextAttrs<'input> for MultipleGroupingSetsContext<'input>{}

pub struct MultipleGroupingSetsContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MultipleGroupingSetsContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for MultipleGroupingSetsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for MultipleGroupingSetsContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_multipleGroupingSets(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_multipleGroupingSets(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for MultipleGroupingSetsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_multipleGroupingSets(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipleGroupingSetsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for MultipleGroupingSetsContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for MultipleGroupingSetsContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for MultipleGroupingSetsContext<'input> {}

impl<'input> MultipleGroupingSetsContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::MultipleGroupingSetsContext(
				BaseParserRuleContext::copy_from(ctx,MultipleGroupingSetsContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SingleGroupingSetContext<'input> = BaseParserRuleContext<'input,SingleGroupingSetContextExt<'input>>;

pub trait SingleGroupingSetContextAttrs<'input>: RedshiftParserContext<'input>{
	fn groupingSet(&self) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SingleGroupingSetContextAttrs<'input> for SingleGroupingSetContext<'input>{}

pub struct SingleGroupingSetContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleGroupingSetContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SingleGroupingSetContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SingleGroupingSetContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleGroupingSet(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_singleGroupingSet(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SingleGroupingSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_singleGroupingSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleGroupingSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for SingleGroupingSetContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for SingleGroupingSetContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for SingleGroupingSetContext<'input> {}

impl<'input> SingleGroupingSetContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::SingleGroupingSetContext(
				BaseParserRuleContext::copy_from(ctx,SingleGroupingSetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CubeContext<'input> = BaseParserRuleContext<'input,CubeContextExt<'input>>;

pub trait CubeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CUBE
	/// Returns `None` if there is no child corresponding to token CUBE
	fn CUBE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CUBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> CubeContextAttrs<'input> for CubeContext<'input>{}

pub struct CubeContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CubeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CubeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CubeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_cube(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_cube(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CubeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_cube(self);
	}
}

impl<'input> CustomRuleContext<'input> for CubeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for CubeContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for CubeContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for CubeContext<'input> {}

impl<'input> CubeContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::CubeContext(
				BaseParserRuleContext::copy_from(ctx,CubeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RollupContext<'input> = BaseParserRuleContext<'input,RollupContextExt<'input>>;

pub trait RollupContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLLUP
	/// Returns `None` if there is no child corresponding to token ROLLUP
	fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ROLLUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> RollupContextAttrs<'input> for RollupContext<'input>{}

pub struct RollupContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RollupContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RollupContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RollupContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rollup(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_rollup(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RollupContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rollup(self);
	}
}

impl<'input> CustomRuleContext<'input> for RollupContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for RollupContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for RollupContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for RollupContext<'input> {}

impl<'input> RollupContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::RollupContext(
				BaseParserRuleContext::copy_from(ctx,RollupContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingElement(&mut self,)
	-> Result<Rc<GroupingElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 114, RULE_groupingElement);
        let mut _localctx: Rc<GroupingElementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1793);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(216,&mut recog.base)? {
				1 =>{
					let tmp = RollupContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1744);
					recog.base.match_token(ROLLUP,&mut recog.err_handler)?;

					recog.base.set_state(1745);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1757);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONVERT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOT - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RIGHT - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (POSIX - 419)) | (1usize << (STRING - 419)) | (1usize << (UNICODE_STRING - 419)) | (1usize << (DOLLAR_QUOTED_STRING - 419)) | (1usize << (BINARY_LITERAL - 419)) | (1usize << (INTEGER_VALUE - 419)) | (1usize << (DECIMAL_VALUE - 419)) | (1usize << (DOUBLE_VALUE - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)) | (1usize << (VARIABLE - 419)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(1746);
						recog.expression()?;

						recog.base.set_state(1751);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(208,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(1747);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(1748);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(1753);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(208,&mut recog.base)?;
						}
						recog.base.set_state(1755);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(1754);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let GroupingElementContextAll::RollupContext(ctx) = cast_mut::<_,GroupingElementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(1759);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = CubeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1760);
					recog.base.match_token(CUBE,&mut recog.err_handler)?;

					recog.base.set_state(1761);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1773);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONVERT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOT - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RIGHT - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (POSIX - 419)) | (1usize << (STRING - 419)) | (1usize << (UNICODE_STRING - 419)) | (1usize << (DOLLAR_QUOTED_STRING - 419)) | (1usize << (BINARY_LITERAL - 419)) | (1usize << (INTEGER_VALUE - 419)) | (1usize << (DECIMAL_VALUE - 419)) | (1usize << (DOUBLE_VALUE - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)) | (1usize << (VARIABLE - 419)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(1762);
						recog.expression()?;

						recog.base.set_state(1767);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(211,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(1763);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(1764);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(1769);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(211,&mut recog.base)?;
						}
						recog.base.set_state(1771);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(1770);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let GroupingElementContextAll::CubeContext(ctx) = cast_mut::<_,GroupingElementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(1775);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = MultipleGroupingSetsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(1776);
					recog.base.match_token(GROUPING,&mut recog.err_handler)?;

					recog.base.set_state(1777);
					recog.base.match_token(SETS,&mut recog.err_handler)?;

					recog.base.set_state(1778);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule groupingSet*/
					recog.base.set_state(1779);
					recog.groupingSet()?;

					recog.base.set_state(1784);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(214,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(1780);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule groupingSet*/
							recog.base.set_state(1781);
							recog.groupingSet()?;

							}
							} 
						}
						recog.base.set_state(1786);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(214,&mut recog.base)?;
					}
					recog.base.set_state(1788);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(1787);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let GroupingElementContextAll::MultipleGroupingSetsContext(ctx) = cast_mut::<_,GroupingElementContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(1790);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = SingleGroupingSetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule groupingSet*/
					recog.base.set_state(1792);
					recog.groupingSet()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingSet ----------------
pub type GroupingSetContextAll<'input> = GroupingSetContext<'input>;


pub type GroupingSetContext<'input> = BaseParserRuleContext<'input,GroupingSetContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingSetContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for GroupingSetContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for GroupingSetContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingSet(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_groupingSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for GroupingSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_groupingSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupingSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingSet }
}
antlr_rust::tid!{GroupingSetContextExt<'a>}

impl<'input> GroupingSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingSetContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingSetContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<GroupingSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> GroupingSetContextAttrs<'input> for GroupingSetContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingSet(&mut self,)
	-> Result<Rc<GroupingSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 116, RULE_groupingSet);
        let mut _localctx: Rc<GroupingSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1811);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(220,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1795);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1804);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONVERT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOT - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RIGHT - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (POSIX - 419)) | (1usize << (STRING - 419)) | (1usize << (UNICODE_STRING - 419)) | (1usize << (DOLLAR_QUOTED_STRING - 419)) | (1usize << (BINARY_LITERAL - 419)) | (1usize << (INTEGER_VALUE - 419)) | (1usize << (DECIMAL_VALUE - 419)) | (1usize << (DOUBLE_VALUE - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)) | (1usize << (VARIABLE - 419)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(1796);
						recog.expression()?;

						recog.base.set_state(1801);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(217,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(1797);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(1798);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(1803);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(217,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(1807);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(1806);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,GroupingSetContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(1809);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expression*/
					recog.base.set_state(1810);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowDefinition ----------------
pub type WindowDefinitionContextAll<'input> = WindowDefinitionContext<'input>;


pub type WindowDefinitionContext<'input> = BaseParserRuleContext<'input,WindowDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct WindowDefinitionContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for WindowDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for WindowDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_windowDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for WindowDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_windowDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowDefinition }
}
antlr_rust::tid!{WindowDefinitionContextExt<'a>}

impl<'input> WindowDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowDefinitionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowDefinitionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<WindowDefinitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn windowSpecification(&self) -> Option<Rc<WindowSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowDefinitionContextAttrs<'input> for WindowDefinitionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowDefinition(&mut self,)
	-> Result<Rc<WindowDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 118, RULE_windowDefinition);
        let mut _localctx: Rc<WindowDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1813);
			let tmp = recog.identifier()?;
			 cast_mut::<_,WindowDefinitionContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(1814);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(1815);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule windowSpecification*/
			recog.base.set_state(1816);
			recog.windowSpecification()?;

			recog.base.set_state(1817);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowSpecification ----------------
pub type WindowSpecificationContextAll<'input> = WindowSpecificationContext<'input>;


pub type WindowSpecificationContext<'input> = BaseParserRuleContext<'input,WindowSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct WindowSpecificationContextExt<'input>{
	pub existingWindowName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for WindowSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for WindowSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowSpecification(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_windowSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for WindowSpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_windowSpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpecification }
}
antlr_rust::tid!{WindowSpecificationContextExt<'a>}

impl<'input> WindowSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowSpecificationContextExt{
				existingWindowName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowSpecificationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<WindowSpecificationContextExt<'input>>{

fn windowSpecificationPartitionBy(&self) -> Option<Rc<WindowSpecificationPartitionByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderBy(&self) -> Option<Rc<OrderByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn windowFrame(&self) -> Option<Rc<WindowFrameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowSpecificationContextAttrs<'input> for WindowSpecificationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowSpecification(&mut self,)
	-> Result<Rc<WindowSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 120, RULE_windowSpecification);
        let mut _localctx: Rc<WindowSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1820);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(221,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1819);
					let tmp = recog.identifier()?;
					 cast_mut::<_,WindowSpecificationContext >(&mut _localctx).existingWindowName = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(1823);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PARTITION {
				{
				/*InvokeRule windowSpecificationPartitionBy*/
				recog.base.set_state(1822);
				recog.windowSpecificationPartitionBy()?;

				}
			}

			recog.base.set_state(1826);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				/*InvokeRule orderBy*/
				recog.base.set_state(1825);
				recog.orderBy()?;

				}
			}

			recog.base.set_state(1829);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==GROUPS || _la==RANGE || _la==ROWS {
				{
				/*InvokeRule windowFrame*/
				recog.base.set_state(1828);
				recog.windowFrame()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowSpecificationPartitionBy ----------------
pub type WindowSpecificationPartitionByContextAll<'input> = WindowSpecificationPartitionByContext<'input>;


pub type WindowSpecificationPartitionByContext<'input> = BaseParserRuleContext<'input,WindowSpecificationPartitionByContextExt<'input>>;

#[derive(Clone)]
pub struct WindowSpecificationPartitionByContextExt<'input>{
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub partition:Vec<Rc<ExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for WindowSpecificationPartitionByContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for WindowSpecificationPartitionByContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowSpecificationPartitionBy(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_windowSpecificationPartitionBy(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for WindowSpecificationPartitionByContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_windowSpecificationPartitionBy(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowSpecificationPartitionByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpecificationPartitionBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpecificationPartitionBy }
}
antlr_rust::tid!{WindowSpecificationPartitionByContextExt<'a>}

impl<'input> WindowSpecificationPartitionByContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowSpecificationPartitionByContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowSpecificationPartitionByContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				expression: None, 
				partition: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowSpecificationPartitionByContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<WindowSpecificationPartitionByContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WindowSpecificationPartitionByContextAttrs<'input> for WindowSpecificationPartitionByContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowSpecificationPartitionBy(&mut self,)
	-> Result<Rc<WindowSpecificationPartitionByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowSpecificationPartitionByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 122, RULE_windowSpecificationPartitionBy);
        let mut _localctx: Rc<WindowSpecificationPartitionByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1831);
			recog.base.match_token(PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(1832);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1833);
			let tmp = recog.expression()?;
			 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression.clone().unwrap()
			 ;
			 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).partition.push(temp);
			  
			recog.base.set_state(1838);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(225,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1834);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1835);
					let tmp = recog.expression()?;
					 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).partition.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1840);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(225,&mut recog.base)?;
			}
			recog.base.set_state(1842);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1841);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderBy ----------------
pub type OrderByContextAll<'input> = OrderByContext<'input>;


pub type OrderByContext<'input> = BaseParserRuleContext<'input,OrderByContextExt<'input>>;

#[derive(Clone)]
pub struct OrderByContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for OrderByContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for OrderByContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderBy(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_orderBy(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for OrderByContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_orderBy(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrderByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderBy }
}
antlr_rust::tid!{OrderByContextExt<'a>}

impl<'input> OrderByContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderByContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderByContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderByContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<OrderByContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> OrderByContextAttrs<'input> for OrderByContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderBy(&mut self,)
	-> Result<Rc<OrderByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 124, RULE_orderBy);
        let mut _localctx: Rc<OrderByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1844);
			recog.base.match_token(ORDER,&mut recog.err_handler)?;

			recog.base.set_state(1845);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule sortItem*/
			recog.base.set_state(1846);
			recog.sortItem()?;

			recog.base.set_state(1851);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(227,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1847);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(1848);
					recog.sortItem()?;

					}
					} 
				}
				recog.base.set_state(1853);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(227,&mut recog.base)?;
			}
			recog.base.set_state(1855);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1854);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,OrderByContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,OrderByContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,OrderByContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedQuery ----------------
pub type NamedQueryContextAll<'input> = NamedQueryContext<'input>;


pub type NamedQueryContext<'input> = BaseParserRuleContext<'input,NamedQueryContextExt<'input>>;

#[derive(Clone)]
pub struct NamedQueryContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for NamedQueryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NamedQueryContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedQuery(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_namedQuery(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NamedQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_namedQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedQuery }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedQuery }
}
antlr_rust::tid!{NamedQueryContextExt<'a>}

impl<'input> NamedQueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedQueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedQueryContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedQueryContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<NamedQueryContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedQueryContextAttrs<'input> for NamedQueryContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedQuery(&mut self,)
	-> Result<Rc<NamedQueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedQueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 126, RULE_namedQuery);
        let mut _localctx: Rc<NamedQueryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1857);
			let tmp = recog.identifier()?;
			 cast_mut::<_,NamedQueryContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(1859);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)))) != 0) || ((((_la - 440)) & !0x3f) == 0 && ((1usize << (_la - 440)) & ((1usize << (IDENTIFIER - 440)) | (1usize << (DIGIT_IDENTIFIER - 440)) | (1usize << (QUOTED_IDENTIFIER - 440)))) != 0) {
				{
				/*InvokeRule columnAliases*/
				recog.base.set_state(1858);
				recog.columnAliases()?;

				}
			}

			recog.base.set_state(1861);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(1862);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule query*/
			recog.base.set_state(1863);
			recog.query()?;

			recog.base.set_state(1864);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectItemAlias ----------------
pub type SelectItemAliasContextAll<'input> = SelectItemAliasContext<'input>;


pub type SelectItemAliasContext<'input> = BaseParserRuleContext<'input,SelectItemAliasContextExt<'input>>;

#[derive(Clone)]
pub struct SelectItemAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SelectItemAliasContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SelectItemAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectItemAlias(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_selectItemAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SelectItemAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_selectItemAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectItemAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItemAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItemAlias }
}
antlr_rust::tid!{SelectItemAliasContextExt<'a>}

impl<'input> SelectItemAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectItemAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectItemAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectItemAliasContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SelectItemAliasContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictNonReserved(&self) -> Option<Rc<StrictNonReservedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SelectItemAliasContextAttrs<'input> for SelectItemAliasContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectItemAlias(&mut self,)
	-> Result<Rc<SelectItemAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectItemAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 128, RULE_selectItemAlias);
        let mut _localctx: Rc<SelectItemAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1868);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
			 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
			 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
			 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEVEL | LIBRARY | LIKE | LIMIT |
			 LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK | LOGICAL |
			 M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE | MATERIALIZED |
			 MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES | MERGE | MIN |
			 MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC | NFD | NFKC |
			 NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS | OBJECT | OF |
			 OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR | ORDER | ORDINALITY |
			 OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW | PARTITION | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENTILE_CONT |
			 PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG | PIVOT | POSITION |
			 PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIMARY | PRIVILEGES |
			 PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE | READ | RECURSIVE | REFERENCES |
			 REFRESH | RENAME | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROLLUP | ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND |
			 SECONDS | SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE |
			 SERDEPROPERTIES | SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR |
			 SOME | SORTKEY | SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET |
			 SUBSTRING | SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY |
			 TERMINATED | TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO |
			 TRAILING | TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE |
			 TYPE | UESCAPE | UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE |
			 UNKNOWN | UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER |
			 UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING |
			 VARIADIC | VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW |
			 WITH | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
			 ZSTD | LBRACKET | IDENTIFIER | DIGIT_IDENTIFIER | DOLLAR_HASH_IDENTIFIER |
			 QUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule columnName*/
					recog.base.set_state(1866);
					recog.columnName()?;

					}
				}

			 CONVERT | CROSS | FULL | INNER | LEFT | MINUS_KW | NATURAL | NOT | OUTER |
			 RIGHT | USING | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule strictNonReserved*/
					recog.base.set_state(1867);
					recog.strictNonReserved()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectItem ----------------
#[derive(Debug)]
pub enum SelectItemContextAll<'input>{
	SelectSingleContext(SelectSingleContext<'input>),
	SelectMultiContext(SelectMultiContext<'input>),
Error(SelectItemContext<'input>)
}
antlr_rust::tid!{SelectItemContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SelectItemContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for SelectItemContextAll<'input>{}

impl<'input> Deref for SelectItemContextAll<'input>{
	type Target = dyn SelectItemContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SelectItemContextAll::*;
		match self{
			SelectSingleContext(inner) => inner,
			SelectMultiContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SelectItemContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SelectItemContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SelectItemContext<'input> = BaseParserRuleContext<'input,SelectItemContextExt<'input>>;

#[derive(Clone)]
pub struct SelectItemContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SelectItemContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SelectItemContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SelectItemContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SelectItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}
antlr_rust::tid!{SelectItemContextExt<'a>}

impl<'input> SelectItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectItemContextAll<'input>> {
		Rc::new(
		SelectItemContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectItemContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SelectItemContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SelectItemContextExt<'input>>{


}

impl<'input> SelectItemContextAttrs<'input> for SelectItemContext<'input>{}

pub type SelectSingleContext<'input> = BaseParserRuleContext<'input,SelectSingleContextExt<'input>>;

pub trait SelectSingleContextAttrs<'input>: RedshiftParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn selectItemAlias(&self) -> Option<Rc<SelectItemAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> SelectSingleContextAttrs<'input> for SelectSingleContext<'input>{}

pub struct SelectSingleContextExt<'input>{
	base:SelectItemContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SelectSingleContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SelectSingleContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SelectSingleContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_selectSingle(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_selectSingle(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SelectSingleContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_selectSingle(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectSingleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}

impl<'input> Borrow<SelectItemContextExt<'input>> for SelectSingleContext<'input>{
	fn borrow(&self) -> &SelectItemContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SelectItemContextExt<'input>> for SelectSingleContext<'input>{
	fn borrow_mut(&mut self) -> &mut SelectItemContextExt<'input> { &mut self.base }
}

impl<'input> SelectItemContextAttrs<'input> for SelectSingleContext<'input> {}

impl<'input> SelectSingleContextExt<'input>{
	fn new(ctx: &dyn SelectItemContextAttrs<'input>) -> Rc<SelectItemContextAll<'input>>  {
		Rc::new(
			SelectItemContextAll::SelectSingleContext(
				BaseParserRuleContext::copy_from(ctx,SelectSingleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SelectMultiContext<'input> = BaseParserRuleContext<'input,SelectMultiContextExt<'input>>;

pub trait SelectMultiContextAttrs<'input>: RedshiftParserContext<'input>{
	fn multiSelect(&self) -> Option<Rc<MultiSelectContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SelectMultiContextAttrs<'input> for SelectMultiContext<'input>{}

pub struct SelectMultiContextExt<'input>{
	base:SelectItemContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SelectMultiContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SelectMultiContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SelectMultiContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_selectMulti(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_selectMulti(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SelectMultiContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_selectMulti(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectMultiContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}

impl<'input> Borrow<SelectItemContextExt<'input>> for SelectMultiContext<'input>{
	fn borrow(&self) -> &SelectItemContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SelectItemContextExt<'input>> for SelectMultiContext<'input>{
	fn borrow_mut(&mut self) -> &mut SelectItemContextExt<'input> { &mut self.base }
}

impl<'input> SelectItemContextAttrs<'input> for SelectMultiContext<'input> {}

impl<'input> SelectMultiContextExt<'input>{
	fn new(ctx: &dyn SelectItemContextAttrs<'input>) -> Rc<SelectItemContextAll<'input>>  {
		Rc::new(
			SelectItemContextAll::SelectMultiContext(
				BaseParserRuleContext::copy_from(ctx,SelectMultiContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectItem(&mut self,)
	-> Result<Rc<SelectItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 130, RULE_selectItem);
        let mut _localctx: Rc<SelectItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1878);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(233,&mut recog.base)? {
				1 =>{
					let tmp = SelectSingleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(1870);
					recog.expression()?;

					recog.base.set_state(1875);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(232,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1872);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==AS {
								{
								recog.base.set_state(1871);
								recog.base.match_token(AS,&mut recog.err_handler)?;

								}
							}

							/*InvokeRule selectItemAlias*/
							recog.base.set_state(1874);
							recog.selectItemAlias()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = SelectMultiContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule multiSelect*/
					recog.base.set_state(1877);
					recog.multiSelect()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiSelect ----------------
pub type MultiSelectContextAll<'input> = MultiSelectContext<'input>;


pub type MultiSelectContext<'input> = BaseParserRuleContext<'input,MultiSelectContextExt<'input>>;

#[derive(Clone)]
pub struct MultiSelectContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for MultiSelectContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for MultiSelectContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiSelect(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_multiSelect(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for MultiSelectContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_multiSelect(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiSelectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiSelect }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiSelect }
}
antlr_rust::tid!{MultiSelectContextExt<'a>}

impl<'input> MultiSelectContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiSelectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiSelectContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiSelectContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<MultiSelectContextExt<'input>>{

fn selectStar(&self) -> Option<Rc<SelectStarContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MultiSelectContextAttrs<'input> for MultiSelectContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiSelect(&mut self,)
	-> Result<Rc<MultiSelectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiSelectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 132, RULE_multiSelect);
        let mut _localctx: Rc<MultiSelectContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule selectStar*/
			recog.base.set_state(1880);
			recog.selectStar()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectStar ----------------
pub type SelectStarContextAll<'input> = SelectStarContext<'input>;


pub type SelectStarContext<'input> = BaseParserRuleContext<'input,SelectStarContextExt<'input>>;

#[derive(Clone)]
pub struct SelectStarContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SelectStarContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SelectStarContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectStar(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_selectStar(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SelectStarContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_selectStar(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectStarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectStar }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectStar }
}
antlr_rust::tid!{SelectStarContextExt<'a>}

impl<'input> SelectStarContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectStarContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectStarContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectStarContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SelectStarContextExt<'input>>{

fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}

}

impl<'input> SelectStarContextAttrs<'input> for SelectStarContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectStar(&mut self,)
	-> Result<Rc<SelectStarContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectStarContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 134, RULE_selectStar);
        let mut _localctx: Rc<SelectStarContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1887);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | CONVERT | COPARTITION | COPY | COUNT |
			 CREATE | CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE |
			 DATE | DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE |
			 DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEFT | LEVEL | LIBRARY | LIKE |
			 LIMIT | LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK |
			 LOGICAL | M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE |
			 MATERIALIZED | MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES |
			 MERGE | MIN | MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC |
			 NFD | NFKC | NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS |
			 OBJECT | OF | OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR |
			 ORDER | ORDINALITY | OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW |
			 PARTITION | PARTITIONED | PARTITIONS | PASSING | PAST | PATH | PATTERN |
			 PER | PERCENTILE_CONT | PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG |
			 PIVOT | POSITION | PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE |
			 PRIMARY | PRIVILEGES | PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE |
			 READ | RECURSIVE | REFERENCES | REFRESH | RENAME | REPEATABLE | REPLACE |
			 RESET | RESPECT | RESTRICT | RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE |
			 RIGHT | RLS | ROLE | ROLES | ROLLBACK | ROLLUP | ROW | ROWS | RUNNING |
			 S | SAGEMAKER | SCALAR | SEC | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SEEK | SELECT | SEMI | SERDE | SERDEPROPERTIES | SERIALIZABLE |
			 SESSION | SET | SETS | SHOW | SIMILAR | SOME | SORTKEY | SQL | STABLE |
			 START | STATS | STORED | STRUCT | SUBSET | SUBSTRING | SYSTEM_TIME |
			 TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY | TERMINATED | TEXT |
			 STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO | TRAILING | TRANSACTION |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE | TYPE | UESCAPE | UNBOUNDED |
			 UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE | UNKNOWN | UNMATCHED |
			 UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER | UTF16 | UTF32 | UTF8 |
			 VACUUM | VALIDATE | VALUE | VALUES | VARYING | VARIADIC | VERBOSE | VERSION |
			 VIEW | VOLATILE | WEEK | WHEN | WINDOW | WITH | WITHOUT | WORK | WRAPPER |
			 WRITE | XZ | YEAR | YEARS | YES | ZONE | ZSTD | LPAREN | LBRACKET | MINUS |
			 DOLLAR | STRING | UNICODE_STRING | DOLLAR_QUOTED_STRING | BINARY_LITERAL |
			 INTEGER_VALUE | DECIMAL_VALUE | DOUBLE_VALUE | IDENTIFIER | DIGIT_IDENTIFIER |
			 DOLLAR_HASH_IDENTIFIER | QUOTED_IDENTIFIER | VARIABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule primaryExpression*/
					recog.base.set_state(1882);
					recog.primaryExpression_rec(0)?;

					recog.base.set_state(1883);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					recog.base.set_state(1884);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}

			 ASTERISK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1886);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relation ----------------
pub type RelationContextAll<'input> = RelationContext<'input>;


pub type RelationContext<'input> = BaseParserRuleContext<'input,RelationContextExt<'input>>;

#[derive(Clone)]
pub struct RelationContextExt<'input>{
	pub target: Option<Rc<PivotedRelationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RelationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relation(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_relation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_relation(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relation }
}
antlr_rust::tid!{RelationContextExt<'a>}

impl<'input> RelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationContextExt{
				target: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RelationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RelationContextExt<'input>>{

fn pivotedRelation(&self) -> Option<Rc<PivotedRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RelationContextAttrs<'input> for RelationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relation(&mut self,)
	-> Result<Rc<RelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 136, RULE_relation);
        let mut _localctx: Rc<RelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule pivotedRelation*/
			recog.base.set_state(1889);
			let tmp = recog.pivotedRelation()?;
			 cast_mut::<_,RelationContext >(&mut _localctx).target = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinedRelation ----------------
#[derive(Debug)]
pub enum JoinedRelationContextAll<'input>{
	RelationDefaultContext(RelationDefaultContext<'input>),
	JoinRelationContext(JoinRelationContext<'input>),
Error(JoinedRelationContext<'input>)
}
antlr_rust::tid!{JoinedRelationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for JoinedRelationContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for JoinedRelationContextAll<'input>{}

impl<'input> Deref for JoinedRelationContextAll<'input>{
	type Target = dyn JoinedRelationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use JoinedRelationContextAll::*;
		match self{
			RelationDefaultContext(inner) => inner,
			JoinRelationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JoinedRelationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JoinedRelationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type JoinedRelationContext<'input> = BaseParserRuleContext<'input,JoinedRelationContextExt<'input>>;

#[derive(Clone)]
pub struct JoinedRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JoinedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JoinedRelationContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JoinedRelationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for JoinedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinedRelation }
}
antlr_rust::tid!{JoinedRelationContextExt<'a>}

impl<'input> JoinedRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinedRelationContextAll<'input>> {
		Rc::new(
		JoinedRelationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinedRelationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait JoinedRelationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JoinedRelationContextExt<'input>>{


}

impl<'input> JoinedRelationContextAttrs<'input> for JoinedRelationContext<'input>{}

pub type RelationDefaultContext<'input> = BaseParserRuleContext<'input,RelationDefaultContextExt<'input>>;

pub trait RelationDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn noJoinRelation(&self) -> Option<Rc<NoJoinRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RelationDefaultContextAttrs<'input> for RelationDefaultContext<'input>{}

pub struct RelationDefaultContextExt<'input>{
	base:JoinedRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RelationDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RelationDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RelationDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_relationDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_relationDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RelationDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_relationDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinedRelation }
}

impl<'input> Borrow<JoinedRelationContextExt<'input>> for RelationDefaultContext<'input>{
	fn borrow(&self) -> &JoinedRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<JoinedRelationContextExt<'input>> for RelationDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut JoinedRelationContextExt<'input> { &mut self.base }
}

impl<'input> JoinedRelationContextAttrs<'input> for RelationDefaultContext<'input> {}

impl<'input> RelationDefaultContextExt<'input>{
	fn new(ctx: &dyn JoinedRelationContextAttrs<'input>) -> Rc<JoinedRelationContextAll<'input>>  {
		Rc::new(
			JoinedRelationContextAll::RelationDefaultContext(
				BaseParserRuleContext::copy_from(ctx,RelationDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JoinRelationContext<'input> = BaseParserRuleContext<'input,JoinRelationContextExt<'input>>;

pub trait JoinRelationContextAttrs<'input>: RedshiftParserContext<'input>{
	fn joinedRelation_all(&self) ->  Vec<Rc<JoinedRelationContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn joinedRelation(&self, i: usize) -> Option<Rc<JoinedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token CROSS
	/// Returns `None` if there is no child corresponding to token CROSS
	fn CROSS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CROSS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token JOIN
	/// Returns `None` if there is no child corresponding to token JOIN
	fn JOIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(JOIN, 0)
	}
	fn joinType(&self) -> Option<Rc<JoinTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NATURAL
	/// Returns `None` if there is no child corresponding to token NATURAL
	fn NATURAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NATURAL, 0)
	}
	fn noJoinRelation(&self) -> Option<Rc<NoJoinRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn joinCriteria(&self) -> Option<Rc<JoinCriteriaContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> JoinRelationContextAttrs<'input> for JoinRelationContext<'input>{}

pub struct JoinRelationContextExt<'input>{
	base:JoinedRelationContextExt<'input>,
	pub left: Option<Rc<JoinedRelationContextAll<'input>>>,
	pub right: Option<Rc<NoJoinRelationContextAll<'input>>>,
	pub rightJoined: Option<Rc<JoinedRelationContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JoinRelationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for JoinRelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JoinRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_joinRelation(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_joinRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JoinRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_joinRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinedRelation }
}

impl<'input> Borrow<JoinedRelationContextExt<'input>> for JoinRelationContext<'input>{
	fn borrow(&self) -> &JoinedRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<JoinedRelationContextExt<'input>> for JoinRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut JoinedRelationContextExt<'input> { &mut self.base }
}

impl<'input> JoinedRelationContextAttrs<'input> for JoinRelationContext<'input> {}

impl<'input> JoinRelationContextExt<'input>{
	fn new(ctx: &dyn JoinedRelationContextAttrs<'input>) -> Rc<JoinedRelationContextAll<'input>>  {
		Rc::new(
			JoinedRelationContextAll::JoinRelationContext(
				BaseParserRuleContext::copy_from(ctx,JoinRelationContextExt{
        			left:None, right:None, rightJoined:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  joinedRelation(&mut self,)
	-> Result<Rc<JoinedRelationContextAll<'input>>,ANTLRError> {
		self.joinedRelation_rec(0)
	}

	fn joinedRelation_rec(&mut self, _p: isize)
	-> Result<Rc<JoinedRelationContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = JoinedRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 138, RULE_joinedRelation, _p);
	    let mut _localctx: Rc<JoinedRelationContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 138;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			{
			let mut tmp = RelationDefaultContextExt::new(&**_localctx);
			recog.ctx = Some(tmp.clone());
			_localctx = tmp;
			_prevctx = _localctx.clone();


			/*InvokeRule noJoinRelation*/
			recog.base.set_state(1892);
			recog.noJoinRelation()?;

			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(1919);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(238,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					{
					/*recRuleLabeledAltStartAction*/
					let mut tmp = JoinRelationContextExt::new(&**JoinedRelationContextExt::new(_parentctx.clone(), _parentState));
					if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut tmp){
						ctx.left = Some(_prevctx.clone());
					} else {unreachable!("cant cast");}
					recog.push_new_recursion_context(tmp.clone(), _startState, RULE_joinedRelation);
					_localctx = tmp;
					recog.base.set_state(1894);
					if !({recog.precpred(None, 2)}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
					}
					recog.base.set_state(1915);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(237,&mut recog.base)? {
						1 =>{
							{
							recog.base.set_state(1895);
							recog.base.match_token(CROSS,&mut recog.err_handler)?;

							recog.base.set_state(1896);
							recog.base.match_token(JOIN,&mut recog.err_handler)?;

							/*InvokeRule noJoinRelation*/
							recog.base.set_state(1897);
							let tmp = recog.noJoinRelation()?;
							if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*InvokeRule joinType*/
							recog.base.set_state(1898);
							recog.joinType()?;

							recog.base.set_state(1899);
							recog.base.match_token(JOIN,&mut recog.err_handler)?;

							/*InvokeRule noJoinRelation*/
							recog.base.set_state(1900);
							let tmp = recog.noJoinRelation()?;
							if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(1902);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(235,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule joinCriteria*/
									recog.base.set_state(1901);
									recog.joinCriteria()?;

									}
								}

								_ => {}
							}
							}
						}
					,
						3 =>{
							{
							/*InvokeRule joinType*/
							recog.base.set_state(1904);
							recog.joinType()?;

							recog.base.set_state(1905);
							recog.base.match_token(JOIN,&mut recog.err_handler)?;

							/*InvokeRule joinedRelation*/
							recog.base.set_state(1906);
							let tmp = recog.joinedRelation_rec(0)?;
							if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut _localctx){
							ctx.rightJoined = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(1908);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(236,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule joinCriteria*/
									recog.base.set_state(1907);
									recog.joinCriteria()?;

									}
								}

								_ => {}
							}
							}
						}
					,
						4 =>{
							{
							recog.base.set_state(1910);
							recog.base.match_token(NATURAL,&mut recog.err_handler)?;

							/*InvokeRule joinType*/
							recog.base.set_state(1911);
							recog.joinType()?;

							recog.base.set_state(1912);
							recog.base.match_token(JOIN,&mut recog.err_handler)?;

							/*InvokeRule noJoinRelation*/
							recog.base.set_state(1913);
							let tmp = recog.noJoinRelation()?;
							if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
					} 
				}
				recog.base.set_state(1921);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(238,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- joinType ----------------
pub type JoinTypeContextAll<'input> = JoinTypeContext<'input>;


pub type JoinTypeContext<'input> = BaseParserRuleContext<'input,JoinTypeContextExt<'input>>;

#[derive(Clone)]
pub struct JoinTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JoinTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JoinTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinType(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_joinType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JoinTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_joinType(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinType }
}
antlr_rust::tid!{JoinTypeContextExt<'a>}

impl<'input> JoinTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinTypeContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JoinTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}

}

impl<'input> JoinTypeContextAttrs<'input> for JoinTypeContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinType(&mut self,)
	-> Result<Rc<JoinTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 140, RULE_joinType);
        let mut _localctx: Rc<JoinTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1937);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INNER | JOIN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1923);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INNER {
						{
						recog.base.set_state(1922);
						recog.base.match_token(INNER,&mut recog.err_handler)?;

						}
					}

					}
				}

			 LEFT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1925);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					recog.base.set_state(1927);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(1926);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}

			 RIGHT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1929);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					recog.base.set_state(1931);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(1930);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}

			 FULL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(1933);
					recog.base.match_token(FULL,&mut recog.err_handler)?;

					recog.base.set_state(1935);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(1934);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinCriteria ----------------
pub type JoinCriteriaContextAll<'input> = JoinCriteriaContext<'input>;


pub type JoinCriteriaContext<'input> = BaseParserRuleContext<'input,JoinCriteriaContextExt<'input>>;

#[derive(Clone)]
pub struct JoinCriteriaContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JoinCriteriaContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JoinCriteriaContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinCriteria(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_joinCriteria(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JoinCriteriaContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_joinCriteria(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinCriteriaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinCriteria }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinCriteria }
}
antlr_rust::tid!{JoinCriteriaContextExt<'a>}

impl<'input> JoinCriteriaContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinCriteriaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinCriteriaContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinCriteriaContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JoinCriteriaContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> JoinCriteriaContextAttrs<'input> for JoinCriteriaContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinCriteria(&mut self,)
	-> Result<Rc<JoinCriteriaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinCriteriaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 142, RULE_joinCriteria);
        let mut _localctx: Rc<JoinCriteriaContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1956);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ON 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1939);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(1940);
					recog.booleanExpression_rec(0)?;

					}
				}

			 USING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1941);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					recog.base.set_state(1942);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1943);
					recog.identifier()?;

					recog.base.set_state(1948);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(244,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(1944);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(1945);
							recog.identifier()?;

							}
							} 
						}
						recog.base.set_state(1950);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(244,&mut recog.base)?;
					}
					recog.base.set_state(1952);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(1951);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,JoinCriteriaContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(1954);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- noJoinRelation ----------------
pub type NoJoinRelationContextAll<'input> = NoJoinRelationContext<'input>;


pub type NoJoinRelationContext<'input> = BaseParserRuleContext<'input,NoJoinRelationContextExt<'input>>;

#[derive(Clone)]
pub struct NoJoinRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for NoJoinRelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NoJoinRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_noJoinRelation(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_noJoinRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NoJoinRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_noJoinRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for NoJoinRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_noJoinRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_noJoinRelation }
}
antlr_rust::tid!{NoJoinRelationContextExt<'a>}

impl<'input> NoJoinRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NoJoinRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NoJoinRelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NoJoinRelationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<NoJoinRelationContextExt<'input>>{

fn relationPrimary(&self) -> Option<Rc<RelationPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NoJoinRelationContextAttrs<'input> for NoJoinRelationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn noJoinRelation(&mut self,)
	-> Result<Rc<NoJoinRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NoJoinRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 144, RULE_noJoinRelation);
        let mut _localctx: Rc<NoJoinRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule relationPrimary*/
			recog.base.set_state(1958);
			recog.relationPrimary()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- trimsSpecification ----------------
pub type TrimsSpecificationContextAll<'input> = TrimsSpecificationContext<'input>;


pub type TrimsSpecificationContext<'input> = BaseParserRuleContext<'input,TrimsSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct TrimsSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TrimsSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TrimsSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_trimsSpecification(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_trimsSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TrimsSpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_trimsSpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for TrimsSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_trimsSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_trimsSpecification }
}
antlr_rust::tid!{TrimsSpecificationContextExt<'a>}

impl<'input> TrimsSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TrimsSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TrimsSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TrimsSpecificationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TrimsSpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEADING
/// Returns `None` if there is no child corresponding to token LEADING
fn LEADING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LEADING, 0)
}
/// Retrieves first TerminalNode corresponding to token TRAILING
/// Returns `None` if there is no child corresponding to token TRAILING
fn TRAILING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRAILING, 0)
}
/// Retrieves first TerminalNode corresponding to token BOTH
/// Returns `None` if there is no child corresponding to token BOTH
fn BOTH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BOTH, 0)
}

}

impl<'input> TrimsSpecificationContextAttrs<'input> for TrimsSpecificationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn trimsSpecification(&mut self,)
	-> Result<Rc<TrimsSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TrimsSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 146, RULE_trimsSpecification);
        let mut _localctx: Rc<TrimsSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1960);
			_la = recog.base.input.la(1);
			if { !(_la==BOTH || _la==LEADING || _la==TRAILING) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- listAggOverflowBehavior ----------------
pub type ListAggOverflowBehaviorContextAll<'input> = ListAggOverflowBehaviorContext<'input>;


pub type ListAggOverflowBehaviorContext<'input> = BaseParserRuleContext<'input,ListAggOverflowBehaviorContextExt<'input>>;

#[derive(Clone)]
pub struct ListAggOverflowBehaviorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ListAggOverflowBehaviorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ListAggOverflowBehaviorContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_listAggOverflowBehavior(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_listAggOverflowBehavior(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ListAggOverflowBehaviorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_listAggOverflowBehavior(self);
	}
}

impl<'input> CustomRuleContext<'input> for ListAggOverflowBehaviorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_listAggOverflowBehavior }
	//fn type_rule_index() -> usize where Self: Sized { RULE_listAggOverflowBehavior }
}
antlr_rust::tid!{ListAggOverflowBehaviorContextExt<'a>}

impl<'input> ListAggOverflowBehaviorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ListAggOverflowBehaviorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ListAggOverflowBehaviorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ListAggOverflowBehaviorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ListAggOverflowBehaviorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ERROR
/// Returns `None` if there is no child corresponding to token ERROR
fn ERROR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ERROR, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUNCATE
/// Returns `None` if there is no child corresponding to token TRUNCATE
fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRUNCATE, 0)
}
fn listaggCountIndication(&self) -> Option<Rc<ListaggCountIndicationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ListAggOverflowBehaviorContextAttrs<'input> for ListAggOverflowBehaviorContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn listAggOverflowBehavior(&mut self,)
	-> Result<Rc<ListAggOverflowBehaviorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ListAggOverflowBehaviorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 148, RULE_listAggOverflowBehavior);
        let mut _localctx: Rc<ListAggOverflowBehaviorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1968);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ERROR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1962);
					recog.base.match_token(ERROR,&mut recog.err_handler)?;

					}
				}

			 TRUNCATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1963);
					recog.base.match_token(TRUNCATE,&mut recog.err_handler)?;

					recog.base.set_state(1965);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if ((((_la - 433)) & !0x3f) == 0 && ((1usize << (_la - 433)) & ((1usize << (STRING - 433)) | (1usize << (UNICODE_STRING - 433)) | (1usize << (DOLLAR_QUOTED_STRING - 433)))) != 0) {
						{
						/*InvokeRule string*/
						recog.base.set_state(1964);
						recog.string()?;

						}
					}

					/*InvokeRule listaggCountIndication*/
					recog.base.set_state(1967);
					recog.listaggCountIndication()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- listaggCountIndication ----------------
pub type ListaggCountIndicationContextAll<'input> = ListaggCountIndicationContext<'input>;


pub type ListaggCountIndicationContext<'input> = BaseParserRuleContext<'input,ListaggCountIndicationContextExt<'input>>;

#[derive(Clone)]
pub struct ListaggCountIndicationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ListaggCountIndicationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ListaggCountIndicationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_listaggCountIndication(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_listaggCountIndication(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ListaggCountIndicationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_listaggCountIndication(self);
	}
}

impl<'input> CustomRuleContext<'input> for ListaggCountIndicationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_listaggCountIndication }
	//fn type_rule_index() -> usize where Self: Sized { RULE_listaggCountIndication }
}
antlr_rust::tid!{ListaggCountIndicationContextExt<'a>}

impl<'input> ListaggCountIndicationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ListaggCountIndicationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ListaggCountIndicationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ListaggCountIndicationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ListaggCountIndicationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token COUNT
/// Returns `None` if there is no child corresponding to token COUNT
fn COUNT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COUNT, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHOUT
/// Returns `None` if there is no child corresponding to token WITHOUT
fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITHOUT, 0)
}

}

impl<'input> ListaggCountIndicationContextAttrs<'input> for ListaggCountIndicationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn listaggCountIndication(&mut self,)
	-> Result<Rc<ListaggCountIndicationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ListaggCountIndicationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 150, RULE_listaggCountIndication);
        let mut _localctx: Rc<ListaggCountIndicationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1974);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 WITH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1970);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(1971);
					recog.base.match_token(COUNT,&mut recog.err_handler)?;

					}
				}

			 WITHOUT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1972);
					recog.base.match_token(WITHOUT,&mut recog.err_handler)?;

					recog.base.set_state(1973);
					recog.base.match_token(COUNT,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- variableDefinition ----------------
pub type VariableDefinitionContextAll<'input> = VariableDefinitionContext<'input>;


pub type VariableDefinitionContext<'input> = BaseParserRuleContext<'input,VariableDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct VariableDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for VariableDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for VariableDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_variableDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_variableDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for VariableDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_variableDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for VariableDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_variableDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_variableDefinition }
}
antlr_rust::tid!{VariableDefinitionContextExt<'a>}

impl<'input> VariableDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VariableDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VariableDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VariableDefinitionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<VariableDefinitionContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> VariableDefinitionContextAttrs<'input> for VariableDefinitionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn variableDefinition(&mut self,)
	-> Result<Rc<VariableDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VariableDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 152, RULE_variableDefinition);
        let mut _localctx: Rc<VariableDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1976);
			recog.identifier()?;

			recog.base.set_state(1977);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1978);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotedRelationTarget ----------------
pub type PivotedRelationTargetContextAll<'input> = PivotedRelationTargetContext<'input>;


pub type PivotedRelationTargetContext<'input> = BaseParserRuleContext<'input,PivotedRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct PivotedRelationTargetContextExt<'input>{
	pub target: Option<Rc<JoinedRelationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PivotedRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotedRelationTargetContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotedRelationTarget(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_pivotedRelationTarget(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotedRelationTargetContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pivotedRelationTarget(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotedRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotedRelationTarget }
}
antlr_rust::tid!{PivotedRelationTargetContextExt<'a>}

impl<'input> PivotedRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotedRelationTargetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotedRelationTargetContextExt{
				target: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotedRelationTargetContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PivotedRelationTargetContextExt<'input>>{

fn joinedRelation(&self) -> Option<Rc<JoinedRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PivotedRelationTargetContextAttrs<'input> for PivotedRelationTargetContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotedRelationTarget(&mut self,)
	-> Result<Rc<PivotedRelationTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotedRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 154, RULE_pivotedRelationTarget);
        let mut _localctx: Rc<PivotedRelationTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule joinedRelation*/
			recog.base.set_state(1980);
			let tmp = recog.joinedRelation_rec(0)?;
			 cast_mut::<_,PivotedRelationTargetContext >(&mut _localctx).target = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotedRelation ----------------
#[derive(Debug)]
pub enum PivotedRelationContextAll<'input>{
	ParenthesizedPivotedRelationContext(ParenthesizedPivotedRelationContext<'input>),
	PivotedRelationDefaultContext(PivotedRelationDefaultContext<'input>),
Error(PivotedRelationContext<'input>)
}
antlr_rust::tid!{PivotedRelationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotedRelationContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PivotedRelationContextAll<'input>{}

impl<'input> Deref for PivotedRelationContextAll<'input>{
	type Target = dyn PivotedRelationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotedRelationContextAll::*;
		match self{
			ParenthesizedPivotedRelationContext(inner) => inner,
			PivotedRelationDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotedRelationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotedRelationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotedRelationContext<'input> = BaseParserRuleContext<'input,PivotedRelationContextExt<'input>>;

#[derive(Clone)]
pub struct PivotedRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PivotedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotedRelationContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotedRelationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotedRelation }
}
antlr_rust::tid!{PivotedRelationContextExt<'a>}

impl<'input> PivotedRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotedRelationContextAll<'input>> {
		Rc::new(
		PivotedRelationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotedRelationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotedRelationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PivotedRelationContextExt<'input>>{


}

impl<'input> PivotedRelationContextAttrs<'input> for PivotedRelationContext<'input>{}

pub type ParenthesizedPivotedRelationContext<'input> = BaseParserRuleContext<'input,ParenthesizedPivotedRelationContextExt<'input>>;

pub trait ParenthesizedPivotedRelationContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn pivotedRelation(&self) -> Option<Rc<PivotedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ParenthesizedPivotedRelationContextAttrs<'input> for ParenthesizedPivotedRelationContext<'input>{}

pub struct ParenthesizedPivotedRelationContextExt<'input>{
	base:PivotedRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ParenthesizedPivotedRelationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ParenthesizedPivotedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ParenthesizedPivotedRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_parenthesizedPivotedRelation(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_parenthesizedPivotedRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ParenthesizedPivotedRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_parenthesizedPivotedRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParenthesizedPivotedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotedRelation }
}

impl<'input> Borrow<PivotedRelationContextExt<'input>> for ParenthesizedPivotedRelationContext<'input>{
	fn borrow(&self) -> &PivotedRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotedRelationContextExt<'input>> for ParenthesizedPivotedRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotedRelationContextExt<'input> { &mut self.base }
}

impl<'input> PivotedRelationContextAttrs<'input> for ParenthesizedPivotedRelationContext<'input> {}

impl<'input> ParenthesizedPivotedRelationContextExt<'input>{
	fn new(ctx: &dyn PivotedRelationContextAttrs<'input>) -> Rc<PivotedRelationContextAll<'input>>  {
		Rc::new(
			PivotedRelationContextAll::ParenthesizedPivotedRelationContext(
				BaseParserRuleContext::copy_from(ctx,ParenthesizedPivotedRelationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PivotedRelationDefaultContext<'input> = BaseParserRuleContext<'input,PivotedRelationDefaultContextExt<'input>>;

pub trait PivotedRelationDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn pivotedRelationTarget(&self) -> Option<Rc<PivotedRelationTargetContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn pivotOperator_all(&self) ->  Vec<Rc<PivotOperatorContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn pivotOperator(&self, i: usize) -> Option<Rc<PivotOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> PivotedRelationDefaultContextAttrs<'input> for PivotedRelationDefaultContext<'input>{}

pub struct PivotedRelationDefaultContextExt<'input>{
	base:PivotedRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotedRelationDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PivotedRelationDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotedRelationDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivotedRelationDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_pivotedRelationDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotedRelationDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pivotedRelationDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotedRelationDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotedRelation }
}

impl<'input> Borrow<PivotedRelationContextExt<'input>> for PivotedRelationDefaultContext<'input>{
	fn borrow(&self) -> &PivotedRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotedRelationContextExt<'input>> for PivotedRelationDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotedRelationContextExt<'input> { &mut self.base }
}

impl<'input> PivotedRelationContextAttrs<'input> for PivotedRelationDefaultContext<'input> {}

impl<'input> PivotedRelationDefaultContextExt<'input>{
	fn new(ctx: &dyn PivotedRelationContextAttrs<'input>) -> Rc<PivotedRelationContextAll<'input>>  {
		Rc::new(
			PivotedRelationContextAll::PivotedRelationDefaultContext(
				BaseParserRuleContext::copy_from(ctx,PivotedRelationDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotedRelation(&mut self,)
	-> Result<Rc<PivotedRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotedRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 156, RULE_pivotedRelation);
        let mut _localctx: Rc<PivotedRelationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1993);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(251,&mut recog.base)? {
				1 =>{
					let tmp = PivotedRelationDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule pivotedRelationTarget*/
					recog.base.set_state(1982);
					recog.pivotedRelationTarget()?;

					recog.base.set_state(1986);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==PIVOT || _la==UNPIVOT {
						{
						{
						/*InvokeRule pivotOperator*/
						recog.base.set_state(1983);
						recog.pivotOperator()?;

						}
						}
						recog.base.set_state(1988);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				2 =>{
					let tmp = ParenthesizedPivotedRelationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1989);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotedRelation*/
					recog.base.set_state(1990);
					recog.pivotedRelation()?;

					recog.base.set_state(1991);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotAggregates ----------------
pub type PivotAggregatesContextAll<'input> = PivotAggregatesContext<'input>;


pub type PivotAggregatesContext<'input> = BaseParserRuleContext<'input,PivotAggregatesContextExt<'input>>;

#[derive(Clone)]
pub struct PivotAggregatesContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PivotAggregatesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotAggregatesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotAggregates(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_pivotAggregates(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotAggregatesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pivotAggregates(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotAggregatesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotAggregates }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotAggregates }
}
antlr_rust::tid!{PivotAggregatesContextExt<'a>}

impl<'input> PivotAggregatesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotAggregatesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotAggregatesContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotAggregatesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PivotAggregatesContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> PivotAggregatesContextAttrs<'input> for PivotAggregatesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotAggregates(&mut self,)
	-> Result<Rc<PivotAggregatesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotAggregatesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 158, RULE_pivotAggregates);
        let mut _localctx: Rc<PivotAggregatesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(1995);
			recog.expression()?;

			recog.base.set_state(2000);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(253,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1997);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(1996);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule identifier*/
					recog.base.set_state(1999);
					let tmp = recog.identifier()?;
					 cast_mut::<_,PivotAggregatesContext >(&mut _localctx).name = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotFrom ----------------
pub type PivotFromContextAll<'input> = PivotFromContext<'input>;


pub type PivotFromContext<'input> = BaseParserRuleContext<'input,PivotFromContextExt<'input>>;

#[derive(Clone)]
pub struct PivotFromContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PivotFromContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotFromContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotFrom(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_pivotFrom(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotFromContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pivotFrom(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotFromContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotFrom }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotFrom }
}
antlr_rust::tid!{PivotFromContextExt<'a>}

impl<'input> PivotFromContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotFromContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotFromContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotFromContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PivotFromContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PivotFromContextAttrs<'input> for PivotFromContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotFrom(&mut self,)
	-> Result<Rc<PivotFromContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotFromContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 160, RULE_pivotFrom);
        let mut _localctx: Rc<PivotFromContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2002);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotInto ----------------
#[derive(Debug)]
pub enum PivotIntoContextAll<'input>{
	PivotIntoDefaultContext(PivotIntoDefaultContext<'input>),
Error(PivotIntoContext<'input>)
}
antlr_rust::tid!{PivotIntoContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotIntoContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PivotIntoContextAll<'input>{}

impl<'input> Deref for PivotIntoContextAll<'input>{
	type Target = dyn PivotIntoContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotIntoContextAll::*;
		match self{
			PivotIntoDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotIntoContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotIntoContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotIntoContext<'input> = BaseParserRuleContext<'input,PivotIntoContextExt<'input>>;

#[derive(Clone)]
pub struct PivotIntoContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PivotIntoContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotIntoContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotIntoContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotIntoContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotInto }
}
antlr_rust::tid!{PivotIntoContextExt<'a>}

impl<'input> PivotIntoContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotIntoContextAll<'input>> {
		Rc::new(
		PivotIntoContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotIntoContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotIntoContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PivotIntoContextExt<'input>>{


}

impl<'input> PivotIntoContextAttrs<'input> for PivotIntoContext<'input>{}

pub type PivotIntoDefaultContext<'input> = BaseParserRuleContext<'input,PivotIntoDefaultContextExt<'input>>;

pub trait PivotIntoDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PivotIntoDefaultContextAttrs<'input> for PivotIntoDefaultContext<'input>{}

pub struct PivotIntoDefaultContextExt<'input>{
	base:PivotIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotIntoDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PivotIntoDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotIntoDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivotIntoDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_pivotIntoDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotIntoDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pivotIntoDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotIntoDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotInto }
}

impl<'input> Borrow<PivotIntoContextExt<'input>> for PivotIntoDefaultContext<'input>{
	fn borrow(&self) -> &PivotIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotIntoContextExt<'input>> for PivotIntoDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotIntoContextExt<'input> { &mut self.base }
}

impl<'input> PivotIntoContextAttrs<'input> for PivotIntoDefaultContext<'input> {}

impl<'input> PivotIntoDefaultContextExt<'input>{
	fn new(ctx: &dyn PivotIntoContextAttrs<'input>) -> Rc<PivotIntoContextAll<'input>>  {
		Rc::new(
			PivotIntoContextAll::PivotIntoDefaultContext(
				BaseParserRuleContext::copy_from(ctx,PivotIntoDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotInto(&mut self,)
	-> Result<Rc<PivotIntoContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotIntoContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 162, RULE_pivotInto);
        let mut _localctx: Rc<PivotIntoContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = PivotIntoDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule expression*/
			recog.base.set_state(2004);
			recog.expression()?;

			recog.base.set_state(2007);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(2005);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				/*InvokeRule columnName*/
				recog.base.set_state(2006);
				recog.columnName()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotAsAlias ----------------
pub type PivotAsAliasContextAll<'input> = PivotAsAliasContext<'input>;


pub type PivotAsAliasContext<'input> = BaseParserRuleContext<'input,PivotAsAliasContextExt<'input>>;

#[derive(Clone)]
pub struct PivotAsAliasContextExt<'input>{
	pub alias: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PivotAsAliasContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotAsAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotAsAlias(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_pivotAsAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotAsAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pivotAsAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotAsAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotAsAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotAsAlias }
}
antlr_rust::tid!{PivotAsAliasContextExt<'a>}

impl<'input> PivotAsAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotAsAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotAsAliasContextExt{
				alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotAsAliasContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PivotAsAliasContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PivotAsAliasContextAttrs<'input> for PivotAsAliasContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotAsAlias(&mut self,)
	-> Result<Rc<PivotAsAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotAsAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 164, RULE_pivotAsAlias);
        let mut _localctx: Rc<PivotAsAliasContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2016);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(257,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2010);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(2009);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule identifier*/
					recog.base.set_state(2012);
					let tmp = recog.identifier()?;
					 cast_mut::<_,PivotAsAliasContext >(&mut _localctx).alias = Some(tmp.clone());
					  

					recog.base.set_state(2014);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(256,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(2013);
							recog.columnAliases()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleColumnUnpivot ----------------
pub type SingleColumnUnpivotContextAll<'input> = SingleColumnUnpivotContext<'input>;


pub type SingleColumnUnpivotContext<'input> = BaseParserRuleContext<'input,SingleColumnUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct SingleColumnUnpivotContextExt<'input>{
	pub valuesColumn: Option<Rc<IdentifierContextAll<'input>>>,
	pub nameColumn: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for SingleColumnUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SingleColumnUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleColumnUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_singleColumnUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SingleColumnUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_singleColumnUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleColumnUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleColumnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleColumnUnpivot }
}
antlr_rust::tid!{SingleColumnUnpivotContextExt<'a>}

impl<'input> SingleColumnUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleColumnUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleColumnUnpivotContextExt{
				valuesColumn: None, nameColumn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleColumnUnpivotContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<SingleColumnUnpivotContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnsToUnpivot(&self) -> Option<Rc<ColumnsToUnpivotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SingleColumnUnpivotContextAttrs<'input> for SingleColumnUnpivotContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleColumnUnpivot(&mut self,)
	-> Result<Rc<SingleColumnUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleColumnUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 166, RULE_singleColumnUnpivot);
        let mut _localctx: Rc<SingleColumnUnpivotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2018);
			let tmp = recog.identifier()?;
			 cast_mut::<_,SingleColumnUnpivotContext >(&mut _localctx).valuesColumn = Some(tmp.clone());
			  

			recog.base.set_state(2019);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(2020);
			let tmp = recog.identifier()?;
			 cast_mut::<_,SingleColumnUnpivotContext >(&mut _localctx).nameColumn = Some(tmp.clone());
			  

			recog.base.set_state(2021);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(2022);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnsToUnpivot*/
			recog.base.set_state(2023);
			recog.columnsToUnpivot()?;

			recog.base.set_state(2024);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnsToUnpivot ----------------
pub type ColumnsToUnpivotContextAll<'input> = ColumnsToUnpivotContext<'input>;


pub type ColumnsToUnpivotContext<'input> = BaseParserRuleContext<'input,ColumnsToUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnsToUnpivotContextExt<'input>{
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub unpivotCol:Vec<Rc<IdentifierContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnsToUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnsToUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnsToUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnsToUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnsToUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnsToUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnsToUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnsToUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnsToUnpivot }
}
antlr_rust::tid!{ColumnsToUnpivotContextExt<'a>}

impl<'input> ColumnsToUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnsToUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnsToUnpivotContextExt{
				tail: None, 
				identifier: None, 
				unpivotCol: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnsToUnpivotContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnsToUnpivotContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnsToUnpivotContextAttrs<'input> for ColumnsToUnpivotContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnsToUnpivot(&mut self,)
	-> Result<Rc<ColumnsToUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnsToUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 168, RULE_columnsToUnpivot);
        let mut _localctx: Rc<ColumnsToUnpivotContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2026);
			let tmp = recog.identifier()?;
			 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier.clone().unwrap()
			 ;
			 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).unpivotCol.push(temp);
			  
			recog.base.set_state(2031);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(258,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2027);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(2028);
					let tmp = recog.identifier()?;
					 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier.clone().unwrap()
					 ;
					 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).unpivotCol.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2033);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(258,&mut recog.base)?;
			}
			recog.base.set_state(2035);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2034);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnUnpivot ----------------
#[derive(Debug)]
pub enum ColumnUnpivotContextAll<'input>{
	SingleColumnUnpivotDefaultContext(SingleColumnUnpivotDefaultContext<'input>),
Error(ColumnUnpivotContext<'input>)
}
antlr_rust::tid!{ColumnUnpivotContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ColumnUnpivotContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for ColumnUnpivotContextAll<'input>{}

impl<'input> Deref for ColumnUnpivotContextAll<'input>{
	type Target = dyn ColumnUnpivotContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ColumnUnpivotContextAll::*;
		match self{
			SingleColumnUnpivotDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnUnpivotContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnUnpivotContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ColumnUnpivotContext<'input> = BaseParserRuleContext<'input,ColumnUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnUnpivotContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnUnpivotContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnUnpivotContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ColumnUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnUnpivot }
}
antlr_rust::tid!{ColumnUnpivotContextExt<'a>}

impl<'input> ColumnUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnUnpivotContextAll<'input>> {
		Rc::new(
		ColumnUnpivotContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnUnpivotContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ColumnUnpivotContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnUnpivotContextExt<'input>>{


}

impl<'input> ColumnUnpivotContextAttrs<'input> for ColumnUnpivotContext<'input>{}

pub type SingleColumnUnpivotDefaultContext<'input> = BaseParserRuleContext<'input,SingleColumnUnpivotDefaultContextExt<'input>>;

pub trait SingleColumnUnpivotDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn singleColumnUnpivot(&self) -> Option<Rc<SingleColumnUnpivotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SingleColumnUnpivotDefaultContextAttrs<'input> for SingleColumnUnpivotDefaultContext<'input>{}

pub struct SingleColumnUnpivotDefaultContextExt<'input>{
	base:ColumnUnpivotContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleColumnUnpivotDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SingleColumnUnpivotDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SingleColumnUnpivotDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleColumnUnpivotDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_singleColumnUnpivotDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SingleColumnUnpivotDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_singleColumnUnpivotDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleColumnUnpivotDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnUnpivot }
}

impl<'input> Borrow<ColumnUnpivotContextExt<'input>> for SingleColumnUnpivotDefaultContext<'input>{
	fn borrow(&self) -> &ColumnUnpivotContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnUnpivotContextExt<'input>> for SingleColumnUnpivotDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnUnpivotContextExt<'input> { &mut self.base }
}

impl<'input> ColumnUnpivotContextAttrs<'input> for SingleColumnUnpivotDefaultContext<'input> {}

impl<'input> SingleColumnUnpivotDefaultContextExt<'input>{
	fn new(ctx: &dyn ColumnUnpivotContextAttrs<'input>) -> Rc<ColumnUnpivotContextAll<'input>>  {
		Rc::new(
			ColumnUnpivotContextAll::SingleColumnUnpivotDefaultContext(
				BaseParserRuleContext::copy_from(ctx,SingleColumnUnpivotDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnUnpivot(&mut self,)
	-> Result<Rc<ColumnUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 170, RULE_columnUnpivot);
        let mut _localctx: Rc<ColumnUnpivotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = SingleColumnUnpivotDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule singleColumnUnpivot*/
			recog.base.set_state(2037);
			recog.singleColumnUnpivot()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotIntos ----------------
#[derive(Debug)]
pub enum PivotIntosContextAll<'input>{
	PivotIntosDefaultContext(PivotIntosDefaultContext<'input>),
Error(PivotIntosContext<'input>)
}
antlr_rust::tid!{PivotIntosContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotIntosContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PivotIntosContextAll<'input>{}

impl<'input> Deref for PivotIntosContextAll<'input>{
	type Target = dyn PivotIntosContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotIntosContextAll::*;
		match self{
			PivotIntosDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotIntosContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotIntosContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotIntosContext<'input> = BaseParserRuleContext<'input,PivotIntosContextExt<'input>>;

#[derive(Clone)]
pub struct PivotIntosContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PivotIntosContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotIntosContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotIntosContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotIntosContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotIntos }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotIntos }
}
antlr_rust::tid!{PivotIntosContextExt<'a>}

impl<'input> PivotIntosContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotIntosContextAll<'input>> {
		Rc::new(
		PivotIntosContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotIntosContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotIntosContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PivotIntosContextExt<'input>>{


}

impl<'input> PivotIntosContextAttrs<'input> for PivotIntosContext<'input>{}

pub type PivotIntosDefaultContext<'input> = BaseParserRuleContext<'input,PivotIntosDefaultContextExt<'input>>;

pub trait PivotIntosDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn pivotInto_all(&self) ->  Vec<Rc<PivotIntoContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn pivotInto(&self, i: usize) -> Option<Rc<PivotIntoContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PivotIntosDefaultContextAttrs<'input> for PivotIntosDefaultContext<'input>{}

pub struct PivotIntosDefaultContextExt<'input>{
	base:PivotIntosContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotIntosDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PivotIntosDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotIntosDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivotIntosDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_pivotIntosDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotIntosDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pivotIntosDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotIntosDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotIntos }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotIntos }
}

impl<'input> Borrow<PivotIntosContextExt<'input>> for PivotIntosDefaultContext<'input>{
	fn borrow(&self) -> &PivotIntosContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotIntosContextExt<'input>> for PivotIntosDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotIntosContextExt<'input> { &mut self.base }
}

impl<'input> PivotIntosContextAttrs<'input> for PivotIntosDefaultContext<'input> {}

impl<'input> PivotIntosDefaultContextExt<'input>{
	fn new(ctx: &dyn PivotIntosContextAttrs<'input>) -> Rc<PivotIntosContextAll<'input>>  {
		Rc::new(
			PivotIntosContextAll::PivotIntosDefaultContext(
				BaseParserRuleContext::copy_from(ctx,PivotIntosDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotIntos(&mut self,)
	-> Result<Rc<PivotIntosContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotIntosContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 172, RULE_pivotIntos);
        let mut _localctx: Rc<PivotIntosContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = PivotIntosDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule pivotInto*/
			recog.base.set_state(2039);
			recog.pivotInto()?;

			recog.base.set_state(2044);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(260,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2040);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule pivotInto*/
					recog.base.set_state(2041);
					recog.pivotInto()?;

					}
					} 
				}
				recog.base.set_state(2046);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(260,&mut recog.base)?;
			}
			recog.base.set_state(2048);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2047);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotOperator ----------------
#[derive(Debug)]
pub enum PivotOperatorContextAll<'input>{
	UnpivotContext(UnpivotContext<'input>),
	PivotContext(PivotContext<'input>),
Error(PivotOperatorContext<'input>)
}
antlr_rust::tid!{PivotOperatorContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotOperatorContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PivotOperatorContextAll<'input>{}

impl<'input> Deref for PivotOperatorContextAll<'input>{
	type Target = dyn PivotOperatorContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotOperatorContextAll::*;
		match self{
			UnpivotContext(inner) => inner,
			PivotContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotOperatorContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotOperatorContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotOperatorContext<'input> = BaseParserRuleContext<'input,PivotOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PivotOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PivotOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotOperatorContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotOperatorContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}
antlr_rust::tid!{PivotOperatorContextExt<'a>}

impl<'input> PivotOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotOperatorContextAll<'input>> {
		Rc::new(
		PivotOperatorContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotOperatorContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotOperatorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PivotOperatorContextExt<'input>>{


}

impl<'input> PivotOperatorContextAttrs<'input> for PivotOperatorContext<'input>{}

pub type UnpivotContext<'input> = BaseParserRuleContext<'input,UnpivotContextExt<'input>>;

pub trait UnpivotContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNPIVOT
	/// Returns `None` if there is no child corresponding to token UNPIVOT
	fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UNPIVOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn columnUnpivot(&self) -> Option<Rc<ColumnUnpivotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn pivotAsAlias(&self) -> Option<Rc<PivotAsAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn unpivotNullClause(&self) -> Option<Rc<UnpivotNullClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnpivotContextAttrs<'input> for UnpivotContext<'input>{}

pub struct UnpivotContextExt<'input>{
	base:PivotOperatorContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnpivotContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UnpivotContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unpivot(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_unpivot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_unpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}

impl<'input> Borrow<PivotOperatorContextExt<'input>> for UnpivotContext<'input>{
	fn borrow(&self) -> &PivotOperatorContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotOperatorContextExt<'input>> for UnpivotContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotOperatorContextExt<'input> { &mut self.base }
}

impl<'input> PivotOperatorContextAttrs<'input> for UnpivotContext<'input> {}

impl<'input> UnpivotContextExt<'input>{
	fn new(ctx: &dyn PivotOperatorContextAttrs<'input>) -> Rc<PivotOperatorContextAll<'input>>  {
		Rc::new(
			PivotOperatorContextAll::UnpivotContext(
				BaseParserRuleContext::copy_from(ctx,UnpivotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PivotContext<'input> = BaseParserRuleContext<'input,PivotContextExt<'input>>;

pub trait PivotContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PIVOT
	/// Returns `None` if there is no child corresponding to token PIVOT
	fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PIVOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	fn pivotAggregates(&self) -> Option<Rc<PivotAggregatesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
	fn pivotFrom(&self) -> Option<Rc<PivotFromContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	fn pivotIntos(&self) -> Option<Rc<PivotIntosContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	fn pivotAsAlias(&self) -> Option<Rc<PivotAsAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PivotContextAttrs<'input> for PivotContext<'input>{}

pub struct PivotContextExt<'input>{
	base:PivotOperatorContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PivotContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PivotContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivot(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_pivot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}

impl<'input> Borrow<PivotOperatorContextExt<'input>> for PivotContext<'input>{
	fn borrow(&self) -> &PivotOperatorContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotOperatorContextExt<'input>> for PivotContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotOperatorContextExt<'input> { &mut self.base }
}

impl<'input> PivotOperatorContextAttrs<'input> for PivotContext<'input> {}

impl<'input> PivotContextExt<'input>{
	fn new(ctx: &dyn PivotOperatorContextAttrs<'input>) -> Rc<PivotOperatorContextAll<'input>>  {
		Rc::new(
			PivotOperatorContextAll::PivotContext(
				BaseParserRuleContext::copy_from(ctx,PivotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotOperator(&mut self,)
	-> Result<Rc<PivotOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 174, RULE_pivotOperator);
        let mut _localctx: Rc<PivotOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2071);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 PIVOT 
				=> {
					let tmp = PivotContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2050);
					recog.base.match_token(PIVOT,&mut recog.err_handler)?;

					recog.base.set_state(2051);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotAggregates*/
					recog.base.set_state(2052);
					recog.pivotAggregates()?;

					recog.base.set_state(2053);
					recog.base.match_token(FOR,&mut recog.err_handler)?;

					/*InvokeRule pivotFrom*/
					recog.base.set_state(2054);
					recog.pivotFrom()?;

					recog.base.set_state(2055);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2056);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotIntos*/
					recog.base.set_state(2057);
					recog.pivotIntos()?;

					recog.base.set_state(2058);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2059);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotAsAlias*/
					recog.base.set_state(2060);
					recog.pivotAsAlias()?;

					}
				}

			 UNPIVOT 
				=> {
					let tmp = UnpivotContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2062);
					recog.base.match_token(UNPIVOT,&mut recog.err_handler)?;

					recog.base.set_state(2064);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EXCLUDE || _la==INCLUDE {
						{
						/*InvokeRule unpivotNullClause*/
						recog.base.set_state(2063);
						recog.unpivotNullClause()?;

						}
					}

					recog.base.set_state(2066);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule columnUnpivot*/
					recog.base.set_state(2067);
					recog.columnUnpivot()?;

					recog.base.set_state(2068);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotAsAlias*/
					recog.base.set_state(2069);
					recog.pivotAsAlias()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aliasedRelationTarget ----------------
#[derive(Debug)]
pub enum AliasedRelationTargetContextAll<'input>{
	SubqueryRelationContext(SubqueryRelationContext<'input>),
	TableNameContext(TableNameContext<'input>),
Error(AliasedRelationTargetContext<'input>)
}
antlr_rust::tid!{AliasedRelationTargetContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for AliasedRelationTargetContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for AliasedRelationTargetContextAll<'input>{}

impl<'input> Deref for AliasedRelationTargetContextAll<'input>{
	type Target = dyn AliasedRelationTargetContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use AliasedRelationTargetContextAll::*;
		match self{
			SubqueryRelationContext(inner) => inner,
			TableNameContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AliasedRelationTargetContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AliasedRelationTargetContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type AliasedRelationTargetContext<'input> = BaseParserRuleContext<'input,AliasedRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct AliasedRelationTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for AliasedRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AliasedRelationTargetContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AliasedRelationTargetContext<'input>{
}

impl<'input> CustomRuleContext<'input> for AliasedRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}
antlr_rust::tid!{AliasedRelationTargetContextExt<'a>}

impl<'input> AliasedRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AliasedRelationTargetContextAll<'input>> {
		Rc::new(
		AliasedRelationTargetContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AliasedRelationTargetContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait AliasedRelationTargetContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<AliasedRelationTargetContextExt<'input>>{


}

impl<'input> AliasedRelationTargetContextAttrs<'input> for AliasedRelationTargetContext<'input>{}

pub type SubqueryRelationContext<'input> = BaseParserRuleContext<'input,SubqueryRelationContextExt<'input>>;

pub trait SubqueryRelationContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> SubqueryRelationContextAttrs<'input> for SubqueryRelationContext<'input>{}

pub struct SubqueryRelationContextExt<'input>{
	base:AliasedRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryRelationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SubqueryRelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SubqueryRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subqueryRelation(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_subqueryRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SubqueryRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_subqueryRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}

impl<'input> Borrow<AliasedRelationTargetContextExt<'input>> for SubqueryRelationContext<'input>{
	fn borrow(&self) -> &AliasedRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<AliasedRelationTargetContextExt<'input>> for SubqueryRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut AliasedRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> AliasedRelationTargetContextAttrs<'input> for SubqueryRelationContext<'input> {}

impl<'input> SubqueryRelationContextExt<'input>{
	fn new(ctx: &dyn AliasedRelationTargetContextAttrs<'input>) -> Rc<AliasedRelationTargetContextAll<'input>>  {
		Rc::new(
			AliasedRelationTargetContextAll::SubqueryRelationContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryRelationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableNameContext<'input> = BaseParserRuleContext<'input,TableNameContextExt<'input>>;

pub trait TableNameContextAttrs<'input>: RedshiftParserContext<'input>{
	fn pathExpression(&self) -> Option<Rc<PathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableNameContextAttrs<'input> for TableNameContext<'input>{}

pub struct TableNameContextExt<'input>{
	base:AliasedRelationTargetContextExt<'input>,
	pub tableNameRef: Option<Rc<PathExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableNameContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TableNameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableNameContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableName(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_tableName(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableName(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}

impl<'input> Borrow<AliasedRelationTargetContextExt<'input>> for TableNameContext<'input>{
	fn borrow(&self) -> &AliasedRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<AliasedRelationTargetContextExt<'input>> for TableNameContext<'input>{
	fn borrow_mut(&mut self) -> &mut AliasedRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> AliasedRelationTargetContextAttrs<'input> for TableNameContext<'input> {}

impl<'input> TableNameContextExt<'input>{
	fn new(ctx: &dyn AliasedRelationTargetContextAttrs<'input>) -> Rc<AliasedRelationTargetContextAll<'input>>  {
		Rc::new(
			AliasedRelationTargetContextAll::TableNameContext(
				BaseParserRuleContext::copy_from(ctx,TableNameContextExt{
        			tableNameRef:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aliasedRelationTarget(&mut self,)
	-> Result<Rc<AliasedRelationTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AliasedRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 176, RULE_aliasedRelationTarget);
        let mut _localctx: Rc<AliasedRelationTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2078);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
			 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
			 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
			 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEVEL | LIBRARY | LIKE | LIMIT |
			 LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK | LOGICAL |
			 M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE | MATERIALIZED |
			 MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES | MERGE | MIN |
			 MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC | NFD | NFKC |
			 NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS | OBJECT | OF |
			 OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR | ORDER | ORDINALITY |
			 OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW | PARTITION | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENTILE_CONT |
			 PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG | PIVOT | POSITION |
			 PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIMARY | PRIVILEGES |
			 PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE | READ | RECURSIVE | REFERENCES |
			 REFRESH | RENAME | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROLLUP | ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND |
			 SECONDS | SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE |
			 SERDEPROPERTIES | SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR |
			 SOME | SORTKEY | SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET |
			 SUBSTRING | SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY |
			 TERMINATED | TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO |
			 TRAILING | TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE |
			 TYPE | UESCAPE | UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE |
			 UNKNOWN | UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER |
			 UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING |
			 VARIADIC | VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW |
			 WITH | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
			 ZSTD | LBRACKET | IDENTIFIER | DIGIT_IDENTIFIER | QUOTED_IDENTIFIER 
				=> {
					let tmp = TableNameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule pathExpression*/
					recog.base.set_state(2073);
					let tmp = recog.pathExpression()?;
					if let AliasedRelationTargetContextAll::TableNameContext(ctx) = cast_mut::<_,AliasedRelationTargetContextAll >(&mut _localctx){
					ctx.tableNameRef = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}

			 LPAREN 
				=> {
					let tmp = SubqueryRelationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2074);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2075);
					recog.query()?;

					recog.base.set_state(2076);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aliasedRelation ----------------
pub type AliasedRelationContextAll<'input> = AliasedRelationContext<'input>;


pub type AliasedRelationContext<'input> = BaseParserRuleContext<'input,AliasedRelationContextExt<'input>>;

#[derive(Clone)]
pub struct AliasedRelationContextExt<'input>{
	pub alias: Option<Rc<IdentifierContextAll<'input>>>,
	pub indexAlias: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for AliasedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AliasedRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aliasedRelation(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_aliasedRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AliasedRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_aliasedRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for AliasedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelation }
}
antlr_rust::tid!{AliasedRelationContextExt<'a>}

impl<'input> AliasedRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AliasedRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AliasedRelationContextExt{
				alias: None, indexAlias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AliasedRelationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<AliasedRelationContextExt<'input>>{

fn aliasedRelationTarget(&self) -> Option<Rc<AliasedRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AT
/// Returns `None` if there is no child corresponding to token AT
fn AT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AT, 0)
}

}

impl<'input> AliasedRelationContextAttrs<'input> for AliasedRelationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aliasedRelation(&mut self,)
	-> Result<Rc<AliasedRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AliasedRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 178, RULE_aliasedRelation);
        let mut _localctx: Rc<AliasedRelationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule aliasedRelationTarget*/
			recog.base.set_state(2080);
			recog.aliasedRelationTarget()?;

			recog.base.set_state(2090);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(267,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2082);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(2081);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule identifier*/
					recog.base.set_state(2084);
					let tmp = recog.identifier()?;
					 cast_mut::<_,AliasedRelationContext >(&mut _localctx).alias = Some(tmp.clone());
					  

					recog.base.set_state(2088);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(266,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(2085);
							recog.columnAliases()?;

							}
						}

						x if x == 2=>{
							{
							recog.base.set_state(2086);
							recog.base.match_token(AT,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(2087);
							let tmp = recog.identifier()?;
							 cast_mut::<_,AliasedRelationContext >(&mut _localctx).indexAlias = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnAliases ----------------
pub type ColumnAliasesContextAll<'input> = ColumnAliasesContext<'input>;


pub type ColumnAliasesContext<'input> = BaseParserRuleContext<'input,ColumnAliasesContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnAliasesContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ColumnAliasesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnAliasesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnAliases(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_columnAliases(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnAliasesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnAliases(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnAliasesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnAliases }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnAliases }
}
antlr_rust::tid!{ColumnAliasesContextExt<'a>}

impl<'input> ColumnAliasesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnAliasesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnAliasesContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnAliasesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ColumnAliasesContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnAliasesContextAttrs<'input> for ColumnAliasesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnAliases(&mut self,)
	-> Result<Rc<ColumnAliasesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnAliasesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 180, RULE_columnAliases);
        let mut _localctx: Rc<ColumnAliasesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2107);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
			 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
			 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
			 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEVEL | LIBRARY | LIKE | LIMIT |
			 LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK | LOGICAL |
			 M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE | MATERIALIZED |
			 MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES | MERGE | MIN |
			 MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC | NFD | NFKC |
			 NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS | OBJECT | OF |
			 OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR | ORDER | ORDINALITY |
			 OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW | PARTITION | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENTILE_CONT |
			 PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG | PIVOT | POSITION |
			 PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIMARY | PRIVILEGES |
			 PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE | READ | RECURSIVE | REFERENCES |
			 REFRESH | RENAME | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROLLUP | ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND |
			 SECONDS | SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE |
			 SERDEPROPERTIES | SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR |
			 SOME | SORTKEY | SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET |
			 SUBSTRING | SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY |
			 TERMINATED | TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO |
			 TRAILING | TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE |
			 TYPE | UESCAPE | UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE |
			 UNKNOWN | UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER |
			 UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING |
			 VARIADIC | VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW |
			 WITH | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
			 ZSTD | LBRACKET | IDENTIFIER | DIGIT_IDENTIFIER | QUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2092);
					recog.identifier()?;

					}
				}

			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2093);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(2094);
					recog.identifier()?;

					recog.base.set_state(2099);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(268,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2095);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(2096);
							recog.identifier()?;

							}
							} 
						}
						recog.base.set_state(2101);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(268,&mut recog.base)?;
					}
					recog.base.set_state(2103);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2102);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,ColumnAliasesContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(2105);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionColumn ----------------
pub type PartitionColumnContextAll<'input> = PartitionColumnContext<'input>;


pub type PartitionColumnContext<'input> = BaseParserRuleContext<'input,PartitionColumnContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionColumnContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PartitionColumnContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PartitionColumnContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionColumn(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_partitionColumn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PartitionColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_partitionColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionColumn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionColumn }
}
antlr_rust::tid!{PartitionColumnContextExt<'a>}

impl<'input> PartitionColumnContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionColumnContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionColumnContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionColumnContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PartitionColumnContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionColumnContextAttrs<'input> for PartitionColumnContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionColumn(&mut self,)
	-> Result<Rc<PartitionColumnContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionColumnContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 182, RULE_partitionColumn);
        let mut _localctx: Rc<PartitionColumnContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2109);
			recog.identifier()?;

			/*InvokeRule type_*/
			recog.base.set_state(2110);
			recog.type_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionColumns ----------------
pub type PartitionColumnsContextAll<'input> = PartitionColumnsContext<'input>;


pub type PartitionColumnsContext<'input> = BaseParserRuleContext<'input,PartitionColumnsContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionColumnsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PartitionColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PartitionColumnsContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionColumns(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_partitionColumns(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PartitionColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_partitionColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionColumns }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionColumns }
}
antlr_rust::tid!{PartitionColumnsContextExt<'a>}

impl<'input> PartitionColumnsContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionColumnsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionColumnsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionColumnsContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PartitionColumnsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn partitionColumn_all(&self) ->  Vec<Rc<PartitionColumnContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionColumn(&self, i: usize) -> Option<Rc<PartitionColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionColumnsContextAttrs<'input> for PartitionColumnsContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionColumns(&mut self,)
	-> Result<Rc<PartitionColumnsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionColumnsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 184, RULE_partitionColumns);
        let mut _localctx: Rc<PartitionColumnsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2112);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule partitionColumn*/
			recog.base.set_state(2113);
			recog.partitionColumn()?;

			recog.base.set_state(2118);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(271,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2114);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule partitionColumn*/
					recog.base.set_state(2115);
					recog.partitionColumn()?;

					}
					} 
				}
				recog.base.set_state(2120);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(271,&mut recog.base)?;
			}
			recog.base.set_state(2122);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2121);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,PartitionColumnsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			recog.base.set_state(2124);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relationPrimary ----------------
#[derive(Debug)]
pub enum RelationPrimaryContextAll<'input>{
	AliasedContext(AliasedContext<'input>),
	ObjectUnpivotContext(ObjectUnpivotContext<'input>),
Error(RelationPrimaryContext<'input>)
}
antlr_rust::tid!{RelationPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RelationPrimaryContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for RelationPrimaryContextAll<'input>{}

impl<'input> Deref for RelationPrimaryContextAll<'input>{
	type Target = dyn RelationPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RelationPrimaryContextAll::*;
		match self{
			AliasedContext(inner) => inner,
			ObjectUnpivotContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RelationPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RelationPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RelationPrimaryContext<'input> = BaseParserRuleContext<'input,RelationPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct RelationPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RelationPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RelationPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RelationPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RelationPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}
antlr_rust::tid!{RelationPrimaryContextExt<'a>}

impl<'input> RelationPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationPrimaryContextAll<'input>> {
		Rc::new(
		RelationPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RelationPrimaryContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RelationPrimaryContextExt<'input>>{


}

impl<'input> RelationPrimaryContextAttrs<'input> for RelationPrimaryContext<'input>{}

pub type AliasedContext<'input> = BaseParserRuleContext<'input,AliasedContextExt<'input>>;

pub trait AliasedContextAttrs<'input>: RedshiftParserContext<'input>{
	fn aliasedRelation(&self) -> Option<Rc<AliasedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AliasedContextAttrs<'input> for AliasedContext<'input>{}

pub struct AliasedContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AliasedContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AliasedContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AliasedContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_aliased(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_aliased(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AliasedContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_aliased(self);
	}
}

impl<'input> CustomRuleContext<'input> for AliasedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for AliasedContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for AliasedContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for AliasedContext<'input> {}

impl<'input> AliasedContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::AliasedContext(
				BaseParserRuleContext::copy_from(ctx,AliasedContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ObjectUnpivotContext<'input> = BaseParserRuleContext<'input,ObjectUnpivotContextExt<'input>>;

pub trait ObjectUnpivotContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNPIVOT
	/// Returns `None` if there is no child corresponding to token UNPIVOT
	fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UNPIVOT, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token AT
	/// Returns `None` if there is no child corresponding to token AT
	fn AT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AT, 0)
	}
}

impl<'input> ObjectUnpivotContextAttrs<'input> for ObjectUnpivotContext<'input>{}

pub struct ObjectUnpivotContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	pub value_alias: Option<Rc<IdentifierContextAll<'input>>>,
	pub attribute_alias: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ObjectUnpivotContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ObjectUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ObjectUnpivotContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_objectUnpivot(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_objectUnpivot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ObjectUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_objectUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for ObjectUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for ObjectUnpivotContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for ObjectUnpivotContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for ObjectUnpivotContext<'input> {}

impl<'input> ObjectUnpivotContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::ObjectUnpivotContext(
				BaseParserRuleContext::copy_from(ctx,ObjectUnpivotContextExt{
        			value_alias:None, attribute_alias:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relationPrimary(&mut self,)
	-> Result<Rc<RelationPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 186, RULE_relationPrimary);
        let mut _localctx: Rc<RelationPrimaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2135);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(274,&mut recog.base)? {
				1 =>{
					let tmp = AliasedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule aliasedRelation*/
					recog.base.set_state(2126);
					recog.aliasedRelation()?;

					}
				}
			,
				2 =>{
					let tmp = ObjectUnpivotContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2127);
					recog.base.match_token(UNPIVOT,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2128);
					recog.expression()?;

					recog.base.set_state(2129);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(2130);
					let tmp = recog.identifier()?;
					if let RelationPrimaryContextAll::ObjectUnpivotContext(ctx) = cast_mut::<_,RelationPrimaryContextAll >(&mut _localctx){
					ctx.value_alias = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2133);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(273,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2131);
							recog.base.match_token(AT,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(2132);
							let tmp = recog.identifier()?;
							if let RelationPrimaryContextAll::ObjectUnpivotContext(ctx) = cast_mut::<_,RelationPrimaryContextAll >(&mut _localctx){
							ctx.attribute_alias = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionCall ----------------
#[derive(Debug)]
pub enum TableFunctionCallContextAll<'input>{
	DefaultTableFunctionCallContext(DefaultTableFunctionCallContext<'input>),
Error(TableFunctionCallContext<'input>)
}
antlr_rust::tid!{TableFunctionCallContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TableFunctionCallContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for TableFunctionCallContextAll<'input>{}

impl<'input> Deref for TableFunctionCallContextAll<'input>{
	type Target = dyn TableFunctionCallContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TableFunctionCallContextAll::*;
		match self{
			DefaultTableFunctionCallContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableFunctionCallContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableFunctionCallContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TableFunctionCallContext<'input> = BaseParserRuleContext<'input,TableFunctionCallContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionCallContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableFunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableFunctionCallContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableFunctionCallContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TableFunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionCall }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionCall }
}
antlr_rust::tid!{TableFunctionCallContextExt<'a>}

impl<'input> TableFunctionCallContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionCallContextAll<'input>> {
		Rc::new(
		TableFunctionCallContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionCallContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TableFunctionCallContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableFunctionCallContextExt<'input>>{


}

impl<'input> TableFunctionCallContextAttrs<'input> for TableFunctionCallContext<'input>{}

pub type DefaultTableFunctionCallContext<'input> = BaseParserRuleContext<'input,DefaultTableFunctionCallContextExt<'input>>;

pub trait DefaultTableFunctionCallContextAttrs<'input>: RedshiftParserContext<'input>{
	fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn tableFunctionArgument_all(&self) ->  Vec<Rc<TableFunctionArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn tableFunctionArgument(&self, i: usize) -> Option<Rc<TableFunctionArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn tableFunctionArgumentCopartition(&self) -> Option<Rc<TableFunctionArgumentCopartitionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> DefaultTableFunctionCallContextAttrs<'input> for DefaultTableFunctionCallContext<'input>{}

pub struct DefaultTableFunctionCallContextExt<'input>{
	base:TableFunctionCallContextExt<'input>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultTableFunctionCallContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DefaultTableFunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DefaultTableFunctionCallContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultTableFunctionCall(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_defaultTableFunctionCall(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DefaultTableFunctionCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_defaultTableFunctionCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultTableFunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionCall }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionCall }
}

impl<'input> Borrow<TableFunctionCallContextExt<'input>> for DefaultTableFunctionCallContext<'input>{
	fn borrow(&self) -> &TableFunctionCallContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableFunctionCallContextExt<'input>> for DefaultTableFunctionCallContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableFunctionCallContextExt<'input> { &mut self.base }
}

impl<'input> TableFunctionCallContextAttrs<'input> for DefaultTableFunctionCallContext<'input> {}

impl<'input> DefaultTableFunctionCallContextExt<'input>{
	fn new(ctx: &dyn TableFunctionCallContextAttrs<'input>) -> Rc<TableFunctionCallContextAll<'input>>  {
		Rc::new(
			TableFunctionCallContextAll::DefaultTableFunctionCallContext(
				BaseParserRuleContext::copy_from(ctx,DefaultTableFunctionCallContextExt{
					COMMA:None, 
        			tail:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionCall(&mut self,)
	-> Result<Rc<TableFunctionCallContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionCallContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 188, RULE_tableFunctionCall);
        let mut _localctx: Rc<TableFunctionCallContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = DefaultTableFunctionCallContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule functionName*/
			recog.base.set_state(2137);
			recog.functionName()?;

			recog.base.set_state(2138);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2150);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(277,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule tableFunctionArgument*/
					recog.base.set_state(2139);
					recog.tableFunctionArgument()?;

					recog.base.set_state(2144);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(275,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2140);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule tableFunctionArgument*/
							recog.base.set_state(2141);
							recog.tableFunctionArgument()?;

							}
							} 
						}
						recog.base.set_state(2146);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(275,&mut recog.base)?;
					}
					recog.base.set_state(2148);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2147);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
						ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

						let temp = if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
						ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
						ctx.tail.push(temp); } else {unreachable!("cant cast");}  
						}
					}

					}
				}

				_ => {}
			}
			recog.base.set_state(2153);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COPARTITION {
				{
				/*InvokeRule tableFunctionArgumentCopartition*/
				recog.base.set_state(2152);
				recog.tableFunctionArgumentCopartition()?;

				}
			}

			recog.base.set_state(2155);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2157);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==OVER {
				{
				/*InvokeRule over*/
				recog.base.set_state(2156);
				recog.over()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionArgumentCopartition ----------------
pub type TableFunctionArgumentCopartitionContextAll<'input> = TableFunctionArgumentCopartitionContext<'input>;


pub type TableFunctionArgumentCopartitionContext<'input> = BaseParserRuleContext<'input,TableFunctionArgumentCopartitionContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionArgumentCopartitionContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableFunctionArgumentCopartitionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableFunctionArgumentCopartitionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFunctionArgumentCopartition(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_tableFunctionArgumentCopartition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableFunctionArgumentCopartitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionArgumentCopartition(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionArgumentCopartitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionArgumentCopartition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionArgumentCopartition }
}
antlr_rust::tid!{TableFunctionArgumentCopartitionContextExt<'a>}

impl<'input> TableFunctionArgumentCopartitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionArgumentCopartitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionArgumentCopartitionContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFunctionArgumentCopartitionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableFunctionArgumentCopartitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COPARTITION
/// Returns `None` if there is no child corresponding to token COPARTITION
fn COPARTITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COPARTITION, 0)
}
fn copartitionTables_all(&self) ->  Vec<Rc<CopartitionTablesContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn copartitionTables(&self, i: usize) -> Option<Rc<CopartitionTablesContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableFunctionArgumentCopartitionContextAttrs<'input> for TableFunctionArgumentCopartitionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionArgumentCopartition(&mut self,)
	-> Result<Rc<TableFunctionArgumentCopartitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionArgumentCopartitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 190, RULE_tableFunctionArgumentCopartition);
        let mut _localctx: Rc<TableFunctionArgumentCopartitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2159);
			recog.base.match_token(COPARTITION,&mut recog.err_handler)?;

			/*InvokeRule copartitionTables*/
			recog.base.set_state(2160);
			recog.copartitionTables()?;

			recog.base.set_state(2165);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(280,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2161);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule copartitionTables*/
					recog.base.set_state(2162);
					recog.copartitionTables()?;

					}
					} 
				}
				recog.base.set_state(2167);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(280,&mut recog.base)?;
			}
			recog.base.set_state(2169);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2168);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,TableFunctionArgumentCopartitionContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,TableFunctionArgumentCopartitionContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,TableFunctionArgumentCopartitionContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionArgumentName ----------------
pub type TableFunctionArgumentNameContextAll<'input> = TableFunctionArgumentNameContext<'input>;


pub type TableFunctionArgumentNameContext<'input> = BaseParserRuleContext<'input,TableFunctionArgumentNameContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionArgumentNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableFunctionArgumentNameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableFunctionArgumentNameContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFunctionArgumentName(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_tableFunctionArgumentName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableFunctionArgumentNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionArgumentName(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionArgumentNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionArgumentName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionArgumentName }
}
antlr_rust::tid!{TableFunctionArgumentNameContextExt<'a>}

impl<'input> TableFunctionArgumentNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionArgumentNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionArgumentNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFunctionArgumentNameContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableFunctionArgumentNameContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableFunctionArgumentNameContextAttrs<'input> for TableFunctionArgumentNameContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionArgumentName(&mut self,)
	-> Result<Rc<TableFunctionArgumentNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionArgumentNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 192, RULE_tableFunctionArgumentName);
        let mut _localctx: Rc<TableFunctionArgumentNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2171);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionArgument ----------------
pub type TableFunctionArgumentContextAll<'input> = TableFunctionArgumentContext<'input>;


pub type TableFunctionArgumentContext<'input> = BaseParserRuleContext<'input,TableFunctionArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableFunctionArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableFunctionArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFunctionArgument(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_tableFunctionArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableFunctionArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionArgument }
}
antlr_rust::tid!{TableFunctionArgumentContextExt<'a>}

impl<'input> TableFunctionArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFunctionArgumentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableFunctionArgumentContextExt<'input>>{

fn tableArgument(&self) -> Option<Rc<TableArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn descriptorArgument(&self) -> Option<Rc<DescriptorArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableFunctionArgumentName(&self) -> Option<Rc<TableFunctionArgumentNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableFunctionArgumentContextAttrs<'input> for TableFunctionArgumentContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionArgument(&mut self,)
	-> Result<Rc<TableFunctionArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 194, RULE_tableFunctionArgument);
        let mut _localctx: Rc<TableFunctionArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2176);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(282,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule tableFunctionArgumentName*/
					recog.base.set_state(2173);
					recog.tableFunctionArgumentName()?;

					recog.base.set_state(2174);
					recog.base.match_token(T__1,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			recog.base.set_state(2181);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(283,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule tableArgument*/
					recog.base.set_state(2178);
					recog.tableArgument()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule descriptorArgument*/
					recog.base.set_state(2179);
					recog.descriptorArgument()?;

					}
				}
			,
				3 =>{
					{
					/*InvokeRule expression*/
					recog.base.set_state(2180);
					recog.expression()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableArgument ----------------
pub type TableArgumentContextAll<'input> = TableArgumentContext<'input>;


pub type TableArgumentContext<'input> = BaseParserRuleContext<'input,TableArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct TableArgumentContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableArgument(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_tableArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgument }
}
antlr_rust::tid!{TableArgumentContextExt<'a>}

impl<'input> TableArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableArgumentContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableArgumentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableArgumentContextExt<'input>>{

fn tableArgumentRelation(&self) -> Option<Rc<TableArgumentRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves first TerminalNode corresponding to token PRUNE
/// Returns `None` if there is no child corresponding to token PRUNE
fn PRUNE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRUNE, 0)
}
/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token EMPTY
/// Returns `None` if there is no child corresponding to token EMPTY
fn EMPTY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EMPTY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEEP
/// Returns `None` if there is no child corresponding to token KEEP
fn KEEP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KEEP, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableArgumentContextAttrs<'input> for TableArgumentContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableArgument(&mut self,)
	-> Result<Rc<TableArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 196, RULE_tableArgument);
        let mut _localctx: Rc<TableArgumentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableArgumentRelation*/
			recog.base.set_state(2183);
			recog.tableArgumentRelation()?;

			recog.base.set_state(2204);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PARTITION {
				{
				recog.base.set_state(2184);
				recog.base.match_token(PARTITION,&mut recog.err_handler)?;

				recog.base.set_state(2185);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(2202);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(287,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(2186);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(2198);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONVERT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOT - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RIGHT - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (POSIX - 419)) | (1usize << (STRING - 419)) | (1usize << (UNICODE_STRING - 419)) | (1usize << (DOLLAR_QUOTED_STRING - 419)) | (1usize << (BINARY_LITERAL - 419)) | (1usize << (INTEGER_VALUE - 419)) | (1usize << (DECIMAL_VALUE - 419)) | (1usize << (DOUBLE_VALUE - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)) | (1usize << (VARIABLE - 419)))) != 0) {
							{
							/*InvokeRule expression*/
							recog.base.set_state(2187);
							recog.expression()?;

							recog.base.set_state(2192);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(284,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2188);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(2189);
									recog.expression()?;

									}
									} 
								}
								recog.base.set_state(2194);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(284,&mut recog.base)?;
							}
							recog.base.set_state(2196);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2195);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								 cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA = Some(tmp);
								  

								let temp =  cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA.clone().unwrap()
								 ;
								 cast_mut::<_,TableArgumentContext >(&mut _localctx).tail.push(temp);
								  
								}
							}

							}
						}

						recog.base.set_state(2200);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule expression*/
						recog.base.set_state(2201);
						recog.expression()?;

						}
					}

					_ => {}
				}
				}
			}

			recog.base.set_state(2212);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 PRUNE 
				=> {
			    	{
			    	recog.base.set_state(2206);
			    	recog.base.match_token(PRUNE,&mut recog.err_handler)?;

			    	recog.base.set_state(2207);
			    	recog.base.match_token(WHEN,&mut recog.err_handler)?;

			    	recog.base.set_state(2208);
			    	recog.base.match_token(EMPTY,&mut recog.err_handler)?;

			    	}
			    }

			 KEEP 
				=> {
			    	{
			    	recog.base.set_state(2209);
			    	recog.base.match_token(KEEP,&mut recog.err_handler)?;

			    	recog.base.set_state(2210);
			    	recog.base.match_token(WHEN,&mut recog.err_handler)?;

			    	recog.base.set_state(2211);
			    	recog.base.match_token(EMPTY,&mut recog.err_handler)?;

			    	}
			    }

			 COMMA | COPARTITION | ORDER | RPAREN 
				=> {
			    }

				_ => {}
			}
			recog.base.set_state(2233);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				recog.base.set_state(2214);
				recog.base.match_token(ORDER,&mut recog.err_handler)?;

				recog.base.set_state(2215);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(2231);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(292,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(2216);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule sortItem*/
						recog.base.set_state(2217);
						recog.sortItem()?;

						recog.base.set_state(2222);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(290,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(2218);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule sortItem*/
								recog.base.set_state(2219);
								recog.sortItem()?;

								}
								} 
							}
							recog.base.set_state(2224);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(290,&mut recog.base)?;
						}
						recog.base.set_state(2226);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(2225);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							 cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA = Some(tmp);
							  

							let temp =  cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA.clone().unwrap()
							 ;
							 cast_mut::<_,TableArgumentContext >(&mut _localctx).tail.push(temp);
							  
							}
						}

						recog.base.set_state(2228);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule sortItem*/
						recog.base.set_state(2230);
						recog.sortItem()?;

						}
					}

					_ => {}
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableArgumentRelation ----------------
#[derive(Debug)]
pub enum TableArgumentRelationContextAll<'input>{
	TableArgumentQueryContext(TableArgumentQueryContext<'input>),
	TableArgumentTableContext(TableArgumentTableContext<'input>),
Error(TableArgumentRelationContext<'input>)
}
antlr_rust::tid!{TableArgumentRelationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TableArgumentRelationContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for TableArgumentRelationContextAll<'input>{}

impl<'input> Deref for TableArgumentRelationContextAll<'input>{
	type Target = dyn TableArgumentRelationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TableArgumentRelationContextAll::*;
		match self{
			TableArgumentQueryContext(inner) => inner,
			TableArgumentTableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableArgumentRelationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableArgumentRelationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TableArgumentRelationContext<'input> = BaseParserRuleContext<'input,TableArgumentRelationContextExt<'input>>;

#[derive(Clone)]
pub struct TableArgumentRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TableArgumentRelationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableArgumentRelationContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableArgumentRelationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TableArgumentRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}
antlr_rust::tid!{TableArgumentRelationContextExt<'a>}

impl<'input> TableArgumentRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableArgumentRelationContextAll<'input>> {
		Rc::new(
		TableArgumentRelationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableArgumentRelationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TableArgumentRelationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TableArgumentRelationContextExt<'input>>{


}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentRelationContext<'input>{}

pub type TableArgumentQueryContext<'input> = BaseParserRuleContext<'input,TableArgumentQueryContextExt<'input>>;

pub trait TableArgumentQueryContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableArgumentQueryContextAttrs<'input> for TableArgumentQueryContext<'input>{}

pub struct TableArgumentQueryContextExt<'input>{
	base:TableArgumentRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableArgumentQueryContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TableArgumentQueryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableArgumentQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableArgumentQuery(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_tableArgumentQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableArgumentQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableArgumentQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}

impl<'input> Borrow<TableArgumentRelationContextExt<'input>> for TableArgumentQueryContext<'input>{
	fn borrow(&self) -> &TableArgumentRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableArgumentRelationContextExt<'input>> for TableArgumentQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableArgumentRelationContextExt<'input> { &mut self.base }
}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentQueryContext<'input> {}

impl<'input> TableArgumentQueryContextExt<'input>{
	fn new(ctx: &dyn TableArgumentRelationContextAttrs<'input>) -> Rc<TableArgumentRelationContextAll<'input>>  {
		Rc::new(
			TableArgumentRelationContextAll::TableArgumentQueryContext(
				BaseParserRuleContext::copy_from(ctx,TableArgumentQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableArgumentTableContext<'input> = BaseParserRuleContext<'input,TableArgumentTableContextExt<'input>>;

pub trait TableArgumentTableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableArgumentTableContextAttrs<'input> for TableArgumentTableContext<'input>{}

pub struct TableArgumentTableContextExt<'input>{
	base:TableArgumentRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableArgumentTableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TableArgumentTableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TableArgumentTableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableArgumentTable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_tableArgumentTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TableArgumentTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_tableArgumentTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}

impl<'input> Borrow<TableArgumentRelationContextExt<'input>> for TableArgumentTableContext<'input>{
	fn borrow(&self) -> &TableArgumentRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableArgumentRelationContextExt<'input>> for TableArgumentTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableArgumentRelationContextExt<'input> { &mut self.base }
}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentTableContext<'input> {}

impl<'input> TableArgumentTableContextExt<'input>{
	fn new(ctx: &dyn TableArgumentRelationContextAttrs<'input>) -> Rc<TableArgumentRelationContextAll<'input>>  {
		Rc::new(
			TableArgumentRelationContextAll::TableArgumentTableContext(
				BaseParserRuleContext::copy_from(ctx,TableArgumentTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableArgumentRelation(&mut self,)
	-> Result<Rc<TableArgumentRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableArgumentRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 198, RULE_tableArgumentRelation);
        let mut _localctx: Rc<TableArgumentRelationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2261);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(300,&mut recog.base)? {
				1 =>{
					let tmp = TableArgumentTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2235);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(2236);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(2237);
					recog.qualifiedName()?;

					recog.base.set_state(2238);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2246);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(296,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2240);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==AS {
								{
								recog.base.set_state(2239);
								recog.base.match_token(AS,&mut recog.err_handler)?;

								}
							}

							/*InvokeRule identifier*/
							recog.base.set_state(2242);
							recog.identifier()?;

							recog.base.set_state(2244);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(295,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule columnAliases*/
									recog.base.set_state(2243);
									recog.columnAliases()?;

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = TableArgumentQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2248);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(2249);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2250);
					recog.query()?;

					recog.base.set_state(2251);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2259);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(299,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2253);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==AS {
								{
								recog.base.set_state(2252);
								recog.base.match_token(AS,&mut recog.err_handler)?;

								}
							}

							/*InvokeRule identifier*/
							recog.base.set_state(2255);
							recog.identifier()?;

							recog.base.set_state(2257);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(298,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule columnAliases*/
									recog.base.set_state(2256);
									recog.columnAliases()?;

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- descriptorArgument ----------------
pub type DescriptorArgumentContextAll<'input> = DescriptorArgumentContext<'input>;


pub type DescriptorArgumentContext<'input> = BaseParserRuleContext<'input,DescriptorArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct DescriptorArgumentContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for DescriptorArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DescriptorArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_descriptorArgument(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_descriptorArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DescriptorArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_descriptorArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescriptorArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_descriptorArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_descriptorArgument }
}
antlr_rust::tid!{DescriptorArgumentContextExt<'a>}

impl<'input> DescriptorArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DescriptorArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DescriptorArgumentContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DescriptorArgumentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<DescriptorArgumentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DESCRIPTOR
/// Returns `None` if there is no child corresponding to token DESCRIPTOR
fn DESCRIPTOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DESCRIPTOR, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn descriptorField_all(&self) ->  Vec<Rc<DescriptorFieldContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn descriptorField(&self, i: usize) -> Option<Rc<DescriptorFieldContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token CAST
/// Returns `None` if there is no child corresponding to token CAST
fn CAST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> DescriptorArgumentContextAttrs<'input> for DescriptorArgumentContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn descriptorArgument(&mut self,)
	-> Result<Rc<DescriptorArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DescriptorArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 200, RULE_descriptorArgument);
        let mut _localctx: Rc<DescriptorArgumentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2284);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DESCRIPTOR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2263);
					recog.base.match_token(DESCRIPTOR,&mut recog.err_handler)?;

					recog.base.set_state(2264);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule descriptorField*/
					recog.base.set_state(2265);
					recog.descriptorField()?;

					recog.base.set_state(2270);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(301,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2266);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule descriptorField*/
							recog.base.set_state(2267);
							recog.descriptorField()?;

							}
							} 
						}
						recog.base.set_state(2272);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(301,&mut recog.base)?;
					}
					recog.base.set_state(2274);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2273);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,DescriptorArgumentContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(2276);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

			 CAST 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2278);
					recog.base.match_token(CAST,&mut recog.err_handler)?;

					recog.base.set_state(2279);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2280);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					recog.base.set_state(2281);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(2282);
					recog.base.match_token(DESCRIPTOR,&mut recog.err_handler)?;

					recog.base.set_state(2283);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- descriptorField ----------------
pub type DescriptorFieldContextAll<'input> = DescriptorFieldContext<'input>;


pub type DescriptorFieldContext<'input> = BaseParserRuleContext<'input,DescriptorFieldContextExt<'input>>;

#[derive(Clone)]
pub struct DescriptorFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for DescriptorFieldContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DescriptorFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_descriptorField(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_descriptorField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DescriptorFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_descriptorField(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescriptorFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_descriptorField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_descriptorField }
}
antlr_rust::tid!{DescriptorFieldContextExt<'a>}

impl<'input> DescriptorFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DescriptorFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DescriptorFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DescriptorFieldContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<DescriptorFieldContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DescriptorFieldContextAttrs<'input> for DescriptorFieldContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn descriptorField(&mut self,)
	-> Result<Rc<DescriptorFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DescriptorFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 202, RULE_descriptorField);
        let mut _localctx: Rc<DescriptorFieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2286);
			recog.identifier()?;

			recog.base.set_state(2288);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LBRACKET - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)))) != 0) {
				{
				/*InvokeRule type_*/
				recog.base.set_state(2287);
				recog.type_()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- copartitionTables ----------------
pub type CopartitionTablesContextAll<'input> = CopartitionTablesContext<'input>;


pub type CopartitionTablesContext<'input> = BaseParserRuleContext<'input,CopartitionTablesContextExt<'input>>;

#[derive(Clone)]
pub struct CopartitionTablesContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for CopartitionTablesContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CopartitionTablesContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_copartitionTables(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_copartitionTables(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CopartitionTablesContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_copartitionTables(self);
	}
}

impl<'input> CustomRuleContext<'input> for CopartitionTablesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_copartitionTables }
	//fn type_rule_index() -> usize where Self: Sized { RULE_copartitionTables }
}
antlr_rust::tid!{CopartitionTablesContextExt<'a>}

impl<'input> CopartitionTablesContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CopartitionTablesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CopartitionTablesContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CopartitionTablesContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<CopartitionTablesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> CopartitionTablesContextAttrs<'input> for CopartitionTablesContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn copartitionTables(&mut self,)
	-> Result<Rc<CopartitionTablesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CopartitionTablesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 204, RULE_copartitionTables);
        let mut _localctx: Rc<CopartitionTablesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2290);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule qualifiedName*/
			recog.base.set_state(2291);
			recog.qualifiedName()?;

			recog.base.set_state(2292);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule qualifiedName*/
			recog.base.set_state(2293);
			recog.qualifiedName()?;

			recog.base.set_state(2298);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(305,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2294);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(2295);
					recog.qualifiedName()?;

					}
					} 
				}
				recog.base.set_state(2300);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(305,&mut recog.base)?;
			}
			recog.base.set_state(2302);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2301);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,CopartitionTablesContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			recog.base.set_state(2304);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expression ----------------
pub type ExpressionContextAll<'input> = ExpressionContext<'input>;


pub type ExpressionContext<'input> = BaseParserRuleContext<'input,ExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expression(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_expression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expression }
}
antlr_rust::tid!{ExpressionContextExt<'a>}

impl<'input> ExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ExpressionContextExt<'input>>{

fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionContextAttrs<'input> for ExpressionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expression(&mut self,)
	-> Result<Rc<ExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 206, RULE_expression);
        let mut _localctx: Rc<ExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule booleanExpression*/
			recog.base.set_state(2306);
			recog.booleanExpression_rec(0)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanExpression ----------------
#[derive(Debug)]
pub enum BooleanExpressionContextAll<'input>{
	DefaultBooleanExpressionContext(DefaultBooleanExpressionContext<'input>),
	LogicalNotContext(LogicalNotContext<'input>),
	OrContext(OrContext<'input>),
	PredicatedContext(PredicatedContext<'input>),
	AndContext(AndContext<'input>),
Error(BooleanExpressionContext<'input>)
}
antlr_rust::tid!{BooleanExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for BooleanExpressionContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for BooleanExpressionContextAll<'input>{}

impl<'input> Deref for BooleanExpressionContextAll<'input>{
	type Target = dyn BooleanExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use BooleanExpressionContextAll::*;
		match self{
			DefaultBooleanExpressionContext(inner) => inner,
			LogicalNotContext(inner) => inner,
			OrContext(inner) => inner,
			PredicatedContext(inner) => inner,
			AndContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BooleanExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BooleanExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type BooleanExpressionContext<'input> = BaseParserRuleContext<'input,BooleanExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for BooleanExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BooleanExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BooleanExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for BooleanExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}
antlr_rust::tid!{BooleanExpressionContextExt<'a>}

impl<'input> BooleanExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanExpressionContextAll<'input>> {
		Rc::new(
		BooleanExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait BooleanExpressionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<BooleanExpressionContextExt<'input>>{


}

impl<'input> BooleanExpressionContextAttrs<'input> for BooleanExpressionContext<'input>{}

pub type DefaultBooleanExpressionContext<'input> = BaseParserRuleContext<'input,DefaultBooleanExpressionContextExt<'input>>;

pub trait DefaultBooleanExpressionContextAttrs<'input>: RedshiftParserContext<'input>{
	fn nonComparisonExpression(&self) -> Option<Rc<NonComparisonExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DefaultBooleanExpressionContextAttrs<'input> for DefaultBooleanExpressionContext<'input>{}

pub struct DefaultBooleanExpressionContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	pub left: Option<Rc<NonComparisonExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultBooleanExpressionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DefaultBooleanExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DefaultBooleanExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultBooleanExpression(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_defaultBooleanExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DefaultBooleanExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_defaultBooleanExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultBooleanExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for DefaultBooleanExpressionContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for DefaultBooleanExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for DefaultBooleanExpressionContext<'input> {}

impl<'input> DefaultBooleanExpressionContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::DefaultBooleanExpressionContext(
				BaseParserRuleContext::copy_from(ctx,DefaultBooleanExpressionContextExt{
        			left:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LogicalNotContext<'input> = BaseParserRuleContext<'input,LogicalNotContextExt<'input>>;

pub trait LogicalNotContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> LogicalNotContextAttrs<'input> for LogicalNotContext<'input>{}

pub struct LogicalNotContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LogicalNotContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for LogicalNotContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LogicalNotContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_logicalNot(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_logicalNot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LogicalNotContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_logicalNot(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalNotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for LogicalNotContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for LogicalNotContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for LogicalNotContext<'input> {}

impl<'input> LogicalNotContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::LogicalNotContext(
				BaseParserRuleContext::copy_from(ctx,LogicalNotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type OrContext<'input> = BaseParserRuleContext<'input,OrContextExt<'input>>;

pub trait OrContextAttrs<'input>: RedshiftParserContext<'input>{
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
}

impl<'input> OrContextAttrs<'input> for OrContext<'input>{}

pub struct OrContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OrContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for OrContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for OrContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_or(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_or(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for OrContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_or(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for OrContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for OrContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for OrContext<'input> {}

impl<'input> OrContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::OrContext(
				BaseParserRuleContext::copy_from(ctx,OrContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PredicatedContext<'input> = BaseParserRuleContext<'input,PredicatedContextExt<'input>>;

pub trait PredicatedContextAttrs<'input>: RedshiftParserContext<'input>{
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn comparisonPredicate(&self) -> Option<Rc<ComparisonPredicateContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PredicatedContextAttrs<'input> for PredicatedContext<'input>{}

pub struct PredicatedContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	pub left: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub pred: Option<Rc<ComparisonPredicateContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PredicatedContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PredicatedContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PredicatedContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_predicated(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_predicated(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PredicatedContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_predicated(self);
	}
}

impl<'input> CustomRuleContext<'input> for PredicatedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for PredicatedContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for PredicatedContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for PredicatedContext<'input> {}

impl<'input> PredicatedContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::PredicatedContext(
				BaseParserRuleContext::copy_from(ctx,PredicatedContextExt{
        			left:None, pred:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AndContext<'input> = BaseParserRuleContext<'input,AndContextExt<'input>>;

pub trait AndContextAttrs<'input>: RedshiftParserContext<'input>{
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
}

impl<'input> AndContextAttrs<'input> for AndContext<'input>{}

pub struct AndContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AndContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AndContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AndContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_and(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_and(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AndContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_and(self);
	}
}

impl<'input> CustomRuleContext<'input> for AndContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for AndContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for AndContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for AndContext<'input> {}

impl<'input> AndContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::AndContext(
				BaseParserRuleContext::copy_from(ctx,AndContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  booleanExpression(&mut self,)
	-> Result<Rc<BooleanExpressionContextAll<'input>>,ANTLRError> {
		self.booleanExpression_rec(0)
	}

	fn booleanExpression_rec(&mut self, _p: isize)
	-> Result<Rc<BooleanExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = BooleanExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 208, RULE_booleanExpression, _p);
	    let mut _localctx: Rc<BooleanExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 208;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2312);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | CONVERT | COPARTITION | COPY | COUNT |
			 CREATE | CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE |
			 DATE | DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE |
			 DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEFT | LEVEL | LIBRARY | LIKE |
			 LIMIT | LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK |
			 LOGICAL | M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE |
			 MATERIALIZED | MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES |
			 MERGE | MIN | MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC |
			 NFD | NFKC | NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS |
			 OBJECT | OF | OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR |
			 ORDER | ORDINALITY | OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW |
			 PARTITION | PARTITIONED | PARTITIONS | PASSING | PAST | PATH | PATTERN |
			 PER | PERCENTILE_CONT | PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG |
			 PIVOT | POSITION | PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE |
			 PRIMARY | PRIVILEGES | PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE |
			 READ | RECURSIVE | REFERENCES | REFRESH | RENAME | REPEATABLE | REPLACE |
			 RESET | RESPECT | RESTRICT | RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE |
			 RIGHT | RLS | ROLE | ROLES | ROLLBACK | ROLLUP | ROW | ROWS | RUNNING |
			 S | SAGEMAKER | SCALAR | SEC | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SEEK | SELECT | SEMI | SERDE | SERDEPROPERTIES | SERIALIZABLE |
			 SESSION | SET | SETS | SHOW | SIMILAR | SOME | SORTKEY | SQL | STABLE |
			 START | STATS | STORED | STRUCT | SUBSET | SUBSTRING | SYSTEM_TIME |
			 TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY | TERMINATED | TEXT |
			 STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO | TRAILING | TRANSACTION |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE | TYPE | UESCAPE | UNBOUNDED |
			 UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE | UNKNOWN | UNMATCHED |
			 UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER | UTF16 | UTF32 | UTF8 |
			 VACUUM | VALIDATE | VALUE | VALUES | VARYING | VARIADIC | VERBOSE | VERSION |
			 VIEW | VOLATILE | WEEK | WHEN | WINDOW | WITH | WITHOUT | WORK | WRAPPER |
			 WRITE | XZ | YEAR | YEARS | YES | ZONE | ZSTD | LPAREN | LBRACKET | PLUS |
			 MINUS | DOLLAR | POSIX | STRING | UNICODE_STRING | DOLLAR_QUOTED_STRING |
			 BINARY_LITERAL | INTEGER_VALUE | DECIMAL_VALUE | DOUBLE_VALUE | IDENTIFIER |
			 DIGIT_IDENTIFIER | DOLLAR_HASH_IDENTIFIER | QUOTED_IDENTIFIER | VARIABLE 
				=> {
					{
					let mut tmp = DefaultBooleanExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					/*InvokeRule nonComparisonExpression*/
					recog.base.set_state(2309);
					let tmp = recog.nonComparisonExpression()?;
					if let BooleanExpressionContextAll::DefaultBooleanExpressionContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
					ctx.left = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}

			 NOT 
				=> {
					{
					let mut tmp = LogicalNotContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2310);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(2311);
					recog.booleanExpression_rec(3)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2324);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(309,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(2322);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(308,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = AndContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(2314);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(2315);
							recog.base.match_token(AND,&mut recog.err_handler)?;

							/*InvokeRule booleanExpression*/
							recog.base.set_state(2316);
							recog.booleanExpression_rec(3)?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = OrContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(2317);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(2318);
							recog.base.match_token(OR,&mut recog.err_handler)?;

							/*InvokeRule booleanExpression*/
							recog.base.set_state(2319);
							recog.booleanExpression_rec(2)?;

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = PredicatedContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let BooleanExpressionContextAll::PredicatedContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(2320);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							/*InvokeRule comparisonPredicate*/
							recog.base.set_state(2321);
							let tmp = recog.comparisonPredicate()?;
							if let BooleanExpressionContextAll::PredicatedContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
							ctx.pred = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(2326);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(309,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- comparisonPredicate ----------------
#[derive(Debug)]
pub enum ComparisonPredicateContextAll<'input>{
	ComparisonContext(ComparisonContext<'input>),
	QuantifiedComparisonContext(QuantifiedComparisonContext<'input>),
Error(ComparisonPredicateContext<'input>)
}
antlr_rust::tid!{ComparisonPredicateContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ComparisonPredicateContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for ComparisonPredicateContextAll<'input>{}

impl<'input> Deref for ComparisonPredicateContextAll<'input>{
	type Target = dyn ComparisonPredicateContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ComparisonPredicateContextAll::*;
		match self{
			ComparisonContext(inner) => inner,
			QuantifiedComparisonContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ComparisonPredicateContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ComparisonPredicateContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ComparisonPredicateContext<'input> = BaseParserRuleContext<'input,ComparisonPredicateContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonPredicateContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ComparisonPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ComparisonPredicateContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ComparisonPredicateContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ComparisonPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonPredicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonPredicate }
}
antlr_rust::tid!{ComparisonPredicateContextExt<'a>}

impl<'input> ComparisonPredicateContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonPredicateContextAll<'input>> {
		Rc::new(
		ComparisonPredicateContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonPredicateContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ComparisonPredicateContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ComparisonPredicateContextExt<'input>>{


}

impl<'input> ComparisonPredicateContextAttrs<'input> for ComparisonPredicateContext<'input>{}

pub type ComparisonContext<'input> = BaseParserRuleContext<'input,ComparisonContextExt<'input>>;

pub trait ComparisonContextAttrs<'input>: RedshiftParserContext<'input>{
	fn comparisonOperator(&self) -> Option<Rc<ComparisonOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ComparisonContextAttrs<'input> for ComparisonContext<'input>{}

pub struct ComparisonContextExt<'input>{
	base:ComparisonPredicateContextExt<'input>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ComparisonContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ComparisonContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ComparisonContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_comparison(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_comparison(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ComparisonContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_comparison(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonPredicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonPredicate }
}

impl<'input> Borrow<ComparisonPredicateContextExt<'input>> for ComparisonContext<'input>{
	fn borrow(&self) -> &ComparisonPredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ComparisonPredicateContextExt<'input>> for ComparisonContext<'input>{
	fn borrow_mut(&mut self) -> &mut ComparisonPredicateContextExt<'input> { &mut self.base }
}

impl<'input> ComparisonPredicateContextAttrs<'input> for ComparisonContext<'input> {}

impl<'input> ComparisonContextExt<'input>{
	fn new(ctx: &dyn ComparisonPredicateContextAttrs<'input>) -> Rc<ComparisonPredicateContextAll<'input>>  {
		Rc::new(
			ComparisonPredicateContextAll::ComparisonContext(
				BaseParserRuleContext::copy_from(ctx,ComparisonContextExt{
        			right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QuantifiedComparisonContext<'input> = BaseParserRuleContext<'input,QuantifiedComparisonContextExt<'input>>;

pub trait QuantifiedComparisonContextAttrs<'input>: RedshiftParserContext<'input>{
	fn comparisonOperator(&self) -> Option<Rc<ComparisonOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn comparisonQuantifier(&self) -> Option<Rc<ComparisonQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> QuantifiedComparisonContextAttrs<'input> for QuantifiedComparisonContext<'input>{}

pub struct QuantifiedComparisonContextExt<'input>{
	base:ComparisonPredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuantifiedComparisonContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for QuantifiedComparisonContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QuantifiedComparisonContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quantifiedComparison(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_quantifiedComparison(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QuantifiedComparisonContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_quantifiedComparison(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuantifiedComparisonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonPredicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonPredicate }
}

impl<'input> Borrow<ComparisonPredicateContextExt<'input>> for QuantifiedComparisonContext<'input>{
	fn borrow(&self) -> &ComparisonPredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ComparisonPredicateContextExt<'input>> for QuantifiedComparisonContext<'input>{
	fn borrow_mut(&mut self) -> &mut ComparisonPredicateContextExt<'input> { &mut self.base }
}

impl<'input> ComparisonPredicateContextAttrs<'input> for QuantifiedComparisonContext<'input> {}

impl<'input> QuantifiedComparisonContextExt<'input>{
	fn new(ctx: &dyn ComparisonPredicateContextAttrs<'input>) -> Rc<ComparisonPredicateContextAll<'input>>  {
		Rc::new(
			ComparisonPredicateContextAll::QuantifiedComparisonContext(
				BaseParserRuleContext::copy_from(ctx,QuantifiedComparisonContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonPredicate(&mut self,)
	-> Result<Rc<ComparisonPredicateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonPredicateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 210, RULE_comparisonPredicate);
        let mut _localctx: Rc<ComparisonPredicateContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2336);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(310,&mut recog.base)? {
				1 =>{
					let tmp = ComparisonContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule comparisonOperator*/
					recog.base.set_state(2327);
					recog.comparisonOperator()?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2328);
					let tmp = recog.valueExpression_rec(0)?;
					if let ComparisonPredicateContextAll::ComparisonContext(ctx) = cast_mut::<_,ComparisonPredicateContextAll >(&mut _localctx){
					ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = QuantifiedComparisonContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule comparisonOperator*/
					recog.base.set_state(2330);
					recog.comparisonOperator()?;

					/*InvokeRule comparisonQuantifier*/
					recog.base.set_state(2331);
					recog.comparisonQuantifier()?;

					recog.base.set_state(2332);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2333);
					recog.query()?;

					recog.base.set_state(2334);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonComparisonExpression ----------------
pub type NonComparisonExpressionContextAll<'input> = NonComparisonExpressionContext<'input>;


pub type NonComparisonExpressionContext<'input> = BaseParserRuleContext<'input,NonComparisonExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NonComparisonExpressionContextExt<'input>{
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub pred: Option<Rc<PredicateContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for NonComparisonExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NonComparisonExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonComparisonExpression(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_nonComparisonExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NonComparisonExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_nonComparisonExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NonComparisonExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonComparisonExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonComparisonExpression }
}
antlr_rust::tid!{NonComparisonExpressionContextExt<'a>}

impl<'input> NonComparisonExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonComparisonExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonComparisonExpressionContextExt{
				left: None, pred: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NonComparisonExpressionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<NonComparisonExpressionContextExt<'input>>{

fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn predicate(&self) -> Option<Rc<PredicateContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NonComparisonExpressionContextAttrs<'input> for NonComparisonExpressionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonComparisonExpression(&mut self,)
	-> Result<Rc<NonComparisonExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonComparisonExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 212, RULE_nonComparisonExpression);
        let mut _localctx: Rc<NonComparisonExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule valueExpression*/
			recog.base.set_state(2338);
			let tmp = recog.valueExpression_rec(0)?;
			 cast_mut::<_,NonComparisonExpressionContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(2340);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(311,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule predicate*/
					recog.base.set_state(2339);
					let tmp = recog.predicate()?;
					 cast_mut::<_,NonComparisonExpressionContext >(&mut _localctx).pred = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- predicate ----------------
#[derive(Debug)]
pub enum PredicateContextAll<'input>{
	FalsePredicateContext(FalsePredicateContext<'input>),
	UnknownPredicateContext(UnknownPredicateContext<'input>),
	LikeContext(LikeContext<'input>),
	InSubqueryContext(InSubqueryContext<'input>),
	DistinctFromContext(DistinctFromContext<'input>),
	SimilarToContext(SimilarToContext<'input>),
	TruePredicateContext(TruePredicateContext<'input>),
	InListContext(InListContext<'input>),
	NullPredicateContext(NullPredicateContext<'input>),
	BetweenContext(BetweenContext<'input>),
Error(PredicateContext<'input>)
}
antlr_rust::tid!{PredicateContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PredicateContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PredicateContextAll<'input>{}

impl<'input> Deref for PredicateContextAll<'input>{
	type Target = dyn PredicateContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PredicateContextAll::*;
		match self{
			FalsePredicateContext(inner) => inner,
			UnknownPredicateContext(inner) => inner,
			LikeContext(inner) => inner,
			InSubqueryContext(inner) => inner,
			DistinctFromContext(inner) => inner,
			SimilarToContext(inner) => inner,
			TruePredicateContext(inner) => inner,
			InListContext(inner) => inner,
			NullPredicateContext(inner) => inner,
			BetweenContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PredicateContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PredicateContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PredicateContext<'input> = BaseParserRuleContext<'input,PredicateContextExt<'input>>;

#[derive(Clone)]
pub struct PredicateContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PredicateContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PredicateContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PredicateContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}
antlr_rust::tid!{PredicateContextExt<'a>}

impl<'input> PredicateContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PredicateContextAll<'input>> {
		Rc::new(
		PredicateContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PredicateContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PredicateContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PredicateContextExt<'input>>{


}

impl<'input> PredicateContextAttrs<'input> for PredicateContext<'input>{}

pub type FalsePredicateContext<'input> = BaseParserRuleContext<'input,FalsePredicateContextExt<'input>>;

pub trait FalsePredicateContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FALSE
	/// Returns `None` if there is no child corresponding to token FALSE
	fn FALSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FALSE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> FalsePredicateContextAttrs<'input> for FalsePredicateContext<'input>{}

pub struct FalsePredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FalsePredicateContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FalsePredicateContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FalsePredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_falsePredicate(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_falsePredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FalsePredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_falsePredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for FalsePredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for FalsePredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for FalsePredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for FalsePredicateContext<'input> {}

impl<'input> FalsePredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::FalsePredicateContext(
				BaseParserRuleContext::copy_from(ctx,FalsePredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnknownPredicateContext<'input> = BaseParserRuleContext<'input,UnknownPredicateContextExt<'input>>;

pub trait UnknownPredicateContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UNKNOWN
	/// Returns `None` if there is no child corresponding to token UNKNOWN
	fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UNKNOWN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> UnknownPredicateContextAttrs<'input> for UnknownPredicateContext<'input>{}

pub struct UnknownPredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnknownPredicateContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UnknownPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UnknownPredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unknownPredicate(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_unknownPredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UnknownPredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_unknownPredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnknownPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for UnknownPredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for UnknownPredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for UnknownPredicateContext<'input> {}

impl<'input> UnknownPredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::UnknownPredicateContext(
				BaseParserRuleContext::copy_from(ctx,UnknownPredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LikeContext<'input> = BaseParserRuleContext<'input,LikeContextExt<'input>>;

pub trait LikeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ILIKE
	/// Returns `None` if there is no child corresponding to token ILIKE
	fn ILIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ILIKE, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ESCAPE
	/// Returns `None` if there is no child corresponding to token ESCAPE
	fn ESCAPE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ESCAPE, 0)
	}
}

impl<'input> LikeContextAttrs<'input> for LikeContext<'input>{}

pub struct LikeContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub pattern: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub escape: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LikeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for LikeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LikeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_like(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_like(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_like(self);
	}
}

impl<'input> CustomRuleContext<'input> for LikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for LikeContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for LikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for LikeContext<'input> {}

impl<'input> LikeContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::LikeContext(
				BaseParserRuleContext::copy_from(ctx,LikeContextExt{
        			pattern:None, escape:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InSubqueryContext<'input> = BaseParserRuleContext<'input,InSubqueryContextExt<'input>>;

pub trait InSubqueryContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> InSubqueryContextAttrs<'input> for InSubqueryContext<'input>{}

pub struct InSubqueryContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InSubqueryContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for InSubqueryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for InSubqueryContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inSubquery(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_inSubquery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for InSubqueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_inSubquery(self);
	}
}

impl<'input> CustomRuleContext<'input> for InSubqueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for InSubqueryContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for InSubqueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for InSubqueryContext<'input> {}

impl<'input> InSubqueryContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::InSubqueryContext(
				BaseParserRuleContext::copy_from(ctx,InSubqueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DistinctFromContext<'input> = BaseParserRuleContext<'input,DistinctFromContextExt<'input>>;

pub trait DistinctFromContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DISTINCT
	/// Returns `None` if there is no child corresponding to token DISTINCT
	fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DISTINCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> DistinctFromContextAttrs<'input> for DistinctFromContext<'input>{}

pub struct DistinctFromContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DistinctFromContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DistinctFromContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DistinctFromContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_distinctFrom(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_distinctFrom(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DistinctFromContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_distinctFrom(self);
	}
}

impl<'input> CustomRuleContext<'input> for DistinctFromContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for DistinctFromContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for DistinctFromContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for DistinctFromContext<'input> {}

impl<'input> DistinctFromContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::DistinctFromContext(
				BaseParserRuleContext::copy_from(ctx,DistinctFromContextExt{
        			right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SimilarToContext<'input> = BaseParserRuleContext<'input,SimilarToContextExt<'input>>;

pub trait SimilarToContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SIMILAR
	/// Returns `None` if there is no child corresponding to token SIMILAR
	fn SIMILAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SIMILAR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ESCAPE
	/// Returns `None` if there is no child corresponding to token ESCAPE
	fn ESCAPE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ESCAPE, 0)
	}
}

impl<'input> SimilarToContextAttrs<'input> for SimilarToContext<'input>{}

pub struct SimilarToContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub pattern: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub escape: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SimilarToContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SimilarToContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SimilarToContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_similarTo(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_similarTo(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SimilarToContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_similarTo(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimilarToContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for SimilarToContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for SimilarToContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for SimilarToContext<'input> {}

impl<'input> SimilarToContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::SimilarToContext(
				BaseParserRuleContext::copy_from(ctx,SimilarToContextExt{
        			pattern:None, escape:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TruePredicateContext<'input> = BaseParserRuleContext<'input,TruePredicateContextExt<'input>>;

pub trait TruePredicateContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRUE
	/// Returns `None` if there is no child corresponding to token TRUE
	fn TRUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TRUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> TruePredicateContextAttrs<'input> for TruePredicateContext<'input>{}

pub struct TruePredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TruePredicateContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TruePredicateContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TruePredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_truePredicate(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_truePredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TruePredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_truePredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for TruePredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for TruePredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for TruePredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for TruePredicateContext<'input> {}

impl<'input> TruePredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::TruePredicateContext(
				BaseParserRuleContext::copy_from(ctx,TruePredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InListContext<'input> = BaseParserRuleContext<'input,InListContextExt<'input>>;

pub trait InListContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> InListContextAttrs<'input> for InListContext<'input>{}

pub struct InListContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InListContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for InListContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for InListContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inList(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_inList(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for InListContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_inList(self);
	}
}

impl<'input> CustomRuleContext<'input> for InListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for InListContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for InListContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for InListContext<'input> {}

impl<'input> InListContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::InListContext(
				BaseParserRuleContext::copy_from(ctx,InListContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NullPredicateContext<'input> = BaseParserRuleContext<'input,NullPredicateContextExt<'input>>;

pub trait NullPredicateContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOTNULL
	/// Returns `None` if there is no child corresponding to token NOTNULL
	fn NOTNULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOTNULL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ISNULL
	/// Returns `None` if there is no child corresponding to token ISNULL
	fn ISNULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ISNULL, 0)
	}
}

impl<'input> NullPredicateContextAttrs<'input> for NullPredicateContext<'input>{}

pub struct NullPredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NullPredicateContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for NullPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NullPredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nullPredicate(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_nullPredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NullPredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_nullPredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for NullPredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for NullPredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for NullPredicateContext<'input> {}

impl<'input> NullPredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::NullPredicateContext(
				BaseParserRuleContext::copy_from(ctx,NullPredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BetweenContext<'input> = BaseParserRuleContext<'input,BetweenContextExt<'input>>;

pub trait BetweenContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BETWEEN
	/// Returns `None` if there is no child corresponding to token BETWEEN
	fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BETWEEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> BetweenContextAttrs<'input> for BetweenContext<'input>{}

pub struct BetweenContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub lower: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub upper: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BetweenContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for BetweenContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BetweenContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_between(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_between(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BetweenContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_between(self);
	}
}

impl<'input> CustomRuleContext<'input> for BetweenContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for BetweenContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for BetweenContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for BetweenContext<'input> {}

impl<'input> BetweenContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::BetweenContext(
				BaseParserRuleContext::copy_from(ctx,BetweenContextExt{
        			lower:None, upper:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn predicate(&mut self,)
	-> Result<Rc<PredicateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PredicateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 214, RULE_predicate);
        let mut _localctx: Rc<PredicateContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2424);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(326,&mut recog.base)? {
				1 =>{
					let tmp = BetweenContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2343);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2342);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2345);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2346);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::BetweenContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.lower = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2347);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2348);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::BetweenContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.upper = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = InListContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2351);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2350);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2353);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2354);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2355);
					recog.expression()?;

					recog.base.set_state(2360);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(314,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2356);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2357);
							recog.expression()?;

							}
							} 
						}
						recog.base.set_state(2362);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(314,&mut recog.base)?;
					}
					recog.base.set_state(2364);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2363);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PredicateContextAll::InListContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2366);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = InSubqueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2369);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2368);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2371);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2372);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2373);
					recog.query()?;

					recog.base.set_state(2374);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = LikeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(2377);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2376);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2379);
					_la = recog.base.input.la(1);
					if { !(_la==ILIKE || _la==LIKE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2380);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::LikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2383);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(318,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2381);
							recog.base.match_token(ESCAPE,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(2382);
							let tmp = recog.valueExpression_rec(0)?;
							if let PredicateContextAll::LikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
							ctx.escape = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				5 =>{
					let tmp = SimilarToContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(2386);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2385);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2388);
					recog.base.match_token(SIMILAR,&mut recog.err_handler)?;

					recog.base.set_state(2389);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2390);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::SimilarToContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2393);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(320,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2391);
							recog.base.match_token(ESCAPE,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(2392);
							let tmp = recog.valueExpression_rec(0)?;
							if let PredicateContextAll::SimilarToContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
							ctx.escape = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				6 =>{
					let tmp = NullPredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(2395);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2397);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2396);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2399);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = DistinctFromContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(2400);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2402);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2401);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2404);
					recog.base.match_token(DISTINCT,&mut recog.err_handler)?;

					recog.base.set_state(2405);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2406);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::DistinctFromContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				8 =>{
					let tmp = NullPredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(2407);
					recog.base.match_token(NOTNULL,&mut recog.err_handler)?;

					}
				}
			,
				9 =>{
					let tmp = NullPredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(2408);
					recog.base.match_token(ISNULL,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					let tmp = TruePredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(2409);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2411);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2410);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2413);
					recog.base.match_token(TRUE,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					let tmp = FalsePredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(2414);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2416);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2415);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2418);
					recog.base.match_token(FALSE,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					let tmp = UnknownPredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 12);
					_localctx = tmp;
					{
					recog.base.set_state(2419);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2421);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2420);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2423);
					recog.base.match_token(UNKNOWN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valueExpression ----------------
#[derive(Debug)]
pub enum ValueExpressionContextAll<'input>{
	ValueExpressionDefaultContext(ValueExpressionDefaultContext<'input>),
	ConcatenationContext(ConcatenationContext<'input>),
	ArithmeticBinaryContext(ArithmeticBinaryContext<'input>),
	ArithmeticUnaryContext(ArithmeticUnaryContext<'input>),
	AtTimeZoneContext(AtTimeZoneContext<'input>),
Error(ValueExpressionContext<'input>)
}
antlr_rust::tid!{ValueExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ValueExpressionContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for ValueExpressionContextAll<'input>{}

impl<'input> Deref for ValueExpressionContextAll<'input>{
	type Target = dyn ValueExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ValueExpressionContextAll::*;
		match self{
			ValueExpressionDefaultContext(inner) => inner,
			ConcatenationContext(inner) => inner,
			ArithmeticBinaryContext(inner) => inner,
			ArithmeticUnaryContext(inner) => inner,
			AtTimeZoneContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ValueExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ValueExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ValueExpressionContext<'input> = BaseParserRuleContext<'input,ValueExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ValueExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ValueExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ValueExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ValueExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ValueExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}
antlr_rust::tid!{ValueExpressionContextExt<'a>}

impl<'input> ValueExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValueExpressionContextAll<'input>> {
		Rc::new(
		ValueExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValueExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ValueExpressionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ValueExpressionContextExt<'input>>{


}

impl<'input> ValueExpressionContextAttrs<'input> for ValueExpressionContext<'input>{}

pub type ValueExpressionDefaultContext<'input> = BaseParserRuleContext<'input,ValueExpressionDefaultContextExt<'input>>;

pub trait ValueExpressionDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ValueExpressionDefaultContextAttrs<'input> for ValueExpressionDefaultContext<'input>{}

pub struct ValueExpressionDefaultContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ValueExpressionDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ValueExpressionDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ValueExpressionDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_valueExpressionDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_valueExpressionDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ValueExpressionDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_valueExpressionDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for ValueExpressionDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ValueExpressionDefaultContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ValueExpressionDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ValueExpressionDefaultContext<'input> {}

impl<'input> ValueExpressionDefaultContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ValueExpressionDefaultContext(
				BaseParserRuleContext::copy_from(ctx,ValueExpressionDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ConcatenationContext<'input> = BaseParserRuleContext<'input,ConcatenationContextExt<'input>>;

pub trait ConcatenationContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CONCAT
	/// Returns `None` if there is no child corresponding to token CONCAT
	fn CONCAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CONCAT, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> ConcatenationContextAttrs<'input> for ConcatenationContext<'input>{}

pub struct ConcatenationContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ConcatenationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ConcatenationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ConcatenationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_concatenation(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_concatenation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ConcatenationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_concatenation(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConcatenationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ConcatenationContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ConcatenationContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ConcatenationContext<'input> {}

impl<'input> ConcatenationContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ConcatenationContext(
				BaseParserRuleContext::copy_from(ctx,ConcatenationContextExt{
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArithmeticBinaryContext<'input> = BaseParserRuleContext<'input,ArithmeticBinaryContextExt<'input>>;

pub trait ArithmeticBinaryContextAttrs<'input>: RedshiftParserContext<'input>{
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SLASH
	/// Returns `None` if there is no child corresponding to token SLASH
	fn SLASH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SLASH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PERCENT
	/// Returns `None` if there is no child corresponding to token PERCENT
	fn PERCENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PERCENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_SHIFT_LEFT
	/// Returns `None` if there is no child corresponding to token BITWISE_SHIFT_LEFT
	fn BITWISE_SHIFT_LEFT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_SHIFT_LEFT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_AND
	/// Returns `None` if there is no child corresponding to token BITWISE_AND
	fn BITWISE_AND(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_AND, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_OR
	/// Returns `None` if there is no child corresponding to token BITWISE_OR
	fn BITWISE_OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_XOR
	/// Returns `None` if there is no child corresponding to token BITWISE_XOR
	fn BITWISE_XOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_XOR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BINARY_EXP
	/// Returns `None` if there is no child corresponding to token BINARY_EXP
	fn BINARY_EXP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BINARY_EXP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX
	/// Returns `None` if there is no child corresponding to token POSIX
	fn POSIX(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(POSIX, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX_LIKE
	/// Returns `None` if there is no child corresponding to token POSIX_LIKE
	fn POSIX_LIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(POSIX_LIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX_ILIKE
	/// Returns `None` if there is no child corresponding to token POSIX_ILIKE
	fn POSIX_ILIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(POSIX_ILIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX_NOT_LIKE
	/// Returns `None` if there is no child corresponding to token POSIX_NOT_LIKE
	fn POSIX_NOT_LIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(POSIX_NOT_LIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX_NOT_ILIKE
	/// Returns `None` if there is no child corresponding to token POSIX_NOT_ILIKE
	fn POSIX_NOT_ILIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(POSIX_NOT_ILIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX_STAR
	/// Returns `None` if there is no child corresponding to token POSIX_STAR
	fn POSIX_STAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(POSIX_STAR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_SHIFT_RIGHT
	/// Returns `None` if there is no child corresponding to token BITWISE_SHIFT_RIGHT
	fn BITWISE_SHIFT_RIGHT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_SHIFT_RIGHT, 0)
	}
}

impl<'input> ArithmeticBinaryContextAttrs<'input> for ArithmeticBinaryContext<'input>{}

pub struct ArithmeticBinaryContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub operator: Option<TokenType<'input>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArithmeticBinaryContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ArithmeticBinaryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ArithmeticBinaryContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arithmeticBinary(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_arithmeticBinary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ArithmeticBinaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_arithmeticBinary(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticBinaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ArithmeticBinaryContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ArithmeticBinaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ArithmeticBinaryContext<'input> {}

impl<'input> ArithmeticBinaryContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ArithmeticBinaryContext(
				BaseParserRuleContext::copy_from(ctx,ArithmeticBinaryContextExt{
					operator:None, 
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArithmeticUnaryContext<'input> = BaseParserRuleContext<'input,ArithmeticUnaryContextExt<'input>>;

pub trait ArithmeticUnaryContextAttrs<'input>: RedshiftParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX
	/// Returns `None` if there is no child corresponding to token POSIX
	fn POSIX(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(POSIX, 0)
	}
}

impl<'input> ArithmeticUnaryContextAttrs<'input> for ArithmeticUnaryContext<'input>{}

pub struct ArithmeticUnaryContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub operator: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArithmeticUnaryContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ArithmeticUnaryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ArithmeticUnaryContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arithmeticUnary(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_arithmeticUnary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ArithmeticUnaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_arithmeticUnary(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticUnaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ArithmeticUnaryContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ArithmeticUnaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ArithmeticUnaryContext<'input> {}

impl<'input> ArithmeticUnaryContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ArithmeticUnaryContext(
				BaseParserRuleContext::copy_from(ctx,ArithmeticUnaryContextExt{
					operator:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AtTimeZoneContext<'input> = BaseParserRuleContext<'input,AtTimeZoneContextExt<'input>>;

pub trait AtTimeZoneContextAttrs<'input>: RedshiftParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AT
	/// Returns `None` if there is no child corresponding to token AT
	fn AT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AT, 0)
	}
	fn timeZoneSpecifier(&self) -> Option<Rc<TimeZoneSpecifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AtTimeZoneContextAttrs<'input> for AtTimeZoneContext<'input>{}

pub struct AtTimeZoneContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AtTimeZoneContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AtTimeZoneContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AtTimeZoneContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_atTimeZone(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_atTimeZone(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AtTimeZoneContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_atTimeZone(self);
	}
}

impl<'input> CustomRuleContext<'input> for AtTimeZoneContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for AtTimeZoneContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for AtTimeZoneContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for AtTimeZoneContext<'input> {}

impl<'input> AtTimeZoneContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::AtTimeZoneContext(
				BaseParserRuleContext::copy_from(ctx,AtTimeZoneContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  valueExpression(&mut self,)
	-> Result<Rc<ValueExpressionContextAll<'input>>,ANTLRError> {
		self.valueExpression_rec(0)
	}

	fn valueExpression_rec(&mut self, _p: isize)
	-> Result<Rc<ValueExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = ValueExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 216, RULE_valueExpression, _p);
	    let mut _localctx: Rc<ValueExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 216;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2433);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(328,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = ValueExpressionDefaultContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					/*InvokeRule primaryExpression*/
					recog.base.set_state(2427);
					recog.primaryExpression_rec(0)?;

					recog.base.set_state(2429);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(327,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2428);
							recog.base.match_token(T__2,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					{
					let mut tmp = ArithmeticUnaryContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2431);
					if let ValueExpressionContextAll::ArithmeticUnaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
					ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(((((_la - 410)) & !0x3f) == 0 && ((1usize << (_la - 410)) & ((1usize << (PLUS - 410)) | (1usize << (MINUS - 410)) | (1usize << (POSIX - 410)))) != 0)) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let ValueExpressionContextAll::ArithmeticUnaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
						ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2432);
					recog.valueExpression_rec(8)?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2461);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(330,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(2459);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(329,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2435);
							if !({recog.precpred(None, 7)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 7)".to_owned()), None))?;
							}
							recog.base.set_state(2436);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(((((_la - 412)) & !0x3f) == 0 && ((1usize << (_la - 412)) & ((1usize << (ASTERISK - 412)) | (1usize << (SLASH - 412)) | (1usize << (PERCENT - 412)))) != 0)) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2437);
							let tmp = recog.valueExpression_rec(8)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2438);
							if !({recog.precpred(None, 6)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 6)".to_owned()), None))?;
							}
							recog.base.set_state(2439);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==PLUS || _la==MINUS) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2440);
							let tmp = recog.valueExpression_rec(7)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ConcatenationContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ConcatenationContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2441);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							recog.base.set_state(2442);
							recog.base.match_token(CONCAT,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(2443);
							let tmp = recog.valueExpression_rec(6)?;
							if let ValueExpressionContextAll::ConcatenationContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						4 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2444);
							if !({recog.precpred(None, 4)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 4)".to_owned()), None))?;
							}
							recog.base.set_state(2445);
							let tmp = recog.base.match_token(BITWISE_SHIFT_LEFT,&mut recog.err_handler)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							/*InvokeRule valueExpression*/
							recog.base.set_state(2446);
							let tmp = recog.valueExpression_rec(5)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						5 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2447);
							if !({recog.precpred(None, 3)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 3)".to_owned()), None))?;
							}
							recog.base.set_state(2448);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(((((_la - 420)) & !0x3f) == 0 && ((1usize << (_la - 420)) & ((1usize << (BITWISE_AND - 420)) | (1usize << (BITWISE_OR - 420)) | (1usize << (BITWISE_XOR - 420)))) != 0)) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2449);
							let tmp = recog.valueExpression_rec(4)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						6 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2450);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(2451);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(((((_la - 423)) & !0x3f) == 0 && ((1usize << (_la - 423)) & ((1usize << (BINARY_EXP - 423)) | (1usize << (POSIX - 423)) | (1usize << (POSIX_LIKE - 423)) | (1usize << (POSIX_ILIKE - 423)) | (1usize << (POSIX_NOT_LIKE - 423)) | (1usize << (POSIX_NOT_ILIKE - 423)) | (1usize << (POSIX_STAR - 423)))) != 0)) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2452);
							let tmp = recog.valueExpression_rec(3)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						7 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2453);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(2454);
							let tmp = recog.base.match_token(BITWISE_SHIFT_RIGHT,&mut recog.err_handler)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							/*InvokeRule valueExpression*/
							recog.base.set_state(2455);
							let tmp = recog.valueExpression_rec(2)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						8 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = AtTimeZoneContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2456);
							if !({recog.precpred(None, 9)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 9)".to_owned()), None))?;
							}
							recog.base.set_state(2457);
							recog.base.match_token(AT,&mut recog.err_handler)?;

							/*InvokeRule timeZoneSpecifier*/
							recog.base.set_state(2458);
							recog.timeZoneSpecifier()?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(2463);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(330,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- primaryExpression ----------------
#[derive(Debug)]
pub enum PrimaryExpressionContextAll<'input>{
	DereferenceContext(DereferenceContext<'input>),
	RedshiftExtractContext(RedshiftExtractContext<'input>),
	FirstValueFunctionContext(FirstValueFunctionContext<'input>),
	TypeConstructorContext(TypeConstructorContext<'input>),
	JsonValueContext(JsonValueContext<'input>),
	AtTimeZonePrimaryContext(AtTimeZonePrimaryContext<'input>),
	ConvertContext(ConvertContext<'input>),
	SubstringContext(SubstringContext<'input>),
	CountStarContext(CountStarContext<'input>),
	PercentileContFunctionContext(PercentileContFunctionContext<'input>),
	CastContext(CastContext<'input>),
	LambdaContext(LambdaContext<'input>),
	ParenthesizedExpressionContext(ParenthesizedExpressionContext<'input>),
	TrimContext(TrimContext<'input>),
	FunctionParameterColumnReferenceContext(FunctionParameterColumnReferenceContext<'input>),
	NormalizeContext(NormalizeContext<'input>),
	JsonObjectContext(JsonObjectContext<'input>),
	CastOperatorContext(CastOperatorContext<'input>),
	IntervalLiteralContext(IntervalLiteralContext<'input>),
	NumericLiteralContext(NumericLiteralContext<'input>),
	BooleanLiteralContext(BooleanLiteralContext<'input>),
	JsonArrayContext(JsonArrayContext<'input>),
	SimpleCaseContext(SimpleCaseContext<'input>),
	ColumnReferenceContext(ColumnReferenceContext<'input>),
	NullLiteralContext(NullLiteralContext<'input>),
	RowConstructorContext(RowConstructorContext<'input>),
	SubscriptContext(SubscriptContext<'input>),
	JsonExistsContext(JsonExistsContext<'input>),
	SubqueryExpressionContext(SubqueryExpressionContext<'input>),
	BinaryLiteralContext(BinaryLiteralContext<'input>),
	JsonQueryContext(JsonQueryContext<'input>),
	MeasureContext(MeasureContext<'input>),
	StringLiteralContext(StringLiteralContext<'input>),
	ArrayConstructorContext(ArrayConstructorContext<'input>),
	FunctionCallContext(FunctionCallContext<'input>),
	ApproximateFunctionContext(ApproximateFunctionContext<'input>),
	VariableContext(VariableContext<'input>),
	ExistsContext(ExistsContext<'input>),
	PercentileDiscFunctionContext(PercentileDiscFunctionContext<'input>),
	PositionContext(PositionContext<'input>),
	ListaggContext(ListaggContext<'input>),
	SearchedCaseContext(SearchedCaseContext<'input>),
Error(PrimaryExpressionContext<'input>)
}
antlr_rust::tid!{PrimaryExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PrimaryExpressionContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PrimaryExpressionContextAll<'input>{}

impl<'input> Deref for PrimaryExpressionContextAll<'input>{
	type Target = dyn PrimaryExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PrimaryExpressionContextAll::*;
		match self{
			DereferenceContext(inner) => inner,
			RedshiftExtractContext(inner) => inner,
			FirstValueFunctionContext(inner) => inner,
			TypeConstructorContext(inner) => inner,
			JsonValueContext(inner) => inner,
			AtTimeZonePrimaryContext(inner) => inner,
			ConvertContext(inner) => inner,
			SubstringContext(inner) => inner,
			CountStarContext(inner) => inner,
			PercentileContFunctionContext(inner) => inner,
			CastContext(inner) => inner,
			LambdaContext(inner) => inner,
			ParenthesizedExpressionContext(inner) => inner,
			TrimContext(inner) => inner,
			FunctionParameterColumnReferenceContext(inner) => inner,
			NormalizeContext(inner) => inner,
			JsonObjectContext(inner) => inner,
			CastOperatorContext(inner) => inner,
			IntervalLiteralContext(inner) => inner,
			NumericLiteralContext(inner) => inner,
			BooleanLiteralContext(inner) => inner,
			JsonArrayContext(inner) => inner,
			SimpleCaseContext(inner) => inner,
			ColumnReferenceContext(inner) => inner,
			NullLiteralContext(inner) => inner,
			RowConstructorContext(inner) => inner,
			SubscriptContext(inner) => inner,
			JsonExistsContext(inner) => inner,
			SubqueryExpressionContext(inner) => inner,
			BinaryLiteralContext(inner) => inner,
			JsonQueryContext(inner) => inner,
			MeasureContext(inner) => inner,
			StringLiteralContext(inner) => inner,
			ArrayConstructorContext(inner) => inner,
			FunctionCallContext(inner) => inner,
			ApproximateFunctionContext(inner) => inner,
			VariableContext(inner) => inner,
			ExistsContext(inner) => inner,
			PercentileDiscFunctionContext(inner) => inner,
			PositionContext(inner) => inner,
			ListaggContext(inner) => inner,
			SearchedCaseContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PrimaryExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PrimaryExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PrimaryExpressionContext<'input> = BaseParserRuleContext<'input,PrimaryExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrimaryExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PrimaryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PrimaryExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PrimaryExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PrimaryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}
antlr_rust::tid!{PrimaryExpressionContextExt<'a>}

impl<'input> PrimaryExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrimaryExpressionContextAll<'input>> {
		Rc::new(
		PrimaryExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrimaryExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PrimaryExpressionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PrimaryExpressionContextExt<'input>>{


}

impl<'input> PrimaryExpressionContextAttrs<'input> for PrimaryExpressionContext<'input>{}

pub type DereferenceContext<'input> = BaseParserRuleContext<'input,DereferenceContextExt<'input>>;

pub trait DereferenceContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn columnNameComponent(&self) -> Option<Rc<ColumnNameComponentContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DereferenceContextAttrs<'input> for DereferenceContext<'input>{}

pub struct DereferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub base_: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub fieldName: Option<Rc<ColumnNameComponentContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DereferenceContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DereferenceContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DereferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dereference(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_dereference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DereferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_dereference(self);
	}
}

impl<'input> CustomRuleContext<'input> for DereferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for DereferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for DereferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for DereferenceContext<'input> {}

impl<'input> DereferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::DereferenceContext(
				BaseParserRuleContext::copy_from(ctx,DereferenceContextExt{
        			base_:None, fieldName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RedshiftExtractContext<'input> = BaseParserRuleContext<'input,RedshiftExtractContextExt<'input>>;

pub trait RedshiftExtractContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXTRACT
	/// Returns `None` if there is no child corresponding to token EXTRACT
	fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXTRACT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RedshiftExtractContextAttrs<'input> for RedshiftExtractContext<'input>{}

pub struct RedshiftExtractContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RedshiftExtractContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RedshiftExtractContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RedshiftExtractContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_redshiftExtract(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_redshiftExtract(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RedshiftExtractContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_redshiftExtract(self);
	}
}

impl<'input> CustomRuleContext<'input> for RedshiftExtractContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for RedshiftExtractContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for RedshiftExtractContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for RedshiftExtractContext<'input> {}

impl<'input> RedshiftExtractContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::RedshiftExtractContext(
				BaseParserRuleContext::copy_from(ctx,RedshiftExtractContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FirstValueFunctionContext<'input> = BaseParserRuleContext<'input,FirstValueFunctionContextExt<'input>>;

pub trait FirstValueFunctionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FIRST_VALUE
	/// Returns `None` if there is no child corresponding to token FIRST_VALUE
	fn FIRST_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FIRST_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LAST_VALUE
	/// Returns `None` if there is no child corresponding to token LAST_VALUE
	fn LAST_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LAST_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LAG
	/// Returns `None` if there is no child corresponding to token LAG
	fn LAG(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LAG, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULLS
	/// Returns `None` if there is no child corresponding to token NULLS
	fn NULLS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NULLS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IGNORE
	/// Returns `None` if there is no child corresponding to token IGNORE
	fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IGNORE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RESPECT
	/// Returns `None` if there is no child corresponding to token RESPECT
	fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RESPECT, 0)
	}
}

impl<'input> FirstValueFunctionContextAttrs<'input> for FirstValueFunctionContext<'input>{}

pub struct FirstValueFunctionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FirstValueFunctionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FirstValueFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FirstValueFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_firstValueFunction(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_firstValueFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FirstValueFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_firstValueFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for FirstValueFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FirstValueFunctionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FirstValueFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FirstValueFunctionContext<'input> {}

impl<'input> FirstValueFunctionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FirstValueFunctionContext(
				BaseParserRuleContext::copy_from(ctx,FirstValueFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TypeConstructorContext<'input> = BaseParserRuleContext<'input,TypeConstructorContextExt<'input>>;

pub trait TypeConstructorContextAttrs<'input>: RedshiftParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DOUBLE
	/// Returns `None` if there is no child corresponding to token DOUBLE
	fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOUBLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECISION
	/// Returns `None` if there is no child corresponding to token PRECISION
	fn PRECISION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PRECISION, 0)
	}
}

impl<'input> TypeConstructorContextAttrs<'input> for TypeConstructorContext<'input>{}

pub struct TypeConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TypeConstructorContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TypeConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TypeConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_typeConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_typeConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TypeConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_typeConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TypeConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TypeConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TypeConstructorContext<'input> {}

impl<'input> TypeConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TypeConstructorContext(
				BaseParserRuleContext::copy_from(ctx,TypeConstructorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JsonValueContext<'input> = BaseParserRuleContext<'input,JsonValueContextExt<'input>>;

pub trait JsonValueContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token JSON_VALUE
	/// Returns `None` if there is no child corresponding to token JSON_VALUE
	fn JSON_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(JSON_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn jsonPathInvocation(&self) -> Option<Rc<JsonPathInvocationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNING
	/// Returns `None` if there is no child corresponding to token RETURNING
	fn RETURNING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RETURNING, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token ON in current rule
	fn ON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ON, starting from 0.
	/// Returns `None` if number of children corresponding to token ON is less or equal than `i`.
	fn ON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ON, i)
	}
	/// Retrieves first TerminalNode corresponding to token EMPTY
	/// Returns `None` if there is no child corresponding to token EMPTY
	fn EMPTY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EMPTY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ERROR
	/// Returns `None` if there is no child corresponding to token ERROR
	fn ERROR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ERROR, 0)
	}
	fn jsonValueBehavior_all(&self) ->  Vec<Rc<JsonValueBehaviorContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn jsonValueBehavior(&self, i: usize) -> Option<Rc<JsonValueBehaviorContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> JsonValueContextAttrs<'input> for JsonValueContext<'input>{}

pub struct JsonValueContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub emptyBehavior: Option<Rc<JsonValueBehaviorContextAll<'input>>>,
	pub errorBehavior: Option<Rc<JsonValueBehaviorContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JsonValueContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for JsonValueContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonValueContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_jsonValue(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_jsonValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for JsonValueContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for JsonValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for JsonValueContext<'input> {}

impl<'input> JsonValueContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::JsonValueContext(
				BaseParserRuleContext::copy_from(ctx,JsonValueContextExt{
        			emptyBehavior:None, errorBehavior:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AtTimeZonePrimaryContext<'input> = BaseParserRuleContext<'input,AtTimeZonePrimaryContextExt<'input>>;

pub trait AtTimeZonePrimaryContextAttrs<'input>: RedshiftParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AT
	/// Returns `None` if there is no child corresponding to token AT
	fn AT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AT, 0)
	}
	fn timeZoneSpecifier(&self) -> Option<Rc<TimeZoneSpecifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AtTimeZonePrimaryContextAttrs<'input> for AtTimeZonePrimaryContext<'input>{}

pub struct AtTimeZonePrimaryContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AtTimeZonePrimaryContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for AtTimeZonePrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for AtTimeZonePrimaryContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_atTimeZonePrimary(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_atTimeZonePrimary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for AtTimeZonePrimaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_atTimeZonePrimary(self);
	}
}

impl<'input> CustomRuleContext<'input> for AtTimeZonePrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for AtTimeZonePrimaryContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for AtTimeZonePrimaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for AtTimeZonePrimaryContext<'input> {}

impl<'input> AtTimeZonePrimaryContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::AtTimeZonePrimaryContext(
				BaseParserRuleContext::copy_from(ctx,AtTimeZonePrimaryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ConvertContext<'input> = BaseParserRuleContext<'input,ConvertContextExt<'input>>;

pub trait ConvertContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CONVERT
	/// Returns `None` if there is no child corresponding to token CONVERT
	fn CONVERT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CONVERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ConvertContextAttrs<'input> for ConvertContext<'input>{}

pub struct ConvertContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ConvertContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ConvertContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ConvertContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_convert(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_convert(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ConvertContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_convert(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConvertContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ConvertContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ConvertContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ConvertContext<'input> {}

impl<'input> ConvertContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ConvertContext(
				BaseParserRuleContext::copy_from(ctx,ConvertContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubstringContext<'input> = BaseParserRuleContext<'input,SubstringContextExt<'input>>;

pub trait SubstringContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SUBSTRING
	/// Returns `None` if there is no child corresponding to token SUBSTRING
	fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SUBSTRING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
}

impl<'input> SubstringContextAttrs<'input> for SubstringContext<'input>{}

pub struct SubstringContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubstringContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SubstringContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SubstringContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_substring(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_substring(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SubstringContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_substring(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubstringContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubstringContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubstringContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubstringContext<'input> {}

impl<'input> SubstringContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubstringContext(
				BaseParserRuleContext::copy_from(ctx,SubstringContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CountStarContext<'input> = BaseParserRuleContext<'input,CountStarContextExt<'input>>;

pub trait CountStarContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COUNT
	/// Returns `None` if there is no child corresponding to token COUNT
	fn COUNT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COUNT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn functionCallTail(&self) -> Option<Rc<FunctionCallTailContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CountStarContextAttrs<'input> for CountStarContext<'input>{}

pub struct CountStarContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CountStarContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CountStarContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CountStarContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_countStar(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_countStar(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CountStarContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_countStar(self);
	}
}

impl<'input> CustomRuleContext<'input> for CountStarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CountStarContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CountStarContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CountStarContext<'input> {}

impl<'input> CountStarContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CountStarContext(
				BaseParserRuleContext::copy_from(ctx,CountStarContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PercentileContFunctionContext<'input> = BaseParserRuleContext<'input,PercentileContFunctionContextExt<'input>>;

pub trait PercentileContFunctionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PERCENTILE_CONT
	/// Returns `None` if there is no child corresponding to token PERCENTILE_CONT
	fn PERCENTILE_CONT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PERCENTILE_CONT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OVER
	/// Returns `None` if there is no child corresponding to token OVER
	fn OVER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OVER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ASC
	/// Returns `None` if there is no child corresponding to token ASC
	fn ASC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ASC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PercentileContFunctionContextAttrs<'input> for PercentileContFunctionContext<'input>{}

pub struct PercentileContFunctionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PercentileContFunctionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PercentileContFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PercentileContFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_percentileContFunction(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_percentileContFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PercentileContFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_percentileContFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for PercentileContFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for PercentileContFunctionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for PercentileContFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for PercentileContFunctionContext<'input> {}

impl<'input> PercentileContFunctionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::PercentileContFunctionContext(
				BaseParserRuleContext::copy_from(ctx,PercentileContFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CastContext<'input> = BaseParserRuleContext<'input,CastContextExt<'input>>;

pub trait CastContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CAST
	/// Returns `None` if there is no child corresponding to token CAST
	fn CAST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CAST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRY_CAST
	/// Returns `None` if there is no child corresponding to token TRY_CAST
	fn TRY_CAST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TRY_CAST, 0)
	}
}

impl<'input> CastContextAttrs<'input> for CastContext<'input>{}

pub struct CastContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CastContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CastContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CastContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_cast(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_cast(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CastContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_cast(self);
	}
}

impl<'input> CustomRuleContext<'input> for CastContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CastContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CastContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CastContext<'input> {}

impl<'input> CastContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CastContext(
				BaseParserRuleContext::copy_from(ctx,CastContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LambdaContext<'input> = BaseParserRuleContext<'input,LambdaContextExt<'input>>;

pub trait LambdaContextAttrs<'input>: RedshiftParserContext<'input>{
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> LambdaContextAttrs<'input> for LambdaContext<'input>{}

pub struct LambdaContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LambdaContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for LambdaContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LambdaContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_lambda(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_lambda(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LambdaContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_lambda(self);
	}
}

impl<'input> CustomRuleContext<'input> for LambdaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for LambdaContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for LambdaContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for LambdaContext<'input> {}

impl<'input> LambdaContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::LambdaContext(
				BaseParserRuleContext::copy_from(ctx,LambdaContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ParenthesizedExpressionContext<'input> = BaseParserRuleContext<'input,ParenthesizedExpressionContextExt<'input>>;

pub trait ParenthesizedExpressionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ParenthesizedExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input>{}

pub struct ParenthesizedExpressionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ParenthesizedExpressionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ParenthesizedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_parenthesizedExpression(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_parenthesizedExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_parenthesizedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParenthesizedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ParenthesizedExpressionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ParenthesizedExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input> {}

impl<'input> ParenthesizedExpressionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ParenthesizedExpressionContext(
				BaseParserRuleContext::copy_from(ctx,ParenthesizedExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TrimContext<'input> = BaseParserRuleContext<'input,TrimContextExt<'input>>;

pub trait TrimContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRIM
	/// Returns `None` if there is no child corresponding to token TRIM
	fn TRIM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TRIM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn trimsSpecification(&self) -> Option<Rc<TrimsSpecificationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> TrimContextAttrs<'input> for TrimContext<'input>{}

pub struct TrimContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub trimChar: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub trimSource: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TrimContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TrimContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TrimContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_trim(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_trim(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TrimContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_trim(self);
	}
}

impl<'input> CustomRuleContext<'input> for TrimContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TrimContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TrimContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TrimContext<'input> {}

impl<'input> TrimContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TrimContext(
				BaseParserRuleContext::copy_from(ctx,TrimContextExt{
					tail:None, 
        			trimChar:None, trimSource:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionParameterColumnReferenceContext<'input> = BaseParserRuleContext<'input,FunctionParameterColumnReferenceContextExt<'input>>;

pub trait FunctionParameterColumnReferenceContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOLLAR
	/// Returns `None` if there is no child corresponding to token DOLLAR
	fn DOLLAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
}

impl<'input> FunctionParameterColumnReferenceContextAttrs<'input> for FunctionParameterColumnReferenceContext<'input>{}

pub struct FunctionParameterColumnReferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionParameterColumnReferenceContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionParameterColumnReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionParameterColumnReferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionParameterColumnReference(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionParameterColumnReference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionParameterColumnReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionParameterColumnReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionParameterColumnReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FunctionParameterColumnReferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FunctionParameterColumnReferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FunctionParameterColumnReferenceContext<'input> {}

impl<'input> FunctionParameterColumnReferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FunctionParameterColumnReferenceContext(
				BaseParserRuleContext::copy_from(ctx,FunctionParameterColumnReferenceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NormalizeContext<'input> = BaseParserRuleContext<'input,NormalizeContextExt<'input>>;

pub trait NormalizeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NORMALIZE
	/// Returns `None` if there is no child corresponding to token NORMALIZE
	fn NORMALIZE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NORMALIZE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	fn normalForm(&self) -> Option<Rc<NormalFormContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NormalizeContextAttrs<'input> for NormalizeContext<'input>{}

pub struct NormalizeContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NormalizeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for NormalizeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NormalizeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_normalize(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_normalize(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NormalizeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_normalize(self);
	}
}

impl<'input> CustomRuleContext<'input> for NormalizeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for NormalizeContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for NormalizeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for NormalizeContext<'input> {}

impl<'input> NormalizeContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::NormalizeContext(
				BaseParserRuleContext::copy_from(ctx,NormalizeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JsonObjectContext<'input> = BaseParserRuleContext<'input,JsonObjectContextExt<'input>>;

pub trait JsonObjectContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token JSON_OBJECT
	/// Returns `None` if there is no child corresponding to token JSON_OBJECT
	fn JSON_OBJECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(JSON_OBJECT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn jsonObjectMember_all(&self) ->  Vec<Rc<JsonObjectMemberContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn jsonObjectMember(&self, i: usize) -> Option<Rc<JsonObjectMemberContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNING
	/// Returns `None` if there is no child corresponding to token RETURNING
	fn RETURNING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RETURNING, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token NULL in current rule
	fn NULL_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token NULL, starting from 0.
	/// Returns `None` if number of children corresponding to token NULL is less or equal than `i`.
	fn NULL(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NULL, i)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ABSENT
	/// Returns `None` if there is no child corresponding to token ABSENT
	fn ABSENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ABSENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UNIQUE
	/// Returns `None` if there is no child corresponding to token UNIQUE
	fn UNIQUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UNIQUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WITHOUT
	/// Returns `None` if there is no child corresponding to token WITHOUT
	fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITHOUT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMAT
	/// Returns `None` if there is no child corresponding to token FORMAT
	fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FORMAT, 0)
	}
	fn jsonRepresentation(&self) -> Option<Rc<JsonRepresentationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token KEYS
	/// Returns `None` if there is no child corresponding to token KEYS
	fn KEYS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(KEYS, 0)
	}
}

impl<'input> JsonObjectContextAttrs<'input> for JsonObjectContext<'input>{}

pub struct JsonObjectContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JsonObjectContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for JsonObjectContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonObjectContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_jsonObject(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_jsonObject(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonObjectContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonObject(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonObjectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for JsonObjectContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for JsonObjectContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for JsonObjectContext<'input> {}

impl<'input> JsonObjectContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::JsonObjectContext(
				BaseParserRuleContext::copy_from(ctx,JsonObjectContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CastOperatorContext<'input> = BaseParserRuleContext<'input,CastOperatorContextExt<'input>>;

pub trait CastOperatorContextAttrs<'input>: RedshiftParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CastOperatorContextAttrs<'input> for CastOperatorContext<'input>{}

pub struct CastOperatorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CastOperatorContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CastOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CastOperatorContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_castOperator(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_castOperator(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CastOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_castOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for CastOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CastOperatorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CastOperatorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CastOperatorContext<'input> {}

impl<'input> CastOperatorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CastOperatorContext(
				BaseParserRuleContext::copy_from(ctx,CastOperatorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntervalLiteralContext<'input> = BaseParserRuleContext<'input,IntervalLiteralContextExt<'input>>;

pub trait IntervalLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IntervalLiteralContextAttrs<'input> for IntervalLiteralContext<'input>{}

pub struct IntervalLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntervalLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for IntervalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IntervalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_intervalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_intervalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IntervalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_intervalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for IntervalLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for IntervalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for IntervalLiteralContext<'input> {}

impl<'input> IntervalLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::IntervalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IntervalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NumericLiteralContext<'input> = BaseParserRuleContext<'input,NumericLiteralContextExt<'input>>;

pub trait NumericLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NumericLiteralContextAttrs<'input> for NumericLiteralContext<'input>{}

pub struct NumericLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NumericLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for NumericLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NumericLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_numericLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_numericLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NumericLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_numericLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NumericLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for NumericLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for NumericLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for NumericLiteralContext<'input> {}

impl<'input> NumericLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::NumericLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NumericLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BooleanLiteralContext<'input> = BaseParserRuleContext<'input,BooleanLiteralContextExt<'input>>;

pub trait BooleanLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	fn booleanValue(&self) -> Option<Rc<BooleanValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> BooleanLiteralContextAttrs<'input> for BooleanLiteralContext<'input>{}

pub struct BooleanLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BooleanLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for BooleanLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BooleanLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_booleanLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_booleanLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BooleanLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_booleanLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for BooleanLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for BooleanLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for BooleanLiteralContext<'input> {}

impl<'input> BooleanLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::BooleanLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BooleanLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JsonArrayContext<'input> = BaseParserRuleContext<'input,JsonArrayContextExt<'input>>;

pub trait JsonArrayContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token JSON_ARRAY
	/// Returns `None` if there is no child corresponding to token JSON_ARRAY
	fn JSON_ARRAY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(JSON_ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn jsonValueExpression_all(&self) ->  Vec<Rc<JsonValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn jsonValueExpression(&self, i: usize) -> Option<Rc<JsonValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNING
	/// Returns `None` if there is no child corresponding to token RETURNING
	fn RETURNING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RETURNING, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token NULL in current rule
	fn NULL_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token NULL, starting from 0.
	/// Returns `None` if number of children corresponding to token NULL is less or equal than `i`.
	fn NULL(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NULL, i)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ABSENT
	/// Returns `None` if there is no child corresponding to token ABSENT
	fn ABSENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ABSENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMAT
	/// Returns `None` if there is no child corresponding to token FORMAT
	fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FORMAT, 0)
	}
	fn jsonRepresentation(&self) -> Option<Rc<JsonRepresentationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> JsonArrayContextAttrs<'input> for JsonArrayContext<'input>{}

pub struct JsonArrayContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JsonArrayContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for JsonArrayContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonArrayContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_jsonArray(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_jsonArray(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonArrayContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonArray(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonArrayContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for JsonArrayContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for JsonArrayContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for JsonArrayContext<'input> {}

impl<'input> JsonArrayContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::JsonArrayContext(
				BaseParserRuleContext::copy_from(ctx,JsonArrayContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SimpleCaseContext<'input> = BaseParserRuleContext<'input,SimpleCaseContextExt<'input>>;

pub trait SimpleCaseContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CASE
	/// Returns `None` if there is no child corresponding to token CASE
	fn CASE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CASE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn whenClause_all(&self) ->  Vec<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn whenClause(&self, i: usize) -> Option<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
}

impl<'input> SimpleCaseContextAttrs<'input> for SimpleCaseContext<'input>{}

pub struct SimpleCaseContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub operand: Option<Rc<ExpressionContextAll<'input>>>,
	pub elseExpression: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SimpleCaseContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SimpleCaseContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SimpleCaseContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_simpleCase(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_simpleCase(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SimpleCaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_simpleCase(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SimpleCaseContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SimpleCaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SimpleCaseContext<'input> {}

impl<'input> SimpleCaseContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SimpleCaseContext(
				BaseParserRuleContext::copy_from(ctx,SimpleCaseContextExt{
        			operand:None, elseExpression:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ColumnReferenceContext<'input> = BaseParserRuleContext<'input,ColumnReferenceContextExt<'input>>;

pub trait ColumnReferenceContextAttrs<'input>: RedshiftParserContext<'input>{
	fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ColumnReferenceContextAttrs<'input> for ColumnReferenceContext<'input>{}

pub struct ColumnReferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnReferenceContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ColumnReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ColumnReferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnReference(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_columnReference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ColumnReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_columnReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ColumnReferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ColumnReferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ColumnReferenceContext<'input> {}

impl<'input> ColumnReferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ColumnReferenceContext(
				BaseParserRuleContext::copy_from(ctx,ColumnReferenceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NullLiteralContext<'input> = BaseParserRuleContext<'input,NullLiteralContextExt<'input>>;

pub trait NullLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
}

impl<'input> NullLiteralContextAttrs<'input> for NullLiteralContext<'input>{}

pub struct NullLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NullLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for NullLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NullLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nullLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_nullLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NullLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_nullLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for NullLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for NullLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for NullLiteralContext<'input> {}

impl<'input> NullLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::NullLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NullLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RowConstructorContext<'input> = BaseParserRuleContext<'input,RowConstructorContextExt<'input>>;

pub trait RowConstructorContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
}

impl<'input> RowConstructorContextAttrs<'input> for RowConstructorContext<'input>{}

pub struct RowConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowConstructorContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RowConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RowConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_rowConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RowConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rowConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for RowConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for RowConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for RowConstructorContext<'input> {}

impl<'input> RowConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::RowConstructorContext(
				BaseParserRuleContext::copy_from(ctx,RowConstructorContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubscriptContext<'input> = BaseParserRuleContext<'input,SubscriptContextExt<'input>>;

pub trait SubscriptContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SubscriptContextAttrs<'input> for SubscriptContext<'input>{}

pub struct SubscriptContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub value: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub index: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubscriptContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SubscriptContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SubscriptContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subscript(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_subscript(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SubscriptContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_subscript(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubscriptContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubscriptContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubscriptContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubscriptContext<'input> {}

impl<'input> SubscriptContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubscriptContext(
				BaseParserRuleContext::copy_from(ctx,SubscriptContextExt{
        			value:None, index:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JsonExistsContext<'input> = BaseParserRuleContext<'input,JsonExistsContextExt<'input>>;

pub trait JsonExistsContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token JSON_EXISTS
	/// Returns `None` if there is no child corresponding to token JSON_EXISTS
	fn JSON_EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(JSON_EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn jsonPathInvocation(&self) -> Option<Rc<JsonPathInvocationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn jsonExistsErrorBehavior(&self) -> Option<Rc<JsonExistsErrorBehaviorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ERROR
	/// Returns `None` if there is no child corresponding to token ERROR
	fn ERROR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ERROR, 0)
	}
}

impl<'input> JsonExistsContextAttrs<'input> for JsonExistsContext<'input>{}

pub struct JsonExistsContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JsonExistsContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for JsonExistsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonExistsContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_jsonExists(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_jsonExists(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonExistsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonExists(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonExistsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for JsonExistsContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for JsonExistsContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for JsonExistsContext<'input> {}

impl<'input> JsonExistsContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::JsonExistsContext(
				BaseParserRuleContext::copy_from(ctx,JsonExistsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubqueryExpressionContext<'input> = BaseParserRuleContext<'input,SubqueryExpressionContextExt<'input>>;

pub trait SubqueryExpressionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> SubqueryExpressionContextAttrs<'input> for SubqueryExpressionContext<'input>{}

pub struct SubqueryExpressionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryExpressionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SubqueryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SubqueryExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subqueryExpression(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_subqueryExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SubqueryExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_subqueryExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubqueryExpressionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubqueryExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubqueryExpressionContext<'input> {}

impl<'input> SubqueryExpressionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubqueryExpressionContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BinaryLiteralContext<'input> = BaseParserRuleContext<'input,BinaryLiteralContextExt<'input>>;

pub trait BinaryLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BINARY_LITERAL
	/// Returns `None` if there is no child corresponding to token BINARY_LITERAL
	fn BINARY_LITERAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BINARY_LITERAL, 0)
	}
}

impl<'input> BinaryLiteralContextAttrs<'input> for BinaryLiteralContext<'input>{}

pub struct BinaryLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BinaryLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for BinaryLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BinaryLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_binaryLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_binaryLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BinaryLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_binaryLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BinaryLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for BinaryLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for BinaryLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for BinaryLiteralContext<'input> {}

impl<'input> BinaryLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::BinaryLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BinaryLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JsonQueryContext<'input> = BaseParserRuleContext<'input,JsonQueryContextExt<'input>>;

pub trait JsonQueryContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token JSON_QUERY
	/// Returns `None` if there is no child corresponding to token JSON_QUERY
	fn JSON_QUERY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(JSON_QUERY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn jsonPathInvocation(&self) -> Option<Rc<JsonPathInvocationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNING
	/// Returns `None` if there is no child corresponding to token RETURNING
	fn RETURNING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RETURNING, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn jsonQueryWrapperBehavior(&self) -> Option<Rc<JsonQueryWrapperBehaviorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token WRAPPER
	/// Returns `None` if there is no child corresponding to token WRAPPER
	fn WRAPPER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WRAPPER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token QUOTES
	/// Returns `None` if there is no child corresponding to token QUOTES
	fn QUOTES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(QUOTES, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token ON in current rule
	fn ON_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ON, starting from 0.
	/// Returns `None` if number of children corresponding to token ON is less or equal than `i`.
	fn ON(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ON, i)
	}
	/// Retrieves first TerminalNode corresponding to token EMPTY
	/// Returns `None` if there is no child corresponding to token EMPTY
	fn EMPTY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EMPTY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ERROR
	/// Returns `None` if there is no child corresponding to token ERROR
	fn ERROR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ERROR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token KEEP
	/// Returns `None` if there is no child corresponding to token KEEP
	fn KEEP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(KEEP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OMIT
	/// Returns `None` if there is no child corresponding to token OMIT
	fn OMIT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OMIT, 0)
	}
	fn jsonQueryBehavior_all(&self) ->  Vec<Rc<JsonQueryBehaviorContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn jsonQueryBehavior(&self, i: usize) -> Option<Rc<JsonQueryBehaviorContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FORMAT
	/// Returns `None` if there is no child corresponding to token FORMAT
	fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FORMAT, 0)
	}
	fn jsonRepresentation(&self) -> Option<Rc<JsonRepresentationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SCALAR
	/// Returns `None` if there is no child corresponding to token SCALAR
	fn SCALAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SCALAR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token STRING_KW
	/// Returns `None` if there is no child corresponding to token STRING_KW
	fn STRING_KW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(STRING_KW, 0)
	}
}

impl<'input> JsonQueryContextAttrs<'input> for JsonQueryContext<'input>{}

pub struct JsonQueryContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub emptyBehavior: Option<Rc<JsonQueryBehaviorContextAll<'input>>>,
	pub errorBehavior: Option<Rc<JsonQueryBehaviorContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JsonQueryContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for JsonQueryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_jsonQuery(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_jsonQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for JsonQueryContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for JsonQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for JsonQueryContext<'input> {}

impl<'input> JsonQueryContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::JsonQueryContext(
				BaseParserRuleContext::copy_from(ctx,JsonQueryContextExt{
        			emptyBehavior:None, errorBehavior:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MeasureContext<'input> = BaseParserRuleContext<'input,MeasureContextExt<'input>>;

pub trait MeasureContextAttrs<'input>: RedshiftParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MeasureContextAttrs<'input> for MeasureContext<'input>{}

pub struct MeasureContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MeasureContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for MeasureContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for MeasureContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_measure(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_measure(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for MeasureContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_measure(self);
	}
}

impl<'input> CustomRuleContext<'input> for MeasureContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for MeasureContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for MeasureContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for MeasureContext<'input> {}

impl<'input> MeasureContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::MeasureContext(
				BaseParserRuleContext::copy_from(ctx,MeasureContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StringLiteralContext<'input> = BaseParserRuleContext<'input,StringLiteralContextExt<'input>>;

pub trait StringLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StringLiteralContextAttrs<'input> for StringLiteralContext<'input>{}

pub struct StringLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StringLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for StringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_stringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_stringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_stringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for StringLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for StringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for StringLiteralContext<'input> {}

impl<'input> StringLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::StringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,StringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArrayConstructorContext<'input> = BaseParserRuleContext<'input,ArrayConstructorContextExt<'input>>;

pub trait ArrayConstructorContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ArrayConstructorContextAttrs<'input> for ArrayConstructorContext<'input>{}

pub struct ArrayConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArrayConstructorContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ArrayConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ArrayConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arrayConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_arrayConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ArrayConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_arrayConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArrayConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ArrayConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ArrayConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ArrayConstructorContext<'input> {}

impl<'input> ArrayConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ArrayConstructorContext(
				BaseParserRuleContext::copy_from(ctx,ArrayConstructorContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionCallContext<'input> = BaseParserRuleContext<'input,FunctionCallContextExt<'input>>;

pub trait FunctionCallContextAttrs<'input>: RedshiftParserContext<'input>{
	fn functionCallHead(&self) -> Option<Rc<FunctionCallHeadContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn functionCallTail(&self) -> Option<Rc<FunctionCallTailContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn functionExtraArguments(&self) -> Option<Rc<FunctionExtraArgumentsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FunctionCallContextAttrs<'input> for FunctionCallContext<'input>{}

pub struct FunctionCallContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionCallContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionCallContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionCall(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionCall(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FunctionCallContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FunctionCallContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FunctionCallContext<'input> {}

impl<'input> FunctionCallContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FunctionCallContext(
				BaseParserRuleContext::copy_from(ctx,FunctionCallContextExt{
					COMMA:None, 
        			tail:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ApproximateFunctionContext<'input> = BaseParserRuleContext<'input,ApproximateFunctionContextExt<'input>>;

pub trait ApproximateFunctionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token APPROXIMATE
	/// Returns `None` if there is no child corresponding to token APPROXIMATE
	fn APPROXIMATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(APPROXIMATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PERCENTILE_DISC
	/// Returns `None` if there is no child corresponding to token PERCENTILE_DISC
	fn PERCENTILE_DISC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PERCENTILE_DISC, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COUNT
	/// Returns `None` if there is no child corresponding to token COUNT
	fn COUNT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COUNT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DISTINCT
	/// Returns `None` if there is no child corresponding to token DISTINCT
	fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DISTINCT, 0)
	}
	fn callArgument(&self) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ApproximateFunctionContextAttrs<'input> for ApproximateFunctionContext<'input>{}

pub struct ApproximateFunctionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ApproximateFunctionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ApproximateFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ApproximateFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_approximateFunction(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_approximateFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ApproximateFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_approximateFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for ApproximateFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ApproximateFunctionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ApproximateFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ApproximateFunctionContext<'input> {}

impl<'input> ApproximateFunctionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ApproximateFunctionContext(
				BaseParserRuleContext::copy_from(ctx,ApproximateFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type VariableContext<'input> = BaseParserRuleContext<'input,VariableContextExt<'input>>;

pub trait VariableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token VARIABLE
	/// Returns `None` if there is no child corresponding to token VARIABLE
	fn VARIABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VARIABLE, 0)
	}
}

impl<'input> VariableContextAttrs<'input> for VariableContext<'input>{}

pub struct VariableContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{VariableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for VariableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for VariableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_variable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_variable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for VariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_variable(self);
	}
}

impl<'input> CustomRuleContext<'input> for VariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for VariableContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for VariableContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for VariableContext<'input> {}

impl<'input> VariableContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::VariableContext(
				BaseParserRuleContext::copy_from(ctx,VariableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExistsContext<'input> = BaseParserRuleContext<'input,ExistsContextExt<'input>>;

pub trait ExistsContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ExistsContextAttrs<'input> for ExistsContext<'input>{}

pub struct ExistsContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExistsContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ExistsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ExistsContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_exists(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_exists(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ExistsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_exists(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExistsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ExistsContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ExistsContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ExistsContext<'input> {}

impl<'input> ExistsContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ExistsContext(
				BaseParserRuleContext::copy_from(ctx,ExistsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PercentileDiscFunctionContext<'input> = BaseParserRuleContext<'input,PercentileDiscFunctionContextExt<'input>>;

pub trait PercentileDiscFunctionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PERCENTILE_DISC
	/// Returns `None` if there is no child corresponding to token PERCENTILE_DISC
	fn PERCENTILE_DISC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PERCENTILE_DISC, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OVER
	/// Returns `None` if there is no child corresponding to token OVER
	fn OVER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OVER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ASC
	/// Returns `None` if there is no child corresponding to token ASC
	fn ASC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ASC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PercentileDiscFunctionContextAttrs<'input> for PercentileDiscFunctionContext<'input>{}

pub struct PercentileDiscFunctionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PercentileDiscFunctionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PercentileDiscFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PercentileDiscFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_percentileDiscFunction(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_percentileDiscFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PercentileDiscFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_percentileDiscFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for PercentileDiscFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for PercentileDiscFunctionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for PercentileDiscFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for PercentileDiscFunctionContext<'input> {}

impl<'input> PercentileDiscFunctionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::PercentileDiscFunctionContext(
				BaseParserRuleContext::copy_from(ctx,PercentileDiscFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PositionContext<'input> = BaseParserRuleContext<'input,PositionContextExt<'input>>;

pub trait PositionContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token POSITION
	/// Returns `None` if there is no child corresponding to token POSITION
	fn POSITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(POSITION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> PositionContextAttrs<'input> for PositionContext<'input>{}

pub struct PositionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub needle: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub haystack: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PositionContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PositionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PositionContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_position(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_position(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PositionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_position(self);
	}
}

impl<'input> CustomRuleContext<'input> for PositionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for PositionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for PositionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for PositionContext<'input> {}

impl<'input> PositionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::PositionContext(
				BaseParserRuleContext::copy_from(ctx,PositionContextExt{
        			needle:None, haystack:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ListaggContext<'input> = BaseParserRuleContext<'input,ListaggContextExt<'input>>;

pub trait ListaggContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token LISTAGG
	/// Returns `None` if there is no child corresponding to token LISTAGG
	fn LISTAGG(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LISTAGG, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LISTAGGDISTINCT
	/// Returns `None` if there is no child corresponding to token LISTAGGDISTINCT
	fn LISTAGGDISTINCT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LISTAGGDISTINCT, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token PG_CATALOG
	/// Returns `None` if there is no child corresponding to token PG_CATALOG
	fn PG_CATALOG(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PG_CATALOG, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OVER
	/// Returns `None` if there is no child corresponding to token OVER
	fn OVER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(OVER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
}

impl<'input> ListaggContextAttrs<'input> for ListaggContext<'input>{}

pub struct ListaggContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub agg_exprs:Vec<Rc<ExpressionContextAll<'input>>>,
	pub agg_expr:Vec<Rc<ExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ListaggContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ListaggContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ListaggContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_listagg(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_listagg(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ListaggContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_listagg(self);
	}
}

impl<'input> CustomRuleContext<'input> for ListaggContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ListaggContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ListaggContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ListaggContext<'input> {}

impl<'input> ListaggContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ListaggContext(
				BaseParserRuleContext::copy_from(ctx,ListaggContextExt{
					COMMA:None, 
        			tail:Vec::new(), 
        			expression:None, 
        			agg_exprs:Vec::new(), agg_expr:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SearchedCaseContext<'input> = BaseParserRuleContext<'input,SearchedCaseContextExt<'input>>;

pub trait SearchedCaseContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CASE
	/// Returns `None` if there is no child corresponding to token CASE
	fn CASE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CASE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn whenClause_all(&self) ->  Vec<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn whenClause(&self, i: usize) -> Option<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SearchedCaseContextAttrs<'input> for SearchedCaseContext<'input>{}

pub struct SearchedCaseContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub elseExpression: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SearchedCaseContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SearchedCaseContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SearchedCaseContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_searchedCase(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_searchedCase(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SearchedCaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_searchedCase(self);
	}
}

impl<'input> CustomRuleContext<'input> for SearchedCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SearchedCaseContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SearchedCaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SearchedCaseContext<'input> {}

impl<'input> SearchedCaseContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SearchedCaseContext(
				BaseParserRuleContext::copy_from(ctx,SearchedCaseContextExt{
        			elseExpression:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  primaryExpression(&mut self,)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		self.primaryExpression_rec(0)
	}

	fn primaryExpression_rec(&mut self, _p: isize)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = PrimaryExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 218, RULE_primaryExpression, _p);
	    let mut _localctx: Rc<PrimaryExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 218;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3008);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(404,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = NullLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					recog.base.set_state(2465);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					{
					let mut tmp = IntervalLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule interval*/
					recog.base.set_state(2466);
					recog.interval()?;

					}
				}
			,
				3 =>{
					{
					let mut tmp = NumericLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule number*/
					recog.base.set_state(2467);
					recog.number()?;

					}
				}
			,
				4 =>{
					{
					let mut tmp = BooleanLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule booleanValue*/
					recog.base.set_state(2468);
					recog.booleanValue()?;

					}
				}
			,
				5 =>{
					{
					let mut tmp = StringLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule string*/
					recog.base.set_state(2469);
					recog.string()?;

					}
				}
			,
				6 =>{
					{
					let mut tmp = BinaryLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2470);
					recog.base.match_token(BINARY_LITERAL,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					{
					let mut tmp = TypeConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(2471);
					recog.identifier()?;

					/*InvokeRule string*/
					recog.base.set_state(2472);
					recog.string()?;

					}
				}
			,
				8 =>{
					{
					let mut tmp = TypeConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2474);
					recog.base.match_token(DOUBLE,&mut recog.err_handler)?;

					recog.base.set_state(2475);
					recog.base.match_token(PRECISION,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(2476);
					recog.string()?;

					}
				}
			,
				9 =>{
					{
					let mut tmp = RowConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2477);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2478);
					recog.expression()?;

					recog.base.set_state(2481); 
					recog.err_handler.sync(&mut recog.base)?;
					_alt = 1;
					loop {
						match _alt {
						    x if x == 1=>
							{
							{
							recog.base.set_state(2479);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2480);
							recog.expression()?;

							}
							}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						recog.base.set_state(2483); 
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(331,&mut recog.base)?;
						if _alt==2 || _alt==INVALID_ALT { break }
					}
					recog.base.set_state(2486);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2485);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::RowConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2488);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					{
					let mut tmp = RowConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2490);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					recog.base.set_state(2491);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2492);
					recog.expression()?;

					recog.base.set_state(2497);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2493);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(2494);
						recog.expression()?;

						}
						}
						recog.base.set_state(2499);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2500);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					{
					let mut tmp = PositionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2502);
					recog.base.match_token(POSITION,&mut recog.err_handler)?;

					recog.base.set_state(2503);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2504);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::PositionContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.needle = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2505);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2506);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::PositionContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.haystack = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2507);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					{
					let mut tmp = ListaggContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2511);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PG_CATALOG {
						{
						recog.base.set_state(2509);
						recog.base.match_token(PG_CATALOG,&mut recog.err_handler)?;

						recog.base.set_state(2510);
						recog.base.match_token(DOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2513);
					_la = recog.base.input.la(1);
					if { !(_la==LISTAGG || _la==LISTAGGDISTINCT) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2514);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2516);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(335,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(2515);
							recog.setQuantifier()?;

							}
						}

						_ => {}
					}
					/*InvokeRule expression*/
					recog.base.set_state(2518);
					let tmp = recog.expression()?;
					if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.agg_exprs.push(temp); } else {unreachable!("cant cast");}  
					recog.base.set_state(2521);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(336,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2519);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2520);
							let tmp = recog.expression()?;
							if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							let temp = if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.agg_expr.push(temp); } else {unreachable!("cant cast");}  
							}
						}

						_ => {}
					}
					recog.base.set_state(2524);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2523);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

						let temp = if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail.push(temp); } else {unreachable!("cant cast");}  
						}
					}

					recog.base.set_state(2526);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2545);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(340,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2527);
							recog.base.match_token(WITHIN,&mut recog.err_handler)?;

							recog.base.set_state(2528);
							recog.base.match_token(GROUP,&mut recog.err_handler)?;

							recog.base.set_state(2529);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(2530);
							recog.base.match_token(ORDER,&mut recog.err_handler)?;

							recog.base.set_state(2531);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule sortItem*/
							recog.base.set_state(2532);
							recog.sortItem()?;

							recog.base.set_state(2537);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(338,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2533);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule sortItem*/
									recog.base.set_state(2534);
									recog.sortItem()?;

									}
									} 
								}
								recog.base.set_state(2539);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(338,&mut recog.base)?;
							}
							recog.base.set_state(2541);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2540);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

								let temp = if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
								if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.tail.push(temp); } else {unreachable!("cant cast");}  
								}
							}

							recog.base.set_state(2543);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2562);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(343,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2547);
							recog.base.match_token(OVER,&mut recog.err_handler)?;

							recog.base.set_state(2548);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(2559);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==PARTITION {
								{
								recog.base.set_state(2549);
								recog.base.match_token(PARTITION,&mut recog.err_handler)?;

								recog.base.set_state(2550);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(2551);
								recog.expression()?;

								recog.base.set_state(2556);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(2552);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(2553);
									recog.expression()?;

									}
									}
									recog.base.set_state(2558);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							recog.base.set_state(2561);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				13 =>{
					{
					let mut tmp = ExistsContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2564);
					recog.base.match_token(EXISTS,&mut recog.err_handler)?;

					recog.base.set_state(2565);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2566);
					recog.query()?;

					recog.base.set_state(2567);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				14 =>{
					{
					let mut tmp = SimpleCaseContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2569);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2570);
					let tmp = recog.expression()?;
					if let PrimaryExpressionContextAll::SimpleCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.operand = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2572); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule whenClause*/
						recog.base.set_state(2571);
						recog.whenClause()?;

						}
						}
						recog.base.set_state(2574); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(2578);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(2576);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(2577);
						let tmp = recog.expression()?;
						if let PrimaryExpressionContextAll::SimpleCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.elseExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2580);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				15 =>{
					{
					let mut tmp = SearchedCaseContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2582);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					recog.base.set_state(2584); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule whenClause*/
						recog.base.set_state(2583);
						recog.whenClause()?;

						}
						}
						recog.base.set_state(2586); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(2590);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(2588);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(2589);
						let tmp = recog.expression()?;
						if let PrimaryExpressionContextAll::SearchedCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.elseExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2592);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				16 =>{
					{
					let mut tmp = CastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2594);
					recog.base.match_token(CAST,&mut recog.err_handler)?;

					recog.base.set_state(2595);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2596);
					recog.expression()?;

					recog.base.set_state(2597);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(2598);
					recog.type_()?;

					recog.base.set_state(2599);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				17 =>{
					{
					let mut tmp = CastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2601);
					recog.base.match_token(TRY_CAST,&mut recog.err_handler)?;

					recog.base.set_state(2602);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2603);
					recog.expression()?;

					recog.base.set_state(2604);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(2605);
					recog.type_()?;

					recog.base.set_state(2606);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				18 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2608);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(2609);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					{
					recog.base.set_state(2611);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(348,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule trimsSpecification*/
							recog.base.set_state(2610);
							recog.trimsSpecification()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2614);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(349,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule valueExpression*/
							recog.base.set_state(2613);
							let tmp = recog.valueExpression_rec(0)?;
							if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(2616);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2618);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2619);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				19 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2621);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(2622);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2630);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(352,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule trimsSpecification*/
							recog.base.set_state(2623);
							recog.trimsSpecification()?;

							recog.base.set_state(2625);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(350,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule valueExpression*/
									recog.base.set_state(2624);
									let tmp = recog.valueExpression_rec(0)?;
									if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
									ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									}
								}

								_ => {}
							}
							recog.base.set_state(2628);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(351,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(2627);
									recog.base.match_token(FROM,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2632);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2633);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				20 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2635);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(2636);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2637);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2638);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2639);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2641);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2640);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2643);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				21 =>{
					{
					let mut tmp = SubstringContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2645);
					recog.base.match_token(SUBSTRING,&mut recog.err_handler)?;

					recog.base.set_state(2646);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2647);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(2648);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2649);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(2652);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(2650);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						/*InvokeRule valueExpression*/
						recog.base.set_state(2651);
						recog.valueExpression_rec(0)?;

						}
					}

					recog.base.set_state(2654);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				22 =>{
					{
					let mut tmp = NormalizeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2656);
					recog.base.match_token(NORMALIZE,&mut recog.err_handler)?;

					recog.base.set_state(2657);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2658);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(2661);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(355,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2659);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule normalForm*/
							recog.base.set_state(2660);
							recog.normalForm()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2664);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2663);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::NormalizeContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2666);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				23 =>{
					{
					let mut tmp = RedshiftExtractContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2668);
					recog.base.match_token(EXTRACT,&mut recog.err_handler)?;

					recog.base.set_state(2669);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2672);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 STRING | UNICODE_STRING | DOLLAR_QUOTED_STRING 
						=> {
							{
							/*InvokeRule string*/
							recog.base.set_state(2670);
							recog.string()?;

							}
						}

					 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
					 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
					 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
					 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
					 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
					 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
					 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
					 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
					 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
					 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
					 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
					 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
					 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
					 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
					 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED |
					 GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS |
					 GZIP | HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
					 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT |
					 INTERLEAVED | INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO |
					 IS | ISOLATION | ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS |
					 JSON_OBJECT | JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG |
					 LAMBDA | LANGUAGE | LAST | LAST_VALUE | LATERAL | LEADING | LEVEL |
					 LIBRARY | LIKE | LIMIT | LINES | LISTAGG | LISTAGGDISTINCT | LOCAL |
					 LOCATION | LOCK | LOGICAL | M | MAP | MASKING | MATCH | MATCHED | MATCHES |
					 MATCH_RECOGNIZE | MATERIALIZED | MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE |
					 MB | MEASURES | MERGE | MIN | MINUTE | MINUTES | MODEL | MONTH | MONTHS |
					 NEXT | NFC | NFD | NFKC | NFKD | NO | NONE | NORMALIZE | NOTNULL |
					 NULL | NULLS | OBJECT | OF | OFFSET | OMIT | ON | ONE | ONLY | OPTION |
					 OPTIONS | OR | ORDER | ORDINALITY | OUT | OUTPUT | OUTPUTFORMAT | OVER |
					 OVERFLOW | PARTITION | PARTITIONED | PARTITIONS | PASSING | PAST |
					 PATH | PATTERN | PER | PERCENTILE_CONT | PERCENTILE_DISC | PERIOD |
					 PERMUTE | PG_CATALOG | PIVOT | POSITION | PRECEDING | PRECISION | PREPARE |
					 PRIOR | PROCEDURE | PRIMARY | PRIVILEGES | PROPERTIES | PRUNE | QUALIFY |
					 QUOTES | RANGE | READ | RECURSIVE | REFERENCES | REFRESH | RENAME |
					 REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT | RETRY_TIMEOUT |
					 RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK | ROLLUP |
					 ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND | SECONDS |
					 SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE | SERDEPROPERTIES |
					 SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR | SOME | SORTKEY |
					 SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET | SUBSTRING |
					 SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY | TERMINATED |
					 TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO | TRAILING |
					 TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE | TYPE | UESCAPE |
					 UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE | UNKNOWN |
					 UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER | UTF16 |
					 UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING | VARIADIC |
					 VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW | WITH |
					 WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
					 ZSTD | LBRACKET | IDENTIFIER | DIGIT_IDENTIFIER | QUOTED_IDENTIFIER 
						=> {
							{
							/*InvokeRule identifier*/
							recog.base.set_state(2671);
							recog.identifier()?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					recog.base.set_state(2674);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2675);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(2676);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				24 =>{
					{
					let mut tmp = CountStarContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2678);
					recog.base.match_token(COUNT,&mut recog.err_handler)?;

					recog.base.set_state(2679);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2680);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(2681);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule functionCallTail*/
					recog.base.set_state(2682);
					recog.functionCallTail()?;

					}
				}
			,
				25 =>{
					{
					let mut tmp = FunctionCallContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule functionCallHead*/
					recog.base.set_state(2683);
					recog.functionCallHead()?;

					/*InvokeRule functionName*/
					recog.base.set_state(2684);
					recog.functionName()?;

					recog.base.set_state(2685);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					{
					recog.base.set_state(2697);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(360,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2687);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(358,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule setQuantifier*/
									recog.base.set_state(2686);
									recog.setQuantifier()?;

									}
								}

								_ => {}
							}
							/*InvokeRule callArgument*/
							recog.base.set_state(2689);
							recog.callArgument()?;

							recog.base.set_state(2694);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(359,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2690);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule callArgument*/
									recog.base.set_state(2691);
									recog.callArgument()?;

									}
									} 
								}
								recog.base.set_state(2696);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(359,&mut recog.base)?;
							}
							}
						}

						_ => {}
					}
					/*InvokeRule functionExtraArguments*/
					recog.base.set_state(2699);
					recog.functionExtraArguments()?;

					}
					recog.base.set_state(2702);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2701);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

						let temp = if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail.push(temp); } else {unreachable!("cant cast");}  
						}
					}

					recog.base.set_state(2704);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule functionCallTail*/
					recog.base.set_state(2705);
					recog.functionCallTail()?;

					}
				}
			,
				26 =>{
					{
					let mut tmp = MeasureContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(2707);
					recog.identifier()?;

					/*InvokeRule over*/
					recog.base.set_state(2708);
					recog.over()?;

					}
				}
			,
				27 =>{
					{
					let mut tmp = LambdaContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(2710);
					recog.identifier()?;

					recog.base.set_state(2711);
					recog.base.match_token(T__3,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2712);
					recog.expression()?;

					}
				}
			,
				28 =>{
					{
					let mut tmp = LambdaContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2714);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2723);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LBRACKET - 384)))) != 0) || ((((_la - 440)) & !0x3f) == 0 && ((1usize << (_la - 440)) & ((1usize << (IDENTIFIER - 440)) | (1usize << (DIGIT_IDENTIFIER - 440)) | (1usize << (QUOTED_IDENTIFIER - 440)))) != 0) {
						{
						/*InvokeRule identifier*/
						recog.base.set_state(2715);
						recog.identifier()?;

						recog.base.set_state(2720);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(362,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(2716);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule identifier*/
								recog.base.set_state(2717);
								recog.identifier()?;

								}
								} 
							}
							recog.base.set_state(2722);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(362,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(2726);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2725);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::LambdaContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2728);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2729);
					recog.base.match_token(T__3,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2730);
					recog.expression()?;

					}
				}
			,
				29 =>{
					{
					let mut tmp = SubqueryExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2731);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2732);
					recog.query()?;

					recog.base.set_state(2733);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				30 =>{
					{
					let mut tmp = ArrayConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2735);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(2736);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(2745);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONVERT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOT - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RIGHT - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)))) != 0) || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (DOLLAR - 419)) | (1usize << (POSIX - 419)) | (1usize << (STRING - 419)) | (1usize << (UNICODE_STRING - 419)) | (1usize << (DOLLAR_QUOTED_STRING - 419)) | (1usize << (BINARY_LITERAL - 419)) | (1usize << (INTEGER_VALUE - 419)) | (1usize << (DECIMAL_VALUE - 419)) | (1usize << (DOUBLE_VALUE - 419)) | (1usize << (IDENTIFIER - 419)) | (1usize << (DIGIT_IDENTIFIER - 419)) | (1usize << (DOLLAR_HASH_IDENTIFIER - 419)) | (1usize << (QUOTED_IDENTIFIER - 419)) | (1usize << (VARIABLE - 419)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(2737);
						recog.expression()?;

						recog.base.set_state(2742);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(365,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(2738);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(2739);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(2744);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(365,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(2748);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2747);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::ArrayConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2750);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				31 =>{
					{
					let mut tmp = ColumnReferenceContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule columnName*/
					recog.base.set_state(2751);
					recog.columnName()?;

					}
				}
			,
				32 =>{
					{
					let mut tmp = FunctionParameterColumnReferenceContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2752);
					recog.base.match_token(DOLLAR,&mut recog.err_handler)?;

					recog.base.set_state(2753);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				33 =>{
					{
					let mut tmp = ParenthesizedExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2754);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2755);
					recog.expression()?;

					recog.base.set_state(2756);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				34 =>{
					{
					let mut tmp = JsonExistsContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2758);
					recog.base.match_token(JSON_EXISTS,&mut recog.err_handler)?;

					recog.base.set_state(2759);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule jsonPathInvocation*/
					recog.base.set_state(2760);
					recog.jsonPathInvocation()?;

					recog.base.set_state(2765);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ERROR || _la==FALSE || _la==TRUE || _la==UNKNOWN {
						{
						/*InvokeRule jsonExistsErrorBehavior*/
						recog.base.set_state(2761);
						recog.jsonExistsErrorBehavior()?;

						recog.base.set_state(2762);
						recog.base.match_token(ON,&mut recog.err_handler)?;

						recog.base.set_state(2763);
						recog.base.match_token(ERROR,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2767);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				35 =>{
					{
					let mut tmp = JsonValueContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2769);
					recog.base.match_token(JSON_VALUE,&mut recog.err_handler)?;

					recog.base.set_state(2770);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule jsonPathInvocation*/
					recog.base.set_state(2771);
					recog.jsonPathInvocation()?;

					recog.base.set_state(2774);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==RETURNING {
						{
						recog.base.set_state(2772);
						recog.base.match_token(RETURNING,&mut recog.err_handler)?;

						/*InvokeRule type_*/
						recog.base.set_state(2773);
						recog.type_()?;

						}
					}

					recog.base.set_state(2780);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(370,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule jsonValueBehavior*/
							recog.base.set_state(2776);
							let tmp = recog.jsonValueBehavior()?;
							if let PrimaryExpressionContextAll::JsonValueContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.emptyBehavior = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(2777);
							recog.base.match_token(ON,&mut recog.err_handler)?;

							recog.base.set_state(2778);
							recog.base.match_token(EMPTY,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2786);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==DEFAULT || _la==ERROR || _la==NULL {
						{
						/*InvokeRule jsonValueBehavior*/
						recog.base.set_state(2782);
						let tmp = recog.jsonValueBehavior()?;
						if let PrimaryExpressionContextAll::JsonValueContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.errorBehavior = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						recog.base.set_state(2783);
						recog.base.match_token(ON,&mut recog.err_handler)?;

						recog.base.set_state(2784);
						recog.base.match_token(ERROR,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2788);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				36 =>{
					{
					let mut tmp = JsonQueryContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2790);
					recog.base.match_token(JSON_QUERY,&mut recog.err_handler)?;

					recog.base.set_state(2791);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule jsonPathInvocation*/
					recog.base.set_state(2792);
					recog.jsonPathInvocation()?;

					recog.base.set_state(2799);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==RETURNING {
						{
						recog.base.set_state(2793);
						recog.base.match_token(RETURNING,&mut recog.err_handler)?;

						/*InvokeRule type_*/
						recog.base.set_state(2794);
						recog.type_()?;

						recog.base.set_state(2797);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==FORMAT {
							{
							recog.base.set_state(2795);
							recog.base.match_token(FORMAT,&mut recog.err_handler)?;

							/*InvokeRule jsonRepresentation*/
							recog.base.set_state(2796);
							recog.jsonRepresentation()?;

							}
						}

						}
					}

					recog.base.set_state(2804);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH || _la==WITHOUT {
						{
						/*InvokeRule jsonQueryWrapperBehavior*/
						recog.base.set_state(2801);
						recog.jsonQueryWrapperBehavior()?;

						recog.base.set_state(2802);
						recog.base.match_token(WRAPPER,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2813);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KEEP || _la==OMIT {
						{
						recog.base.set_state(2806);
						_la = recog.base.input.la(1);
						if { !(_la==KEEP || _la==OMIT) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						recog.base.set_state(2807);
						recog.base.match_token(QUOTES,&mut recog.err_handler)?;

						recog.base.set_state(2811);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==ON {
							{
							recog.base.set_state(2808);
							recog.base.match_token(ON,&mut recog.err_handler)?;

							recog.base.set_state(2809);
							recog.base.match_token(SCALAR,&mut recog.err_handler)?;

							recog.base.set_state(2810);
							recog.base.match_token(STRING_KW,&mut recog.err_handler)?;

							}
						}

						}
					}

					recog.base.set_state(2819);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(377,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule jsonQueryBehavior*/
							recog.base.set_state(2815);
							let tmp = recog.jsonQueryBehavior()?;
							if let PrimaryExpressionContextAll::JsonQueryContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.emptyBehavior = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(2816);
							recog.base.match_token(ON,&mut recog.err_handler)?;

							recog.base.set_state(2817);
							recog.base.match_token(EMPTY,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2825);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EMPTY || _la==ERROR || _la==NULL {
						{
						/*InvokeRule jsonQueryBehavior*/
						recog.base.set_state(2821);
						let tmp = recog.jsonQueryBehavior()?;
						if let PrimaryExpressionContextAll::JsonQueryContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.errorBehavior = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						recog.base.set_state(2822);
						recog.base.match_token(ON,&mut recog.err_handler)?;

						recog.base.set_state(2823);
						recog.base.match_token(ERROR,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2827);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				37 =>{
					{
					let mut tmp = JsonObjectContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2829);
					recog.base.match_token(JSON_OBJECT,&mut recog.err_handler)?;

					recog.base.set_state(2830);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2862);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(385,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule jsonObjectMember*/
							recog.base.set_state(2831);
							recog.jsonObjectMember()?;

							recog.base.set_state(2836);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(379,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2832);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule jsonObjectMember*/
									recog.base.set_state(2833);
									recog.jsonObjectMember()?;

									}
									} 
								}
								recog.base.set_state(2838);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(379,&mut recog.base)?;
							}
							recog.base.set_state(2840);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2839);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let PrimaryExpressionContextAll::JsonObjectContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							recog.base.set_state(2848);
							recog.err_handler.sync(&mut recog.base)?;
							match recog.base.input.la(1) {
							 NULL 
								=> {
							    	{
							    	recog.base.set_state(2842);
							    	recog.base.match_token(NULL,&mut recog.err_handler)?;

							    	recog.base.set_state(2843);
							    	recog.base.match_token(ON,&mut recog.err_handler)?;

							    	recog.base.set_state(2844);
							    	recog.base.match_token(NULL,&mut recog.err_handler)?;

							    	}
							    }

							 ABSENT 
								=> {
							    	{
							    	recog.base.set_state(2845);
							    	recog.base.match_token(ABSENT,&mut recog.err_handler)?;

							    	recog.base.set_state(2846);
							    	recog.base.match_token(ON,&mut recog.err_handler)?;

							    	recog.base.set_state(2847);
							    	recog.base.match_token(NULL,&mut recog.err_handler)?;

							    	}
							    }

							 RETURNING | WITH | WITHOUT | RPAREN 
								=> {
							    }

								_ => {}
							}
							recog.base.set_state(2860);
							recog.err_handler.sync(&mut recog.base)?;
							match recog.base.input.la(1) {
							 WITH 
								=> {
							    	{
							    	recog.base.set_state(2850);
							    	recog.base.match_token(WITH,&mut recog.err_handler)?;

							    	recog.base.set_state(2851);
							    	recog.base.match_token(UNIQUE,&mut recog.err_handler)?;

							    	recog.base.set_state(2853);
							    	recog.err_handler.sync(&mut recog.base)?;
							    	_la = recog.base.input.la(1);
							    	if _la==KEYS {
							    		{
							    		recog.base.set_state(2852);
							    		recog.base.match_token(KEYS,&mut recog.err_handler)?;

							    		}
							    	}

							    	}
							    }

							 WITHOUT 
								=> {
							    	{
							    	recog.base.set_state(2855);
							    	recog.base.match_token(WITHOUT,&mut recog.err_handler)?;

							    	recog.base.set_state(2856);
							    	recog.base.match_token(UNIQUE,&mut recog.err_handler)?;

							    	recog.base.set_state(2858);
							    	recog.err_handler.sync(&mut recog.base)?;
							    	_la = recog.base.input.la(1);
							    	if _la==KEYS {
							    		{
							    		recog.base.set_state(2857);
							    		recog.base.match_token(KEYS,&mut recog.err_handler)?;

							    		}
							    	}

							    	}
							    }

							 RETURNING | RPAREN 
								=> {
							    }

								_ => {}
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(2870);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==RETURNING {
						{
						recog.base.set_state(2864);
						recog.base.match_token(RETURNING,&mut recog.err_handler)?;

						/*InvokeRule type_*/
						recog.base.set_state(2865);
						recog.type_()?;

						recog.base.set_state(2868);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==FORMAT {
							{
							recog.base.set_state(2866);
							recog.base.match_token(FORMAT,&mut recog.err_handler)?;

							/*InvokeRule jsonRepresentation*/
							recog.base.set_state(2867);
							recog.jsonRepresentation()?;

							}
						}

						}
					}

					recog.base.set_state(2872);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				38 =>{
					{
					let mut tmp = JsonArrayContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2873);
					recog.base.match_token(JSON_ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(2874);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2894);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(391,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule jsonValueExpression*/
							recog.base.set_state(2875);
							recog.jsonValueExpression()?;

							recog.base.set_state(2880);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(388,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2876);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule jsonValueExpression*/
									recog.base.set_state(2877);
									recog.jsonValueExpression()?;

									}
									} 
								}
								recog.base.set_state(2882);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(388,&mut recog.base)?;
							}
							recog.base.set_state(2884);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2883);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let PrimaryExpressionContextAll::JsonArrayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							recog.base.set_state(2892);
							recog.err_handler.sync(&mut recog.base)?;
							match recog.base.input.la(1) {
							 NULL 
								=> {
							    	{
							    	recog.base.set_state(2886);
							    	recog.base.match_token(NULL,&mut recog.err_handler)?;

							    	recog.base.set_state(2887);
							    	recog.base.match_token(ON,&mut recog.err_handler)?;

							    	recog.base.set_state(2888);
							    	recog.base.match_token(NULL,&mut recog.err_handler)?;

							    	}
							    }

							 ABSENT 
								=> {
							    	{
							    	recog.base.set_state(2889);
							    	recog.base.match_token(ABSENT,&mut recog.err_handler)?;

							    	recog.base.set_state(2890);
							    	recog.base.match_token(ON,&mut recog.err_handler)?;

							    	recog.base.set_state(2891);
							    	recog.base.match_token(NULL,&mut recog.err_handler)?;

							    	}
							    }

							 RETURNING | RPAREN 
								=> {
							    }

								_ => {}
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(2902);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==RETURNING {
						{
						recog.base.set_state(2896);
						recog.base.match_token(RETURNING,&mut recog.err_handler)?;

						/*InvokeRule type_*/
						recog.base.set_state(2897);
						recog.type_()?;

						recog.base.set_state(2900);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==FORMAT {
							{
							recog.base.set_state(2898);
							recog.base.match_token(FORMAT,&mut recog.err_handler)?;

							/*InvokeRule jsonRepresentation*/
							recog.base.set_state(2899);
							recog.jsonRepresentation()?;

							}
						}

						}
					}

					recog.base.set_state(2904);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				39 =>{
					{
					let mut tmp = VariableContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2905);
					recog.base.match_token(VARIABLE,&mut recog.err_handler)?;

					}
				}
			,
				40 =>{
					{
					let mut tmp = ApproximateFunctionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2906);
					recog.base.match_token(APPROXIMATE,&mut recog.err_handler)?;

					recog.base.set_state(2907);
					recog.base.match_token(PERCENTILE_DISC,&mut recog.err_handler)?;

					recog.base.set_state(2908);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule number*/
					recog.base.set_state(2909);
					recog.number()?;

					recog.base.set_state(2910);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2911);
					recog.base.match_token(WITHIN,&mut recog.err_handler)?;

					recog.base.set_state(2912);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(2913);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2914);
					recog.base.match_token(ORDER,&mut recog.err_handler)?;

					recog.base.set_state(2915);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2916);
					recog.expression()?;

					recog.base.set_state(2917);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				41 =>{
					{
					let mut tmp = ApproximateFunctionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2919);
					recog.base.match_token(APPROXIMATE,&mut recog.err_handler)?;

					recog.base.set_state(2920);
					recog.base.match_token(COUNT,&mut recog.err_handler)?;

					recog.base.set_state(2921);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2922);
					recog.base.match_token(DISTINCT,&mut recog.err_handler)?;

					/*InvokeRule callArgument*/
					recog.base.set_state(2923);
					recog.callArgument()?;

					recog.base.set_state(2924);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				42 =>{
					{
					let mut tmp = ConvertContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2926);
					recog.base.match_token(CONVERT,&mut recog.err_handler)?;

					recog.base.set_state(2927);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(2928);
					recog.type_()?;

					recog.base.set_state(2929);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2930);
					recog.expression()?;

					recog.base.set_state(2932);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2931);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::ConvertContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2934);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				43 =>{
					{
					let mut tmp = PercentileContFunctionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2936);
					recog.base.match_token(PERCENTILE_CONT,&mut recog.err_handler)?;

					recog.base.set_state(2937);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule number*/
					recog.base.set_state(2938);
					recog.number()?;

					recog.base.set_state(2939);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2940);
					recog.base.match_token(WITHIN,&mut recog.err_handler)?;

					recog.base.set_state(2941);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(2942);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2943);
					recog.base.match_token(ORDER,&mut recog.err_handler)?;

					recog.base.set_state(2944);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2945);
					recog.expression()?;

					recog.base.set_state(2947);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ASC || _la==DESC {
						{
						recog.base.set_state(2946);
						_la = recog.base.input.la(1);
						if { !(_la==ASC || _la==DESC) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(2949);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2965);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(398,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2950);
							recog.base.match_token(OVER,&mut recog.err_handler)?;

							recog.base.set_state(2951);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(2962);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==PARTITION {
								{
								recog.base.set_state(2952);
								recog.base.match_token(PARTITION,&mut recog.err_handler)?;

								recog.base.set_state(2953);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(2954);
								recog.expression()?;

								recog.base.set_state(2959);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(2955);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(2956);
									recog.expression()?;

									}
									}
									recog.base.set_state(2961);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							recog.base.set_state(2964);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				44 =>{
					{
					let mut tmp = PercentileDiscFunctionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2967);
					recog.base.match_token(PERCENTILE_DISC,&mut recog.err_handler)?;

					recog.base.set_state(2968);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule number*/
					recog.base.set_state(2969);
					recog.number()?;

					recog.base.set_state(2970);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2971);
					recog.base.match_token(WITHIN,&mut recog.err_handler)?;

					recog.base.set_state(2972);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(2973);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2974);
					recog.base.match_token(ORDER,&mut recog.err_handler)?;

					recog.base.set_state(2975);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2976);
					recog.expression()?;

					recog.base.set_state(2978);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ASC || _la==DESC {
						{
						recog.base.set_state(2977);
						_la = recog.base.input.la(1);
						if { !(_la==ASC || _la==DESC) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(2980);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2996);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(402,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2981);
							recog.base.match_token(OVER,&mut recog.err_handler)?;

							recog.base.set_state(2982);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(2993);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==PARTITION {
								{
								recog.base.set_state(2983);
								recog.base.match_token(PARTITION,&mut recog.err_handler)?;

								recog.base.set_state(2984);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(2985);
								recog.expression()?;

								recog.base.set_state(2990);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(2986);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(2987);
									recog.expression()?;

									}
									}
									recog.base.set_state(2992);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							recog.base.set_state(2995);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				45 =>{
					{
					let mut tmp = FirstValueFunctionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2998);
					_la = recog.base.input.la(1);
					if { !(_la==FIRST_VALUE || _la==LAG || _la==LAST_VALUE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2999);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3000);
					recog.expression()?;

					recog.base.set_state(3003);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IGNORE || _la==RESPECT {
						{
						recog.base.set_state(3001);
						_la = recog.base.input.la(1);
						if { !(_la==IGNORE || _la==RESPECT) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						recog.base.set_state(3002);
						recog.base.match_token(NULLS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3005);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule over*/
					recog.base.set_state(3006);
					recog.over()?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(3026);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(406,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(3024);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(405,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = CastOperatorContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3010);
							if !({recog.precpred(None, 19)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 19)".to_owned()), None))?;
							}
							recog.base.set_state(3011);
							recog.base.match_token(T__4,&mut recog.err_handler)?;

							/*InvokeRule type_*/
							recog.base.set_state(3012);
							recog.type_()?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = AtTimeZonePrimaryContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3013);
							if !({recog.precpred(None, 18)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 18)".to_owned()), None))?;
							}
							recog.base.set_state(3014);
							recog.base.match_token(AT,&mut recog.err_handler)?;

							/*InvokeRule timeZoneSpecifier*/
							recog.base.set_state(3015);
							recog.timeZoneSpecifier()?;

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = SubscriptContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::SubscriptContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.value = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3016);
							if !({recog.precpred(None, 17)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 17)".to_owned()), None))?;
							}
							recog.base.set_state(3017);
							recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(3018);
							let tmp = recog.valueExpression_rec(0)?;
							if let PrimaryExpressionContextAll::SubscriptContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.index = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(3019);
							recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

							}
						}
					,
						4 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = DereferenceContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::DereferenceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.base_ = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3021);
							if !({recog.precpred(None, 16)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 16)".to_owned()), None))?;
							}
							recog.base.set_state(3022);
							recog.base.match_token(DOT,&mut recog.err_handler)?;

							/*InvokeRule columnNameComponent*/
							recog.base.set_state(3023);
							let tmp = recog.columnNameComponent()?;
							if let PrimaryExpressionContextAll::DereferenceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.fieldName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(3028);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(406,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- functionCallHead ----------------
pub type FunctionCallHeadContextAll<'input> = FunctionCallHeadContext<'input>;


pub type FunctionCallHeadContext<'input> = BaseParserRuleContext<'input,FunctionCallHeadContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallHeadContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FunctionCallHeadContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionCallHeadContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallHead(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_functionCallHead(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionCallHeadContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionCallHead(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallHeadContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallHead }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallHead }
}
antlr_rust::tid!{FunctionCallHeadContextExt<'a>}

impl<'input> FunctionCallHeadContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallHeadContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallHeadContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallHeadContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FunctionCallHeadContextExt<'input>>{

fn processingMode(&self) -> Option<Rc<ProcessingModeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallHeadContextAttrs<'input> for FunctionCallHeadContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallHead(&mut self,)
	-> Result<Rc<FunctionCallHeadContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallHeadContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 220, RULE_functionCallHead);
        let mut _localctx: Rc<FunctionCallHeadContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3030);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(407,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule processingMode*/
					recog.base.set_state(3029);
					recog.processingMode()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallTail ----------------
pub type FunctionCallTailContextAll<'input> = FunctionCallTailContext<'input>;


pub type FunctionCallTailContext<'input> = BaseParserRuleContext<'input,FunctionCallTailContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallTailContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FunctionCallTailContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionCallTailContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallTail(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_functionCallTail(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionCallTailContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionCallTail(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallTailContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallTail }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallTail }
}
antlr_rust::tid!{FunctionCallTailContextExt<'a>}

impl<'input> FunctionCallTailContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallTailContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallTailContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallTailContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FunctionCallTailContextExt<'input>>{

fn filter(&self) -> Option<Rc<FilterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn nullTreatment(&self) -> Option<Rc<NullTreatmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallTailContextAttrs<'input> for FunctionCallTailContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallTail(&mut self,)
	-> Result<Rc<FunctionCallTailContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallTailContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 222, RULE_functionCallTail);
        let mut _localctx: Rc<FunctionCallTailContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3033);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(408,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule filter*/
					recog.base.set_state(3032);
					recog.filter()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(3039);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(410,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3036);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IGNORE || _la==RESPECT {
						{
						/*InvokeRule nullTreatment*/
						recog.base.set_state(3035);
						recog.nullTreatment()?;

						}
					}

					/*InvokeRule over*/
					recog.base.set_state(3038);
					recog.over()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- callArgument ----------------
#[derive(Debug)]
pub enum CallArgumentContextAll<'input>{
	PositionalArgumentContext(PositionalArgumentContext<'input>),
	MultiArgumentContext(MultiArgumentContext<'input>),
Error(CallArgumentContext<'input>)
}
antlr_rust::tid!{CallArgumentContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for CallArgumentContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for CallArgumentContextAll<'input>{}

impl<'input> Deref for CallArgumentContextAll<'input>{
	type Target = dyn CallArgumentContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use CallArgumentContextAll::*;
		match self{
			PositionalArgumentContext(inner) => inner,
			MultiArgumentContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CallArgumentContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CallArgumentContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type CallArgumentContext<'input> = BaseParserRuleContext<'input,CallArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct CallArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for CallArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CallArgumentContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CallArgumentContext<'input>{
}

impl<'input> CustomRuleContext<'input> for CallArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}
antlr_rust::tid!{CallArgumentContextExt<'a>}

impl<'input> CallArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CallArgumentContextAll<'input>> {
		Rc::new(
		CallArgumentContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CallArgumentContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait CallArgumentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<CallArgumentContextExt<'input>>{


}

impl<'input> CallArgumentContextAttrs<'input> for CallArgumentContext<'input>{}

pub type PositionalArgumentContext<'input> = BaseParserRuleContext<'input,PositionalArgumentContextExt<'input>>;

pub trait PositionalArgumentContextAttrs<'input>: RedshiftParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PositionalArgumentContextAttrs<'input> for PositionalArgumentContext<'input>{}

pub struct PositionalArgumentContextExt<'input>{
	base:CallArgumentContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PositionalArgumentContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PositionalArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PositionalArgumentContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_positionalArgument(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_positionalArgument(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PositionalArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_positionalArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for PositionalArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}

impl<'input> Borrow<CallArgumentContextExt<'input>> for PositionalArgumentContext<'input>{
	fn borrow(&self) -> &CallArgumentContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CallArgumentContextExt<'input>> for PositionalArgumentContext<'input>{
	fn borrow_mut(&mut self) -> &mut CallArgumentContextExt<'input> { &mut self.base }
}

impl<'input> CallArgumentContextAttrs<'input> for PositionalArgumentContext<'input> {}

impl<'input> PositionalArgumentContextExt<'input>{
	fn new(ctx: &dyn CallArgumentContextAttrs<'input>) -> Rc<CallArgumentContextAll<'input>>  {
		Rc::new(
			CallArgumentContextAll::PositionalArgumentContext(
				BaseParserRuleContext::copy_from(ctx,PositionalArgumentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MultiArgumentContext<'input> = BaseParserRuleContext<'input,MultiArgumentContextExt<'input>>;

pub trait MultiArgumentContextAttrs<'input>: RedshiftParserContext<'input>{
	fn multiSelect(&self) -> Option<Rc<MultiSelectContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MultiArgumentContextAttrs<'input> for MultiArgumentContext<'input>{}

pub struct MultiArgumentContextExt<'input>{
	base:CallArgumentContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MultiArgumentContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for MultiArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for MultiArgumentContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_multiArgument(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_multiArgument(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for MultiArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_multiArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}

impl<'input> Borrow<CallArgumentContextExt<'input>> for MultiArgumentContext<'input>{
	fn borrow(&self) -> &CallArgumentContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CallArgumentContextExt<'input>> for MultiArgumentContext<'input>{
	fn borrow_mut(&mut self) -> &mut CallArgumentContextExt<'input> { &mut self.base }
}

impl<'input> CallArgumentContextAttrs<'input> for MultiArgumentContext<'input> {}

impl<'input> MultiArgumentContextExt<'input>{
	fn new(ctx: &dyn CallArgumentContextAttrs<'input>) -> Rc<CallArgumentContextAll<'input>>  {
		Rc::new(
			CallArgumentContextAll::MultiArgumentContext(
				BaseParserRuleContext::copy_from(ctx,MultiArgumentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn callArgument(&mut self,)
	-> Result<Rc<CallArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CallArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 224, RULE_callArgument);
        let mut _localctx: Rc<CallArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3043);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(411,&mut recog.base)? {
				1 =>{
					let tmp = PositionalArgumentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(3041);
					recog.expression()?;

					}
				}
			,
				2 =>{
					let tmp = MultiArgumentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule multiSelect*/
					recog.base.set_state(3042);
					recog.multiSelect()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionExtraArguments ----------------
pub type FunctionExtraArgumentsContextAll<'input> = FunctionExtraArgumentsContext<'input>;


pub type FunctionExtraArgumentsContext<'input> = BaseParserRuleContext<'input,FunctionExtraArgumentsContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionExtraArgumentsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FunctionExtraArgumentsContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionExtraArgumentsContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionExtraArguments(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_functionExtraArguments(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionExtraArgumentsContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionExtraArguments(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionExtraArgumentsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionExtraArguments }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionExtraArguments }
}
antlr_rust::tid!{FunctionExtraArgumentsContextExt<'a>}

impl<'input> FunctionExtraArgumentsContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionExtraArgumentsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionExtraArgumentsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionExtraArgumentsContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FunctionExtraArgumentsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> FunctionExtraArgumentsContextAttrs<'input> for FunctionExtraArgumentsContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionExtraArguments(&mut self,)
	-> Result<Rc<FunctionExtraArgumentsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionExtraArgumentsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 226, RULE_functionExtraArguments);
        let mut _localctx: Rc<FunctionExtraArgumentsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3055);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				recog.base.set_state(3045);
				recog.base.match_token(ORDER,&mut recog.err_handler)?;

				recog.base.set_state(3046);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule sortItem*/
				recog.base.set_state(3047);
				recog.sortItem()?;

				recog.base.set_state(3052);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(412,&mut recog.base)?;
				while { _alt!=2 && _alt!=INVALID_ALT } {
					if _alt==1 {
						{
						{
						recog.base.set_state(3048);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule sortItem*/
						recog.base.set_state(3049);
						recog.sortItem()?;

						}
						} 
					}
					recog.base.set_state(3054);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(412,&mut recog.base)?;
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionName ----------------
pub type FunctionNameContextAll<'input> = FunctionNameContext<'input>;


pub type FunctionNameContext<'input> = BaseParserRuleContext<'input,FunctionNameContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FunctionNameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionNameContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionName(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_functionName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionName(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionName }
}
antlr_rust::tid!{FunctionNameContextExt<'a>}

impl<'input> FunctionNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionNameContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FunctionNameContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}

}

impl<'input> FunctionNameContextAttrs<'input> for FunctionNameContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionName(&mut self,)
	-> Result<Rc<FunctionNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 228, RULE_functionName);
        let mut _localctx: Rc<FunctionNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3063);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(414,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(3057);
					recog.qualifiedName()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3058);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3059);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3060);
					recog.base.match_token(IF,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3061);
					recog.base.match_token(REPLACE,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(3062);
					recog.base.match_token(GROUPING,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedParameter ----------------
pub type NamedParameterContextAll<'input> = NamedParameterContext<'input>;


pub type NamedParameterContext<'input> = BaseParserRuleContext<'input,NamedParameterContextExt<'input>>;

#[derive(Clone)]
pub struct NamedParameterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for NamedParameterContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NamedParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedParameter(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_namedParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NamedParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_namedParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedParameter }
}
antlr_rust::tid!{NamedParameterContextExt<'a>}

impl<'input> NamedParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedParameterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedParameterContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<NamedParameterContextExt<'input>>{

fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token INOUT
/// Returns `None` if there is no child corresponding to token INOUT
fn INOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INOUT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUT
/// Returns `None` if there is no child corresponding to token OUT
fn OUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OUT, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIADIC
/// Returns `None` if there is no child corresponding to token VARIADIC
fn VARIADIC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VARIADIC, 0)
}

}

impl<'input> NamedParameterContextAttrs<'input> for NamedParameterContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedParameter(&mut self,)
	-> Result<Rc<NamedParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 230, RULE_namedParameter);
        let mut _localctx: Rc<NamedParameterContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3066);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(415,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3065);
					_la = recog.base.input.la(1);
					if { !(_la==IN || _la==INOUT || _la==OUT || _la==VARIADIC) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(3069);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(416,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3068);
					recog.identifier()?;

					}
				}

				_ => {}
			}
			/*InvokeRule type_*/
			recog.base.set_state(3071);
			recog.type_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- field ----------------
pub type FieldContextAll<'input> = FieldContext<'input>;


pub type FieldContext<'input> = BaseParserRuleContext<'input,FieldContextExt<'input>>;

#[derive(Clone)]
pub struct FieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FieldContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FieldContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_field(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_field(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_field(self);
	}
}

impl<'input> CustomRuleContext<'input> for FieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_field }
	//fn type_rule_index() -> usize where Self: Sized { RULE_field }
}
antlr_rust::tid!{FieldContextExt<'a>}

impl<'input> FieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FieldContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FieldContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FieldContextAttrs<'input> for FieldContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn field(&mut self,)
	-> Result<Rc<FieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 232, RULE_field);
        let mut _localctx: Rc<FieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(3073);
			recog.expression()?;

			recog.base.set_state(3076);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(3074);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				/*InvokeRule identifier*/
				recog.base.set_state(3075);
				recog.identifier()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPathInvocation ----------------
pub type JsonPathInvocationContextAll<'input> = JsonPathInvocationContext<'input>;


pub type JsonPathInvocationContext<'input> = BaseParserRuleContext<'input,JsonPathInvocationContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPathInvocationContextExt<'input>{
	pub path: Option<Rc<StringContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonPathInvocationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonPathInvocationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPathInvocation(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonPathInvocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonPathInvocationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonPathInvocation(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPathInvocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPathInvocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPathInvocation }
}
antlr_rust::tid!{JsonPathInvocationContextExt<'a>}

impl<'input> JsonPathInvocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPathInvocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPathInvocationContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				path: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPathInvocationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonPathInvocationContextExt<'input>>{

fn jsonValueExpression(&self) -> Option<Rc<JsonValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PASSING
/// Returns `None` if there is no child corresponding to token PASSING
fn PASSING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PASSING, 0)
}
fn jsonArgument_all(&self) ->  Vec<Rc<JsonArgumentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn jsonArgument(&self, i: usize) -> Option<Rc<JsonArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> JsonPathInvocationContextAttrs<'input> for JsonPathInvocationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPathInvocation(&mut self,)
	-> Result<Rc<JsonPathInvocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPathInvocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 234, RULE_jsonPathInvocation);
        let mut _localctx: Rc<JsonPathInvocationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule jsonValueExpression*/
			recog.base.set_state(3078);
			recog.jsonValueExpression()?;

			recog.base.set_state(3079);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule string*/
			recog.base.set_state(3080);
			let tmp = recog.string()?;
			 cast_mut::<_,JsonPathInvocationContext >(&mut _localctx).path = Some(tmp.clone());
			  

			recog.base.set_state(3082);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(418,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3081);
					let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
					 cast_mut::<_,JsonPathInvocationContext >(&mut _localctx).COMMA = Some(tmp);
					  

					let temp =  cast_mut::<_,JsonPathInvocationContext >(&mut _localctx).COMMA.clone().unwrap()
					 ;
					 cast_mut::<_,JsonPathInvocationContext >(&mut _localctx).tail.push(temp);
					  
					}
				}

				_ => {}
			}
			recog.base.set_state(3093);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PASSING {
				{
				recog.base.set_state(3084);
				recog.base.match_token(PASSING,&mut recog.err_handler)?;

				/*InvokeRule jsonArgument*/
				recog.base.set_state(3085);
				recog.jsonArgument()?;

				recog.base.set_state(3090);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(419,&mut recog.base)?;
				while { _alt!=2 && _alt!=INVALID_ALT } {
					if _alt==1 {
						{
						{
						recog.base.set_state(3086);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule jsonArgument*/
						recog.base.set_state(3087);
						recog.jsonArgument()?;

						}
						} 
					}
					recog.base.set_state(3092);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(419,&mut recog.base)?;
				}
				}
			}

			recog.base.set_state(3096);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(3095);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,JsonPathInvocationContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,JsonPathInvocationContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,JsonPathInvocationContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonValueExpression ----------------
pub type JsonValueExpressionContextAll<'input> = JsonValueExpressionContext<'input>;


pub type JsonValueExpressionContext<'input> = BaseParserRuleContext<'input,JsonValueExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct JsonValueExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonValueExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonValueExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonValueExpression(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonValueExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonValueExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonValueExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonValueExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonValueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonValueExpression }
}
antlr_rust::tid!{JsonValueExpressionContextExt<'a>}

impl<'input> JsonValueExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonValueExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonValueExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonValueExpressionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonValueExpressionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FORMAT
/// Returns `None` if there is no child corresponding to token FORMAT
fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FORMAT, 0)
}
fn jsonRepresentation(&self) -> Option<Rc<JsonRepresentationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JsonValueExpressionContextAttrs<'input> for JsonValueExpressionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonValueExpression(&mut self,)
	-> Result<Rc<JsonValueExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonValueExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 236, RULE_jsonValueExpression);
        let mut _localctx: Rc<JsonValueExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(3098);
			recog.expression()?;

			recog.base.set_state(3101);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==FORMAT {
				{
				recog.base.set_state(3099);
				recog.base.match_token(FORMAT,&mut recog.err_handler)?;

				/*InvokeRule jsonRepresentation*/
				recog.base.set_state(3100);
				recog.jsonRepresentation()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonRepresentation ----------------
pub type JsonRepresentationContextAll<'input> = JsonRepresentationContext<'input>;


pub type JsonRepresentationContext<'input> = BaseParserRuleContext<'input,JsonRepresentationContextExt<'input>>;

#[derive(Clone)]
pub struct JsonRepresentationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonRepresentationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonRepresentationContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonRepresentation(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonRepresentation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonRepresentationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonRepresentation(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonRepresentationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonRepresentation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonRepresentation }
}
antlr_rust::tid!{JsonRepresentationContextExt<'a>}

impl<'input> JsonRepresentationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonRepresentationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonRepresentationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonRepresentationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonRepresentationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token JSON
/// Returns `None` if there is no child corresponding to token JSON
fn JSON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(JSON, 0)
}
/// Retrieves first TerminalNode corresponding to token ENCODING
/// Returns `None` if there is no child corresponding to token ENCODING
fn ENCODING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ENCODING, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF8
/// Returns `None` if there is no child corresponding to token UTF8
fn UTF8(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UTF8, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF16
/// Returns `None` if there is no child corresponding to token UTF16
fn UTF16(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UTF16, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF32
/// Returns `None` if there is no child corresponding to token UTF32
fn UTF32(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UTF32, 0)
}

}

impl<'input> JsonRepresentationContextAttrs<'input> for JsonRepresentationContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonRepresentation(&mut self,)
	-> Result<Rc<JsonRepresentationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonRepresentationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 238, RULE_jsonRepresentation);
        let mut _localctx: Rc<JsonRepresentationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3103);
			recog.base.match_token(JSON,&mut recog.err_handler)?;

			recog.base.set_state(3106);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ENCODING {
				{
				recog.base.set_state(3104);
				recog.base.match_token(ENCODING,&mut recog.err_handler)?;

				recog.base.set_state(3105);
				_la = recog.base.input.la(1);
				if { !(((((_la - 370)) & !0x3f) == 0 && ((1usize << (_la - 370)) & ((1usize << (UTF16 - 370)) | (1usize << (UTF32 - 370)) | (1usize << (UTF8 - 370)))) != 0)) } {
					recog.err_handler.recover_inline(&mut recog.base)?;

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonArgument ----------------
pub type JsonArgumentContextAll<'input> = JsonArgumentContext<'input>;


pub type JsonArgumentContext<'input> = BaseParserRuleContext<'input,JsonArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct JsonArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonArgument(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonArgument }
}
antlr_rust::tid!{JsonArgumentContextExt<'a>}

impl<'input> JsonArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonArgumentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonArgumentContextExt<'input>>{

fn jsonValueExpression(&self) -> Option<Rc<JsonValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JsonArgumentContextAttrs<'input> for JsonArgumentContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonArgument(&mut self,)
	-> Result<Rc<JsonArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 240, RULE_jsonArgument);
        let mut _localctx: Rc<JsonArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule jsonValueExpression*/
			recog.base.set_state(3108);
			recog.jsonValueExpression()?;

			recog.base.set_state(3109);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(3110);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonExistsErrorBehavior ----------------
pub type JsonExistsErrorBehaviorContextAll<'input> = JsonExistsErrorBehaviorContext<'input>;


pub type JsonExistsErrorBehaviorContext<'input> = BaseParserRuleContext<'input,JsonExistsErrorBehaviorContextExt<'input>>;

#[derive(Clone)]
pub struct JsonExistsErrorBehaviorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonExistsErrorBehaviorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonExistsErrorBehaviorContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonExistsErrorBehavior(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonExistsErrorBehavior(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonExistsErrorBehaviorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonExistsErrorBehavior(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonExistsErrorBehaviorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonExistsErrorBehavior }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonExistsErrorBehavior }
}
antlr_rust::tid!{JsonExistsErrorBehaviorContextExt<'a>}

impl<'input> JsonExistsErrorBehaviorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonExistsErrorBehaviorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonExistsErrorBehaviorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonExistsErrorBehaviorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonExistsErrorBehaviorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNKNOWN
/// Returns `None` if there is no child corresponding to token UNKNOWN
fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNKNOWN, 0)
}
/// Retrieves first TerminalNode corresponding to token ERROR
/// Returns `None` if there is no child corresponding to token ERROR
fn ERROR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ERROR, 0)
}

}

impl<'input> JsonExistsErrorBehaviorContextAttrs<'input> for JsonExistsErrorBehaviorContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonExistsErrorBehavior(&mut self,)
	-> Result<Rc<JsonExistsErrorBehaviorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonExistsErrorBehaviorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 242, RULE_jsonExistsErrorBehavior);
        let mut _localctx: Rc<JsonExistsErrorBehaviorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3112);
			_la = recog.base.input.la(1);
			if { !(_la==ERROR || _la==FALSE || _la==TRUE || _la==UNKNOWN) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonValueBehavior ----------------
pub type JsonValueBehaviorContextAll<'input> = JsonValueBehaviorContext<'input>;


pub type JsonValueBehaviorContext<'input> = BaseParserRuleContext<'input,JsonValueBehaviorContextExt<'input>>;

#[derive(Clone)]
pub struct JsonValueBehaviorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonValueBehaviorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonValueBehaviorContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonValueBehavior(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonValueBehavior(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonValueBehaviorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonValueBehavior(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonValueBehaviorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonValueBehavior }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonValueBehavior }
}
antlr_rust::tid!{JsonValueBehaviorContextExt<'a>}

impl<'input> JsonValueBehaviorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonValueBehaviorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonValueBehaviorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonValueBehaviorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonValueBehaviorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ERROR
/// Returns `None` if there is no child corresponding to token ERROR
fn ERROR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ERROR, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JsonValueBehaviorContextAttrs<'input> for JsonValueBehaviorContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonValueBehavior(&mut self,)
	-> Result<Rc<JsonValueBehaviorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonValueBehaviorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 244, RULE_jsonValueBehavior);
        let mut _localctx: Rc<JsonValueBehaviorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3118);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ERROR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3114);
					recog.base.match_token(ERROR,&mut recog.err_handler)?;

					}
				}

			 NULL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3115);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

			 DEFAULT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3116);
					recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3117);
					recog.expression()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonQueryWrapperBehavior ----------------
pub type JsonQueryWrapperBehaviorContextAll<'input> = JsonQueryWrapperBehaviorContext<'input>;


pub type JsonQueryWrapperBehaviorContext<'input> = BaseParserRuleContext<'input,JsonQueryWrapperBehaviorContextExt<'input>>;

#[derive(Clone)]
pub struct JsonQueryWrapperBehaviorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonQueryWrapperBehaviorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonQueryWrapperBehaviorContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonQueryWrapperBehavior(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonQueryWrapperBehavior(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonQueryWrapperBehaviorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonQueryWrapperBehavior(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonQueryWrapperBehaviorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonQueryWrapperBehavior }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonQueryWrapperBehavior }
}
antlr_rust::tid!{JsonQueryWrapperBehaviorContextExt<'a>}

impl<'input> JsonQueryWrapperBehaviorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonQueryWrapperBehaviorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonQueryWrapperBehaviorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonQueryWrapperBehaviorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonQueryWrapperBehaviorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITHOUT
/// Returns `None` if there is no child corresponding to token WITHOUT
fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITHOUT, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAY
/// Returns `None` if there is no child corresponding to token ARRAY
fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token CONDITIONAL
/// Returns `None` if there is no child corresponding to token CONDITIONAL
fn CONDITIONAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONDITIONAL, 0)
}
/// Retrieves first TerminalNode corresponding to token UNCONDITIONAL
/// Returns `None` if there is no child corresponding to token UNCONDITIONAL
fn UNCONDITIONAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNCONDITIONAL, 0)
}

}

impl<'input> JsonQueryWrapperBehaviorContextAttrs<'input> for JsonQueryWrapperBehaviorContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonQueryWrapperBehavior(&mut self,)
	-> Result<Rc<JsonQueryWrapperBehaviorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonQueryWrapperBehaviorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 246, RULE_jsonQueryWrapperBehavior);
        let mut _localctx: Rc<JsonQueryWrapperBehaviorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3131);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 WITHOUT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3120);
					recog.base.match_token(WITHOUT,&mut recog.err_handler)?;

					recog.base.set_state(3122);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ARRAY {
						{
						recog.base.set_state(3121);
						recog.base.match_token(ARRAY,&mut recog.err_handler)?;

						}
					}

					}
				}

			 WITH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3124);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(3126);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==CONDITIONAL || _la==UNCONDITIONAL {
						{
						recog.base.set_state(3125);
						_la = recog.base.input.la(1);
						if { !(_la==CONDITIONAL || _la==UNCONDITIONAL) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(3129);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ARRAY {
						{
						recog.base.set_state(3128);
						recog.base.match_token(ARRAY,&mut recog.err_handler)?;

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonQueryBehavior ----------------
pub type JsonQueryBehaviorContextAll<'input> = JsonQueryBehaviorContext<'input>;


pub type JsonQueryBehaviorContext<'input> = BaseParserRuleContext<'input,JsonQueryBehaviorContextExt<'input>>;

#[derive(Clone)]
pub struct JsonQueryBehaviorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonQueryBehaviorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonQueryBehaviorContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonQueryBehavior(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonQueryBehavior(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonQueryBehaviorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonQueryBehavior(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonQueryBehaviorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonQueryBehavior }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonQueryBehavior }
}
antlr_rust::tid!{JsonQueryBehaviorContextExt<'a>}

impl<'input> JsonQueryBehaviorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonQueryBehaviorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonQueryBehaviorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonQueryBehaviorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonQueryBehaviorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ERROR
/// Returns `None` if there is no child corresponding to token ERROR
fn ERROR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ERROR, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token EMPTY
/// Returns `None` if there is no child corresponding to token EMPTY
fn EMPTY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EMPTY, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAY
/// Returns `None` if there is no child corresponding to token ARRAY
fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token OBJECT
/// Returns `None` if there is no child corresponding to token OBJECT
fn OBJECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OBJECT, 0)
}

}

impl<'input> JsonQueryBehaviorContextAttrs<'input> for JsonQueryBehaviorContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonQueryBehavior(&mut self,)
	-> Result<Rc<JsonQueryBehaviorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonQueryBehaviorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 248, RULE_jsonQueryBehavior);
        let mut _localctx: Rc<JsonQueryBehaviorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3139);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(429,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3133);
					recog.base.match_token(ERROR,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3134);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3135);
					recog.base.match_token(EMPTY,&mut recog.err_handler)?;

					recog.base.set_state(3136);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3137);
					recog.base.match_token(EMPTY,&mut recog.err_handler)?;

					recog.base.set_state(3138);
					recog.base.match_token(OBJECT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonObjectMember ----------------
pub type JsonObjectMemberContextAll<'input> = JsonObjectMemberContext<'input>;


pub type JsonObjectMemberContext<'input> = BaseParserRuleContext<'input,JsonObjectMemberContextExt<'input>>;

#[derive(Clone)]
pub struct JsonObjectMemberContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for JsonObjectMemberContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for JsonObjectMemberContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonObjectMember(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_jsonObjectMember(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for JsonObjectMemberContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_jsonObjectMember(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonObjectMemberContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonObjectMember }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonObjectMember }
}
antlr_rust::tid!{JsonObjectMemberContextExt<'a>}

impl<'input> JsonObjectMemberContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonObjectMemberContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonObjectMemberContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonObjectMemberContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<JsonObjectMemberContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token VALUE
/// Returns `None` if there is no child corresponding to token VALUE
fn VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VALUE, 0)
}
fn jsonValueExpression(&self) -> Option<Rc<JsonValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}

}

impl<'input> JsonObjectMemberContextAttrs<'input> for JsonObjectMemberContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonObjectMember(&mut self,)
	-> Result<Rc<JsonObjectMemberContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonObjectMemberContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 250, RULE_jsonObjectMember);
        let mut _localctx: Rc<JsonObjectMemberContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3152);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(431,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3142);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(430,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3141);
							recog.base.match_token(KEY,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule expression*/
					recog.base.set_state(3144);
					recog.expression()?;

					recog.base.set_state(3145);
					recog.base.match_token(VALUE,&mut recog.err_handler)?;

					/*InvokeRule jsonValueExpression*/
					recog.base.set_state(3146);
					recog.jsonValueExpression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expression*/
					recog.base.set_state(3148);
					recog.expression()?;

					recog.base.set_state(3149);
					recog.base.match_token(COLON,&mut recog.err_handler)?;

					/*InvokeRule jsonValueExpression*/
					recog.base.set_state(3150);
					recog.jsonValueExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- processingMode ----------------
pub type ProcessingModeContextAll<'input> = ProcessingModeContext<'input>;


pub type ProcessingModeContext<'input> = BaseParserRuleContext<'input,ProcessingModeContextExt<'input>>;

#[derive(Clone)]
pub struct ProcessingModeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ProcessingModeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ProcessingModeContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_processingMode(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_processingMode(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ProcessingModeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_processingMode(self);
	}
}

impl<'input> CustomRuleContext<'input> for ProcessingModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_processingMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_processingMode }
}
antlr_rust::tid!{ProcessingModeContextExt<'a>}

impl<'input> ProcessingModeContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProcessingModeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProcessingModeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ProcessingModeContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ProcessingModeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RUNNING
/// Returns `None` if there is no child corresponding to token RUNNING
fn RUNNING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RUNNING, 0)
}
/// Retrieves first TerminalNode corresponding to token FINAL
/// Returns `None` if there is no child corresponding to token FINAL
fn FINAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FINAL, 0)
}

}

impl<'input> ProcessingModeContextAttrs<'input> for ProcessingModeContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn processingMode(&mut self,)
	-> Result<Rc<ProcessingModeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProcessingModeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 252, RULE_processingMode);
        let mut _localctx: Rc<ProcessingModeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3154);
			_la = recog.base.input.la(1);
			if { !(_la==FINAL || _la==RUNNING) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nullTreatment ----------------
pub type NullTreatmentContextAll<'input> = NullTreatmentContext<'input>;


pub type NullTreatmentContext<'input> = BaseParserRuleContext<'input,NullTreatmentContextExt<'input>>;

#[derive(Clone)]
pub struct NullTreatmentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for NullTreatmentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NullTreatmentContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nullTreatment(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_nullTreatment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NullTreatmentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_nullTreatment(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullTreatmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nullTreatment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nullTreatment }
}
antlr_rust::tid!{NullTreatmentContextExt<'a>}

impl<'input> NullTreatmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NullTreatmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NullTreatmentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NullTreatmentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<NullTreatmentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IGNORE
/// Returns `None` if there is no child corresponding to token IGNORE
fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token RESPECT
/// Returns `None` if there is no child corresponding to token RESPECT
fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RESPECT, 0)
}

}

impl<'input> NullTreatmentContextAttrs<'input> for NullTreatmentContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nullTreatment(&mut self,)
	-> Result<Rc<NullTreatmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NullTreatmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 254, RULE_nullTreatment);
        let mut _localctx: Rc<NullTreatmentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3160);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IGNORE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3156);
					recog.base.match_token(IGNORE,&mut recog.err_handler)?;

					recog.base.set_state(3157);
					recog.base.match_token(NULLS,&mut recog.err_handler)?;

					}
				}

			 RESPECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3158);
					recog.base.match_token(RESPECT,&mut recog.err_handler)?;

					recog.base.set_state(3159);
					recog.base.match_token(NULLS,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- string ----------------
#[derive(Debug)]
pub enum StringContextAll<'input>{
	UnicodeStringLiteralContext(UnicodeStringLiteralContext<'input>),
	DollarQuotedStringLiteralContext(DollarQuotedStringLiteralContext<'input>),
	BasicStringLiteralContext(BasicStringLiteralContext<'input>),
Error(StringContext<'input>)
}
antlr_rust::tid!{StringContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StringContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for StringContextAll<'input>{}

impl<'input> Deref for StringContextAll<'input>{
	type Target = dyn StringContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StringContextAll::*;
		match self{
			UnicodeStringLiteralContext(inner) => inner,
			DollarQuotedStringLiteralContext(inner) => inner,
			BasicStringLiteralContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StringContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StringContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StringContext<'input> = BaseParserRuleContext<'input,StringContextExt<'input>>;

#[derive(Clone)]
pub struct StringContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for StringContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StringContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StringContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StringContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}
antlr_rust::tid!{StringContextExt<'a>}

impl<'input> StringContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringContextAll<'input>> {
		Rc::new(
		StringContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StringContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<StringContextExt<'input>>{


}

impl<'input> StringContextAttrs<'input> for StringContext<'input>{}

pub type UnicodeStringLiteralContext<'input> = BaseParserRuleContext<'input,UnicodeStringLiteralContextExt<'input>>;

pub trait UnicodeStringLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNICODE_STRING
	/// Returns `None` if there is no child corresponding to token UNICODE_STRING
	fn UNICODE_STRING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UNICODE_STRING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UESCAPE
	/// Returns `None` if there is no child corresponding to token UESCAPE
	fn UESCAPE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UESCAPE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token STRING
	/// Returns `None` if there is no child corresponding to token STRING
	fn STRING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(STRING, 0)
	}
}

impl<'input> UnicodeStringLiteralContextAttrs<'input> for UnicodeStringLiteralContext<'input>{}

pub struct UnicodeStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnicodeStringLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UnicodeStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UnicodeStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unicodeStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_unicodeStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UnicodeStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_unicodeStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnicodeStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for UnicodeStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for UnicodeStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for UnicodeStringLiteralContext<'input> {}

impl<'input> UnicodeStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::UnicodeStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,UnicodeStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DollarQuotedStringLiteralContext<'input> = BaseParserRuleContext<'input,DollarQuotedStringLiteralContextExt<'input>>;

pub trait DollarQuotedStringLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOLLAR_QUOTED_STRING
	/// Returns `None` if there is no child corresponding to token DOLLAR_QUOTED_STRING
	fn DOLLAR_QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR_QUOTED_STRING, 0)
	}
}

impl<'input> DollarQuotedStringLiteralContextAttrs<'input> for DollarQuotedStringLiteralContext<'input>{}

pub struct DollarQuotedStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DollarQuotedStringLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DollarQuotedStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DollarQuotedStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dollarQuotedStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_dollarQuotedStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DollarQuotedStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_dollarQuotedStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DollarQuotedStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for DollarQuotedStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for DollarQuotedStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for DollarQuotedStringLiteralContext<'input> {}

impl<'input> DollarQuotedStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::DollarQuotedStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DollarQuotedStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BasicStringLiteralContext<'input> = BaseParserRuleContext<'input,BasicStringLiteralContextExt<'input>>;

pub trait BasicStringLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STRING
	/// Returns `None` if there is no child corresponding to token STRING
	fn STRING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(STRING, 0)
	}
}

impl<'input> BasicStringLiteralContextAttrs<'input> for BasicStringLiteralContext<'input>{}

pub struct BasicStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BasicStringLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for BasicStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BasicStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_basicStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_basicStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BasicStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_basicStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BasicStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for BasicStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for BasicStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for BasicStringLiteralContext<'input> {}

impl<'input> BasicStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::BasicStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BasicStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn string(&mut self,)
	-> Result<Rc<StringContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 256, RULE_string);
        let mut _localctx: Rc<StringContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3169);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 STRING 
				=> {
					let tmp = BasicStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3162);
					recog.base.match_token(STRING,&mut recog.err_handler)?;

					}
				}

			 DOLLAR_QUOTED_STRING 
				=> {
					let tmp = DollarQuotedStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3163);
					recog.base.match_token(DOLLAR_QUOTED_STRING,&mut recog.err_handler)?;

					}
				}

			 UNICODE_STRING 
				=> {
					let tmp = UnicodeStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3164);
					recog.base.match_token(UNICODE_STRING,&mut recog.err_handler)?;

					recog.base.set_state(3167);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(433,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3165);
							recog.base.match_token(UESCAPE,&mut recog.err_handler)?;

							recog.base.set_state(3166);
							recog.base.match_token(STRING,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- timeZoneSpecifier ----------------
pub type TimeZoneSpecifierContextAll<'input> = TimeZoneSpecifierContext<'input>;


pub type TimeZoneSpecifierContext<'input> = BaseParserRuleContext<'input,TimeZoneSpecifierContextExt<'input>>;

#[derive(Clone)]
pub struct TimeZoneSpecifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TimeZoneSpecifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TimeZoneSpecifierContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_timeZoneSpecifier(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_timeZoneSpecifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TimeZoneSpecifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_timeZoneSpecifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for TimeZoneSpecifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_timeZoneSpecifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_timeZoneSpecifier }
}
antlr_rust::tid!{TimeZoneSpecifierContextExt<'a>}

impl<'input> TimeZoneSpecifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TimeZoneSpecifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TimeZoneSpecifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TimeZoneSpecifierContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TimeZoneSpecifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token ZONE
/// Returns `None` if there is no child corresponding to token ZONE
fn ZONE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ZONE, 0)
}
fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TimeZoneSpecifierContextAttrs<'input> for TimeZoneSpecifierContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn timeZoneSpecifier(&mut self,)
	-> Result<Rc<TimeZoneSpecifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TimeZoneSpecifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 258, RULE_timeZoneSpecifier);
        let mut _localctx: Rc<TimeZoneSpecifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3180);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(435,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3171);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(3172);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					/*InvokeRule interval*/
					recog.base.set_state(3173);
					recog.interval()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3174);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(3175);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(3176);
					recog.string()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3177);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(3178);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3179);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comparisonOperator ----------------
pub type ComparisonOperatorContextAll<'input> = ComparisonOperatorContext<'input>;


pub type ComparisonOperatorContext<'input> = BaseParserRuleContext<'input,ComparisonOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ComparisonOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ComparisonOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comparisonOperator(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_comparisonOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ComparisonOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_comparisonOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonOperator }
}
antlr_rust::tid!{ComparisonOperatorContextExt<'a>}

impl<'input> ComparisonOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComparisonOperatorContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ComparisonOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
/// Retrieves first TerminalNode corresponding to token NEQ
/// Returns `None` if there is no child corresponding to token NEQ
fn NEQ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NEQ, 0)
}
/// Retrieves first TerminalNode corresponding to token LT
/// Returns `None` if there is no child corresponding to token LT
fn LT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LT, 0)
}
/// Retrieves first TerminalNode corresponding to token LTE
/// Returns `None` if there is no child corresponding to token LTE
fn LTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LTE, 0)
}
/// Retrieves first TerminalNode corresponding to token GT
/// Returns `None` if there is no child corresponding to token GT
fn GT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GT, 0)
}
/// Retrieves first TerminalNode corresponding to token GTE
/// Returns `None` if there is no child corresponding to token GTE
fn GTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GTE, 0)
}

}

impl<'input> ComparisonOperatorContextAttrs<'input> for ComparisonOperatorContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonOperator(&mut self,)
	-> Result<Rc<ComparisonOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 260, RULE_comparisonOperator);
        let mut _localctx: Rc<ComparisonOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3182);
			_la = recog.base.input.la(1);
			if { !(((((_la - 404)) & !0x3f) == 0 && ((1usize << (_la - 404)) & ((1usize << (EQ - 404)) | (1usize << (NEQ - 404)) | (1usize << (LT - 404)) | (1usize << (LTE - 404)) | (1usize << (GT - 404)) | (1usize << (GTE - 404)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comparisonQuantifier ----------------
pub type ComparisonQuantifierContextAll<'input> = ComparisonQuantifierContext<'input>;


pub type ComparisonQuantifierContext<'input> = BaseParserRuleContext<'input,ComparisonQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for ComparisonQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ComparisonQuantifierContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comparisonQuantifier(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_comparisonQuantifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ComparisonQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_comparisonQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonQuantifier }
}
antlr_rust::tid!{ComparisonQuantifierContextExt<'a>}

impl<'input> ComparisonQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonQuantifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonQuantifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComparisonQuantifierContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<ComparisonQuantifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token SOME
/// Returns `None` if there is no child corresponding to token SOME
fn SOME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}

}

impl<'input> ComparisonQuantifierContextAttrs<'input> for ComparisonQuantifierContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonQuantifier(&mut self,)
	-> Result<Rc<ComparisonQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 262, RULE_comparisonQuantifier);
        let mut _localctx: Rc<ComparisonQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3184);
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==ANY || _la==SOME) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanValue ----------------
pub type BooleanValueContextAll<'input> = BooleanValueContext<'input>;


pub type BooleanValueContext<'input> = BaseParserRuleContext<'input,BooleanValueContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for BooleanValueContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BooleanValueContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_booleanValue(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_booleanValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BooleanValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_booleanValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanValue }
}
antlr_rust::tid!{BooleanValueContextExt<'a>}

impl<'input> BooleanValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BooleanValueContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<BooleanValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}

}

impl<'input> BooleanValueContextAttrs<'input> for BooleanValueContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn booleanValue(&mut self,)
	-> Result<Rc<BooleanValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BooleanValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 264, RULE_booleanValue);
        let mut _localctx: Rc<BooleanValueContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3186);
			_la = recog.base.input.la(1);
			if { !(_la==FALSE || _la==TRUE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- interval ----------------
pub type IntervalContextAll<'input> = IntervalContext<'input>;


pub type IntervalContext<'input> = BaseParserRuleContext<'input,IntervalContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalContextExt<'input>{
	pub sign: Option<TokenType<'input>>,
	pub from: Option<Rc<IntervalFieldContextAll<'input>>>,
	pub to: Option<Rc<IntervalFieldContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for IntervalContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_interval(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_interval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_interval(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_interval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_interval }
}
antlr_rust::tid!{IntervalContextExt<'a>}

impl<'input> IntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalContextExt{
				sign: None, 
				from: None, to: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<IntervalContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
fn intervalField_all(&self) ->  Vec<Rc<IntervalFieldContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn intervalField(&self, i: usize) -> Option<Rc<IntervalFieldContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}

}

impl<'input> IntervalContextAttrs<'input> for IntervalContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn interval(&mut self,)
	-> Result<Rc<IntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 266, RULE_interval);
        let mut _localctx: Rc<IntervalContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3188);
			recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

			recog.base.set_state(3190);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PLUS || _la==MINUS {
				{
				recog.base.set_state(3189);
				 cast_mut::<_,IntervalContext >(&mut _localctx).sign = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==PLUS || _la==MINUS) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,IntervalContext >(&mut _localctx).sign = Some(tmp);
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			recog.base.set_state(3194);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 STRING | UNICODE_STRING | DOLLAR_QUOTED_STRING 
				=> {
					{
					/*InvokeRule string*/
					recog.base.set_state(3192);
					recog.string()?;

					}
				}

			 INTEGER_VALUE 
				=> {
					{
					recog.base.set_state(3193);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			/*InvokeRule intervalField*/
			recog.base.set_state(3196);
			let tmp = recog.intervalField()?;
			 cast_mut::<_,IntervalContext >(&mut _localctx).from = Some(tmp.clone());
			  

			recog.base.set_state(3199);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(438,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3197);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule intervalField*/
					recog.base.set_state(3198);
					let tmp = recog.intervalField()?;
					 cast_mut::<_,IntervalContext >(&mut _localctx).to = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalField ----------------
pub type IntervalFieldContextAll<'input> = IntervalFieldContext<'input>;


pub type IntervalFieldContext<'input> = BaseParserRuleContext<'input,IntervalFieldContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for IntervalFieldContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IntervalFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalField(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_intervalField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IntervalFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_intervalField(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalField }
}
antlr_rust::tid!{IntervalFieldContextExt<'a>}

impl<'input> IntervalFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalFieldContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<IntervalFieldContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token M
/// Returns `None` if there is no child corresponding to token M
fn M(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(M, 0)
}
/// Retrieves first TerminalNode corresponding to token MIN
/// Returns `None` if there is no child corresponding to token MIN
fn MIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MIN, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token S
/// Returns `None` if there is no child corresponding to token S
fn S(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(S, 0)
}
/// Retrieves first TerminalNode corresponding to token SEC
/// Returns `None` if there is no child corresponding to token SEC
fn SEC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SEC, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token YEARS
/// Returns `None` if there is no child corresponding to token YEARS
fn YEARS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(YEARS, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTHS
/// Returns `None` if there is no child corresponding to token MONTHS
fn MONTHS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MONTHS, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYS
/// Returns `None` if there is no child corresponding to token DAYS
fn DAYS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token HOURS
/// Returns `None` if there is no child corresponding to token HOURS
fn HOURS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(HOURS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTES
/// Returns `None` if there is no child corresponding to token MINUTES
fn MINUTES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MINUTES, 0)
}
/// Retrieves first TerminalNode corresponding to token SECONDS
/// Returns `None` if there is no child corresponding to token SECONDS
fn SECONDS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}

}

impl<'input> IntervalFieldContextAttrs<'input> for IntervalFieldContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalField(&mut self,)
	-> Result<Rc<IntervalFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 268, RULE_intervalField);
        let mut _localctx: Rc<IntervalFieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3201);
			_la = recog.base.input.la(1);
			if { !(_la==DAY || _la==DAYS || _la==HOUR || _la==HOURS || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (M - 197)) | (1usize << (MIN - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)))) != 0) || ((((_la - 299)) & !0x3f) == 0 && ((1usize << (_la - 299)) & ((1usize << (S - 299)) | (1usize << (SEC - 299)) | (1usize << (SECOND - 299)) | (1usize << (SECONDS - 299)))) != 0) || ((((_la - 383)) & !0x3f) == 0 && ((1usize << (_la - 383)) & ((1usize << (WEEK - 383)) | (1usize << (YEAR - 383)) | (1usize << (YEARS - 383)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- normalForm ----------------
pub type NormalFormContextAll<'input> = NormalFormContext<'input>;


pub type NormalFormContext<'input> = BaseParserRuleContext<'input,NormalFormContextExt<'input>>;

#[derive(Clone)]
pub struct NormalFormContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for NormalFormContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NormalFormContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_normalForm(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_normalForm(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NormalFormContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_normalForm(self);
	}
}

impl<'input> CustomRuleContext<'input> for NormalFormContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_normalForm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_normalForm }
}
antlr_rust::tid!{NormalFormContextExt<'a>}

impl<'input> NormalFormContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NormalFormContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NormalFormContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NormalFormContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<NormalFormContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NFD
/// Returns `None` if there is no child corresponding to token NFD
fn NFD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NFD, 0)
}
/// Retrieves first TerminalNode corresponding to token NFC
/// Returns `None` if there is no child corresponding to token NFC
fn NFC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NFC, 0)
}
/// Retrieves first TerminalNode corresponding to token NFKD
/// Returns `None` if there is no child corresponding to token NFKD
fn NFKD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NFKD, 0)
}
/// Retrieves first TerminalNode corresponding to token NFKC
/// Returns `None` if there is no child corresponding to token NFKC
fn NFKC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NFKC, 0)
}

}

impl<'input> NormalFormContextAttrs<'input> for NormalFormContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn normalForm(&mut self,)
	-> Result<Rc<NormalFormContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NormalFormContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 270, RULE_normalForm);
        let mut _localctx: Rc<NormalFormContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3203);
			_la = recog.base.input.la(1);
			if { !(((((_la - 220)) & !0x3f) == 0 && ((1usize << (_la - 220)) & ((1usize << (NFC - 220)) | (1usize << (NFD - 220)) | (1usize << (NFKC - 220)) | (1usize << (NFKD - 220)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- typeIdentifier ----------------
pub type TypeIdentifierContextAll<'input> = TypeIdentifierContext<'input>;


pub type TypeIdentifierContext<'input> = BaseParserRuleContext<'input,TypeIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct TypeIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TypeIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TypeIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_typeIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_typeIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TypeIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_typeIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_typeIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_typeIdentifier }
}
antlr_rust::tid!{TypeIdentifierContextExt<'a>}

impl<'input> TypeIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TypeIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TypeIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TypeIdentifierContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TypeIdentifierContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TypeIdentifierContextAttrs<'input> for TypeIdentifierContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn typeIdentifier(&mut self,)
	-> Result<Rc<TypeIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TypeIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 272, RULE_typeIdentifier);
        let mut _localctx: Rc<TypeIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3205);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- type_ ----------------
#[derive(Debug)]
pub enum Type_ContextAll<'input>{
	IntervalTypeContext(IntervalTypeContext<'input>),
	FunctionSignatureGenericTypeContext(FunctionSignatureGenericTypeContext<'input>),
	DateTimeWithTzTypeContext(DateTimeWithTzTypeContext<'input>),
	DoublePrecisionTypeContext(DoublePrecisionTypeContext<'input>),
	BinaryVaryingContext(BinaryVaryingContext<'input>),
	PrimitiveTypeContext(PrimitiveTypeContext<'input>),
	DateTimeTypeContext(DateTimeTypeContext<'input>),
	CharacterVaryingContext(CharacterVaryingContext<'input>),
Error(Type_Context<'input>)
}
antlr_rust::tid!{Type_ContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for Type_ContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for Type_ContextAll<'input>{}

impl<'input> Deref for Type_ContextAll<'input>{
	type Target = dyn Type_ContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use Type_ContextAll::*;
		match self{
			IntervalTypeContext(inner) => inner,
			FunctionSignatureGenericTypeContext(inner) => inner,
			DateTimeWithTzTypeContext(inner) => inner,
			DoublePrecisionTypeContext(inner) => inner,
			BinaryVaryingContext(inner) => inner,
			PrimitiveTypeContext(inner) => inner,
			DateTimeTypeContext(inner) => inner,
			CharacterVaryingContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for Type_ContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for Type_ContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type Type_Context<'input> = BaseParserRuleContext<'input,Type_ContextExt<'input>>;

#[derive(Clone)]
pub struct Type_ContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for Type_Context<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for Type_Context<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for Type_Context<'input>{
}

impl<'input> CustomRuleContext<'input> for Type_ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}
antlr_rust::tid!{Type_ContextExt<'a>}

impl<'input> Type_ContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Type_ContextAll<'input>> {
		Rc::new(
		Type_ContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Type_ContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait Type_ContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<Type_ContextExt<'input>>{


}

impl<'input> Type_ContextAttrs<'input> for Type_Context<'input>{}

pub type IntervalTypeContext<'input> = BaseParserRuleContext<'input,IntervalTypeContextExt<'input>>;

pub trait IntervalTypeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTERVAL
	/// Returns `None` if there is no child corresponding to token INTERVAL
	fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INTERVAL, 0)
	}
	fn intervalField_all(&self) ->  Vec<Rc<IntervalFieldContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn intervalField(&self, i: usize) -> Option<Rc<IntervalFieldContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
}

impl<'input> IntervalTypeContextAttrs<'input> for IntervalTypeContext<'input>{}

pub struct IntervalTypeContextExt<'input>{
	base:Type_ContextExt<'input>,
	pub from: Option<Rc<IntervalFieldContextAll<'input>>>,
	pub to: Option<Rc<IntervalFieldContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntervalTypeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for IntervalTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IntervalTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_intervalType(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_intervalType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IntervalTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_intervalType(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for IntervalTypeContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for IntervalTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for IntervalTypeContext<'input> {}

impl<'input> IntervalTypeContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::IntervalTypeContext(
				BaseParserRuleContext::copy_from(ctx,IntervalTypeContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionSignatureGenericTypeContext<'input> = BaseParserRuleContext<'input,FunctionSignatureGenericTypeContextExt<'input>>;

pub trait FunctionSignatureGenericTypeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOLLAR
	/// Returns `None` if there is no child corresponding to token DOLLAR
	fn DOLLAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
}

impl<'input> FunctionSignatureGenericTypeContextAttrs<'input> for FunctionSignatureGenericTypeContext<'input>{}

pub struct FunctionSignatureGenericTypeContextExt<'input>{
	base:Type_ContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionSignatureGenericTypeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for FunctionSignatureGenericTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FunctionSignatureGenericTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionSignatureGenericType(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_functionSignatureGenericType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FunctionSignatureGenericTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_functionSignatureGenericType(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionSignatureGenericTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for FunctionSignatureGenericTypeContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for FunctionSignatureGenericTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for FunctionSignatureGenericTypeContext<'input> {}

impl<'input> FunctionSignatureGenericTypeContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::FunctionSignatureGenericTypeContext(
				BaseParserRuleContext::copy_from(ctx,FunctionSignatureGenericTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DateTimeWithTzTypeContext<'input> = BaseParserRuleContext<'input,DateTimeWithTzTypeContextExt<'input>>;

pub trait DateTimeWithTzTypeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TIME in current rule
	fn TIME_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TIME, starting from 0.
	/// Returns `None` if number of children corresponding to token TIME is less or equal than `i`.
	fn TIME(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TIME, i)
	}
	/// Retrieves first TerminalNode corresponding to token ZONE
	/// Returns `None` if there is no child corresponding to token ZONE
	fn ZONE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ZONE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TIMESTAMP
	/// Returns `None` if there is no child corresponding to token TIMESTAMP
	fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TIMESTAMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn typeParameter(&self) -> Option<Rc<TypeParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DateTimeWithTzTypeContextAttrs<'input> for DateTimeWithTzTypeContext<'input>{}

pub struct DateTimeWithTzTypeContextExt<'input>{
	base:Type_ContextExt<'input>,
	pub base_: Option<TokenType<'input>>,
	pub precision: Option<Rc<TypeParameterContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DateTimeWithTzTypeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DateTimeWithTzTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DateTimeWithTzTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dateTimeWithTzType(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_dateTimeWithTzType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DateTimeWithTzTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_dateTimeWithTzType(self);
	}
}

impl<'input> CustomRuleContext<'input> for DateTimeWithTzTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for DateTimeWithTzTypeContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for DateTimeWithTzTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for DateTimeWithTzTypeContext<'input> {}

impl<'input> DateTimeWithTzTypeContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::DateTimeWithTzTypeContext(
				BaseParserRuleContext::copy_from(ctx,DateTimeWithTzTypeContextExt{
					base_:None, 
        			precision:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DoublePrecisionTypeContext<'input> = BaseParserRuleContext<'input,DoublePrecisionTypeContextExt<'input>>;

pub trait DoublePrecisionTypeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOUBLE
	/// Returns `None` if there is no child corresponding to token DOUBLE
	fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOUBLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECISION
	/// Returns `None` if there is no child corresponding to token PRECISION
	fn PRECISION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PRECISION, 0)
	}
}

impl<'input> DoublePrecisionTypeContextAttrs<'input> for DoublePrecisionTypeContext<'input>{}

pub struct DoublePrecisionTypeContextExt<'input>{
	base:Type_ContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DoublePrecisionTypeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DoublePrecisionTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DoublePrecisionTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_doublePrecisionType(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_doublePrecisionType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DoublePrecisionTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_doublePrecisionType(self);
	}
}

impl<'input> CustomRuleContext<'input> for DoublePrecisionTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for DoublePrecisionTypeContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for DoublePrecisionTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for DoublePrecisionTypeContext<'input> {}

impl<'input> DoublePrecisionTypeContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::DoublePrecisionTypeContext(
				BaseParserRuleContext::copy_from(ctx,DoublePrecisionTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BinaryVaryingContext<'input> = BaseParserRuleContext<'input,BinaryVaryingContextExt<'input>>;

pub trait BinaryVaryingContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BINARY
	/// Returns `None` if there is no child corresponding to token BINARY
	fn BINARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BINARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VARYING
	/// Returns `None` if there is no child corresponding to token VARYING
	fn VARYING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VARYING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> BinaryVaryingContextAttrs<'input> for BinaryVaryingContext<'input>{}

pub struct BinaryVaryingContextExt<'input>{
	base:Type_ContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BinaryVaryingContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for BinaryVaryingContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BinaryVaryingContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_binaryVarying(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_binaryVarying(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BinaryVaryingContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_binaryVarying(self);
	}
}

impl<'input> CustomRuleContext<'input> for BinaryVaryingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for BinaryVaryingContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for BinaryVaryingContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for BinaryVaryingContext<'input> {}

impl<'input> BinaryVaryingContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::BinaryVaryingContext(
				BaseParserRuleContext::copy_from(ctx,BinaryVaryingContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrimitiveTypeContext<'input> = BaseParserRuleContext<'input,PrimitiveTypeContextExt<'input>>;

pub trait PrimitiveTypeContextAttrs<'input>: RedshiftParserContext<'input>{
	fn typeIdentifier(&self) -> Option<Rc<TypeIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn typeParameter_all(&self) ->  Vec<Rc<TypeParameterContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn typeParameter(&self, i: usize) -> Option<Rc<TypeParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PrimitiveTypeContextAttrs<'input> for PrimitiveTypeContext<'input>{}

pub struct PrimitiveTypeContextExt<'input>{
	base:Type_ContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrimitiveTypeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PrimitiveTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PrimitiveTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_primitiveType(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_primitiveType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PrimitiveTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_primitiveType(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrimitiveTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for PrimitiveTypeContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for PrimitiveTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for PrimitiveTypeContext<'input> {}

impl<'input> PrimitiveTypeContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::PrimitiveTypeContext(
				BaseParserRuleContext::copy_from(ctx,PrimitiveTypeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DateTimeTypeContext<'input> = BaseParserRuleContext<'input,DateTimeTypeContextExt<'input>>;

pub trait DateTimeTypeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TIMESTAMP
	/// Returns `None` if there is no child corresponding to token TIMESTAMP
	fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TIMESTAMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WITHOUT
	/// Returns `None` if there is no child corresponding to token WITHOUT
	fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WITHOUT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TIME in current rule
	fn TIME_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TIME, starting from 0.
	/// Returns `None` if number of children corresponding to token TIME is less or equal than `i`.
	fn TIME(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(TIME, i)
	}
	/// Retrieves first TerminalNode corresponding to token ZONE
	/// Returns `None` if there is no child corresponding to token ZONE
	fn ZONE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ZONE, 0)
	}
	fn typeParameter(&self) -> Option<Rc<TypeParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DateTimeTypeContextAttrs<'input> for DateTimeTypeContext<'input>{}

pub struct DateTimeTypeContextExt<'input>{
	base:Type_ContextExt<'input>,
	pub base_: Option<TokenType<'input>>,
	pub precision: Option<Rc<TypeParameterContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DateTimeTypeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DateTimeTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DateTimeTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dateTimeType(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_dateTimeType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DateTimeTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_dateTimeType(self);
	}
}

impl<'input> CustomRuleContext<'input> for DateTimeTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for DateTimeTypeContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for DateTimeTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for DateTimeTypeContext<'input> {}

impl<'input> DateTimeTypeContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::DateTimeTypeContext(
				BaseParserRuleContext::copy_from(ctx,DateTimeTypeContextExt{
					base_:None, 
        			precision:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CharacterVaryingContext<'input> = BaseParserRuleContext<'input,CharacterVaryingContextExt<'input>>;

pub trait CharacterVaryingContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CHARACTER
	/// Returns `None` if there is no child corresponding to token CHARACTER
	fn CHARACTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CHARACTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VARYING
	/// Returns `None` if there is no child corresponding to token VARYING
	fn VARYING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(VARYING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> CharacterVaryingContextAttrs<'input> for CharacterVaryingContext<'input>{}

pub struct CharacterVaryingContextExt<'input>{
	base:Type_ContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CharacterVaryingContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CharacterVaryingContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CharacterVaryingContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_characterVarying(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_characterVarying(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CharacterVaryingContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_characterVarying(self);
	}
}

impl<'input> CustomRuleContext<'input> for CharacterVaryingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for CharacterVaryingContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for CharacterVaryingContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for CharacterVaryingContext<'input> {}

impl<'input> CharacterVaryingContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::CharacterVaryingContext(
				BaseParserRuleContext::copy_from(ctx,CharacterVaryingContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn type_(&mut self,)
	-> Result<Rc<Type_ContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Type_ContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 274, RULE_type_);
        let mut _localctx: Rc<Type_ContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(3292);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(451,&mut recog.base)? {
				1 =>{
					let tmp = FunctionSignatureGenericTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3207);
					recog.base.match_token(DOLLAR,&mut recog.err_handler)?;

					recog.base.set_state(3208);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = IntervalTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3209);
					recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

					/*InvokeRule intervalField*/
					recog.base.set_state(3210);
					let tmp = recog.intervalField()?;
					if let Type_ContextAll::IntervalTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3213);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(439,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3211);
							recog.base.match_token(TO,&mut recog.err_handler)?;

							/*InvokeRule intervalField*/
							recog.base.set_state(3212);
							let tmp = recog.intervalField()?;
							if let Type_ContextAll::IntervalTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
							ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				3 =>{
					let tmp = DateTimeTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3215);
					let tmp = recog.base.match_token(TIMESTAMP,&mut recog.err_handler)?;
					if let Type_ContextAll::DateTimeTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
					ctx.base_ = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(3220);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(440,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3216);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule typeParameter*/
							recog.base.set_state(3217);
							let tmp = recog.typeParameter()?;
							if let Type_ContextAll::DateTimeTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
							ctx.precision = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(3218);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3225);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(441,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3222);
							recog.base.match_token(WITHOUT,&mut recog.err_handler)?;

							recog.base.set_state(3223);
							recog.base.match_token(TIME,&mut recog.err_handler)?;

							recog.base.set_state(3224);
							recog.base.match_token(ZONE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				4 =>{
					let tmp = DateTimeWithTzTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3227);
					let tmp = recog.base.match_token(TIMESTAMP,&mut recog.err_handler)?;
					if let Type_ContextAll::DateTimeWithTzTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
					ctx.base_ = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(3232);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(3228);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule typeParameter*/
						recog.base.set_state(3229);
						let tmp = recog.typeParameter()?;
						if let Type_ContextAll::DateTimeWithTzTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
						ctx.precision = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						recog.base.set_state(3230);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3234);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(3235);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(3236);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = DateTimeTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(3237);
					let tmp = recog.base.match_token(TIME,&mut recog.err_handler)?;
					if let Type_ContextAll::DateTimeTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
					ctx.base_ = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(3242);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(443,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3238);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule typeParameter*/
							recog.base.set_state(3239);
							let tmp = recog.typeParameter()?;
							if let Type_ContextAll::DateTimeTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
							ctx.precision = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(3240);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3247);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(444,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3244);
							recog.base.match_token(WITHOUT,&mut recog.err_handler)?;

							recog.base.set_state(3245);
							recog.base.match_token(TIME,&mut recog.err_handler)?;

							recog.base.set_state(3246);
							recog.base.match_token(ZONE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				6 =>{
					let tmp = DateTimeWithTzTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(3249);
					let tmp = recog.base.match_token(TIME,&mut recog.err_handler)?;
					if let Type_ContextAll::DateTimeWithTzTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
					ctx.base_ = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(3254);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(3250);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule typeParameter*/
						recog.base.set_state(3251);
						let tmp = recog.typeParameter()?;
						if let Type_ContextAll::DateTimeWithTzTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
						ctx.precision = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						recog.base.set_state(3252);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3256);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(3257);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(3258);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = DoublePrecisionTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(3259);
					recog.base.match_token(DOUBLE,&mut recog.err_handler)?;

					recog.base.set_state(3260);
					recog.base.match_token(PRECISION,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					let tmp = CharacterVaryingContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(3261);
					recog.base.match_token(CHARACTER,&mut recog.err_handler)?;

					recog.base.set_state(3262);
					recog.base.match_token(VARYING,&mut recog.err_handler)?;

					recog.base.set_state(3266);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(446,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3263);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(3264);
							recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

							recog.base.set_state(3265);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				9 =>{
					let tmp = BinaryVaryingContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(3268);
					recog.base.match_token(BINARY,&mut recog.err_handler)?;

					recog.base.set_state(3269);
					recog.base.match_token(VARYING,&mut recog.err_handler)?;

					recog.base.set_state(3273);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(447,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3270);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(3271);
							recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

							recog.base.set_state(3272);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				10 =>{
					let tmp = PrimitiveTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					/*InvokeRule typeIdentifier*/
					recog.base.set_state(3275);
					recog.typeIdentifier()?;

					recog.base.set_state(3290);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(450,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3276);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule typeParameter*/
							recog.base.set_state(3277);
							recog.typeParameter()?;

							recog.base.set_state(3282);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(448,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(3278);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule typeParameter*/
									recog.base.set_state(3279);
									recog.typeParameter()?;

									}
									} 
								}
								recog.base.set_state(3284);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(448,&mut recog.base)?;
							}
							recog.base.set_state(3286);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(3285);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let Type_ContextAll::PrimitiveTypeContext(ctx) = cast_mut::<_,Type_ContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							recog.base.set_state(3288);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowField ----------------
pub type RowFieldContextAll<'input> = RowFieldContext<'input>;


pub type RowFieldContext<'input> = BaseParserRuleContext<'input,RowFieldContextExt<'input>>;

#[derive(Clone)]
pub struct RowFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RowFieldContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RowFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowField(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_rowField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RowFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rowField(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowField }
}
antlr_rust::tid!{RowFieldContextExt<'a>}

impl<'input> RowFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowFieldContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RowFieldContextExt<'input>>{

fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RowFieldContextAttrs<'input> for RowFieldContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowField(&mut self,)
	-> Result<Rc<RowFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 276, RULE_rowField);
        let mut _localctx: Rc<RowFieldContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3298);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(452,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule type_*/
					recog.base.set_state(3294);
					recog.type_()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3295);
					recog.identifier()?;

					/*InvokeRule type_*/
					recog.base.set_state(3296);
					recog.type_()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- typeParameter ----------------
pub type TypeParameterContextAll<'input> = TypeParameterContext<'input>;


pub type TypeParameterContext<'input> = BaseParserRuleContext<'input,TypeParameterContextExt<'input>>;

#[derive(Clone)]
pub struct TypeParameterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TypeParameterContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TypeParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_typeParameter(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_typeParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TypeParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_typeParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_typeParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_typeParameter }
}
antlr_rust::tid!{TypeParameterContextExt<'a>}

impl<'input> TypeParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TypeParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TypeParameterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TypeParameterContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TypeParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TypeParameterContextAttrs<'input> for TypeParameterContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn typeParameter(&mut self,)
	-> Result<Rc<TypeParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TypeParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 278, RULE_typeParameter);
        let mut _localctx: Rc<TypeParameterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3302);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INTEGER_VALUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3300);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}

			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
			 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
			 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
			 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEVEL | LIBRARY | LIKE | LIMIT |
			 LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK | LOGICAL |
			 M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE | MATERIALIZED |
			 MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES | MERGE | MIN |
			 MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC | NFD | NFKC |
			 NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS | OBJECT | OF |
			 OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR | ORDER | ORDINALITY |
			 OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW | PARTITION | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENTILE_CONT |
			 PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG | PIVOT | POSITION |
			 PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIMARY | PRIVILEGES |
			 PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE | READ | RECURSIVE | REFERENCES |
			 REFRESH | RENAME | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROLLUP | ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND |
			 SECONDS | SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE |
			 SERDEPROPERTIES | SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR |
			 SOME | SORTKEY | SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET |
			 SUBSTRING | SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY |
			 TERMINATED | TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO |
			 TRAILING | TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE |
			 TYPE | UESCAPE | UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE |
			 UNKNOWN | UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER |
			 UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING |
			 VARIADIC | VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW |
			 WITH | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
			 ZSTD | LBRACKET | DOLLAR | IDENTIFIER | DIGIT_IDENTIFIER | QUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule type_*/
					recog.base.set_state(3301);
					recog.type_()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenClause ----------------
pub type WhenClauseContextAll<'input> = WhenClauseContext<'input>;


pub type WhenClauseContext<'input> = BaseParserRuleContext<'input,WhenClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhenClauseContextExt<'input>{
	pub condition: Option<Rc<ExpressionContextAll<'input>>>,
	pub result: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for WhenClauseContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for WhenClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenClause(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_whenClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for WhenClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_whenClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhenClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenClause }
}
antlr_rust::tid!{WhenClauseContextExt<'a>}

impl<'input> WhenClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenClauseContextExt{
				condition: None, result: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenClauseContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<WhenClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> WhenClauseContextAttrs<'input> for WhenClauseContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenClause(&mut self,)
	-> Result<Rc<WhenClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 280, RULE_whenClause);
        let mut _localctx: Rc<WhenClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3304);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3305);
			let tmp = recog.expression()?;
			 cast_mut::<_,WhenClauseContext >(&mut _localctx).condition = Some(tmp.clone());
			  

			recog.base.set_state(3306);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3307);
			let tmp = recog.expression()?;
			 cast_mut::<_,WhenClauseContext >(&mut _localctx).result = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- filter ----------------
pub type FilterContextAll<'input> = FilterContext<'input>;


pub type FilterContext<'input> = BaseParserRuleContext<'input,FilterContextExt<'input>>;

#[derive(Clone)]
pub struct FilterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FilterContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FilterContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_filter(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_filter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FilterContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_filter(self);
	}
}

impl<'input> CustomRuleContext<'input> for FilterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_filter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_filter }
}
antlr_rust::tid!{FilterContextExt<'a>}

impl<'input> FilterContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FilterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FilterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FilterContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FilterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> FilterContextAttrs<'input> for FilterContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn filter(&mut self,)
	-> Result<Rc<FilterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FilterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 282, RULE_filter);
        let mut _localctx: Rc<FilterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3309);
			recog.base.match_token(FILTER,&mut recog.err_handler)?;

			recog.base.set_state(3310);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(3311);
			recog.base.match_token(WHERE,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(3312);
			recog.booleanExpression_rec(0)?;

			recog.base.set_state(3313);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- over ----------------
pub type OverContextAll<'input> = OverContext<'input>;


pub type OverContext<'input> = BaseParserRuleContext<'input,OverContextExt<'input>>;

#[derive(Clone)]
pub struct OverContextExt<'input>{
	pub windowName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for OverContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for OverContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_over(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_over(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for OverContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_over(self);
	}
}

impl<'input> CustomRuleContext<'input> for OverContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_over }
	//fn type_rule_index() -> usize where Self: Sized { RULE_over }
}
antlr_rust::tid!{OverContextExt<'a>}

impl<'input> OverContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OverContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OverContextExt{
				windowName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait OverContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<OverContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OVER
/// Returns `None` if there is no child corresponding to token OVER
fn OVER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn windowSpecification(&self) -> Option<Rc<WindowSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> OverContextAttrs<'input> for OverContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn over(&mut self,)
	-> Result<Rc<OverContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OverContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 284, RULE_over);
        let mut _localctx: Rc<OverContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3315);
			recog.base.match_token(OVER,&mut recog.err_handler)?;

			recog.base.set_state(3321);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALL | ALTER | ANALYZE | AND |
			 ANTI | ANY | APPROXIMATE | ARRAY | ASC | AT | ATTACH | AUTHORIZATION |
			 AUTO | BACKUP | BEGIN | BERNOULLI | BETWEEN | BINARY | BINDING | BOTH |
			 BY | BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COLLATE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | COPARTITION | COPY | COUNT | CREATE |
			 CUBE | CURRENT | CURRENT_ROLE | DATA | DATABASE | DATASHARE | DATE |
			 DAY | DAYS | DEALLOCATE | DECLARE | DEFAULT | DEFAULTS | DEFINE | DEFINER |
			 DELETE | DELIMITED | DELIMITER | DENY | DESC | DESCRIBE | DESCRIPTOR |
			 DISTINCT | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH | DOUBLE | DROP |
			 ELSE | EMPTY | ENCODE | ENCODING | END | ERROR | ESCAPE | EVEN | EXCEPT |
			 EXCLUDE | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FINAL | FIRST | FIRST_VALUE | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FROM | FUNCTION | FUNCTIONS | GENERATED | GRACE |
			 GRANT | GRANTED | GRANTS | GRAPHVIZ | GROUP | GROUPING | GROUPS | GZIP |
			 HAVING | HEADER | HOUR | HOURS | IAM_ROLE | IF | IGNORE | IMMUTABLE |
			 IN | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INOUT | INTERLEAVED |
			 INSERT | INTERSECT | INTERVAL | INTO | INVOKER | IO | IS | ISOLATION |
			 ISNULL | ILIKE | JOIN | JSON | JSON_ARRAY | JSON_EXISTS | JSON_OBJECT |
			 JSON_QUERY | JSON_VALUE | KB | KEEP | KEY | KEYS | LAG | LAMBDA | LANGUAGE |
			 LAST | LAST_VALUE | LATERAL | LEADING | LEVEL | LIBRARY | LIKE | LIMIT |
			 LINES | LISTAGG | LISTAGGDISTINCT | LOCAL | LOCATION | LOCK | LOGICAL |
			 M | MAP | MASKING | MATCH | MATCHED | MATCHES | MATCH_RECOGNIZE | MATERIALIZED |
			 MAX | MAX_BATCH_ROWS | MAX_BATCH_SIZE | MB | MEASURES | MERGE | MIN |
			 MINUTE | MINUTES | MODEL | MONTH | MONTHS | NEXT | NFC | NFD | NFKC |
			 NFKD | NO | NONE | NORMALIZE | NOTNULL | NULL | NULLS | OBJECT | OF |
			 OFFSET | OMIT | ON | ONE | ONLY | OPTION | OPTIONS | OR | ORDER | ORDINALITY |
			 OUT | OUTPUT | OUTPUTFORMAT | OVER | OVERFLOW | PARTITION | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENTILE_CONT |
			 PERCENTILE_DISC | PERIOD | PERMUTE | PG_CATALOG | PIVOT | POSITION |
			 PRECEDING | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIMARY | PRIVILEGES |
			 PROPERTIES | PRUNE | QUALIFY | QUOTES | RANGE | READ | RECURSIVE | REFERENCES |
			 REFRESH | RENAME | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETRY_TIMEOUT | RETURNING | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROLLUP | ROW | ROWS | RUNNING | S | SAGEMAKER | SCALAR | SEC | SECOND |
			 SECONDS | SCHEMA | SCHEMAS | SECURITY | SEEK | SELECT | SEMI | SERDE |
			 SERDEPROPERTIES | SERIALIZABLE | SESSION | SET | SETS | SHOW | SIMILAR |
			 SOME | SORTKEY | SQL | STABLE | START | STATS | STORED | STRUCT | SUBSET |
			 SUBSTRING | SYSTEM_TIME | TABLE | TABLES | TABLESAMPLE | TEMP | TEMPORARY |
			 TERMINATED | TEXT | STRING_KW | THEN | TIES | TIME | TIMESTAMP | TO |
			 TRAILING | TRANSACTION | TRIM | TRUE | TRUNCATE | TRY_CAST | TUPLE |
			 TYPE | UESCAPE | UNBOUNDED | UNCOMMITTED | UNCONDITIONAL | UNION | UNIQUE |
			 UNKNOWN | UNMATCHED | UNNEST | UNPIVOT | UNSIGNED | UPDATE | USE | USER |
			 UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES | VARYING |
			 VARIADIC | VERBOSE | VERSION | VIEW | VOLATILE | WEEK | WHEN | WINDOW |
			 WITH | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YEARS | YES | ZONE |
			 ZSTD | LBRACKET | IDENTIFIER | DIGIT_IDENTIFIER | QUOTED_IDENTIFIER 
				=> {
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3316);
					let tmp = recog.identifier()?;
					 cast_mut::<_,OverContext >(&mut _localctx).windowName = Some(tmp.clone());
					  

					}
				}

			 LPAREN 
				=> {
					{
					recog.base.set_state(3317);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule windowSpecification*/
					recog.base.set_state(3318);
					recog.windowSpecification()?;

					recog.base.set_state(3319);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowFrame ----------------
pub type WindowFrameContextAll<'input> = WindowFrameContext<'input>;


pub type WindowFrameContext<'input> = BaseParserRuleContext<'input,WindowFrameContextExt<'input>>;

#[derive(Clone)]
pub struct WindowFrameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for WindowFrameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for WindowFrameContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowFrame(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_windowFrame(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for WindowFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_windowFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowFrame }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowFrame }
}
antlr_rust::tid!{WindowFrameContextExt<'a>}

impl<'input> WindowFrameContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowFrameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowFrameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowFrameContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<WindowFrameContextExt<'input>>{

fn frameExtent(&self) -> Option<Rc<FrameExtentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowFrameContextAttrs<'input> for WindowFrameContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowFrame(&mut self,)
	-> Result<Rc<WindowFrameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowFrameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 286, RULE_windowFrame);
        let mut _localctx: Rc<WindowFrameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule frameExtent*/
			recog.base.set_state(3323);
			recog.frameExtent()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- frameExtent ----------------
pub type FrameExtentContextAll<'input> = FrameExtentContext<'input>;


pub type FrameExtentContext<'input> = BaseParserRuleContext<'input,FrameExtentContextExt<'input>>;

#[derive(Clone)]
pub struct FrameExtentContextExt<'input>{
	pub frameType: Option<TokenType<'input>>,
	pub start: Option<Rc<FrameBoundContextAll<'input>>>,
	pub end: Option<Rc<FrameBoundContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FrameExtentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FrameExtentContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_frameExtent(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_frameExtent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FrameExtentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_frameExtent(self);
	}
}

impl<'input> CustomRuleContext<'input> for FrameExtentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameExtent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameExtent }
}
antlr_rust::tid!{FrameExtentContextExt<'a>}

impl<'input> FrameExtentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FrameExtentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FrameExtentContextExt{
				frameType: None, 
				start: None, end: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FrameExtentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FrameExtentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
fn frameBound_all(&self) ->  Vec<Rc<FrameBoundContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn frameBound(&self, i: usize) -> Option<Rc<FrameBoundContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPS
/// Returns `None` if there is no child corresponding to token GROUPS
fn GROUPS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GROUPS, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}

}

impl<'input> FrameExtentContextAttrs<'input> for FrameExtentContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn frameExtent(&mut self,)
	-> Result<Rc<FrameExtentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FrameExtentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 288, RULE_frameExtent);
        let mut _localctx: Rc<FrameExtentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3349);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(455,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3325);
					let tmp = recog.base.match_token(RANGE,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(3326);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3327);
					let tmp = recog.base.match_token(ROWS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(3328);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3329);
					let tmp = recog.base.match_token(GROUPS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(3330);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3331);
					let tmp = recog.base.match_token(RANGE,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					recog.base.set_state(3332);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3333);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(3334);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3335);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3337);
					let tmp = recog.base.match_token(ROWS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					recog.base.set_state(3338);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3339);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(3340);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3341);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(3343);
					let tmp = recog.base.match_token(GROUPS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					recog.base.set_state(3344);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3345);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(3346);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3347);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- frameBound ----------------
#[derive(Debug)]
pub enum FrameBoundContextAll<'input>{
	BoundedFrameContext(BoundedFrameContext<'input>),
	UnboundedFrameContext(UnboundedFrameContext<'input>),
	CurrentRowBoundContext(CurrentRowBoundContext<'input>),
Error(FrameBoundContext<'input>)
}
antlr_rust::tid!{FrameBoundContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for FrameBoundContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for FrameBoundContextAll<'input>{}

impl<'input> Deref for FrameBoundContextAll<'input>{
	type Target = dyn FrameBoundContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use FrameBoundContextAll::*;
		match self{
			BoundedFrameContext(inner) => inner,
			UnboundedFrameContext(inner) => inner,
			CurrentRowBoundContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FrameBoundContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FrameBoundContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type FrameBoundContext<'input> = BaseParserRuleContext<'input,FrameBoundContextExt<'input>>;

#[derive(Clone)]
pub struct FrameBoundContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for FrameBoundContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for FrameBoundContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for FrameBoundContext<'input>{
}

impl<'input> CustomRuleContext<'input> for FrameBoundContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}
antlr_rust::tid!{FrameBoundContextExt<'a>}

impl<'input> FrameBoundContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FrameBoundContextAll<'input>> {
		Rc::new(
		FrameBoundContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FrameBoundContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait FrameBoundContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<FrameBoundContextExt<'input>>{


}

impl<'input> FrameBoundContextAttrs<'input> for FrameBoundContext<'input>{}

pub type BoundedFrameContext<'input> = BaseParserRuleContext<'input,BoundedFrameContextExt<'input>>;

pub trait BoundedFrameContextAttrs<'input>: RedshiftParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECEDING
	/// Returns `None` if there is no child corresponding to token PRECEDING
	fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PRECEDING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOLLOWING
	/// Returns `None` if there is no child corresponding to token FOLLOWING
	fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FOLLOWING, 0)
	}
}

impl<'input> BoundedFrameContextAttrs<'input> for BoundedFrameContext<'input>{}

pub struct BoundedFrameContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	pub boundType: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BoundedFrameContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for BoundedFrameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for BoundedFrameContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_boundedFrame(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_boundedFrame(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for BoundedFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_boundedFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for BoundedFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for BoundedFrameContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for BoundedFrameContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for BoundedFrameContext<'input> {}

impl<'input> BoundedFrameContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::BoundedFrameContext(
				BaseParserRuleContext::copy_from(ctx,BoundedFrameContextExt{
					boundType:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnboundedFrameContext<'input> = BaseParserRuleContext<'input,UnboundedFrameContextExt<'input>>;

pub trait UnboundedFrameContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNBOUNDED
	/// Returns `None` if there is no child corresponding to token UNBOUNDED
	fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UNBOUNDED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECEDING
	/// Returns `None` if there is no child corresponding to token PRECEDING
	fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PRECEDING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOLLOWING
	/// Returns `None` if there is no child corresponding to token FOLLOWING
	fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(FOLLOWING, 0)
	}
}

impl<'input> UnboundedFrameContextAttrs<'input> for UnboundedFrameContext<'input>{}

pub struct UnboundedFrameContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	pub boundType: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnboundedFrameContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UnboundedFrameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UnboundedFrameContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unboundedFrame(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_unboundedFrame(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UnboundedFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_unboundedFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnboundedFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for UnboundedFrameContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for UnboundedFrameContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for UnboundedFrameContext<'input> {}

impl<'input> UnboundedFrameContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::UnboundedFrameContext(
				BaseParserRuleContext::copy_from(ctx,UnboundedFrameContextExt{
					boundType:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CurrentRowBoundContext<'input> = BaseParserRuleContext<'input,CurrentRowBoundContextExt<'input>>;

pub trait CurrentRowBoundContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CURRENT
	/// Returns `None` if there is no child corresponding to token CURRENT
	fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(CURRENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
}

impl<'input> CurrentRowBoundContextAttrs<'input> for CurrentRowBoundContext<'input>{}

pub struct CurrentRowBoundContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CurrentRowBoundContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for CurrentRowBoundContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for CurrentRowBoundContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_currentRowBound(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_currentRowBound(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for CurrentRowBoundContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_currentRowBound(self);
	}
}

impl<'input> CustomRuleContext<'input> for CurrentRowBoundContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for CurrentRowBoundContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for CurrentRowBoundContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for CurrentRowBoundContext<'input> {}

impl<'input> CurrentRowBoundContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::CurrentRowBoundContext(
				BaseParserRuleContext::copy_from(ctx,CurrentRowBoundContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn frameBound(&mut self,)
	-> Result<Rc<FrameBoundContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FrameBoundContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 290, RULE_frameBound);
        let mut _localctx: Rc<FrameBoundContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3360);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(456,&mut recog.base)? {
				1 =>{
					let tmp = UnboundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3351);
					recog.base.match_token(UNBOUNDED,&mut recog.err_handler)?;

					recog.base.set_state(3352);
					let tmp = recog.base.match_token(PRECEDING,&mut recog.err_handler)?;
					if let FrameBoundContextAll::UnboundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = UnboundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3353);
					recog.base.match_token(UNBOUNDED,&mut recog.err_handler)?;

					recog.base.set_state(3354);
					let tmp = recog.base.match_token(FOLLOWING,&mut recog.err_handler)?;
					if let FrameBoundContextAll::UnboundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
				}
			,
				3 =>{
					let tmp = CurrentRowBoundContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3355);
					recog.base.match_token(CURRENT,&mut recog.err_handler)?;

					recog.base.set_state(3356);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = BoundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(3357);
					recog.expression()?;

					recog.base.set_state(3358);
					if let FrameBoundContextAll::BoundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==FOLLOWING || _la==PRECEDING) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let FrameBoundContextAll::BoundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
						ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowPattern ----------------
#[derive(Debug)]
pub enum RowPatternContextAll<'input>{
	QuantifiedPrimaryContext(QuantifiedPrimaryContext<'input>),
	PatternConcatenationContext(PatternConcatenationContext<'input>),
	PatternAlternationContext(PatternAlternationContext<'input>),
Error(RowPatternContext<'input>)
}
antlr_rust::tid!{RowPatternContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RowPatternContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for RowPatternContextAll<'input>{}

impl<'input> Deref for RowPatternContextAll<'input>{
	type Target = dyn RowPatternContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RowPatternContextAll::*;
		match self{
			QuantifiedPrimaryContext(inner) => inner,
			PatternConcatenationContext(inner) => inner,
			PatternAlternationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RowPatternContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RowPatternContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RowPatternContext<'input> = BaseParserRuleContext<'input,RowPatternContextExt<'input>>;

#[derive(Clone)]
pub struct RowPatternContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RowPatternContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RowPatternContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RowPatternContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RowPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowPattern }
}
antlr_rust::tid!{RowPatternContextExt<'a>}

impl<'input> RowPatternContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowPatternContextAll<'input>> {
		Rc::new(
		RowPatternContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowPatternContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RowPatternContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RowPatternContextExt<'input>>{


}

impl<'input> RowPatternContextAttrs<'input> for RowPatternContext<'input>{}

pub type QuantifiedPrimaryContext<'input> = BaseParserRuleContext<'input,QuantifiedPrimaryContextExt<'input>>;

pub trait QuantifiedPrimaryContextAttrs<'input>: RedshiftParserContext<'input>{
	fn patternPrimary(&self) -> Option<Rc<PatternPrimaryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn patternQuantifier(&self) -> Option<Rc<PatternQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QuantifiedPrimaryContextAttrs<'input> for QuantifiedPrimaryContext<'input>{}

pub struct QuantifiedPrimaryContextExt<'input>{
	base:RowPatternContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuantifiedPrimaryContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for QuantifiedPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QuantifiedPrimaryContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quantifiedPrimary(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_quantifiedPrimary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QuantifiedPrimaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_quantifiedPrimary(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuantifiedPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowPattern }
}

impl<'input> Borrow<RowPatternContextExt<'input>> for QuantifiedPrimaryContext<'input>{
	fn borrow(&self) -> &RowPatternContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowPatternContextExt<'input>> for QuantifiedPrimaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowPatternContextExt<'input> { &mut self.base }
}

impl<'input> RowPatternContextAttrs<'input> for QuantifiedPrimaryContext<'input> {}

impl<'input> QuantifiedPrimaryContextExt<'input>{
	fn new(ctx: &dyn RowPatternContextAttrs<'input>) -> Rc<RowPatternContextAll<'input>>  {
		Rc::new(
			RowPatternContextAll::QuantifiedPrimaryContext(
				BaseParserRuleContext::copy_from(ctx,QuantifiedPrimaryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PatternConcatenationContext<'input> = BaseParserRuleContext<'input,PatternConcatenationContextExt<'input>>;

pub trait PatternConcatenationContextAttrs<'input>: RedshiftParserContext<'input>{
	fn rowPattern_all(&self) ->  Vec<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowPattern(&self, i: usize) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> PatternConcatenationContextAttrs<'input> for PatternConcatenationContext<'input>{}

pub struct PatternConcatenationContextExt<'input>{
	base:RowPatternContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PatternConcatenationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PatternConcatenationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PatternConcatenationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_patternConcatenation(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_patternConcatenation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PatternConcatenationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_patternConcatenation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PatternConcatenationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowPattern }
}

impl<'input> Borrow<RowPatternContextExt<'input>> for PatternConcatenationContext<'input>{
	fn borrow(&self) -> &RowPatternContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowPatternContextExt<'input>> for PatternConcatenationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowPatternContextExt<'input> { &mut self.base }
}

impl<'input> RowPatternContextAttrs<'input> for PatternConcatenationContext<'input> {}

impl<'input> PatternConcatenationContextExt<'input>{
	fn new(ctx: &dyn RowPatternContextAttrs<'input>) -> Rc<RowPatternContextAll<'input>>  {
		Rc::new(
			RowPatternContextAll::PatternConcatenationContext(
				BaseParserRuleContext::copy_from(ctx,PatternConcatenationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PatternAlternationContext<'input> = BaseParserRuleContext<'input,PatternAlternationContextExt<'input>>;

pub trait PatternAlternationContextAttrs<'input>: RedshiftParserContext<'input>{
	fn rowPattern_all(&self) ->  Vec<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowPattern(&self, i: usize) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_OR
	/// Returns `None` if there is no child corresponding to token BITWISE_OR
	fn BITWISE_OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_OR, 0)
	}
}

impl<'input> PatternAlternationContextAttrs<'input> for PatternAlternationContext<'input>{}

pub struct PatternAlternationContextExt<'input>{
	base:RowPatternContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PatternAlternationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PatternAlternationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PatternAlternationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_patternAlternation(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_patternAlternation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PatternAlternationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_patternAlternation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PatternAlternationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowPattern }
}

impl<'input> Borrow<RowPatternContextExt<'input>> for PatternAlternationContext<'input>{
	fn borrow(&self) -> &RowPatternContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowPatternContextExt<'input>> for PatternAlternationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowPatternContextExt<'input> { &mut self.base }
}

impl<'input> RowPatternContextAttrs<'input> for PatternAlternationContext<'input> {}

impl<'input> PatternAlternationContextExt<'input>{
	fn new(ctx: &dyn RowPatternContextAttrs<'input>) -> Rc<RowPatternContextAll<'input>>  {
		Rc::new(
			RowPatternContextAll::PatternAlternationContext(
				BaseParserRuleContext::copy_from(ctx,PatternAlternationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  rowPattern(&mut self,)
	-> Result<Rc<RowPatternContextAll<'input>>,ANTLRError> {
		self.rowPattern_rec(0)
	}

	fn rowPattern_rec(&mut self, _p: isize)
	-> Result<Rc<RowPatternContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = RowPatternContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 292, RULE_rowPattern, _p);
	    let mut _localctx: Rc<RowPatternContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 292;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			{
			let mut tmp = QuantifiedPrimaryContextExt::new(&**_localctx);
			recog.ctx = Some(tmp.clone());
			_localctx = tmp;
			_prevctx = _localctx.clone();


			/*InvokeRule patternPrimary*/
			recog.base.set_state(3363);
			recog.patternPrimary()?;

			recog.base.set_state(3365);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(457,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule patternQuantifier*/
					recog.base.set_state(3364);
					recog.patternQuantifier()?;

					}
				}

				_ => {}
			}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(3374);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(459,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(3372);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(458,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = PatternConcatenationContextExt::new(&**RowPatternContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_rowPattern);
							_localctx = tmp;
							recog.base.set_state(3367);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							/*InvokeRule rowPattern*/
							recog.base.set_state(3368);
							recog.rowPattern_rec(3)?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = PatternAlternationContextExt::new(&**RowPatternContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_rowPattern);
							_localctx = tmp;
							recog.base.set_state(3369);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(3370);
							recog.base.match_token(BITWISE_OR,&mut recog.err_handler)?;

							/*InvokeRule rowPattern*/
							recog.base.set_state(3371);
							recog.rowPattern_rec(2)?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(3376);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(459,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- patternPrimary ----------------
#[derive(Debug)]
pub enum PatternPrimaryContextAll<'input>{
	PatternPermutationContext(PatternPermutationContext<'input>),
	PartitionEndAnchorContext(PartitionEndAnchorContext<'input>),
	PatternVariableContext(PatternVariableContext<'input>),
	ExcludedPatternContext(ExcludedPatternContext<'input>),
	PartitionStartAnchorContext(PartitionStartAnchorContext<'input>),
	EmptyPatternContext(EmptyPatternContext<'input>),
	GroupedPatternContext(GroupedPatternContext<'input>),
Error(PatternPrimaryContext<'input>)
}
antlr_rust::tid!{PatternPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PatternPrimaryContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PatternPrimaryContextAll<'input>{}

impl<'input> Deref for PatternPrimaryContextAll<'input>{
	type Target = dyn PatternPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PatternPrimaryContextAll::*;
		match self{
			PatternPermutationContext(inner) => inner,
			PartitionEndAnchorContext(inner) => inner,
			PatternVariableContext(inner) => inner,
			ExcludedPatternContext(inner) => inner,
			PartitionStartAnchorContext(inner) => inner,
			EmptyPatternContext(inner) => inner,
			GroupedPatternContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PatternPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PatternPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PatternPrimaryContext<'input> = BaseParserRuleContext<'input,PatternPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct PatternPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PatternPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PatternPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PatternPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PatternPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}
antlr_rust::tid!{PatternPrimaryContextExt<'a>}

impl<'input> PatternPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PatternPrimaryContextAll<'input>> {
		Rc::new(
		PatternPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PatternPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PatternPrimaryContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PatternPrimaryContextExt<'input>>{


}

impl<'input> PatternPrimaryContextAttrs<'input> for PatternPrimaryContext<'input>{}

pub type PatternPermutationContext<'input> = BaseParserRuleContext<'input,PatternPermutationContextExt<'input>>;

pub trait PatternPermutationContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PERMUTE
	/// Returns `None` if there is no child corresponding to token PERMUTE
	fn PERMUTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PERMUTE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn rowPattern_all(&self) ->  Vec<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowPattern(&self, i: usize) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PatternPermutationContextAttrs<'input> for PatternPermutationContext<'input>{}

pub struct PatternPermutationContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PatternPermutationContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PatternPermutationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PatternPermutationContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_patternPermutation(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_patternPermutation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PatternPermutationContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_patternPermutation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PatternPermutationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for PatternPermutationContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for PatternPermutationContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for PatternPermutationContext<'input> {}

impl<'input> PatternPermutationContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::PatternPermutationContext(
				BaseParserRuleContext::copy_from(ctx,PatternPermutationContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PartitionEndAnchorContext<'input> = BaseParserRuleContext<'input,PartitionEndAnchorContextExt<'input>>;

pub trait PartitionEndAnchorContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOLLAR
	/// Returns `None` if there is no child corresponding to token DOLLAR
	fn DOLLAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR, 0)
	}
}

impl<'input> PartitionEndAnchorContextAttrs<'input> for PartitionEndAnchorContext<'input>{}

pub struct PartitionEndAnchorContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PartitionEndAnchorContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PartitionEndAnchorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PartitionEndAnchorContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_partitionEndAnchor(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_partitionEndAnchor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PartitionEndAnchorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_partitionEndAnchor(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionEndAnchorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for PartitionEndAnchorContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for PartitionEndAnchorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for PartitionEndAnchorContext<'input> {}

impl<'input> PartitionEndAnchorContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::PartitionEndAnchorContext(
				BaseParserRuleContext::copy_from(ctx,PartitionEndAnchorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PatternVariableContext<'input> = BaseParserRuleContext<'input,PatternVariableContextExt<'input>>;

pub trait PatternVariableContextAttrs<'input>: RedshiftParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PatternVariableContextAttrs<'input> for PatternVariableContext<'input>{}

pub struct PatternVariableContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PatternVariableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PatternVariableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PatternVariableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_patternVariable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_patternVariable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PatternVariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_patternVariable(self);
	}
}

impl<'input> CustomRuleContext<'input> for PatternVariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for PatternVariableContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for PatternVariableContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for PatternVariableContext<'input> {}

impl<'input> PatternVariableContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::PatternVariableContext(
				BaseParserRuleContext::copy_from(ctx,PatternVariableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExcludedPatternContext<'input> = BaseParserRuleContext<'input,ExcludedPatternContextExt<'input>>;

pub trait ExcludedPatternContextAttrs<'input>: RedshiftParserContext<'input>{
	fn rowPattern(&self) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExcludedPatternContextAttrs<'input> for ExcludedPatternContext<'input>{}

pub struct ExcludedPatternContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExcludedPatternContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ExcludedPatternContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ExcludedPatternContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_excludedPattern(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_excludedPattern(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ExcludedPatternContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_excludedPattern(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExcludedPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for ExcludedPatternContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for ExcludedPatternContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for ExcludedPatternContext<'input> {}

impl<'input> ExcludedPatternContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::ExcludedPatternContext(
				BaseParserRuleContext::copy_from(ctx,ExcludedPatternContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PartitionStartAnchorContext<'input> = BaseParserRuleContext<'input,PartitionStartAnchorContextExt<'input>>;

pub trait PartitionStartAnchorContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BINARY_EXP
	/// Returns `None` if there is no child corresponding to token BINARY_EXP
	fn BINARY_EXP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(BINARY_EXP, 0)
	}
}

impl<'input> PartitionStartAnchorContextAttrs<'input> for PartitionStartAnchorContext<'input>{}

pub struct PartitionStartAnchorContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PartitionStartAnchorContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for PartitionStartAnchorContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PartitionStartAnchorContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_partitionStartAnchor(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_partitionStartAnchor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PartitionStartAnchorContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_partitionStartAnchor(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionStartAnchorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for PartitionStartAnchorContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for PartitionStartAnchorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for PartitionStartAnchorContext<'input> {}

impl<'input> PartitionStartAnchorContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::PartitionStartAnchorContext(
				BaseParserRuleContext::copy_from(ctx,PartitionStartAnchorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type EmptyPatternContext<'input> = BaseParserRuleContext<'input,EmptyPatternContextExt<'input>>;

pub trait EmptyPatternContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> EmptyPatternContextAttrs<'input> for EmptyPatternContext<'input>{}

pub struct EmptyPatternContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{EmptyPatternContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for EmptyPatternContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for EmptyPatternContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_emptyPattern(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_emptyPattern(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for EmptyPatternContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_emptyPattern(self);
	}
}

impl<'input> CustomRuleContext<'input> for EmptyPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for EmptyPatternContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for EmptyPatternContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for EmptyPatternContext<'input> {}

impl<'input> EmptyPatternContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::EmptyPatternContext(
				BaseParserRuleContext::copy_from(ctx,EmptyPatternContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GroupedPatternContext<'input> = BaseParserRuleContext<'input,GroupedPatternContextExt<'input>>;

pub trait GroupedPatternContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn rowPattern(&self) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> GroupedPatternContextAttrs<'input> for GroupedPatternContext<'input>{}

pub struct GroupedPatternContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GroupedPatternContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for GroupedPatternContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for GroupedPatternContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_groupedPattern(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_groupedPattern(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for GroupedPatternContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_groupedPattern(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupedPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for GroupedPatternContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for GroupedPatternContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for GroupedPatternContext<'input> {}

impl<'input> GroupedPatternContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::GroupedPatternContext(
				BaseParserRuleContext::copy_from(ctx,GroupedPatternContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn patternPrimary(&mut self,)
	-> Result<Rc<PatternPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PatternPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 294, RULE_patternPrimary);
        let mut _localctx: Rc<PatternPrimaryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(3405);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(462,&mut recog.base)? {
				1 =>{
					let tmp = PatternVariableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3377);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					let tmp = EmptyPatternContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3378);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3379);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = PatternPermutationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3380);
					recog.base.match_token(PERMUTE,&mut recog.err_handler)?;

					recog.base.set_state(3381);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule rowPattern*/
					recog.base.set_state(3382);
					recog.rowPattern_rec(0)?;

					recog.base.set_state(3387);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(460,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(3383);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule rowPattern*/
							recog.base.set_state(3384);
							recog.rowPattern_rec(0)?;

							}
							} 
						}
						recog.base.set_state(3389);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(460,&mut recog.base)?;
					}
					recog.base.set_state(3391);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3390);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PatternPrimaryContextAll::PatternPermutationContext(ctx) = cast_mut::<_,PatternPrimaryContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3393);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = GroupedPatternContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3395);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule rowPattern*/
					recog.base.set_state(3396);
					recog.rowPattern_rec(0)?;

					recog.base.set_state(3397);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = PartitionStartAnchorContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(3399);
					recog.base.match_token(BINARY_EXP,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					let tmp = PartitionEndAnchorContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(3400);
					recog.base.match_token(DOLLAR,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = ExcludedPatternContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(3401);
					recog.base.match_token(T__5,&mut recog.err_handler)?;

					/*InvokeRule rowPattern*/
					recog.base.set_state(3402);
					recog.rowPattern_rec(0)?;

					recog.base.set_state(3403);
					recog.base.match_token(T__6,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- patternQuantifier ----------------
#[derive(Debug)]
pub enum PatternQuantifierContextAll<'input>{
	ZeroOrMoreQuantifierContext(ZeroOrMoreQuantifierContext<'input>),
	OneOrMoreQuantifierContext(OneOrMoreQuantifierContext<'input>),
	ZeroOrOneQuantifierContext(ZeroOrOneQuantifierContext<'input>),
	RangeQuantifierContext(RangeQuantifierContext<'input>),
Error(PatternQuantifierContext<'input>)
}
antlr_rust::tid!{PatternQuantifierContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PatternQuantifierContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PatternQuantifierContextAll<'input>{}

impl<'input> Deref for PatternQuantifierContextAll<'input>{
	type Target = dyn PatternQuantifierContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PatternQuantifierContextAll::*;
		match self{
			ZeroOrMoreQuantifierContext(inner) => inner,
			OneOrMoreQuantifierContext(inner) => inner,
			ZeroOrOneQuantifierContext(inner) => inner,
			RangeQuantifierContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PatternQuantifierContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PatternQuantifierContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PatternQuantifierContext<'input> = BaseParserRuleContext<'input,PatternQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct PatternQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PatternQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PatternQuantifierContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PatternQuantifierContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PatternQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}
antlr_rust::tid!{PatternQuantifierContextExt<'a>}

impl<'input> PatternQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PatternQuantifierContextAll<'input>> {
		Rc::new(
		PatternQuantifierContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PatternQuantifierContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PatternQuantifierContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PatternQuantifierContextExt<'input>>{


}

impl<'input> PatternQuantifierContextAttrs<'input> for PatternQuantifierContext<'input>{}

pub type ZeroOrMoreQuantifierContext<'input> = BaseParserRuleContext<'input,ZeroOrMoreQuantifierContextExt<'input>>;

pub trait ZeroOrMoreQuantifierContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token QUESTION_MARK
	/// Returns `None` if there is no child corresponding to token QUESTION_MARK
	fn QUESTION_MARK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, 0)
	}
}

impl<'input> ZeroOrMoreQuantifierContextAttrs<'input> for ZeroOrMoreQuantifierContext<'input>{}

pub struct ZeroOrMoreQuantifierContextExt<'input>{
	base:PatternQuantifierContextExt<'input>,
	pub reluctant: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ZeroOrMoreQuantifierContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ZeroOrMoreQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ZeroOrMoreQuantifierContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_zeroOrMoreQuantifier(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_zeroOrMoreQuantifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ZeroOrMoreQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_zeroOrMoreQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for ZeroOrMoreQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}

impl<'input> Borrow<PatternQuantifierContextExt<'input>> for ZeroOrMoreQuantifierContext<'input>{
	fn borrow(&self) -> &PatternQuantifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternQuantifierContextExt<'input>> for ZeroOrMoreQuantifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternQuantifierContextExt<'input> { &mut self.base }
}

impl<'input> PatternQuantifierContextAttrs<'input> for ZeroOrMoreQuantifierContext<'input> {}

impl<'input> ZeroOrMoreQuantifierContextExt<'input>{
	fn new(ctx: &dyn PatternQuantifierContextAttrs<'input>) -> Rc<PatternQuantifierContextAll<'input>>  {
		Rc::new(
			PatternQuantifierContextAll::ZeroOrMoreQuantifierContext(
				BaseParserRuleContext::copy_from(ctx,ZeroOrMoreQuantifierContextExt{
					reluctant:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type OneOrMoreQuantifierContext<'input> = BaseParserRuleContext<'input,OneOrMoreQuantifierContextExt<'input>>;

pub trait OneOrMoreQuantifierContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token QUESTION_MARK
	/// Returns `None` if there is no child corresponding to token QUESTION_MARK
	fn QUESTION_MARK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, 0)
	}
}

impl<'input> OneOrMoreQuantifierContextAttrs<'input> for OneOrMoreQuantifierContext<'input>{}

pub struct OneOrMoreQuantifierContextExt<'input>{
	base:PatternQuantifierContextExt<'input>,
	pub reluctant: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OneOrMoreQuantifierContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for OneOrMoreQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for OneOrMoreQuantifierContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_oneOrMoreQuantifier(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_oneOrMoreQuantifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for OneOrMoreQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_oneOrMoreQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for OneOrMoreQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}

impl<'input> Borrow<PatternQuantifierContextExt<'input>> for OneOrMoreQuantifierContext<'input>{
	fn borrow(&self) -> &PatternQuantifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternQuantifierContextExt<'input>> for OneOrMoreQuantifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternQuantifierContextExt<'input> { &mut self.base }
}

impl<'input> PatternQuantifierContextAttrs<'input> for OneOrMoreQuantifierContext<'input> {}

impl<'input> OneOrMoreQuantifierContextExt<'input>{
	fn new(ctx: &dyn PatternQuantifierContextAttrs<'input>) -> Rc<PatternQuantifierContextAll<'input>>  {
		Rc::new(
			PatternQuantifierContextAll::OneOrMoreQuantifierContext(
				BaseParserRuleContext::copy_from(ctx,OneOrMoreQuantifierContextExt{
					reluctant:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ZeroOrOneQuantifierContext<'input> = BaseParserRuleContext<'input,ZeroOrOneQuantifierContextExt<'input>>;

pub trait ZeroOrOneQuantifierContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token QUESTION_MARK in current rule
	fn QUESTION_MARK_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token QUESTION_MARK, starting from 0.
	/// Returns `None` if number of children corresponding to token QUESTION_MARK is less or equal than `i`.
	fn QUESTION_MARK(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, i)
	}
}

impl<'input> ZeroOrOneQuantifierContextAttrs<'input> for ZeroOrOneQuantifierContext<'input>{}

pub struct ZeroOrOneQuantifierContextExt<'input>{
	base:PatternQuantifierContextExt<'input>,
	pub reluctant: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ZeroOrOneQuantifierContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ZeroOrOneQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ZeroOrOneQuantifierContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_zeroOrOneQuantifier(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_zeroOrOneQuantifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ZeroOrOneQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_zeroOrOneQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for ZeroOrOneQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}

impl<'input> Borrow<PatternQuantifierContextExt<'input>> for ZeroOrOneQuantifierContext<'input>{
	fn borrow(&self) -> &PatternQuantifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternQuantifierContextExt<'input>> for ZeroOrOneQuantifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternQuantifierContextExt<'input> { &mut self.base }
}

impl<'input> PatternQuantifierContextAttrs<'input> for ZeroOrOneQuantifierContext<'input> {}

impl<'input> ZeroOrOneQuantifierContextExt<'input>{
	fn new(ctx: &dyn PatternQuantifierContextAttrs<'input>) -> Rc<PatternQuantifierContextAll<'input>>  {
		Rc::new(
			PatternQuantifierContextAll::ZeroOrOneQuantifierContext(
				BaseParserRuleContext::copy_from(ctx,ZeroOrOneQuantifierContextExt{
					reluctant:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RangeQuantifierContext<'input> = BaseParserRuleContext<'input,RangeQuantifierContextExt<'input>>;

pub trait RangeQuantifierContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token INTEGER_VALUE in current rule
	fn INTEGER_VALUE_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token INTEGER_VALUE, starting from 0.
	/// Returns `None` if number of children corresponding to token INTEGER_VALUE is less or equal than `i`.
	fn INTEGER_VALUE(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, i)
	}
	/// Retrieves first TerminalNode corresponding to token QUESTION_MARK
	/// Returns `None` if there is no child corresponding to token QUESTION_MARK
	fn QUESTION_MARK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> RangeQuantifierContextAttrs<'input> for RangeQuantifierContext<'input>{}

pub struct RangeQuantifierContextExt<'input>{
	base:PatternQuantifierContextExt<'input>,
	pub exactly: Option<TokenType<'input>>,
	pub reluctant: Option<TokenType<'input>>,
	pub atLeast: Option<TokenType<'input>>,
	pub atMost: Option<TokenType<'input>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RangeQuantifierContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RangeQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RangeQuantifierContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rangeQuantifier(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_rangeQuantifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RangeQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rangeQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for RangeQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}

impl<'input> Borrow<PatternQuantifierContextExt<'input>> for RangeQuantifierContext<'input>{
	fn borrow(&self) -> &PatternQuantifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternQuantifierContextExt<'input>> for RangeQuantifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternQuantifierContextExt<'input> { &mut self.base }
}

impl<'input> PatternQuantifierContextAttrs<'input> for RangeQuantifierContext<'input> {}

impl<'input> RangeQuantifierContextExt<'input>{
	fn new(ctx: &dyn PatternQuantifierContextAttrs<'input>) -> Rc<PatternQuantifierContextAll<'input>>  {
		Rc::new(
			PatternQuantifierContextAll::RangeQuantifierContext(
				BaseParserRuleContext::copy_from(ctx,RangeQuantifierContextExt{
					exactly:None, reluctant:None, atLeast:None, atMost:None, tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn patternQuantifier(&mut self,)
	-> Result<Rc<PatternQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PatternQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 296, RULE_patternQuantifier);
        let mut _localctx: Rc<PatternQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3440);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(471,&mut recog.base)? {
				1 =>{
					let tmp = ZeroOrMoreQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3407);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(3409);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(463,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3408);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::ZeroOrMoreQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = OneOrMoreQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3411);
					recog.base.match_token(PLUS,&mut recog.err_handler)?;

					recog.base.set_state(3413);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(464,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3412);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::OneOrMoreQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				3 =>{
					let tmp = ZeroOrOneQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3415);
					recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;

					recog.base.set_state(3417);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(465,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3416);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::ZeroOrOneQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				4 =>{
					let tmp = RangeQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3419);
					recog.base.match_token(T__7,&mut recog.err_handler)?;

					recog.base.set_state(3420);
					let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
					if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
					ctx.exactly = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(3421);
					recog.base.match_token(T__8,&mut recog.err_handler)?;

					recog.base.set_state(3423);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(466,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3422);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				5 =>{
					let tmp = RangeQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(3425);
					recog.base.match_token(T__7,&mut recog.err_handler)?;

					recog.base.set_state(3427);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INTEGER_VALUE {
						{
						recog.base.set_state(3426);
						let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
						if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
						ctx.atLeast = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3429);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					recog.base.set_state(3431);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INTEGER_VALUE {
						{
						recog.base.set_state(3430);
						let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
						if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
						ctx.atMost = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3434);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3433);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3436);
					recog.base.match_token(T__8,&mut recog.err_handler)?;

					recog.base.set_state(3438);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(470,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3437);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transactionMode ----------------
#[derive(Debug)]
pub enum TransactionModeContextAll<'input>{
	TransactionAccessModeContext(TransactionAccessModeContext<'input>),
	IsolationLevelContext(IsolationLevelContext<'input>),
Error(TransactionModeContext<'input>)
}
antlr_rust::tid!{TransactionModeContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TransactionModeContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for TransactionModeContextAll<'input>{}

impl<'input> Deref for TransactionModeContextAll<'input>{
	type Target = dyn TransactionModeContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TransactionModeContextAll::*;
		match self{
			TransactionAccessModeContext(inner) => inner,
			IsolationLevelContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TransactionModeContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TransactionModeContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TransactionModeContext<'input> = BaseParserRuleContext<'input,TransactionModeContextExt<'input>>;

#[derive(Clone)]
pub struct TransactionModeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for TransactionModeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TransactionModeContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TransactionModeContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TransactionModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transactionMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transactionMode }
}
antlr_rust::tid!{TransactionModeContextExt<'a>}

impl<'input> TransactionModeContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransactionModeContextAll<'input>> {
		Rc::new(
		TransactionModeContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransactionModeContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TransactionModeContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<TransactionModeContextExt<'input>>{


}

impl<'input> TransactionModeContextAttrs<'input> for TransactionModeContext<'input>{}

pub type TransactionAccessModeContext<'input> = BaseParserRuleContext<'input,TransactionAccessModeContextExt<'input>>;

pub trait TransactionAccessModeContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token READ
	/// Returns `None` if there is no child corresponding to token READ
	fn READ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(READ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ONLY
	/// Returns `None` if there is no child corresponding to token ONLY
	fn ONLY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ONLY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WRITE
	/// Returns `None` if there is no child corresponding to token WRITE
	fn WRITE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(WRITE, 0)
	}
}

impl<'input> TransactionAccessModeContextAttrs<'input> for TransactionAccessModeContext<'input>{}

pub struct TransactionAccessModeContextExt<'input>{
	base:TransactionModeContextExt<'input>,
	pub accessMode: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TransactionAccessModeContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for TransactionAccessModeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for TransactionAccessModeContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_transactionAccessMode(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_transactionAccessMode(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for TransactionAccessModeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_transactionAccessMode(self);
	}
}

impl<'input> CustomRuleContext<'input> for TransactionAccessModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transactionMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transactionMode }
}

impl<'input> Borrow<TransactionModeContextExt<'input>> for TransactionAccessModeContext<'input>{
	fn borrow(&self) -> &TransactionModeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TransactionModeContextExt<'input>> for TransactionAccessModeContext<'input>{
	fn borrow_mut(&mut self) -> &mut TransactionModeContextExt<'input> { &mut self.base }
}

impl<'input> TransactionModeContextAttrs<'input> for TransactionAccessModeContext<'input> {}

impl<'input> TransactionAccessModeContextExt<'input>{
	fn new(ctx: &dyn TransactionModeContextAttrs<'input>) -> Rc<TransactionModeContextAll<'input>>  {
		Rc::new(
			TransactionModeContextAll::TransactionAccessModeContext(
				BaseParserRuleContext::copy_from(ctx,TransactionAccessModeContextExt{
					accessMode:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IsolationLevelContext<'input> = BaseParserRuleContext<'input,IsolationLevelContextExt<'input>>;

pub trait IsolationLevelContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ISOLATION
	/// Returns `None` if there is no child corresponding to token ISOLATION
	fn ISOLATION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ISOLATION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEVEL
	/// Returns `None` if there is no child corresponding to token LEVEL
	fn LEVEL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LEVEL, 0)
	}
	fn levelOfIsolation(&self) -> Option<Rc<LevelOfIsolationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IsolationLevelContextAttrs<'input> for IsolationLevelContext<'input>{}

pub struct IsolationLevelContextExt<'input>{
	base:TransactionModeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IsolationLevelContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for IsolationLevelContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IsolationLevelContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_isolationLevel(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_isolationLevel(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IsolationLevelContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_isolationLevel(self);
	}
}

impl<'input> CustomRuleContext<'input> for IsolationLevelContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transactionMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transactionMode }
}

impl<'input> Borrow<TransactionModeContextExt<'input>> for IsolationLevelContext<'input>{
	fn borrow(&self) -> &TransactionModeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TransactionModeContextExt<'input>> for IsolationLevelContext<'input>{
	fn borrow_mut(&mut self) -> &mut TransactionModeContextExt<'input> { &mut self.base }
}

impl<'input> TransactionModeContextAttrs<'input> for IsolationLevelContext<'input> {}

impl<'input> IsolationLevelContextExt<'input>{
	fn new(ctx: &dyn TransactionModeContextAttrs<'input>) -> Rc<TransactionModeContextAll<'input>>  {
		Rc::new(
			TransactionModeContextAll::IsolationLevelContext(
				BaseParserRuleContext::copy_from(ctx,IsolationLevelContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transactionMode(&mut self,)
	-> Result<Rc<TransactionModeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransactionModeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 298, RULE_transactionMode);
        let mut _localctx: Rc<TransactionModeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3447);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ISOLATION 
				=> {
					let tmp = IsolationLevelContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3442);
					recog.base.match_token(ISOLATION,&mut recog.err_handler)?;

					recog.base.set_state(3443);
					recog.base.match_token(LEVEL,&mut recog.err_handler)?;

					/*InvokeRule levelOfIsolation*/
					recog.base.set_state(3444);
					recog.levelOfIsolation()?;

					}
				}

			 READ 
				=> {
					let tmp = TransactionAccessModeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3445);
					recog.base.match_token(READ,&mut recog.err_handler)?;

					recog.base.set_state(3446);
					if let TransactionModeContextAll::TransactionAccessModeContext(ctx) = cast_mut::<_,TransactionModeContextAll >(&mut _localctx){
					ctx.accessMode = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==ONLY || _la==WRITE) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let TransactionModeContextAll::TransactionAccessModeContext(ctx) = cast_mut::<_,TransactionModeContextAll >(&mut _localctx){
						ctx.accessMode = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- levelOfIsolation ----------------
#[derive(Debug)]
pub enum LevelOfIsolationContextAll<'input>{
	ReadUncommittedContext(ReadUncommittedContext<'input>),
	SerializableContext(SerializableContext<'input>),
	ReadCommittedContext(ReadCommittedContext<'input>),
	RepeatableReadContext(RepeatableReadContext<'input>),
Error(LevelOfIsolationContext<'input>)
}
antlr_rust::tid!{LevelOfIsolationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for LevelOfIsolationContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for LevelOfIsolationContextAll<'input>{}

impl<'input> Deref for LevelOfIsolationContextAll<'input>{
	type Target = dyn LevelOfIsolationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use LevelOfIsolationContextAll::*;
		match self{
			ReadUncommittedContext(inner) => inner,
			SerializableContext(inner) => inner,
			ReadCommittedContext(inner) => inner,
			RepeatableReadContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LevelOfIsolationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LevelOfIsolationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type LevelOfIsolationContext<'input> = BaseParserRuleContext<'input,LevelOfIsolationContextExt<'input>>;

#[derive(Clone)]
pub struct LevelOfIsolationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for LevelOfIsolationContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for LevelOfIsolationContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for LevelOfIsolationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for LevelOfIsolationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}
antlr_rust::tid!{LevelOfIsolationContextExt<'a>}

impl<'input> LevelOfIsolationContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LevelOfIsolationContextAll<'input>> {
		Rc::new(
		LevelOfIsolationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LevelOfIsolationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait LevelOfIsolationContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<LevelOfIsolationContextExt<'input>>{


}

impl<'input> LevelOfIsolationContextAttrs<'input> for LevelOfIsolationContext<'input>{}

pub type ReadUncommittedContext<'input> = BaseParserRuleContext<'input,ReadUncommittedContextExt<'input>>;

pub trait ReadUncommittedContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token READ
	/// Returns `None` if there is no child corresponding to token READ
	fn READ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(READ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UNCOMMITTED
	/// Returns `None` if there is no child corresponding to token UNCOMMITTED
	fn UNCOMMITTED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(UNCOMMITTED, 0)
	}
}

impl<'input> ReadUncommittedContextAttrs<'input> for ReadUncommittedContext<'input>{}

pub struct ReadUncommittedContextExt<'input>{
	base:LevelOfIsolationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ReadUncommittedContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ReadUncommittedContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ReadUncommittedContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_readUncommitted(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_readUncommitted(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ReadUncommittedContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_readUncommitted(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReadUncommittedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}

impl<'input> Borrow<LevelOfIsolationContextExt<'input>> for ReadUncommittedContext<'input>{
	fn borrow(&self) -> &LevelOfIsolationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LevelOfIsolationContextExt<'input>> for ReadUncommittedContext<'input>{
	fn borrow_mut(&mut self) -> &mut LevelOfIsolationContextExt<'input> { &mut self.base }
}

impl<'input> LevelOfIsolationContextAttrs<'input> for ReadUncommittedContext<'input> {}

impl<'input> ReadUncommittedContextExt<'input>{
	fn new(ctx: &dyn LevelOfIsolationContextAttrs<'input>) -> Rc<LevelOfIsolationContextAll<'input>>  {
		Rc::new(
			LevelOfIsolationContextAll::ReadUncommittedContext(
				BaseParserRuleContext::copy_from(ctx,ReadUncommittedContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SerializableContext<'input> = BaseParserRuleContext<'input,SerializableContextExt<'input>>;

pub trait SerializableContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SERIALIZABLE
	/// Returns `None` if there is no child corresponding to token SERIALIZABLE
	fn SERIALIZABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(SERIALIZABLE, 0)
	}
}

impl<'input> SerializableContextAttrs<'input> for SerializableContext<'input>{}

pub struct SerializableContextExt<'input>{
	base:LevelOfIsolationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SerializableContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for SerializableContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for SerializableContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_serializable(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_serializable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for SerializableContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_serializable(self);
	}
}

impl<'input> CustomRuleContext<'input> for SerializableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}

impl<'input> Borrow<LevelOfIsolationContextExt<'input>> for SerializableContext<'input>{
	fn borrow(&self) -> &LevelOfIsolationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LevelOfIsolationContextExt<'input>> for SerializableContext<'input>{
	fn borrow_mut(&mut self) -> &mut LevelOfIsolationContextExt<'input> { &mut self.base }
}

impl<'input> LevelOfIsolationContextAttrs<'input> for SerializableContext<'input> {}

impl<'input> SerializableContextExt<'input>{
	fn new(ctx: &dyn LevelOfIsolationContextAttrs<'input>) -> Rc<LevelOfIsolationContextAll<'input>>  {
		Rc::new(
			LevelOfIsolationContextAll::SerializableContext(
				BaseParserRuleContext::copy_from(ctx,SerializableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ReadCommittedContext<'input> = BaseParserRuleContext<'input,ReadCommittedContextExt<'input>>;

pub trait ReadCommittedContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token READ
	/// Returns `None` if there is no child corresponding to token READ
	fn READ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(READ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMITTED
	/// Returns `None` if there is no child corresponding to token COMMITTED
	fn COMMITTED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(COMMITTED, 0)
	}
}

impl<'input> ReadCommittedContextAttrs<'input> for ReadCommittedContext<'input>{}

pub struct ReadCommittedContextExt<'input>{
	base:LevelOfIsolationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ReadCommittedContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for ReadCommittedContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for ReadCommittedContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_readCommitted(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_readCommitted(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for ReadCommittedContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_readCommitted(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReadCommittedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}

impl<'input> Borrow<LevelOfIsolationContextExt<'input>> for ReadCommittedContext<'input>{
	fn borrow(&self) -> &LevelOfIsolationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LevelOfIsolationContextExt<'input>> for ReadCommittedContext<'input>{
	fn borrow_mut(&mut self) -> &mut LevelOfIsolationContextExt<'input> { &mut self.base }
}

impl<'input> LevelOfIsolationContextAttrs<'input> for ReadCommittedContext<'input> {}

impl<'input> ReadCommittedContextExt<'input>{
	fn new(ctx: &dyn LevelOfIsolationContextAttrs<'input>) -> Rc<LevelOfIsolationContextAll<'input>>  {
		Rc::new(
			LevelOfIsolationContextAll::ReadCommittedContext(
				BaseParserRuleContext::copy_from(ctx,ReadCommittedContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RepeatableReadContext<'input> = BaseParserRuleContext<'input,RepeatableReadContextExt<'input>>;

pub trait RepeatableReadContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REPEATABLE
	/// Returns `None` if there is no child corresponding to token REPEATABLE
	fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(REPEATABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token READ
	/// Returns `None` if there is no child corresponding to token READ
	fn READ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(READ, 0)
	}
}

impl<'input> RepeatableReadContextAttrs<'input> for RepeatableReadContext<'input>{}

pub struct RepeatableReadContextExt<'input>{
	base:LevelOfIsolationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RepeatableReadContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RepeatableReadContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RepeatableReadContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_repeatableRead(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_repeatableRead(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RepeatableReadContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_repeatableRead(self);
	}
}

impl<'input> CustomRuleContext<'input> for RepeatableReadContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}

impl<'input> Borrow<LevelOfIsolationContextExt<'input>> for RepeatableReadContext<'input>{
	fn borrow(&self) -> &LevelOfIsolationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LevelOfIsolationContextExt<'input>> for RepeatableReadContext<'input>{
	fn borrow_mut(&mut self) -> &mut LevelOfIsolationContextExt<'input> { &mut self.base }
}

impl<'input> LevelOfIsolationContextAttrs<'input> for RepeatableReadContext<'input> {}

impl<'input> RepeatableReadContextExt<'input>{
	fn new(ctx: &dyn LevelOfIsolationContextAttrs<'input>) -> Rc<LevelOfIsolationContextAll<'input>>  {
		Rc::new(
			LevelOfIsolationContextAll::RepeatableReadContext(
				BaseParserRuleContext::copy_from(ctx,RepeatableReadContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn levelOfIsolation(&mut self,)
	-> Result<Rc<LevelOfIsolationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LevelOfIsolationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 300, RULE_levelOfIsolation);
        let mut _localctx: Rc<LevelOfIsolationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3456);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(473,&mut recog.base)? {
				1 =>{
					let tmp = ReadUncommittedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3449);
					recog.base.match_token(READ,&mut recog.err_handler)?;

					recog.base.set_state(3450);
					recog.base.match_token(UNCOMMITTED,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = ReadCommittedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3451);
					recog.base.match_token(READ,&mut recog.err_handler)?;

					recog.base.set_state(3452);
					recog.base.match_token(COMMITTED,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = RepeatableReadContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3453);
					recog.base.match_token(REPEATABLE,&mut recog.err_handler)?;

					recog.base.set_state(3454);
					recog.base.match_token(READ,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = SerializableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3455);
					recog.base.match_token(SERIALIZABLE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privilege ----------------
pub type PrivilegeContextAll<'input> = PrivilegeContext<'input>;


pub type PrivilegeContext<'input> = BaseParserRuleContext<'input,PrivilegeContextExt<'input>>;

#[derive(Clone)]
pub struct PrivilegeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PrivilegeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PrivilegeContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privilege(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_privilege(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PrivilegeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_privilege(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrivilegeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privilege }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privilege }
}
antlr_rust::tid!{PrivilegeContextExt<'a>}

impl<'input> PrivilegeContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivilegeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivilegeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivilegeContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PrivilegeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}

}

impl<'input> PrivilegeContextAttrs<'input> for PrivilegeContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privilege(&mut self,)
	-> Result<Rc<PrivilegeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivilegeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 302, RULE_privilege);
        let mut _localctx: Rc<PrivilegeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3458);
			_la = recog.base.input.la(1);
			if { !(_la==CREATE || _la==DELETE || _la==INSERT || _la==SELECT || _la==UPDATE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- qualifiedName ----------------
#[derive(Debug)]
pub enum QualifiedNameContextAll<'input>{
	QualifiedNameDefaultContext(QualifiedNameDefaultContext<'input>),
Error(QualifiedNameContext<'input>)
}
antlr_rust::tid!{QualifiedNameContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QualifiedNameContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for QualifiedNameContextAll<'input>{}

impl<'input> Deref for QualifiedNameContextAll<'input>{
	type Target = dyn QualifiedNameContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QualifiedNameContextAll::*;
		match self{
			QualifiedNameDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QualifiedNameContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QualifiedNameContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QualifiedNameContext<'input> = BaseParserRuleContext<'input,QualifiedNameContextExt<'input>>;

#[derive(Clone)]
pub struct QualifiedNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QualifiedNameContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QualifiedNameContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QualifiedNameContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QualifiedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedName }
}
antlr_rust::tid!{QualifiedNameContextExt<'a>}

impl<'input> QualifiedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QualifiedNameContextAll<'input>> {
		Rc::new(
		QualifiedNameContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QualifiedNameContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QualifiedNameContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QualifiedNameContextExt<'input>>{


}

impl<'input> QualifiedNameContextAttrs<'input> for QualifiedNameContext<'input>{}

pub type QualifiedNameDefaultContext<'input> = BaseParserRuleContext<'input,QualifiedNameDefaultContextExt<'input>>;

pub trait QualifiedNameDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
	fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,RedshiftParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
	/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
	fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOT, i)
	}
	fn pathComponent_all(&self) ->  Vec<Rc<PathComponentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn pathComponent(&self, i: usize) -> Option<Rc<PathComponentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> QualifiedNameDefaultContextAttrs<'input> for QualifiedNameDefaultContext<'input>{}

pub struct QualifiedNameDefaultContextExt<'input>{
	base:QualifiedNameContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QualifiedNameDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for QualifiedNameDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QualifiedNameDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_qualifiedNameDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_qualifiedNameDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QualifiedNameDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_qualifiedNameDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QualifiedNameDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedName }
}

impl<'input> Borrow<QualifiedNameContextExt<'input>> for QualifiedNameDefaultContext<'input>{
	fn borrow(&self) -> &QualifiedNameContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QualifiedNameContextExt<'input>> for QualifiedNameDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QualifiedNameContextExt<'input> { &mut self.base }
}

impl<'input> QualifiedNameContextAttrs<'input> for QualifiedNameDefaultContext<'input> {}

impl<'input> QualifiedNameDefaultContextExt<'input>{
	fn new(ctx: &dyn QualifiedNameContextAttrs<'input>) -> Rc<QualifiedNameContextAll<'input>>  {
		Rc::new(
			QualifiedNameContextAll::QualifiedNameDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QualifiedNameDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn qualifiedName(&mut self,)
	-> Result<Rc<QualifiedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QualifiedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 304, RULE_qualifiedName);
        let mut _localctx: Rc<QualifiedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = QualifiedNameDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3460);
			recog.identifier()?;

			recog.base.set_state(3465);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(474,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3461);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule pathComponent*/
					recog.base.set_state(3462);
					recog.pathComponent()?;

					}
					} 
				}
				recog.base.set_state(3467);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(474,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pathExpression ----------------
pub type PathExpressionContextAll<'input> = PathExpressionContext<'input>;


pub type PathExpressionContext<'input> = BaseParserRuleContext<'input,PathExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PathExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PathExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PathExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pathExpression(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_pathExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PathExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pathExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for PathExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pathExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pathExpression }
}
antlr_rust::tid!{PathExpressionContextExt<'a>}

impl<'input> PathExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PathExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PathExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PathExpressionContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PathExpressionContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PathExpressionContextAttrs<'input> for PathExpressionContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pathExpression(&mut self,)
	-> Result<Rc<PathExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PathExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 306, RULE_pathExpression);
        let mut _localctx: Rc<PathExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(3468);
			recog.qualifiedName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryPeriod ----------------
pub type QueryPeriodContextAll<'input> = QueryPeriodContext<'input>;


pub type QueryPeriodContext<'input> = BaseParserRuleContext<'input,QueryPeriodContextExt<'input>>;

#[derive(Clone)]
pub struct QueryPeriodContextExt<'input>{
	pub end: Option<Rc<ValueExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QueryPeriodContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QueryPeriodContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryPeriod(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_queryPeriod(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QueryPeriodContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_queryPeriod(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryPeriodContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPeriod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPeriod }
}
antlr_rust::tid!{QueryPeriodContextExt<'a>}

impl<'input> QueryPeriodContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryPeriodContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryPeriodContextExt{
				end: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryPeriodContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QueryPeriodContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
fn rangeType(&self) -> Option<Rc<RangeTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryPeriodContextAttrs<'input> for QueryPeriodContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryPeriod(&mut self,)
	-> Result<Rc<QueryPeriodContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryPeriodContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 308, RULE_queryPeriod);
        let mut _localctx: Rc<QueryPeriodContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3470);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule rangeType*/
			recog.base.set_state(3471);
			recog.rangeType()?;

			recog.base.set_state(3472);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(3473);
			recog.base.match_token(OF,&mut recog.err_handler)?;

			/*InvokeRule valueExpression*/
			recog.base.set_state(3474);
			let tmp = recog.valueExpression_rec(0)?;
			 cast_mut::<_,QueryPeriodContext >(&mut _localctx).end = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rangeType ----------------
pub type RangeTypeContextAll<'input> = RangeTypeContext<'input>;


pub type RangeTypeContext<'input> = BaseParserRuleContext<'input,RangeTypeContextExt<'input>>;

#[derive(Clone)]
pub struct RangeTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for RangeTypeContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RangeTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rangeType(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_rangeType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RangeTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rangeType(self);
	}
}

impl<'input> CustomRuleContext<'input> for RangeTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rangeType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rangeType }
}
antlr_rust::tid!{RangeTypeContextExt<'a>}

impl<'input> RangeTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RangeTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RangeTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RangeTypeContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<RangeTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}

}

impl<'input> RangeTypeContextAttrs<'input> for RangeTypeContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rangeType(&mut self,)
	-> Result<Rc<RangeTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RangeTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 310, RULE_rangeType);
        let mut _localctx: Rc<RangeTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3476);
			_la = recog.base.input.la(1);
			if { !(_la==TIMESTAMP || _la==VERSION) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- principal ----------------
#[derive(Debug)]
pub enum PrincipalContextAll<'input>{
	UnspecifiedPrincipalContext(UnspecifiedPrincipalContext<'input>),
	UserPrincipalContext(UserPrincipalContext<'input>),
	RolePrincipalContext(RolePrincipalContext<'input>),
Error(PrincipalContext<'input>)
}
antlr_rust::tid!{PrincipalContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PrincipalContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for PrincipalContextAll<'input>{}

impl<'input> Deref for PrincipalContextAll<'input>{
	type Target = dyn PrincipalContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PrincipalContextAll::*;
		match self{
			UnspecifiedPrincipalContext(inner) => inner,
			UserPrincipalContext(inner) => inner,
			RolePrincipalContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PrincipalContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PrincipalContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PrincipalContext<'input> = BaseParserRuleContext<'input,PrincipalContextExt<'input>>;

#[derive(Clone)]
pub struct PrincipalContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PrincipalContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PrincipalContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}
antlr_rust::tid!{PrincipalContextExt<'a>}

impl<'input> PrincipalContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrincipalContextAll<'input>> {
		Rc::new(
		PrincipalContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrincipalContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PrincipalContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PrincipalContextExt<'input>>{


}

impl<'input> PrincipalContextAttrs<'input> for PrincipalContext<'input>{}

pub type UnspecifiedPrincipalContext<'input> = BaseParserRuleContext<'input,UnspecifiedPrincipalContextExt<'input>>;

pub trait UnspecifiedPrincipalContextAttrs<'input>: RedshiftParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnspecifiedPrincipalContextAttrs<'input> for UnspecifiedPrincipalContext<'input>{}

pub struct UnspecifiedPrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnspecifiedPrincipalContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UnspecifiedPrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UnspecifiedPrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unspecifiedPrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_unspecifiedPrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UnspecifiedPrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_unspecifiedPrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnspecifiedPrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for UnspecifiedPrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for UnspecifiedPrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for UnspecifiedPrincipalContext<'input> {}

impl<'input> UnspecifiedPrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::UnspecifiedPrincipalContext(
				BaseParserRuleContext::copy_from(ctx,UnspecifiedPrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UserPrincipalContext<'input> = BaseParserRuleContext<'input,UserPrincipalContextExt<'input>>;

pub trait UserPrincipalContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token USER
	/// Returns `None` if there is no child corresponding to token USER
	fn USER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(USER, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UserPrincipalContextAttrs<'input> for UserPrincipalContext<'input>{}

pub struct UserPrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UserPrincipalContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UserPrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UserPrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_userPrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_userPrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UserPrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_userPrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for UserPrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for UserPrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for UserPrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for UserPrincipalContext<'input> {}

impl<'input> UserPrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::UserPrincipalContext(
				BaseParserRuleContext::copy_from(ctx,UserPrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RolePrincipalContext<'input> = BaseParserRuleContext<'input,RolePrincipalContextExt<'input>>;

pub trait RolePrincipalContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLE
	/// Returns `None` if there is no child corresponding to token ROLE
	fn ROLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(ROLE, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RolePrincipalContextAttrs<'input> for RolePrincipalContext<'input>{}

pub struct RolePrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RolePrincipalContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for RolePrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for RolePrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rolePrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_rolePrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for RolePrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_rolePrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for RolePrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for RolePrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for RolePrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for RolePrincipalContext<'input> {}

impl<'input> RolePrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::RolePrincipalContext(
				BaseParserRuleContext::copy_from(ctx,RolePrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn principal(&mut self,)
	-> Result<Rc<PrincipalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrincipalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 312, RULE_principal);
        let mut _localctx: Rc<PrincipalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3483);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(475,&mut recog.base)? {
				1 =>{
					let tmp = UnspecifiedPrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3478);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					let tmp = UserPrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3479);
					recog.base.match_token(USER,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3480);
					recog.identifier()?;

					}
				}
			,
				3 =>{
					let tmp = RolePrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3481);
					recog.base.match_token(ROLE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3482);
					recog.identifier()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifier ----------------
#[derive(Debug)]
pub enum IdentifierContextAll<'input>{
	QuotedIdentifierDefaultContext(QuotedIdentifierDefaultContext<'input>),
	DigitIdentifierContext(DigitIdentifierContext<'input>),
	UnquotedIdentifierContext(UnquotedIdentifierContext<'input>),
Error(IdentifierContext<'input>)
}
antlr_rust::tid!{IdentifierContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for IdentifierContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for IdentifierContextAll<'input>{}

impl<'input> Deref for IdentifierContextAll<'input>{
	type Target = dyn IdentifierContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use IdentifierContextAll::*;
		match self{
			QuotedIdentifierDefaultContext(inner) => inner,
			DigitIdentifierContext(inner) => inner,
			UnquotedIdentifierContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IdentifierContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IdentifierContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type IdentifierContext<'input> = BaseParserRuleContext<'input,IdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for IdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IdentifierContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IdentifierContext<'input>{
}

impl<'input> CustomRuleContext<'input> for IdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}
antlr_rust::tid!{IdentifierContextExt<'a>}

impl<'input> IdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierContextAll<'input>> {
		Rc::new(
		IdentifierContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait IdentifierContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<IdentifierContextExt<'input>>{


}

impl<'input> IdentifierContextAttrs<'input> for IdentifierContext<'input>{}

pub type QuotedIdentifierDefaultContext<'input> = BaseParserRuleContext<'input,QuotedIdentifierDefaultContextExt<'input>>;

pub trait QuotedIdentifierDefaultContextAttrs<'input>: RedshiftParserContext<'input>{
	fn quotedIdentifier(&self) -> Option<Rc<QuotedIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
}

impl<'input> QuotedIdentifierDefaultContextAttrs<'input> for QuotedIdentifierDefaultContext<'input>{}

pub struct QuotedIdentifierDefaultContextExt<'input>{
	base:IdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuotedIdentifierDefaultContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for QuotedIdentifierDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QuotedIdentifierDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quotedIdentifierDefault(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_quotedIdentifierDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QuotedIdentifierDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_quotedIdentifierDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuotedIdentifierDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}

impl<'input> Borrow<IdentifierContextExt<'input>> for QuotedIdentifierDefaultContext<'input>{
	fn borrow(&self) -> &IdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IdentifierContextExt<'input>> for QuotedIdentifierDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut IdentifierContextExt<'input> { &mut self.base }
}

impl<'input> IdentifierContextAttrs<'input> for QuotedIdentifierDefaultContext<'input> {}

impl<'input> QuotedIdentifierDefaultContextExt<'input>{
	fn new(ctx: &dyn IdentifierContextAttrs<'input>) -> Rc<IdentifierContextAll<'input>>  {
		Rc::new(
			IdentifierContextAll::QuotedIdentifierDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QuotedIdentifierDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DigitIdentifierContext<'input> = BaseParserRuleContext<'input,DigitIdentifierContextExt<'input>>;

pub trait DigitIdentifierContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DIGIT_IDENTIFIER
	/// Returns `None` if there is no child corresponding to token DIGIT_IDENTIFIER
	fn DIGIT_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DIGIT_IDENTIFIER, 0)
	}
}

impl<'input> DigitIdentifierContextAttrs<'input> for DigitIdentifierContext<'input>{}

pub struct DigitIdentifierContextExt<'input>{
	base:IdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DigitIdentifierContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DigitIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DigitIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_digitIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_digitIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DigitIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_digitIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for DigitIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}

impl<'input> Borrow<IdentifierContextExt<'input>> for DigitIdentifierContext<'input>{
	fn borrow(&self) -> &IdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IdentifierContextExt<'input>> for DigitIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut IdentifierContextExt<'input> { &mut self.base }
}

impl<'input> IdentifierContextAttrs<'input> for DigitIdentifierContext<'input> {}

impl<'input> DigitIdentifierContextExt<'input>{
	fn new(ctx: &dyn IdentifierContextAttrs<'input>) -> Rc<IdentifierContextAll<'input>>  {
		Rc::new(
			IdentifierContextAll::DigitIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,DigitIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnquotedIdentifierContext<'input> = BaseParserRuleContext<'input,UnquotedIdentifierContextExt<'input>>;

pub trait UnquotedIdentifierContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IDENTIFIER
	/// Returns `None` if there is no child corresponding to token IDENTIFIER
	fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(IDENTIFIER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	fn nonReserved(&self) -> Option<Rc<NonReservedContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnquotedIdentifierContextAttrs<'input> for UnquotedIdentifierContext<'input>{}

pub struct UnquotedIdentifierContextExt<'input>{
	base:IdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnquotedIdentifierContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for UnquotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for UnquotedIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unquotedIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_unquotedIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for UnquotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_unquotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnquotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}

impl<'input> Borrow<IdentifierContextExt<'input>> for UnquotedIdentifierContext<'input>{
	fn borrow(&self) -> &IdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IdentifierContextExt<'input>> for UnquotedIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut IdentifierContextExt<'input> { &mut self.base }
}

impl<'input> IdentifierContextAttrs<'input> for UnquotedIdentifierContext<'input> {}

impl<'input> UnquotedIdentifierContextExt<'input>{
	fn new(ctx: &dyn IdentifierContextAttrs<'input>) -> Rc<IdentifierContextAll<'input>>  {
		Rc::new(
			IdentifierContextAll::UnquotedIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,UnquotedIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifier(&mut self,)
	-> Result<Rc<IdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 314, RULE_identifier);
        let mut _localctx: Rc<IdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3500);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(476,&mut recog.base)? {
				1 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3485);
					recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3486);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(3487);
					recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;

					recog.base.set_state(3488);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = QuotedIdentifierDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule quotedIdentifier*/
					recog.base.set_state(3489);
					recog.quotedIdentifier()?;

					}
				}
			,
				4 =>{
					let tmp = QuotedIdentifierDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3490);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					/*InvokeRule quotedIdentifier*/
					recog.base.set_state(3491);
					recog.quotedIdentifier()?;

					recog.base.set_state(3492);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					/*InvokeRule nonReserved*/
					recog.base.set_state(3494);
					recog.nonReserved()?;

					}
				}
			,
				6 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(3495);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					/*InvokeRule nonReserved*/
					recog.base.set_state(3496);
					recog.nonReserved()?;

					recog.base.set_state(3497);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = DigitIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(3499);
					recog.base.match_token(DIGIT_IDENTIFIER,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- quotedIdentifier ----------------
pub type QuotedIdentifierContextAll<'input> = QuotedIdentifierContext<'input>;


pub type QuotedIdentifierContext<'input> = BaseParserRuleContext<'input,QuotedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct QuotedIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for QuotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for QuotedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_quotedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_quotedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for QuotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_quotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_quotedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_quotedIdentifier }
}
antlr_rust::tid!{QuotedIdentifierContextExt<'a>}

impl<'input> QuotedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuotedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuotedIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QuotedIdentifierContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<QuotedIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token QUOTED_IDENTIFIER
/// Returns `None` if there is no child corresponding to token QUOTED_IDENTIFIER
fn QUOTED_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(QUOTED_IDENTIFIER, 0)
}

}

impl<'input> QuotedIdentifierContextAttrs<'input> for QuotedIdentifierContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn quotedIdentifier(&mut self,)
	-> Result<Rc<QuotedIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuotedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 316, RULE_quotedIdentifier);
        let mut _localctx: Rc<QuotedIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3502);
			recog.base.match_token(QUOTED_IDENTIFIER,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pathComponent ----------------
pub type PathComponentContextAll<'input> = PathComponentContext<'input>;


pub type PathComponentContext<'input> = BaseParserRuleContext<'input,PathComponentContextExt<'input>>;

#[derive(Clone)]
pub struct PathComponentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for PathComponentContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for PathComponentContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pathComponent(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_pathComponent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for PathComponentContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_pathComponent(self);
	}
}

impl<'input> CustomRuleContext<'input> for PathComponentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pathComponent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pathComponent }
}
antlr_rust::tid!{PathComponentContextExt<'a>}

impl<'input> PathComponentContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PathComponentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PathComponentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PathComponentContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<PathComponentContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PathComponentContextAttrs<'input> for PathComponentContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pathComponent(&mut self,)
	-> Result<Rc<PathComponentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PathComponentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 318, RULE_pathComponent);
        let mut _localctx: Rc<PathComponentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3504);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneIdentifier ----------------
pub type StandaloneIdentifierContextAll<'input> = StandaloneIdentifierContext<'input>;


pub type StandaloneIdentifierContext<'input> = BaseParserRuleContext<'input,StandaloneIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for StandaloneIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StandaloneIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_standaloneIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StandaloneIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_standaloneIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneIdentifier }
}
antlr_rust::tid!{StandaloneIdentifierContextExt<'a>}

impl<'input> StandaloneIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneIdentifierContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<StandaloneIdentifierContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneIdentifierContextAttrs<'input> for StandaloneIdentifierContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneIdentifier(&mut self,)
	-> Result<Rc<StandaloneIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 320, RULE_standaloneIdentifier);
        let mut _localctx: Rc<StandaloneIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3506);
			recog.identifier()?;

			recog.base.set_state(3507);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- number ----------------
#[derive(Debug)]
pub enum NumberContextAll<'input>{
	DecimalLiteralContext(DecimalLiteralContext<'input>),
	DoubleLiteralContext(DoubleLiteralContext<'input>),
	IntegerLiteralContext(IntegerLiteralContext<'input>),
Error(NumberContext<'input>)
}
antlr_rust::tid!{NumberContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for NumberContextAll<'input>{}

impl<'input> RedshiftParserContext<'input> for NumberContextAll<'input>{}

impl<'input> Deref for NumberContextAll<'input>{
	type Target = dyn NumberContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use NumberContextAll::*;
		match self{
			DecimalLiteralContext(inner) => inner,
			DoubleLiteralContext(inner) => inner,
			IntegerLiteralContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NumberContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NumberContextAll<'input>{
    fn enter(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn RedshiftListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type NumberContext<'input> = BaseParserRuleContext<'input,NumberContextExt<'input>>;

#[derive(Clone)]
pub struct NumberContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for NumberContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NumberContext<'input>{
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NumberContext<'input>{
}

impl<'input> CustomRuleContext<'input> for NumberContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}
antlr_rust::tid!{NumberContextExt<'a>}

impl<'input> NumberContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NumberContextAll<'input>> {
		Rc::new(
		NumberContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NumberContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait NumberContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<NumberContextExt<'input>>{


}

impl<'input> NumberContextAttrs<'input> for NumberContext<'input>{}

pub type DecimalLiteralContext<'input> = BaseParserRuleContext<'input,DecimalLiteralContextExt<'input>>;

pub trait DecimalLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
	fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> DecimalLiteralContextAttrs<'input> for DecimalLiteralContext<'input>{}

pub struct DecimalLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DecimalLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DecimalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DecimalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_decimalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_decimalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DecimalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_decimalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DecimalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for DecimalLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for DecimalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for DecimalLiteralContext<'input> {}

impl<'input> DecimalLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::DecimalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DecimalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DoubleLiteralContext<'input> = BaseParserRuleContext<'input,DoubleLiteralContextExt<'input>>;

pub trait DoubleLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOUBLE_VALUE
	/// Returns `None` if there is no child corresponding to token DOUBLE_VALUE
	fn DOUBLE_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(DOUBLE_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> DoubleLiteralContextAttrs<'input> for DoubleLiteralContext<'input>{}

pub struct DoubleLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DoubleLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for DoubleLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for DoubleLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_doubleLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_doubleLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for DoubleLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_doubleLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DoubleLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for DoubleLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for DoubleLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for DoubleLiteralContext<'input> {}

impl<'input> DoubleLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::DoubleLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DoubleLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntegerLiteralContext<'input> = BaseParserRuleContext<'input,IntegerLiteralContextExt<'input>>;

pub trait IntegerLiteralContextAttrs<'input>: RedshiftParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> IntegerLiteralContextAttrs<'input> for IntegerLiteralContext<'input>{}

pub struct IntegerLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntegerLiteralContextExt<'a>}

impl<'input> RedshiftParserContext<'input> for IntegerLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for IntegerLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_integerLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
		listener.exit_integerLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for IntegerLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_integerLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntegerLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for IntegerLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for IntegerLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for IntegerLiteralContext<'input> {}

impl<'input> IntegerLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::IntegerLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IntegerLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn number(&mut self,)
	-> Result<Rc<NumberContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NumberContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 322, RULE_number);
        let mut _localctx: Rc<NumberContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3521);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(480,&mut recog.base)? {
				1 =>{
					let tmp = DecimalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3510);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3509);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3512);
					recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = DoubleLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3514);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3513);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3516);
					recog.base.match_token(DOUBLE_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = IntegerLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3518);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3517);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3520);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- strictNonReserved ----------------
pub type StrictNonReservedContextAll<'input> = StrictNonReservedContext<'input>;


pub type StrictNonReservedContext<'input> = BaseParserRuleContext<'input,StrictNonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct StrictNonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for StrictNonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for StrictNonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_strictNonReserved(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_strictNonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for StrictNonReservedContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_strictNonReserved(self);
	}
}

impl<'input> CustomRuleContext<'input> for StrictNonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictNonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictNonReserved }
}
antlr_rust::tid!{StrictNonReservedContextExt<'a>}

impl<'input> StrictNonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StrictNonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StrictNonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StrictNonReservedContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<StrictNonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CONVERT
/// Returns `None` if there is no child corresponding to token CONVERT
fn CONVERT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONVERT, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSS
/// Returns `None` if there is no child corresponding to token CROSS
fn CROSS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CROSS, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}
/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS_KW
/// Returns `None` if there is no child corresponding to token MINUS_KW
fn MINUS_KW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MINUS_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token NATURAL
/// Returns `None` if there is no child corresponding to token NATURAL
fn NATURAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NATURAL, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}

}

impl<'input> StrictNonReservedContextAttrs<'input> for StrictNonReservedContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn strictNonReserved(&mut self,)
	-> Result<Rc<StrictNonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StrictNonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 324, RULE_strictNonReserved);
        let mut _localctx: Rc<StrictNonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3523);
			_la = recog.base.input.la(1);
			if { !(_la==CONVERT || _la==CROSS || _la==FULL || _la==INNER || _la==LEFT || _la==MINUS_KW || ((((_la - 218)) & !0x3f) == 0 && ((1usize << (_la - 218)) & ((1usize << (NATURAL - 218)) | (1usize << (NOT - 218)) | (1usize << (OUTER - 218)))) != 0) || _la==RIGHT || _la==USING || _la==WHERE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonReserved ----------------
pub type NonReservedContextAll<'input> = NonReservedContext<'input>;


pub type NonReservedContext<'input> = BaseParserRuleContext<'input,NonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct NonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> RedshiftParserContext<'input> for NonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn RedshiftListener<'input> + 'a> for NonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonReserved(self);
		}
		fn exit(&self,listener: &mut (dyn RedshiftListener<'input> + 'a)) {
			listener.exit_nonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn RedshiftVisitor<'input> + 'a> for NonReservedContext<'input>{
	fn accept(&self,visitor: &mut (dyn RedshiftVisitor<'input> + 'a)) {
		visitor.visit_nonReserved(self);
	}
}

impl<'input> CustomRuleContext<'input> for NonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = RedshiftParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonReserved }
}
antlr_rust::tid!{NonReservedContextExt<'a>}

impl<'input> NonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn RedshiftParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NonReservedContextAttrs<'input>: RedshiftParserContext<'input> + BorrowMut<NonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ABORT
/// Returns `None` if there is no child corresponding to token ABORT
fn ABORT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ABORT, 0)
}
/// Retrieves first TerminalNode corresponding to token ABSENT
/// Returns `None` if there is no child corresponding to token ABSENT
fn ABSENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ABSENT, 0)
}
/// Retrieves first TerminalNode corresponding to token ADD
/// Returns `None` if there is no child corresponding to token ADD
fn ADD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token ADMIN
/// Returns `None` if there is no child corresponding to token ADMIN
fn ADMIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ADMIN, 0)
}
/// Retrieves first TerminalNode corresponding to token AFTER
/// Returns `None` if there is no child corresponding to token AFTER
fn AFTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AFTER, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token ALTER
/// Returns `None` if there is no child corresponding to token ALTER
fn ALTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token ANALYZE
/// Returns `None` if there is no child corresponding to token ANALYZE
fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ANALYZE, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
/// Retrieves first TerminalNode corresponding to token ANTI
/// Returns `None` if there is no child corresponding to token ANTI
fn ANTI(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ANTI, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token APPROXIMATE
/// Returns `None` if there is no child corresponding to token APPROXIMATE
fn APPROXIMATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(APPROXIMATE, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAY
/// Returns `None` if there is no child corresponding to token ARRAY
fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token AT
/// Returns `None` if there is no child corresponding to token AT
fn AT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AT, 0)
}
/// Retrieves first TerminalNode corresponding to token ATTACH
/// Returns `None` if there is no child corresponding to token ATTACH
fn ATTACH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ATTACH, 0)
}
/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
/// Returns `None` if there is no child corresponding to token AUTHORIZATION
fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AUTHORIZATION, 0)
}
/// Retrieves first TerminalNode corresponding to token AUTO
/// Returns `None` if there is no child corresponding to token AUTO
fn AUTO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(AUTO, 0)
}
/// Retrieves first TerminalNode corresponding to token BACKUP
/// Returns `None` if there is no child corresponding to token BACKUP
fn BACKUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BACKUP, 0)
}
/// Retrieves first TerminalNode corresponding to token BEGIN
/// Returns `None` if there is no child corresponding to token BEGIN
fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BEGIN, 0)
}
/// Retrieves first TerminalNode corresponding to token BERNOULLI
/// Returns `None` if there is no child corresponding to token BERNOULLI
fn BERNOULLI(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BERNOULLI, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY
/// Returns `None` if there is no child corresponding to token BINARY
fn BINARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token BINDING
/// Returns `None` if there is no child corresponding to token BINDING
fn BINDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BINDING, 0)
}
/// Retrieves first TerminalNode corresponding to token BOTH
/// Returns `None` if there is no child corresponding to token BOTH
fn BOTH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BOTH, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token BZIP2
/// Returns `None` if there is no child corresponding to token BZIP2
fn BZIP2(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(BZIP2, 0)
}
/// Retrieves first TerminalNode corresponding to token CALL
/// Returns `None` if there is no child corresponding to token CALL
fn CALL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CALL, 0)
}
/// Retrieves first TerminalNode corresponding to token CANCEL
/// Returns `None` if there is no child corresponding to token CANCEL
fn CANCEL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CANCEL, 0)
}
/// Retrieves first TerminalNode corresponding to token CASCADE
/// Returns `None` if there is no child corresponding to token CASCADE
fn CASCADE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CASCADE, 0)
}
/// Retrieves first TerminalNode corresponding to token CASE
/// Returns `None` if there is no child corresponding to token CASE
fn CASE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CASE, 0)
}
/// Retrieves first TerminalNode corresponding to token CASE_INSENSITIVE
/// Returns `None` if there is no child corresponding to token CASE_INSENSITIVE
fn CASE_INSENSITIVE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CASE_INSENSITIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token CASE_SENSITIVE
/// Returns `None` if there is no child corresponding to token CASE_SENSITIVE
fn CASE_SENSITIVE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CASE_SENSITIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token CAST
/// Returns `None` if there is no child corresponding to token CAST
fn CAST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token CATALOGS
/// Returns `None` if there is no child corresponding to token CATALOGS
fn CATALOGS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CATALOGS, 0)
}
/// Retrieves first TerminalNode corresponding to token CHARACTER
/// Returns `None` if there is no child corresponding to token CHARACTER
fn CHARACTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CHARACTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CLONE
/// Returns `None` if there is no child corresponding to token CLONE
fn CLONE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CLONE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSE
/// Returns `None` if there is no child corresponding to token CLOSE
fn CLOSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CLOSE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLATE
/// Returns `None` if there is no child corresponding to token COLLATE
fn COLLATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COLLATE, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMN
/// Returns `None` if there is no child corresponding to token COLUMN
fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMNS
/// Returns `None` if there is no child corresponding to token COLUMNS
fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMIT
/// Returns `None` if there is no child corresponding to token COMMIT
fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMITTED
/// Returns `None` if there is no child corresponding to token COMMITTED
fn COMMITTED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMMITTED, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPOUND
/// Returns `None` if there is no child corresponding to token COMPOUND
fn COMPOUND(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMPOUND, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPRESSION
/// Returns `None` if there is no child corresponding to token COMPRESSION
fn COMPRESSION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COMPRESSION, 0)
}
/// Retrieves first TerminalNode corresponding to token CONDITIONAL
/// Returns `None` if there is no child corresponding to token CONDITIONAL
fn CONDITIONAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONDITIONAL, 0)
}
/// Retrieves first TerminalNode corresponding to token CONNECT
/// Returns `None` if there is no child corresponding to token CONNECT
fn CONNECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONNECT, 0)
}
/// Retrieves first TerminalNode corresponding to token CONNECTION
/// Returns `None` if there is no child corresponding to token CONNECTION
fn CONNECTION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONNECTION, 0)
}
/// Retrieves first TerminalNode corresponding to token CONSTRAINT
/// Returns `None` if there is no child corresponding to token CONSTRAINT
fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, 0)
}
/// Retrieves first TerminalNode corresponding to token COPARTITION
/// Returns `None` if there is no child corresponding to token COPARTITION
fn COPARTITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COPARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token COPY
/// Returns `None` if there is no child corresponding to token COPY
fn COPY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COPY, 0)
}
/// Retrieves first TerminalNode corresponding to token COUNT
/// Returns `None` if there is no child corresponding to token COUNT
fn COUNT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(COUNT, 0)
}
/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CUBE
/// Returns `None` if there is no child corresponding to token CUBE
fn CUBE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CUBE, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT
/// Returns `None` if there is no child corresponding to token CURRENT
fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_ROLE
/// Returns `None` if there is no child corresponding to token CURRENT_ROLE
fn CURRENT_ROLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATA
/// Returns `None` if there is no child corresponding to token DATA
fn DATA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATASHARE
/// Returns `None` if there is no child corresponding to token DATASHARE
fn DATASHARE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DATASHARE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYS
/// Returns `None` if there is no child corresponding to token DAYS
fn DAYS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token DEALLOCATE
/// Returns `None` if there is no child corresponding to token DEALLOCATE
fn DEALLOCATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DEALLOCATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULTS
/// Returns `None` if there is no child corresponding to token DEFAULTS
fn DEFAULTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DEFAULTS, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINE
/// Returns `None` if there is no child corresponding to token DEFINE
fn DEFINE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DEFINE, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINER
/// Returns `None` if there is no child corresponding to token DEFINER
fn DEFINER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DEFINER, 0)
}
/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITED
/// Returns `None` if there is no child corresponding to token DELIMITED
fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DELIMITED, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITER
/// Returns `None` if there is no child corresponding to token DELIMITER
fn DELIMITER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DELIMITER, 0)
}
/// Retrieves first TerminalNode corresponding to token DENY
/// Returns `None` if there is no child corresponding to token DENY
fn DENY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DENY, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESCRIBE
/// Returns `None` if there is no child corresponding to token DESCRIBE
fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DESCRIBE, 0)
}
/// Retrieves first TerminalNode corresponding to token DESCRIPTOR
/// Returns `None` if there is no child corresponding to token DESCRIPTOR
fn DESCRIPTOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DESCRIPTOR, 0)
}
/// Retrieves first TerminalNode corresponding to token DETACH
/// Returns `None` if there is no child corresponding to token DETACH
fn DETACH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DETACH, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTKEY
/// Returns `None` if there is no child corresponding to token DISTKEY
fn DISTKEY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DISTKEY, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTRIBUTED
/// Returns `None` if there is no child corresponding to token DISTRIBUTED
fn DISTRIBUTED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DISTRIBUTED, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTSTYLE
/// Returns `None` if there is no child corresponding to token DISTSTYLE
fn DISTSTYLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DISTSTYLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DROP
/// Returns `None` if there is no child corresponding to token DROP
fn DROP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token ELSE
/// Returns `None` if there is no child corresponding to token ELSE
fn ELSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ELSE, 0)
}
/// Retrieves first TerminalNode corresponding to token EMPTY
/// Returns `None` if there is no child corresponding to token EMPTY
fn EMPTY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EMPTY, 0)
}
/// Retrieves first TerminalNode corresponding to token ENCODE
/// Returns `None` if there is no child corresponding to token ENCODE
fn ENCODE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ENCODE, 0)
}
/// Retrieves first TerminalNode corresponding to token ENCODING
/// Returns `None` if there is no child corresponding to token ENCODING
fn ENCODING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ENCODING, 0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
/// Retrieves first TerminalNode corresponding to token ERROR
/// Returns `None` if there is no child corresponding to token ERROR
fn ERROR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ERROR, 0)
}
/// Retrieves first TerminalNode corresponding to token ESCAPE
/// Returns `None` if there is no child corresponding to token ESCAPE
fn ESCAPE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ESCAPE, 0)
}
/// Retrieves first TerminalNode corresponding to token EVEN
/// Returns `None` if there is no child corresponding to token EVEN
fn EVEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EVEN, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDING
/// Returns `None` if there is no child corresponding to token EXCLUDING
fn EXCLUDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDING, 0)
}
/// Retrieves first TerminalNode corresponding to token EXECUTE
/// Returns `None` if there is no child corresponding to token EXECUTE
fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXECUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXISTS
/// Returns `None` if there is no child corresponding to token EXISTS
fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXISTS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPLAIN
/// Returns `None` if there is no child corresponding to token EXPLAIN
fn EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXPLAIN, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTERNAL
/// Returns `None` if there is no child corresponding to token EXTERNAL
fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXTERNAL, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTRACT
/// Returns `None` if there is no child corresponding to token EXTRACT
fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(EXTRACT, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}
/// Retrieves first TerminalNode corresponding to token FETCH
/// Returns `None` if there is no child corresponding to token FETCH
fn FETCH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FETCH, 0)
}
/// Retrieves first TerminalNode corresponding to token FIELDS
/// Returns `None` if there is no child corresponding to token FIELDS
fn FIELDS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FIELDS, 0)
}
/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token FINAL
/// Returns `None` if there is no child corresponding to token FINAL
fn FINAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FINAL, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST_VALUE
/// Returns `None` if there is no child corresponding to token FIRST_VALUE
fn FIRST_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FIRST_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token FOLLOWING
/// Returns `None` if there is no child corresponding to token FOLLOWING
fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FOLLOWING, 0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token FOREIGN
/// Returns `None` if there is no child corresponding to token FOREIGN
fn FOREIGN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FOREIGN, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMAT
/// Returns `None` if there is no child corresponding to token FORMAT
fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTION
/// Returns `None` if there is no child corresponding to token FUNCTION
fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FUNCTION, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTIONS
/// Returns `None` if there is no child corresponding to token FUNCTIONS
fn FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(FUNCTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token GENERATED
/// Returns `None` if there is no child corresponding to token GENERATED
fn GENERATED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GENERATED, 0)
}
/// Retrieves first TerminalNode corresponding to token GRACE
/// Returns `None` if there is no child corresponding to token GRACE
fn GRACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GRACE, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANT
/// Returns `None` if there is no child corresponding to token GRANT
fn GRANT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GRANT, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANTED
/// Returns `None` if there is no child corresponding to token GRANTED
fn GRANTED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GRANTED, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANTS
/// Returns `None` if there is no child corresponding to token GRANTS
fn GRANTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GRANTS, 0)
}
/// Retrieves first TerminalNode corresponding to token GRAPHVIZ
/// Returns `None` if there is no child corresponding to token GRAPHVIZ
fn GRAPHVIZ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GRAPHVIZ, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUP
/// Returns `None` if there is no child corresponding to token GROUP
fn GROUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPS
/// Returns `None` if there is no child corresponding to token GROUPS
fn GROUPS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GROUPS, 0)
}
/// Retrieves first TerminalNode corresponding to token GZIP
/// Returns `None` if there is no child corresponding to token GZIP
fn GZIP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(GZIP, 0)
}
/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
/// Retrieves first TerminalNode corresponding to token HEADER
/// Returns `None` if there is no child corresponding to token HEADER
fn HEADER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(HEADER, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token HOURS
/// Returns `None` if there is no child corresponding to token HOURS
fn HOURS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(HOURS, 0)
}
/// Retrieves first TerminalNode corresponding to token IAM_ROLE
/// Returns `None` if there is no child corresponding to token IAM_ROLE
fn IAM_ROLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IAM_ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
/// Retrieves first TerminalNode corresponding to token IGNORE
/// Returns `None` if there is no child corresponding to token IGNORE
fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token ILIKE
/// Returns `None` if there is no child corresponding to token ILIKE
fn ILIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ILIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMMUTABLE
/// Returns `None` if there is no child corresponding to token IMMUTABLE
fn IMMUTABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IMMUTABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDING
/// Returns `None` if there is no child corresponding to token INCLUDING
fn INCLUDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INCLUDING, 0)
}
/// Retrieves first TerminalNode corresponding to token INITIAL
/// Returns `None` if there is no child corresponding to token INITIAL
fn INITIAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INITIAL, 0)
}
/// Retrieves first TerminalNode corresponding to token INOUT
/// Returns `None` if there is no child corresponding to token INOUT
fn INOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INOUT, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUT
/// Returns `None` if there is no child corresponding to token INPUT
fn INPUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUTFORMAT
/// Returns `None` if there is no child corresponding to token INPUTFORMAT
fn INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERLEAVED
/// Returns `None` if there is no child corresponding to token INTERLEAVED
fn INTERLEAVED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTERLEAVED, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token INTO
/// Returns `None` if there is no child corresponding to token INTO
fn INTO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token INVOKER
/// Returns `None` if there is no child corresponding to token INVOKER
fn INVOKER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(INVOKER, 0)
}
/// Retrieves first TerminalNode corresponding to token IO
/// Returns `None` if there is no child corresponding to token IO
fn IO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IO, 0)
}
/// Retrieves first TerminalNode corresponding to token IS
/// Returns `None` if there is no child corresponding to token IS
fn IS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(IS, 0)
}
/// Retrieves first TerminalNode corresponding to token ISNULL
/// Returns `None` if there is no child corresponding to token ISNULL
fn ISNULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ISNULL, 0)
}
/// Retrieves first TerminalNode corresponding to token ISOLATION
/// Returns `None` if there is no child corresponding to token ISOLATION
fn ISOLATION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ISOLATION, 0)
}
/// Retrieves first TerminalNode corresponding to token JOIN
/// Returns `None` if there is no child corresponding to token JOIN
fn JOIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(JOIN, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON
/// Returns `None` if there is no child corresponding to token JSON
fn JSON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(JSON, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON_ARRAY
/// Returns `None` if there is no child corresponding to token JSON_ARRAY
fn JSON_ARRAY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(JSON_ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON_EXISTS
/// Returns `None` if there is no child corresponding to token JSON_EXISTS
fn JSON_EXISTS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(JSON_EXISTS, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON_OBJECT
/// Returns `None` if there is no child corresponding to token JSON_OBJECT
fn JSON_OBJECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(JSON_OBJECT, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON_QUERY
/// Returns `None` if there is no child corresponding to token JSON_QUERY
fn JSON_QUERY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(JSON_QUERY, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON_VALUE
/// Returns `None` if there is no child corresponding to token JSON_VALUE
fn JSON_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(JSON_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token KB
/// Returns `None` if there is no child corresponding to token KB
fn KB(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KB, 0)
}
/// Retrieves first TerminalNode corresponding to token KEEP
/// Returns `None` if there is no child corresponding to token KEEP
fn KEEP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KEEP, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEYS
/// Returns `None` if there is no child corresponding to token KEYS
fn KEYS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(KEYS, 0)
}
/// Retrieves first TerminalNode corresponding to token LAG
/// Returns `None` if there is no child corresponding to token LAG
fn LAG(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LAG, 0)
}
/// Retrieves first TerminalNode corresponding to token LAMBDA
/// Returns `None` if there is no child corresponding to token LAMBDA
fn LAMBDA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LAMBDA, 0)
}
/// Retrieves first TerminalNode corresponding to token LANGUAGE
/// Returns `None` if there is no child corresponding to token LANGUAGE
fn LANGUAGE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LANGUAGE, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST_VALUE
/// Returns `None` if there is no child corresponding to token LAST_VALUE
fn LAST_VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LAST_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token LATERAL
/// Returns `None` if there is no child corresponding to token LATERAL
fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LATERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LEADING
/// Returns `None` if there is no child corresponding to token LEADING
fn LEADING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LEADING, 0)
}
/// Retrieves first TerminalNode corresponding to token LEVEL
/// Returns `None` if there is no child corresponding to token LEVEL
fn LEVEL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LEVEL, 0)
}
/// Retrieves first TerminalNode corresponding to token LIBRARY
/// Returns `None` if there is no child corresponding to token LIBRARY
fn LIBRARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LIBRARY, 0)
}
/// Retrieves first TerminalNode corresponding to token LIKE
/// Returns `None` if there is no child corresponding to token LIKE
fn LIKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token LINES
/// Returns `None` if there is no child corresponding to token LINES
fn LINES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LINES, 0)
}
/// Retrieves first TerminalNode corresponding to token LISTAGG
/// Returns `None` if there is no child corresponding to token LISTAGG
fn LISTAGG(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LISTAGG, 0)
}
/// Retrieves first TerminalNode corresponding to token LISTAGGDISTINCT
/// Returns `None` if there is no child corresponding to token LISTAGGDISTINCT
fn LISTAGGDISTINCT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LISTAGGDISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCAL
/// Returns `None` if there is no child corresponding to token LOCAL
fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LOCAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCK
/// Returns `None` if there is no child corresponding to token LOCK
fn LOCK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token LOGICAL
/// Returns `None` if there is no child corresponding to token LOGICAL
fn LOGICAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(LOGICAL, 0)
}
/// Retrieves first TerminalNode corresponding to token M
/// Returns `None` if there is no child corresponding to token M
fn M(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(M, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token MASKING
/// Returns `None` if there is no child corresponding to token MASKING
fn MASKING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MASKING, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCH
/// Returns `None` if there is no child corresponding to token MATCH
fn MATCH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MATCH, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHES
/// Returns `None` if there is no child corresponding to token MATCHES
fn MATCHES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MATCHES, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCH_RECOGNIZE
/// Returns `None` if there is no child corresponding to token MATCH_RECOGNIZE
fn MATCH_RECOGNIZE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MATCH_RECOGNIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token MATERIALIZED
/// Returns `None` if there is no child corresponding to token MATERIALIZED
fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token MAX
/// Returns `None` if there is no child corresponding to token MAX
fn MAX(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MAX, 0)
}
/// Retrieves first TerminalNode corresponding to token MAX_BATCH_ROWS
/// Returns `None` if there is no child corresponding to token MAX_BATCH_ROWS
fn MAX_BATCH_ROWS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MAX_BATCH_ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token MAX_BATCH_SIZE
/// Returns `None` if there is no child corresponding to token MAX_BATCH_SIZE
fn MAX_BATCH_SIZE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MAX_BATCH_SIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token MB
/// Returns `None` if there is no child corresponding to token MB
fn MB(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MB, 0)
}
/// Retrieves first TerminalNode corresponding to token MEASURES
/// Returns `None` if there is no child corresponding to token MEASURES
fn MEASURES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MEASURES, 0)
}
/// Retrieves first TerminalNode corresponding to token MERGE
/// Returns `None` if there is no child corresponding to token MERGE
fn MERGE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MERGE, 0)
}
/// Retrieves first TerminalNode corresponding to token MIN
/// Returns `None` if there is no child corresponding to token MIN
fn MIN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MIN, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTES
/// Returns `None` if there is no child corresponding to token MINUTES
fn MINUTES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MINUTES, 0)
}
/// Retrieves first TerminalNode corresponding to token MODEL
/// Returns `None` if there is no child corresponding to token MODEL
fn MODEL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MODEL, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTHS
/// Returns `None` if there is no child corresponding to token MONTHS
fn MONTHS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(MONTHS, 0)
}
/// Retrieves first TerminalNode corresponding to token NEXT
/// Returns `None` if there is no child corresponding to token NEXT
fn NEXT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NEXT, 0)
}
/// Retrieves first TerminalNode corresponding to token NFC
/// Returns `None` if there is no child corresponding to token NFC
fn NFC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NFC, 0)
}
/// Retrieves first TerminalNode corresponding to token NFD
/// Returns `None` if there is no child corresponding to token NFD
fn NFD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NFD, 0)
}
/// Retrieves first TerminalNode corresponding to token NFKC
/// Returns `None` if there is no child corresponding to token NFKC
fn NFKC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NFKC, 0)
}
/// Retrieves first TerminalNode corresponding to token NFKD
/// Returns `None` if there is no child corresponding to token NFKD
fn NFKD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NFKD, 0)
}
/// Retrieves first TerminalNode corresponding to token NO
/// Returns `None` if there is no child corresponding to token NO
fn NO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NO, 0)
}
/// Retrieves first TerminalNode corresponding to token NONE
/// Returns `None` if there is no child corresponding to token NONE
fn NONE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NONE, 0)
}
/// Retrieves first TerminalNode corresponding to token NORMALIZE
/// Returns `None` if there is no child corresponding to token NORMALIZE
fn NORMALIZE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NORMALIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token NOTNULL
/// Returns `None` if there is no child corresponding to token NOTNULL
fn NOTNULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NOTNULL, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token OBJECT
/// Returns `None` if there is no child corresponding to token OBJECT
fn OBJECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OBJECT, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
/// Retrieves first TerminalNode corresponding to token OMIT
/// Returns `None` if there is no child corresponding to token OMIT
fn OMIT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
/// Retrieves first TerminalNode corresponding to token ONE
/// Returns `None` if there is no child corresponding to token ONE
fn ONE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ONE, 0)
}
/// Retrieves first TerminalNode corresponding to token ONLY
/// Returns `None` if there is no child corresponding to token ONLY
fn ONLY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ONLY, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTION
/// Returns `None` if there is no child corresponding to token OPTION
fn OPTION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONS
/// Returns `None` if there is no child corresponding to token OPTIONS
fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token OR
/// Returns `None` if there is no child corresponding to token OR
fn OR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OR, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDINALITY
/// Returns `None` if there is no child corresponding to token ORDINALITY
fn ORDINALITY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ORDINALITY, 0)
}
/// Retrieves first TerminalNode corresponding to token OUT
/// Returns `None` if there is no child corresponding to token OUT
fn OUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OUT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTPUT
/// Returns `None` if there is no child corresponding to token OUTPUT
fn OUTPUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OUTPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token OUTPUTFORMAT
fn OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OUTPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token OVER
/// Returns `None` if there is no child corresponding to token OVER
fn OVER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERFLOW
/// Returns `None` if there is no child corresponding to token OVERFLOW
fn OVERFLOW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(OVERFLOW, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONED
/// Returns `None` if there is no child corresponding to token PARTITIONED
fn PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONS
/// Returns `None` if there is no child corresponding to token PARTITIONS
fn PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token PASSING
/// Returns `None` if there is no child corresponding to token PASSING
fn PASSING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PASSING, 0)
}
/// Retrieves first TerminalNode corresponding to token PAST
/// Returns `None` if there is no child corresponding to token PAST
fn PAST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PAST, 0)
}
/// Retrieves first TerminalNode corresponding to token PATH
/// Returns `None` if there is no child corresponding to token PATH
fn PATH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PATH, 0)
}
/// Retrieves first TerminalNode corresponding to token PATTERN
/// Returns `None` if there is no child corresponding to token PATTERN
fn PATTERN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PATTERN, 0)
}
/// Retrieves first TerminalNode corresponding to token PER
/// Returns `None` if there is no child corresponding to token PER
fn PER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PER, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENTILE_CONT
/// Returns `None` if there is no child corresponding to token PERCENTILE_CONT
fn PERCENTILE_CONT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PERCENTILE_CONT, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENTILE_DISC
/// Returns `None` if there is no child corresponding to token PERCENTILE_DISC
fn PERCENTILE_DISC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PERCENTILE_DISC, 0)
}
/// Retrieves first TerminalNode corresponding to token PERIOD
/// Returns `None` if there is no child corresponding to token PERIOD
fn PERIOD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PERIOD, 0)
}
/// Retrieves first TerminalNode corresponding to token PERMUTE
/// Returns `None` if there is no child corresponding to token PERMUTE
fn PERMUTE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PERMUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token PG_CATALOG
/// Returns `None` if there is no child corresponding to token PG_CATALOG
fn PG_CATALOG(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PG_CATALOG, 0)
}
/// Retrieves first TerminalNode corresponding to token PIVOT
/// Returns `None` if there is no child corresponding to token PIVOT
fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token POSITION
/// Returns `None` if there is no child corresponding to token POSITION
fn POSITION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(POSITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PRECEDING
/// Returns `None` if there is no child corresponding to token PRECEDING
fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRECEDING, 0)
}
/// Retrieves first TerminalNode corresponding to token PRECISION
/// Returns `None` if there is no child corresponding to token PRECISION
fn PRECISION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRECISION, 0)
}
/// Retrieves first TerminalNode corresponding to token PREPARE
/// Returns `None` if there is no child corresponding to token PREPARE
fn PREPARE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PREPARE, 0)
}
/// Retrieves first TerminalNode corresponding to token PRIMARY
/// Returns `None` if there is no child corresponding to token PRIMARY
fn PRIMARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRIMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token PRIOR
/// Returns `None` if there is no child corresponding to token PRIOR
fn PRIOR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRIOR, 0)
}
/// Retrieves first TerminalNode corresponding to token PRIVILEGES
/// Returns `None` if there is no child corresponding to token PRIVILEGES
fn PRIVILEGES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRIVILEGES, 0)
}
/// Retrieves first TerminalNode corresponding to token PROCEDURE
/// Returns `None` if there is no child corresponding to token PROCEDURE
fn PROCEDURE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PROCEDURE, 0)
}
/// Retrieves first TerminalNode corresponding to token PROPERTIES
/// Returns `None` if there is no child corresponding to token PROPERTIES
fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token PRUNE
/// Returns `None` if there is no child corresponding to token PRUNE
fn PRUNE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(PRUNE, 0)
}
/// Retrieves first TerminalNode corresponding to token QUALIFY
/// Returns `None` if there is no child corresponding to token QUALIFY
fn QUALIFY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(QUALIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token QUOTES
/// Returns `None` if there is no child corresponding to token QUOTES
fn QUOTES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(QUOTES, 0)
}
/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token READ
/// Returns `None` if there is no child corresponding to token READ
fn READ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(READ, 0)
}
/// Retrieves first TerminalNode corresponding to token RECURSIVE
/// Returns `None` if there is no child corresponding to token RECURSIVE
fn RECURSIVE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RECURSIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token REFERENCES
/// Returns `None` if there is no child corresponding to token REFERENCES
fn REFERENCES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(REFERENCES, 0)
}
/// Retrieves first TerminalNode corresponding to token REFRESH
/// Returns `None` if there is no child corresponding to token REFRESH
fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(REFRESH, 0)
}
/// Retrieves first TerminalNode corresponding to token RENAME
/// Returns `None` if there is no child corresponding to token RENAME
fn RENAME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token REPEATABLE
/// Returns `None` if there is no child corresponding to token REPEATABLE
fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(REPEATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token RESET
/// Returns `None` if there is no child corresponding to token RESET
fn RESET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RESET, 0)
}
/// Retrieves first TerminalNode corresponding to token RESPECT
/// Returns `None` if there is no child corresponding to token RESPECT
fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RESPECT, 0)
}
/// Retrieves first TerminalNode corresponding to token RESTRICT
/// Returns `None` if there is no child corresponding to token RESTRICT
fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token RETRY_TIMEOUT
/// Returns `None` if there is no child corresponding to token RETRY_TIMEOUT
fn RETRY_TIMEOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RETRY_TIMEOUT, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURNING
/// Returns `None` if there is no child corresponding to token RETURNING
fn RETURNING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RETURNING, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURNS
/// Returns `None` if there is no child corresponding to token RETURNS
fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RETURNS, 0)
}
/// Retrieves first TerminalNode corresponding to token REVOKE
/// Returns `None` if there is no child corresponding to token REVOKE
fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(REVOKE, 0)
}
/// Retrieves first TerminalNode corresponding to token RLS
/// Returns `None` if there is no child corresponding to token RLS
fn RLS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RLS, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLE
/// Returns `None` if there is no child corresponding to token ROLE
fn ROLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLES
/// Returns `None` if there is no child corresponding to token ROLES
fn ROLES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROLES, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLBACK
/// Returns `None` if there is no child corresponding to token ROLLBACK
fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROLLBACK, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLUP
/// Returns `None` if there is no child corresponding to token ROLLUP
fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token ROW
/// Returns `None` if there is no child corresponding to token ROW
fn ROW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token RUNNING
/// Returns `None` if there is no child corresponding to token RUNNING
fn RUNNING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(RUNNING, 0)
}
/// Retrieves first TerminalNode corresponding to token S
/// Returns `None` if there is no child corresponding to token S
fn S(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(S, 0)
}
/// Retrieves first TerminalNode corresponding to token SAGEMAKER
/// Returns `None` if there is no child corresponding to token SAGEMAKER
fn SAGEMAKER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SAGEMAKER, 0)
}
/// Retrieves first TerminalNode corresponding to token SCALAR
/// Returns `None` if there is no child corresponding to token SCALAR
fn SCALAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SCALAR, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMA
/// Returns `None` if there is no child corresponding to token SCHEMA
fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SCHEMA, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMAS
/// Returns `None` if there is no child corresponding to token SCHEMAS
fn SCHEMAS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SCHEMAS, 0)
}
/// Retrieves first TerminalNode corresponding to token SEC
/// Returns `None` if there is no child corresponding to token SEC
fn SEC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SEC, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token SECONDS
/// Returns `None` if there is no child corresponding to token SECONDS
fn SECONDS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECURITY
/// Returns `None` if there is no child corresponding to token SECURITY
fn SECURITY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SECURITY, 0)
}
/// Retrieves first TerminalNode corresponding to token SEEK
/// Returns `None` if there is no child corresponding to token SEEK
fn SEEK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves first TerminalNode corresponding to token SEMI
/// Returns `None` if there is no child corresponding to token SEMI
fn SEMI(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDE
/// Returns `None` if there is no child corresponding to token SERDE
fn SERDE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SERDE, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SERDEPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token SERIALIZABLE
/// Returns `None` if there is no child corresponding to token SERIALIZABLE
fn SERIALIZABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SERIALIZABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token SESSION
/// Returns `None` if there is no child corresponding to token SESSION
fn SESSION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SESSION, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token SETS
/// Returns `None` if there is no child corresponding to token SETS
fn SETS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SETS, 0)
}
/// Retrieves first TerminalNode corresponding to token SHOW
/// Returns `None` if there is no child corresponding to token SHOW
fn SHOW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token SIMILAR
/// Returns `None` if there is no child corresponding to token SIMILAR
fn SIMILAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SIMILAR, 0)
}
/// Retrieves first TerminalNode corresponding to token SOME
/// Returns `None` if there is no child corresponding to token SOME
fn SOME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token SORTKEY
/// Returns `None` if there is no child corresponding to token SORTKEY
fn SORTKEY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SORTKEY, 0)
}
/// Retrieves first TerminalNode corresponding to token SQL
/// Returns `None` if there is no child corresponding to token SQL
fn SQL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SQL, 0)
}
/// Retrieves first TerminalNode corresponding to token STABLE
/// Returns `None` if there is no child corresponding to token STABLE
fn STABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(STABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token START
/// Returns `None` if there is no child corresponding to token START
fn START(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(START, 0)
}
/// Retrieves first TerminalNode corresponding to token STATS
/// Returns `None` if there is no child corresponding to token STATS
fn STATS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(STATS, 0)
}
/// Retrieves first TerminalNode corresponding to token STRING_KW
/// Returns `None` if there is no child corresponding to token STRING_KW
fn STRING_KW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(STRING_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token STRUCT
/// Returns `None` if there is no child corresponding to token STRUCT
fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSET
/// Returns `None` if there is no child corresponding to token SUBSET
fn SUBSET(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SUBSET, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSTRING
/// Returns `None` if there is no child corresponding to token SUBSTRING
fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SUBSTRING, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLES
/// Returns `None` if there is no child corresponding to token TABLES
fn TABLES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TABLES, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMP
/// Returns `None` if there is no child corresponding to token TEMP
fn TEMP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TEMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMPORARY
/// Returns `None` if there is no child corresponding to token TEMPORARY
fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token TERMINATED
/// Returns `None` if there is no child corresponding to token TERMINATED
fn TERMINATED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token TEXT
/// Returns `None` if there is no child corresponding to token TEXT
fn TEXT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TEXT, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
/// Retrieves first TerminalNode corresponding to token TIES
/// Returns `None` if there is no child corresponding to token TIES
fn TIES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TIES, 0)
}
/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token TRAILING
/// Returns `None` if there is no child corresponding to token TRAILING
fn TRAILING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRAILING, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTION
/// Returns `None` if there is no child corresponding to token TRANSACTION
fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token TRIM
/// Returns `None` if there is no child corresponding to token TRIM
fn TRIM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRIM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUNCATE
/// Returns `None` if there is no child corresponding to token TRUNCATE
fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRUNCATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRY_CAST
/// Returns `None` if there is no child corresponding to token TRY_CAST
fn TRY_CAST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TRY_CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token TUPLE
/// Returns `None` if there is no child corresponding to token TUPLE
fn TUPLE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TUPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token UESCAPE
/// Returns `None` if there is no child corresponding to token UESCAPE
fn UESCAPE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UESCAPE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNBOUNDED
/// Returns `None` if there is no child corresponding to token UNBOUNDED
fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNBOUNDED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNCOMMITTED
/// Returns `None` if there is no child corresponding to token UNCOMMITTED
fn UNCOMMITTED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNCOMMITTED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNCONDITIONAL
/// Returns `None` if there is no child corresponding to token UNCONDITIONAL
fn UNCONDITIONAL(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNCONDITIONAL, 0)
}
/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token UNIQUE
/// Returns `None` if there is no child corresponding to token UNIQUE
fn UNIQUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNIQUE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNKNOWN
/// Returns `None` if there is no child corresponding to token UNKNOWN
fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNKNOWN, 0)
}
/// Retrieves first TerminalNode corresponding to token UNMATCHED
/// Returns `None` if there is no child corresponding to token UNMATCHED
fn UNMATCHED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNMATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNNEST
/// Returns `None` if there is no child corresponding to token UNNEST
fn UNNEST(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNNEST, 0)
}
/// Retrieves first TerminalNode corresponding to token UNPIVOT
/// Returns `None` if there is no child corresponding to token UNPIVOT
fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNPIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token UNSIGNED
/// Returns `None` if there is no child corresponding to token UNSIGNED
fn UNSIGNED(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UNSIGNED, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token USE
/// Returns `None` if there is no child corresponding to token USE
fn USE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(USE, 0)
}
/// Retrieves first TerminalNode corresponding to token USER
/// Returns `None` if there is no child corresponding to token USER
fn USER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(USER, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF16
/// Returns `None` if there is no child corresponding to token UTF16
fn UTF16(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UTF16, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF32
/// Returns `None` if there is no child corresponding to token UTF32
fn UTF32(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UTF32, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF8
/// Returns `None` if there is no child corresponding to token UTF8
fn UTF8(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(UTF8, 0)
}
/// Retrieves first TerminalNode corresponding to token VACUUM
/// Returns `None` if there is no child corresponding to token VACUUM
fn VACUUM(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VACUUM, 0)
}
/// Retrieves first TerminalNode corresponding to token VALIDATE
/// Returns `None` if there is no child corresponding to token VALIDATE
fn VALIDATE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VALIDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUE
/// Returns `None` if there is no child corresponding to token VALUE
fn VALUE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIADIC
/// Returns `None` if there is no child corresponding to token VARIADIC
fn VARIADIC(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VARIADIC, 0)
}
/// Retrieves first TerminalNode corresponding to token VARYING
/// Returns `None` if there is no child corresponding to token VARYING
fn VARYING(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VARYING, 0)
}
/// Retrieves first TerminalNode corresponding to token VERBOSE
/// Returns `None` if there is no child corresponding to token VERBOSE
fn VERBOSE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VERBOSE, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token VOLATILE
/// Returns `None` if there is no child corresponding to token VOLATILE
fn VOLATILE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(VOLATILE, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHOUT
/// Returns `None` if there is no child corresponding to token WITHOUT
fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WITHOUT, 0)
}
/// Retrieves first TerminalNode corresponding to token WORK
/// Returns `None` if there is no child corresponding to token WORK
fn WORK(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WORK, 0)
}
/// Retrieves first TerminalNode corresponding to token WRAPPER
/// Returns `None` if there is no child corresponding to token WRAPPER
fn WRAPPER(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WRAPPER, 0)
}
/// Retrieves first TerminalNode corresponding to token WRITE
/// Returns `None` if there is no child corresponding to token WRITE
fn WRITE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(WRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token XZ
/// Returns `None` if there is no child corresponding to token XZ
fn XZ(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(XZ, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token YEARS
/// Returns `None` if there is no child corresponding to token YEARS
fn YEARS(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(YEARS, 0)
}
/// Retrieves first TerminalNode corresponding to token YES
/// Returns `None` if there is no child corresponding to token YES
fn YES(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(YES, 0)
}
/// Retrieves first TerminalNode corresponding to token ZONE
/// Returns `None` if there is no child corresponding to token ZONE
fn ZONE(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ZONE, 0)
}
/// Retrieves first TerminalNode corresponding to token ZSTD
/// Returns `None` if there is no child corresponding to token ZSTD
fn ZSTD(&self) -> Option<Rc<TerminalNode<'input,RedshiftParserContextType>>> where Self:Sized{
	self.get_token(ZSTD, 0)
}

}

impl<'input> NonReservedContextAttrs<'input> for NonReservedContext<'input>{}

impl<'input, I, H> RedshiftParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonReserved(&mut self,)
	-> Result<Rc<NonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 326, RULE_nonReserved);
        let mut _localctx: Rc<NonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3525);
			_la = recog.base.input.la(1);
			if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << APPROXIMATE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BETWEEN - 32)) | (1usize << (BINARY - 32)) | (1usize << (BINDING - 32)) | (1usize << (BOTH - 32)) | (1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COPARTITION - 64)) | (1usize << (COPY - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)) | (1usize << (DISTRIBUTED - 64)) | (1usize << (DISTSTYLE - 64)) | (1usize << (DETACH - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FIRST_VALUE - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)) | (1usize << (FOREIGN - 96)) | (1usize << (FORMAT - 96)) | (1usize << (FROM - 96)) | (1usize << (FUNCTION - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IAM_ROLE - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMUTABLE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INOUT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)) | (1usize << (INTERSECT - 128)) | (1usize << (INTERVAL - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISNULL - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (JSON_ARRAY - 160)) | (1usize << (JSON_EXISTS - 160)) | (1usize << (JSON_OBJECT - 160)) | (1usize << (JSON_QUERY - 160)) | (1usize << (JSON_VALUE - 160)) | (1usize << (KB - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAG - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LAST_VALUE - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LISTAGGDISTINCT - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (M - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MAX_BATCH_ROWS - 192)) | (1usize << (MAX_BATCH_SIZE - 192)) | (1usize << (MB - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NORMALIZE - 224)) | (1usize << (NOTNULL - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (ORDINALITY - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PER - 256)) | (1usize << (PERCENTILE_CONT - 256)) | (1usize << (PERCENTILE_DISC - 256)) | (1usize << (PERIOD - 256)) | (1usize << (PERMUTE - 256)) | (1usize << (PG_CATALOG - 256)) | (1usize << (PIVOT - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETRY_TIMEOUT - 256)) | (1usize << (RETURNING - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLS - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (S - 288)) | (1usize << (SAGEMAKER - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SEC - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SOME - 320)) | (1usize << (SORTKEY - 320)) | (1usize << (SQL - 320)) | (1usize << (STABLE - 320)) | (1usize << (START - 320)) | (1usize << (STATS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSET - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TO - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TUPLE - 352)) | (1usize << (TYPE - 352)) | (1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VARIADIC - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VOLATILE - 352)) | (1usize << (WEEK - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WHEN - 384)) | (1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YEARS - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}

thread_local! {
    static _ATN: Rc<ATN> =
        Rc::new(ATNDeserializer::new(None).deserialize(_serializedATN.chars()));
    static _decision_to_DFA: Rc<Vec<RefCell<DFA>>> = {
        let mut dfa = Vec::new();
        let size = _ATN.with(|atn| atn.decision_to_state.len());
        for i in 0..size {
            dfa.push(DFA::new(_ATN.with(|atn| atn.clone()), _ATN.with(|atn| atn
            .get_decision_state(i)), i as isize).into())
        }
        Rc::new(dfa)
    };
}



const _serializedATN:&'static str =
	"\x03\u{608b}\u{a72a}\u{8133}\u{b9ed}\u{417c}\u{3be7}\u{7786}\u{5964}\x03\
	\u{1c3}\u{dca}\x04\x02\x09\x02\x04\x03\x09\x03\x04\x04\x09\x04\x04\x05\x09\
	\x05\x04\x06\x09\x06\x04\x07\x09\x07\x04\x08\x09\x08\x04\x09\x09\x09\x04\
	\x0a\x09\x0a\x04\x0b\x09\x0b\x04\x0c\x09\x0c\x04\x0d\x09\x0d\x04\x0e\x09\
	\x0e\x04\x0f\x09\x0f\x04\x10\x09\x10\x04\x11\x09\x11\x04\x12\x09\x12\x04\
	\x13\x09\x13\x04\x14\x09\x14\x04\x15\x09\x15\x04\x16\x09\x16\x04\x17\x09\
	\x17\x04\x18\x09\x18\x04\x19\x09\x19\x04\x1a\x09\x1a\x04\x1b\x09\x1b\x04\
	\x1c\x09\x1c\x04\x1d\x09\x1d\x04\x1e\x09\x1e\x04\x1f\x09\x1f\x04\x20\x09\
	\x20\x04\x21\x09\x21\x04\x22\x09\x22\x04\x23\x09\x23\x04\x24\x09\x24\x04\
	\x25\x09\x25\x04\x26\x09\x26\x04\x27\x09\x27\x04\x28\x09\x28\x04\x29\x09\
	\x29\x04\x2a\x09\x2a\x04\x2b\x09\x2b\x04\x2c\x09\x2c\x04\x2d\x09\x2d\x04\
	\x2e\x09\x2e\x04\x2f\x09\x2f\x04\x30\x09\x30\x04\x31\x09\x31\x04\x32\x09\
	\x32\x04\x33\x09\x33\x04\x34\x09\x34\x04\x35\x09\x35\x04\x36\x09\x36\x04\
	\x37\x09\x37\x04\x38\x09\x38\x04\x39\x09\x39\x04\x3a\x09\x3a\x04\x3b\x09\
	\x3b\x04\x3c\x09\x3c\x04\x3d\x09\x3d\x04\x3e\x09\x3e\x04\x3f\x09\x3f\x04\
	\x40\x09\x40\x04\x41\x09\x41\x04\x42\x09\x42\x04\x43\x09\x43\x04\x44\x09\
	\x44\x04\x45\x09\x45\x04\x46\x09\x46\x04\x47\x09\x47\x04\x48\x09\x48\x04\
	\x49\x09\x49\x04\x4a\x09\x4a\x04\x4b\x09\x4b\x04\x4c\x09\x4c\x04\x4d\x09\
	\x4d\x04\x4e\x09\x4e\x04\x4f\x09\x4f\x04\x50\x09\x50\x04\x51\x09\x51\x04\
	\x52\x09\x52\x04\x53\x09\x53\x04\x54\x09\x54\x04\x55\x09\x55\x04\x56\x09\
	\x56\x04\x57\x09\x57\x04\x58\x09\x58\x04\x59\x09\x59\x04\x5a\x09\x5a\x04\
	\x5b\x09\x5b\x04\x5c\x09\x5c\x04\x5d\x09\x5d\x04\x5e\x09\x5e\x04\x5f\x09\
	\x5f\x04\x60\x09\x60\x04\x61\x09\x61\x04\x62\x09\x62\x04\x63\x09\x63\x04\
	\x64\x09\x64\x04\x65\x09\x65\x04\x66\x09\x66\x04\x67\x09\x67\x04\x68\x09\
	\x68\x04\x69\x09\x69\x04\x6a\x09\x6a\x04\x6b\x09\x6b\x04\x6c\x09\x6c\x04\
	\x6d\x09\x6d\x04\x6e\x09\x6e\x04\x6f\x09\x6f\x04\x70\x09\x70\x04\x71\x09\
	\x71\x04\x72\x09\x72\x04\x73\x09\x73\x04\x74\x09\x74\x04\x75\x09\x75\x04\
	\x76\x09\x76\x04\x77\x09\x77\x04\x78\x09\x78\x04\x79\x09\x79\x04\x7a\x09\
	\x7a\x04\x7b\x09\x7b\x04\x7c\x09\x7c\x04\x7d\x09\x7d\x04\x7e\x09\x7e\x04\
	\x7f\x09\x7f\x04\u{80}\x09\u{80}\x04\u{81}\x09\u{81}\x04\u{82}\x09\u{82}\
	\x04\u{83}\x09\u{83}\x04\u{84}\x09\u{84}\x04\u{85}\x09\u{85}\x04\u{86}\x09\
	\u{86}\x04\u{87}\x09\u{87}\x04\u{88}\x09\u{88}\x04\u{89}\x09\u{89}\x04\u{8a}\
	\x09\u{8a}\x04\u{8b}\x09\u{8b}\x04\u{8c}\x09\u{8c}\x04\u{8d}\x09\u{8d}\x04\
	\u{8e}\x09\u{8e}\x04\u{8f}\x09\u{8f}\x04\u{90}\x09\u{90}\x04\u{91}\x09\u{91}\
	\x04\u{92}\x09\u{92}\x04\u{93}\x09\u{93}\x04\u{94}\x09\u{94}\x04\u{95}\x09\
	\u{95}\x04\u{96}\x09\u{96}\x04\u{97}\x09\u{97}\x04\u{98}\x09\u{98}\x04\u{99}\
	\x09\u{99}\x04\u{9a}\x09\u{9a}\x04\u{9b}\x09\u{9b}\x04\u{9c}\x09\u{9c}\x04\
	\u{9d}\x09\u{9d}\x04\u{9e}\x09\u{9e}\x04\u{9f}\x09\u{9f}\x04\u{a0}\x09\u{a0}\
	\x04\u{a1}\x09\u{a1}\x04\u{a2}\x09\u{a2}\x04\u{a3}\x09\u{a3}\x04\u{a4}\x09\
	\u{a4}\x04\u{a5}\x09\u{a5}\x03\x02\x05\x02\u{14c}\x0a\x02\x03\x02\x03\x02\
	\x05\x02\u{150}\x0a\x02\x07\x02\u{152}\x0a\x02\x0c\x02\x0e\x02\u{155}\x0b\
	\x02\x03\x02\x03\x02\x03\x03\x05\x03\u{15a}\x0a\x03\x03\x03\x05\x03\u{15d}\
	\x0a\x03\x03\x03\x03\x03\x03\x04\x03\x04\x03\x04\x03\x05\x03\x05\x03\x05\
	\x03\x06\x03\x06\x03\x06\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{176}\x0a\x07\
	\x03\x07\x03\x07\x07\x07\u{17a}\x0a\x07\x0c\x07\x0e\x07\u{17d}\x0b\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\
	\x07\u{19a}\x0a\x07\x03\x07\x03\x07\x05\x07\u{19e}\x0a\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x05\x07\u{1ad}\x0a\x07\x03\x07\x03\x07\x05\x07\u{1b1}\x0a\
	\x07\x03\x07\x05\x07\u{1b4}\x0a\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{1b9}\
	\x0a\x07\x03\x07\x03\x07\x05\x07\u{1bd}\x0a\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{1c6}\x0a\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x05\x07\u{1cc}\x0a\x07\x03\x07\x03\x07\x05\x07\u{1d0}\x0a\
	\x07\x03\x07\x05\x07\u{1d3}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\
	\x07\u{1d9}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{1df}\x0a\x07\
	\x03\x07\x03\x07\x05\x07\u{1e3}\x0a\x07\x03\x07\x03\x07\x05\x07\u{1e7}\x0a\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{1ef}\x0a\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{1f6}\x0a\x07\x03\
	\x07\x03\x07\x03\x07\x05\x07\u{1fb}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x05\x07\u{201}\x0a\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{206}\x0a\x07\
	\x03\x07\x03\x07\x03\x07\x05\x07\u{20b}\x0a\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x05\x07\u{212}\x0a\x07\x03\x07\x03\x07\x05\x07\u{216}\x0a\
	\x07\x03\x07\x03\x07\x05\x07\u{21a}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x05\x07\u{222}\x0a\x07\x03\x07\x03\x07\x03\x07\x05\
	\x07\u{227}\x0a\x07\x03\x07\x03\x07\x05\x07\u{22b}\x0a\x07\x03\x07\x03\x07\
	\x05\x07\u{22f}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x05\x07\u{237}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{23d}\x0a\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\
	\x07\u{247}\x0a\x07\x03\x07\x05\x07\u{24a}\x0a\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x07\x07\u{252}\x0a\x07\x0c\x07\x0e\x07\u{255}\x0b\
	\x07\x03\x07\x05\x07\u{258}\x0a\x07\x05\x07\u{25a}\x0a\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x06\x07\u{260}\x0a\x07\x0d\x07\x0e\x07\u{261}\x03\x07\x03\
	\x07\x07\x07\u{266}\x0a\x07\x0c\x07\x0e\x07\u{269}\x0b\x07\x03\x07\x03\x07\
	\x05\x07\u{26d}\x0a\x07\x03\x07\x03\x07\x07\x07\u{271}\x0a\x07\x0c\x07\x0e\
	\x07\u{274}\x0b\x07\x03\x07\x03\x07\x07\x07\u{278}\x0a\x07\x0c\x07\x0e\x07\
	\u{27b}\x0b\x07\x03\x07\x03\x07\x07\x07\u{27f}\x0a\x07\x0c\x07\x0e\x07\u{282}\
	\x0b\x07\x03\x07\x03\x07\x07\x07\u{286}\x0a\x07\x0c\x07\x0e\x07\u{289}\x0b\
	\x07\x03\x07\x03\x07\x07\x07\u{28d}\x0a\x07\x0c\x07\x0e\x07\u{290}\x0b\x07\
	\x03\x07\x03\x07\x07\x07\u{294}\x0a\x07\x0c\x07\x0e\x07\u{297}\x0b\x07\x03\
	\x07\x03\x07\x07\x07\u{29b}\x0a\x07\x0c\x07\x0e\x07\u{29e}\x0b\x07\x03\x07\
	\x03\x07\x03\x07\x05\x07\u{2a3}\x0a\x07\x03\x07\x03\x07\x07\x07\u{2a7}\x0a\
	\x07\x0c\x07\x0e\x07\u{2aa}\x0b\x07\x03\x07\x03\x07\x07\x07\u{2ae}\x0a\x07\
	\x0c\x07\x0e\x07\u{2b1}\x0b\x07\x03\x07\x03\x07\x07\x07\u{2b5}\x0a\x07\x0c\
	\x07\x0e\x07\u{2b8}\x0b\x07\x03\x07\x03\x07\x07\x07\u{2bc}\x0a\x07\x0c\x07\
	\x0e\x07\u{2bf}\x0b\x07\x03\x07\x03\x07\x07\x07\u{2c3}\x0a\x07\x0c\x07\x0e\
	\x07\u{2c6}\x0b\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{2cc}\x0a\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x05\x07\u{2d7}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x05\x07\u{2df}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x05\x07\u{2e7}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\
	\u{2ee}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x05\x07\u{2f8}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x05\x07\u{2ff}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x05\x07\u{307}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\x07\
	\u{329}\x0a\x07\x0c\x07\x0e\x07\u{32c}\x0b\x07\x05\x07\u{32e}\x0a\x07\x03\
	\x07\x05\x07\u{331}\x0a\x07\x03\x07\x05\x07\u{334}\x0a\x07\x03\x07\x03\x07\
	\x05\x07\u{338}\x0a\x07\x03\x07\x03\x07\x07\x07\u{33c}\x0a\x07\x0c\x07\x0e\
	\x07\u{33f}\x0b\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x05\x07\u{34a}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{369}\
	\x0a\x07\x0c\x07\x0e\x07\u{36c}\x0b\x07\x03\x07\x03\x07\x03\x07\x07\x07\
	\u{371}\x0a\x07\x0c\x07\x0e\x07\u{374}\x0b\x07\x03\x07\x03\x07\x07\x07\u{378}\
	\x0a\x07\x0c\x07\x0e\x07\u{37b}\x0b\x07\x03\x07\x03\x07\x07\x07\u{37f}\x0a\
	\x07\x0c\x07\x0e\x07\u{382}\x0b\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\
	\x07\u{388}\x0a\x07\x0c\x07\x0e\x07\u{38b}\x0b\x07\x03\x07\x05\x07\u{38e}\
	\x0a\x07\x03\x07\x03\x07\x05\x07\u{392}\x0a\x07\x03\x07\x03\x07\x05\x07\
	\u{396}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\
	\u{39e}\x0a\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{3a3}\x0a\x07\x0c\x07\x0e\
	\x07\u{3a6}\x0b\x07\x03\x07\x03\x07\x07\x07\u{3aa}\x0a\x07\x0c\x07\x0e\x07\
	\u{3ad}\x0b\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{3b4}\x0a\
	\x07\x0c\x07\x0e\x07\u{3b7}\x0b\x07\x03\x07\x05\x07\u{3ba}\x0a\x07\x05\x07\
	\u{3bc}\x0a\x07\x03\x07\x03\x07\x07\x07\u{3c0}\x0a\x07\x0c\x07\x0e\x07\u{3c3}\
	\x0b\x07\x03\x07\x03\x07\x07\x07\u{3c7}\x0a\x07\x0c\x07\x0e\x07\u{3ca}\x0b\
	\x07\x03\x07\x03\x07\x07\x07\u{3ce}\x0a\x07\x0c\x07\x0e\x07\u{3d1}\x0b\x07\
	\x03\x07\x03\x07\x07\x07\u{3d5}\x0a\x07\x0c\x07\x0e\x07\u{3d8}\x0b\x07\x03\
	\x07\x03\x07\x07\x07\u{3dc}\x0a\x07\x0c\x07\x0e\x07\u{3df}\x0b\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{3e9}\
	\x0a\x07\x0c\x07\x0e\x07\u{3ec}\x0b\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x07\x07\u{3f2}\x0a\x07\x0c\x07\x0e\x07\u{3f5}\x0b\x07\x03\x07\x03\x07\x03\
	\x07\x07\x07\u{3fa}\x0a\x07\x0c\x07\x0e\x07\u{3fd}\x0b\x07\x03\x07\x03\x07\
	\x03\x07\x07\x07\u{402}\x0a\x07\x0c\x07\x0e\x07\u{405}\x0b\x07\x03\x07\x03\
	\x07\x03\x07\x05\x07\u{40a}\x0a\x07\x03\x07\x03\x07\x07\x07\u{40e}\x0a\x07\
	\x0c\x07\x0e\x07\u{411}\x0b\x07\x03\x07\x03\x07\x07\x07\u{415}\x0a\x07\x0c\
	\x07\x0e\x07\u{418}\x0b\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{41d}\x0a\x07\
	\x0c\x07\x0e\x07\u{420}\x0b\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{425}\x0a\
	\x07\x0c\x07\x0e\x07\u{428}\x0b\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{42d}\
	\x0a\x07\x0c\x07\x0e\x07\u{430}\x0b\x07\x03\x07\x03\x07\x03\x07\x05\x07\
	\u{435}\x0a\x07\x03\x07\x03\x07\x07\x07\u{439}\x0a\x07\x0c\x07\x0e\x07\u{43c}\
	\x0b\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{441}\x0a\x07\x0c\x07\x0e\x07\
	\u{444}\x0b\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{449}\x0a\x07\x0c\x07\x0e\
	\x07\u{44c}\x0b\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{451}\x0a\x07\x0c\x07\
	\x0e\x07\u{454}\x0b\x07\x03\x07\x03\x07\x07\x07\u{458}\x0a\x07\x0c\x07\x0e\
	\x07\u{45b}\x0b\x07\x03\x07\x03\x07\x07\x07\u{45f}\x0a\x07\x0c\x07\x0e\x07\
	\u{462}\x0b\x07\x03\x07\x03\x07\x07\x07\u{466}\x0a\x07\x0c\x07\x0e\x07\u{469}\
	\x0b\x07\x03\x07\x03\x07\x07\x07\u{46d}\x0a\x07\x0c\x07\x0e\x07\u{470}\x0b\
	\x07\x03\x07\x03\x07\x07\x07\u{474}\x0a\x07\x0c\x07\x0e\x07\u{477}\x0b\x07\
	\x03\x07\x03\x07\x07\x07\u{47b}\x0a\x07\x0c\x07\x0e\x07\u{47e}\x0b\x07\x03\
	\x07\x03\x07\x07\x07\u{482}\x0a\x07\x0c\x07\x0e\x07\u{485}\x0b\x07\x05\x07\
	\u{487}\x0a\x07\x03\x08\x03\x08\x03\x08\x07\x08\u{48c}\x0a\x08\x0c\x08\x0e\
	\x08\u{48f}\x0b\x08\x03\x09\x03\x09\x03\x09\x03\x0a\x03\x0a\x03\x0a\x03\
	\x0a\x03\x0a\x07\x0a\u{499}\x0a\x0a\x0c\x0a\x0e\x0a\u{49c}\x0b\x0a\x03\x0b\
	\x03\x0b\x03\x0b\x03\x0b\x03\x0b\x07\x0b\u{4a3}\x0a\x0b\x0c\x0b\x0e\x0b\
	\u{4a6}\x0b\x0b\x03\x0c\x03\x0c\x03\x0c\x03\x0d\x03\x0d\x03\x0d\x03\x0d\
	\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0f\x03\x0f\x03\x0f\x03\x0f\x03\x0f\
	\x03\x0f\x03\x0f\x03\x0f\x05\x0f\u{4bb}\x0a\x0f\x03\x10\x03\x10\x03\x10\
	\x03\x10\x03\x10\x03\x10\x03\x10\x06\x10\u{4c4}\x0a\x10\x0d\x10\x0e\x10\
	\u{4c5}\x03\x11\x03\x11\x03\x11\x03\x11\x03\x11\x03\x11\x03\x11\x06\x11\
	\u{4cf}\x0a\x11\x0d\x11\x0e\x11\u{4d0}\x03\x11\x03\x11\x03\x11\x03\x11\x03\
	\x11\x03\x11\x03\x11\x03\x11\x03\x11\x03\x11\x03\x11\x03\x11\x03\x11\x03\
	\x11\x07\x11\u{4e1}\x0a\x11\x0c\x11\x0e\x11\u{4e4}\x0b\x11\x03\x11\x05\x11\
	\u{4e7}\x0a\x11\x03\x11\x03\x11\x05\x11\u{4eb}\x0a\x11\x05\x11\u{4ed}\x0a\
	\x11\x03\x12\x03\x12\x03\x12\x03\x12\x03\x12\x03\x12\x03\x12\x03\x12\x03\
	\x12\x03\x12\x03\x12\x03\x12\x07\x12\u{4fb}\x0a\x12\x0c\x12\x0e\x12\u{4fe}\
	\x0b\x12\x03\x12\x05\x12\u{501}\x0a\x12\x03\x12\x03\x12\x03\x13\x03\x13\
	\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x05\x13\u{50d}\x0a\x13\
	\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\
	\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x05\x13\u{51d}\x0a\x13\x03\x14\
	\x05\x14\u{520}\x0a\x14\x03\x14\x03\x14\x03\x15\x03\x15\x05\x15\u{526}\x0a\
	\x15\x03\x15\x03\x15\x03\x15\x07\x15\u{52b}\x0a\x15\x0c\x15\x0e\x15\u{52e}\
	\x0b\x15\x03\x16\x03\x16\x03\x16\x05\x16\u{533}\x0a\x16\x03\x17\x03\x17\
	\x05\x17\u{537}\x0a\x17\x03\x17\x03\x17\x03\x17\x03\x17\x03\x17\x05\x17\
	\u{53e}\x0a\x17\x03\x17\x03\x17\x03\x17\x05\x17\u{543}\x0a\x17\x03\x17\x03\
	\x17\x03\x17\x03\x17\x03\x17\x03\x17\x05\x17\u{54b}\x0a\x17\x03\x18\x03\
	\x18\x03\x18\x07\x18\u{550}\x0a\x18\x0c\x18\x0e\x18\u{553}\x0b\x18\x03\x18\
	\x03\x18\x05\x18\u{557}\x0a\x18\x03\x19\x03\x19\x03\x19\x03\x19\x03\x19\
	\x03\x19\x05\x19\u{55f}\x0a\x19\x03\x1a\x03\x1a\x05\x1a\u{563}\x0a\x1a\x03\
	\x1b\x03\x1b\x05\x1b\u{567}\x0a\x1b\x03\x1c\x03\x1c\x05\x1c\u{56b}\x0a\x1c\
	\x03\x1c\x05\x1c\u{56e}\x0a\x1c\x03\x1d\x03\x1d\x03\x1d\x07\x1d\u{573}\x0a\
	\x1d\x0c\x1d\x0e\x1d\u{576}\x0b\x1d\x03\x1d\x05\x1d\u{579}\x0a\x1d\x03\x1e\
	\x03\x1e\x03\x1e\x03\x1e\x03\x1f\x03\x1f\x03\x20\x03\x20\x03\x20\x03\x20\
	\x03\x20\x03\x20\x03\x20\x03\x20\x05\x20\u{589}\x0a\x20\x03\x20\x03\x20\
	\x05\x20\u{58d}\x0a\x20\x03\x20\x03\x20\x03\x20\x03\x20\x03\x20\x03\x20\
	\x03\x20\x03\x20\x03\x20\x03\x20\x05\x20\u{599}\x0a\x20\x03\x20\x03\x20\
	\x05\x20\u{59d}\x0a\x20\x03\x20\x03\x20\x03\x20\x03\x20\x03\x20\x03\x20\
	\x03\x20\x03\x20\x05\x20\u{5a7}\x0a\x20\x03\x20\x03\x20\x06\x20\u{5ab}\x0a\
	\x20\x0d\x20\x0e\x20\u{5ac}\x03\x21\x03\x21\x03\x21\x05\x21\u{5b2}\x0a\x21\
	\x03\x21\x03\x21\x03\x21\x05\x21\u{5b7}\x0a\x21\x03\x21\x03\x21\x03\x21\
	\x03\x21\x03\x21\x03\x21\x06\x21\u{5bf}\x0a\x21\x0d\x21\x0e\x21\u{5c0}\x03\
	\x22\x03\x22\x03\x22\x03\x22\x05\x22\u{5c7}\x0a\x22\x03\x23\x03\x23\x03\
	\x23\x03\x23\x03\x23\x03\x23\x03\x23\x03\x23\x05\x23\u{5d1}\x0a\x23\x03\
	\x23\x03\x23\x03\x23\x03\x23\x03\x23\x07\x23\u{5d8}\x0a\x23\x0c\x23\x0e\
	\x23\u{5db}\x0b\x23\x05\x23\u{5dd}\x0a\x23\x03\x23\x05\x23\u{5e0}\x0a\x23\
	\x03\x23\x03\x23\x03\x23\x05\x23\u{5e5}\x0a\x23\x03\x23\x03\x23\x07\x23\
	\u{5e9}\x0a\x23\x0c\x23\x0e\x23\u{5ec}\x0b\x23\x03\x24\x03\x24\x05\x24\u{5f0}\
	\x0a\x24\x03\x24\x03\x24\x03\x25\x03\x25\x03\x25\x07\x25\u{5f7}\x0a\x25\
	\x0c\x25\x0e\x25\u{5fa}\x0b\x25\x03\x25\x05\x25\u{5fd}\x0a\x25\x03\x26\x03\
	\x26\x03\x26\x03\x26\x07\x26\u{603}\x0a\x26\x0c\x26\x0e\x26\u{606}\x0b\x26\
	\x03\x26\x03\x26\x03\x26\x03\x26\x03\x26\x03\x26\x05\x26\u{60e}\x0a\x26\
	\x03\x27\x03\x27\x03\x28\x03\x28\x03\x28\x05\x28\u{615}\x0a\x28\x03\x29\
	\x03\x29\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x05\x2a\u{61e}\x0a\x2a\
	\x05\x2a\u{620}\x0a\x2a\x03\x2b\x03\x2b\x05\x2b\u{624}\x0a\x2b\x03\x2c\x03\
	\x2c\x05\x2c\u{628}\x0a\x2c\x03\x2d\x03\x2d\x03\x2e\x03\x2e\x03\x2f\x03\
	\x2f\x03\x2f\x03\x2f\x07\x2f\u{632}\x0a\x2f\x0c\x2f\x0e\x2f\u{635}\x0b\x2f\
	\x03\x30\x03\x30\x05\x30\u{639}\x0a\x30\x03\x31\x03\x31\x03\x31\x03\x31\
	\x07\x31\u{63f}\x0a\x31\x0c\x31\x0e\x31\u{642}\x0b\x31\x03\x32\x03\x32\x05\
	\x32\u{646}\x0a\x32\x03\x33\x03\x33\x03\x34\x03\x34\x03\x34\x03\x34\x07\
	\x34\u{64e}\x0a\x34\x0c\x34\x0e\x34\u{651}\x0b\x34\x03\x34\x05\x34\u{654}\
	\x0a\x34\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\
	\x05\x35\u{65e}\x0a\x35\x03\x36\x03\x36\x05\x36\u{662}\x0a\x36\x03\x36\x03\
	\x36\x05\x36\u{666}\x0a\x36\x03\x37\x03\x37\x03\x37\x05\x37\u{66b}\x0a\x37\
	\x03\x37\x05\x37\u{66e}\x0a\x37\x03\x37\x03\x37\x03\x37\x03\x37\x03\x37\
	\x07\x37\u{675}\x0a\x37\x0c\x37\x0e\x37\u{678}\x0b\x37\x03\x37\x05\x37\u{67b}\
	\x0a\x37\x05\x37\u{67d}\x0a\x37\x03\x37\x03\x37\x05\x37\u{681}\x0a\x37\x03\
	\x37\x03\x37\x03\x37\x05\x37\u{686}\x0a\x37\x03\x37\x03\x37\x03\x37\x03\
	\x37\x03\x37\x03\x37\x03\x37\x03\x37\x03\x37\x03\x37\x03\x37\x03\x37\x05\
	\x37\u{694}\x0a\x37\x03\x37\x03\x37\x03\x37\x05\x37\u{699}\x0a\x37\x05\x37\
	\u{69b}\x0a\x37\x03\x37\x05\x37\u{69e}\x0a\x37\x03\x37\x03\x37\x05\x37\u{6a2}\
	\x0a\x37\x03\x37\x03\x37\x05\x37\u{6a6}\x0a\x37\x03\x37\x03\x37\x03\x37\
	\x03\x37\x07\x37\u{6ac}\x0a\x37\x0c\x37\x0e\x37\u{6af}\x0b\x37\x03\x37\x05\
	\x37\u{6b2}\x0a\x37\x05\x37\u{6b4}\x0a\x37\x03\x38\x03\x38\x03\x38\x07\x38\
	\u{6b9}\x0a\x38\x0c\x38\x0e\x38\u{6bc}\x0b\x38\x03\x38\x05\x38\u{6bf}\x0a\
	\x38\x03\x39\x03\x39\x03\x39\x03\x39\x03\x3a\x05\x3a\u{6c6}\x0a\x3a\x03\
	\x3a\x03\x3a\x03\x3a\x07\x3a\u{6cb}\x0a\x3a\x0c\x3a\x0e\x3a\u{6ce}\x0b\x3a\
	\x03\x3a\x05\x3a\u{6d1}\x0a\x3a\x03\x3b\x03\x3b\x03\x3b\x03\x3b\x03\x3b\
	\x07\x3b\u{6d8}\x0a\x3b\x0c\x3b\x0e\x3b\u{6db}\x0b\x3b\x03\x3b\x05\x3b\u{6de}\
	\x0a\x3b\x05\x3b\u{6e0}\x0a\x3b\x03\x3b\x03\x3b\x03\x3b\x03\x3b\x03\x3b\
	\x03\x3b\x07\x3b\u{6e8}\x0a\x3b\x0c\x3b\x0e\x3b\u{6eb}\x0b\x3b\x03\x3b\x05\
	\x3b\u{6ee}\x0a\x3b\x05\x3b\u{6f0}\x0a\x3b\x03\x3b\x03\x3b\x03\x3b\x03\x3b\
	\x03\x3b\x03\x3b\x03\x3b\x07\x3b\u{6f9}\x0a\x3b\x0c\x3b\x0e\x3b\u{6fc}\x0b\
	\x3b\x03\x3b\x05\x3b\u{6ff}\x0a\x3b\x03\x3b\x03\x3b\x03\x3b\x05\x3b\u{704}\
	\x0a\x3b\x03\x3c\x03\x3c\x03\x3c\x03\x3c\x07\x3c\u{70a}\x0a\x3c\x0c\x3c\
	\x0e\x3c\u{70d}\x0b\x3c\x05\x3c\u{70f}\x0a\x3c\x03\x3c\x05\x3c\u{712}\x0a\
	\x3c\x03\x3c\x03\x3c\x05\x3c\u{716}\x0a\x3c\x03\x3d\x03\x3d\x03\x3d\x03\
	\x3d\x03\x3d\x03\x3d\x03\x3e\x05\x3e\u{71f}\x0a\x3e\x03\x3e\x05\x3e\u{722}\
	\x0a\x3e\x03\x3e\x05\x3e\u{725}\x0a\x3e\x03\x3e\x05\x3e\u{728}\x0a\x3e\x03\
	\x3f\x03\x3f\x03\x3f\x03\x3f\x03\x3f\x07\x3f\u{72f}\x0a\x3f\x0c\x3f\x0e\
	\x3f\u{732}\x0b\x3f\x03\x3f\x05\x3f\u{735}\x0a\x3f\x03\x40\x03\x40\x03\x40\
	\x03\x40\x03\x40\x07\x40\u{73c}\x0a\x40\x0c\x40\x0e\x40\u{73f}\x0b\x40\x03\
	\x40\x05\x40\u{742}\x0a\x40\x03\x41\x03\x41\x05\x41\u{746}\x0a\x41\x03\x41\
	\x03\x41\x03\x41\x03\x41\x03\x41\x03\x42\x03\x42\x05\x42\u{74f}\x0a\x42\
	\x03\x43\x03\x43\x05\x43\u{753}\x0a\x43\x03\x43\x05\x43\u{756}\x0a\x43\x03\
	\x43\x05\x43\u{759}\x0a\x43\x03\x44\x03\x44\x03\x45\x03\x45\x03\x45\x03\
	\x45\x03\x45\x05\x45\u{762}\x0a\x45\x03\x46\x03\x46\x03\x47\x03\x47\x03\
	\x47\x03\x47\x03\x47\x03\x47\x03\x47\x03\x47\x03\x47\x03\x47\x03\x47\x05\
	\x47\u{771}\x0a\x47\x03\x47\x03\x47\x03\x47\x03\x47\x05\x47\u{777}\x0a\x47\
	\x03\x47\x03\x47\x03\x47\x03\x47\x03\x47\x05\x47\u{77e}\x0a\x47\x07\x47\
	\u{780}\x0a\x47\x0c\x47\x0e\x47\u{783}\x0b\x47\x03\x48\x05\x48\u{786}\x0a\
	\x48\x03\x48\x03\x48\x05\x48\u{78a}\x0a\x48\x03\x48\x03\x48\x05\x48\u{78e}\
	\x0a\x48\x03\x48\x03\x48\x05\x48\u{792}\x0a\x48\x05\x48\u{794}\x0a\x48\x03\
	\x49\x03\x49\x03\x49\x03\x49\x03\x49\x03\x49\x03\x49\x07\x49\u{79d}\x0a\
	\x49\x0c\x49\x0e\x49\u{7a0}\x0b\x49\x03\x49\x05\x49\u{7a3}\x0a\x49\x03\x49\
	\x03\x49\x05\x49\u{7a7}\x0a\x49\x03\x4a\x03\x4a\x03\x4b\x03\x4b\x03\x4c\
	\x03\x4c\x03\x4c\x05\x4c\u{7b0}\x0a\x4c\x03\x4c\x05\x4c\u{7b3}\x0a\x4c\x03\
	\x4d\x03\x4d\x03\x4d\x03\x4d\x05\x4d\u{7b9}\x0a\x4d\x03\x4e\x03\x4e\x03\
	\x4e\x03\x4e\x03\x4f\x03\x4f\x03\x50\x03\x50\x07\x50\u{7c3}\x0a\x50\x0c\
	\x50\x0e\x50\u{7c6}\x0b\x50\x03\x50\x03\x50\x03\x50\x03\x50\x05\x50\u{7cc}\
	\x0a\x50\x03\x51\x03\x51\x05\x51\u{7d0}\x0a\x51\x03\x51\x05\x51\u{7d3}\x0a\
	\x51\x03\x52\x03\x52\x03\x53\x03\x53\x03\x53\x05\x53\u{7da}\x0a\x53\x03\
	\x54\x05\x54\u{7dd}\x0a\x54\x03\x54\x03\x54\x05\x54\u{7e1}\x0a\x54\x05\x54\
	\u{7e3}\x0a\x54\x03\x55\x03\x55\x03\x55\x03\x55\x03\x55\x03\x55\x03\x55\
	\x03\x55\x03\x56\x03\x56\x03\x56\x07\x56\u{7f0}\x0a\x56\x0c\x56\x0e\x56\
	\u{7f3}\x0b\x56\x03\x56\x05\x56\u{7f6}\x0a\x56\x03\x57\x03\x57\x03\x58\x03\
	\x58\x03\x58\x07\x58\u{7fd}\x0a\x58\x0c\x58\x0e\x58\u{800}\x0b\x58\x03\x58\
	\x05\x58\u{803}\x0a\x58\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\
	\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x05\x59\
	\u{813}\x0a\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x05\x59\u{81a}\x0a\
	\x59\x03\x5a\x03\x5a\x03\x5a\x03\x5a\x03\x5a\x05\x5a\u{821}\x0a\x5a\x03\
	\x5b\x03\x5b\x05\x5b\u{825}\x0a\x5b\x03\x5b\x03\x5b\x03\x5b\x03\x5b\x05\
	\x5b\u{82b}\x0a\x5b\x05\x5b\u{82d}\x0a\x5b\x03\x5c\x03\x5c\x03\x5c\x03\x5c\
	\x03\x5c\x07\x5c\u{834}\x0a\x5c\x0c\x5c\x0e\x5c\u{837}\x0b\x5c\x03\x5c\x05\
	\x5c\u{83a}\x0a\x5c\x03\x5c\x03\x5c\x05\x5c\u{83e}\x0a\x5c\x03\x5d\x03\x5d\
	\x03\x5d\x03\x5e\x03\x5e\x03\x5e\x03\x5e\x07\x5e\u{847}\x0a\x5e\x0c\x5e\
	\x0e\x5e\u{84a}\x0b\x5e\x03\x5e\x05\x5e\u{84d}\x0a\x5e\x03\x5e\x03\x5e\x03\
	\x5f\x03\x5f\x03\x5f\x03\x5f\x03\x5f\x03\x5f\x03\x5f\x05\x5f\u{858}\x0a\
	\x5f\x05\x5f\u{85a}\x0a\x5f\x03\x60\x03\x60\x03\x60\x03\x60\x03\x60\x07\
	\x60\u{861}\x0a\x60\x0c\x60\x0e\x60\u{864}\x0b\x60\x03\x60\x05\x60\u{867}\
	\x0a\x60\x05\x60\u{869}\x0a\x60\x03\x60\x05\x60\u{86c}\x0a\x60\x03\x60\x03\
	\x60\x05\x60\u{870}\x0a\x60\x03\x61\x03\x61\x03\x61\x03\x61\x07\x61\u{876}\
	\x0a\x61\x0c\x61\x0e\x61\u{879}\x0b\x61\x03\x61\x05\x61\u{87c}\x0a\x61\x03\
	\x62\x03\x62\x03\x63\x03\x63\x03\x63\x05\x63\u{883}\x0a\x63\x03\x63\x03\
	\x63\x03\x63\x05\x63\u{888}\x0a\x63\x03\x64\x03\x64\x03\x64\x03\x64\x03\
	\x64\x03\x64\x03\x64\x07\x64\u{891}\x0a\x64\x0c\x64\x0e\x64\u{894}\x0b\x64\
	\x03\x64\x05\x64\u{897}\x0a\x64\x05\x64\u{899}\x0a\x64\x03\x64\x03\x64\x05\
	\x64\u{89d}\x0a\x64\x05\x64\u{89f}\x0a\x64\x03\x64\x03\x64\x03\x64\x03\x64\
	\x03\x64\x03\x64\x05\x64\u{8a7}\x0a\x64\x03\x64\x03\x64\x03\x64\x03\x64\
	\x03\x64\x03\x64\x07\x64\u{8af}\x0a\x64\x0c\x64\x0e\x64\u{8b2}\x0b\x64\x03\
	\x64\x05\x64\u{8b5}\x0a\x64\x03\x64\x03\x64\x03\x64\x05\x64\u{8ba}\x0a\x64\
	\x05\x64\u{8bc}\x0a\x64\x03\x65\x03\x65\x03\x65\x03\x65\x03\x65\x05\x65\
	\u{8c3}\x0a\x65\x03\x65\x03\x65\x05\x65\u{8c7}\x0a\x65\x05\x65\u{8c9}\x0a\
	\x65\x03\x65\x03\x65\x03\x65\x03\x65\x03\x65\x05\x65\u{8d0}\x0a\x65\x03\
	\x65\x03\x65\x05\x65\u{8d4}\x0a\x65\x05\x65\u{8d6}\x0a\x65\x05\x65\u{8d8}\
	\x0a\x65\x03\x66\x03\x66\x03\x66\x03\x66\x03\x66\x07\x66\u{8df}\x0a\x66\
	\x0c\x66\x0e\x66\u{8e2}\x0b\x66\x03\x66\x05\x66\u{8e5}\x0a\x66\x03\x66\x03\
	\x66\x03\x66\x03\x66\x03\x66\x03\x66\x03\x66\x03\x66\x05\x66\u{8ef}\x0a\
	\x66\x03\x67\x03\x67\x05\x67\u{8f3}\x0a\x67\x03\x68\x03\x68\x03\x68\x03\
	\x68\x03\x68\x03\x68\x07\x68\u{8fb}\x0a\x68\x0c\x68\x0e\x68\u{8fe}\x0b\x68\
	\x03\x68\x05\x68\u{901}\x0a\x68\x03\x68\x03\x68\x03\x69\x03\x69\x03\x6a\
	\x03\x6a\x03\x6a\x03\x6a\x05\x6a\u{90b}\x0a\x6a\x03\x6a\x03\x6a\x03\x6a\
	\x03\x6a\x03\x6a\x03\x6a\x03\x6a\x03\x6a\x07\x6a\u{915}\x0a\x6a\x0c\x6a\
	\x0e\x6a\u{918}\x0b\x6a\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6b\
	\x03\x6b\x03\x6b\x03\x6b\x05\x6b\u{923}\x0a\x6b\x03\x6c\x03\x6c\x05\x6c\
	\u{927}\x0a\x6c\x03\x6d\x05\x6d\u{92a}\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x03\
	\x6d\x03\x6d\x03\x6d\x05\x6d\u{932}\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x03\
	\x6d\x03\x6d\x07\x6d\u{939}\x0a\x6d\x0c\x6d\x0e\x6d\u{93c}\x0b\x6d\x03\x6d\
	\x05\x6d\u{93f}\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x05\x6d\u{944}\x0a\x6d\x03\
	\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x05\x6d\u{94c}\x0a\x6d\x03\
	\x6d\x03\x6d\x03\x6d\x03\x6d\x05\x6d\u{952}\x0a\x6d\x03\x6d\x05\x6d\u{955}\
	\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x05\x6d\u{95c}\x0a\x6d\
	\x03\x6d\x03\x6d\x05\x6d\u{960}\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x05\x6d\
	\u{965}\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\
	\x05\x6d\u{96e}\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x05\x6d\u{973}\x0a\x6d\x03\
	\x6d\x03\x6d\x03\x6d\x05\x6d\u{978}\x0a\x6d\x03\x6d\x05\x6d\u{97b}\x0a\x6d\
	\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{980}\x0a\x6e\x03\x6e\x03\x6e\x05\x6e\
	\u{984}\x0a\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x07\x6e\
	\u{99e}\x0a\x6e\x0c\x6e\x0e\x6e\u{9a1}\x0b\x6e\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x06\x6f\u{9b4}\x0a\x6f\x0d\x6f\x0e\
	\x6f\u{9b5}\x03\x6f\x05\x6f\u{9b9}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x07\x6f\u{9c2}\x0a\x6f\x0c\x6f\x0e\x6f\u{9c5}\x0b\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x05\x6f\u{9d2}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x05\
	\x6f\u{9d7}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{9dc}\x0a\x6f\x03\x6f\
	\x05\x6f\u{9df}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x07\x6f\u{9ea}\x0a\x6f\x0c\x6f\x0e\x6f\u{9ed}\x0b\
	\x6f\x03\x6f\x05\x6f\u{9f0}\x0a\x6f\x03\x6f\x03\x6f\x05\x6f\u{9f4}\x0a\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x07\x6f\u{9fd}\
	\x0a\x6f\x0c\x6f\x0e\x6f\u{a00}\x0b\x6f\x05\x6f\u{a02}\x0a\x6f\x03\x6f\x05\
	\x6f\u{a05}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x06\x6f\u{a0f}\x0a\x6f\x0d\x6f\x0e\x6f\u{a10}\x03\x6f\x03\x6f\
	\x05\x6f\u{a15}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x06\x6f\u{a1b}\x0a\
	\x6f\x0d\x6f\x0e\x6f\u{a1c}\x03\x6f\x03\x6f\x05\x6f\u{a21}\x0a\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x05\x6f\u{a36}\x0a\x6f\x03\x6f\x05\x6f\u{a39}\x0a\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{a44}\x0a\
	\x6f\x03\x6f\x05\x6f\u{a47}\x0a\x6f\x05\x6f\u{a49}\x0a\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{a54}\
	\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x05\x6f\u{a5f}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x05\x6f\u{a68}\x0a\x6f\x03\x6f\x05\x6f\u{a6b}\x0a\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{a73}\x0a\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{a82}\x0a\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x07\x6f\u{a87}\x0a\x6f\x0c\x6f\x0e\x6f\u{a8a}\x0b\x6f\x05\x6f\u{a8c}\
	\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{a91}\x0a\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x07\x6f\u{aa1}\x0a\x6f\x0c\x6f\x0e\x6f\u{aa4}\x0b\
	\x6f\x05\x6f\u{aa6}\x0a\x6f\x03\x6f\x05\x6f\u{aa9}\x0a\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x07\x6f\u{ab7}\x0a\x6f\x0c\x6f\x0e\x6f\u{aba}\x0b\x6f\x05\x6f\u{abc}\
	\x0a\x6f\x03\x6f\x05\x6f\u{abf}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x05\x6f\u{ad0}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{ad9}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x05\x6f\u{adf}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\
	\u{ae5}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x05\x6f\u{af0}\x0a\x6f\x05\x6f\u{af2}\x0a\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x05\x6f\u{af7}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x05\x6f\u{afe}\x0a\x6f\x05\x6f\u{b00}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x05\x6f\u{b06}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\
	\u{b0c}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x07\x6f\u{b15}\x0a\x6f\x0c\x6f\x0e\x6f\u{b18}\x0b\x6f\x03\x6f\x05\x6f\u{b1b}\
	\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{b23}\
	\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{b28}\x0a\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x05\x6f\u{b2d}\x0a\x6f\x05\x6f\u{b2f}\x0a\x6f\x05\x6f\u{b31}\x0a\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{b37}\x0a\x6f\x05\x6f\u{b39}\
	\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x07\x6f\u{b41}\
	\x0a\x6f\x0c\x6f\x0e\x6f\u{b44}\x0b\x6f\x03\x6f\x05\x6f\u{b47}\x0a\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{b4f}\x0a\x6f\x05\
	\x6f\u{b51}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{b57}\x0a\x6f\
	\x05\x6f\u{b59}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{b77}\x0a\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x05\x6f\u{b86}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x07\x6f\u{b90}\x0a\x6f\x0c\x6f\x0e\x6f\
	\u{b93}\x0b\x6f\x05\x6f\u{b95}\x0a\x6f\x03\x6f\x05\x6f\u{b98}\x0a\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x05\x6f\u{ba5}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x07\x6f\u{baf}\x0a\x6f\x0c\x6f\x0e\x6f\u{bb2}\
	\x0b\x6f\x05\x6f\u{bb4}\x0a\x6f\x03\x6f\x05\x6f\u{bb7}\x0a\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{bbe}\x0a\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x05\x6f\u{bc3}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x07\
	\x6f\u{bd3}\x0a\x6f\x0c\x6f\x0e\x6f\u{bd6}\x0b\x6f\x03\x70\x05\x70\u{bd9}\
	\x0a\x70\x03\x71\x05\x71\u{bdc}\x0a\x71\x03\x71\x05\x71\u{bdf}\x0a\x71\x03\
	\x71\x05\x71\u{be2}\x0a\x71\x03\x72\x03\x72\x05\x72\u{be6}\x0a\x72\x03\x73\
	\x03\x73\x03\x73\x03\x73\x03\x73\x07\x73\u{bed}\x0a\x73\x0c\x73\x0e\x73\
	\u{bf0}\x0b\x73\x05\x73\u{bf2}\x0a\x73\x03\x74\x03\x74\x03\x74\x03\x74\x03\
	\x74\x03\x74\x05\x74\u{bfa}\x0a\x74\x03\x75\x05\x75\u{bfd}\x0a\x75\x03\x75\
	\x05\x75\u{c00}\x0a\x75\x03\x75\x03\x75\x03\x76\x03\x76\x03\x76\x05\x76\
	\u{c07}\x0a\x76\x03\x77\x03\x77\x03\x77\x03\x77\x05\x77\u{c0d}\x0a\x77\x03\
	\x77\x03\x77\x03\x77\x03\x77\x07\x77\u{c13}\x0a\x77\x0c\x77\x0e\x77\u{c16}\
	\x0b\x77\x05\x77\u{c18}\x0a\x77\x03\x77\x05\x77\u{c1b}\x0a\x77\x03\x78\x03\
	\x78\x03\x78\x05\x78\u{c20}\x0a\x78\x03\x79\x03\x79\x03\x79\x05\x79\u{c25}\
	\x0a\x79\x03\x7a\x03\x7a\x03\x7a\x03\x7a\x03\x7b\x03\x7b\x03\x7c\x03\x7c\
	\x03\x7c\x03\x7c\x05\x7c\u{c31}\x0a\x7c\x03\x7d\x03\x7d\x05\x7d\u{c35}\x0a\
	\x7d\x03\x7d\x03\x7d\x05\x7d\u{c39}\x0a\x7d\x03\x7d\x05\x7d\u{c3c}\x0a\x7d\
	\x05\x7d\u{c3e}\x0a\x7d\x03\x7e\x03\x7e\x03\x7e\x03\x7e\x03\x7e\x03\x7e\
	\x05\x7e\u{c46}\x0a\x7e\x03\x7f\x05\x7f\u{c49}\x0a\x7f\x03\x7f\x03\x7f\x03\
	\x7f\x03\x7f\x03\x7f\x03\x7f\x03\x7f\x03\x7f\x05\x7f\u{c53}\x0a\x7f\x03\
	\u{80}\x03\u{80}\x03\u{81}\x03\u{81}\x03\u{81}\x03\u{81}\x05\u{81}\u{c5b}\
	\x0a\u{81}\x03\u{82}\x03\u{82}\x03\u{82}\x03\u{82}\x03\u{82}\x05\u{82}\u{c62}\
	\x0a\u{82}\x05\u{82}\u{c64}\x0a\u{82}\x03\u{83}\x03\u{83}\x03\u{83}\x03\
	\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x05\u{83}\u{c6f}\
	\x0a\u{83}\x03\u{84}\x03\u{84}\x03\u{85}\x03\u{85}\x03\u{86}\x03\u{86}\x03\
	\u{87}\x03\u{87}\x05\u{87}\u{c79}\x0a\u{87}\x03\u{87}\x03\u{87}\x05\u{87}\
	\u{c7d}\x0a\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x05\u{87}\u{c82}\x0a\u{87}\
	\x03\u{88}\x03\u{88}\x03\u{89}\x03\u{89}\x03\u{8a}\x03\u{8a}\x03\u{8b}\x03\
	\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{c90}\x0a\u{8b}\
	\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{c97}\x0a\
	\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{c9c}\x0a\u{8b}\x03\u{8b}\
	\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{ca3}\x0a\u{8b}\x03\
	\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\
	\x05\u{8b}\u{cad}\x0a\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{cb2}\
	\x0a\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{cb9}\
	\x0a\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\
	\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{cc5}\x0a\u{8b}\x03\u{8b}\
	\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{ccc}\x0a\u{8b}\x03\
	\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x07\u{8b}\u{cd3}\x0a\u{8b}\
	\x0c\u{8b}\x0e\u{8b}\u{cd6}\x0b\u{8b}\x03\u{8b}\x05\u{8b}\u{cd9}\x0a\u{8b}\
	\x03\u{8b}\x03\u{8b}\x05\u{8b}\u{cdd}\x0a\u{8b}\x05\u{8b}\u{cdf}\x0a\u{8b}\
	\x03\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x05\u{8c}\u{ce5}\x0a\u{8c}\x03\
	\u{8d}\x03\u{8d}\x05\u{8d}\u{ce9}\x0a\u{8d}\x03\u{8e}\x03\u{8e}\x03\u{8e}\
	\x03\u{8e}\x03\u{8e}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x03\
	\u{8f}\x03\u{90}\x03\u{90}\x03\u{90}\x03\u{90}\x03\u{90}\x03\u{90}\x05\u{90}\
	\u{cfc}\x0a\u{90}\x03\u{91}\x03\u{91}\x03\u{92}\x03\u{92}\x03\u{92}\x03\
	\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\
	\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\
	\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x05\u{92}\u{d18}\
	\x0a\u{92}\x03\u{93}\x03\u{93}\x03\u{93}\x03\u{93}\x03\u{93}\x03\u{93}\x03\
	\u{93}\x03\u{93}\x03\u{93}\x05\u{93}\u{d23}\x0a\u{93}\x03\u{94}\x03\u{94}\
	\x03\u{94}\x05\u{94}\u{d28}\x0a\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\
	\u{94}\x03\u{94}\x07\u{94}\u{d2f}\x0a\u{94}\x0c\u{94}\x0e\u{94}\u{d32}\x0b\
	\u{94}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\
	\x03\u{95}\x07\u{95}\u{d3c}\x0a\u{95}\x0c\u{95}\x0e\u{95}\u{d3f}\x0b\u{95}\
	\x03\u{95}\x05\u{95}\u{d42}\x0a\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\
	\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\
	\x03\u{95}\x05\u{95}\u{d50}\x0a\u{95}\x03\u{96}\x03\u{96}\x05\u{96}\u{d54}\
	\x0a\u{96}\x03\u{96}\x03\u{96}\x05\u{96}\u{d58}\x0a\u{96}\x03\u{96}\x03\
	\u{96}\x05\u{96}\u{d5c}\x0a\u{96}\x03\u{96}\x03\u{96}\x03\u{96}\x03\u{96}\
	\x05\u{96}\u{d62}\x0a\u{96}\x03\u{96}\x03\u{96}\x05\u{96}\u{d66}\x0a\u{96}\
	\x03\u{96}\x03\u{96}\x05\u{96}\u{d6a}\x0a\u{96}\x03\u{96}\x05\u{96}\u{d6d}\
	\x0a\u{96}\x03\u{96}\x03\u{96}\x05\u{96}\u{d71}\x0a\u{96}\x05\u{96}\u{d73}\
	\x0a\u{96}\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x05\u{97}\u{d7a}\
	\x0a\u{97}\x03\u{98}\x03\u{98}\x03\u{98}\x03\u{98}\x03\u{98}\x03\u{98}\x03\
	\u{98}\x05\u{98}\u{d83}\x0a\u{98}\x03\u{99}\x03\u{99}\x03\u{9a}\x03\u{9a}\
	\x03\u{9a}\x07\u{9a}\u{d8a}\x0a\u{9a}\x0c\u{9a}\x0e\u{9a}\u{d8d}\x0b\u{9a}\
	\x03\u{9b}\x03\u{9b}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\
	\u{9c}\x03\u{9d}\x03\u{9d}\x03\u{9e}\x03\u{9e}\x03\u{9e}\x03\u{9e}\x03\u{9e}\
	\x05\u{9e}\u{d9e}\x0a\u{9e}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x03\
	\u{9f}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x03\u{9f}\
	\x03\u{9f}\x03\u{9f}\x03\u{9f}\x05\u{9f}\u{daf}\x0a\u{9f}\x03\u{a0}\x03\
	\u{a0}\x03\u{a1}\x03\u{a1}\x03\u{a2}\x03\u{a2}\x03\u{a2}\x03\u{a3}\x05\u{a3}\
	\u{db9}\x0a\u{a3}\x03\u{a3}\x03\u{a3}\x05\u{a3}\u{dbd}\x0a\u{a3}\x03\u{a3}\
	\x03\u{a3}\x05\u{a3}\u{dc1}\x0a\u{a3}\x03\u{a3}\x05\u{a3}\u{dc4}\x0a\u{a3}\
	\x03\u{a4}\x03\u{a4}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x02\x07\u{8c}\u{d2}\u{da}\
	\u{dc}\u{126}\u{a6}\x02\x04\x06\x08\x0a\x0c\x0e\x10\x12\x14\x16\x18\x1a\
	\x1c\x1e\x20\x22\x24\x26\x28\x2a\x2c\x2e\x30\x32\x34\x36\x38\x3a\x3c\x3e\
	\x40\x42\x44\x46\x48\x4a\x4c\x4e\x50\x52\x54\x56\x58\x5a\x5c\x5e\x60\x62\
	\x64\x66\x68\x6a\x6c\x6e\x70\x72\x74\x76\x78\x7a\x7c\x7e\u{80}\u{82}\u{84}\
	\u{86}\u{88}\u{8a}\u{8c}\u{8e}\u{90}\u{92}\u{94}\u{96}\u{98}\u{9a}\u{9c}\
	\u{9e}\u{a0}\u{a2}\u{a4}\u{a6}\u{a8}\u{aa}\u{ac}\u{ae}\u{b0}\u{b2}\u{b4}\
	\u{b6}\u{b8}\u{ba}\u{bc}\u{be}\u{c0}\u{c2}\u{c4}\u{c6}\u{c8}\u{ca}\u{cc}\
	\u{ce}\u{d0}\u{d2}\u{d4}\u{d6}\u{d8}\u{da}\u{dc}\u{de}\u{e0}\u{e2}\u{e4}\
	\u{e6}\u{e8}\u{ea}\u{ec}\u{ee}\u{f0}\u{f2}\u{f4}\u{f6}\u{f8}\u{fa}\u{fc}\
	\u{fe}\u{100}\u{102}\u{104}\u{106}\u{108}\u{10a}\u{10c}\u{10e}\u{110}\u{112}\
	\u{114}\u{116}\u{118}\u{11a}\u{11c}\u{11e}\u{120}\u{122}\u{124}\u{126}\u{128}\
	\u{12a}\u{12c}\u{12e}\u{130}\u{132}\u{134}\u{136}\u{138}\u{13a}\u{13c}\u{13e}\
	\u{140}\u{142}\u{144}\u{146}\u{148}\x02\x30\x03\x02\u{1a3}\u{1a3}\x03\x02\
	\u{151}\u{152}\x04\x02\u{e2}\u{e2}\u{18e}\u{18e}\x04\x02\x55\x55\u{a3}\u{a3}\
	\x04\x02\u{15d}\u{15d}\u{188}\u{188}\x04\x02\u{133}\u{133}\u{14e}\u{14e}\
	\x04\x02\x03\x03\u{1a3}\u{1a3}\x04\x02\x6d\x6d\u{97}\u{97}\x04\x02\x76\x76\
	\u{c0}\u{c0}\x04\x02\u{b0}\u{b0}\u{d2}\u{d2}\x04\x02\x6e\x6e\u{98}\u{98}\
	\x04\x02\x53\x53\u{111}\u{111}\x06\x02\x11\x11\x1e\x1e\x6b\x6b\u{b2}\u{b2}\
	\x04\x02\x3b\x3b\u{9e}\u{9e}\x04\x02\u{1a2}\u{1a2}\u{1b7}\u{1b7}\x05\x02\
	\x6c\x6c\u{d6}\u{d6}\u{168}\u{168}\x04\x02\x11\x11\x5d\x5d\x04\x02\x1a\x1a\
	\x5a\x5a\x04\x02\x79\x79\u{b7}\u{b7}\x05\x02\x25\x25\u{ba}\u{ba}\u{15c}\
	\u{15c}\x04\x02\u{a8}\u{a8}\u{be}\u{be}\x04\x02\u{19c}\u{19d}\u{1ac}\u{1ac}\
	\x03\x02\u{19e}\u{1a0}\x03\x02\u{19c}\u{19d}\x03\x02\u{1a6}\u{1a8}\x04\x02\
	\u{1a9}\u{1a9}\u{1ac}\u{1b1}\x03\x02\u{c1}\u{c2}\x04\x02\u{b1}\u{b1}\u{ec}\
	\u{ec}\x05\x02\x7a\x7a\u{b4}\u{b4}\u{b8}\u{b8}\x04\x02\u{94}\u{94}\u{11e}\
	\u{11e}\x06\x02\u{96}\u{96}\u{9d}\u{9d}\u{f5}\u{f5}\u{17c}\u{17c}\x03\x02\
	\u{174}\u{176}\x06\x02\x69\x69\x74\x74\u{15f}\u{15f}\u{16a}\u{16a}\x04\x02\
	\x3d\x3d\u{167}\u{167}\x04\x02\x78\x78\u{12c}\u{12c}\x03\x02\u{196}\u{19b}\
	\x05\x02\x11\x11\x16\x16\u{142}\u{142}\x04\x02\x74\x74\u{15f}\u{15f}\x0c\
	\x02\x4e\x4f\u{8f}\u{90}\u{c7}\u{c7}\u{d5}\u{d5}\u{d7}\u{d8}\u{da}\u{db}\
	\u{12d}\u{12d}\u{130}\u{132}\u{181}\u{181}\u{18c}\u{18d}\x03\x02\u{de}\u{e1}\
	\x04\x02\x7b\x7b\u{10a}\u{10a}\x04\x02\u{ef}\u{ef}\u{18a}\u{18a}\x07\x02\
	\x45\x45\x56\x56\u{9f}\u{9f}\u{137}\u{137}\u{170}\u{170}\x04\x02\u{159}\
	\u{159}\u{17e}\u{17e}\x0e\x02\x41\x41\x46\x46\u{80}\u{80}\u{9a}\u{9a}\u{bb}\
	\u{bb}\u{d6}\u{d6}\u{dc}\u{dc}\u{e5}\u{e5}\u{f6}\u{f6}\u{124}\u{124}\u{173}\
	\u{173}\u{183}\u{183}\x17\x02\x0c\x18\x1a\x36\x38\x40\x42\x45\x47\x7f\u{81}\
	\u{91}\u{93}\u{99}\u{9b}\u{ba}\u{bc}\u{d5}\u{d7}\u{db}\u{dd}\u{e4}\u{e6}\
	\u{f5}\u{f7}\u{123}\u{125}\u{140}\u{142}\u{14b}\u{14d}\u{15a}\u{15c}\u{16a}\
	\u{16c}\u{172}\u{174}\u{182}\u{184}\u{185}\u{187}\u{190}\x02\u{fe3}\x02\
	\u{14b}\x03\x02\x02\x02\x04\u{159}\x03\x02\x02\x02\x06\u{160}\x03\x02\x02\
	\x02\x08\u{163}\x03\x02\x02\x02\x0a\u{166}\x03\x02\x02\x02\x0c\u{486}\x03\
	\x02\x02\x02\x0e\u{488}\x03\x02\x02\x02\x10\u{490}\x03\x02\x02\x02\x12\u{49a}\
	\x03\x02\x02\x02\x14\u{4a4}\x03\x02\x02\x02\x16\u{4a7}\x03\x02\x02\x02\x18\
	\u{4aa}\x03\x02\x02\x02\x1a\u{4ae}\x03\x02\x02\x02\x1c\u{4b2}\x03\x02\x02\
	\x02\x1e\u{4bc}\x03\x02\x02\x02\x20\u{4c7}\x03\x02\x02\x02\x22\u{4ee}\x03\
	\x02\x02\x02\x24\u{51c}\x03\x02\x02\x02\x26\u{51f}\x03\x02\x02\x02\x28\u{523}\
	\x03\x02\x02\x02\x2a\u{532}\x03\x02\x02\x02\x2c\u{536}\x03\x02\x02\x02\x2e\
	\u{54c}\x03\x02\x02\x02\x30\u{55e}\x03\x02\x02\x02\x32\u{562}\x03\x02\x02\
	\x02\x34\u{566}\x03\x02\x02\x02\x36\u{568}\x03\x02\x02\x02\x38\u{56f}\x03\
	\x02\x02\x02\x3a\u{57a}\x03\x02\x02\x02\x3c\u{57e}\x03\x02\x02\x02\x3e\u{5aa}\
	\x03\x02\x02\x02\x40\u{5be}\x03\x02\x02\x02\x42\u{5c2}\x03\x02\x02\x02\x44\
	\u{5ea}\x03\x02\x02\x02\x46\u{5ed}\x03\x02\x02\x02\x48\u{5f3}\x03\x02\x02\
	\x02\x4a\u{60d}\x03\x02\x02\x02\x4c\u{60f}\x03\x02\x02\x02\x4e\u{614}\x03\
	\x02\x02\x02\x50\u{616}\x03\x02\x02\x02\x52\u{618}\x03\x02\x02\x02\x54\u{621}\
	\x03\x02\x02\x02\x56\u{627}\x03\x02\x02\x02\x58\u{629}\x03\x02\x02\x02\x5a\
	\u{62b}\x03\x02\x02\x02\x5c\u{62d}\x03\x02\x02\x02\x5e\u{636}\x03\x02\x02\
	\x02\x60\u{63a}\x03\x02\x02\x02\x62\u{643}\x03\x02\x02\x02\x64\u{647}\x03\
	\x02\x02\x02\x66\u{649}\x03\x02\x02\x02\x68\u{65d}\x03\x02\x02\x02\x6a\u{65f}\
	\x03\x02\x02\x02\x6c\u{667}\x03\x02\x02\x02\x6e\u{6b5}\x03\x02\x02\x02\x70\
	\u{6c0}\x03\x02\x02\x02\x72\u{6c5}\x03\x02\x02\x02\x74\u{703}\x03\x02\x02\
	\x02\x76\u{715}\x03\x02\x02\x02\x78\u{717}\x03\x02\x02\x02\x7a\u{71e}\x03\
	\x02\x02\x02\x7c\u{729}\x03\x02\x02\x02\x7e\u{736}\x03\x02\x02\x02\u{80}\
	\u{743}\x03\x02\x02\x02\u{82}\u{74e}\x03\x02\x02\x02\u{84}\u{758}\x03\x02\
	\x02\x02\u{86}\u{75a}\x03\x02\x02\x02\u{88}\u{761}\x03\x02\x02\x02\u{8a}\
	\u{763}\x03\x02\x02\x02\u{8c}\u{765}\x03\x02\x02\x02\u{8e}\u{793}\x03\x02\
	\x02\x02\u{90}\u{7a6}\x03\x02\x02\x02\u{92}\u{7a8}\x03\x02\x02\x02\u{94}\
	\u{7aa}\x03\x02\x02\x02\u{96}\u{7b2}\x03\x02\x02\x02\u{98}\u{7b8}\x03\x02\
	\x02\x02\u{9a}\u{7ba}\x03\x02\x02\x02\u{9c}\u{7be}\x03\x02\x02\x02\u{9e}\
	\u{7cb}\x03\x02\x02\x02\u{a0}\u{7cd}\x03\x02\x02\x02\u{a2}\u{7d4}\x03\x02\
	\x02\x02\u{a4}\u{7d6}\x03\x02\x02\x02\u{a6}\u{7e2}\x03\x02\x02\x02\u{a8}\
	\u{7e4}\x03\x02\x02\x02\u{aa}\u{7ec}\x03\x02\x02\x02\u{ac}\u{7f7}\x03\x02\
	\x02\x02\u{ae}\u{7f9}\x03\x02\x02\x02\u{b0}\u{819}\x03\x02\x02\x02\u{b2}\
	\u{820}\x03\x02\x02\x02\u{b4}\u{822}\x03\x02\x02\x02\u{b6}\u{83d}\x03\x02\
	\x02\x02\u{b8}\u{83f}\x03\x02\x02\x02\u{ba}\u{842}\x03\x02\x02\x02\u{bc}\
	\u{859}\x03\x02\x02\x02\u{be}\u{85b}\x03\x02\x02\x02\u{c0}\u{871}\x03\x02\
	\x02\x02\u{c2}\u{87d}\x03\x02\x02\x02\u{c4}\u{882}\x03\x02\x02\x02\u{c6}\
	\u{889}\x03\x02\x02\x02\u{c8}\u{8d7}\x03\x02\x02\x02\u{ca}\u{8ee}\x03\x02\
	\x02\x02\u{cc}\u{8f0}\x03\x02\x02\x02\u{ce}\u{8f4}\x03\x02\x02\x02\u{d0}\
	\u{904}\x03\x02\x02\x02\u{d2}\u{90a}\x03\x02\x02\x02\u{d4}\u{922}\x03\x02\
	\x02\x02\u{d6}\u{924}\x03\x02\x02\x02\u{d8}\u{97a}\x03\x02\x02\x02\u{da}\
	\u{983}\x03\x02\x02\x02\u{dc}\u{bc2}\x03\x02\x02\x02\u{de}\u{bd8}\x03\x02\
	\x02\x02\u{e0}\u{bdb}\x03\x02\x02\x02\u{e2}\u{be5}\x03\x02\x02\x02\u{e4}\
	\u{bf1}\x03\x02\x02\x02\u{e6}\u{bf9}\x03\x02\x02\x02\u{e8}\u{bfc}\x03\x02\
	\x02\x02\u{ea}\u{c03}\x03\x02\x02\x02\u{ec}\u{c08}\x03\x02\x02\x02\u{ee}\
	\u{c1c}\x03\x02\x02\x02\u{f0}\u{c21}\x03\x02\x02\x02\u{f2}\u{c26}\x03\x02\
	\x02\x02\u{f4}\u{c2a}\x03\x02\x02\x02\u{f6}\u{c30}\x03\x02\x02\x02\u{f8}\
	\u{c3d}\x03\x02\x02\x02\u{fa}\u{c45}\x03\x02\x02\x02\u{fc}\u{c52}\x03\x02\
	\x02\x02\u{fe}\u{c54}\x03\x02\x02\x02\u{100}\u{c5a}\x03\x02\x02\x02\u{102}\
	\u{c63}\x03\x02\x02\x02\u{104}\u{c6e}\x03\x02\x02\x02\u{106}\u{c70}\x03\
	\x02\x02\x02\u{108}\u{c72}\x03\x02\x02\x02\u{10a}\u{c74}\x03\x02\x02\x02\
	\u{10c}\u{c76}\x03\x02\x02\x02\u{10e}\u{c83}\x03\x02\x02\x02\u{110}\u{c85}\
	\x03\x02\x02\x02\u{112}\u{c87}\x03\x02\x02\x02\u{114}\u{cde}\x03\x02\x02\
	\x02\u{116}\u{ce4}\x03\x02\x02\x02\u{118}\u{ce8}\x03\x02\x02\x02\u{11a}\
	\u{cea}\x03\x02\x02\x02\u{11c}\u{cef}\x03\x02\x02\x02\u{11e}\u{cf5}\x03\
	\x02\x02\x02\u{120}\u{cfd}\x03\x02\x02\x02\u{122}\u{d17}\x03\x02\x02\x02\
	\u{124}\u{d22}\x03\x02\x02\x02\u{126}\u{d24}\x03\x02\x02\x02\u{128}\u{d4f}\
	\x03\x02\x02\x02\u{12a}\u{d72}\x03\x02\x02\x02\u{12c}\u{d79}\x03\x02\x02\
	\x02\u{12e}\u{d82}\x03\x02\x02\x02\u{130}\u{d84}\x03\x02\x02\x02\u{132}\
	\u{d86}\x03\x02\x02\x02\u{134}\u{d8e}\x03\x02\x02\x02\u{136}\u{d90}\x03\
	\x02\x02\x02\u{138}\u{d96}\x03\x02\x02\x02\u{13a}\u{d9d}\x03\x02\x02\x02\
	\u{13c}\u{dae}\x03\x02\x02\x02\u{13e}\u{db0}\x03\x02\x02\x02\u{140}\u{db2}\
	\x03\x02\x02\x02\u{142}\u{db4}\x03\x02\x02\x02\u{144}\u{dc3}\x03\x02\x02\
	\x02\u{146}\u{dc5}\x03\x02\x02\x02\u{148}\u{dc7}\x03\x02\x02\x02\u{14a}\
	\u{14c}\x05\x0c\x07\x02\u{14b}\u{14a}\x03\x02\x02\x02\u{14b}\u{14c}\x03\
	\x02\x02\x02\u{14c}\u{153}\x03\x02\x02\x02\u{14d}\u{14f}\x07\u{1a3}\x02\
	\x02\u{14e}\u{150}\x05\x0c\x07\x02\u{14f}\u{14e}\x03\x02\x02\x02\u{14f}\
	\u{150}\x03\x02\x02\x02\u{150}\u{152}\x03\x02\x02\x02\u{151}\u{14d}\x03\
	\x02\x02\x02\u{152}\u{155}\x03\x02\x02\x02\u{153}\u{151}\x03\x02\x02\x02\
	\u{153}\u{154}\x03\x02\x02\x02\u{154}\u{156}\x03\x02\x02\x02\u{155}\u{153}\
	\x03\x02\x02\x02\u{156}\u{157}\x07\x02\x02\x03\u{157}\x03\x03\x02\x02\x02\
	\u{158}\u{15a}\x05\x0c\x07\x02\u{159}\u{158}\x03\x02\x02\x02\u{159}\u{15a}\
	\x03\x02\x02\x02\u{15a}\u{15c}\x03\x02\x02\x02\u{15b}\u{15d}\x07\u{1a3}\
	\x02\x02\u{15c}\u{15b}\x03\x02\x02\x02\u{15c}\u{15d}\x03\x02\x02\x02\u{15d}\
	\u{15e}\x03\x02\x02\x02\u{15e}\u{15f}\x07\x02\x02\x03\u{15f}\x05\x03\x02\
	\x02\x02\u{160}\u{161}\x05\u{d0}\x69\x02\u{161}\u{162}\x07\x02\x02\x03\u{162}\
	\x07\x03\x02\x02\x02\u{163}\u{164}\x05\u{132}\u{9a}\x02\u{164}\u{165}\x07\
	\x02\x02\x03\u{165}\x09\x03\x02\x02\x02\u{166}\u{167}\x05\u{114}\u{8b}\x02\
	\u{167}\u{168}\x07\x02\x02\x03\u{168}\x0b\x03\x02\x02\x02\u{169}\u{487}\
	\x05\x26\x14\x02\u{16a}\u{16b}\x07\u{171}\x02\x02\u{16b}\u{487}\x05\u{13c}\
	\u{9f}\x02\u{16c}\u{16d}\x07\u{171}\x02\x02\u{16d}\u{16e}\x05\u{13c}\u{9f}\
	\x02\u{16e}\u{16f}\x07\u{195}\x02\x02\u{16f}\u{170}\x05\u{13c}\u{9f}\x02\
	\u{170}\u{487}\x03\x02\x02\x02\u{171}\u{172}\x07\x63\x02\x02\u{172}\u{175}\
	\x07\u{133}\x02\x02\u{173}\u{174}\x07\u{93}\x02\x02\u{174}\u{176}\x07\x70\
	\x02\x02\u{175}\u{173}\x03\x02\x02\x02\u{175}\u{176}\x03\x02\x02\x02\u{176}\
	\u{177}\x03\x02\x02\x02\u{177}\u{17b}\x05\u{132}\u{9a}\x02\u{178}\u{17a}\
	\x0a\x02\x02\x02\u{179}\u{178}\x03\x02\x02\x02\u{17a}\u{17d}\x03\x02\x02\
	\x02\u{17b}\u{179}\x03\x02\x02\x02\u{17b}\u{17c}\x03\x02\x02\x02\u{17c}\
	\u{487}\x03\x02\x02\x02\u{17d}\u{17b}\x03\x02\x02\x02\u{17e}\u{17f}\x07\
	\x12\x02\x02\u{17f}\u{180}\x07\u{133}\x02\x02\u{180}\u{181}\x05\u{132}\u{9a}\
	\x02\u{181}\u{182}\x07\u{11a}\x02\x02\u{182}\u{183}\x07\u{15a}\x02\x02\u{183}\
	\u{184}\x05\u{13c}\u{9f}\x02\u{184}\u{487}\x03\x02\x02\x02\u{185}\u{186}\
	\x07\x12\x02\x02\u{186}\u{187}\x07\u{133}\x02\x02\u{187}\u{188}\x05\u{132}\
	\u{9a}\x02\u{188}\u{189}\x07\u{13d}\x02\x02\u{189}\u{18a}\x07\x1d\x02\x02\
	\u{18a}\u{18b}\x05\u{13a}\u{9e}\x02\u{18b}\u{487}\x03\x02\x02\x02\u{18c}\
	\u{18d}\x07\x63\x02\x02\u{18d}\u{18e}\x07\u{14e}\x02\x02\u{18e}\u{487}\x05\
	\u{132}\u{9a}\x02\u{18f}\u{190}\x07\x63\x02\x02\u{190}\u{191}\x07\u{17f}\
	\x02\x02\u{191}\u{487}\x05\u{132}\u{9a}\x02\u{192}\u{193}\x07\x45\x02\x02\
	\u{193}\u{194}\x07\x72\x02\x02\u{194}\u{195}\x07\u{14e}\x02\x02\u{195}\u{19d}\
	\x05\u{132}\u{9a}\x02\u{196}\u{197}\x07\u{191}\x02\x02\u{197}\u{199}\x05\
	\x0e\x08\x02\u{198}\u{19a}\x07\x37\x02\x02\u{199}\u{198}\x03\x02\x02\x02\
	\u{199}\u{19a}\x03\x02\x02\x02\u{19a}\u{19b}\x03\x02\x02\x02\u{19b}\u{19c}\
	\x07\u{192}\x02\x02\u{19c}\u{19e}\x03\x02\x02\x02\u{19d}\u{196}\x03\x02\
	\x02\x02\u{19d}\u{19e}\x03\x02\x02\x02\u{19e}\u{19f}\x03\x02\x02\x02\u{19f}\
	\u{1a0}\x05\x12\x0a\x02\u{1a0}\u{487}\x03\x02\x02\x02\u{1a1}\u{1a2}\x07\
	\x45\x02\x02\u{1a2}\u{1a3}\x07\x72\x02\x02\u{1a3}\u{1a4}\x07\u{14e}\x02\
	\x02\u{1a4}\u{1a5}\x05\u{132}\u{9a}\x02\u{1a5}\u{1a6}\x05\x14\x0b\x02\u{1a6}\
	\u{1ac}\x07\x19\x02\x02\u{1a7}\u{1ad}\x05\x26\x14\x02\u{1a8}\u{1a9}\x07\
	\u{191}\x02\x02\u{1a9}\u{1aa}\x05\x26\x14\x02\u{1aa}\u{1ab}\x07\u{192}\x02\
	\x02\u{1ab}\u{1ad}\x03\x02\x02\x02\u{1ac}\u{1a7}\x03\x02\x02\x02\u{1ac}\
	\u{1a8}\x03\x02\x02\x02\u{1ad}\u{487}\x03\x02\x02\x02\u{1ae}\u{1b0}\x07\
	\x45\x02\x02\u{1af}\u{1b1}\x07\u{c3}\x02\x02\u{1b0}\u{1af}\x03\x02\x02\x02\
	\u{1b0}\u{1b1}\x03\x02\x02\x02\u{1b1}\u{1b3}\x03\x02\x02\x02\u{1b2}\u{1b4}\
	\x09\x03\x02\x02\u{1b3}\u{1b2}\x03\x02\x02\x02\u{1b3}\u{1b4}\x03\x02\x02\
	\x02\u{1b4}\u{1b5}\x03\x02\x02\x02\u{1b5}\u{1b6}\x07\u{14e}\x02\x02\u{1b6}\
	\u{1b8}\x05\u{132}\u{9a}\x02\u{1b7}\u{1b9}\x05\u{b6}\x5c\x02\u{1b8}\u{1b7}\
	\x03\x02\x02\x02\u{1b8}\u{1b9}\x03\x02\x02\x02\u{1b9}\u{1bc}\x03\x02\x02\
	\x02\u{1ba}\u{1bb}\x07\x1f\x02\x02\u{1bb}\u{1bd}\x09\x04\x02\x02\u{1bc}\
	\u{1ba}\x03\x02\x02\x02\u{1bc}\u{1bd}\x03\x02\x02\x02\u{1bd}\u{1be}\x03\
	\x02\x02\x02\u{1be}\u{1bf}\x05\x44\x23\x02\u{1bf}\u{1c5}\x07\x19\x02\x02\
	\u{1c0}\u{1c6}\x05\x26\x14\x02\u{1c1}\u{1c2}\x07\u{191}\x02\x02\u{1c2}\u{1c3}\
	\x05\x26\x14\x02\u{1c3}\u{1c4}\x07\u{192}\x02\x02\u{1c4}\u{1c6}\x03\x02\
	\x02\x02\u{1c5}\u{1c0}\x03\x02\x02\x02\u{1c5}\u{1c1}\x03\x02\x02\x02\u{1c6}\
	\u{1cb}\x03\x02\x02\x02\u{1c7}\u{1c8}\x07\u{185}\x02\x02\u{1c8}\u{1c9}\x07\
	\u{e2}\x02\x02\u{1c9}\u{1ca}\x07\u{133}\x02\x02\u{1ca}\u{1cc}\x07\x24\x02\
	\x02\u{1cb}\u{1c7}\x03\x02\x02\x02\u{1cb}\u{1cc}\x03\x02\x02\x02\u{1cc}\
	\u{487}\x03\x02\x02\x02\u{1cd}\u{1cf}\x07\x45\x02\x02\u{1ce}\u{1d0}\x07\
	\u{c3}\x02\x02\u{1cf}\u{1ce}\x03\x02\x02\x02\u{1cf}\u{1d0}\x03\x02\x02\x02\
	\u{1d0}\u{1d2}\x03\x02\x02\x02\u{1d1}\u{1d3}\x09\x03\x02\x02\u{1d2}\u{1d1}\
	\x03\x02\x02\x02\u{1d2}\u{1d3}\x03\x02\x02\x02\u{1d3}\u{1d4}\x03\x02\x02\
	\x02\u{1d4}\u{1d8}\x07\u{14e}\x02\x02\u{1d5}\u{1d6}\x07\u{93}\x02\x02\u{1d6}\
	\u{1d7}\x07\u{e5}\x02\x02\u{1d7}\u{1d9}\x07\x70\x02\x02\u{1d8}\u{1d5}\x03\
	\x02\x02\x02\u{1d8}\u{1d9}\x03\x02\x02\x02\u{1d9}\u{1da}\x03\x02\x02\x02\
	\u{1da}\u{1e2}\x05\u{132}\u{9a}\x02\u{1db}\u{1dc}\x07\u{191}\x02\x02\u{1dc}\
	\u{1de}\x05\x0e\x08\x02\u{1dd}\u{1df}\x07\x37\x02\x02\u{1de}\u{1dd}\x03\
	\x02\x02\x02\u{1de}\u{1df}\x03\x02\x02\x02\u{1df}\u{1e0}\x03\x02\x02\x02\
	\u{1e0}\u{1e1}\x07\u{192}\x02\x02\u{1e1}\u{1e3}\x03\x02\x02\x02\u{1e2}\u{1db}\
	\x03\x02\x02\x02\u{1e2}\u{1e3}\x03\x02\x02\x02\u{1e3}\u{1e6}\x03\x02\x02\
	\x02\u{1e4}\u{1e5}\x07\x1f\x02\x02\u{1e5}\u{1e7}\x09\x04\x02\x02\u{1e6}\
	\u{1e4}\x03\x02\x02\x02\u{1e6}\u{1e7}\x03\x02\x02\x02\u{1e7}\u{1e8}\x03\
	\x02\x02\x02\u{1e8}\u{1e9}\x05\x44\x23\x02\u{1e9}\u{487}\x03\x02\x02\x02\
	\u{1ea}\u{1eb}\x07\u{9f}\x02\x02\u{1eb}\u{1ec}\x07\u{a2}\x02\x02\u{1ec}\
	\u{1ee}\x05\u{132}\u{9a}\x02\u{1ed}\u{1ef}\x05\u{b6}\x5c\x02\u{1ee}\u{1ed}\
	\x03\x02\x02\x02\u{1ee}\u{1ef}\x03\x02\x02\x02\u{1ef}\u{1f5}\x03\x02\x02\
	\x02\u{1f0}\u{1f6}\x05\x26\x14\x02\u{1f1}\u{1f2}\x07\u{191}\x02\x02\u{1f2}\
	\u{1f3}\x05\x26\x14\x02\u{1f3}\u{1f4}\x07\u{192}\x02\x02\u{1f4}\u{1f6}\x03\
	\x02\x02\x02\u{1f5}\u{1f0}\x03\x02\x02\x02\u{1f5}\u{1f1}\x03\x02\x02\x02\
	\u{1f6}\u{487}\x03\x02\x02\x02\u{1f7}\u{1fa}\x07\x45\x02\x02\u{1f8}\u{1f9}\
	\x07\u{f2}\x02\x02\u{1f9}\u{1fb}\x07\u{11c}\x02\x02\u{1fa}\u{1f8}\x03\x02\
	\x02\x02\u{1fa}\u{1fb}\x03\x02\x02\x02\u{1fb}\u{1fc}\x03\x02\x02\x02\u{1fc}\
	\u{1fd}\x07\u{ce}\x02\x02\u{1fd}\u{200}\x07\u{17f}\x02\x02\u{1fe}\u{1ff}\
	\x07\x1f\x02\x02\u{1ff}\u{201}\x09\x04\x02\x02\u{200}\u{1fe}\x03\x02\x02\
	\x02\u{200}\u{201}\x03\x02\x02\x02\u{201}\u{205}\x03\x02\x02\x02\u{202}\
	\u{203}\x07\x1e\x02\x02\u{203}\u{204}\x07\u{119}\x02\x02\u{204}\u{206}\x09\
	\x04\x02\x02\u{205}\u{202}\x03\x02\x02\x02\u{205}\u{206}\x03\x02\x02\x02\
	\u{206}\u{20a}\x03\x02\x02\x02\u{207}\u{208}\x07\u{93}\x02\x02\u{208}\u{209}\
	\x07\u{e5}\x02\x02\u{209}\u{20b}\x07\x70\x02\x02\u{20a}\u{207}\x03\x02\x02\
	\x02\u{20a}\u{20b}\x03\x02\x02\x02\u{20b}\u{20c}\x03\x02\x02\x02\u{20c}\
	\u{20d}\x05\u{132}\u{9a}\x02\u{20d}\u{211}\x05\x44\x23\x02\u{20e}\u{20f}\
	\x07\u{84}\x02\x02\u{20f}\u{210}\x07\u{105}\x02\x02\u{210}\u{212}\x05\u{10c}\
	\u{87}\x02\u{211}\u{20e}\x03\x02\x02\x02\u{211}\u{212}\x03\x02\x02\x02\u{212}\
	\u{215}\x03\x02\x02\x02\u{213}\u{214}\x07\x38\x02\x02\u{214}\u{216}\x05\
	\u{102}\u{82}\x02\u{215}\u{213}\x03\x02\x02\x02\u{215}\u{216}\x03\x02\x02\
	\x02\u{216}\u{219}\x03\x02\x02\x02\u{217}\u{218}\x07\u{185}\x02\x02\u{218}\
	\u{21a}\x05\x46\x24\x02\u{219}\u{217}\x03\x02\x02\x02\u{219}\u{21a}\x03\
	\x02\x02\x02\u{21a}\u{21b}\x03\x02\x02\x02\u{21b}\u{21c}\x07\x19\x02\x02\
	\u{21c}\u{21d}\x05\x26\x14\x02\u{21d}\u{487}\x03\x02\x02\x02\u{21e}\u{221}\
	\x07\x45\x02\x02\u{21f}\u{220}\x07\u{f2}\x02\x02\u{220}\u{222}\x07\u{11c}\
	\x02\x02\u{221}\u{21f}\x03\x02\x02\x02\u{221}\u{222}\x03\x02\x02\x02\u{222}\
	\u{223}\x03\x02\x02\x02\u{223}\u{224}\x07\u{17f}\x02\x02\u{224}\u{226}\x05\
	\u{132}\u{9a}\x02\u{225}\u{227}\x05\u{b6}\x5c\x02\u{226}\u{225}\x03\x02\
	\x02\x02\u{226}\u{227}\x03\x02\x02\x02\u{227}\u{22a}\x03\x02\x02\x02\u{228}\
	\u{229}\x07\x38\x02\x02\u{229}\u{22b}\x05\u{102}\u{82}\x02\u{22a}\u{228}\
	\x03\x02\x02\x02\u{22a}\u{22b}\x03\x02\x02\x02\u{22b}\u{22e}\x03\x02\x02\
	\x02\u{22c}\u{22d}\x07\u{135}\x02\x02\u{22d}\u{22f}\x09\x05\x02\x02\u{22e}\
	\u{22c}\x03\x02\x02\x02\u{22e}\u{22f}\x03\x02\x02\x02\u{22f}\u{230}\x03\
	\x02\x02\x02\u{230}\u{236}\x07\x19\x02\x02\u{231}\u{237}\x05\x26\x14\x02\
	\u{232}\u{233}\x07\u{191}\x02\x02\u{233}\u{234}\x05\x26\x14\x02\u{234}\u{235}\
	\x07\u{192}\x02\x02\u{235}\u{237}\x03\x02\x02\x02\u{236}\u{231}\x03\x02\
	\x02\x02\u{236}\u{232}\x03\x02\x02\x02\u{237}\u{23c}\x03\x02\x02\x02\u{238}\
	\u{239}\x07\u{185}\x02\x02\u{239}\u{23a}\x07\u{e2}\x02\x02\u{23a}\u{23b}\
	\x07\u{133}\x02\x02\u{23b}\u{23d}\x07\x24\x02\x02\u{23c}\u{238}\x03\x02\
	\x02\x02\u{23c}\u{23d}\x03\x02\x02\x02\u{23d}\u{487}\x03\x02\x02\x02\u{23e}\
	\u{23f}\x07\u{13f}\x02\x02\u{23f}\u{240}\x07\x36\x02\x02\u{240}\u{241}\x07\
	\x7f\x02\x02\u{241}\u{242}\x07\u{14e}\x02\x02\u{242}\u{487}\x05\u{132}\u{9a}\
	\x02\u{243}\u{246}\x07\x45\x02\x02\u{244}\u{245}\x07\u{f2}\x02\x02\u{245}\
	\u{247}\x07\u{11c}\x02\x02\u{246}\u{244}\x03\x02\x02\x02\u{246}\u{247}\x03\
	\x02\x02\x02\u{247}\u{249}\x03\x02\x02\x02\u{248}\u{24a}\x07\x72\x02\x02\
	\u{249}\u{248}\x03\x02\x02\x02\u{249}\u{24a}\x03\x02\x02\x02\u{24a}\u{24b}\
	\x03\x02\x02\x02\u{24b}\u{24c}\x07\u{81}\x02\x02\u{24c}\u{24d}\x05\u{132}\
	\u{9a}\x02\u{24d}\u{259}\x07\u{191}\x02\x02\u{24e}\u{253}\x05\u{e8}\x75\
	\x02\u{24f}\u{250}\x07\x37\x02\x02\u{250}\u{252}\x05\u{e8}\x75\x02\u{251}\
	\u{24f}\x03\x02\x02\x02\u{252}\u{255}\x03\x02\x02\x02\u{253}\u{251}\x03\
	\x02\x02\x02\u{253}\u{254}\x03\x02\x02\x02\u{254}\u{257}\x03\x02\x02\x02\
	\u{255}\u{253}\x03\x02\x02\x02\u{256}\u{258}\x07\x37\x02\x02\u{257}\u{256}\
	\x03\x02\x02\x02\u{257}\u{258}\x03\x02\x02\x02\u{258}\u{25a}\x03\x02\x02\
	\x02\u{259}\u{24e}\x03\x02\x02\x02\u{259}\u{25a}\x03\x02\x02\x02\u{25a}\
	\u{25b}\x03\x02\x02\x02\u{25b}\u{25c}\x07\u{192}\x02\x02\u{25c}\u{25d}\x07\
	\u{122}\x02\x02\u{25d}\u{25f}\x05\u{114}\u{8b}\x02\u{25e}\u{260}\x05\x24\
	\x13\x02\u{25f}\u{25e}\x03\x02\x02\x02\u{260}\u{261}\x03\x02\x02\x02\u{261}\
	\u{25f}\x03\x02\x02\x02\u{261}\u{262}\x03\x02\x02\x02\u{262}\u{487}\x03\
	\x02\x02\x02\u{263}\u{267}\x07\u{d4}\x02\x02\u{264}\u{266}\x0a\x02\x02\x02\
	\u{265}\u{264}\x03\x02\x02\x02\u{266}\u{269}\x03\x02\x02\x02\u{267}\u{265}\
	\x03\x02\x02\x02\u{267}\u{268}\x03\x02\x02\x02\u{268}\u{487}\x03\x02\x02\
	\x02\u{269}\u{267}\x03\x02\x02\x02\u{26a}\u{26c}\x07\x0c\x02\x02\u{26b}\
	\u{26d}\x09\x06\x02\x02\u{26c}\u{26b}\x03\x02\x02\x02\u{26c}\u{26d}\x03\
	\x02\x02\x02\u{26d}\u{487}\x03\x02\x02\x02\u{26e}\u{272}\x07\x12\x02\x02\
	\u{26f}\u{271}\x0a\x02\x02\x02\u{270}\u{26f}\x03\x02\x02\x02\u{271}\u{274}\
	\x03\x02\x02\x02\u{272}\u{270}\x03\x02\x02\x02\u{272}\u{273}\x03\x02\x02\
	\x02\u{273}\u{487}\x03\x02\x02\x02\u{274}\u{272}\x03\x02\x02\x02\u{275}\
	\u{279}\x07\x1c\x02\x02\u{276}\u{278}\x0a\x02\x02\x02\u{277}\u{276}\x03\
	\x02\x02\x02\u{278}\u{27b}\x03\x02\x02\x02\u{279}\u{277}\x03\x02\x02\x02\
	\u{279}\u{27a}\x03\x02\x02\x02\u{27a}\u{487}\x03\x02\x02\x02\u{27b}\u{279}\
	\x03\x02\x02\x02\u{27c}\u{280}\x07\x20\x02\x02\u{27d}\u{27f}\x0a\x02\x02\
	\x02\u{27e}\u{27d}\x03\x02\x02\x02\u{27f}\u{282}\x03\x02\x02\x02\u{280}\
	\u{27e}\x03\x02\x02\x02\u{280}\u{281}\x03\x02\x02\x02\u{281}\u{487}\x03\
	\x02\x02\x02\u{282}\u{280}\x03\x02\x02\x02\u{283}\u{287}\x07\x29\x02\x02\
	\u{284}\u{286}\x0a\x02\x02\x02\u{285}\u{284}\x03\x02\x02\x02\u{286}\u{289}\
	\x03\x02\x02\x02\u{287}\u{285}\x03\x02\x02\x02\u{287}\u{288}\x03\x02\x02\
	\x02\u{288}\u{487}\x03\x02\x02\x02\u{289}\u{287}\x03\x02\x02\x02\u{28a}\
	\u{28e}\x07\x32\x02\x02\u{28b}\u{28d}\x0a\x02\x02\x02\u{28c}\u{28b}\x03\
	\x02\x02\x02\u{28d}\u{290}\x03\x02\x02\x02\u{28e}\u{28c}\x03\x02\x02\x02\
	\u{28e}\u{28f}\x03\x02\x02\x02\u{28f}\u{487}\x03\x02\x02\x02\u{290}\u{28e}\
	\x03\x02\x02\x02\u{291}\u{295}\x07\x43\x02\x02\u{292}\u{294}\x0a\x02\x02\
	\x02\u{293}\u{292}\x03\x02\x02\x02\u{294}\u{297}\x03\x02\x02\x02\u{295}\
	\u{293}\x03\x02\x02\x02\u{295}\u{296}\x03\x02\x02\x02\u{296}\u{487}\x03\
	\x02\x02\x02\u{297}\u{295}\x03\x02\x02\x02\u{298}\u{29c}\x07\u{13d}\x02\
	\x02\u{299}\u{29b}\x0a\x02\x02\x02\u{29a}\u{299}\x03\x02\x02\x02\u{29b}\
	\u{29e}\x03\x02\x02\x02\u{29c}\u{29a}\x03\x02\x02\x02\u{29c}\u{29d}\x03\
	\x02\x02\x02\u{29d}\u{487}\x03\x02\x02\x02\u{29e}\u{29c}\x03\x02\x02\x02\
	\u{29f}\u{2a2}\x07\x45\x02\x02\u{2a0}\u{2a1}\x07\u{f2}\x02\x02\u{2a1}\u{2a3}\
	\x07\u{11c}\x02\x02\u{2a2}\u{2a0}\x03\x02\x02\x02\u{2a2}\u{2a3}\x03\x02\
	\x02\x02\u{2a3}\u{2a4}\x03\x02\x02\x02\u{2a4}\u{2a8}\x07\u{133}\x02\x02\
	\u{2a5}\u{2a7}\x0a\x02\x02\x02\u{2a6}\u{2a5}\x03\x02\x02\x02\u{2a7}\u{2aa}\
	\x03\x02\x02\x02\u{2a8}\u{2a6}\x03\x02\x02\x02\u{2a8}\u{2a9}\x03\x02\x02\
	\x02\u{2a9}\u{487}\x03\x02\x02\x02\u{2aa}\u{2a8}\x03\x02\x02\x02\u{2ab}\
	\u{2af}\x07\x63\x02\x02\u{2ac}\u{2ae}\x0a\x02\x02\x02\u{2ad}\u{2ac}\x03\
	\x02\x02\x02\u{2ae}\u{2b1}\x03\x02\x02\x02\u{2af}\u{2ad}\x03\x02\x02\x02\
	\u{2af}\u{2b0}\x03\x02\x02\x02\u{2b0}\u{487}\x03\x02\x02\x02\u{2b1}\u{2af}\
	\x03\x02\x02\x02\u{2b2}\u{2b6}\x07\x56\x02\x02\u{2b3}\u{2b5}\x0a\x02\x02\
	\x02\u{2b4}\u{2b3}\x03\x02\x02\x02\u{2b5}\u{2b8}\x03\x02\x02\x02\u{2b6}\
	\u{2b4}\x03\x02\x02\x02\u{2b6}\u{2b7}\x03\x02\x02\x02\u{2b7}\u{487}\x03\
	\x02\x02\x02\u{2b8}\u{2b6}\x03\x02\x02\x02\u{2b9}\u{2bd}\x07\u{160}\x02\
	\x02\u{2ba}\u{2bc}\x0a\x02\x02\x02\u{2bb}\u{2ba}\x03\x02\x02\x02\u{2bc}\
	\u{2bf}\x03\x02\x02\x02\u{2bd}\u{2bb}\x03\x02\x02\x02\u{2bd}\u{2be}\x03\
	\x02\x02\x02\u{2be}\u{487}\x03\x02\x02\x02\u{2bf}\u{2bd}\x03\x02\x02\x02\
	\u{2c0}\u{2c4}\x07\x38\x02\x02\u{2c1}\u{2c3}\x0a\x02\x02\x02\u{2c2}\u{2c1}\
	\x03\x02\x02\x02\u{2c3}\u{2c6}\x03\x02\x02\x02\u{2c4}\u{2c2}\x03\x02\x02\
	\x02\u{2c4}\u{2c5}\x03\x02\x02\x02\u{2c5}\u{487}\x03\x02\x02\x02\u{2c6}\
	\u{2c4}\x03\x02\x02\x02\u{2c7}\u{2c8}\x07\x12\x02\x02\u{2c8}\u{2cb}\x07\
	\u{14e}\x02\x02\u{2c9}\u{2ca}\x07\u{93}\x02\x02\u{2ca}\u{2cc}\x07\x70\x02\
	\x02\u{2cb}\u{2c9}\x03\x02\x02\x02\u{2cb}\u{2cc}\x03\x02\x02\x02\u{2cc}\
	\u{2cd}\x03\x02\x02\x02\u{2cd}\u{2ce}\x05\u{132}\u{9a}\x02\u{2ce}\u{2cf}\
	\x07\u{11a}\x02\x02\u{2cf}\u{2d0}\x07\u{15a}\x02\x02\u{2d0}\u{2d1}\x05\u{132}\
	\u{9a}\x02\u{2d1}\u{487}\x03\x02\x02\x02\u{2d2}\u{2d3}\x07\x12\x02\x02\u{2d3}\
	\u{2d6}\x07\u{14e}\x02\x02\u{2d4}\u{2d5}\x07\u{93}\x02\x02\u{2d5}\u{2d7}\
	\x07\x70\x02\x02\u{2d6}\u{2d4}\x03\x02\x02\x02\u{2d6}\u{2d7}\x03\x02\x02\
	\x02\u{2d7}\u{2d8}\x03\x02\x02\x02\u{2d8}\u{2d9}\x05\u{132}\u{9a}\x02\u{2d9}\
	\u{2da}\x07\x0e\x02\x02\u{2da}\u{2de}\x07\x35\x02\x02\u{2db}\u{2dc}\x07\
	\u{93}\x02\x02\u{2dc}\u{2dd}\x07\u{e5}\x02\x02\u{2dd}\u{2df}\x07\x70\x02\
	\x02\u{2de}\u{2db}\x03\x02\x02\x02\u{2de}\u{2df}\x03\x02\x02\x02\u{2df}\
	\u{2e0}\x03\x02\x02\x02\u{2e0}\u{2e1}\x05\x2e\x18\x02\u{2e1}\u{487}\x03\
	\x02\x02\x02\u{2e2}\u{2e3}\x07\x12\x02\x02\u{2e3}\u{2e6}\x07\u{14e}\x02\
	\x02\u{2e4}\u{2e5}\x07\u{93}\x02\x02\u{2e5}\u{2e7}\x07\x70\x02\x02\u{2e6}\
	\u{2e4}\x03\x02\x02\x02\u{2e6}\u{2e7}\x03\x02\x02\x02\u{2e7}\u{2e8}\x03\
	\x02\x02\x02\u{2e8}\u{2e9}\x05\u{132}\u{9a}\x02\u{2e9}\u{2ea}\x07\u{11a}\
	\x02\x02\u{2ea}\u{2ed}\x07\x35\x02\x02\u{2eb}\u{2ec}\x07\u{93}\x02\x02\u{2ec}\
	\u{2ee}\x07\x70\x02\x02\u{2ed}\u{2eb}\x03\x02\x02\x02\u{2ed}\u{2ee}\x03\
	\x02\x02\x02\u{2ee}\u{2ef}\x03\x02\x02\x02\u{2ef}\u{2f0}\x05\u{13c}\u{9f}\
	\x02\u{2f0}\u{2f1}\x07\u{15a}\x02\x02\u{2f1}\u{2f2}\x05\u{13c}\u{9f}\x02\
	\u{2f2}\u{487}\x03\x02\x02\x02\u{2f3}\u{2f4}\x07\x12\x02\x02\u{2f4}\u{2f7}\
	\x07\u{14e}\x02\x02\u{2f5}\u{2f6}\x07\u{93}\x02\x02\u{2f6}\u{2f8}\x07\x70\
	\x02\x02\u{2f7}\u{2f5}\x03\x02\x02\x02\u{2f7}\u{2f8}\x03\x02\x02\x02\u{2f8}\
	\u{2f9}\x03\x02\x02\x02\u{2f9}\u{2fa}\x05\u{132}\u{9a}\x02\u{2fa}\u{2fb}\
	\x07\x63\x02\x02\u{2fb}\u{2fe}\x07\x35\x02\x02\u{2fc}\u{2fd}\x07\u{93}\x02\
	\x02\u{2fd}\u{2ff}\x07\x70\x02\x02\u{2fe}\u{2fc}\x03\x02\x02\x02\u{2fe}\
	\u{2ff}\x03\x02\x02\x02\u{2ff}\u{300}\x03\x02\x02\x02\u{300}\u{301}\x05\
	\u{132}\u{9a}\x02\u{301}\u{487}\x03\x02\x02\x02\u{302}\u{303}\x07\x12\x02\
	\x02\u{303}\u{306}\x07\u{14e}\x02\x02\u{304}\u{305}\x07\u{93}\x02\x02\u{305}\
	\u{307}\x07\x70\x02\x02\u{306}\u{304}\x03\x02\x02\x02\u{306}\u{307}\x03\
	\x02\x02\x02\u{307}\u{308}\x03\x02\x02\x02\u{308}\u{309}\x05\u{132}\u{9a}\
	\x02\u{309}\u{30a}\x07\x12\x02\x02\u{30a}\u{30b}\x07\x35\x02\x02\u{30b}\
	\u{30c}\x05\u{13c}\u{9f}\x02\u{30c}\u{30d}\x07\u{13d}\x02\x02\u{30d}\u{30e}\
	\x07\x4a\x02\x02\u{30e}\u{30f}\x07\u{163}\x02\x02\u{30f}\u{310}\x05\u{114}\
	\u{8b}\x02\u{310}\u{487}\x03\x02\x02\x02\u{311}\u{312}\x07\x12\x02\x02\u{312}\
	\u{313}\x07\u{14e}\x02\x02\u{313}\u{314}\x05\u{132}\u{9a}\x02\u{314}\u{315}\
	\x07\u{13d}\x02\x02\u{315}\u{316}\x07\x1d\x02\x02\u{316}\u{317}\x05\u{13a}\
	\u{9e}\x02\u{317}\u{487}\x03\x02\x02\x02\u{318}\u{319}\x07\x12\x02\x02\u{319}\
	\u{31a}\x07\u{14e}\x02\x02\u{31a}\u{31b}\x05\u{132}\u{9a}\x02\u{31b}\u{31c}\
	\x07\u{13d}\x02\x02\u{31c}\u{31d}\x07\u{111}\x02\x02\u{31d}\u{31e}\x05\x48\
	\x25\x02\u{31e}\u{487}\x03\x02\x02\x02\u{31f}\u{320}\x07\x12\x02\x02\u{320}\
	\u{321}\x07\u{14e}\x02\x02\u{321}\u{322}\x05\u{132}\u{9a}\x02\u{322}\u{323}\
	\x07\x6f\x02\x02\u{323}\u{333}\x05\u{13c}\u{9f}\x02\u{324}\u{32d}\x07\u{191}\
	\x02\x02\u{325}\u{32a}\x05\u{e2}\x72\x02\u{326}\u{327}\x07\x37\x02\x02\u{327}\
	\u{329}\x05\u{e2}\x72\x02\u{328}\u{326}\x03\x02\x02\x02\u{329}\u{32c}\x03\
	\x02\x02\x02\u{32a}\u{328}\x03\x02\x02\x02\u{32a}\u{32b}\x03\x02\x02\x02\
	\u{32b}\u{32e}\x03\x02\x02\x02\u{32c}\u{32a}\x03\x02\x02\x02\u{32d}\u{325}\
	\x03\x02\x02\x02\u{32d}\u{32e}\x03\x02\x02\x02\u{32e}\u{330}\x03\x02\x02\
	\x02\u{32f}\u{331}\x07\x37\x02\x02\u{330}\u{32f}\x03\x02\x02\x02\u{330}\
	\u{331}\x03\x02\x02\x02\u{331}\u{332}\x03\x02\x02\x02\u{332}\u{334}\x07\
	\u{192}\x02\x02\u{333}\u{324}\x03\x02\x02\x02\u{333}\u{334}\x03\x02\x02\
	\x02\u{334}\u{337}\x03\x02\x02\x02\u{335}\u{336}\x07\u{183}\x02\x02\u{336}\
	\u{338}\x05\u{d2}\x6a\x02\u{337}\u{335}\x03\x02\x02\x02\u{337}\u{338}\x03\
	\x02\x02\x02\u{338}\u{487}\x03\x02\x02\x02\u{339}\u{33d}\x07\x13\x02\x02\
	\u{33a}\u{33c}\x0a\x02\x02\x02\u{33b}\u{33a}\x03\x02\x02\x02\u{33c}\u{33f}\
	\x03\x02\x02\x02\u{33d}\u{33b}\x03\x02\x02\x02\u{33d}\u{33e}\x03\x02\x02\
	\x02\u{33e}\u{487}\x03\x02\x02\x02\u{33f}\u{33d}\x03\x02\x02\x02\u{340}\
	\u{341}\x07\u{119}\x02\x02\u{341}\u{342}\x07\u{ce}\x02\x02\u{342}\u{343}\
	\x07\u{17f}\x02\x02\u{343}\u{487}\x05\u{132}\u{9a}\x02\u{344}\u{345}\x07\
	\x12\x02\x02\u{345}\u{346}\x07\u{ce}\x02\x02\u{346}\u{349}\x07\u{17f}\x02\
	\x02\u{347}\u{348}\x07\u{93}\x02\x02\u{348}\u{34a}\x07\x70\x02\x02\u{349}\
	\u{347}\x03\x02\x02\x02\u{349}\u{34a}\x03\x02\x02\x02\u{34a}\u{34b}\x03\
	\x02\x02\x02\u{34b}\u{34c}\x05\u{132}\u{9a}\x02\u{34c}\u{34d}\x07\u{11a}\
	\x02\x02\u{34d}\u{34e}\x07\u{15a}\x02\x02\u{34e}\u{34f}\x05\u{132}\u{9a}\
	\x02\u{34f}\u{487}\x03\x02\x02\x02\u{350}\u{351}\x07\x12\x02\x02\u{351}\
	\u{352}\x07\u{ce}\x02\x02\u{352}\u{353}\x07\u{17f}\x02\x02\u{353}\u{354}\
	\x05\u{132}\u{9a}\x02\u{354}\u{355}\x07\u{13d}\x02\x02\u{355}\u{356}\x07\
	\u{111}\x02\x02\u{356}\u{357}\x05\x48\x25\x02\u{357}\u{487}\x03\x02\x02\
	\x02\u{358}\u{359}\x07\x12\x02\x02\u{359}\u{35a}\x07\u{17f}\x02\x02\u{35a}\
	\u{35b}\x05\u{132}\u{9a}\x02\u{35b}\u{35c}\x07\u{11a}\x02\x02\u{35c}\u{35d}\
	\x07\u{15a}\x02\x02\u{35d}\u{35e}\x05\u{132}\u{9a}\x02\u{35e}\u{487}\x03\
	\x02\x02\x02\u{35f}\u{360}\x07\x12\x02\x02\u{360}\u{361}\x07\u{17f}\x02\
	\x02\u{361}\u{362}\x05\u{132}\u{9a}\x02\u{362}\u{363}\x07\u{13d}\x02\x02\
	\u{363}\u{364}\x07\x1d\x02\x02\u{364}\u{365}\x05\u{13a}\u{9e}\x02\u{365}\
	\u{487}\x03\x02\x02\x02\u{366}\u{36a}\x07\x28\x02\x02\u{367}\u{369}\x0a\
	\x02\x02\x02\u{368}\u{367}\x03\x02\x02\x02\u{369}\u{36c}\x03\x02\x02\x02\
	\u{36a}\u{368}\x03\x02\x02\x02\u{36a}\u{36b}\x03\x02\x02\x02\u{36b}\u{487}\
	\x03\x02\x02\x02\u{36c}\u{36a}\x03\x02\x02\x02\u{36d}\u{36e}\x07\x45\x02\
	\x02\u{36e}\u{372}\x07\u{126}\x02\x02\u{36f}\u{371}\x0a\x02\x02\x02\u{370}\
	\u{36f}\x03\x02\x02\x02\u{371}\u{374}\x03\x02\x02\x02\u{372}\u{370}\x03\
	\x02\x02\x02\u{372}\u{373}\x03\x02\x02\x02\u{373}\u{487}\x03\x02\x02\x02\
	\u{374}\u{372}\x03\x02\x02\x02\u{375}\u{379}\x07\u{85}\x02\x02\u{376}\u{378}\
	\x0a\x02\x02\x02\u{377}\u{376}\x03\x02\x02\x02\u{378}\u{37b}\x03\x02\x02\
	\x02\u{379}\u{377}\x03\x02\x02\x02\u{379}\u{37a}\x03\x02\x02\x02\u{37a}\
	\u{487}\x03\x02\x02\x02\u{37b}\u{379}\x03\x02\x02\x02\u{37c}\u{380}\x07\
	\u{123}\x02\x02\u{37d}\u{37f}\x0a\x02\x02\x02\u{37e}\u{37d}\x03\x02\x02\
	\x02\u{37f}\u{382}\x03\x02\x02\x02\u{380}\u{37e}\x03\x02\x02\x02\u{380}\
	\u{381}\x03\x02\x02\x02\u{381}\u{487}\x03\x02\x02\x02\u{382}\u{380}\x03\
	\x02\x02\x02\u{383}\u{391}\x07\x59\x02\x02\u{384}\u{389}\x05\u{130}\u{99}\
	\x02\u{385}\u{386}\x07\x37\x02\x02\u{386}\u{388}\x05\u{130}\u{99}\x02\u{387}\
	\u{385}\x03\x02\x02\x02\u{388}\u{38b}\x03\x02\x02\x02\u{389}\u{387}\x03\
	\x02\x02\x02\u{389}\u{38a}\x03\x02\x02\x02\u{38a}\u{38d}\x03\x02\x02\x02\
	\u{38b}\u{389}\x03\x02\x02\x02\u{38c}\u{38e}\x07\x37\x02\x02\u{38d}\u{38c}\
	\x03\x02\x02\x02\u{38d}\u{38e}\x03\x02\x02\x02\u{38e}\u{392}\x03\x02\x02\
	\x02\u{38f}\u{390}\x07\x11\x02\x02\u{390}\u{392}\x07\u{110}\x02\x02\u{391}\
	\u{384}\x03\x02\x02\x02\u{391}\u{38f}\x03\x02\x02\x02\u{392}\u{393}\x03\
	\x02\x02\x02\u{393}\u{395}\x07\u{ed}\x02\x02\u{394}\u{396}\x09\x07\x02\x02\
	\u{395}\u{394}\x03\x02\x02\x02\u{395}\u{396}\x03\x02\x02\x02\u{396}\u{397}\
	\x03\x02\x02\x02\u{397}\u{398}\x05\u{132}\u{9a}\x02\u{398}\u{399}\x07\u{15a}\
	\x02\x02\u{399}\u{39a}\x05\u{13a}\u{9e}\x02\u{39a}\u{487}\x03\x02\x02\x02\
	\u{39b}\u{39d}\x07\x71\x02\x02\u{39c}\u{39e}\x07\u{17d}\x02\x02\u{39d}\u{39c}\
	\x03\x02\x02\x02\u{39d}\u{39e}\x03\x02\x02\x02\u{39e}\u{39f}\x03\x02\x02\
	\x02\u{39f}\u{487}\x05\x0c\x07\x02\u{3a0}\u{3a4}\x07\u{13f}\x02\x02\u{3a1}\
	\u{3a3}\x0a\x02\x02\x02\u{3a2}\u{3a1}\x03\x02\x02\x02\u{3a3}\u{3a6}\x03\
	\x02\x02\x02\u{3a4}\u{3a2}\x03\x02\x02\x02\u{3a4}\u{3a5}\x03\x02\x02\x02\
	\u{3a5}\u{487}\x03\x02\x02\x02\u{3a6}\u{3a4}\x03\x02\x02\x02\u{3a7}\u{3ab}\
	\x07\u{11d}\x02\x02\u{3a8}\u{3aa}\x0a\x02\x02\x02\u{3a9}\u{3a8}\x03\x02\
	\x02\x02\u{3aa}\u{3ad}\x03\x02\x02\x02\u{3ab}\u{3a9}\x03\x02\x02\x02\u{3ab}\
	\u{3ac}\x03\x02\x02\x02\u{3ac}\u{487}\x03\x02\x02\x02\u{3ad}\u{3ab}\x03\
	\x02\x02\x02\u{3ae}\u{3af}\x07\u{146}\x02\x02\u{3af}\u{3bb}\x07\u{15d}\x02\
	\x02\u{3b0}\u{3b5}\x05\u{12c}\u{97}\x02\u{3b1}\u{3b2}\x07\x37\x02\x02\u{3b2}\
	\u{3b4}\x05\u{12c}\u{97}\x02\u{3b3}\u{3b1}\x03\x02\x02\x02\u{3b4}\u{3b7}\
	\x03\x02\x02\x02\u{3b5}\u{3b3}\x03\x02\x02\x02\u{3b5}\u{3b6}\x03\x02\x02\
	\x02\u{3b6}\u{3b9}\x03\x02\x02\x02\u{3b7}\u{3b5}\x03\x02\x02\x02\u{3b8}\
	\u{3ba}\x07\x37\x02\x02\u{3b9}\u{3b8}\x03\x02\x02\x02\u{3b9}\u{3ba}\x03\
	\x02\x02\x02\u{3ba}\u{3bc}\x03\x02\x02\x02\u{3bb}\u{3b0}\x03\x02\x02\x02\
	\u{3bb}\u{3bc}\x03\x02\x02\x02\u{3bc}\u{487}\x03\x02\x02\x02\u{3bd}\u{3c1}\
	\x07\x39\x02\x02\u{3be}\u{3c0}\x0a\x02\x02\x02\u{3bf}\u{3be}\x03\x02\x02\
	\x02\u{3c0}\u{3c3}\x03\x02\x02\x02\u{3c1}\u{3bf}\x03\x02\x02\x02\u{3c1}\
	\u{3c2}\x03\x02\x02\x02\u{3c2}\u{487}\x03\x02\x02\x02\u{3c3}\u{3c1}\x03\
	\x02\x02\x02\u{3c4}\u{3c8}\x07\u{128}\x02\x02\u{3c5}\u{3c7}\x0a\x02\x02\
	\x02\u{3c6}\u{3c5}\x03\x02\x02\x02\u{3c7}\u{3ca}\x03\x02\x02\x02\u{3c8}\
	\u{3c6}\x03\x02\x02\x02\u{3c8}\u{3c9}\x03\x02\x02\x02\u{3c9}\u{487}\x03\
	\x02\x02\x02\u{3ca}\u{3c8}\x03\x02\x02\x02\u{3cb}\u{3cf}\x07\u{10c}\x02\
	\x02\u{3cc}\u{3ce}\x0a\x02\x02\x02\u{3cd}\u{3cc}\x03\x02\x02\x02\u{3ce}\
	\u{3d1}\x03\x02\x02\x02\u{3cf}\u{3cd}\x03\x02\x02\x02\u{3cf}\u{3d0}\x03\
	\x02\x02\x02\u{3d0}\u{487}\x03\x02\x02\x02\u{3d1}\u{3cf}\x03\x02\x02\x02\
	\u{3d2}\u{3d6}\x07\x50\x02\x02\u{3d3}\u{3d5}\x0a\x02\x02\x02\u{3d4}\u{3d3}\
	\x03\x02\x02\x02\u{3d5}\u{3d8}\x03\x02\x02\x02\u{3d6}\u{3d4}\x03\x02\x02\
	\x02\u{3d6}\u{3d7}\x03\x02\x02\x02\u{3d7}\u{487}\x03\x02\x02\x02\u{3d8}\
	\u{3d6}\x03\x02\x02\x02\u{3d9}\u{3dd}\x07\x6f\x02\x02\u{3da}\u{3dc}\x0a\
	\x02\x02\x02\u{3db}\u{3da}\x03\x02\x02\x02\u{3dc}\u{3df}\x03\x02\x02\x02\
	\u{3dd}\u{3db}\x03\x02\x02\x02\u{3dd}\u{3de}\x03\x02\x02\x02\u{3de}\u{487}\
	\x03\x02\x02\x02\u{3df}\u{3dd}\x03\x02\x02\x02\u{3e0}\u{3e1}\x07\x5b\x02\
	\x02\u{3e1}\u{3e2}\x07\u{9b}\x02\x02\u{3e2}\u{487}\x05\u{13c}\u{9f}\x02\
	\u{3e3}\u{3e4}\x07\x5b\x02\x02\u{3e4}\u{3e5}\x07\u{f7}\x02\x02\u{3e5}\u{487}\
	\x05\u{13c}\u{9f}\x02\u{3e6}\u{3ea}\x07\u{170}\x02\x02\u{3e7}\u{3e9}\x0a\
	\x02\x02\x02\u{3e8}\u{3e7}\x03\x02\x02\x02\u{3e9}\u{3ec}\x03\x02\x02\x02\
	\u{3ea}\u{3e8}\x03\x02\x02\x02\u{3ea}\u{3eb}\x03\x02\x02\x02\u{3eb}\u{487}\
	\x03\x02\x02\x02\u{3ec}\u{3ea}\x03\x02\x02\x02\u{3ed}\u{3ee}\x07\x45\x02\
	\x02\u{3ee}\u{3ef}\x07\x72\x02\x02\u{3ef}\u{3f3}\x07\u{133}\x02\x02\u{3f0}\
	\u{3f2}\x0a\x02\x02\x02\u{3f1}\u{3f0}\x03\x02\x02\x02\u{3f2}\u{3f5}\x03\
	\x02\x02\x02\u{3f3}\u{3f1}\x03\x02\x02\x02\u{3f3}\u{3f4}\x03\x02\x02\x02\
	\u{3f4}\u{487}\x03\x02\x02\x02\u{3f5}\u{3f3}\x03\x02\x02\x02\u{3f6}\u{3f7}\
	\x07\x45\x02\x02\u{3f7}\u{3fb}\x07\u{89}\x02\x02\u{3f8}\u{3fa}\x0a\x02\x02\
	\x02\u{3f9}\u{3f8}\x03\x02\x02\x02\u{3fa}\u{3fd}\x03\x02\x02\x02\u{3fb}\
	\u{3f9}\x03\x02\x02\x02\u{3fb}\u{3fc}\x03\x02\x02\x02\u{3fc}\u{487}\x03\
	\x02\x02\x02\u{3fd}\u{3fb}\x03\x02\x02\x02\u{3fe}\u{3ff}\x07\x45\x02\x02\
	\u{3ff}\u{403}\x07\u{92}\x02\x02\u{400}\u{402}\x0a\x02\x02\x02\u{401}\u{400}\
	\x03\x02\x02\x02\u{402}\u{405}\x03\x02\x02\x02\u{403}\u{401}\x03\x02\x02\
	\x02\u{403}\u{404}\x03\x02\x02\x02\u{404}\u{487}\x03\x02\x02\x02\u{405}\
	\u{403}\x03\x02\x02\x02\u{406}\u{409}\x07\x45\x02\x02\u{407}\u{408}\x07\
	\u{f2}\x02\x02\u{408}\u{40a}\x07\u{11c}\x02\x02\u{409}\u{407}\x03\x02\x02\
	\x02\u{409}\u{40a}\x03\x02\x02\x02\u{40a}\u{40b}\x03\x02\x02\x02\u{40b}\
	\u{40f}\x07\u{10e}\x02\x02\u{40c}\u{40e}\x0a\x08\x02\x02\u{40d}\u{40c}\x03\
	\x02\x02\x02\u{40e}\u{411}\x03\x02\x02\x02\u{40f}\u{40d}\x03\x02\x02\x02\
	\u{40f}\u{410}\x03\x02\x02\x02\u{410}\u{412}\x03\x02\x02\x02\u{411}\u{40f}\
	\x03\x02\x02\x02\u{412}\u{416}\x07\u{1b5}\x02\x02\u{413}\u{415}\x0a\x02\
	\x02\x02\u{414}\u{413}\x03\x02\x02\x02\u{415}\u{418}\x03\x02\x02\x02\u{416}\
	\u{414}\x03\x02\x02\x02\u{416}\u{417}\x03\x02\x02\x02\u{417}\u{487}\x03\
	\x02\x02\x02\u{418}\u{416}\x03\x02\x02\x02\u{419}\u{41a}\x07\x45\x02\x02\
	\u{41a}\u{41e}\x07\u{172}\x02\x02\u{41b}\u{41d}\x0a\x02\x02\x02\u{41c}\u{41b}\
	\x03\x02\x02\x02\u{41d}\u{420}\x03\x02\x02\x02\u{41e}\u{41c}\x03\x02\x02\
	\x02\u{41e}\u{41f}\x03\x02\x02\x02\u{41f}\u{487}\x03\x02\x02\x02\u{420}\
	\u{41e}\x03\x02\x02\x02\u{421}\u{422}\x07\x45\x02\x02\u{422}\u{426}\x07\
	\x4b\x02\x02\u{423}\u{425}\x0a\x02\x02\x02\u{424}\u{423}\x03\x02\x02\x02\
	\u{425}\u{428}\x03\x02\x02\x02\u{426}\u{424}\x03\x02\x02\x02\u{426}\u{427}\
	\x03\x02\x02\x02\u{427}\u{487}\x03\x02\x02\x02\u{428}\u{426}\x03\x02\x02\
	\x02\u{429}\u{42a}\x07\x45\x02\x02\u{42a}\u{42e}\x07\x4c\x02\x02\u{42b}\
	\u{42d}\x0a\x02\x02\x02\u{42c}\u{42b}\x03\x02\x02\x02\u{42d}\u{430}\x03\
	\x02\x02\x02\u{42e}\u{42c}\x03\x02\x02\x02\u{42e}\u{42f}\x03\x02\x02\x02\
	\u{42f}\u{487}\x03\x02\x02\x02\u{430}\u{42e}\x03\x02\x02\x02\u{431}\u{434}\
	\x07\x45\x02\x02\u{432}\u{433}\x07\u{f2}\x02\x02\u{433}\u{435}\x07\u{11c}\
	\x02\x02\u{434}\u{432}\x03\x02\x02\x02\u{434}\u{435}\x03\x02\x02\x02\u{435}\
	\u{436}\x03\x02\x02\x02\u{436}\u{43a}\x07\u{bd}\x02\x02\u{437}\u{439}\x0a\
	\x02\x02\x02\u{438}\u{437}\x03\x02\x02\x02\u{439}\u{43c}\x03\x02\x02\x02\
	\u{43a}\u{438}\x03\x02\x02\x02\u{43a}\u{43b}\x03\x02\x02\x02\u{43b}\u{487}\
	\x03\x02\x02\x02\u{43c}\u{43a}\x03\x02\x02\x02\u{43d}\u{43e}\x07\x45\x02\
	\x02\u{43e}\u{442}\x07\u{c9}\x02\x02\u{43f}\u{441}\x0a\x02\x02\x02\u{440}\
	\u{43f}\x03\x02\x02\x02\u{441}\u{444}\x03\x02\x02\x02\u{442}\u{440}\x03\
	\x02\x02\x02\u{442}\u{443}\x03\x02\x02\x02\u{443}\u{487}\x03\x02\x02\x02\
	\u{444}\u{442}\x03\x02\x02\x02\u{445}\u{446}\x07\x45\x02\x02\u{446}\u{44a}\
	\x07\u{d9}\x02\x02\u{447}\u{449}\x0a\x02\x02\x02\u{448}\u{447}\x03\x02\x02\
	\x02\u{449}\u{44c}\x03\x02\x02\x02\u{44a}\u{448}\x03\x02\x02\x02\u{44a}\
	\u{44b}\x03\x02\x02\x02\u{44b}\u{487}\x03\x02\x02\x02\u{44c}\u{44a}\x03\
	\x02\x02\x02\u{44d}\u{44e}\x07\x45\x02\x02\u{44e}\u{452}\x07\u{125}\x02\
	\x02\u{44f}\u{451}\x0a\x02\x02\x02\u{450}\u{44f}\x03\x02\x02\x02\u{451}\
	\u{454}\x03\x02\x02\x02\u{452}\u{450}\x03\x02\x02\x02\u{452}\u{453}\x03\
	\x02\x02\x02\u{453}\u{487}\x03\x02\x02\x02\u{454}\u{452}\x03\x02\x02\x02\
	\u{455}\u{459}\x07\x51\x02\x02\u{456}\u{458}\x0a\x02\x02\x02\u{457}\u{456}\
	\x03\x02\x02\x02\u{458}\u{45b}\x03\x02\x02\x02\u{459}\u{457}\x03\x02\x02\
	\x02\u{459}\u{45a}\x03\x02\x02\x02\u{45a}\u{487}\x03\x02\x02\x02\u{45b}\
	\u{459}\x03\x02\x02\x02\u{45c}\u{460}\x07\x61\x02\x02\u{45d}\u{45f}\x0a\
	\x02\x02\x02\u{45e}\u{45d}\x03\x02\x02\x02\u{45f}\u{462}\x03\x02\x02\x02\
	\u{460}\u{45e}\x03\x02\x02\x02\u{460}\u{461}\x03\x02\x02\x02\u{461}\u{487}\
	\x03\x02\x02\x02\u{462}\u{460}\x03\x02\x02\x02\u{463}\u{467}\x07\x68\x02\
	\x02\u{464}\u{466}\x0a\x02\x02\x02\u{465}\u{464}\x03\x02\x02\x02\u{466}\
	\u{469}\x03\x02\x02\x02\u{467}\u{465}\x03\x02\x02\x02\u{467}\u{468}\x03\
	\x02\x02\x02\u{468}\u{487}\x03\x02\x02\x02\u{469}\u{467}\x03\x02\x02\x02\
	\u{46a}\u{46e}\x07\x75\x02\x02\u{46b}\u{46d}\x0a\x02\x02\x02\u{46c}\u{46b}\
	\x03\x02\x02\x02\u{46d}\u{470}\x03\x02\x02\x02\u{46e}\u{46c}\x03\x02\x02\
	\x02\u{46e}\u{46f}\x03\x02\x02\x02\u{46f}\u{487}\x03\x02\x02\x02\u{470}\
	\u{46e}\x03\x02\x02\x02\u{471}\u{475}\x07\u{c5}\x02\x02\u{472}\u{474}\x0a\
	\x02\x02\x02\u{473}\u{472}\x03\x02\x02\x02\u{474}\u{477}\x03\x02\x02\x02\
	\u{475}\u{473}\x03\x02\x02\x02\u{475}\u{476}\x03\x02\x02\x02\u{476}\u{487}\
	\x03\x02\x02\x02\u{477}\u{475}\x03\x02\x02\x02\u{478}\u{47c}\x07\u{16b}\
	\x02\x02\u{479}\u{47b}\x0a\x02\x02\x02\u{47a}\u{479}\x03\x02\x02\x02\u{47b}\
	\u{47e}\x03\x02\x02\x02\u{47c}\u{47a}\x03\x02\x02\x02\u{47c}\u{47d}\x03\
	\x02\x02\x02\u{47d}\u{487}\x03\x02\x02\x02\u{47e}\u{47c}\x03\x02\x02\x02\
	\u{47f}\u{483}\x07\u{177}\x02\x02\u{480}\u{482}\x0a\x02\x02\x02\u{481}\u{480}\
	\x03\x02\x02\x02\u{482}\u{485}\x03\x02\x02\x02\u{483}\u{481}\x03\x02\x02\
	\x02\u{483}\u{484}\x03\x02\x02\x02\u{484}\u{487}\x03\x02\x02\x02\u{485}\
	\u{483}\x03\x02\x02\x02\u{486}\u{169}\x03\x02\x02\x02\u{486}\u{16a}\x03\
	\x02\x02\x02\u{486}\u{16c}\x03\x02\x02\x02\u{486}\u{171}\x03\x02\x02\x02\
	\u{486}\u{17e}\x03\x02\x02\x02\u{486}\u{185}\x03\x02\x02\x02\u{486}\u{18c}\
	\x03\x02\x02\x02\u{486}\u{18f}\x03\x02\x02\x02\u{486}\u{192}\x03\x02\x02\
	\x02\u{486}\u{1a1}\x03\x02\x02\x02\u{486}\u{1ae}\x03\x02\x02\x02\u{486}\
	\u{1cd}\x03\x02\x02\x02\u{486}\u{1ea}\x03\x02\x02\x02\u{486}\u{1f7}\x03\
	\x02\x02\x02\u{486}\u{21e}\x03\x02\x02\x02\u{486}\u{23e}\x03\x02\x02\x02\
	\u{486}\u{243}\x03\x02\x02\x02\u{486}\u{263}\x03\x02\x02\x02\u{486}\u{26a}\
	\x03\x02\x02\x02\u{486}\u{26e}\x03\x02\x02\x02\u{486}\u{275}\x03\x02\x02\
	\x02\u{486}\u{27c}\x03\x02\x02\x02\u{486}\u{283}\x03\x02\x02\x02\u{486}\
	\u{28a}\x03\x02\x02\x02\u{486}\u{291}\x03\x02\x02\x02\u{486}\u{298}\x03\
	\x02\x02\x02\u{486}\u{29f}\x03\x02\x02\x02\u{486}\u{2ab}\x03\x02\x02\x02\
	\u{486}\u{2b2}\x03\x02\x02\x02\u{486}\u{2b9}\x03\x02\x02\x02\u{486}\u{2c0}\
	\x03\x02\x02\x02\u{486}\u{2c7}\x03\x02\x02\x02\u{486}\u{2d2}\x03\x02\x02\
	\x02\u{486}\u{2e2}\x03\x02\x02\x02\u{486}\u{2f3}\x03\x02\x02\x02\u{486}\
	\u{302}\x03\x02\x02\x02\u{486}\u{311}\x03\x02\x02\x02\u{486}\u{318}\x03\
	\x02\x02\x02\u{486}\u{31f}\x03\x02\x02\x02\u{486}\u{339}\x03\x02\x02\x02\
	\u{486}\u{340}\x03\x02\x02\x02\u{486}\u{344}\x03\x02\x02\x02\u{486}\u{350}\
	\x03\x02\x02\x02\u{486}\u{358}\x03\x02\x02\x02\u{486}\u{35f}\x03\x02\x02\
	\x02\u{486}\u{366}\x03\x02\x02\x02\u{486}\u{36d}\x03\x02\x02\x02\u{486}\
	\u{375}\x03\x02\x02\x02\u{486}\u{37c}\x03\x02\x02\x02\u{486}\u{383}\x03\
	\x02\x02\x02\u{486}\u{39b}\x03\x02\x02\x02\u{486}\u{3a0}\x03\x02\x02\x02\
	\u{486}\u{3a7}\x03\x02\x02\x02\u{486}\u{3ae}\x03\x02\x02\x02\u{486}\u{3bd}\
	\x03\x02\x02\x02\u{486}\u{3c4}\x03\x02\x02\x02\u{486}\u{3cb}\x03\x02\x02\
	\x02\u{486}\u{3d2}\x03\x02\x02\x02\u{486}\u{3d9}\x03\x02\x02\x02\u{486}\
	\u{3e0}\x03\x02\x02\x02\u{486}\u{3e3}\x03\x02\x02\x02\u{486}\u{3e6}\x03\
	\x02\x02\x02\u{486}\u{3ed}\x03\x02\x02\x02\u{486}\u{3f6}\x03\x02\x02\x02\
	\u{486}\u{3fe}\x03\x02\x02\x02\u{486}\u{406}\x03\x02\x02\x02\u{486}\u{419}\
	\x03\x02\x02\x02\u{486}\u{421}\x03\x02\x02\x02\u{486}\u{429}\x03\x02\x02\
	\x02\u{486}\u{431}\x03\x02\x02\x02\u{486}\u{43d}\x03\x02\x02\x02\u{486}\
	\u{445}\x03\x02\x02\x02\u{486}\u{44d}\x03\x02\x02\x02\u{486}\u{455}\x03\
	\x02\x02\x02\u{486}\u{45c}\x03\x02\x02\x02\u{486}\u{463}\x03\x02\x02\x02\
	\u{486}\u{46a}\x03\x02\x02\x02\u{486}\u{471}\x03\x02\x02\x02\u{486}\u{478}\
	\x03\x02\x02\x02\u{486}\u{47f}\x03\x02\x02\x02\u{487}\x0d\x03\x02\x02\x02\
	\u{488}\u{48d}\x05\x2a\x16\x02\u{489}\u{48a}\x07\x37\x02\x02\u{48a}\u{48c}\
	\x05\x2a\x16\x02\u{48b}\u{489}\x03\x02\x02\x02\u{48c}\u{48f}\x03\x02\x02\
	\x02\u{48d}\u{48b}\x03\x02\x02\x02\u{48d}\u{48e}\x03\x02\x02\x02\u{48e}\
	\x0f\x03\x02\x02\x02\u{48f}\u{48d}\x03\x02\x02\x02\u{490}\u{491}\x09\x09\
	\x02\x02\u{491}\u{492}\x07\u{e8}\x02\x02\u{492}\x11\x03\x02\x02\x02\u{493}\
	\u{499}\x05\x16\x0c\x02\u{494}\u{499}\x05\x1a\x0e\x02\u{495}\u{499}\x05\
	\x20\x11\x02\u{496}\u{499}\x05\x1c\x0f\x02\u{497}\u{499}\x05\x22\x12\x02\
	\u{498}\u{493}\x03\x02\x02\x02\u{498}\u{494}\x03\x02\x02\x02\u{498}\u{495}\
	\x03\x02\x02\x02\u{498}\u{496}\x03\x02\x02\x02\u{498}\u{497}\x03\x02\x02\
	\x02\u{499}\u{49c}\x03\x02\x02\x02\u{49a}\u{498}\x03\x02\x02\x02\u{49a}\
	\u{49b}\x03\x02\x02\x02\u{49b}\x13\x03\x02\x02\x02\u{49c}\u{49a}\x03\x02\
	\x02\x02\u{49d}\u{4a3}\x05\x16\x0c\x02\u{49e}\u{4a3}\x05\x18\x0d\x02\u{49f}\
	\u{4a3}\x05\x1e\x10\x02\u{4a0}\u{4a3}\x05\x1c\x0f\x02\u{4a1}\u{4a3}\x05\
	\x22\x12\x02\u{4a2}\u{49d}\x03\x02\x02\x02\u{4a2}\u{49e}\x03\x02\x02\x02\
	\u{4a2}\u{49f}\x03\x02\x02\x02\u{4a2}\u{4a0}\x03\x02\x02\x02\u{4a2}\u{4a1}\
	\x03\x02\x02\x02\u{4a3}\u{4a6}\x03\x02\x02\x02\u{4a4}\u{4a2}\x03\x02\x02\
	\x02\u{4a4}\u{4a5}\x03\x02\x02\x02\u{4a5}\x15\x03\x02\x02\x02\u{4a6}\u{4a4}\
	\x03\x02\x02\x02\u{4a7}\u{4a8}\x07\u{c4}\x02\x02\u{4a8}\u{4a9}\x05\u{102}\
	\u{82}\x02\u{4a9}\x17\x03\x02\x02\x02\u{4aa}\u{4ab}\x07\u{fc}\x02\x02\u{4ab}\
	\u{4ac}\x07\x26\x02\x02\u{4ac}\u{4ad}\x05\u{b6}\x5c\x02\u{4ad}\x19\x03\x02\
	\x02\x02\u{4ae}\u{4af}\x07\u{fc}\x02\x02\u{4af}\u{4b0}\x07\x26\x02\x02\u{4b0}\
	\u{4b1}\x05\u{ba}\x5e\x02\u{4b1}\x1b\x03\x02\x02\x02\u{4b2}\u{4b3}\x07\u{148}\
	\x02\x02\u{4b3}\u{4ba}\x07\x19\x02\x02\u{4b4}\u{4bb}\x05\u{13c}\u{9f}\x02\
	\u{4b5}\u{4b6}\x07\u{9c}\x02\x02\u{4b6}\u{4b7}\x05\u{102}\u{82}\x02\u{4b7}\
	\u{4b8}\x07\u{f8}\x02\x02\u{4b8}\u{4b9}\x05\u{102}\u{82}\x02\u{4b9}\u{4bb}\
	\x03\x02\x02\x02\u{4ba}\u{4b4}\x03\x02\x02\x02\u{4ba}\u{4b5}\x03\x02\x02\
	\x02\u{4bb}\x1d\x03\x02\x02\x02\u{4bc}\u{4bd}\x07\u{12a}\x02\x02\u{4bd}\
	\u{4be}\x07\x7e\x02\x02\u{4be}\u{4c3}\x07\x57\x02\x02\u{4bf}\u{4c0}\x09\
	\x0a\x02\x02\u{4c0}\u{4c1}\x07\u{153}\x02\x02\u{4c1}\u{4c2}\x07\x26\x02\
	\x02\u{4c2}\u{4c4}\x05\u{102}\u{82}\x02\u{4c3}\u{4bf}\x03\x02\x02\x02\u{4c4}\
	\u{4c5}\x03\x02\x02\x02\u{4c5}\u{4c3}\x03\x02\x02\x02\u{4c5}\u{4c6}\x03\
	\x02\x02\x02\u{4c6}\x1f\x03\x02\x02\x02\u{4c7}\u{4c8}\x07\u{12a}\x02\x02\
	\u{4c8}\u{4ec}\x07\x7e\x02\x02\u{4c9}\u{4ce}\x07\x57\x02\x02\u{4ca}\u{4cb}\
	\x09\x0a\x02\x02\u{4cb}\u{4cc}\x07\u{153}\x02\x02\u{4cc}\u{4cd}\x07\x26\
	\x02\x02\u{4cd}\u{4cf}\x05\u{102}\u{82}\x02\u{4ce}\u{4ca}\x03\x02\x02\x02\
	\u{4cf}\u{4d0}\x03\x02\x02\x02\u{4d0}\u{4ce}\x03\x02\x02\x02\u{4d0}\u{4d1}\
	\x03\x02\x02\x02\u{4d1}\u{4ed}\x03\x02\x02\x02\u{4d2}\u{4d3}\x07\u{139}\
	\x02\x02\u{4d3}\u{4ea}\x05\u{102}\u{82}\x02\u{4d4}\u{4d5}\x07\u{185}\x02\
	\x02\u{4d5}\u{4d6}\x07\u{13a}\x02\x02\u{4d6}\u{4d7}\x07\u{191}\x02\x02\u{4d7}\
	\u{4d8}\x05\u{102}\u{82}\x02\u{4d8}\u{4d9}\x07\u{196}\x02\x02\u{4d9}\u{4da}\
	\x05\u{102}\u{82}\x02\u{4da}\u{4e2}\x03\x02\x02\x02\u{4db}\u{4dc}\x07\x37\
	\x02\x02\u{4dc}\u{4dd}\x05\u{102}\u{82}\x02\u{4dd}\u{4de}\x07\u{196}\x02\
	\x02\u{4de}\u{4df}\x05\u{102}\u{82}\x02\u{4df}\u{4e1}\x03\x02\x02\x02\u{4e0}\
	\u{4db}\x03\x02\x02\x02\u{4e1}\u{4e4}\x03\x02\x02\x02\u{4e2}\u{4e0}\x03\
	\x02\x02\x02\u{4e2}\u{4e3}\x03\x02\x02\x02\u{4e3}\u{4e6}\x03\x02\x02\x02\
	\u{4e4}\u{4e2}\x03\x02\x02\x02\u{4e5}\u{4e7}\x07\x37\x02\x02\u{4e6}\u{4e5}\
	\x03\x02\x02\x02\u{4e6}\u{4e7}\x03\x02\x02\x02\u{4e7}\u{4e8}\x03\x02\x02\
	\x02\u{4e8}\u{4e9}\x07\u{192}\x02\x02\u{4e9}\u{4eb}\x03\x02\x02\x02\u{4ea}\
	\u{4d4}\x03\x02\x02\x02\u{4ea}\u{4eb}\x03\x02\x02\x02\u{4eb}\u{4ed}\x03\
	\x02\x02\x02\u{4ec}\u{4c9}\x03\x02\x02\x02\u{4ec}\u{4d2}\x03\x02\x02\x02\
	\u{4ed}\x21\x03\x02\x02\x02\u{4ee}\u{4ef}\x07\u{14e}\x02\x02\u{4ef}\u{4f0}\
	\x07\u{111}\x02\x02\u{4f0}\u{4f1}\x07\u{191}\x02\x02\u{4f1}\u{4f2}\x05\u{102}\
	\u{82}\x02\u{4f2}\u{4f3}\x07\u{196}\x02\x02\u{4f3}\u{4f4}\x05\u{102}\u{82}\
	\x02\u{4f4}\u{4fc}\x03\x02\x02\x02\u{4f5}\u{4f6}\x07\x37\x02\x02\u{4f6}\
	\u{4f7}\x05\u{102}\u{82}\x02\u{4f7}\u{4f8}\x07\u{196}\x02\x02\u{4f8}\u{4f9}\
	\x05\u{102}\u{82}\x02\u{4f9}\u{4fb}\x03\x02\x02\x02\u{4fa}\u{4f5}\x03\x02\
	\x02\x02\u{4fb}\u{4fe}\x03\x02\x02\x02\u{4fc}\u{4fa}\x03\x02\x02\x02\u{4fc}\
	\u{4fd}\x03\x02\x02\x02\u{4fd}\u{500}\x03\x02\x02\x02\u{4fe}\u{4fc}\x03\
	\x02\x02\x02\u{4ff}\u{501}\x07\x37\x02\x02\u{500}\u{4ff}\x03\x02\x02\x02\
	\u{500}\u{501}\x03\x02\x02\x02\u{501}\u{502}\x03\x02\x02\x02\u{502}\u{503}\
	\x07\u{192}\x02\x02\u{503}\x23\x03\x02\x02\x02\u{504}\u{505}\x07\u{b6}\x02\
	\x02\u{505}\u{51d}\x05\u{13c}\u{9f}\x02\u{506}\u{51d}\x07\u{95}\x02\x02\
	\u{507}\u{51d}\x07\u{145}\x02\x02\u{508}\u{51d}\x07\u{180}\x02\x02\u{509}\
	\u{50c}\x07\u{91}\x02\x02\u{50a}\u{50d}\x07\x52\x02\x02\u{50b}\u{50d}\x05\
	\u{102}\u{82}\x02\u{50c}\u{50a}\x03\x02\x02\x02\u{50c}\u{50b}\x03\x02\x02\
	\x02\u{50d}\u{51d}\x03\x02\x02\x02\u{50e}\u{50f}\x07\u{b5}\x02\x02\u{50f}\
	\u{51d}\x05\u{102}\u{82}\x02\u{510}\u{511}\x07\u{120}\x02\x02\u{511}\u{51d}\
	\x05\u{144}\u{a3}\x02\u{512}\u{513}\x07\u{d0}\x02\x02\u{513}\u{51d}\x05\
	\u{144}\u{a3}\x02\u{514}\u{515}\x07\u{d1}\x02\x02\u{515}\u{516}\x05\u{144}\
	\u{a3}\x02\u{516}\u{517}\x09\x0b\x02\x02\u{517}\u{51d}\x03\x02\x02\x02\u{518}\
	\u{519}\x07\u{12e}\x02\x02\u{519}\u{51d}\x05\u{102}\u{82}\x02\u{51a}\u{51b}\
	\x07\x19\x02\x02\u{51b}\u{51d}\x07\u{1b5}\x02\x02\u{51c}\u{504}\x03\x02\
	\x02\x02\u{51c}\u{506}\x03\x02\x02\x02\u{51c}\u{507}\x03\x02\x02\x02\u{51c}\
	\u{508}\x03\x02\x02\x02\u{51c}\u{509}\x03\x02\x02\x02\u{51c}\u{50e}\x03\
	\x02\x02\x02\u{51c}\u{510}\x03\x02\x02\x02\u{51c}\u{512}\x03\x02\x02\x02\
	\u{51c}\u{514}\x03\x02\x02\x02\u{51c}\u{518}\x03\x02\x02\x02\u{51c}\u{51a}\
	\x03\x02\x02\x02\u{51d}\x25\x03\x02\x02\x02\u{51e}\u{520}\x05\x28\x15\x02\
	\u{51f}\u{51e}\x03\x02\x02\x02\u{51f}\u{520}\x03\x02\x02\x02\u{520}\u{521}\
	\x03\x02\x02\x02\u{521}\u{522}\x05\x50\x29\x02\u{522}\x27\x03\x02\x02\x02\
	\u{523}\u{525}\x07\u{185}\x02\x02\u{524}\u{526}\x07\u{117}\x02\x02\u{525}\
	\u{524}\x03\x02\x02\x02\u{525}\u{526}\x03\x02\x02\x02\u{526}\u{527}\x03\
	\x02\x02\x02\u{527}\u{52c}\x05\u{80}\x41\x02\u{528}\u{529}\x07\x37\x02\x02\
	\u{529}\u{52b}\x05\u{80}\x41\x02\u{52a}\u{528}\x03\x02\x02\x02\u{52b}\u{52e}\
	\x03\x02\x02\x02\u{52c}\u{52a}\x03\x02\x02\x02\u{52c}\u{52d}\x03\x02\x02\
	\x02\u{52d}\x29\x03\x02\x02\x02\u{52e}\u{52c}\x03\x02\x02\x02\u{52f}\u{533}\
	\x05\x2c\x17\x02\u{530}\u{533}\x05\x42\x22\x02\u{531}\u{533}\x05\x2e\x18\
	\x02\u{532}\u{52f}\x03\x02\x02\x02\u{532}\u{530}\x03\x02\x02\x02\u{532}\
	\u{531}\x03\x02\x02\x02\u{533}\x2b\x03\x02\x02\x02\u{534}\u{535}\x07\x40\
	\x02\x02\u{535}\u{537}\x05\u{13c}\u{9f}\x02\u{536}\u{534}\x03\x02\x02\x02\
	\u{536}\u{537}\x03\x02\x02\x02\u{537}\u{54a}\x03\x02\x02\x02\u{538}\u{539}\
	\x07\u{169}\x02\x02\u{539}\u{54b}\x05\u{b6}\x5c\x02\u{53a}\u{53b}\x07\u{10f}\
	\x02\x02\u{53b}\u{53d}\x07\u{b2}\x02\x02\u{53c}\u{53e}\x05\u{b6}\x5c\x02\
	\u{53d}\u{53c}\x03\x02\x02\x02\u{53d}\u{53e}\x03\x02\x02\x02\u{53e}\u{54b}\
	\x03\x02\x02\x02\u{53f}\u{540}\x07\x7d\x02\x02\u{540}\u{542}\x07\u{b2}\x02\
	\x02\u{541}\u{543}\x05\u{b6}\x5c\x02\u{542}\u{541}\x03\x02\x02\x02\u{542}\
	\u{543}\x03\x02\x02\x02\u{543}\u{544}\x03\x02\x02\x02\u{544}\u{545}\x07\
	\u{118}\x02\x02\u{545}\u{546}\x05\u{132}\u{9a}\x02\u{546}\u{547}\x07\u{191}\
	\x02\x02\u{547}\u{548}\x05\u{13c}\u{9f}\x02\u{548}\u{549}\x07\u{192}\x02\
	\x02\u{549}\u{54b}\x03\x02\x02\x02\u{54a}\u{538}\x03\x02\x02\x02\u{54a}\
	\u{53a}\x03\x02\x02\x02\u{54a}\u{53f}\x03\x02\x02\x02\u{54b}\x2d\x03\x02\
	\x02\x02\u{54c}\u{551}\x05\x30\x19\x02\u{54d}\u{550}\x05\x3e\x20\x02\u{54e}\
	\u{550}\x05\x40\x21\x02\u{54f}\u{54d}\x03\x02\x02\x02\u{54f}\u{54e}\x03\
	\x02\x02\x02\u{550}\u{553}\x03\x02\x02\x02\u{551}\u{54f}\x03\x02\x02\x02\
	\u{551}\u{552}\x03\x02\x02\x02\u{552}\u{556}\x03\x02\x02\x02\u{553}\u{551}\
	\x03\x02\x02\x02\u{554}\u{555}\x07\x38\x02\x02\u{555}\u{557}\x05\u{102}\
	\u{82}\x02\u{556}\u{554}\x03\x02\x02\x02\u{556}\u{557}\x03\x02\x02\x02\u{557}\
	\x2f\x03\x02\x02\x02\u{558}\u{559}\x05\x32\x1a\x02\u{559}\u{55a}\x05\x36\
	\x1c\x02\u{55a}\u{55f}\x03\x02\x02\x02\u{55b}\u{55c}\x05\u{146}\u{a4}\x02\
	\u{55c}\u{55d}\x05\x36\x1c\x02\u{55d}\u{55f}\x03\x02\x02\x02\u{55e}\u{558}\
	\x03\x02\x02\x02\u{55e}\u{55b}\x03\x02\x02\x02\u{55f}\x31\x03\x02\x02\x02\
	\u{560}\u{563}\x05\u{13c}\u{9f}\x02\u{561}\u{563}\x07\u{1bc}\x02\x02\u{562}\
	\u{560}\x03\x02\x02\x02\u{562}\u{561}\x03\x02\x02\x02\u{563}\x33\x03\x02\
	\x02\x02\u{564}\u{567}\x05\x32\x1a\x02\u{565}\u{567}\x05\u{146}\u{a4}\x02\
	\u{566}\u{564}\x03\x02\x02\x02\u{566}\u{565}\x03\x02\x02\x02\u{567}\x35\
	\x03\x02\x02\x02\u{568}\u{56d}\x05\x3c\x1f\x02\u{569}\u{56b}\x07\u{e5}\x02\
	\x02\u{56a}\u{569}\x03\x02\x02\x02\u{56a}\u{56b}\x03\x02\x02\x02\u{56b}\
	\u{56c}\x03\x02\x02\x02\u{56c}\u{56e}\x07\u{e7}\x02\x02\u{56d}\u{56a}\x03\
	\x02\x02\x02\u{56d}\u{56e}\x03\x02\x02\x02\u{56e}\x37\x03\x02\x02\x02\u{56f}\
	\u{574}\x05\x3a\x1e\x02\u{570}\u{571}\x07\x37\x02\x02\u{571}\u{573}\x05\
	\x3a\x1e\x02\u{572}\u{570}\x03\x02\x02\x02\u{573}\u{576}\x03\x02\x02\x02\
	\u{574}\u{572}\x03\x02\x02\x02\u{574}\u{575}\x03\x02\x02\x02\u{575}\u{578}\
	\x03\x02\x02\x02\u{576}\u{574}\x03\x02\x02\x02\u{577}\u{579}\x07\x37\x02\
	\x02\u{578}\u{577}\x03\x02\x02\x02\u{578}\u{579}\x03\x02\x02\x02\u{579}\
	\x39\x03\x02\x02\x02\u{57a}\u{57b}\x05\u{13c}\u{9f}\x02\u{57b}\u{57c}\x07\
	\u{196}\x02\x02\u{57c}\u{57d}\x05\u{d0}\x69\x02\u{57d}\x3b\x03\x02\x02\x02\
	\u{57e}\u{57f}\x05\u{114}\u{8b}\x02\u{57f}\x3d\x03\x02\x02\x02\u{580}\u{581}\
	\x07\x52\x02\x02\u{581}\u{5ab}\x05\u{d0}\x69\x02\u{582}\u{58c}\x07\u{92}\
	\x02\x02\u{583}\u{584}\x07\u{191}\x02\x02\u{584}\u{585}\x05\u{144}\u{a3}\
	\x02\u{585}\u{586}\x07\x37\x02\x02\u{586}\u{588}\x05\u{144}\u{a3}\x02\u{587}\
	\u{589}\x07\x37\x02\x02\u{588}\u{587}\x03\x02\x02\x02\u{588}\u{589}\x03\
	\x02\x02\x02\u{589}\u{58a}\x03\x02\x02\x02\u{58a}\u{58b}\x07\u{192}\x02\
	\x02\u{58b}\u{58d}\x03\x02\x02\x02\u{58c}\u{583}\x03\x02\x02\x02\u{58c}\
	\u{58d}\x03\x02\x02\x02\u{58d}\u{5ab}\x03\x02\x02\x02\u{58e}\u{58f}\x07\
	\u{83}\x02\x02\u{58f}\u{590}\x07\x26\x02\x02\u{590}\u{591}\x07\x52\x02\x02\
	\u{591}\u{592}\x07\x19\x02\x02\u{592}\u{59c}\x07\u{92}\x02\x02\u{593}\u{594}\
	\x07\u{191}\x02\x02\u{594}\u{595}\x05\u{144}\u{a3}\x02\u{595}\u{596}\x07\
	\x37\x02\x02\u{596}\u{598}\x05\u{144}\u{a3}\x02\u{597}\u{599}\x07\x37\x02\
	\x02\u{598}\u{597}\x03\x02\x02\x02\u{598}\u{599}\x03\x02\x02\x02\u{599}\
	\u{59a}\x03\x02\x02\x02\u{59a}\u{59b}\x07\u{192}\x02\x02\u{59b}\u{59d}\x03\
	\x02\x02\x02\u{59c}\u{593}\x03\x02\x02\x02\u{59c}\u{59d}\x03\x02\x02\x02\
	\u{59d}\u{5ab}\x03\x02\x02\x02\u{59e}\u{59f}\x07\x66\x02\x02\u{59f}\u{5ab}\
	\x05\u{13c}\u{9f}\x02\u{5a0}\u{5ab}\x07\x5e\x02\x02\u{5a1}\u{5ab}\x07\u{143}\
	\x02\x02\u{5a2}\u{5a3}\x07\x34\x02\x02\u{5a3}\u{5a7}\x07\x2c\x02\x02\u{5a4}\
	\u{5a5}\x07\x34\x02\x02\u{5a5}\u{5a7}\x07\x2d\x02\x02\u{5a6}\u{5a2}\x03\
	\x02\x02\x02\u{5a6}\u{5a4}\x03\x02\x02\x02\u{5a7}\u{5ab}\x03\x02\x02\x02\
	\u{5a8}\u{5a9}\x07\x40\x02\x02\u{5a9}\u{5ab}\x05\u{13c}\u{9f}\x02\u{5aa}\
	\u{580}\x03\x02\x02\x02\u{5aa}\u{582}\x03\x02\x02\x02\u{5aa}\u{58e}\x03\
	\x02\x02\x02\u{5aa}\u{59e}\x03\x02\x02\x02\u{5aa}\u{5a0}\x03\x02\x02\x02\
	\u{5aa}\u{5a1}\x03\x02\x02\x02\u{5aa}\u{5a6}\x03\x02\x02\x02\u{5aa}\u{5a8}\
	\x03\x02\x02\x02\u{5ab}\u{5ac}\x03\x02\x02\x02\u{5ac}\u{5aa}\x03\x02\x02\
	\x02\u{5ac}\u{5ad}\x03\x02\x02\x02\u{5ad}\x3f\x03\x02\x02\x02\u{5ae}\u{5af}\
	\x07\u{e5}\x02\x02\u{5af}\u{5b2}\x07\u{e7}\x02\x02\u{5b0}\u{5b2}\x07\u{e7}\
	\x02\x02\u{5b1}\u{5ae}\x03\x02\x02\x02\u{5b1}\u{5b0}\x03\x02\x02\x02\u{5b2}\
	\u{5bf}\x03\x02\x02\x02\u{5b3}\u{5b7}\x07\u{169}\x02\x02\u{5b4}\u{5b5}\x07\
	\u{10f}\x02\x02\u{5b5}\u{5b7}\x07\u{b2}\x02\x02\u{5b6}\u{5b3}\x03\x02\x02\
	\x02\u{5b6}\u{5b4}\x03\x02\x02\x02\u{5b7}\u{5bf}\x03\x02\x02\x02\u{5b8}\
	\u{5b9}\x07\u{118}\x02\x02\u{5b9}\u{5ba}\x05\u{132}\u{9a}\x02\u{5ba}\u{5bb}\
	\x07\u{191}\x02\x02\u{5bb}\u{5bc}\x05\u{13c}\u{9f}\x02\u{5bc}\u{5bd}\x07\
	\u{192}\x02\x02\u{5bd}\u{5bf}\x03\x02\x02\x02\u{5be}\u{5b1}\x03\x02\x02\
	\x02\u{5be}\u{5b6}\x03\x02\x02\x02\u{5be}\u{5b8}\x03\x02\x02\x02\u{5bf}\
	\u{5c0}\x03\x02\x02\x02\u{5c0}\u{5be}\x03\x02\x02\x02\u{5c0}\u{5c1}\x03\
	\x02\x02\x02\u{5c1}\x41\x03\x02\x02\x02\u{5c2}\u{5c3}\x07\u{be}\x02\x02\
	\u{5c3}\u{5c6}\x05\u{132}\u{9a}\x02\u{5c4}\u{5c5}\x09\x0c\x02\x02\u{5c5}\
	\u{5c7}\x09\x0d\x02\x02\u{5c6}\u{5c4}\x03\x02\x02\x02\u{5c6}\u{5c7}\x03\
	\x02\x02\x02\u{5c7}\x43\x03\x02\x02\x02\u{5c8}\u{5c9}\x07\x60\x02\x02\u{5c9}\
	\u{5e9}\x09\x0e\x02\x02\u{5ca}\u{5cb}\x07\x5e\x02\x02\u{5cb}\u{5cc}\x07\
	\u{191}\x02\x02\u{5cc}\u{5cd}\x05\u{d0}\x69\x02\u{5cd}\u{5ce}\x07\u{192}\
	\x02\x02\u{5ce}\u{5e9}\x03\x02\x02\x02\u{5cf}\u{5d1}\x09\x0f\x02\x02\u{5d0}\
	\u{5cf}\x03\x02\x02\x02\u{5d0}\u{5d1}\x03\x02\x02\x02\u{5d1}\u{5d2}\x03\
	\x02\x02\x02\u{5d2}\u{5d3}\x07\u{143}\x02\x02\u{5d3}\u{5dc}\x07\u{191}\x02\
	\x02\u{5d4}\u{5d9}\x05\u{d0}\x69\x02\u{5d5}\u{5d6}\x07\x37\x02\x02\u{5d6}\
	\u{5d8}\x05\u{d0}\x69\x02\u{5d7}\u{5d5}\x03\x02\x02\x02\u{5d8}\u{5db}\x03\
	\x02\x02\x02\u{5d9}\u{5d7}\x03\x02\x02\x02\u{5d9}\u{5da}\x03\x02\x02\x02\
	\u{5da}\u{5dd}\x03\x02\x02\x02\u{5db}\u{5d9}\x03\x02\x02\x02\u{5dc}\u{5d4}\
	\x03\x02\x02\x02\u{5dc}\u{5dd}\x03\x02\x02\x02\u{5dd}\u{5df}\x03\x02\x02\
	\x02\u{5de}\u{5e0}\x07\x37\x02\x02\u{5df}\u{5de}\x03\x02\x02\x02\u{5df}\
	\u{5e0}\x03\x02\x02\x02\u{5e0}\u{5e1}\x03\x02\x02\x02\u{5e1}\u{5e5}\x07\
	\u{192}\x02\x02\u{5e2}\u{5e3}\x07\u{143}\x02\x02\u{5e3}\u{5e5}\x07\x1e\x02\
	\x02\u{5e4}\u{5d0}\x03\x02\x02\x02\u{5e4}\u{5e2}\x03\x02\x02\x02\u{5e5}\
	\u{5e9}\x03\x02\x02\x02\u{5e6}\u{5e7}\x07\x66\x02\x02\u{5e7}\u{5e9}\x07\
	\x1e\x02\x02\u{5e8}\u{5c8}\x03\x02\x02\x02\u{5e8}\u{5ca}\x03\x02\x02\x02\
	\u{5e8}\u{5e4}\x03\x02\x02\x02\u{5e8}\u{5e6}\x03\x02\x02\x02\u{5e9}\u{5ec}\
	\x03\x02\x02\x02\u{5ea}\u{5e8}\x03\x02\x02\x02\u{5ea}\u{5eb}\x03\x02\x02\
	\x02\u{5eb}\x45\x03\x02\x02\x02\u{5ec}\u{5ea}\x03\x02\x02\x02\u{5ed}\u{5ef}\
	\x07\u{191}\x02\x02\u{5ee}\u{5f0}\x05\x48\x25\x02\u{5ef}\u{5ee}\x03\x02\
	\x02\x02\u{5ef}\u{5f0}\x03\x02\x02\x02\u{5f0}\u{5f1}\x03\x02\x02\x02\u{5f1}\
	\u{5f2}\x07\u{192}\x02\x02\u{5f2}\x47\x03\x02\x02\x02\u{5f3}\u{5f8}\x05\
	\x4a\x26\x02\u{5f4}\u{5f5}\x07\x37\x02\x02\u{5f5}\u{5f7}\x05\x4a\x26\x02\
	\u{5f6}\u{5f4}\x03\x02\x02\x02\u{5f7}\u{5fa}\x03\x02\x02\x02\u{5f8}\u{5f6}\
	\x03\x02\x02\x02\u{5f8}\u{5f9}\x03\x02\x02\x02\u{5f9}\u{5fc}\x03\x02\x02\
	\x02\u{5fa}\u{5f8}\x03\x02\x02\x02\u{5fb}\u{5fd}\x07\x37\x02\x02\u{5fc}\
	\u{5fb}\x03\x02\x02\x02\u{5fc}\u{5fd}\x03\x02\x02\x02\u{5fd}\x49\x03\x02\
	\x02\x02\u{5fe}\u{5ff}\x05\x4c\x27\x02\u{5ff}\u{600}\x07\u{196}\x02\x02\
	\u{600}\u{604}\x07\u{191}\x02\x02\u{601}\u{603}\x05\x4a\x26\x02\u{602}\u{601}\
	\x03\x02\x02\x02\u{603}\u{606}\x03\x02\x02\x02\u{604}\u{602}\x03\x02\x02\
	\x02\u{604}\u{605}\x03\x02\x02\x02\u{605}\u{607}\x03\x02\x02\x02\u{606}\
	\u{604}\x03\x02\x02\x02\u{607}\u{608}\x07\u{192}\x02\x02\u{608}\u{60e}\x03\
	\x02\x02\x02\u{609}\u{60a}\x05\x4c\x27\x02\u{60a}\u{60b}\x07\u{196}\x02\
	\x02\u{60b}\u{60c}\x05\x4e\x28\x02\u{60c}\u{60e}\x03\x02\x02\x02\u{60d}\
	\u{5fe}\x03\x02\x02\x02\u{60d}\u{609}\x03\x02\x02\x02\u{60e}\x4b\x03\x02\
	\x02\x02\u{60f}\u{610}\x05\u{13c}\u{9f}\x02\u{610}\x4d\x03\x02\x02\x02\u{611}\
	\u{615}\x07\x52\x02\x02\u{612}\u{615}\x05\u{13c}\u{9f}\x02\u{613}\u{615}\
	\x05\u{d0}\x69\x02\u{614}\u{611}\x03\x02\x02\x02\u{614}\u{612}\x03\x02\x02\
	\x02\u{614}\u{613}\x03\x02\x02\x02\u{615}\x4f\x03\x02\x02\x02\u{616}\u{617}\
	\x05\x52\x2a\x02\u{617}\x51\x03\x02\x02\x02\u{618}\u{61f}\x05\x54\x2b\x02\
	\u{619}\u{61a}\x07\u{bf}\x02\x02\u{61a}\u{61d}\x05\x56\x2c\x02\u{61b}\u{61c}\
	\x07\u{eb}\x02\x02\u{61c}\u{61e}\x05\x58\x2d\x02\u{61d}\u{61b}\x03\x02\x02\
	\x02\u{61d}\u{61e}\x03\x02\x02\x02\u{61e}\u{620}\x03\x02\x02\x02\u{61f}\
	\u{619}\x03\x02\x02\x02\u{61f}\u{620}\x03\x02\x02\x02\u{620}\x53\x03\x02\
	\x02\x02\u{621}\u{623}\x05\x5a\x2e\x02\u{622}\u{624}\x05\x7e\x40\x02\u{623}\
	\u{622}\x03\x02\x02\x02\u{623}\u{624}\x03\x02\x02\x02\u{624}\x55\x03\x02\
	\x02\x02\u{625}\u{628}\x07\x11\x02\x02\u{626}\u{628}\x05\x58\x2d\x02\u{627}\
	\u{625}\x03\x02\x02\x02\u{627}\u{626}\x03\x02\x02\x02\u{628}\x57\x03\x02\
	\x02\x02\u{629}\u{62a}\x09\x10\x02\x02\u{62a}\x59\x03\x02\x02\x02\u{62b}\
	\u{62c}\x05\x5c\x2f\x02\u{62c}\x5b\x03\x02\x02\x02\u{62d}\u{633}\x05\x60\
	\x31\x02\u{62e}\u{62f}\x05\x5e\x30\x02\u{62f}\u{630}\x05\x60\x31\x02\u{630}\
	\u{632}\x03\x02\x02\x02\u{631}\u{62e}\x03\x02\x02\x02\u{632}\u{635}\x03\
	\x02\x02\x02\u{633}\u{631}\x03\x02\x02\x02\u{633}\u{634}\x03\x02\x02\x02\
	\u{634}\x5d\x03\x02\x02\x02\u{635}\u{633}\x03\x02\x02\x02\u{636}\u{638}\
	\x09\x11\x02\x02\u{637}\u{639}\x05\x64\x33\x02\u{638}\u{637}\x03\x02\x02\
	\x02\u{638}\u{639}\x03\x02\x02\x02\u{639}\x5f\x03\x02\x02\x02\u{63a}\u{640}\
	\x05\x68\x35\x02\u{63b}\u{63c}\x05\x62\x32\x02\u{63c}\u{63d}\x05\x68\x35\
	\x02\u{63d}\u{63f}\x03\x02\x02\x02\u{63e}\u{63b}\x03\x02\x02\x02\u{63f}\
	\u{642}\x03\x02\x02\x02\u{640}\u{63e}\x03\x02\x02\x02\u{640}\u{641}\x03\
	\x02\x02\x02\u{641}\x61\x03\x02\x02\x02\u{642}\u{640}\x03\x02\x02\x02\u{643}\
	\u{645}\x07\u{a0}\x02\x02\u{644}\u{646}\x05\x64\x33\x02\u{645}\u{644}\x03\
	\x02\x02\x02\u{645}\u{646}\x03\x02\x02\x02\u{646}\x63\x03\x02\x02\x02\u{647}\
	\u{648}\x09\x12\x02\x02\u{648}\x65\x03\x02\x02\x02\u{649}\u{64a}\x07\u{17a}\
	\x02\x02\u{64a}\u{64f}\x05\u{d0}\x69\x02\u{64b}\u{64c}\x07\x37\x02\x02\u{64c}\
	\u{64e}\x05\u{d0}\x69\x02\u{64d}\u{64b}\x03\x02\x02\x02\u{64e}\u{651}\x03\
	\x02\x02\x02\u{64f}\u{64d}\x03\x02\x02\x02\u{64f}\u{650}\x03\x02\x02\x02\
	\u{650}\u{653}\x03\x02\x02\x02\u{651}\u{64f}\x03\x02\x02\x02\u{652}\u{654}\
	\x07\x37\x02\x02\u{653}\u{652}\x03\x02\x02\x02\u{653}\u{654}\x03\x02\x02\
	\x02\u{654}\x67\x03\x02\x02\x02\u{655}\u{65e}\x05\x6c\x37\x02\u{656}\u{657}\
	\x07\u{14e}\x02\x02\u{657}\u{65e}\x05\u{134}\u{9b}\x02\u{658}\u{65e}\x05\
	\x66\x34\x02\u{659}\u{65a}\x07\u{191}\x02\x02\u{65a}\u{65b}\x05\x26\x14\
	\x02\u{65b}\u{65c}\x07\u{192}\x02\x02\u{65c}\u{65e}\x03\x02\x02\x02\u{65d}\
	\u{655}\x03\x02\x02\x02\u{65d}\u{656}\x03\x02\x02\x02\u{65d}\u{658}\x03\
	\x02\x02\x02\u{65d}\u{659}\x03\x02\x02\x02\u{65e}\x69\x03\x02\x02\x02\u{65f}\
	\u{661}\x05\u{d0}\x69\x02\u{660}\u{662}\x09\x13\x02\x02\u{661}\u{660}\x03\
	\x02\x02\x02\u{661}\u{662}\x03\x02\x02\x02\u{662}\u{665}\x03\x02\x02\x02\
	\u{663}\u{664}\x07\u{e8}\x02\x02\u{664}\u{666}\x09\x14\x02\x02\u{665}\u{663}\
	\x03\x02\x02\x02\u{665}\u{666}\x03\x02\x02\x02\u{666}\x6b\x03\x02\x02\x02\
	\u{667}\u{66a}\x07\u{137}\x02\x02\u{668}\u{669}\x07\u{15b}\x02\x02\u{669}\
	\u{66b}\x05\u{144}\u{a3}\x02\u{66a}\u{668}\x03\x02\x02\x02\u{66a}\u{66b}\
	\x03\x02\x02\x02\u{66b}\u{66d}\x03\x02\x02\x02\u{66c}\u{66e}\x05\x64\x33\
	\x02\u{66d}\u{66c}\x03\x02\x02\x02\u{66d}\u{66e}\x03\x02\x02\x02\u{66e}\
	\u{66f}\x03\x02\x02\x02\u{66f}\u{67c}\x05\x6e\x38\x02\u{670}\u{671}\x07\
	\x7f\x02\x02\u{671}\u{676}\x05\u{8a}\x46\x02\u{672}\u{673}\x07\x37\x02\x02\
	\u{673}\u{675}\x05\u{8a}\x46\x02\u{674}\u{672}\x03\x02\x02\x02\u{675}\u{678}\
	\x03\x02\x02\x02\u{676}\u{674}\x03\x02\x02\x02\u{676}\u{677}\x03\x02\x02\
	\x02\u{677}\u{67a}\x03\x02\x02\x02\u{678}\u{676}\x03\x02\x02\x02\u{679}\
	\u{67b}\x07\x37\x02\x02\u{67a}\u{679}\x03\x02\x02\x02\u{67a}\u{67b}\x03\
	\x02\x02\x02\u{67b}\u{67d}\x03\x02\x02\x02\u{67c}\u{670}\x03\x02\x02\x02\
	\u{67c}\u{67d}\x03\x02\x02\x02\u{67d}\u{680}\x03\x02\x02\x02\u{67e}\u{67f}\
	\x07\u{183}\x02\x02\u{67f}\u{681}\x05\u{d2}\x6a\x02\u{680}\u{67e}\x03\x02\
	\x02\x02\u{680}\u{681}\x03\x02\x02\x02\u{681}\u{69a}\x03\x02\x02\x02\u{682}\
	\u{683}\x07\u{146}\x02\x02\u{683}\u{684}\x07\u{185}\x02\x02\u{684}\u{686}\
	\x05\u{d0}\x69\x02\u{685}\u{682}\x03\x02\x02\x02\u{685}\u{686}\x03\x02\x02\
	\x02\u{686}\u{687}\x03\x02\x02\x02\u{687}\u{688}\x07\x3e\x02\x02\u{688}\
	\u{693}\x07\x26\x02\x02\u{689}\u{68a}\x07\u{10d}\x02\x02\u{68a}\u{68b}\x05\
	\u{13c}\u{9f}\x02\u{68b}\u{68c}\x07\u{196}\x02\x02\u{68c}\u{68d}\x05\u{d0}\
	\x69\x02\u{68d}\u{694}\x03\x02\x02\x02\u{68e}\u{68f}\x05\u{d0}\x69\x02\u{68f}\
	\u{690}\x07\u{19a}\x02\x02\u{690}\u{691}\x07\u{10d}\x02\x02\u{691}\u{692}\
	\x05\u{13c}\u{9f}\x02\u{692}\u{694}\x03\x02\x02\x02\u{693}\u{689}\x03\x02\
	\x02\x02\u{693}\u{68e}\x03\x02\x02\x02\u{694}\u{698}\x03\x02\x02\x02\u{695}\
	\u{696}\x07\u{146}\x02\x02\u{696}\u{697}\x07\u{185}\x02\x02\u{697}\u{699}\
	\x05\u{d0}\x69\x02\u{698}\u{695}\x03\x02\x02\x02\u{698}\u{699}\x03\x02\x02\
	\x02\u{699}\u{69b}\x03\x02\x02\x02\u{69a}\u{685}\x03\x02\x02\x02\u{69a}\
	\u{69b}\x03\x02\x02\x02\u{69b}\u{69d}\x03\x02\x02\x02\u{69c}\u{69e}\x05\
	\x70\x39\x02\u{69d}\u{69c}\x03\x02\x02\x02\u{69d}\u{69e}\x03\x02\x02\x02\
	\u{69e}\u{6a1}\x03\x02\x02\x02\u{69f}\u{6a0}\x07\u{8d}\x02\x02\u{6a0}\u{6a2}\
	\x05\u{d2}\x6a\x02\u{6a1}\u{69f}\x03\x02\x02\x02\u{6a1}\u{6a2}\x03\x02\x02\
	\x02\u{6a2}\u{6a5}\x03\x02\x02\x02\u{6a3}\u{6a4}\x07\u{113}\x02\x02\u{6a4}\
	\u{6a6}\x05\u{d2}\x6a\x02\u{6a5}\u{6a3}\x03\x02\x02\x02\u{6a5}\u{6a6}\x03\
	\x02\x02\x02\u{6a6}\u{6b3}\x03\x02\x02\x02\u{6a7}\u{6a8}\x07\u{184}\x02\
	\x02\u{6a8}\u{6ad}\x05\x78\x3d\x02\u{6a9}\u{6aa}\x07\x37\x02\x02\u{6aa}\
	\u{6ac}\x05\x78\x3d\x02\u{6ab}\u{6a9}\x03\x02\x02\x02\u{6ac}\u{6af}\x03\
	\x02\x02\x02\u{6ad}\u{6ab}\x03\x02\x02\x02\u{6ad}\u{6ae}\x03\x02\x02\x02\
	\u{6ae}\u{6b1}\x03\x02\x02\x02\u{6af}\u{6ad}\x03\x02\x02\x02\u{6b0}\u{6b2}\
	\x07\x37\x02\x02\u{6b1}\u{6b0}\x03\x02\x02\x02\u{6b1}\u{6b2}\x03\x02\x02\
	\x02\u{6b2}\u{6b4}\x03\x02\x02\x02\u{6b3}\u{6a7}\x03\x02\x02\x02\u{6b3}\
	\u{6b4}\x03\x02\x02\x02\u{6b4}\x6d\x03\x02\x02\x02\u{6b5}\u{6ba}\x05\u{84}\
	\x43\x02\u{6b6}\u{6b7}\x07\x37\x02\x02\u{6b7}\u{6b9}\x05\u{84}\x43\x02\u{6b8}\
	\u{6b6}\x03\x02\x02\x02\u{6b9}\u{6bc}\x03\x02\x02\x02\u{6ba}\u{6b8}\x03\
	\x02\x02\x02\u{6ba}\u{6bb}\x03\x02\x02\x02\u{6bb}\u{6be}\x03\x02\x02\x02\
	\u{6bc}\u{6ba}\x03\x02\x02\x02\u{6bd}\u{6bf}\x07\x37\x02\x02\u{6be}\u{6bd}\
	\x03\x02\x02\x02\u{6be}\u{6bf}\x03\x02\x02\x02\u{6bf}\x6f\x03\x02\x02\x02\
	\u{6c0}\u{6c1}\x07\u{89}\x02\x02\u{6c1}\u{6c2}\x07\x26\x02\x02\u{6c2}\u{6c3}\
	\x05\x72\x3a\x02\u{6c3}\x71\x03\x02\x02\x02\u{6c4}\u{6c6}\x05\x64\x33\x02\
	\u{6c5}\u{6c4}\x03\x02\x02\x02\u{6c5}\u{6c6}\x03\x02\x02\x02\u{6c6}\u{6c7}\
	\x03\x02\x02\x02\u{6c7}\u{6cc}\x05\x74\x3b\x02\u{6c8}\u{6c9}\x07\x37\x02\
	\x02\u{6c9}\u{6cb}\x05\x74\x3b\x02\u{6ca}\u{6c8}\x03\x02\x02\x02\u{6cb}\
	\u{6ce}\x03\x02\x02\x02\u{6cc}\u{6ca}\x03\x02\x02\x02\u{6cc}\u{6cd}\x03\
	\x02\x02\x02\u{6cd}\u{6d0}\x03\x02\x02\x02\u{6ce}\u{6cc}\x03\x02\x02\x02\
	\u{6cf}\u{6d1}\x07\x37\x02\x02\u{6d0}\u{6cf}\x03\x02\x02\x02\u{6d0}\u{6d1}\
	\x03\x02\x02\x02\u{6d1}\x73\x03\x02\x02\x02\u{6d2}\u{6d3}\x07\u{129}\x02\
	\x02\u{6d3}\u{6df}\x07\u{191}\x02\x02\u{6d4}\u{6d9}\x05\u{d0}\x69\x02\u{6d5}\
	\u{6d6}\x07\x37\x02\x02\u{6d6}\u{6d8}\x05\u{d0}\x69\x02\u{6d7}\u{6d5}\x03\
	\x02\x02\x02\u{6d8}\u{6db}\x03\x02\x02\x02\u{6d9}\u{6d7}\x03\x02\x02\x02\
	\u{6d9}\u{6da}\x03\x02\x02\x02\u{6da}\u{6dd}\x03\x02\x02\x02\u{6db}\u{6d9}\
	\x03\x02\x02\x02\u{6dc}\u{6de}\x07\x37\x02\x02\u{6dd}\u{6dc}\x03\x02\x02\
	\x02\u{6dd}\u{6de}\x03\x02\x02\x02\u{6de}\u{6e0}\x03\x02\x02\x02\u{6df}\
	\u{6d4}\x03\x02\x02\x02\u{6df}\u{6e0}\x03\x02\x02\x02\u{6e0}\u{6e1}\x03\
	\x02\x02\x02\u{6e1}\u{704}\x07\u{192}\x02\x02\u{6e2}\u{6e3}\x07\x47\x02\
	\x02\u{6e3}\u{6ef}\x07\u{191}\x02\x02\u{6e4}\u{6e9}\x05\u{d0}\x69\x02\u{6e5}\
	\u{6e6}\x07\x37\x02\x02\u{6e6}\u{6e8}\x05\u{d0}\x69\x02\u{6e7}\u{6e5}\x03\
	\x02\x02\x02\u{6e8}\u{6eb}\x03\x02\x02\x02\u{6e9}\u{6e7}\x03\x02\x02\x02\
	\u{6e9}\u{6ea}\x03\x02\x02\x02\u{6ea}\u{6ed}\x03\x02\x02\x02\u{6eb}\u{6e9}\
	\x03\x02\x02\x02\u{6ec}\u{6ee}\x07\x37\x02\x02\u{6ed}\u{6ec}\x03\x02\x02\
	\x02\u{6ed}\u{6ee}\x03\x02\x02\x02\u{6ee}\u{6f0}\x03\x02\x02\x02\u{6ef}\
	\u{6e4}\x03\x02\x02\x02\u{6ef}\u{6f0}\x03\x02\x02\x02\u{6f0}\u{6f1}\x03\
	\x02\x02\x02\u{6f1}\u{704}\x07\u{192}\x02\x02\u{6f2}\u{6f3}\x07\u{8a}\x02\
	\x02\u{6f3}\u{6f4}\x07\u{13e}\x02\x02\u{6f4}\u{6f5}\x07\u{191}\x02\x02\u{6f5}\
	\u{6fa}\x05\x76\x3c\x02\u{6f6}\u{6f7}\x07\x37\x02\x02\u{6f7}\u{6f9}\x05\
	\x76\x3c\x02\u{6f8}\u{6f6}\x03\x02\x02\x02\u{6f9}\u{6fc}\x03\x02\x02\x02\
	\u{6fa}\u{6f8}\x03\x02\x02\x02\u{6fa}\u{6fb}\x03\x02\x02\x02\u{6fb}\u{6fe}\
	\x03\x02\x02\x02\u{6fc}\u{6fa}\x03\x02\x02\x02\u{6fd}\u{6ff}\x07\x37\x02\
	\x02\u{6fe}\u{6fd}\x03\x02\x02\x02\u{6fe}\u{6ff}\x03\x02\x02\x02\u{6ff}\
	\u{700}\x03\x02\x02\x02\u{700}\u{701}\x07\u{192}\x02\x02\u{701}\u{704}\x03\
	\x02\x02\x02\u{702}\u{704}\x05\x76\x3c\x02\u{703}\u{6d2}\x03\x02\x02\x02\
	\u{703}\u{6e2}\x03\x02\x02\x02\u{703}\u{6f2}\x03\x02\x02\x02\u{703}\u{702}\
	\x03\x02\x02\x02\u{704}\x75\x03\x02\x02\x02\u{705}\u{70e}\x07\u{191}\x02\
	\x02\u{706}\u{70b}\x05\u{d0}\x69\x02\u{707}\u{708}\x07\x37\x02\x02\u{708}\
	\u{70a}\x05\u{d0}\x69\x02\u{709}\u{707}\x03\x02\x02\x02\u{70a}\u{70d}\x03\
	\x02\x02\x02\u{70b}\u{709}\x03\x02\x02\x02\u{70b}\u{70c}\x03\x02\x02\x02\
	\u{70c}\u{70f}\x03\x02\x02\x02\u{70d}\u{70b}\x03\x02\x02\x02\u{70e}\u{706}\
	\x03\x02\x02\x02\u{70e}\u{70f}\x03\x02\x02\x02\u{70f}\u{711}\x03\x02\x02\
	\x02\u{710}\u{712}\x07\x37\x02\x02\u{711}\u{710}\x03\x02\x02\x02\u{711}\
	\u{712}\x03\x02\x02\x02\u{712}\u{713}\x03\x02\x02\x02\u{713}\u{716}\x07\
	\u{192}\x02\x02\u{714}\u{716}\x05\u{d0}\x69\x02\u{715}\u{705}\x03\x02\x02\
	\x02\u{715}\u{714}\x03\x02\x02\x02\u{716}\x77\x03\x02\x02\x02\u{717}\u{718}\
	\x05\u{13c}\u{9f}\x02\u{718}\u{719}\x07\x19\x02\x02\u{719}\u{71a}\x07\u{191}\
	\x02\x02\u{71a}\u{71b}\x05\x7a\x3e\x02\u{71b}\u{71c}\x07\u{192}\x02\x02\
	\u{71c}\x79\x03\x02\x02\x02\u{71d}\u{71f}\x05\u{13c}\u{9f}\x02\u{71e}\u{71d}\
	\x03\x02\x02\x02\u{71e}\u{71f}\x03\x02\x02\x02\u{71f}\u{721}\x03\x02\x02\
	\x02\u{720}\u{722}\x05\x7c\x3f\x02\u{721}\u{720}\x03\x02\x02\x02\u{721}\
	\u{722}\x03\x02\x02\x02\u{722}\u{724}\x03\x02\x02\x02\u{723}\u{725}\x05\
	\x7e\x40\x02\u{724}\u{723}\x03\x02\x02\x02\u{724}\u{725}\x03\x02\x02\x02\
	\u{725}\u{727}\x03\x02\x02\x02\u{726}\u{728}\x05\u{120}\u{91}\x02\u{727}\
	\u{726}\x03\x02\x02\x02\u{727}\u{728}\x03\x02\x02\x02\u{728}\x7b\x03\x02\
	\x02\x02\u{729}\u{72a}\x07\u{fb}\x02\x02\u{72a}\u{72b}\x07\x26\x02\x02\u{72b}\
	\u{730}\x05\u{d0}\x69\x02\u{72c}\u{72d}\x07\x37\x02\x02\u{72d}\u{72f}\x05\
	\u{d0}\x69\x02\u{72e}\u{72c}\x03\x02\x02\x02\u{72f}\u{732}\x03\x02\x02\x02\
	\u{730}\u{72e}\x03\x02\x02\x02\u{730}\u{731}\x03\x02\x02\x02\u{731}\u{734}\
	\x03\x02\x02\x02\u{732}\u{730}\x03\x02\x02\x02\u{733}\u{735}\x07\x37\x02\
	\x02\u{734}\u{733}\x03\x02\x02\x02\u{734}\u{735}\x03\x02\x02\x02\u{735}\
	\x7d\x03\x02\x02\x02\u{736}\u{737}\x07\u{f3}\x02\x02\u{737}\u{738}\x07\x26\
	\x02\x02\u{738}\u{73d}\x05\x6a\x36\x02\u{739}\u{73a}\x07\x37\x02\x02\u{73a}\
	\u{73c}\x05\x6a\x36\x02\u{73b}\u{739}\x03\x02\x02\x02\u{73c}\u{73f}\x03\
	\x02\x02\x02\u{73d}\u{73b}\x03\x02\x02\x02\u{73d}\u{73e}\x03\x02\x02\x02\
	\u{73e}\u{741}\x03\x02\x02\x02\u{73f}\u{73d}\x03\x02\x02\x02\u{740}\u{742}\
	\x07\x37\x02\x02\u{741}\u{740}\x03\x02\x02\x02\u{741}\u{742}\x03\x02\x02\
	\x02\u{742}\x7f\x03\x02\x02\x02\u{743}\u{745}\x05\u{13c}\u{9f}\x02\u{744}\
	\u{746}\x05\u{b6}\x5c\x02\u{745}\u{744}\x03\x02\x02\x02\u{745}\u{746}\x03\
	\x02\x02\x02\u{746}\u{747}\x03\x02\x02\x02\u{747}\u{748}\x07\x19\x02\x02\
	\u{748}\u{749}\x07\u{191}\x02\x02\u{749}\u{74a}\x05\x26\x14\x02\u{74a}\u{74b}\
	\x07\u{192}\x02\x02\u{74b}\u{81}\x03\x02\x02\x02\u{74c}\u{74f}\x05\x32\x1a\
	\x02\u{74d}\u{74f}\x05\u{146}\u{a4}\x02\u{74e}\u{74c}\x03\x02\x02\x02\u{74e}\
	\u{74d}\x03\x02\x02\x02\u{74f}\u{83}\x03\x02\x02\x02\u{750}\u{755}\x05\u{d0}\
	\x69\x02\u{751}\u{753}\x07\x19\x02\x02\u{752}\u{751}\x03\x02\x02\x02\u{752}\
	\u{753}\x03\x02\x02\x02\u{753}\u{754}\x03\x02\x02\x02\u{754}\u{756}\x05\
	\u{82}\x42\x02\u{755}\u{752}\x03\x02\x02\x02\u{755}\u{756}\x03\x02\x02\x02\
	\u{756}\u{759}\x03\x02\x02\x02\u{757}\u{759}\x05\u{86}\x44\x02\u{758}\u{750}\
	\x03\x02\x02\x02\u{758}\u{757}\x03\x02\x02\x02\u{759}\u{85}\x03\x02\x02\
	\x02\u{75a}\u{75b}\x05\u{88}\x45\x02\u{75b}\u{87}\x03\x02\x02\x02\u{75c}\
	\u{75d}\x05\u{dc}\x6f\x02\u{75d}\u{75e}\x07\u{195}\x02\x02\u{75e}\u{75f}\
	\x07\u{19e}\x02\x02\u{75f}\u{762}\x03\x02\x02\x02\u{760}\u{762}\x07\u{19e}\
	\x02\x02\u{761}\u{75c}\x03\x02\x02\x02\u{761}\u{760}\x03\x02\x02\x02\u{762}\
	\u{89}\x03\x02\x02\x02\u{763}\u{764}\x05\u{9e}\x50\x02\u{764}\u{8b}\x03\
	\x02\x02\x02\u{765}\u{766}\x08\x47\x01\x02\u{766}\u{767}\x05\u{92}\x4a\x02\
	\u{767}\u{781}\x03\x02\x02\x02\u{768}\u{77d}\x0c\x04\x02\x02\u{769}\u{76a}\
	\x07\x46\x02\x02\u{76a}\u{76b}\x07\u{a9}\x02\x02\u{76b}\u{77e}\x05\u{92}\
	\x4a\x02\u{76c}\u{76d}\x05\u{8e}\x48\x02\u{76d}\u{76e}\x07\u{a9}\x02\x02\
	\u{76e}\u{770}\x05\u{92}\x4a\x02\u{76f}\u{771}\x05\u{90}\x49\x02\u{770}\
	\u{76f}\x03\x02\x02\x02\u{770}\u{771}\x03\x02\x02\x02\u{771}\u{77e}\x03\
	\x02\x02\x02\u{772}\u{773}\x05\u{8e}\x48\x02\u{773}\u{774}\x07\u{a9}\x02\
	\x02\u{774}\u{776}\x05\u{8c}\x47\x02\u{775}\u{777}\x05\u{90}\x49\x02\u{776}\
	\u{775}\x03\x02\x02\x02\u{776}\u{777}\x03\x02\x02\x02\u{777}\u{77e}\x03\
	\x02\x02\x02\u{778}\u{779}\x07\u{dc}\x02\x02\u{779}\u{77a}\x05\u{8e}\x48\
	\x02\u{77a}\u{77b}\x07\u{a9}\x02\x02\u{77b}\u{77c}\x05\u{92}\x4a\x02\u{77c}\
	\u{77e}\x03\x02\x02\x02\u{77d}\u{769}\x03\x02\x02\x02\u{77d}\u{76c}\x03\
	\x02\x02\x02\u{77d}\u{772}\x03\x02\x02\x02\u{77d}\u{778}\x03\x02\x02\x02\
	\u{77e}\u{780}\x03\x02\x02\x02\u{77f}\u{768}\x03\x02\x02\x02\u{780}\u{783}\
	\x03\x02\x02\x02\u{781}\u{77f}\x03\x02\x02\x02\u{781}\u{782}\x03\x02\x02\
	\x02\u{782}\u{8d}\x03\x02\x02\x02\u{783}\u{781}\x03\x02\x02\x02\u{784}\u{786}\
	\x07\u{9a}\x02\x02\u{785}\u{784}\x03\x02\x02\x02\u{785}\u{786}\x03\x02\x02\
	\x02\u{786}\u{794}\x03\x02\x02\x02\u{787}\u{789}\x07\u{bb}\x02\x02\u{788}\
	\u{78a}\x07\u{f6}\x02\x02\u{789}\u{788}\x03\x02\x02\x02\u{789}\u{78a}\x03\
	\x02\x02\x02\u{78a}\u{794}\x03\x02\x02\x02\u{78b}\u{78d}\x07\u{124}\x02\
	\x02\u{78c}\u{78e}\x07\u{f6}\x02\x02\u{78d}\u{78c}\x03\x02\x02\x02\u{78d}\
	\u{78e}\x03\x02\x02\x02\u{78e}\u{794}\x03\x02\x02\x02\u{78f}\u{791}\x07\
	\u{80}\x02\x02\u{790}\u{792}\x07\u{f6}\x02\x02\u{791}\u{790}\x03\x02\x02\
	\x02\u{791}\u{792}\x03\x02\x02\x02\u{792}\u{794}\x03\x02\x02\x02\u{793}\
	\u{785}\x03\x02\x02\x02\u{793}\u{787}\x03\x02\x02\x02\u{793}\u{78b}\x03\
	\x02\x02\x02\u{793}\u{78f}\x03\x02\x02\x02\u{794}\u{8f}\x03\x02\x02\x02\
	\u{795}\u{796}\x07\u{ed}\x02\x02\u{796}\u{7a7}\x05\u{d2}\x6a\x02\u{797}\
	\u{798}\x07\u{173}\x02\x02\u{798}\u{799}\x07\u{191}\x02\x02\u{799}\u{79e}\
	\x05\u{13c}\u{9f}\x02\u{79a}\u{79b}\x07\x37\x02\x02\u{79b}\u{79d}\x05\u{13c}\
	\u{9f}\x02\u{79c}\u{79a}\x03\x02\x02\x02\u{79d}\u{7a0}\x03\x02\x02\x02\u{79e}\
	\u{79c}\x03\x02\x02\x02\u{79e}\u{79f}\x03\x02\x02\x02\u{79f}\u{7a2}\x03\
	\x02\x02\x02\u{7a0}\u{79e}\x03\x02\x02\x02\u{7a1}\u{7a3}\x07\x37\x02\x02\
	\u{7a2}\u{7a1}\x03\x02\x02\x02\u{7a2}\u{7a3}\x03\x02\x02\x02\u{7a3}\u{7a4}\
	\x03\x02\x02\x02\u{7a4}\u{7a5}\x07\u{192}\x02\x02\u{7a5}\u{7a7}\x03\x02\
	\x02\x02\u{7a6}\u{795}\x03\x02\x02\x02\u{7a6}\u{797}\x03\x02\x02\x02\u{7a7}\
	\u{91}\x03\x02\x02\x02\u{7a8}\u{7a9}\x05\u{bc}\x5f\x02\u{7a9}\u{93}\x03\
	\x02\x02\x02\u{7aa}\u{7ab}\x09\x15\x02\x02\u{7ab}\u{95}\x03\x02\x02\x02\
	\u{7ac}\u{7b3}\x07\x69\x02\x02\u{7ad}\u{7af}\x07\u{160}\x02\x02\u{7ae}\u{7b0}\
	\x05\u{102}\u{82}\x02\u{7af}\u{7ae}\x03\x02\x02\x02\u{7af}\u{7b0}\x03\x02\
	\x02\x02\u{7b0}\u{7b1}\x03\x02\x02\x02\u{7b1}\u{7b3}\x05\u{98}\x4d\x02\u{7b2}\
	\u{7ac}\x03\x02\x02\x02\u{7b2}\u{7ad}\x03\x02\x02\x02\u{7b3}\u{97}\x03\x02\
	\x02\x02\u{7b4}\u{7b5}\x07\u{185}\x02\x02\u{7b5}\u{7b9}\x07\x44\x02\x02\
	\u{7b6}\u{7b7}\x07\u{187}\x02\x02\u{7b7}\u{7b9}\x07\x44\x02\x02\u{7b8}\u{7b4}\
	\x03\x02\x02\x02\u{7b8}\u{7b6}\x03\x02\x02\x02\u{7b9}\u{99}\x03\x02\x02\
	\x02\u{7ba}\u{7bb}\x05\u{13c}\u{9f}\x02\u{7bb}\u{7bc}\x07\x19\x02\x02\u{7bc}\
	\u{7bd}\x05\u{d0}\x69\x02\u{7bd}\u{9b}\x03\x02\x02\x02\u{7be}\u{7bf}\x05\
	\u{8c}\x47\x02\u{7bf}\u{9d}\x03\x02\x02\x02\u{7c0}\u{7c4}\x05\u{9c}\x4f\
	\x02\u{7c1}\u{7c3}\x05\u{b0}\x59\x02\u{7c2}\u{7c1}\x03\x02\x02\x02\u{7c3}\
	\u{7c6}\x03\x02\x02\x02\u{7c4}\u{7c2}\x03\x02\x02\x02\u{7c4}\u{7c5}\x03\
	\x02\x02\x02\u{7c5}\u{7cc}\x03\x02\x02\x02\u{7c6}\u{7c4}\x03\x02\x02\x02\
	\u{7c7}\u{7c8}\x07\u{191}\x02\x02\u{7c8}\u{7c9}\x05\u{9e}\x50\x02\u{7c9}\
	\u{7ca}\x07\u{192}\x02\x02\u{7ca}\u{7cc}\x03\x02\x02\x02\u{7cb}\u{7c0}\x03\
	\x02\x02\x02\u{7cb}\u{7c7}\x03\x02\x02\x02\u{7cc}\u{9f}\x03\x02\x02\x02\
	\u{7cd}\u{7d2}\x05\u{d0}\x69\x02\u{7ce}\u{7d0}\x07\x19\x02\x02\u{7cf}\u{7ce}\
	\x03\x02\x02\x02\u{7cf}\u{7d0}\x03\x02\x02\x02\u{7d0}\u{7d1}\x03\x02\x02\
	\x02\u{7d1}\u{7d3}\x05\u{13c}\u{9f}\x02\u{7d2}\u{7cf}\x03\x02\x02\x02\u{7d2}\
	\u{7d3}\x03\x02\x02\x02\u{7d3}\u{a1}\x03\x02\x02\x02\u{7d4}\u{7d5}\x05\u{13c}\
	\u{9f}\x02\u{7d5}\u{a3}\x03\x02\x02\x02\u{7d6}\u{7d9}\x05\u{d0}\x69\x02\
	\u{7d7}\u{7d8}\x07\x19\x02\x02\u{7d8}\u{7da}\x05\x32\x1a\x02\u{7d9}\u{7d7}\
	\x03\x02\x02\x02\u{7d9}\u{7da}\x03\x02\x02\x02\u{7da}\u{a5}\x03\x02\x02\
	\x02\u{7db}\u{7dd}\x07\x19\x02\x02\u{7dc}\u{7db}\x03\x02\x02\x02\u{7dc}\
	\u{7dd}\x03\x02\x02\x02\u{7dd}\u{7de}\x03\x02\x02\x02\u{7de}\u{7e0}\x05\
	\u{13c}\u{9f}\x02\u{7df}\u{7e1}\x05\u{b6}\x5c\x02\u{7e0}\u{7df}\x03\x02\
	\x02\x02\u{7e0}\u{7e1}\x03\x02\x02\x02\u{7e1}\u{7e3}\x03\x02\x02\x02\u{7e2}\
	\u{7dc}\x03\x02\x02\x02\u{7e2}\u{7e3}\x03\x02\x02\x02\u{7e3}\u{a7}\x03\x02\
	\x02\x02\u{7e4}\u{7e5}\x05\u{13c}\u{9f}\x02\u{7e5}\u{7e6}\x07\x7c\x02\x02\
	\u{7e6}\u{7e7}\x05\u{13c}\u{9f}\x02\u{7e7}\u{7e8}\x07\u{96}\x02\x02\u{7e8}\
	\u{7e9}\x07\u{191}\x02\x02\u{7e9}\u{7ea}\x05\u{aa}\x56\x02\u{7ea}\u{7eb}\
	\x07\u{192}\x02\x02\u{7eb}\u{a9}\x03\x02\x02\x02\u{7ec}\u{7f1}\x05\u{13c}\
	\u{9f}\x02\u{7ed}\u{7ee}\x07\x37\x02\x02\u{7ee}\u{7f0}\x05\u{13c}\u{9f}\
	\x02\u{7ef}\u{7ed}\x03\x02\x02\x02\u{7f0}\u{7f3}\x03\x02\x02\x02\u{7f1}\
	\u{7ef}\x03\x02\x02\x02\u{7f1}\u{7f2}\x03\x02\x02\x02\u{7f2}\u{7f5}\x03\
	\x02\x02\x02\u{7f3}\u{7f1}\x03\x02\x02\x02\u{7f4}\u{7f6}\x07\x37\x02\x02\
	\u{7f5}\u{7f4}\x03\x02\x02\x02\u{7f5}\u{7f6}\x03\x02\x02\x02\u{7f6}\u{ab}\
	\x03\x02\x02\x02\u{7f7}\u{7f8}\x05\u{a8}\x55\x02\u{7f8}\u{ad}\x03\x02\x02\
	\x02\u{7f9}\u{7fe}\x05\u{a4}\x53\x02\u{7fa}\u{7fb}\x07\x37\x02\x02\u{7fb}\
	\u{7fd}\x05\u{a4}\x53\x02\u{7fc}\u{7fa}\x03\x02\x02\x02\u{7fd}\u{800}\x03\
	\x02\x02\x02\u{7fe}\u{7fc}\x03\x02\x02\x02\u{7fe}\u{7ff}\x03\x02\x02\x02\
	\u{7ff}\u{802}\x03\x02\x02\x02\u{800}\u{7fe}\x03\x02\x02\x02\u{801}\u{803}\
	\x07\x37\x02\x02\u{802}\u{801}\x03\x02\x02\x02\u{802}\u{803}\x03\x02\x02\
	\x02\u{803}\u{af}\x03\x02\x02\x02\u{804}\u{805}\x07\u{108}\x02\x02\u{805}\
	\u{806}\x07\u{191}\x02\x02\u{806}\u{807}\x05\u{a0}\x51\x02\u{807}\u{808}\
	\x07\x7c\x02\x02\u{808}\u{809}\x05\u{a2}\x52\x02\u{809}\u{80a}\x07\u{96}\
	\x02\x02\u{80a}\u{80b}\x07\u{191}\x02\x02\u{80b}\u{80c}\x05\u{ae}\x58\x02\
	\u{80c}\u{80d}\x07\u{192}\x02\x02\u{80d}\u{80e}\x07\u{192}\x02\x02\u{80e}\
	\u{80f}\x05\u{a6}\x54\x02\u{80f}\u{81a}\x03\x02\x02\x02\u{810}\u{812}\x07\
	\u{16e}\x02\x02\u{811}\u{813}\x05\x10\x09\x02\u{812}\u{811}\x03\x02\x02\
	\x02\u{812}\u{813}\x03\x02\x02\x02\u{813}\u{814}\x03\x02\x02\x02\u{814}\
	\u{815}\x07\u{191}\x02\x02\u{815}\u{816}\x05\u{ac}\x57\x02\u{816}\u{817}\
	\x07\u{192}\x02\x02\u{817}\u{818}\x05\u{a6}\x54\x02\u{818}\u{81a}\x03\x02\
	\x02\x02\u{819}\u{804}\x03\x02\x02\x02\u{819}\u{810}\x03\x02\x02\x02\u{81a}\
	\u{b1}\x03\x02\x02\x02\u{81b}\u{821}\x05\u{134}\u{9b}\x02\u{81c}\u{81d}\
	\x07\u{191}\x02\x02\u{81d}\u{81e}\x05\x26\x14\x02\u{81e}\u{81f}\x07\u{192}\
	\x02\x02\u{81f}\u{821}\x03\x02\x02\x02\u{820}\u{81b}\x03\x02\x02\x02\u{820}\
	\u{81c}\x03\x02\x02\x02\u{821}\u{b3}\x03\x02\x02\x02\u{822}\u{82c}\x05\u{b2}\
	\x5a\x02\u{823}\u{825}\x07\x19\x02\x02\u{824}\u{823}\x03\x02\x02\x02\u{824}\
	\u{825}\x03\x02\x02\x02\u{825}\u{826}\x03\x02\x02\x02\u{826}\u{82a}\x05\
	\u{13c}\u{9f}\x02\u{827}\u{82b}\x05\u{b6}\x5c\x02\u{828}\u{829}\x07\x1b\
	\x02\x02\u{829}\u{82b}\x05\u{13c}\u{9f}\x02\u{82a}\u{827}\x03\x02\x02\x02\
	\u{82a}\u{828}\x03\x02\x02\x02\u{82a}\u{82b}\x03\x02\x02\x02\u{82b}\u{82d}\
	\x03\x02\x02\x02\u{82c}\u{824}\x03\x02\x02\x02\u{82c}\u{82d}\x03\x02\x02\
	\x02\u{82d}\u{b5}\x03\x02\x02\x02\u{82e}\u{83e}\x05\u{13c}\u{9f}\x02\u{82f}\
	\u{830}\x07\u{191}\x02\x02\u{830}\u{835}\x05\u{13c}\u{9f}\x02\u{831}\u{832}\
	\x07\x37\x02\x02\u{832}\u{834}\x05\u{13c}\u{9f}\x02\u{833}\u{831}\x03\x02\
	\x02\x02\u{834}\u{837}\x03\x02\x02\x02\u{835}\u{833}\x03\x02\x02\x02\u{835}\
	\u{836}\x03\x02\x02\x02\u{836}\u{839}\x03\x02\x02\x02\u{837}\u{835}\x03\
	\x02\x02\x02\u{838}\u{83a}\x07\x37\x02\x02\u{839}\u{838}\x03\x02\x02\x02\
	\u{839}\u{83a}\x03\x02\x02\x02\u{83a}\u{83b}\x03\x02\x02\x02\u{83b}\u{83c}\
	\x07\u{192}\x02\x02\u{83c}\u{83e}\x03\x02\x02\x02\u{83d}\u{82e}\x03\x02\
	\x02\x02\u{83d}\u{82f}\x03\x02\x02\x02\u{83e}\u{b7}\x03\x02\x02\x02\u{83f}\
	\u{840}\x05\u{13c}\u{9f}\x02\u{840}\u{841}\x05\u{114}\u{8b}\x02\u{841}\u{b9}\
	\x03\x02\x02\x02\u{842}\u{843}\x07\u{191}\x02\x02\u{843}\u{848}\x05\u{b8}\
	\x5d\x02\u{844}\u{845}\x07\x37\x02\x02\u{845}\u{847}\x05\u{b8}\x5d\x02\u{846}\
	\u{844}\x03\x02\x02\x02\u{847}\u{84a}\x03\x02\x02\x02\u{848}\u{846}\x03\
	\x02\x02\x02\u{848}\u{849}\x03\x02\x02\x02\u{849}\u{84c}\x03\x02\x02\x02\
	\u{84a}\u{848}\x03\x02\x02\x02\u{84b}\u{84d}\x07\x37\x02\x02\u{84c}\u{84b}\
	\x03\x02\x02\x02\u{84c}\u{84d}\x03\x02\x02\x02\u{84d}\u{84e}\x03\x02\x02\
	\x02\u{84e}\u{84f}\x07\u{192}\x02\x02\u{84f}\u{bb}\x03\x02\x02\x02\u{850}\
	\u{85a}\x05\u{b4}\x5b\x02\u{851}\u{852}\x07\u{16e}\x02\x02\u{852}\u{853}\
	\x05\u{d0}\x69\x02\u{853}\u{854}\x07\x19\x02\x02\u{854}\u{857}\x05\u{13c}\
	\u{9f}\x02\u{855}\u{856}\x07\x1b\x02\x02\u{856}\u{858}\x05\u{13c}\u{9f}\
	\x02\u{857}\u{855}\x03\x02\x02\x02\u{857}\u{858}\x03\x02\x02\x02\u{858}\
	\u{85a}\x03\x02\x02\x02\u{859}\u{850}\x03\x02\x02\x02\u{859}\u{851}\x03\
	\x02\x02\x02\u{85a}\u{bd}\x03\x02\x02\x02\u{85b}\u{85c}\x05\u{e6}\x74\x02\
	\u{85c}\u{868}\x07\u{191}\x02\x02\u{85d}\u{862}\x05\u{c4}\x63\x02\u{85e}\
	\u{85f}\x07\x37\x02\x02\u{85f}\u{861}\x05\u{c4}\x63\x02\u{860}\u{85e}\x03\
	\x02\x02\x02\u{861}\u{864}\x03\x02\x02\x02\u{862}\u{860}\x03\x02\x02\x02\
	\u{862}\u{863}\x03\x02\x02\x02\u{863}\u{866}\x03\x02\x02\x02\u{864}\u{862}\
	\x03\x02\x02\x02\u{865}\u{867}\x07\x37\x02\x02\u{866}\u{865}\x03\x02\x02\
	\x02\u{866}\u{867}\x03\x02\x02\x02\u{867}\u{869}\x03\x02\x02\x02\u{868}\
	\u{85d}\x03\x02\x02\x02\u{868}\u{869}\x03\x02\x02\x02\u{869}\u{86b}\x03\
	\x02\x02\x02\u{86a}\u{86c}\x05\u{c0}\x61\x02\u{86b}\u{86a}\x03\x02\x02\x02\
	\u{86b}\u{86c}\x03\x02\x02\x02\u{86c}\u{86d}\x03\x02\x02\x02\u{86d}\u{86f}\
	\x07\u{192}\x02\x02\u{86e}\u{870}\x05\u{11e}\u{90}\x02\u{86f}\u{86e}\x03\
	\x02\x02\x02\u{86f}\u{870}\x03\x02\x02\x02\u{870}\u{bf}\x03\x02\x02\x02\
	\u{871}\u{872}\x07\x42\x02\x02\u{872}\u{877}\x05\u{ce}\x68\x02\u{873}\u{874}\
	\x07\x37\x02\x02\u{874}\u{876}\x05\u{ce}\x68\x02\u{875}\u{873}\x03\x02\x02\
	\x02\u{876}\u{879}\x03\x02\x02\x02\u{877}\u{875}\x03\x02\x02\x02\u{877}\
	\u{878}\x03\x02\x02\x02\u{878}\u{87b}\x03\x02\x02\x02\u{879}\u{877}\x03\
	\x02\x02\x02\u{87a}\u{87c}\x07\x37\x02\x02\u{87b}\u{87a}\x03\x02\x02\x02\
	\u{87b}\u{87c}\x03\x02\x02\x02\u{87c}\u{c1}\x03\x02\x02\x02\u{87d}\u{87e}\
	\x05\u{13c}\u{9f}\x02\u{87e}\u{c3}\x03\x02\x02\x02\u{87f}\u{880}\x05\u{c2}\
	\x62\x02\u{880}\u{881}\x07\x04\x02\x02\u{881}\u{883}\x03\x02\x02\x02\u{882}\
	\u{87f}\x03\x02\x02\x02\u{882}\u{883}\x03\x02\x02\x02\u{883}\u{887}\x03\
	\x02\x02\x02\u{884}\u{888}\x05\u{c6}\x64\x02\u{885}\u{888}\x05\u{ca}\x66\
	\x02\u{886}\u{888}\x05\u{d0}\x69\x02\u{887}\u{884}\x03\x02\x02\x02\u{887}\
	\u{885}\x03\x02\x02\x02\u{887}\u{886}\x03\x02\x02\x02\u{888}\u{c5}\x03\x02\
	\x02\x02\u{889}\u{89e}\x05\u{c8}\x65\x02\u{88a}\u{88b}\x07\u{fb}\x02\x02\
	\u{88b}\u{89c}\x07\x26\x02\x02\u{88c}\u{898}\x07\u{191}\x02\x02\u{88d}\u{892}\
	\x05\u{d0}\x69\x02\u{88e}\u{88f}\x07\x37\x02\x02\u{88f}\u{891}\x05\u{d0}\
	\x69\x02\u{890}\u{88e}\x03\x02\x02\x02\u{891}\u{894}\x03\x02\x02\x02\u{892}\
	\u{890}\x03\x02\x02\x02\u{892}\u{893}\x03\x02\x02\x02\u{893}\u{896}\x03\
	\x02\x02\x02\u{894}\u{892}\x03\x02\x02\x02\u{895}\u{897}\x07\x37\x02\x02\
	\u{896}\u{895}\x03\x02\x02\x02\u{896}\u{897}\x03\x02\x02\x02\u{897}\u{899}\
	\x03\x02\x02\x02\u{898}\u{88d}\x03\x02\x02\x02\u{898}\u{899}\x03\x02\x02\
	\x02\u{899}\u{89a}\x03\x02\x02\x02\u{89a}\u{89d}\x07\u{192}\x02\x02\u{89b}\
	\u{89d}\x05\u{d0}\x69\x02\u{89c}\u{88c}\x03\x02\x02\x02\u{89c}\u{89b}\x03\
	\x02\x02\x02\u{89d}\u{89f}\x03\x02\x02\x02\u{89e}\u{88a}\x03\x02\x02\x02\
	\u{89e}\u{89f}\x03\x02\x02\x02\u{89f}\u{8a6}\x03\x02\x02\x02\u{8a0}\u{8a1}\
	\x07\u{112}\x02\x02\u{8a1}\u{8a2}\x07\u{182}\x02\x02\u{8a2}\u{8a7}\x07\x65\
	\x02\x02\u{8a3}\u{8a4}\x07\u{b1}\x02\x02\u{8a4}\u{8a5}\x07\u{182}\x02\x02\
	\u{8a5}\u{8a7}\x07\x65\x02\x02\u{8a6}\u{8a0}\x03\x02\x02\x02\u{8a6}\u{8a3}\
	\x03\x02\x02\x02\u{8a6}\u{8a7}\x03\x02\x02\x02\u{8a7}\u{8bb}\x03\x02\x02\
	\x02\u{8a8}\u{8a9}\x07\u{f3}\x02\x02\u{8a9}\u{8b9}\x07\x26\x02\x02\u{8aa}\
	\u{8ab}\x07\u{191}\x02\x02\u{8ab}\u{8b0}\x05\x6a\x36\x02\u{8ac}\u{8ad}\x07\
	\x37\x02\x02\u{8ad}\u{8af}\x05\x6a\x36\x02\u{8ae}\u{8ac}\x03\x02\x02\x02\
	\u{8af}\u{8b2}\x03\x02\x02\x02\u{8b0}\u{8ae}\x03\x02\x02\x02\u{8b0}\u{8b1}\
	\x03\x02\x02\x02\u{8b1}\u{8b4}\x03\x02\x02\x02\u{8b2}\u{8b0}\x03\x02\x02\
	\x02\u{8b3}\u{8b5}\x07\x37\x02\x02\u{8b4}\u{8b3}\x03\x02\x02\x02\u{8b4}\
	\u{8b5}\x03\x02\x02\x02\u{8b5}\u{8b6}\x03\x02\x02\x02\u{8b6}\u{8b7}\x07\
	\u{192}\x02\x02\u{8b7}\u{8ba}\x03\x02\x02\x02\u{8b8}\u{8ba}\x05\x6a\x36\
	\x02\u{8b9}\u{8aa}\x03\x02\x02\x02\u{8b9}\u{8b8}\x03\x02\x02\x02\u{8ba}\
	\u{8bc}\x03\x02\x02\x02\u{8bb}\u{8a8}\x03\x02\x02\x02\u{8bb}\u{8bc}\x03\
	\x02\x02\x02\u{8bc}\u{c7}\x03\x02\x02\x02\u{8bd}\u{8be}\x07\u{14e}\x02\x02\
	\u{8be}\u{8bf}\x07\u{191}\x02\x02\u{8bf}\u{8c0}\x05\u{132}\u{9a}\x02\u{8c0}\
	\u{8c8}\x07\u{192}\x02\x02\u{8c1}\u{8c3}\x07\x19\x02\x02\u{8c2}\u{8c1}\x03\
	\x02\x02\x02\u{8c2}\u{8c3}\x03\x02\x02\x02\u{8c3}\u{8c4}\x03\x02\x02\x02\
	\u{8c4}\u{8c6}\x05\u{13c}\u{9f}\x02\u{8c5}\u{8c7}\x05\u{b6}\x5c\x02\u{8c6}\
	\u{8c5}\x03\x02\x02\x02\u{8c6}\u{8c7}\x03\x02\x02\x02\u{8c7}\u{8c9}\x03\
	\x02\x02\x02\u{8c8}\u{8c2}\x03\x02\x02\x02\u{8c8}\u{8c9}\x03\x02\x02\x02\
	\u{8c9}\u{8d8}\x03\x02\x02\x02\u{8ca}\u{8cb}\x07\u{14e}\x02\x02\u{8cb}\u{8cc}\
	\x07\u{191}\x02\x02\u{8cc}\u{8cd}\x05\x26\x14\x02\u{8cd}\u{8d5}\x07\u{192}\
	\x02\x02\u{8ce}\u{8d0}\x07\x19\x02\x02\u{8cf}\u{8ce}\x03\x02\x02\x02\u{8cf}\
	\u{8d0}\x03\x02\x02\x02\u{8d0}\u{8d1}\x03\x02\x02\x02\u{8d1}\u{8d3}\x05\
	\u{13c}\u{9f}\x02\u{8d2}\u{8d4}\x05\u{b6}\x5c\x02\u{8d3}\u{8d2}\x03\x02\
	\x02\x02\u{8d3}\u{8d4}\x03\x02\x02\x02\u{8d4}\u{8d6}\x03\x02\x02\x02\u{8d5}\
	\u{8cf}\x03\x02\x02\x02\u{8d5}\u{8d6}\x03\x02\x02\x02\u{8d6}\u{8d8}\x03\
	\x02\x02\x02\u{8d7}\u{8bd}\x03\x02\x02\x02\u{8d7}\u{8ca}\x03\x02\x02\x02\
	\u{8d8}\u{c9}\x03\x02\x02\x02\u{8d9}\u{8da}\x07\x5c\x02\x02\u{8da}\u{8db}\
	\x07\u{191}\x02\x02\u{8db}\u{8e0}\x05\u{cc}\x67\x02\u{8dc}\u{8dd}\x07\x37\
	\x02\x02\u{8dd}\u{8df}\x05\u{cc}\x67\x02\u{8de}\u{8dc}\x03\x02\x02\x02\u{8df}\
	\u{8e2}\x03\x02\x02\x02\u{8e0}\u{8de}\x03\x02\x02\x02\u{8e0}\u{8e1}\x03\
	\x02\x02\x02\u{8e1}\u{8e4}\x03\x02\x02\x02\u{8e2}\u{8e0}\x03\x02\x02\x02\
	\u{8e3}\u{8e5}\x07\x37\x02\x02\u{8e4}\u{8e3}\x03\x02\x02\x02\u{8e4}\u{8e5}\
	\x03\x02\x02\x02\u{8e5}\u{8e6}\x03\x02\x02\x02\u{8e6}\u{8e7}\x07\u{192}\
	\x02\x02\u{8e7}\u{8ef}\x03\x02\x02\x02\u{8e8}\u{8e9}\x07\x2e\x02\x02\u{8e9}\
	\u{8ea}\x07\u{191}\x02\x02\u{8ea}\u{8eb}\x07\u{e7}\x02\x02\u{8eb}\u{8ec}\
	\x07\x19\x02\x02\u{8ec}\u{8ed}\x07\x5c\x02\x02\u{8ed}\u{8ef}\x07\u{192}\
	\x02\x02\u{8ee}\u{8d9}\x03\x02\x02\x02\u{8ee}\u{8e8}\x03\x02\x02\x02\u{8ef}\
	\u{cb}\x03\x02\x02\x02\u{8f0}\u{8f2}\x05\u{13c}\u{9f}\x02\u{8f1}\u{8f3}\
	\x05\u{114}\u{8b}\x02\u{8f2}\u{8f1}\x03\x02\x02\x02\u{8f2}\u{8f3}\x03\x02\
	\x02\x02\u{8f3}\u{cd}\x03\x02\x02\x02\u{8f4}\u{8f5}\x07\u{191}\x02\x02\u{8f5}\
	\u{8f6}\x05\u{132}\u{9a}\x02\u{8f6}\u{8f7}\x07\x37\x02\x02\u{8f7}\u{8fc}\
	\x05\u{132}\u{9a}\x02\u{8f8}\u{8f9}\x07\x37\x02\x02\u{8f9}\u{8fb}\x05\u{132}\
	\u{9a}\x02\u{8fa}\u{8f8}\x03\x02\x02\x02\u{8fb}\u{8fe}\x03\x02\x02\x02\u{8fc}\
	\u{8fa}\x03\x02\x02\x02\u{8fc}\u{8fd}\x03\x02\x02\x02\u{8fd}\u{900}\x03\
	\x02\x02\x02\u{8fe}\u{8fc}\x03\x02\x02\x02\u{8ff}\u{901}\x07\x37\x02\x02\
	\u{900}\u{8ff}\x03\x02\x02\x02\u{900}\u{901}\x03\x02\x02\x02\u{901}\u{902}\
	\x03\x02\x02\x02\u{902}\u{903}\x07\u{192}\x02\x02\u{903}\u{cf}\x03\x02\x02\
	\x02\u{904}\u{905}\x05\u{d2}\x6a\x02\u{905}\u{d1}\x03\x02\x02\x02\u{906}\
	\u{907}\x08\x6a\x01\x02\u{907}\u{90b}\x05\u{d6}\x6c\x02\u{908}\u{909}\x07\
	\u{e5}\x02\x02\u{909}\u{90b}\x05\u{d2}\x6a\x05\u{90a}\u{906}\x03\x02\x02\
	\x02\u{90a}\u{908}\x03\x02\x02\x02\u{90b}\u{916}\x03\x02\x02\x02\u{90c}\
	\u{90d}\x0c\x04\x02\x02\u{90d}\u{90e}\x07\x14\x02\x02\u{90e}\u{915}\x05\
	\u{d2}\x6a\x05\u{90f}\u{910}\x0c\x03\x02\x02\u{910}\u{911}\x07\u{f2}\x02\
	\x02\u{911}\u{915}\x05\u{d2}\x6a\x04\u{912}\u{913}\x0c\x07\x02\x02\u{913}\
	\u{915}\x05\u{d4}\x6b\x02\u{914}\u{90c}\x03\x02\x02\x02\u{914}\u{90f}\x03\
	\x02\x02\x02\u{914}\u{912}\x03\x02\x02\x02\u{915}\u{918}\x03\x02\x02\x02\
	\u{916}\u{914}\x03\x02\x02\x02\u{916}\u{917}\x03\x02\x02\x02\u{917}\u{d3}\
	\x03\x02\x02\x02\u{918}\u{916}\x03\x02\x02\x02\u{919}\u{91a}\x05\u{106}\
	\u{84}\x02\u{91a}\u{91b}\x05\u{da}\x6e\x02\u{91b}\u{923}\x03\x02\x02\x02\
	\u{91c}\u{91d}\x05\u{106}\u{84}\x02\u{91d}\u{91e}\x05\u{108}\u{85}\x02\u{91e}\
	\u{91f}\x07\u{191}\x02\x02\u{91f}\u{920}\x05\x26\x14\x02\u{920}\u{921}\x07\
	\u{192}\x02\x02\u{921}\u{923}\x03\x02\x02\x02\u{922}\u{919}\x03\x02\x02\
	\x02\u{922}\u{91c}\x03\x02\x02\x02\u{923}\u{d5}\x03\x02\x02\x02\u{924}\u{926}\
	\x05\u{da}\x6e\x02\u{925}\u{927}\x05\u{d8}\x6d\x02\u{926}\u{925}\x03\x02\
	\x02\x02\u{926}\u{927}\x03\x02\x02\x02\u{927}\u{d7}\x03\x02\x02\x02\u{928}\
	\u{92a}\x07\u{e5}\x02\x02\u{929}\u{928}\x03\x02\x02\x02\u{929}\u{92a}\x03\
	\x02\x02\x02\u{92a}\u{92b}\x03\x02\x02\x02\u{92b}\u{92c}\x07\x22\x02\x02\
	\u{92c}\u{92d}\x05\u{da}\x6e\x02\u{92d}\u{92e}\x07\x14\x02\x02\u{92e}\u{92f}\
	\x05\u{da}\x6e\x02\u{92f}\u{97b}\x03\x02\x02\x02\u{930}\u{932}\x07\u{e5}\
	\x02\x02\u{931}\u{930}\x03\x02\x02\x02\u{931}\u{932}\x03\x02\x02\x02\u{932}\
	\u{933}\x03\x02\x02\x02\u{933}\u{934}\x07\u{96}\x02\x02\u{934}\u{935}\x07\
	\u{191}\x02\x02\u{935}\u{93a}\x05\u{d0}\x69\x02\u{936}\u{937}\x07\x37\x02\
	\x02\u{937}\u{939}\x05\u{d0}\x69\x02\u{938}\u{936}\x03\x02\x02\x02\u{939}\
	\u{93c}\x03\x02\x02\x02\u{93a}\u{938}\x03\x02\x02\x02\u{93a}\u{93b}\x03\
	\x02\x02\x02\u{93b}\u{93e}\x03\x02\x02\x02\u{93c}\u{93a}\x03\x02\x02\x02\
	\u{93d}\u{93f}\x07\x37\x02\x02\u{93e}\u{93d}\x03\x02\x02\x02\u{93e}\u{93f}\
	\x03\x02\x02\x02\u{93f}\u{940}\x03\x02\x02\x02\u{940}\u{941}\x07\u{192}\
	\x02\x02\u{941}\u{97b}\x03\x02\x02\x02\u{942}\u{944}\x07\u{e5}\x02\x02\u{943}\
	\u{942}\x03\x02\x02\x02\u{943}\u{944}\x03\x02\x02\x02\u{944}\u{945}\x03\
	\x02\x02\x02\u{945}\u{946}\x07\u{96}\x02\x02\u{946}\u{947}\x07\u{191}\x02\
	\x02\u{947}\u{948}\x05\x26\x14\x02\u{948}\u{949}\x07\u{192}\x02\x02\u{949}\
	\u{97b}\x03\x02\x02\x02\u{94a}\u{94c}\x07\u{e5}\x02\x02\u{94b}\u{94a}\x03\
	\x02\x02\x02\u{94b}\u{94c}\x03\x02\x02\x02\u{94c}\u{94d}\x03\x02\x02\x02\
	\u{94d}\u{94e}\x09\x16\x02\x02\u{94e}\u{951}\x05\u{da}\x6e\x02\u{94f}\u{950}\
	\x07\x6a\x02\x02\u{950}\u{952}\x05\u{da}\x6e\x02\u{951}\u{94f}\x03\x02\x02\
	\x02\u{951}\u{952}\x03\x02\x02\x02\u{952}\u{97b}\x03\x02\x02\x02\u{953}\
	\u{955}\x07\u{e5}\x02\x02\u{954}\u{953}\x03\x02\x02\x02\u{954}\u{955}\x03\
	\x02\x02\x02\u{955}\u{956}\x03\x02\x02\x02\u{956}\u{957}\x07\u{140}\x02\
	\x02\u{957}\u{958}\x07\u{15a}\x02\x02\u{958}\u{95b}\x05\u{da}\x6e\x02\u{959}\
	\u{95a}\x07\x6a\x02\x02\u{95a}\u{95c}\x05\u{da}\x6e\x02\u{95b}\u{959}\x03\
	\x02\x02\x02\u{95b}\u{95c}\x03\x02\x02\x02\u{95c}\u{97b}\x03\x02\x02\x02\
	\u{95d}\u{95f}\x07\u{a5}\x02\x02\u{95e}\u{960}\x07\u{e5}\x02\x02\u{95f}\
	\u{95e}\x03\x02\x02\x02\u{95f}\u{960}\x03\x02\x02\x02\u{960}\u{961}\x03\
	\x02\x02\x02\u{961}\u{97b}\x07\u{e7}\x02\x02\u{962}\u{964}\x07\u{a5}\x02\
	\x02\u{963}\u{965}\x07\u{e5}\x02\x02\u{964}\u{963}\x03\x02\x02\x02\u{964}\
	\u{965}\x03\x02\x02\x02\u{965}\u{966}\x03\x02\x02\x02\u{966}\u{967}\x07\
	\x5d\x02\x02\u{967}\u{968}\x07\x7f\x02\x02\u{968}\u{97b}\x05\u{da}\x6e\x02\
	\u{969}\u{97b}\x07\u{e6}\x02\x02\u{96a}\u{97b}\x07\u{a7}\x02\x02\u{96b}\
	\u{96d}\x07\u{a5}\x02\x02\u{96c}\u{96e}\x07\u{e5}\x02\x02\u{96d}\u{96c}\
	\x03\x02\x02\x02\u{96d}\u{96e}\x03\x02\x02\x02\u{96e}\u{96f}\x03\x02\x02\
	\x02\u{96f}\u{97b}\x07\u{15f}\x02\x02\u{970}\u{972}\x07\u{a5}\x02\x02\u{971}\
	\u{973}\x07\u{e5}\x02\x02\u{972}\u{971}\x03\x02\x02\x02\u{972}\u{973}\x03\
	\x02\x02\x02\u{973}\u{974}\x03\x02\x02\x02\u{974}\u{97b}\x07\x74\x02\x02\
	\u{975}\u{977}\x07\u{a5}\x02\x02\u{976}\u{978}\x07\u{e5}\x02\x02\u{977}\
	\u{976}\x03\x02\x02\x02\u{977}\u{978}\x03\x02\x02\x02\u{978}\u{979}\x03\
	\x02\x02\x02\u{979}\u{97b}\x07\u{16a}\x02\x02\u{97a}\u{929}\x03\x02\x02\
	\x02\u{97a}\u{931}\x03\x02\x02\x02\u{97a}\u{943}\x03\x02\x02\x02\u{97a}\
	\u{94b}\x03\x02\x02\x02\u{97a}\u{954}\x03\x02\x02\x02\u{97a}\u{95d}\x03\
	\x02\x02\x02\u{97a}\u{962}\x03\x02\x02\x02\u{97a}\u{969}\x03\x02\x02\x02\
	\u{97a}\u{96a}\x03\x02\x02\x02\u{97a}\u{96b}\x03\x02\x02\x02\u{97a}\u{970}\
	\x03\x02\x02\x02\u{97a}\u{975}\x03\x02\x02\x02\u{97b}\u{d9}\x03\x02\x02\
	\x02\u{97c}\u{97d}\x08\x6e\x01\x02\u{97d}\u{97f}\x05\u{dc}\x6f\x02\u{97e}\
	\u{980}\x07\x05\x02\x02\u{97f}\u{97e}\x03\x02\x02\x02\u{97f}\u{980}\x03\
	\x02\x02\x02\u{980}\u{984}\x03\x02\x02\x02\u{981}\u{982}\x09\x17\x02\x02\
	\u{982}\u{984}\x05\u{da}\x6e\x0a\u{983}\u{97c}\x03\x02\x02\x02\u{983}\u{981}\
	\x03\x02\x02\x02\u{984}\u{99f}\x03\x02\x02\x02\u{985}\u{986}\x0c\x09\x02\
	\x02\u{986}\u{987}\x09\x18\x02\x02\u{987}\u{99e}\x05\u{da}\x6e\x0a\u{988}\
	\u{989}\x0c\x08\x02\x02\u{989}\u{98a}\x09\x19\x02\x02\u{98a}\u{99e}\x05\
	\u{da}\x6e\x09\u{98b}\u{98c}\x0c\x07\x02\x02\u{98c}\u{98d}\x07\u{1a1}\x02\
	\x02\u{98d}\u{99e}\x05\u{da}\x6e\x08\u{98e}\u{98f}\x0c\x06\x02\x02\u{98f}\
	\u{990}\x07\u{1aa}\x02\x02\u{990}\u{99e}\x05\u{da}\x6e\x07\u{991}\u{992}\
	\x0c\x05\x02\x02\u{992}\u{993}\x09\x1a\x02\x02\u{993}\u{99e}\x05\u{da}\x6e\
	\x06\u{994}\u{995}\x0c\x04\x02\x02\u{995}\u{996}\x09\x1b\x02\x02\u{996}\
	\u{99e}\x05\u{da}\x6e\x05\u{997}\u{998}\x0c\x03\x02\x02\u{998}\u{999}\x07\
	\u{1ab}\x02\x02\u{999}\u{99e}\x05\u{da}\x6e\x04\u{99a}\u{99b}\x0c\x0b\x02\
	\x02\u{99b}\u{99c}\x07\x1b\x02\x02\u{99c}\u{99e}\x05\u{104}\u{83}\x02\u{99d}\
	\u{985}\x03\x02\x02\x02\u{99d}\u{988}\x03\x02\x02\x02\u{99d}\u{98b}\x03\
	\x02\x02\x02\u{99d}\u{98e}\x03\x02\x02\x02\u{99d}\u{991}\x03\x02\x02\x02\
	\u{99d}\u{994}\x03\x02\x02\x02\u{99d}\u{997}\x03\x02\x02\x02\u{99d}\u{99a}\
	\x03\x02\x02\x02\u{99e}\u{9a1}\x03\x02\x02\x02\u{99f}\u{99d}\x03\x02\x02\
	\x02\u{99f}\u{9a0}\x03\x02\x02\x02\u{9a0}\u{db}\x03\x02\x02\x02\u{9a1}\u{99f}\
	\x03\x02\x02\x02\u{9a2}\u{9a3}\x08\x6f\x01\x02\u{9a3}\u{bc3}\x07\u{e7}\x02\
	\x02\u{9a4}\u{bc3}\x05\u{10c}\u{87}\x02\u{9a5}\u{bc3}\x05\u{144}\u{a3}\x02\
	\u{9a6}\u{bc3}\x05\u{10a}\u{86}\x02\u{9a7}\u{bc3}\x05\u{102}\u{82}\x02\u{9a8}\
	\u{bc3}\x07\u{1b6}\x02\x02\u{9a9}\u{9aa}\x05\u{13c}\u{9f}\x02\u{9aa}\u{9ab}\
	\x05\u{102}\u{82}\x02\u{9ab}\u{bc3}\x03\x02\x02\x02\u{9ac}\u{9ad}\x07\x62\
	\x02\x02\u{9ad}\u{9ae}\x07\u{10b}\x02\x02\u{9ae}\u{bc3}\x05\u{102}\u{82}\
	\x02\u{9af}\u{9b0}\x07\u{191}\x02\x02\u{9b0}\u{9b3}\x05\u{d0}\x69\x02\u{9b1}\
	\u{9b2}\x07\x37\x02\x02\u{9b2}\u{9b4}\x05\u{d0}\x69\x02\u{9b3}\u{9b1}\x03\
	\x02\x02\x02\u{9b4}\u{9b5}\x03\x02\x02\x02\u{9b5}\u{9b3}\x03\x02\x02\x02\
	\u{9b5}\u{9b6}\x03\x02\x02\x02\u{9b6}\u{9b8}\x03\x02\x02\x02\u{9b7}\u{9b9}\
	\x07\x37\x02\x02\u{9b8}\u{9b7}\x03\x02\x02\x02\u{9b8}\u{9b9}\x03\x02\x02\
	\x02\u{9b9}\u{9ba}\x03\x02\x02\x02\u{9ba}\u{9bb}\x07\u{192}\x02\x02\u{9bb}\
	\u{bc3}\x03\x02\x02\x02\u{9bc}\u{9bd}\x07\u{12a}\x02\x02\u{9bd}\u{9be}\x07\
	\u{191}\x02\x02\u{9be}\u{9c3}\x05\u{d0}\x69\x02\u{9bf}\u{9c0}\x07\x37\x02\
	\x02\u{9c0}\u{9c2}\x05\u{d0}\x69\x02\u{9c1}\u{9bf}\x03\x02\x02\x02\u{9c2}\
	\u{9c5}\x03\x02\x02\x02\u{9c3}\u{9c1}\x03\x02\x02\x02\u{9c3}\u{9c4}\x03\
	\x02\x02\x02\u{9c4}\u{9c6}\x03\x02\x02\x02\u{9c5}\u{9c3}\x03\x02\x02\x02\
	\u{9c6}\u{9c7}\x07\u{192}\x02\x02\u{9c7}\u{bc3}\x03\x02\x02\x02\u{9c8}\u{9c9}\
	\x07\u{109}\x02\x02\u{9c9}\u{9ca}\x07\u{191}\x02\x02\u{9ca}\u{9cb}\x05\u{da}\
	\x6e\x02\u{9cb}\u{9cc}\x07\u{96}\x02\x02\u{9cc}\u{9cd}\x05\u{da}\x6e\x02\
	\u{9cd}\u{9ce}\x07\u{192}\x02\x02\u{9ce}\u{bc3}\x03\x02\x02\x02\u{9cf}\u{9d0}\
	\x07\u{107}\x02\x02\u{9d0}\u{9d2}\x07\u{195}\x02\x02\u{9d1}\u{9cf}\x03\x02\
	\x02\x02\u{9d1}\u{9d2}\x03\x02\x02\x02\u{9d2}\u{9d3}\x03\x02\x02\x02\u{9d3}\
	\u{9d4}\x09\x1c\x02\x02\u{9d4}\u{9d6}\x07\u{191}\x02\x02\u{9d5}\u{9d7}\x05\
	\x64\x33\x02\u{9d6}\u{9d5}\x03\x02\x02\x02\u{9d6}\u{9d7}\x03\x02\x02\x02\
	\u{9d7}\u{9d8}\x03\x02\x02\x02\u{9d8}\u{9db}\x05\u{d0}\x69\x02\u{9d9}\u{9da}\
	\x07\x37\x02\x02\u{9da}\u{9dc}\x05\u{d0}\x69\x02\u{9db}\u{9d9}\x03\x02\x02\
	\x02\u{9db}\u{9dc}\x03\x02\x02\x02\u{9dc}\u{9de}\x03\x02\x02\x02\u{9dd}\
	\u{9df}\x07\x37\x02\x02\u{9de}\u{9dd}\x03\x02\x02\x02\u{9de}\u{9df}\x03\
	\x02\x02\x02\u{9df}\u{9e0}\x03\x02\x02\x02\u{9e0}\u{9f3}\x07\u{192}\x02\
	\x02\u{9e1}\u{9e2}\x07\u{186}\x02\x02\u{9e2}\u{9e3}\x07\u{89}\x02\x02\u{9e3}\
	\u{9e4}\x07\u{191}\x02\x02\u{9e4}\u{9e5}\x07\u{f3}\x02\x02\u{9e5}\u{9e6}\
	\x07\x26\x02\x02\u{9e6}\u{9eb}\x05\x6a\x36\x02\u{9e7}\u{9e8}\x07\x37\x02\
	\x02\u{9e8}\u{9ea}\x05\x6a\x36\x02\u{9e9}\u{9e7}\x03\x02\x02\x02\u{9ea}\
	\u{9ed}\x03\x02\x02\x02\u{9eb}\u{9e9}\x03\x02\x02\x02\u{9eb}\u{9ec}\x03\
	\x02\x02\x02\u{9ec}\u{9ef}\x03\x02\x02\x02\u{9ed}\u{9eb}\x03\x02\x02\x02\
	\u{9ee}\u{9f0}\x07\x37\x02\x02\u{9ef}\u{9ee}\x03\x02\x02\x02\u{9ef}\u{9f0}\
	\x03\x02\x02\x02\u{9f0}\u{9f1}\x03\x02\x02\x02\u{9f1}\u{9f2}\x07\u{192}\
	\x02\x02\u{9f2}\u{9f4}\x03\x02\x02\x02\u{9f3}\u{9e1}\x03\x02\x02\x02\u{9f3}\
	\u{9f4}\x03\x02\x02\x02\u{9f4}\u{a04}\x03\x02\x02\x02\u{9f5}\u{9f6}\x07\
	\u{f9}\x02\x02\u{9f6}\u{a01}\x07\u{191}\x02\x02\u{9f7}\u{9f8}\x07\u{fb}\
	\x02\x02\u{9f8}\u{9f9}\x07\x26\x02\x02\u{9f9}\u{9fe}\x05\u{d0}\x69\x02\u{9fa}\
	\u{9fb}\x07\x37\x02\x02\u{9fb}\u{9fd}\x05\u{d0}\x69\x02\u{9fc}\u{9fa}\x03\
	\x02\x02\x02\u{9fd}\u{a00}\x03\x02\x02\x02\u{9fe}\u{9fc}\x03\x02\x02\x02\
	\u{9fe}\u{9ff}\x03\x02\x02\x02\u{9ff}\u{a02}\x03\x02\x02\x02\u{a00}\u{9fe}\
	\x03\x02\x02\x02\u{a01}\u{9f7}\x03\x02\x02\x02\u{a01}\u{a02}\x03\x02\x02\
	\x02\u{a02}\u{a03}\x03\x02\x02\x02\u{a03}\u{a05}\x07\u{192}\x02\x02\u{a04}\
	\u{9f5}\x03\x02\x02\x02\u{a04}\u{a05}\x03\x02\x02\x02\u{a05}\u{bc3}\x03\
	\x02\x02\x02\u{a06}\u{a07}\x07\x70\x02\x02\u{a07}\u{a08}\x07\u{191}\x02\
	\x02\u{a08}\u{a09}\x05\x26\x14\x02\u{a09}\u{a0a}\x07\u{192}\x02\x02\u{a0a}\
	\u{bc3}\x03\x02\x02\x02\u{a0b}\u{a0c}\x07\x2b\x02\x02\u{a0c}\u{a0e}\x05\
	\u{d0}\x69\x02\u{a0d}\u{a0f}\x05\u{11a}\u{8e}\x02\u{a0e}\u{a0d}\x03\x02\
	\x02\x02\u{a0f}\u{a10}\x03\x02\x02\x02\u{a10}\u{a0e}\x03\x02\x02\x02\u{a10}\
	\u{a11}\x03\x02\x02\x02\u{a11}\u{a14}\x03\x02\x02\x02\u{a12}\u{a13}\x07\
	\x64\x02\x02\u{a13}\u{a15}\x05\u{d0}\x69\x02\u{a14}\u{a12}\x03\x02\x02\x02\
	\u{a14}\u{a15}\x03\x02\x02\x02\u{a15}\u{a16}\x03\x02\x02\x02\u{a16}\u{a17}\
	\x07\x68\x02\x02\u{a17}\u{bc3}\x03\x02\x02\x02\u{a18}\u{a1a}\x07\x2b\x02\
	\x02\u{a19}\u{a1b}\x05\u{11a}\u{8e}\x02\u{a1a}\u{a19}\x03\x02\x02\x02\u{a1b}\
	\u{a1c}\x03\x02\x02\x02\u{a1c}\u{a1a}\x03\x02\x02\x02\u{a1c}\u{a1d}\x03\
	\x02\x02\x02\u{a1d}\u{a20}\x03\x02\x02\x02\u{a1e}\u{a1f}\x07\x64\x02\x02\
	\u{a1f}\u{a21}\x05\u{d0}\x69\x02\u{a20}\u{a1e}\x03\x02\x02\x02\u{a20}\u{a21}\
	\x03\x02\x02\x02\u{a21}\u{a22}\x03\x02\x02\x02\u{a22}\u{a23}\x07\x68\x02\
	\x02\u{a23}\u{bc3}\x03\x02\x02\x02\u{a24}\u{a25}\x07\x2e\x02\x02\u{a25}\
	\u{a26}\x07\u{191}\x02\x02\u{a26}\u{a27}\x05\u{d0}\x69\x02\u{a27}\u{a28}\
	\x07\x19\x02\x02\u{a28}\u{a29}\x05\u{114}\u{8b}\x02\u{a29}\u{a2a}\x07\u{192}\
	\x02\x02\u{a2a}\u{bc3}\x03\x02\x02\x02\u{a2b}\u{a2c}\x07\u{161}\x02\x02\
	\u{a2c}\u{a2d}\x07\u{191}\x02\x02\u{a2d}\u{a2e}\x05\u{d0}\x69\x02\u{a2e}\
	\u{a2f}\x07\x19\x02\x02\u{a2f}\u{a30}\x05\u{114}\u{8b}\x02\u{a30}\u{a31}\
	\x07\u{192}\x02\x02\u{a31}\u{bc3}\x03\x02\x02\x02\u{a32}\u{a33}\x07\u{15e}\
	\x02\x02\u{a33}\u{a35}\x07\u{191}\x02\x02\u{a34}\u{a36}\x05\u{94}\x4b\x02\
	\u{a35}\u{a34}\x03\x02\x02\x02\u{a35}\u{a36}\x03\x02\x02\x02\u{a36}\u{a38}\
	\x03\x02\x02\x02\u{a37}\u{a39}\x05\u{da}\x6e\x02\u{a38}\u{a37}\x03\x02\x02\
	\x02\u{a38}\u{a39}\x03\x02\x02\x02\u{a39}\u{a3a}\x03\x02\x02\x02\u{a3a}\
	\u{a3b}\x07\x7f\x02\x02\u{a3b}\u{a3c}\x03\x02\x02\x02\u{a3c}\u{a3d}\x05\
	\u{da}\x6e\x02\u{a3d}\u{a3e}\x07\u{192}\x02\x02\u{a3e}\u{bc3}\x03\x02\x02\
	\x02\u{a3f}\u{a40}\x07\u{15e}\x02\x02\u{a40}\u{a48}\x07\u{191}\x02\x02\u{a41}\
	\u{a43}\x05\u{94}\x4b\x02\u{a42}\u{a44}\x05\u{da}\x6e\x02\u{a43}\u{a42}\
	\x03\x02\x02\x02\u{a43}\u{a44}\x03\x02\x02\x02\u{a44}\u{a46}\x03\x02\x02\
	\x02\u{a45}\u{a47}\x07\x7f\x02\x02\u{a46}\u{a45}\x03\x02\x02\x02\u{a46}\
	\u{a47}\x03\x02\x02\x02\u{a47}\u{a49}\x03\x02\x02\x02\u{a48}\u{a41}\x03\
	\x02\x02\x02\u{a48}\u{a49}\x03\x02\x02\x02\u{a49}\u{a4a}\x03\x02\x02\x02\
	\u{a4a}\u{a4b}\x05\u{da}\x6e\x02\u{a4b}\u{a4c}\x07\u{192}\x02\x02\u{a4c}\
	\u{bc3}\x03\x02\x02\x02\u{a4d}\u{a4e}\x07\u{15e}\x02\x02\u{a4e}\u{a4f}\x07\
	\u{191}\x02\x02\u{a4f}\u{a50}\x05\u{da}\x6e\x02\u{a50}\u{a51}\x07\x37\x02\
	\x02\u{a51}\u{a53}\x05\u{da}\x6e\x02\u{a52}\u{a54}\x07\x37\x02\x02\u{a53}\
	\u{a52}\x03\x02\x02\x02\u{a53}\u{a54}\x03\x02\x02\x02\u{a54}\u{a55}\x03\
	\x02\x02\x02\u{a55}\u{a56}\x07\u{192}\x02\x02\u{a56}\u{bc3}\x03\x02\x02\
	\x02\u{a57}\u{a58}\x07\u{14b}\x02\x02\u{a58}\u{a59}\x07\u{191}\x02\x02\u{a59}\
	\u{a5a}\x05\u{da}\x6e\x02\u{a5a}\u{a5b}\x07\x7f\x02\x02\u{a5b}\u{a5e}\x05\
	\u{da}\x6e\x02\u{a5c}\u{a5d}\x07\x7c\x02\x02\u{a5d}\u{a5f}\x05\u{da}\x6e\
	\x02\u{a5e}\u{a5c}\x03\x02\x02\x02\u{a5e}\u{a5f}\x03\x02\x02\x02\u{a5f}\
	\u{a60}\x03\x02\x02\x02\u{a60}\u{a61}\x07\u{192}\x02\x02\u{a61}\u{bc3}\x03\
	\x02\x02\x02\u{a62}\u{a63}\x07\u{e4}\x02\x02\u{a63}\u{a64}\x07\u{191}\x02\
	\x02\u{a64}\u{a67}\x05\u{da}\x6e\x02\u{a65}\u{a66}\x07\x37\x02\x02\u{a66}\
	\u{a68}\x05\u{110}\u{89}\x02\u{a67}\u{a65}\x03\x02\x02\x02\u{a67}\u{a68}\
	\x03\x02\x02\x02\u{a68}\u{a6a}\x03\x02\x02\x02\u{a69}\u{a6b}\x07\x37\x02\
	\x02\u{a6a}\u{a69}\x03\x02\x02\x02\u{a6a}\u{a6b}\x03\x02\x02\x02\u{a6b}\
	\u{a6c}\x03\x02\x02\x02\u{a6c}\u{a6d}\x07\u{192}\x02\x02\u{a6d}\u{bc3}\x03\
	\x02\x02\x02\u{a6e}\u{a6f}\x07\x73\x02\x02\u{a6f}\u{a72}\x07\u{191}\x02\
	\x02\u{a70}\u{a73}\x05\u{102}\u{82}\x02\u{a71}\u{a73}\x05\u{13c}\u{9f}\x02\
	\u{a72}\u{a70}\x03\x02\x02\x02\u{a72}\u{a71}\x03\x02\x02\x02\u{a73}\u{a74}\
	\x03\x02\x02\x02\u{a74}\u{a75}\x07\x7f\x02\x02\u{a75}\u{a76}\x05\u{da}\x6e\
	\x02\u{a76}\u{a77}\x07\u{192}\x02\x02\u{a77}\u{bc3}\x03\x02\x02\x02\u{a78}\
	\u{a79}\x07\x44\x02\x02\u{a79}\u{a7a}\x07\u{191}\x02\x02\u{a7a}\u{a7b}\x07\
	\u{19e}\x02\x02\u{a7b}\u{a7c}\x07\u{192}\x02\x02\u{a7c}\u{bc3}\x05\u{e0}\
	\x71\x02\u{a7d}\u{a7e}\x05\u{de}\x70\x02\u{a7e}\u{a7f}\x05\u{e6}\x74\x02\
	\u{a7f}\u{a8b}\x07\u{191}\x02\x02\u{a80}\u{a82}\x05\x64\x33\x02\u{a81}\u{a80}\
	\x03\x02\x02\x02\u{a81}\u{a82}\x03\x02\x02\x02\u{a82}\u{a83}\x03\x02\x02\
	\x02\u{a83}\u{a88}\x05\u{e2}\x72\x02\u{a84}\u{a85}\x07\x37\x02\x02\u{a85}\
	\u{a87}\x05\u{e2}\x72\x02\u{a86}\u{a84}\x03\x02\x02\x02\u{a87}\u{a8a}\x03\
	\x02\x02\x02\u{a88}\u{a86}\x03\x02\x02\x02\u{a88}\u{a89}\x03\x02\x02\x02\
	\u{a89}\u{a8c}\x03\x02\x02\x02\u{a8a}\u{a88}\x03\x02\x02\x02\u{a8b}\u{a81}\
	\x03\x02\x02\x02\u{a8b}\u{a8c}\x03\x02\x02\x02\u{a8c}\u{a8d}\x03\x02\x02\
	\x02\u{a8d}\u{a8e}\x05\u{e4}\x73\x02\u{a8e}\u{a90}\x03\x02\x02\x02\u{a8f}\
	\u{a91}\x07\x37\x02\x02\u{a90}\u{a8f}\x03\x02\x02\x02\u{a90}\u{a91}\x03\
	\x02\x02\x02\u{a91}\u{a92}\x03\x02\x02\x02\u{a92}\u{a93}\x07\u{192}\x02\
	\x02\u{a93}\u{a94}\x05\u{e0}\x71\x02\u{a94}\u{bc3}\x03\x02\x02\x02\u{a95}\
	\u{a96}\x05\u{13c}\u{9f}\x02\u{a96}\u{a97}\x05\u{11e}\u{90}\x02\u{a97}\u{bc3}\
	\x03\x02\x02\x02\u{a98}\u{a99}\x05\u{13c}\u{9f}\x02\u{a99}\u{a9a}\x07\x06\
	\x02\x02\u{a9a}\u{a9b}\x05\u{d0}\x69\x02\u{a9b}\u{bc3}\x03\x02\x02\x02\u{a9c}\
	\u{aa5}\x07\u{191}\x02\x02\u{a9d}\u{aa2}\x05\u{13c}\u{9f}\x02\u{a9e}\u{a9f}\
	\x07\x37\x02\x02\u{a9f}\u{aa1}\x05\u{13c}\u{9f}\x02\u{aa0}\u{a9e}\x03\x02\
	\x02\x02\u{aa1}\u{aa4}\x03\x02\x02\x02\u{aa2}\u{aa0}\x03\x02\x02\x02\u{aa2}\
	\u{aa3}\x03\x02\x02\x02\u{aa3}\u{aa6}\x03\x02\x02\x02\u{aa4}\u{aa2}\x03\
	\x02\x02\x02\u{aa5}\u{a9d}\x03\x02\x02\x02\u{aa5}\u{aa6}\x03\x02\x02\x02\
	\u{aa6}\u{aa8}\x03\x02\x02\x02\u{aa7}\u{aa9}\x07\x37\x02\x02\u{aa8}\u{aa7}\
	\x03\x02\x02\x02\u{aa8}\u{aa9}\x03\x02\x02\x02\u{aa9}\u{aaa}\x03\x02\x02\
	\x02\u{aaa}\u{aab}\x07\u{192}\x02\x02\u{aab}\u{aac}\x07\x06\x02\x02\u{aac}\
	\u{bc3}\x05\u{d0}\x69\x02\u{aad}\u{aae}\x07\u{191}\x02\x02\u{aae}\u{aaf}\
	\x05\x26\x14\x02\u{aaf}\u{ab0}\x07\u{192}\x02\x02\u{ab0}\u{bc3}\x03\x02\
	\x02\x02\u{ab1}\u{ab2}\x07\x18\x02\x02\u{ab2}\u{abb}\x07\u{193}\x02\x02\
	\u{ab3}\u{ab8}\x05\u{d0}\x69\x02\u{ab4}\u{ab5}\x07\x37\x02\x02\u{ab5}\u{ab7}\
	\x05\u{d0}\x69\x02\u{ab6}\u{ab4}\x03\x02\x02\x02\u{ab7}\u{aba}\x03\x02\x02\
	\x02\u{ab8}\u{ab6}\x03\x02\x02\x02\u{ab8}\u{ab9}\x03\x02\x02\x02\u{ab9}\
	\u{abc}\x03\x02\x02\x02\u{aba}\u{ab8}\x03\x02\x02\x02\u{abb}\u{ab3}\x03\
	\x02\x02\x02\u{abb}\u{abc}\x03\x02\x02\x02\u{abc}\u{abe}\x03\x02\x02\x02\
	\u{abd}\u{abf}\x07\x37\x02\x02\u{abe}\u{abd}\x03\x02\x02\x02\u{abe}\u{abf}\
	\x03\x02\x02\x02\u{abf}\u{ac0}\x03\x02\x02\x02\u{ac0}\u{bc3}\x07\u{194}\
	\x02\x02\u{ac1}\u{bc3}\x05\x32\x1a\x02\u{ac2}\u{ac3}\x07\u{1a5}\x02\x02\
	\u{ac3}\u{bc3}\x07\u{1b7}\x02\x02\u{ac4}\u{ac5}\x07\u{191}\x02\x02\u{ac5}\
	\u{ac6}\x05\u{d0}\x69\x02\u{ac6}\u{ac7}\x07\u{192}\x02\x02\u{ac7}\u{bc3}\
	\x03\x02\x02\x02\u{ac8}\u{ac9}\x07\u{ac}\x02\x02\u{ac9}\u{aca}\x07\u{191}\
	\x02\x02\u{aca}\u{acf}\x05\u{ec}\x77\x02\u{acb}\u{acc}\x05\u{f4}\x7b\x02\
	\u{acc}\u{acd}\x07\u{ed}\x02\x02\u{acd}\u{ace}\x07\x69\x02\x02\u{ace}\u{ad0}\
	\x03\x02\x02\x02\u{acf}\u{acb}\x03\x02\x02\x02\u{acf}\u{ad0}\x03\x02\x02\
	\x02\u{ad0}\u{ad1}\x03\x02\x02\x02\u{ad1}\u{ad2}\x07\u{192}\x02\x02\u{ad2}\
	\u{bc3}\x03\x02\x02\x02\u{ad3}\u{ad4}\x07\u{af}\x02\x02\u{ad4}\u{ad5}\x07\
	\u{191}\x02\x02\u{ad5}\u{ad8}\x05\u{ec}\x77\x02\u{ad6}\u{ad7}\x07\u{121}\
	\x02\x02\u{ad7}\u{ad9}\x05\u{114}\u{8b}\x02\u{ad8}\u{ad6}\x03\x02\x02\x02\
	\u{ad8}\u{ad9}\x03\x02\x02\x02\u{ad9}\u{ade}\x03\x02\x02\x02\u{ada}\u{adb}\
	\x05\u{f6}\x7c\x02\u{adb}\u{adc}\x07\u{ed}\x02\x02\u{adc}\u{add}\x07\x65\
	\x02\x02\u{add}\u{adf}\x03\x02\x02\x02\u{ade}\u{ada}\x03\x02\x02\x02\u{ade}\
	\u{adf}\x03\x02\x02\x02\u{adf}\u{ae4}\x03\x02\x02\x02\u{ae0}\u{ae1}\x05\
	\u{f6}\x7c\x02\u{ae1}\u{ae2}\x07\u{ed}\x02\x02\u{ae2}\u{ae3}\x07\x69\x02\
	\x02\u{ae3}\u{ae5}\x03\x02\x02\x02\u{ae4}\u{ae0}\x03\x02\x02\x02\u{ae4}\
	\u{ae5}\x03\x02\x02\x02\u{ae5}\u{ae6}\x03\x02\x02\x02\u{ae6}\u{ae7}\x07\
	\u{192}\x02\x02\u{ae7}\u{bc3}\x03\x02\x02\x02\u{ae8}\u{ae9}\x07\u{ae}\x02\
	\x02\u{ae9}\u{aea}\x07\u{191}\x02\x02\u{aea}\u{af1}\x05\u{ec}\x77\x02\u{aeb}\
	\u{aec}\x07\u{121}\x02\x02\u{aec}\u{aef}\x05\u{114}\u{8b}\x02\u{aed}\u{aee}\
	\x07\x7e\x02\x02\u{aee}\u{af0}\x05\u{f0}\x79\x02\u{aef}\u{aed}\x03\x02\x02\
	\x02\u{aef}\u{af0}\x03\x02\x02\x02\u{af0}\u{af2}\x03\x02\x02\x02\u{af1}\
	\u{aeb}\x03\x02\x02\x02\u{af1}\u{af2}\x03\x02\x02\x02\u{af2}\u{af6}\x03\
	\x02\x02\x02\u{af3}\u{af4}\x05\u{f8}\x7d\x02\u{af4}\u{af5}\x07\u{189}\x02\
	\x02\u{af5}\u{af7}\x03\x02\x02\x02\u{af6}\u{af3}\x03\x02\x02\x02\u{af6}\
	\u{af7}\x03\x02\x02\x02\u{af7}\u{aff}\x03\x02\x02\x02\u{af8}\u{af9}\x09\
	\x1d\x02\x02\u{af9}\u{afd}\x07\u{114}\x02\x02\u{afa}\u{afb}\x07\u{ed}\x02\
	\x02\u{afb}\u{afc}\x07\u{12f}\x02\x02\u{afc}\u{afe}\x07\u{155}\x02\x02\u{afd}\
	\u{afa}\x03\x02\x02\x02\u{afd}\u{afe}\x03\x02\x02\x02\u{afe}\u{b00}\x03\
	\x02\x02\x02\u{aff}\u{af8}\x03\x02\x02\x02\u{aff}\u{b00}\x03\x02\x02\x02\
	\u{b00}\u{b05}\x03\x02\x02\x02\u{b01}\u{b02}\x05\u{fa}\x7e\x02\u{b02}\u{b03}\
	\x07\u{ed}\x02\x02\u{b03}\u{b04}\x07\x65\x02\x02\u{b04}\u{b06}\x03\x02\x02\
	\x02\u{b05}\u{b01}\x03\x02\x02\x02\u{b05}\u{b06}\x03\x02\x02\x02\u{b06}\
	\u{b0b}\x03\x02\x02\x02\u{b07}\u{b08}\x05\u{fa}\x7e\x02\u{b08}\u{b09}\x07\
	\u{ed}\x02\x02\u{b09}\u{b0a}\x07\x69\x02\x02\u{b0a}\u{b0c}\x03\x02\x02\x02\
	\u{b0b}\u{b07}\x03\x02\x02\x02\u{b0b}\u{b0c}\x03\x02\x02\x02\u{b0c}\u{b0d}\
	\x03\x02\x02\x02\u{b0d}\u{b0e}\x07\u{192}\x02\x02\u{b0e}\u{bc3}\x03\x02\
	\x02\x02\u{b0f}\u{b10}\x07\u{ad}\x02\x02\u{b10}\u{b30}\x07\u{191}\x02\x02\
	\u{b11}\u{b16}\x05\u{fc}\x7f\x02\u{b12}\u{b13}\x07\x37\x02\x02\u{b13}\u{b15}\
	\x05\u{fc}\x7f\x02\u{b14}\u{b12}\x03\x02\x02\x02\u{b15}\u{b18}\x03\x02\x02\
	\x02\u{b16}\u{b14}\x03\x02\x02\x02\u{b16}\u{b17}\x03\x02\x02\x02\u{b17}\
	\u{b1a}\x03\x02\x02\x02\u{b18}\u{b16}\x03\x02\x02\x02\u{b19}\u{b1b}\x07\
	\x37\x02\x02\u{b1a}\u{b19}\x03\x02\x02\x02\u{b1a}\u{b1b}\x03\x02\x02\x02\
	\u{b1b}\u{b22}\x03\x02\x02\x02\u{b1c}\u{b1d}\x07\u{e7}\x02\x02\u{b1d}\u{b1e}\
	\x07\u{ed}\x02\x02\u{b1e}\u{b23}\x07\u{e7}\x02\x02\u{b1f}\u{b20}\x07\x0d\
	\x02\x02\u{b20}\u{b21}\x07\u{ed}\x02\x02\u{b21}\u{b23}\x07\u{e7}\x02\x02\
	\u{b22}\u{b1c}\x03\x02\x02\x02\u{b22}\u{b1f}\x03\x02\x02\x02\u{b22}\u{b23}\
	\x03\x02\x02\x02\u{b23}\u{b2e}\x03\x02\x02\x02\u{b24}\u{b25}\x07\u{185}\
	\x02\x02\u{b25}\u{b27}\x07\u{169}\x02\x02\u{b26}\u{b28}\x07\u{b3}\x02\x02\
	\u{b27}\u{b26}\x03\x02\x02\x02\u{b27}\u{b28}\x03\x02\x02\x02\u{b28}\u{b2f}\
	\x03\x02\x02\x02\u{b29}\u{b2a}\x07\u{187}\x02\x02\u{b2a}\u{b2c}\x07\u{169}\
	\x02\x02\u{b2b}\u{b2d}\x07\u{b3}\x02\x02\u{b2c}\u{b2b}\x03\x02\x02\x02\u{b2c}\
	\u{b2d}\x03\x02\x02\x02\u{b2d}\u{b2f}\x03\x02\x02\x02\u{b2e}\u{b24}\x03\
	\x02\x02\x02\u{b2e}\u{b29}\x03\x02\x02\x02\u{b2e}\u{b2f}\x03\x02\x02\x02\
	\u{b2f}\u{b31}\x03\x02\x02\x02\u{b30}\u{b11}\x03\x02\x02\x02\u{b30}\u{b31}\
	\x03\x02\x02\x02\u{b31}\u{b38}\x03\x02\x02\x02\u{b32}\u{b33}\x07\u{121}\
	\x02\x02\u{b33}\u{b36}\x05\u{114}\u{8b}\x02\u{b34}\u{b35}\x07\x7e\x02\x02\
	\u{b35}\u{b37}\x05\u{f0}\x79\x02\u{b36}\u{b34}\x03\x02\x02\x02\u{b36}\u{b37}\
	\x03\x02\x02\x02\u{b37}\u{b39}\x03\x02\x02\x02\u{b38}\u{b32}\x03\x02\x02\
	\x02\u{b38}\u{b39}\x03\x02\x02\x02\u{b39}\u{b3a}\x03\x02\x02\x02\u{b3a}\
	\u{bc3}\x07\u{192}\x02\x02\u{b3b}\u{b3c}\x07\u{ab}\x02\x02\u{b3c}\u{b50}\
	\x07\u{191}\x02\x02\u{b3d}\u{b42}\x05\u{ee}\x78\x02\u{b3e}\u{b3f}\x07\x37\
	\x02\x02\u{b3f}\u{b41}\x05\u{ee}\x78\x02\u{b40}\u{b3e}\x03\x02\x02\x02\u{b41}\
	\u{b44}\x03\x02\x02\x02\u{b42}\u{b40}\x03\x02\x02\x02\u{b42}\u{b43}\x03\
	\x02\x02\x02\u{b43}\u{b46}\x03\x02\x02\x02\u{b44}\u{b42}\x03\x02\x02\x02\
	\u{b45}\u{b47}\x07\x37\x02\x02\u{b46}\u{b45}\x03\x02\x02\x02\u{b46}\u{b47}\
	\x03\x02\x02\x02\u{b47}\u{b4e}\x03\x02\x02\x02\u{b48}\u{b49}\x07\u{e7}\x02\
	\x02\u{b49}\u{b4a}\x07\u{ed}\x02\x02\u{b4a}\u{b4f}\x07\u{e7}\x02\x02\u{b4b}\
	\u{b4c}\x07\x0d\x02\x02\u{b4c}\u{b4d}\x07\u{ed}\x02\x02\u{b4d}\u{b4f}\x07\
	\u{e7}\x02\x02\u{b4e}\u{b48}\x03\x02\x02\x02\u{b4e}\u{b4b}\x03\x02\x02\x02\
	\u{b4e}\u{b4f}\x03\x02\x02\x02\u{b4f}\u{b51}\x03\x02\x02\x02\u{b50}\u{b3d}\
	\x03\x02\x02\x02\u{b50}\u{b51}\x03\x02\x02\x02\u{b51}\u{b58}\x03\x02\x02\
	\x02\u{b52}\u{b53}\x07\u{121}\x02\x02\u{b53}\u{b56}\x05\u{114}\u{8b}\x02\
	\u{b54}\u{b55}\x07\x7e\x02\x02\u{b55}\u{b57}\x05\u{f0}\x79\x02\u{b56}\u{b54}\
	\x03\x02\x02\x02\u{b56}\u{b57}\x03\x02\x02\x02\u{b57}\u{b59}\x03\x02\x02\
	\x02\u{b58}\u{b52}\x03\x02\x02\x02\u{b58}\u{b59}\x03\x02\x02\x02\u{b59}\
	\u{b5a}\x03\x02\x02\x02\u{b5a}\u{bc3}\x07\u{192}\x02\x02\u{b5b}\u{bc3}\x07\
	\u{1be}\x02\x02\u{b5c}\u{b5d}\x07\x17\x02\x02\u{b5d}\u{b5e}\x07\u{104}\x02\
	\x02\u{b5e}\u{b5f}\x07\u{191}\x02\x02\u{b5f}\u{b60}\x05\u{144}\u{a3}\x02\
	\u{b60}\u{b61}\x07\u{192}\x02\x02\u{b61}\u{b62}\x07\u{186}\x02\x02\u{b62}\
	\u{b63}\x07\u{89}\x02\x02\u{b63}\u{b64}\x07\u{191}\x02\x02\u{b64}\u{b65}\
	\x07\u{f3}\x02\x02\u{b65}\u{b66}\x07\x26\x02\x02\u{b66}\u{b67}\x05\u{d0}\
	\x69\x02\u{b67}\u{b68}\x07\u{192}\x02\x02\u{b68}\u{bc3}\x03\x02\x02\x02\
	\u{b69}\u{b6a}\x07\x17\x02\x02\u{b6a}\u{b6b}\x07\x44\x02\x02\u{b6b}\u{b6c}\
	\x07\u{191}\x02\x02\u{b6c}\u{b6d}\x07\x5d\x02\x02\u{b6d}\u{b6e}\x05\u{e2}\
	\x72\x02\u{b6e}\u{b6f}\x07\u{192}\x02\x02\u{b6f}\u{bc3}\x03\x02\x02\x02\
	\u{b70}\u{b71}\x07\x41\x02\x02\u{b71}\u{b72}\x07\u{191}\x02\x02\u{b72}\u{b73}\
	\x05\u{114}\u{8b}\x02\u{b73}\u{b74}\x07\x37\x02\x02\u{b74}\u{b76}\x05\u{d0}\
	\x69\x02\u{b75}\u{b77}\x07\x37\x02\x02\u{b76}\u{b75}\x03\x02\x02\x02\u{b76}\
	\u{b77}\x03\x02\x02\x02\u{b77}\u{b78}\x03\x02\x02\x02\u{b78}\u{b79}\x07\
	\u{192}\x02\x02\u{b79}\u{bc3}\x03\x02\x02\x02\u{b7a}\u{b7b}\x07\u{103}\x02\
	\x02\u{b7b}\u{b7c}\x07\u{191}\x02\x02\u{b7c}\u{b7d}\x05\u{144}\u{a3}\x02\
	\u{b7d}\u{b7e}\x07\u{192}\x02\x02\u{b7e}\u{b7f}\x07\u{186}\x02\x02\u{b7f}\
	\u{b80}\x07\u{89}\x02\x02\u{b80}\u{b81}\x07\u{191}\x02\x02\u{b81}\u{b82}\
	\x07\u{f3}\x02\x02\u{b82}\u{b83}\x07\x26\x02\x02\u{b83}\u{b85}\x05\u{d0}\
	\x69\x02\u{b84}\u{b86}\x09\x13\x02\x02\u{b85}\u{b84}\x03\x02\x02\x02\u{b85}\
	\u{b86}\x03\x02\x02\x02\u{b86}\u{b87}\x03\x02\x02\x02\u{b87}\u{b97}\x07\
	\u{192}\x02\x02\u{b88}\u{b89}\x07\u{f9}\x02\x02\u{b89}\u{b94}\x07\u{191}\
	\x02\x02\u{b8a}\u{b8b}\x07\u{fb}\x02\x02\u{b8b}\u{b8c}\x07\x26\x02\x02\u{b8c}\
	\u{b91}\x05\u{d0}\x69\x02\u{b8d}\u{b8e}\x07\x37\x02\x02\u{b8e}\u{b90}\x05\
	\u{d0}\x69\x02\u{b8f}\u{b8d}\x03\x02\x02\x02\u{b90}\u{b93}\x03\x02\x02\x02\
	\u{b91}\u{b8f}\x03\x02\x02\x02\u{b91}\u{b92}\x03\x02\x02\x02\u{b92}\u{b95}\
	\x03\x02\x02\x02\u{b93}\u{b91}\x03\x02\x02\x02\u{b94}\u{b8a}\x03\x02\x02\
	\x02\u{b94}\u{b95}\x03\x02\x02\x02\u{b95}\u{b96}\x03\x02\x02\x02\u{b96}\
	\u{b98}\x07\u{192}\x02\x02\u{b97}\u{b88}\x03\x02\x02\x02\u{b97}\u{b98}\x03\
	\x02\x02\x02\u{b98}\u{bc3}\x03\x02\x02\x02\u{b99}\u{b9a}\x07\u{104}\x02\
	\x02\u{b9a}\u{b9b}\x07\u{191}\x02\x02\u{b9b}\u{b9c}\x05\u{144}\u{a3}\x02\
	\u{b9c}\u{b9d}\x07\u{192}\x02\x02\u{b9d}\u{b9e}\x07\u{186}\x02\x02\u{b9e}\
	\u{b9f}\x07\u{89}\x02\x02\u{b9f}\u{ba0}\x07\u{191}\x02\x02\u{ba0}\u{ba1}\
	\x07\u{f3}\x02\x02\u{ba1}\u{ba2}\x07\x26\x02\x02\u{ba2}\u{ba4}\x05\u{d0}\
	\x69\x02\u{ba3}\u{ba5}\x09\x13\x02\x02\u{ba4}\u{ba3}\x03\x02\x02\x02\u{ba4}\
	\u{ba5}\x03\x02\x02\x02\u{ba5}\u{ba6}\x03\x02\x02\x02\u{ba6}\u{bb6}\x07\
	\u{192}\x02\x02\u{ba7}\u{ba8}\x07\u{f9}\x02\x02\u{ba8}\u{bb3}\x07\u{191}\
	\x02\x02\u{ba9}\u{baa}\x07\u{fb}\x02\x02\u{baa}\u{bab}\x07\x26\x02\x02\u{bab}\
	\u{bb0}\x05\u{d0}\x69\x02\u{bac}\u{bad}\x07\x37\x02\x02\u{bad}\u{baf}\x05\
	\u{d0}\x69\x02\u{bae}\u{bac}\x03\x02\x02\x02\u{baf}\u{bb2}\x03\x02\x02\x02\
	\u{bb0}\u{bae}\x03\x02\x02\x02\u{bb0}\u{bb1}\x03\x02\x02\x02\u{bb1}\u{bb4}\
	\x03\x02\x02\x02\u{bb2}\u{bb0}\x03\x02\x02\x02\u{bb3}\u{ba9}\x03\x02\x02\
	\x02\u{bb3}\u{bb4}\x03\x02\x02\x02\u{bb4}\u{bb5}\x03\x02\x02\x02\u{bb5}\
	\u{bb7}\x07\u{192}\x02\x02\u{bb6}\u{ba7}\x03\x02\x02\x02\u{bb6}\u{bb7}\x03\
	\x02\x02\x02\u{bb7}\u{bc3}\x03\x02\x02\x02\u{bb8}\u{bb9}\x09\x1e\x02\x02\
	\u{bb9}\u{bba}\x07\u{191}\x02\x02\u{bba}\u{bbd}\x05\u{d0}\x69\x02\u{bbb}\
	\u{bbc}\x09\x1f\x02\x02\u{bbc}\u{bbe}\x07\u{e8}\x02\x02\u{bbd}\u{bbb}\x03\
	\x02\x02\x02\u{bbd}\u{bbe}\x03\x02\x02\x02\u{bbe}\u{bbf}\x03\x02\x02\x02\
	\u{bbf}\u{bc0}\x07\u{192}\x02\x02\u{bc0}\u{bc1}\x05\u{11e}\u{90}\x02\u{bc1}\
	\u{bc3}\x03\x02\x02\x02\u{bc2}\u{9a2}\x03\x02\x02\x02\u{bc2}\u{9a4}\x03\
	\x02\x02\x02\u{bc2}\u{9a5}\x03\x02\x02\x02\u{bc2}\u{9a6}\x03\x02\x02\x02\
	\u{bc2}\u{9a7}\x03\x02\x02\x02\u{bc2}\u{9a8}\x03\x02\x02\x02\u{bc2}\u{9a9}\
	\x03\x02\x02\x02\u{bc2}\u{9ac}\x03\x02\x02\x02\u{bc2}\u{9af}\x03\x02\x02\
	\x02\u{bc2}\u{9bc}\x03\x02\x02\x02\u{bc2}\u{9c8}\x03\x02\x02\x02\u{bc2}\
	\u{9d1}\x03\x02\x02\x02\u{bc2}\u{a06}\x03\x02\x02\x02\u{bc2}\u{a0b}\x03\
	\x02\x02\x02\u{bc2}\u{a18}\x03\x02\x02\x02\u{bc2}\u{a24}\x03\x02\x02\x02\
	\u{bc2}\u{a2b}\x03\x02\x02\x02\u{bc2}\u{a32}\x03\x02\x02\x02\u{bc2}\u{a3f}\
	\x03\x02\x02\x02\u{bc2}\u{a4d}\x03\x02\x02\x02\u{bc2}\u{a57}\x03\x02\x02\
	\x02\u{bc2}\u{a62}\x03\x02\x02\x02\u{bc2}\u{a6e}\x03\x02\x02\x02\u{bc2}\
	\u{a78}\x03\x02\x02\x02\u{bc2}\u{a7d}\x03\x02\x02\x02\u{bc2}\u{a95}\x03\
	\x02\x02\x02\u{bc2}\u{a98}\x03\x02\x02\x02\u{bc2}\u{a9c}\x03\x02\x02\x02\
	\u{bc2}\u{aad}\x03\x02\x02\x02\u{bc2}\u{ab1}\x03\x02\x02\x02\u{bc2}\u{ac1}\
	\x03\x02\x02\x02\u{bc2}\u{ac2}\x03\x02\x02\x02\u{bc2}\u{ac4}\x03\x02\x02\
	\x02\u{bc2}\u{ac8}\x03\x02\x02\x02\u{bc2}\u{ad3}\x03\x02\x02\x02\u{bc2}\
	\u{ae8}\x03\x02\x02\x02\u{bc2}\u{b0f}\x03\x02\x02\x02\u{bc2}\u{b3b}\x03\
	\x02\x02\x02\u{bc2}\u{b5b}\x03\x02\x02\x02\u{bc2}\u{b5c}\x03\x02\x02\x02\
	\u{bc2}\u{b69}\x03\x02\x02\x02\u{bc2}\u{b70}\x03\x02\x02\x02\u{bc2}\u{b7a}\
	\x03\x02\x02\x02\u{bc2}\u{b99}\x03\x02\x02\x02\u{bc2}\u{bb8}\x03\x02\x02\
	\x02\u{bc3}\u{bd4}\x03\x02\x02\x02\u{bc4}\u{bc5}\x0c\x15\x02\x02\u{bc5}\
	\u{bc6}\x07\x07\x02\x02\u{bc6}\u{bd3}\x05\u{114}\u{8b}\x02\u{bc7}\u{bc8}\
	\x0c\x14\x02\x02\u{bc8}\u{bc9}\x07\x1b\x02\x02\u{bc9}\u{bd3}\x05\u{104}\
	\u{83}\x02\u{bca}\u{bcb}\x0c\x13\x02\x02\u{bcb}\u{bcc}\x07\u{193}\x02\x02\
	\u{bcc}\u{bcd}\x05\u{da}\x6e\x02\u{bcd}\u{bce}\x07\u{194}\x02\x02\u{bce}\
	\u{bd3}\x03\x02\x02\x02\u{bcf}\u{bd0}\x0c\x12\x02\x02\u{bd0}\u{bd1}\x07\
	\u{195}\x02\x02\u{bd1}\u{bd3}\x05\x34\x1b\x02\u{bd2}\u{bc4}\x03\x02\x02\
	\x02\u{bd2}\u{bc7}\x03\x02\x02\x02\u{bd2}\u{bca}\x03\x02\x02\x02\u{bd2}\
	\u{bcf}\x03\x02\x02\x02\u{bd3}\u{bd6}\x03\x02\x02\x02\u{bd4}\u{bd2}\x03\
	\x02\x02\x02\u{bd4}\u{bd5}\x03\x02\x02\x02\u{bd5}\u{dd}\x03\x02\x02\x02\
	\u{bd6}\u{bd4}\x03\x02\x02\x02\u{bd7}\u{bd9}\x05\u{fe}\u{80}\x02\u{bd8}\
	\u{bd7}\x03\x02\x02\x02\u{bd8}\u{bd9}\x03\x02\x02\x02\u{bd9}\u{df}\x03\x02\
	\x02\x02\u{bda}\u{bdc}\x05\u{11c}\u{8f}\x02\u{bdb}\u{bda}\x03\x02\x02\x02\
	\u{bdb}\u{bdc}\x03\x02\x02\x02\u{bdc}\u{be1}\x03\x02\x02\x02\u{bdd}\u{bdf}\
	\x05\u{100}\u{81}\x02\u{bde}\u{bdd}\x03\x02\x02\x02\u{bde}\u{bdf}\x03\x02\
	\x02\x02\u{bdf}\u{be0}\x03\x02\x02\x02\u{be0}\u{be2}\x05\u{11e}\u{90}\x02\
	\u{be1}\u{bde}\x03\x02\x02\x02\u{be1}\u{be2}\x03\x02\x02\x02\u{be2}\u{e1}\
	\x03\x02\x02\x02\u{be3}\u{be6}\x05\u{d0}\x69\x02\u{be4}\u{be6}\x05\u{86}\
	\x44\x02\u{be5}\u{be3}\x03\x02\x02\x02\u{be5}\u{be4}\x03\x02\x02\x02\u{be6}\
	\u{e3}\x03\x02\x02\x02\u{be7}\u{be8}\x07\u{f3}\x02\x02\u{be8}\u{be9}\x07\
	\x26\x02\x02\u{be9}\u{bee}\x05\x6a\x36\x02\u{bea}\u{beb}\x07\x37\x02\x02\
	\u{beb}\u{bed}\x05\x6a\x36\x02\u{bec}\u{bea}\x03\x02\x02\x02\u{bed}\u{bf0}\
	\x03\x02\x02\x02\u{bee}\u{bec}\x03\x02\x02\x02\u{bee}\u{bef}\x03\x02\x02\
	\x02\u{bef}\u{bf2}\x03\x02\x02\x02\u{bf0}\u{bee}\x03\x02\x02\x02\u{bf1}\
	\u{be7}\x03\x02\x02\x02\u{bf1}\u{bf2}\x03\x02\x02\x02\u{bf2}\u{e5}\x03\x02\
	\x02\x02\u{bf3}\u{bfa}\x05\u{132}\u{9a}\x02\u{bf4}\u{bfa}\x07\u{bb}\x02\
	\x02\u{bf5}\u{bfa}\x07\u{124}\x02\x02\u{bf6}\u{bfa}\x07\u{93}\x02\x02\u{bf7}\
	\u{bfa}\x07\u{11c}\x02\x02\u{bf8}\u{bfa}\x07\u{8a}\x02\x02\u{bf9}\u{bf3}\
	\x03\x02\x02\x02\u{bf9}\u{bf4}\x03\x02\x02\x02\u{bf9}\u{bf5}\x03\x02\x02\
	\x02\u{bf9}\u{bf6}\x03\x02\x02\x02\u{bf9}\u{bf7}\x03\x02\x02\x02\u{bf9}\
	\u{bf8}\x03\x02\x02\x02\u{bfa}\u{e7}\x03\x02\x02\x02\u{bfb}\u{bfd}\x09\x20\
	\x02\x02\u{bfc}\u{bfb}\x03\x02\x02\x02\u{bfc}\u{bfd}\x03\x02\x02\x02\u{bfd}\
	\u{bff}\x03\x02\x02\x02\u{bfe}\u{c00}\x05\u{13c}\u{9f}\x02\u{bff}\u{bfe}\
	\x03\x02\x02\x02\u{bff}\u{c00}\x03\x02\x02\x02\u{c00}\u{c01}\x03\x02\x02\
	\x02\u{c01}\u{c02}\x05\u{114}\u{8b}\x02\u{c02}\u{e9}\x03\x02\x02\x02\u{c03}\
	\u{c06}\x05\u{d0}\x69\x02\u{c04}\u{c05}\x07\x19\x02\x02\u{c05}\u{c07}\x05\
	\u{13c}\u{9f}\x02\u{c06}\u{c04}\x03\x02\x02\x02\u{c06}\u{c07}\x03\x02\x02\
	\x02\u{c07}\u{eb}\x03\x02\x02\x02\u{c08}\u{c09}\x05\u{ee}\x78\x02\u{c09}\
	\u{c0a}\x07\x37\x02\x02\u{c0a}\u{c0c}\x05\u{102}\u{82}\x02\u{c0b}\u{c0d}\
	\x07\x37\x02\x02\u{c0c}\u{c0b}\x03\x02\x02\x02\u{c0c}\u{c0d}\x03\x02\x02\
	\x02\u{c0d}\u{c17}\x03\x02\x02\x02\u{c0e}\u{c0f}\x07\u{fe}\x02\x02\u{c0f}\
	\u{c14}\x05\u{f2}\x7a\x02\u{c10}\u{c11}\x07\x37\x02\x02\u{c11}\u{c13}\x05\
	\u{f2}\x7a\x02\u{c12}\u{c10}\x03\x02\x02\x02\u{c13}\u{c16}\x03\x02\x02\x02\
	\u{c14}\u{c12}\x03\x02\x02\x02\u{c14}\u{c15}\x03\x02\x02\x02\u{c15}\u{c18}\
	\x03\x02\x02\x02\u{c16}\u{c14}\x03\x02\x02\x02\u{c17}\u{c0e}\x03\x02\x02\
	\x02\u{c17}\u{c18}\x03\x02\x02\x02\u{c18}\u{c1a}\x03\x02\x02\x02\u{c19}\
	\u{c1b}\x07\x37\x02\x02\u{c1a}\u{c19}\x03\x02\x02\x02\u{c1a}\u{c1b}\x03\
	\x02\x02\x02\u{c1b}\u{ed}\x03\x02\x02\x02\u{c1c}\u{c1f}\x05\u{d0}\x69\x02\
	\u{c1d}\u{c1e}\x07\x7e\x02\x02\u{c1e}\u{c20}\x05\u{f0}\x79\x02\u{c1f}\u{c1d}\
	\x03\x02\x02\x02\u{c1f}\u{c20}\x03\x02\x02\x02\u{c20}\u{ef}\x03\x02\x02\
	\x02\u{c21}\u{c24}\x07\u{aa}\x02\x02\u{c22}\u{c23}\x07\x67\x02\x02\u{c23}\
	\u{c25}\x09\x21\x02\x02\u{c24}\u{c22}\x03\x02\x02\x02\u{c24}\u{c25}\x03\
	\x02\x02\x02\u{c25}\u{f1}\x03\x02\x02\x02\u{c26}\u{c27}\x05\u{ee}\x78\x02\
	\u{c27}\u{c28}\x07\x19\x02\x02\u{c28}\u{c29}\x05\u{13c}\u{9f}\x02\u{c29}\
	\u{f3}\x03\x02\x02\x02\u{c2a}\u{c2b}\x09\x22\x02\x02\u{c2b}\u{f5}\x03\x02\
	\x02\x02\u{c2c}\u{c31}\x07\x69\x02\x02\u{c2d}\u{c31}\x07\u{e7}\x02\x02\u{c2e}\
	\u{c2f}\x07\x52\x02\x02\u{c2f}\u{c31}\x05\u{d0}\x69\x02\u{c30}\u{c2c}\x03\
	\x02\x02\x02\u{c30}\u{c2d}\x03\x02\x02\x02\u{c30}\u{c2e}\x03\x02\x02\x02\
	\u{c31}\u{f7}\x03\x02\x02\x02\u{c32}\u{c34}\x07\u{187}\x02\x02\u{c33}\u{c35}\
	\x07\x18\x02\x02\u{c34}\u{c33}\x03\x02\x02\x02\u{c34}\u{c35}\x03\x02\x02\
	\x02\u{c35}\u{c3e}\x03\x02\x02\x02\u{c36}\u{c38}\x07\u{185}\x02\x02\u{c37}\
	\u{c39}\x09\x23\x02\x02\u{c38}\u{c37}\x03\x02\x02\x02\u{c38}\u{c39}\x03\
	\x02\x02\x02\u{c39}\u{c3b}\x03\x02\x02\x02\u{c3a}\u{c3c}\x07\x18\x02\x02\
	\u{c3b}\u{c3a}\x03\x02\x02\x02\u{c3b}\u{c3c}\x03\x02\x02\x02\u{c3c}\u{c3e}\
	\x03\x02\x02\x02\u{c3d}\u{c32}\x03\x02\x02\x02\u{c3d}\u{c36}\x03\x02\x02\
	\x02\u{c3e}\u{f9}\x03\x02\x02\x02\u{c3f}\u{c46}\x07\x69\x02\x02\u{c40}\u{c46}\
	\x07\u{e7}\x02\x02\u{c41}\u{c42}\x07\x65\x02\x02\u{c42}\u{c46}\x07\x18\x02\
	\x02\u{c43}\u{c44}\x07\x65\x02\x02\u{c44}\u{c46}\x07\u{e9}\x02\x02\u{c45}\
	\u{c3f}\x03\x02\x02\x02\u{c45}\u{c40}\x03\x02\x02\x02\u{c45}\u{c41}\x03\
	\x02\x02\x02\u{c45}\u{c43}\x03\x02\x02\x02\u{c46}\u{fb}\x03\x02\x02\x02\
	\u{c47}\u{c49}\x07\u{b2}\x02\x02\u{c48}\u{c47}\x03\x02\x02\x02\u{c48}\u{c49}\
	\x03\x02\x02\x02\u{c49}\u{c4a}\x03\x02\x02\x02\u{c4a}\u{c4b}\x05\u{d0}\x69\
	\x02\u{c4b}\u{c4c}\x07\u{179}\x02\x02\u{c4c}\u{c4d}\x05\u{ee}\x78\x02\u{c4d}\
	\u{c53}\x03\x02\x02\x02\u{c4e}\u{c4f}\x05\u{d0}\x69\x02\u{c4f}\u{c50}\x07\
	\u{1a4}\x02\x02\u{c50}\u{c51}\x05\u{ee}\x78\x02\u{c51}\u{c53}\x03\x02\x02\
	\x02\u{c52}\u{c48}\x03\x02\x02\x02\u{c52}\u{c4e}\x03\x02\x02\x02\u{c53}\
	\u{fd}\x03\x02\x02\x02\u{c54}\u{c55}\x09\x24\x02\x02\u{c55}\u{ff}\x03\x02\
	\x02\x02\u{c56}\u{c57}\x07\u{94}\x02\x02\u{c57}\u{c5b}\x07\u{e8}\x02\x02\
	\u{c58}\u{c59}\x07\u{11e}\x02\x02\u{c59}\u{c5b}\x07\u{e8}\x02\x02\u{c5a}\
	\u{c56}\x03\x02\x02\x02\u{c5a}\u{c58}\x03\x02\x02\x02\u{c5b}\u{101}\x03\
	\x02\x02\x02\u{c5c}\u{c64}\x07\u{1b3}\x02\x02\u{c5d}\u{c64}\x07\u{1b5}\x02\
	\x02\u{c5e}\u{c61}\x07\u{1b4}\x02\x02\u{c5f}\u{c60}\x07\u{164}\x02\x02\u{c60}\
	\u{c62}\x07\u{1b3}\x02\x02\u{c61}\u{c5f}\x03\x02\x02\x02\u{c61}\u{c62}\x03\
	\x02\x02\x02\u{c62}\u{c64}\x03\x02\x02\x02\u{c63}\u{c5c}\x03\x02\x02\x02\
	\u{c63}\u{c5d}\x03\x02\x02\x02\u{c63}\u{c5e}\x03\x02\x02\x02\u{c64}\u{103}\
	\x03\x02\x02\x02\u{c65}\u{c66}\x07\u{158}\x02\x02\u{c66}\u{c67}\x07\u{18f}\
	\x02\x02\u{c67}\u{c6f}\x05\u{10c}\u{87}\x02\u{c68}\u{c69}\x07\u{158}\x02\
	\x02\u{c69}\u{c6a}\x07\u{18f}\x02\x02\u{c6a}\u{c6f}\x05\u{102}\u{82}\x02\
	\u{c6b}\u{c6c}\x07\u{158}\x02\x02\u{c6c}\u{c6d}\x07\u{18f}\x02\x02\u{c6d}\
	\u{c6f}\x05\u{d0}\x69\x02\u{c6e}\u{c65}\x03\x02\x02\x02\u{c6e}\u{c68}\x03\
	\x02\x02\x02\u{c6e}\u{c6b}\x03\x02\x02\x02\u{c6f}\u{105}\x03\x02\x02\x02\
	\u{c70}\u{c71}\x09\x25\x02\x02\u{c71}\u{107}\x03\x02\x02\x02\u{c72}\u{c73}\
	\x09\x26\x02\x02\u{c73}\u{109}\x03\x02\x02\x02\u{c74}\u{c75}\x09\x27\x02\
	\x02\u{c75}\u{10b}\x03\x02\x02\x02\u{c76}\u{c78}\x07\u{a1}\x02\x02\u{c77}\
	\u{c79}\x09\x19\x02\x02\u{c78}\u{c77}\x03\x02\x02\x02\u{c78}\u{c79}\x03\
	\x02\x02\x02\u{c79}\u{c7c}\x03\x02\x02\x02\u{c7a}\u{c7d}\x05\u{102}\u{82}\
	\x02\u{c7b}\u{c7d}\x07\u{1b7}\x02\x02\u{c7c}\u{c7a}\x03\x02\x02\x02\u{c7c}\
	\u{c7b}\x03\x02\x02\x02\u{c7d}\u{c7e}\x03\x02\x02\x02\u{c7e}\u{c81}\x05\
	\u{10e}\u{88}\x02\u{c7f}\u{c80}\x07\u{15a}\x02\x02\u{c80}\u{c82}\x05\u{10e}\
	\u{88}\x02\u{c81}\u{c7f}\x03\x02\x02\x02\u{c81}\u{c82}\x03\x02\x02\x02\u{c82}\
	\u{10d}\x03\x02\x02\x02\u{c83}\u{c84}\x09\x28\x02\x02\u{c84}\u{10f}\x03\
	\x02\x02\x02\u{c85}\u{c86}\x09\x29\x02\x02\u{c86}\u{111}\x03\x02\x02\x02\
	\u{c87}\u{c88}\x05\u{13c}\u{9f}\x02\u{c88}\u{113}\x03\x02\x02\x02\u{c89}\
	\u{c8a}\x07\u{1a5}\x02\x02\u{c8a}\u{cdf}\x07\u{1b7}\x02\x02\u{c8b}\u{c8c}\
	\x07\u{a1}\x02\x02\u{c8c}\u{c8f}\x05\u{10e}\u{88}\x02\u{c8d}\u{c8e}\x07\
	\u{15a}\x02\x02\u{c8e}\u{c90}\x05\u{10e}\u{88}\x02\u{c8f}\u{c8d}\x03\x02\
	\x02\x02\u{c8f}\u{c90}\x03\x02\x02\x02\u{c90}\u{cdf}\x03\x02\x02\x02\u{c91}\
	\u{c96}\x07\u{159}\x02\x02\u{c92}\u{c93}\x07\u{191}\x02\x02\u{c93}\u{c94}\
	\x05\u{118}\u{8d}\x02\u{c94}\u{c95}\x07\u{192}\x02\x02\u{c95}\u{c97}\x03\
	\x02\x02\x02\u{c96}\u{c92}\x03\x02\x02\x02\u{c96}\u{c97}\x03\x02\x02\x02\
	\u{c97}\u{c9b}\x03\x02\x02\x02\u{c98}\u{c99}\x07\u{187}\x02\x02\u{c99}\u{c9a}\
	\x07\u{158}\x02\x02\u{c9a}\u{c9c}\x07\u{18f}\x02\x02\u{c9b}\u{c98}\x03\x02\
	\x02\x02\u{c9b}\u{c9c}\x03\x02\x02\x02\u{c9c}\u{cdf}\x03\x02\x02\x02\u{c9d}\
	\u{ca2}\x07\u{159}\x02\x02\u{c9e}\u{c9f}\x07\u{191}\x02\x02\u{c9f}\u{ca0}\
	\x05\u{118}\u{8d}\x02\u{ca0}\u{ca1}\x07\u{192}\x02\x02\u{ca1}\u{ca3}\x03\
	\x02\x02\x02\u{ca2}\u{c9e}\x03\x02\x02\x02\u{ca2}\u{ca3}\x03\x02\x02\x02\
	\u{ca3}\u{ca4}\x03\x02\x02\x02\u{ca4}\u{ca5}\x07\u{185}\x02\x02\u{ca5}\u{ca6}\
	\x07\u{158}\x02\x02\u{ca6}\u{cdf}\x07\u{18f}\x02\x02\u{ca7}\u{cac}\x07\u{158}\
	\x02\x02\u{ca8}\u{ca9}\x07\u{191}\x02\x02\u{ca9}\u{caa}\x05\u{118}\u{8d}\
	\x02\u{caa}\u{cab}\x07\u{192}\x02\x02\u{cab}\u{cad}\x03\x02\x02\x02\u{cac}\
	\u{ca8}\x03\x02\x02\x02\u{cac}\u{cad}\x03\x02\x02\x02\u{cad}\u{cb1}\x03\
	\x02\x02\x02\u{cae}\u{caf}\x07\u{187}\x02\x02\u{caf}\u{cb0}\x07\u{158}\x02\
	\x02\u{cb0}\u{cb2}\x07\u{18f}\x02\x02\u{cb1}\u{cae}\x03\x02\x02\x02\u{cb1}\
	\u{cb2}\x03\x02\x02\x02\u{cb2}\u{cdf}\x03\x02\x02\x02\u{cb3}\u{cb8}\x07\
	\u{158}\x02\x02\u{cb4}\u{cb5}\x07\u{191}\x02\x02\u{cb5}\u{cb6}\x05\u{118}\
	\u{8d}\x02\u{cb6}\u{cb7}\x07\u{192}\x02\x02\u{cb7}\u{cb9}\x03\x02\x02\x02\
	\u{cb8}\u{cb4}\x03\x02\x02\x02\u{cb8}\u{cb9}\x03\x02\x02\x02\u{cb9}\u{cba}\
	\x03\x02\x02\x02\u{cba}\u{cbb}\x07\u{185}\x02\x02\u{cbb}\u{cbc}\x07\u{158}\
	\x02\x02\u{cbc}\u{cdf}\x07\u{18f}\x02\x02\u{cbd}\u{cbe}\x07\x62\x02\x02\
	\u{cbe}\u{cdf}\x07\u{10b}\x02\x02\u{cbf}\u{cc0}\x07\x30\x02\x02\u{cc0}\u{cc4}\
	\x07\u{17b}\x02\x02\u{cc1}\u{cc2}\x07\u{191}\x02\x02\u{cc2}\u{cc3}\x07\u{1b7}\
	\x02\x02\u{cc3}\u{cc5}\x07\u{192}\x02\x02\u{cc4}\u{cc1}\x03\x02\x02\x02\
	\u{cc4}\u{cc5}\x03\x02\x02\x02\u{cc5}\u{cdf}\x03\x02\x02\x02\u{cc6}\u{cc7}\
	\x07\x23\x02\x02\u{cc7}\u{ccb}\x07\u{17b}\x02\x02\u{cc8}\u{cc9}\x07\u{191}\
	\x02\x02\u{cc9}\u{cca}\x07\u{1b7}\x02\x02\u{cca}\u{ccc}\x07\u{192}\x02\x02\
	\u{ccb}\u{cc8}\x03\x02\x02\x02\u{ccb}\u{ccc}\x03\x02\x02\x02\u{ccc}\u{cdf}\
	\x03\x02\x02\x02\u{ccd}\u{cdc}\x05\u{112}\u{8a}\x02\u{cce}\u{ccf}\x07\u{191}\
	\x02\x02\u{ccf}\u{cd4}\x05\u{118}\u{8d}\x02\u{cd0}\u{cd1}\x07\x37\x02\x02\
	\u{cd1}\u{cd3}\x05\u{118}\u{8d}\x02\u{cd2}\u{cd0}\x03\x02\x02\x02\u{cd3}\
	\u{cd6}\x03\x02\x02\x02\u{cd4}\u{cd2}\x03\x02\x02\x02\u{cd4}\u{cd5}\x03\
	\x02\x02\x02\u{cd5}\u{cd8}\x03\x02\x02\x02\u{cd6}\u{cd4}\x03\x02\x02\x02\
	\u{cd7}\u{cd9}\x07\x37\x02\x02\u{cd8}\u{cd7}\x03\x02\x02\x02\u{cd8}\u{cd9}\
	\x03\x02\x02\x02\u{cd9}\u{cda}\x03\x02\x02\x02\u{cda}\u{cdb}\x07\u{192}\
	\x02\x02\u{cdb}\u{cdd}\x03\x02\x02\x02\u{cdc}\u{cce}\x03\x02\x02\x02\u{cdc}\
	\u{cdd}\x03\x02\x02\x02\u{cdd}\u{cdf}\x03\x02\x02\x02\u{cde}\u{c89}\x03\
	\x02\x02\x02\u{cde}\u{c8b}\x03\x02\x02\x02\u{cde}\u{c91}\x03\x02\x02\x02\
	\u{cde}\u{c9d}\x03\x02\x02\x02\u{cde}\u{ca7}\x03\x02\x02\x02\u{cde}\u{cb3}\
	\x03\x02\x02\x02\u{cde}\u{cbd}\x03\x02\x02\x02\u{cde}\u{cbf}\x03\x02\x02\
	\x02\u{cde}\u{cc6}\x03\x02\x02\x02\u{cde}\u{ccd}\x03\x02\x02\x02\u{cdf}\
	\u{115}\x03\x02\x02\x02\u{ce0}\u{ce5}\x05\u{114}\u{8b}\x02\u{ce1}\u{ce2}\
	\x05\u{13c}\u{9f}\x02\u{ce2}\u{ce3}\x05\u{114}\u{8b}\x02\u{ce3}\u{ce5}\x03\
	\x02\x02\x02\u{ce4}\u{ce0}\x03\x02\x02\x02\u{ce4}\u{ce1}\x03\x02\x02\x02\
	\u{ce5}\u{117}\x03\x02\x02\x02\u{ce6}\u{ce9}\x07\u{1b7}\x02\x02\u{ce7}\u{ce9}\
	\x05\u{114}\u{8b}\x02\u{ce8}\u{ce6}\x03\x02\x02\x02\u{ce8}\u{ce7}\x03\x02\
	\x02\x02\u{ce9}\u{119}\x03\x02\x02\x02\u{cea}\u{ceb}\x07\u{182}\x02\x02\
	\u{ceb}\u{cec}\x05\u{d0}\x69\x02\u{cec}\u{ced}\x07\u{156}\x02\x02\u{ced}\
	\u{cee}\x05\u{d0}\x69\x02\u{cee}\u{11b}\x03\x02\x02\x02\u{cef}\u{cf0}\x07\
	\x77\x02\x02\u{cf0}\u{cf1}\x07\u{191}\x02\x02\u{cf1}\u{cf2}\x07\u{183}\x02\
	\x02\u{cf2}\u{cf3}\x05\u{d2}\x6a\x02\u{cf3}\u{cf4}\x07\u{192}\x02\x02\u{cf4}\
	\u{11d}\x03\x02\x02\x02\u{cf5}\u{cfb}\x07\u{f9}\x02\x02\u{cf6}\u{cfc}\x05\
	\u{13c}\u{9f}\x02\u{cf7}\u{cf8}\x07\u{191}\x02\x02\u{cf8}\u{cf9}\x05\x7a\
	\x3e\x02\u{cf9}\u{cfa}\x07\u{192}\x02\x02\u{cfa}\u{cfc}\x03\x02\x02\x02\
	\u{cfb}\u{cf6}\x03\x02\x02\x02\u{cfb}\u{cf7}\x03\x02\x02\x02\u{cfc}\u{11f}\
	\x03\x02\x02\x02\u{cfd}\u{cfe}\x05\u{122}\u{92}\x02\u{cfe}\u{121}\x03\x02\
	\x02\x02\u{cff}\u{d00}\x07\u{115}\x02\x02\u{d00}\u{d18}\x05\u{124}\u{93}\
	\x02\u{d01}\u{d02}\x07\u{12b}\x02\x02\u{d02}\u{d18}\x05\u{124}\u{93}\x02\
	\u{d03}\u{d04}\x07\u{8b}\x02\x02\u{d04}\u{d18}\x05\u{124}\u{93}\x02\u{d05}\
	\u{d06}\x07\u{115}\x02\x02\u{d06}\u{d07}\x07\x22\x02\x02\u{d07}\u{d08}\x05\
	\u{124}\u{93}\x02\u{d08}\u{d09}\x07\x14\x02\x02\u{d09}\u{d0a}\x05\u{124}\
	\u{93}\x02\u{d0a}\u{d18}\x03\x02\x02\x02\u{d0b}\u{d0c}\x07\u{12b}\x02\x02\
	\u{d0c}\u{d0d}\x07\x22\x02\x02\u{d0d}\u{d0e}\x05\u{124}\u{93}\x02\u{d0e}\
	\u{d0f}\x07\x14\x02\x02\u{d0f}\u{d10}\x05\u{124}\u{93}\x02\u{d10}\u{d18}\
	\x03\x02\x02\x02\u{d11}\u{d12}\x07\u{8b}\x02\x02\u{d12}\u{d13}\x07\x22\x02\
	\x02\u{d13}\u{d14}\x05\u{124}\u{93}\x02\u{d14}\u{d15}\x07\x14\x02\x02\u{d15}\
	\u{d16}\x05\u{124}\u{93}\x02\u{d16}\u{d18}\x03\x02\x02\x02\u{d17}\u{cff}\
	\x03\x02\x02\x02\u{d17}\u{d01}\x03\x02\x02\x02\u{d17}\u{d03}\x03\x02\x02\
	\x02\u{d17}\u{d05}\x03\x02\x02\x02\u{d17}\u{d0b}\x03\x02\x02\x02\u{d17}\
	\u{d11}\x03\x02\x02\x02\u{d18}\u{123}\x03\x02\x02\x02\u{d19}\u{d1a}\x07\
	\u{165}\x02\x02\u{d1a}\u{d23}\x07\u{10a}\x02\x02\u{d1b}\u{d1c}\x07\u{165}\
	\x02\x02\u{d1c}\u{d23}\x07\x7b\x02\x02\u{d1d}\u{d1e}\x07\x48\x02\x02\u{d1e}\
	\u{d23}\x07\u{12a}\x02\x02\u{d1f}\u{d20}\x05\u{d0}\x69\x02\u{d20}\u{d21}\
	\x09\x2a\x02\x02\u{d21}\u{d23}\x03\x02\x02\x02\u{d22}\u{d19}\x03\x02\x02\
	\x02\u{d22}\u{d1b}\x03\x02\x02\x02\u{d22}\u{d1d}\x03\x02\x02\x02\u{d22}\
	\u{d1f}\x03\x02\x02\x02\u{d23}\u{125}\x03\x02\x02\x02\u{d24}\u{d25}\x08\
	\u{94}\x01\x02\u{d25}\u{d27}\x05\u{128}\u{95}\x02\u{d26}\u{d28}\x05\u{12a}\
	\u{96}\x02\u{d27}\u{d26}\x03\x02\x02\x02\u{d27}\u{d28}\x03\x02\x02\x02\u{d28}\
	\u{d30}\x03\x02\x02\x02\u{d29}\u{d2a}\x0c\x04\x02\x02\u{d2a}\u{d2f}\x05\
	\u{126}\u{94}\x05\u{d2b}\u{d2c}\x0c\x03\x02\x02\u{d2c}\u{d2d}\x07\u{1a7}\
	\x02\x02\u{d2d}\u{d2f}\x05\u{126}\u{94}\x04\u{d2e}\u{d29}\x03\x02\x02\x02\
	\u{d2e}\u{d2b}\x03\x02\x02\x02\u{d2f}\u{d32}\x03\x02\x02\x02\u{d30}\u{d2e}\
	\x03\x02\x02\x02\u{d30}\u{d31}\x03\x02\x02\x02\u{d31}\u{127}\x03\x02\x02\
	\x02\u{d32}\u{d30}\x03\x02\x02\x02\u{d33}\u{d50}\x05\u{13c}\u{9f}\x02\u{d34}\
	\u{d35}\x07\u{191}\x02\x02\u{d35}\u{d50}\x07\u{192}\x02\x02\u{d36}\u{d37}\
	\x07\u{106}\x02\x02\u{d37}\u{d38}\x07\u{191}\x02\x02\u{d38}\u{d3d}\x05\u{126}\
	\u{94}\x02\u{d39}\u{d3a}\x07\x37\x02\x02\u{d3a}\u{d3c}\x05\u{126}\u{94}\
	\x02\u{d3b}\u{d39}\x03\x02\x02\x02\u{d3c}\u{d3f}\x03\x02\x02\x02\u{d3d}\
	\u{d3b}\x03\x02\x02\x02\u{d3d}\u{d3e}\x03\x02\x02\x02\u{d3e}\u{d41}\x03\
	\x02\x02\x02\u{d3f}\u{d3d}\x03\x02\x02\x02\u{d40}\u{d42}\x07\x37\x02\x02\
	\u{d41}\u{d40}\x03\x02\x02\x02\u{d41}\u{d42}\x03\x02\x02\x02\u{d42}\u{d43}\
	\x03\x02\x02\x02\u{d43}\u{d44}\x07\u{192}\x02\x02\u{d44}\u{d50}\x03\x02\
	\x02\x02\u{d45}\u{d46}\x07\u{191}\x02\x02\u{d46}\u{d47}\x05\u{126}\u{94}\
	\x02\u{d47}\u{d48}\x07\u{192}\x02\x02\u{d48}\u{d50}\x03\x02\x02\x02\u{d49}\
	\u{d50}\x07\u{1a9}\x02\x02\u{d4a}\u{d50}\x07\u{1a5}\x02\x02\u{d4b}\u{d4c}\
	\x07\x08\x02\x02\u{d4c}\u{d4d}\x05\u{126}\u{94}\x02\u{d4d}\u{d4e}\x07\x09\
	\x02\x02\u{d4e}\u{d50}\x03\x02\x02\x02\u{d4f}\u{d33}\x03\x02\x02\x02\u{d4f}\
	\u{d34}\x03\x02\x02\x02\u{d4f}\u{d36}\x03\x02\x02\x02\u{d4f}\u{d45}\x03\
	\x02\x02\x02\u{d4f}\u{d49}\x03\x02\x02\x02\u{d4f}\u{d4a}\x03\x02\x02\x02\
	\u{d4f}\u{d4b}\x03\x02\x02\x02\u{d50}\u{129}\x03\x02\x02\x02\u{d51}\u{d53}\
	\x07\u{19e}\x02\x02\u{d52}\u{d54}\x07\u{1a2}\x02\x02\u{d53}\u{d52}\x03\x02\
	\x02\x02\u{d53}\u{d54}\x03\x02\x02\x02\u{d54}\u{d73}\x03\x02\x02\x02\u{d55}\
	\u{d57}\x07\u{19c}\x02\x02\u{d56}\u{d58}\x07\u{1a2}\x02\x02\u{d57}\u{d56}\
	\x03\x02\x02\x02\u{d57}\u{d58}\x03\x02\x02\x02\u{d58}\u{d73}\x03\x02\x02\
	\x02\u{d59}\u{d5b}\x07\u{1a2}\x02\x02\u{d5a}\u{d5c}\x07\u{1a2}\x02\x02\u{d5b}\
	\u{d5a}\x03\x02\x02\x02\u{d5b}\u{d5c}\x03\x02\x02\x02\u{d5c}\u{d73}\x03\
	\x02\x02\x02\u{d5d}\u{d5e}\x07\x0a\x02\x02\u{d5e}\u{d5f}\x07\u{1b7}\x02\
	\x02\u{d5f}\u{d61}\x07\x0b\x02\x02\u{d60}\u{d62}\x07\u{1a2}\x02\x02\u{d61}\
	\u{d60}\x03\x02\x02\x02\u{d61}\u{d62}\x03\x02\x02\x02\u{d62}\u{d73}\x03\
	\x02\x02\x02\u{d63}\u{d65}\x07\x0a\x02\x02\u{d64}\u{d66}\x07\u{1b7}\x02\
	\x02\u{d65}\u{d64}\x03\x02\x02\x02\u{d65}\u{d66}\x03\x02\x02\x02\u{d66}\
	\u{d67}\x03\x02\x02\x02\u{d67}\u{d69}\x07\x37\x02\x02\u{d68}\u{d6a}\x07\
	\u{1b7}\x02\x02\u{d69}\u{d68}\x03\x02\x02\x02\u{d69}\u{d6a}\x03\x02\x02\
	\x02\u{d6a}\u{d6c}\x03\x02\x02\x02\u{d6b}\u{d6d}\x07\x37\x02\x02\u{d6c}\
	\u{d6b}\x03\x02\x02\x02\u{d6c}\u{d6d}\x03\x02\x02\x02\u{d6d}\u{d6e}\x03\
	\x02\x02\x02\u{d6e}\u{d70}\x07\x0b\x02\x02\u{d6f}\u{d71}\x07\u{1a2}\x02\
	\x02\u{d70}\u{d6f}\x03\x02\x02\x02\u{d70}\u{d71}\x03\x02\x02\x02\u{d71}\
	\u{d73}\x03\x02\x02\x02\u{d72}\u{d51}\x03\x02\x02\x02\u{d72}\u{d55}\x03\
	\x02\x02\x02\u{d72}\u{d59}\x03\x02\x02\x02\u{d72}\u{d5d}\x03\x02\x02\x02\
	\u{d72}\u{d63}\x03\x02\x02\x02\u{d73}\u{12b}\x03\x02\x02\x02\u{d74}\u{d75}\
	\x07\u{a6}\x02\x02\u{d75}\u{d76}\x07\u{bc}\x02\x02\u{d76}\u{d7a}\x05\u{12e}\
	\u{98}\x02\u{d77}\u{d78}\x07\u{116}\x02\x02\u{d78}\u{d7a}\x09\x2b\x02\x02\
	\u{d79}\u{d74}\x03\x02\x02\x02\u{d79}\u{d77}\x03\x02\x02\x02\u{d7a}\u{12d}\
	\x03\x02\x02\x02\u{d7b}\u{d7c}\x07\u{116}\x02\x02\u{d7c}\u{d83}\x07\u{166}\
	\x02\x02\u{d7d}\u{d7e}\x07\u{116}\x02\x02\u{d7e}\u{d83}\x07\x3a\x02\x02\
	\u{d7f}\u{d80}\x07\u{11b}\x02\x02\u{d80}\u{d83}\x07\u{116}\x02\x02\u{d81}\
	\u{d83}\x07\u{13b}\x02\x02\u{d82}\u{d7b}\x03\x02\x02\x02\u{d82}\u{d7d}\x03\
	\x02\x02\x02\u{d82}\u{d7f}\x03\x02\x02\x02\u{d82}\u{d81}\x03\x02\x02\x02\
	\u{d83}\u{12f}\x03\x02\x02\x02\u{d84}\u{d85}\x09\x2c\x02\x02\u{d85}\u{131}\
	\x03\x02\x02\x02\u{d86}\u{d8b}\x05\u{13c}\u{9f}\x02\u{d87}\u{d88}\x07\u{195}\
	\x02\x02\u{d88}\u{d8a}\x05\u{140}\u{a1}\x02\u{d89}\u{d87}\x03\x02\x02\x02\
	\u{d8a}\u{d8d}\x03\x02\x02\x02\u{d8b}\u{d89}\x03\x02\x02\x02\u{d8b}\u{d8c}\
	\x03\x02\x02\x02\u{d8c}\u{133}\x03\x02\x02\x02\u{d8d}\u{d8b}\x03\x02\x02\
	\x02\u{d8e}\u{d8f}\x05\u{132}\u{9a}\x02\u{d8f}\u{135}\x03\x02\x02\x02\u{d90}\
	\u{d91}\x07\x7c\x02\x02\u{d91}\u{d92}\x05\u{138}\u{9d}\x02\u{d92}\u{d93}\
	\x07\x19\x02\x02\u{d93}\u{d94}\x07\u{ea}\x02\x02\u{d94}\u{d95}\x05\u{da}\
	\x6e\x02\u{d95}\u{137}\x03\x02\x02\x02\u{d96}\u{d97}\x09\x2d\x02\x02\u{d97}\
	\u{139}\x03\x02\x02\x02\u{d98}\u{d9e}\x05\u{13c}\u{9f}\x02\u{d99}\u{d9a}\
	\x07\u{172}\x02\x02\u{d9a}\u{d9e}\x05\u{13c}\u{9f}\x02\u{d9b}\u{d9c}\x07\
	\u{126}\x02\x02\u{d9c}\u{d9e}\x05\u{13c}\u{9f}\x02\u{d9d}\u{d98}\x03\x02\
	\x02\x02\u{d9d}\u{d99}\x03\x02\x02\x02\u{d9d}\u{d9b}\x03\x02\x02\x02\u{d9e}\
	\u{13b}\x03\x02\x02\x02\u{d9f}\u{daf}\x07\u{1ba}\x02\x02\u{da0}\u{da1}\x07\
	\u{193}\x02\x02\u{da1}\u{da2}\x07\u{1ba}\x02\x02\u{da2}\u{daf}\x07\u{194}\
	\x02\x02\u{da3}\u{daf}\x05\u{13e}\u{a0}\x02\u{da4}\u{da5}\x07\u{193}\x02\
	\x02\u{da5}\u{da6}\x05\u{13e}\u{a0}\x02\u{da6}\u{da7}\x07\u{194}\x02\x02\
	\u{da7}\u{daf}\x03\x02\x02\x02\u{da8}\u{daf}\x05\u{148}\u{a5}\x02\u{da9}\
	\u{daa}\x07\u{193}\x02\x02\u{daa}\u{dab}\x05\u{148}\u{a5}\x02\u{dab}\u{dac}\
	\x07\u{194}\x02\x02\u{dac}\u{daf}\x03\x02\x02\x02\u{dad}\u{daf}\x07\u{1bb}\
	\x02\x02\u{dae}\u{d9f}\x03\x02\x02\x02\u{dae}\u{da0}\x03\x02\x02\x02\u{dae}\
	\u{da3}\x03\x02\x02\x02\u{dae}\u{da4}\x03\x02\x02\x02\u{dae}\u{da8}\x03\
	\x02\x02\x02\u{dae}\u{da9}\x03\x02\x02\x02\u{dae}\u{dad}\x03\x02\x02\x02\
	\u{daf}\u{13d}\x03\x02\x02\x02\u{db0}\u{db1}\x07\u{1bd}\x02\x02\u{db1}\u{13f}\
	\x03\x02\x02\x02\u{db2}\u{db3}\x05\u{13c}\u{9f}\x02\u{db3}\u{141}\x03\x02\
	\x02\x02\u{db4}\u{db5}\x05\u{13c}\u{9f}\x02\u{db5}\u{db6}\x07\x02\x02\x03\
	\u{db6}\u{143}\x03\x02\x02\x02\u{db7}\u{db9}\x07\u{19d}\x02\x02\u{db8}\u{db7}\
	\x03\x02\x02\x02\u{db8}\u{db9}\x03\x02\x02\x02\u{db9}\u{dba}\x03\x02\x02\
	\x02\u{dba}\u{dc4}\x07\u{1b8}\x02\x02\u{dbb}\u{dbd}\x07\u{19d}\x02\x02\u{dbc}\
	\u{dbb}\x03\x02\x02\x02\u{dbc}\u{dbd}\x03\x02\x02\x02\u{dbd}\u{dbe}\x03\
	\x02\x02\x02\u{dbe}\u{dc4}\x07\u{1b9}\x02\x02\u{dbf}\u{dc1}\x07\u{19d}\x02\
	\x02\u{dc0}\u{dbf}\x03\x02\x02\x02\u{dc0}\u{dc1}\x03\x02\x02\x02\u{dc1}\
	\u{dc2}\x03\x02\x02\x02\u{dc2}\u{dc4}\x07\u{1b7}\x02\x02\u{dc3}\u{db8}\x03\
	\x02\x02\x02\u{dc3}\u{dbc}\x03\x02\x02\x02\u{dc3}\u{dc0}\x03\x02\x02\x02\
	\u{dc4}\u{145}\x03\x02\x02\x02\u{dc5}\u{dc6}\x09\x2e\x02\x02\u{dc6}\u{147}\
	\x03\x02\x02\x02\u{dc7}\u{dc8}\x09\x2f\x02\x02\u{dc8}\u{149}\x03\x02\x02\
	\x02\u{1e3}\u{14b}\u{14f}\u{153}\u{159}\u{15c}\u{175}\u{17b}\u{199}\u{19d}\
	\u{1ac}\u{1b0}\u{1b3}\u{1b8}\u{1bc}\u{1c5}\u{1cb}\u{1cf}\u{1d2}\u{1d8}\u{1de}\
	\u{1e2}\u{1e6}\u{1ee}\u{1f5}\u{1fa}\u{200}\u{205}\u{20a}\u{211}\u{215}\u{219}\
	\u{221}\u{226}\u{22a}\u{22e}\u{236}\u{23c}\u{246}\u{249}\u{253}\u{257}\u{259}\
	\u{261}\u{267}\u{26c}\u{272}\u{279}\u{280}\u{287}\u{28e}\u{295}\u{29c}\u{2a2}\
	\u{2a8}\u{2af}\u{2b6}\u{2bd}\u{2c4}\u{2cb}\u{2d6}\u{2de}\u{2e6}\u{2ed}\u{2f7}\
	\u{2fe}\u{306}\u{32a}\u{32d}\u{330}\u{333}\u{337}\u{33d}\u{349}\u{36a}\u{372}\
	\u{379}\u{380}\u{389}\u{38d}\u{391}\u{395}\u{39d}\u{3a4}\u{3ab}\u{3b5}\u{3b9}\
	\u{3bb}\u{3c1}\u{3c8}\u{3cf}\u{3d6}\u{3dd}\u{3ea}\u{3f3}\u{3fb}\u{403}\u{409}\
	\u{40f}\u{416}\u{41e}\u{426}\u{42e}\u{434}\u{43a}\u{442}\u{44a}\u{452}\u{459}\
	\u{460}\u{467}\u{46e}\u{475}\u{47c}\u{483}\u{486}\u{48d}\u{498}\u{49a}\u{4a2}\
	\u{4a4}\u{4ba}\u{4c5}\u{4d0}\u{4e2}\u{4e6}\u{4ea}\u{4ec}\u{4fc}\u{500}\u{50c}\
	\u{51c}\u{51f}\u{525}\u{52c}\u{532}\u{536}\u{53d}\u{542}\u{54a}\u{54f}\u{551}\
	\u{556}\u{55e}\u{562}\u{566}\u{56a}\u{56d}\u{574}\u{578}\u{588}\u{58c}\u{598}\
	\u{59c}\u{5a6}\u{5aa}\u{5ac}\u{5b1}\u{5b6}\u{5be}\u{5c0}\u{5c6}\u{5d0}\u{5d9}\
	\u{5dc}\u{5df}\u{5e4}\u{5e8}\u{5ea}\u{5ef}\u{5f8}\u{5fc}\u{604}\u{60d}\u{614}\
	\u{61d}\u{61f}\u{623}\u{627}\u{633}\u{638}\u{640}\u{645}\u{64f}\u{653}\u{65d}\
	\u{661}\u{665}\u{66a}\u{66d}\u{676}\u{67a}\u{67c}\u{680}\u{685}\u{693}\u{698}\
	\u{69a}\u{69d}\u{6a1}\u{6a5}\u{6ad}\u{6b1}\u{6b3}\u{6ba}\u{6be}\u{6c5}\u{6cc}\
	\u{6d0}\u{6d9}\u{6dd}\u{6df}\u{6e9}\u{6ed}\u{6ef}\u{6fa}\u{6fe}\u{703}\u{70b}\
	\u{70e}\u{711}\u{715}\u{71e}\u{721}\u{724}\u{727}\u{730}\u{734}\u{73d}\u{741}\
	\u{745}\u{74e}\u{752}\u{755}\u{758}\u{761}\u{770}\u{776}\u{77d}\u{781}\u{785}\
	\u{789}\u{78d}\u{791}\u{793}\u{79e}\u{7a2}\u{7a6}\u{7af}\u{7b2}\u{7b8}\u{7c4}\
	\u{7cb}\u{7cf}\u{7d2}\u{7d9}\u{7dc}\u{7e0}\u{7e2}\u{7f1}\u{7f5}\u{7fe}\u{802}\
	\u{812}\u{819}\u{820}\u{824}\u{82a}\u{82c}\u{835}\u{839}\u{83d}\u{848}\u{84c}\
	\u{857}\u{859}\u{862}\u{866}\u{868}\u{86b}\u{86f}\u{877}\u{87b}\u{882}\u{887}\
	\u{892}\u{896}\u{898}\u{89c}\u{89e}\u{8a6}\u{8b0}\u{8b4}\u{8b9}\u{8bb}\u{8c2}\
	\u{8c6}\u{8c8}\u{8cf}\u{8d3}\u{8d5}\u{8d7}\u{8e0}\u{8e4}\u{8ee}\u{8f2}\u{8fc}\
	\u{900}\u{90a}\u{914}\u{916}\u{922}\u{926}\u{929}\u{931}\u{93a}\u{93e}\u{943}\
	\u{94b}\u{951}\u{954}\u{95b}\u{95f}\u{964}\u{96d}\u{972}\u{977}\u{97a}\u{97f}\
	\u{983}\u{99d}\u{99f}\u{9b5}\u{9b8}\u{9c3}\u{9d1}\u{9d6}\u{9db}\u{9de}\u{9eb}\
	\u{9ef}\u{9f3}\u{9fe}\u{a01}\u{a04}\u{a10}\u{a14}\u{a1c}\u{a20}\u{a35}\u{a38}\
	\u{a43}\u{a46}\u{a48}\u{a53}\u{a5e}\u{a67}\u{a6a}\u{a72}\u{a81}\u{a88}\u{a8b}\
	\u{a90}\u{aa2}\u{aa5}\u{aa8}\u{ab8}\u{abb}\u{abe}\u{acf}\u{ad8}\u{ade}\u{ae4}\
	\u{aef}\u{af1}\u{af6}\u{afd}\u{aff}\u{b05}\u{b0b}\u{b16}\u{b1a}\u{b22}\u{b27}\
	\u{b2c}\u{b2e}\u{b30}\u{b36}\u{b38}\u{b42}\u{b46}\u{b4e}\u{b50}\u{b56}\u{b58}\
	\u{b76}\u{b85}\u{b91}\u{b94}\u{b97}\u{ba4}\u{bb0}\u{bb3}\u{bb6}\u{bbd}\u{bc2}\
	\u{bd2}\u{bd4}\u{bd8}\u{bdb}\u{bde}\u{be1}\u{be5}\u{bee}\u{bf1}\u{bf9}\u{bfc}\
	\u{bff}\u{c06}\u{c0c}\u{c14}\u{c17}\u{c1a}\u{c1f}\u{c24}\u{c30}\u{c34}\u{c38}\
	\u{c3b}\u{c3d}\u{c45}\u{c48}\u{c52}\u{c5a}\u{c61}\u{c63}\u{c6e}\u{c78}\u{c7c}\
	\u{c81}\u{c8f}\u{c96}\u{c9b}\u{ca2}\u{cac}\u{cb1}\u{cb8}\u{cc4}\u{ccb}\u{cd4}\
	\u{cd8}\u{cdc}\u{cde}\u{ce4}\u{ce8}\u{cfb}\u{d17}\u{d22}\u{d27}\u{d2e}\u{d30}\
	\u{d3d}\u{d41}\u{d4f}\u{d53}\u{d57}\u{d5b}\u{d61}\u{d65}\u{d69}\u{d6c}\u{d70}\
	\u{d72}\u{d79}\u{d82}\u{d8b}\u{d9d}\u{dae}\u{db8}\u{dbc}\u{dc0}\u{dc3}";

