// Generated from Bigquery.g4 by ANTLR 4.8
#![allow(dead_code)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(nonstandard_style)]
#![allow(unused_imports)]
#![allow(unused_mut)]
#![allow(unused_braces)]
use antlr_rust::PredictionContextCache;
use antlr_rust::error_listener::ErrorListener;
use antlr_rust::parser::{Parser, BaseParser, ParserRecog, ParserNodeType};
use antlr_rust::token_stream::TokenStream;
use antlr_rust::TokenSource;
use antlr_rust::parser_atn_simulator::ParserATNSimulator;
use antlr_rust::errors::*;
use antlr_rust::rule_context::{BaseRuleContext, CustomRuleContext, RuleContext};
use antlr_rust::recognizer::{Recognizer,Actions};
use antlr_rust::atn_deserializer::ATNDeserializer;
use antlr_rust::dfa::DFA;
use antlr_rust::atn::{ATN, INVALID_ALT};
use antlr_rust::error_strategy::{ErrorStrategy, DefaultErrorStrategy};
use antlr_rust::parser_rule_context::{BaseParserRuleContext, ParserRuleContext,cast,cast_mut};
use antlr_rust::tree::*;
use antlr_rust::token::{TOKEN_EOF,OwningToken,Token};
use antlr_rust::int_stream::EOF;
use antlr_rust::vocabulary::{Vocabulary,VocabularyImpl};
use antlr_rust::token_factory::{CommonTokenFactory,TokenFactory, TokenAware};
use super::bigquerylistener::*;
use super::bigqueryvisitor::*;

use antlr_rust::{TidAble,TidExt};

use std::marker::PhantomData;
use std::rc::Rc;
use std::convert::TryFrom;
use std::cell::RefCell;
use std::ops::{DerefMut, Deref};
use std::borrow::{Borrow,BorrowMut};
use std::any::{Any,TypeId};

		pub const T__0:isize=1; 
		pub const T__1:isize=2; 
		pub const T__2:isize=3; 
		pub const T__3:isize=4; 
		pub const T__4:isize=5; 
		pub const T__5:isize=6; 
		pub const T__6:isize=7; 
		pub const ABORT:isize=8; 
		pub const ABSENT:isize=9; 
		pub const ADD:isize=10; 
		pub const ADMIN:isize=11; 
		pub const AFTER:isize=12; 
		pub const ALL:isize=13; 
		pub const ALTER:isize=14; 
		pub const ANALYZE:isize=15; 
		pub const AND:isize=16; 
		pub const ANTI:isize=17; 
		pub const ANY:isize=18; 
		pub const ARRAY:isize=19; 
		pub const AS:isize=20; 
		pub const ASC:isize=21; 
		pub const AT:isize=22; 
		pub const ATTACH:isize=23; 
		pub const AUTHORIZATION:isize=24; 
		pub const AUTO:isize=25; 
		pub const BACKUP:isize=26; 
		pub const BEGIN:isize=27; 
		pub const BERNOULLI:isize=28; 
		pub const BETWEEN:isize=29; 
		pub const BOTH:isize=30; 
		pub const BREAK:isize=31; 
		pub const BY:isize=32; 
		pub const BZIP2:isize=33; 
		pub const CALL:isize=34; 
		pub const CANCEL:isize=35; 
		pub const CASCADE:isize=36; 
		pub const CASE:isize=37; 
		pub const CASE_SENSITIVE:isize=38; 
		pub const CASE_INSENSITIVE:isize=39; 
		pub const CAST:isize=40; 
		pub const CATALOGS:isize=41; 
		pub const CHARACTER:isize=42; 
		pub const CLONE:isize=43; 
		pub const CLOSE:isize=44; 
		pub const CLUSTER:isize=45; 
		pub const COALESCE:isize=46; 
		pub const COLLATE:isize=47; 
		pub const COLUMN:isize=48; 
		pub const COLUMNS:isize=49; 
		pub const COMMA:isize=50; 
		pub const COMMENT:isize=51; 
		pub const COMMIT:isize=52; 
		pub const COMMITTED:isize=53; 
		pub const COMPOUND:isize=54; 
		pub const COMPRESSION:isize=55; 
		pub const CONDITIONAL:isize=56; 
		pub const CONNECT:isize=57; 
		pub const CONNECTION:isize=58; 
		pub const CONSTRAINT:isize=59; 
		pub const CONTINUE:isize=60; 
		pub const COPARTITION:isize=61; 
		pub const COPY:isize=62; 
		pub const COUNT:isize=63; 
		pub const CREATE:isize=64; 
		pub const CROSS:isize=65; 
		pub const CUBE:isize=66; 
		pub const CURRENT:isize=67; 
		pub const CURRENT_ROLE:isize=68; 
		pub const CUSTOM_HOLIDAY:isize=69; 
		pub const DATA:isize=70; 
		pub const DATABASE:isize=71; 
		pub const DATASHARE:isize=72; 
		pub const DATE:isize=73; 
		pub const DATETIME:isize=74; 
		pub const DAY:isize=75; 
		pub const DAYOFWEEK:isize=76; 
		pub const DAYOFYEAR:isize=77; 
		pub const DATETIME_DIFF:isize=78; 
		pub const DATE_DIFF:isize=79; 
		pub const DEALLOCATE:isize=80; 
		pub const DECLARE:isize=81; 
		pub const DEFAULT:isize=82; 
		pub const DEFAULTS:isize=83; 
		pub const DEFINE:isize=84; 
		pub const DEFINER:isize=85; 
		pub const DELETE:isize=86; 
		pub const DELIMITED:isize=87; 
		pub const DELIMITER:isize=88; 
		pub const DENY:isize=89; 
		pub const DESC:isize=90; 
		pub const DESCRIBE:isize=91; 
		pub const DESCRIPTOR:isize=92; 
		pub const DETERMINISTIC:isize=93; 
		pub const DISTINCT:isize=94; 
		pub const DISTKEY:isize=95; 
		pub const DISTRIBUTED:isize=96; 
		pub const DISTSTYLE:isize=97; 
		pub const DETACH:isize=98; 
		pub const DO:isize=99; 
		pub const DOUBLE:isize=100; 
		pub const DROP:isize=101; 
		pub const ELSE:isize=102; 
		pub const ELSEIF:isize=103; 
		pub const EMPTY:isize=104; 
		pub const ENCODE:isize=105; 
		pub const ENCODING:isize=106; 
		pub const END:isize=107; 
		pub const ERROR:isize=108; 
		pub const ESCAPE:isize=109; 
		pub const EVEN:isize=110; 
		pub const EXCEPT:isize=111; 
		pub const EXCEPTION:isize=112; 
		pub const EXCLUDE:isize=113; 
		pub const EXCLUDING:isize=114; 
		pub const EXECUTE:isize=115; 
		pub const EXISTS:isize=116; 
		pub const EXPLAIN:isize=117; 
		pub const EXTERNAL:isize=118; 
		pub const EXTRACT:isize=119; 
		pub const FALSE:isize=120; 
		pub const FETCH:isize=121; 
		pub const FIELDS:isize=122; 
		pub const FILTER:isize=123; 
		pub const FINAL:isize=124; 
		pub const FIRST:isize=125; 
		pub const FOLLOWING:isize=126; 
		pub const FOR:isize=127; 
		pub const FORMAT:isize=128; 
		pub const FRIDAY:isize=129; 
		pub const FROM:isize=130; 
		pub const FULL:isize=131; 
		pub const FUNCTION:isize=132; 
		pub const FUNCTIONS:isize=133; 
		pub const GENERATED:isize=134; 
		pub const GRACE:isize=135; 
		pub const GRANT:isize=136; 
		pub const GRANTED:isize=137; 
		pub const GRANTS:isize=138; 
		pub const GRAPHVIZ:isize=139; 
		pub const GROUP:isize=140; 
		pub const GROUPING:isize=141; 
		pub const GROUPS:isize=142; 
		pub const GZIP:isize=143; 
		pub const HAVING:isize=144; 
		pub const HEADER:isize=145; 
		pub const HOUR:isize=146; 
		pub const IDENTITY:isize=147; 
		pub const IF:isize=148; 
		pub const IGNORE:isize=149; 
		pub const IMMEDIATE:isize=150; 
		pub const IN:isize=151; 
		pub const INCLUDE:isize=152; 
		pub const INCLUDING:isize=153; 
		pub const INITIAL:isize=154; 
		pub const INNER:isize=155; 
		pub const INPUT:isize=156; 
		pub const INPUTFORMAT:isize=157; 
		pub const INTERLEAVED:isize=158; 
		pub const INSERT:isize=159; 
		pub const INTERSECT:isize=160; 
		pub const INTERVAL:isize=161; 
		pub const INTO:isize=162; 
		pub const INVOKER:isize=163; 
		pub const IO:isize=164; 
		pub const IS:isize=165; 
		pub const ISOLATION:isize=166; 
		pub const ISOWEEK:isize=167; 
		pub const ISOYEAR:isize=168; 
		pub const ITERATE:isize=169; 
		pub const ILIKE:isize=170; 
		pub const JOIN:isize=171; 
		pub const JSON:isize=172; 
		pub const KEEP:isize=173; 
		pub const KEY:isize=174; 
		pub const KEYS:isize=175; 
		pub const LAMBDA:isize=176; 
		pub const LANGUAGE:isize=177; 
		pub const LEAVE:isize=178; 
		pub const LAST:isize=179; 
		pub const LATERAL:isize=180; 
		pub const LEADING:isize=181; 
		pub const LEFT:isize=182; 
		pub const LEVEL:isize=183; 
		pub const LIBRARY:isize=184; 
		pub const LIKE:isize=185; 
		pub const LIMIT:isize=186; 
		pub const LINES:isize=187; 
		pub const LISTAGG:isize=188; 
		pub const LOCAL:isize=189; 
		pub const LOCATION:isize=190; 
		pub const LOCK:isize=191; 
		pub const LOGICAL:isize=192; 
		pub const LOOP:isize=193; 
		pub const MAP:isize=194; 
		pub const MASKING:isize=195; 
		pub const MATCH:isize=196; 
		pub const MATCHED:isize=197; 
		pub const MATCHES:isize=198; 
		pub const MATCH_RECOGNIZE:isize=199; 
		pub const MATERIALIZED:isize=200; 
		pub const MAX:isize=201; 
		pub const MEASURES:isize=202; 
		pub const MERGE:isize=203; 
		pub const MESSAGE:isize=204; 
		pub const MICROSECOND:isize=205; 
		pub const MILLISECOND:isize=206; 
		pub const MIN:isize=207; 
		pub const MINUS_KW:isize=208; 
		pub const MINUTE:isize=209; 
		pub const MODEL:isize=210; 
		pub const MONDAY:isize=211; 
		pub const MONTH:isize=212; 
		pub const NAME:isize=213; 
		pub const NATURAL:isize=214; 
		pub const NEXT:isize=215; 
		pub const NFC:isize=216; 
		pub const NFD:isize=217; 
		pub const NFKC:isize=218; 
		pub const NFKD:isize=219; 
		pub const NO:isize=220; 
		pub const NONE:isize=221; 
		pub const NORMALIZE:isize=222; 
		pub const NOT:isize=223; 
		pub const NULL:isize=224; 
		pub const NULLS:isize=225; 
		pub const OBJECT:isize=226; 
		pub const OF:isize=227; 
		pub const OFFSET:isize=228; 
		pub const OMIT:isize=229; 
		pub const ON:isize=230; 
		pub const ONE:isize=231; 
		pub const ONLY:isize=232; 
		pub const OPTION:isize=233; 
		pub const OPTIONS:isize=234; 
		pub const OR:isize=235; 
		pub const ORDER:isize=236; 
		pub const OUTER:isize=237; 
		pub const OUTPUT:isize=238; 
		pub const OUTPUTFORMAT:isize=239; 
		pub const OVER:isize=240; 
		pub const OVERFLOW:isize=241; 
		pub const PARTITION:isize=242; 
		pub const PARTITIONED:isize=243; 
		pub const PARTITIONS:isize=244; 
		pub const PASSING:isize=245; 
		pub const PAST:isize=246; 
		pub const PATH:isize=247; 
		pub const PATTERN:isize=248; 
		pub const PER:isize=249; 
		pub const PERCENT_KW:isize=250; 
		pub const PERIOD:isize=251; 
		pub const PERMUTE:isize=252; 
		pub const PIVOT:isize=253; 
		pub const POSITION:isize=254; 
		pub const PRECEDING:isize=255; 
		pub const PRECISION:isize=256; 
		pub const PREPARE:isize=257; 
		pub const PRIOR:isize=258; 
		pub const PROCEDURE:isize=259; 
		pub const PRIVILEGES:isize=260; 
		pub const PROPERTIES:isize=261; 
		pub const PRUNE:isize=262; 
		pub const QUALIFY:isize=263; 
		pub const QUARTER:isize=264; 
		pub const QUOTES:isize=265; 
		pub const RAISE:isize=266; 
		pub const RANGE:isize=267; 
		pub const READ:isize=268; 
		pub const RECURSIVE:isize=269; 
		pub const REFRESH:isize=270; 
		pub const RENAME:isize=271; 
		pub const REPEATABLE:isize=272; 
		pub const REPLACE:isize=273; 
		pub const RESET:isize=274; 
		pub const RESPECT:isize=275; 
		pub const RESTRICT:isize=276; 
		pub const RETURN:isize=277; 
		pub const RETURNING:isize=278; 
		pub const REMOTE:isize=279; 
		pub const REPEAT:isize=280; 
		pub const RETURNS:isize=281; 
		pub const REVOKE:isize=282; 
		pub const RIGHT:isize=283; 
		pub const RLS:isize=284; 
		pub const ROLE:isize=285; 
		pub const ROLES:isize=286; 
		pub const ROLLBACK:isize=287; 
		pub const ROLLUP:isize=288; 
		pub const ROW:isize=289; 
		pub const ROWS:isize=290; 
		pub const RUNNING:isize=291; 
		pub const SAFE:isize=292; 
		pub const SAFE_CAST:isize=293; 
		pub const SATURDAY:isize=294; 
		pub const SCALAR:isize=295; 
		pub const SECOND:isize=296; 
		pub const SCHEMA:isize=297; 
		pub const SCHEMAS:isize=298; 
		pub const SECURITY:isize=299; 
		pub const SEEK:isize=300; 
		pub const SELECT:isize=301; 
		pub const SEMI:isize=302; 
		pub const SERDE:isize=303; 
		pub const SERDEPROPERTIES:isize=304; 
		pub const SERIALIZABLE:isize=305; 
		pub const SESSION:isize=306; 
		pub const SET:isize=307; 
		pub const SETS:isize=308; 
		pub const SHOW:isize=309; 
		pub const SIMILAR:isize=310; 
		pub const SNAPSHOT:isize=311; 
		pub const SOME:isize=312; 
		pub const SORTKEY:isize=313; 
		pub const START:isize=314; 
		pub const STATS:isize=315; 
		pub const STORED:isize=316; 
		pub const STRUCT:isize=317; 
		pub const SUBSET:isize=318; 
		pub const SUBSTRING:isize=319; 
		pub const SUNDAY:isize=320; 
		pub const SYSTEM:isize=321; 
		pub const SYSTEM_TIME:isize=322; 
		pub const TABLE:isize=323; 
		pub const TABLES:isize=324; 
		pub const TABLESAMPLE:isize=325; 
		pub const TEMP:isize=326; 
		pub const TEMPORARY:isize=327; 
		pub const TERMINATED:isize=328; 
		pub const TEXT:isize=329; 
		pub const STRING_KW:isize=330; 
		pub const THEN:isize=331; 
		pub const THURSDAY:isize=332; 
		pub const TIES:isize=333; 
		pub const TIME:isize=334; 
		pub const TIMESTAMP:isize=335; 
		pub const TIMESTAMP_DIFF:isize=336; 
		pub const TO:isize=337; 
		pub const TOP:isize=338; 
		pub const TRAILING:isize=339; 
		pub const TARGET:isize=340; 
		pub const SOURCE:isize=341; 
		pub const TRAINING_DATA:isize=342; 
		pub const TRANSACTION:isize=343; 
		pub const TRANSFORM:isize=344; 
		pub const TRIM:isize=345; 
		pub const TRUE:isize=346; 
		pub const TRUNCATE:isize=347; 
		pub const TRY_CAST:isize=348; 
		pub const TUPLE:isize=349; 
		pub const TUESDAY:isize=350; 
		pub const TYPE:isize=351; 
		pub const UESCAPE:isize=352; 
		pub const UNBOUNDED:isize=353; 
		pub const UNCOMMITTED:isize=354; 
		pub const UNCONDITIONAL:isize=355; 
		pub const UNION:isize=356; 
		pub const UNKNOWN:isize=357; 
		pub const UNLOAD:isize=358; 
		pub const UNMATCHED:isize=359; 
		pub const UNNEST:isize=360; 
		pub const UNPIVOT:isize=361; 
		pub const UNSIGNED:isize=362; 
		pub const UNTIL:isize=363; 
		pub const UPDATE:isize=364; 
		pub const USE:isize=365; 
		pub const USER:isize=366; 
		pub const USING:isize=367; 
		pub const UTF16:isize=368; 
		pub const UTF32:isize=369; 
		pub const UTF8:isize=370; 
		pub const VACUUM:isize=371; 
		pub const VALIDATE:isize=372; 
		pub const VALUE:isize=373; 
		pub const VALUES:isize=374; 
		pub const VARYING:isize=375; 
		pub const VERBOSE:isize=376; 
		pub const VERSION:isize=377; 
		pub const VIEW:isize=378; 
		pub const WEDNESDAY:isize=379; 
		pub const WEEK:isize=380; 
		pub const WHEN:isize=381; 
		pub const WHERE:isize=382; 
		pub const WHILE:isize=383; 
		pub const WINDOW:isize=384; 
		pub const WITH:isize=385; 
		pub const WITHOUT:isize=386; 
		pub const WORK:isize=387; 
		pub const WRAPPER:isize=388; 
		pub const WRITE:isize=389; 
		pub const XZ:isize=390; 
		pub const YEAR:isize=391; 
		pub const YES:isize=392; 
		pub const ZONE:isize=393; 
		pub const ZSTD:isize=394; 
		pub const LPAREN:isize=395; 
		pub const RPAREN:isize=396; 
		pub const LBRACKET:isize=397; 
		pub const RBRACKET:isize=398; 
		pub const DOT:isize=399; 
		pub const EQ:isize=400; 
		pub const NEQ:isize=401; 
		pub const LT:isize=402; 
		pub const LTE:isize=403; 
		pub const GT:isize=404; 
		pub const GTE:isize=405; 
		pub const PLUS:isize=406; 
		pub const MINUS:isize=407; 
		pub const ASTERISK:isize=408; 
		pub const SLASH:isize=409; 
		pub const PERCENT:isize=410; 
		pub const CONCAT:isize=411; 
		pub const QUESTION_MARK:isize=412; 
		pub const SEMI_COLON:isize=413; 
		pub const COLON:isize=414; 
		pub const DOLLAR:isize=415; 
		pub const BITWISE_AND:isize=416; 
		pub const BITWISE_OR:isize=417; 
		pub const BITWISE_XOR:isize=418; 
		pub const BITWISE_SHIFT_LEFT:isize=419; 
		pub const POSIX:isize=420; 
		pub const ESCAPE_SEQUENCE:isize=421; 
		pub const QUOTED_STRING:isize=422; 
		pub const TRIPLE_QUOTED_STRING:isize=423; 
		pub const RAW_QUOTED_STRING:isize=424; 
		pub const RAW_TRIPLE_QUOTED_STRING:isize=425; 
		pub const BINARY_LITERAL:isize=426; 
		pub const INTEGER_VALUE:isize=427; 
		pub const HEXADECIMAL_VALUE:isize=428; 
		pub const DECIMAL_VALUE:isize=429; 
		pub const DOUBLE_VALUE:isize=430; 
		pub const IDENTIFIER:isize=431; 
		pub const BACKQUOTED_IDENTIFIER:isize=432; 
		pub const VARIABLE:isize=433; 
		pub const SIMPLE_COMMENT:isize=434; 
		pub const BIG_QUERY_SIMPLE_COMMENT:isize=435; 
		pub const BRACKETED_COMMENT:isize=436; 
		pub const WS:isize=437; 
		pub const OTHER_WS:isize=438; 
		pub const UNPAIRED_TOKEN:isize=439; 
		pub const UNRECOGNIZED:isize=440;
	pub const RULE_multipleStatement:usize = 0; 
	pub const RULE_singleStatement:usize = 1; 
	pub const RULE_standaloneExpression:usize = 2; 
	pub const RULE_standaloneQualifiedName:usize = 3; 
	pub const RULE_standaloneType:usize = 4; 
	pub const RULE_statementBlock:usize = 5; 
	pub const RULE_statement:usize = 6; 
	pub const RULE_tableElements:usize = 7; 
	pub const RULE_namedExpressionSeq:usize = 8; 
	pub const RULE_namedExpression:usize = 9; 
	pub const RULE_unpivotNullClause:usize = 10; 
	pub const RULE_locationSpec:usize = 11; 
	pub const RULE_connectionSpec:usize = 12; 
	pub const RULE_query:usize = 13; 
	pub const RULE_with:usize = 14; 
	pub const RULE_tableElement:usize = 15; 
	pub const RULE_columnDefinition:usize = 16; 
	pub const RULE_fieldDefinition:usize = 17; 
	pub const RULE_columnName:usize = 18; 
	pub const RULE_columnNameComponent:usize = 19; 
	pub const RULE_columnSchemaWithMetadata:usize = 20; 
	pub const RULE_columnOptionList:usize = 21; 
	pub const RULE_columnOption:usize = 22; 
	pub const RULE_columnSchema:usize = 23; 
	pub const RULE_fieldList:usize = 24; 
	pub const RULE_arrayElementSchema:usize = 25; 
	pub const RULE_structDefinition:usize = 26; 
	pub const RULE_properties:usize = 27; 
	pub const RULE_propertyAssignments:usize = 28; 
	pub const RULE_property:usize = 29; 
	pub const RULE_propertyKey:usize = 30; 
	pub const RULE_propertyValue:usize = 31; 
	pub const RULE_queryNoWith:usize = 32; 
	pub const RULE_queryLimit:usize = 33; 
	pub const RULE_queryLimitTarget:usize = 34; 
	pub const RULE_limitRowCount:usize = 35; 
	pub const RULE_rowCount:usize = 36; 
	pub const RULE_queryTerm:usize = 37; 
	pub const RULE_setOperation:usize = 38; 
	pub const RULE_setOperator:usize = 39; 
	pub const RULE_setOperationIntersect:usize = 40; 
	pub const RULE_setIntersectOperator:usize = 41; 
	pub const RULE_setQuantifier:usize = 42; 
	pub const RULE_inlineTable:usize = 43; 
	pub const RULE_queryPrimary:usize = 44; 
	pub const RULE_sortItem:usize = 45; 
	pub const RULE_querySpecification:usize = 46; 
	pub const RULE_replaceDefinition:usize = 47; 
	pub const RULE_querySelectItems:usize = 48; 
	pub const RULE_aggregationClause:usize = 49; 
	pub const RULE_groupBy:usize = 50; 
	pub const RULE_groupingElement:usize = 51; 
	pub const RULE_groupingSet:usize = 52; 
	pub const RULE_windowDefinition:usize = 53; 
	pub const RULE_windowSpecification:usize = 54; 
	pub const RULE_windowSpecificationPartitionBy:usize = 55; 
	pub const RULE_orderBy:usize = 56; 
	pub const RULE_namedQuery:usize = 57; 
	pub const RULE_selectItemAlias:usize = 58; 
	pub const RULE_selectItem:usize = 59; 
	pub const RULE_multiSelect:usize = 60; 
	pub const RULE_selectStar:usize = 61; 
	pub const RULE_relation:usize = 62; 
	pub const RULE_joinedRelation:usize = 63; 
	pub const RULE_noJoinRelation:usize = 64; 
	pub const RULE_joinType:usize = 65; 
	pub const RULE_joinCriteria:usize = 66; 
	pub const RULE_sampledRelationTarget:usize = 67; 
	pub const RULE_sampledRelation:usize = 68; 
	pub const RULE_sampleOperator:usize = 69; 
	pub const RULE_sampleMethod:usize = 70; 
	pub const RULE_trimsSpecification:usize = 71; 
	pub const RULE_listAggOverflowBehavior:usize = 72; 
	pub const RULE_listaggCountIndication:usize = 73; 
	pub const RULE_variableDefinition:usize = 74; 
	pub const RULE_pivotedRelationTarget:usize = 75; 
	pub const RULE_pivotedRelation:usize = 76; 
	pub const RULE_pivotAggregates:usize = 77; 
	pub const RULE_pivotFrom:usize = 78; 
	pub const RULE_pivotInto:usize = 79; 
	pub const RULE_pivotAsAlias:usize = 80; 
	pub const RULE_singleColumnUnpivot:usize = 81; 
	pub const RULE_columnsToUnpivot:usize = 82; 
	pub const RULE_unpivotAlias:usize = 83; 
	pub const RULE_multiColumnUnpivot:usize = 84; 
	pub const RULE_valueColumnSet:usize = 85; 
	pub const RULE_unpivotColumnSet:usize = 86; 
	pub const RULE_columnSetsToUnpivot:usize = 87; 
	pub const RULE_columnUnpivot:usize = 88; 
	pub const RULE_pivotIntos:usize = 89; 
	pub const RULE_pivotOperator:usize = 90; 
	pub const RULE_aliasedRelationTarget:usize = 91; 
	pub const RULE_aliasedRelation:usize = 92; 
	pub const RULE_columnAliases:usize = 93; 
	pub const RULE_partitionColumn:usize = 94; 
	pub const RULE_partitionColumns:usize = 95; 
	pub const RULE_relationPrimary:usize = 96; 
	pub const RULE_tableFunctionCall:usize = 97; 
	pub const RULE_tableFunctionArgumentCopartition:usize = 98; 
	pub const RULE_tableFunctionArgumentName:usize = 99; 
	pub const RULE_tableFunctionArgument:usize = 100; 
	pub const RULE_tableArgument:usize = 101; 
	pub const RULE_tableArgumentRelation:usize = 102; 
	pub const RULE_descriptorArgument:usize = 103; 
	pub const RULE_descriptorField:usize = 104; 
	pub const RULE_copartitionTables:usize = 105; 
	pub const RULE_expression:usize = 106; 
	pub const RULE_booleanExpression:usize = 107; 
	pub const RULE_predicate:usize = 108; 
	pub const RULE_valueExpression:usize = 109; 
	pub const RULE_primaryExpression:usize = 110; 
	pub const RULE_functionCallHead:usize = 111; 
	pub const RULE_functionCallTail:usize = 112; 
	pub const RULE_callArgument:usize = 113; 
	pub const RULE_functionExtraArguments:usize = 114; 
	pub const RULE_dateDiffCall:usize = 115; 
	pub const RULE_datePart:usize = 116; 
	pub const RULE_functionName:usize = 117; 
	pub const RULE_havingArgument:usize = 118; 
	pub const RULE_limitArgument:usize = 119; 
	pub const RULE_namedParameter:usize = 120; 
	pub const RULE_field:usize = 121; 
	pub const RULE_processingMode:usize = 122; 
	pub const RULE_nullTreatment:usize = 123; 
	pub const RULE_string:usize = 124; 
	pub const RULE_comparisonOperator:usize = 125; 
	pub const RULE_comparisonQuantifier:usize = 126; 
	pub const RULE_booleanValue:usize = 127; 
	pub const RULE_interval:usize = 128; 
	pub const RULE_intervalField:usize = 129; 
	pub const RULE_normalForm:usize = 130; 
	pub const RULE_typeIdentifier:usize = 131; 
	pub const RULE_type_:usize = 132; 
	pub const RULE_nonnullableType:usize = 133; 
	pub const RULE_rowField:usize = 134; 
	pub const RULE_typeParameter:usize = 135; 
	pub const RULE_whenClause:usize = 136; 
	pub const RULE_filter:usize = 137; 
	pub const RULE_mergeCase:usize = 138; 
	pub const RULE_mergeUpdateClause:usize = 139; 
	pub const RULE_mergeInsertClause:usize = 140; 
	pub const RULE_over:usize = 141; 
	pub const RULE_windowFrame:usize = 142; 
	pub const RULE_frameExtent:usize = 143; 
	pub const RULE_frameBound:usize = 144; 
	pub const RULE_rowPattern:usize = 145; 
	pub const RULE_patternPrimary:usize = 146; 
	pub const RULE_patternQuantifier:usize = 147; 
	pub const RULE_transactionMode:usize = 148; 
	pub const RULE_levelOfIsolation:usize = 149; 
	pub const RULE_privilege:usize = 150; 
	pub const RULE_qualifiedName:usize = 151; 
	pub const RULE_pathExpression:usize = 152; 
	pub const RULE_nonquotedIdentifier:usize = 153; 
	pub const RULE_dashedIdentifier:usize = 154; 
	pub const RULE_maybeDashedIdentifier:usize = 155; 
	pub const RULE_dashedPathExpression:usize = 156; 
	pub const RULE_maybeDashedPathExpression:usize = 157; 
	pub const RULE_queryPeriod:usize = 158; 
	pub const RULE_rangeType:usize = 159; 
	pub const RULE_principal:usize = 160; 
	pub const RULE_identifier:usize = 161; 
	pub const RULE_pathComponent:usize = 162; 
	pub const RULE_standaloneIdentifier:usize = 163; 
	pub const RULE_identifierList:usize = 164; 
	pub const RULE_identifierSeq:usize = 165; 
	pub const RULE_number:usize = 166; 
	pub const RULE_nonReserved:usize = 167;
	pub const ruleNames: [&'static str; 168] =  [
		"multipleStatement", "singleStatement", "standaloneExpression", "standaloneQualifiedName", 
		"standaloneType", "statementBlock", "statement", "tableElements", "namedExpressionSeq", 
		"namedExpression", "unpivotNullClause", "locationSpec", "connectionSpec", 
		"query", "with", "tableElement", "columnDefinition", "fieldDefinition", 
		"columnName", "columnNameComponent", "columnSchemaWithMetadata", "columnOptionList", 
		"columnOption", "columnSchema", "fieldList", "arrayElementSchema", "structDefinition", 
		"properties", "propertyAssignments", "property", "propertyKey", "propertyValue", 
		"queryNoWith", "queryLimit", "queryLimitTarget", "limitRowCount", "rowCount", 
		"queryTerm", "setOperation", "setOperator", "setOperationIntersect", "setIntersectOperator", 
		"setQuantifier", "inlineTable", "queryPrimary", "sortItem", "querySpecification", 
		"replaceDefinition", "querySelectItems", "aggregationClause", "groupBy", 
		"groupingElement", "groupingSet", "windowDefinition", "windowSpecification", 
		"windowSpecificationPartitionBy", "orderBy", "namedQuery", "selectItemAlias", 
		"selectItem", "multiSelect", "selectStar", "relation", "joinedRelation", 
		"noJoinRelation", "joinType", "joinCriteria", "sampledRelationTarget", 
		"sampledRelation", "sampleOperator", "sampleMethod", "trimsSpecification", 
		"listAggOverflowBehavior", "listaggCountIndication", "variableDefinition", 
		"pivotedRelationTarget", "pivotedRelation", "pivotAggregates", "pivotFrom", 
		"pivotInto", "pivotAsAlias", "singleColumnUnpivot", "columnsToUnpivot", 
		"unpivotAlias", "multiColumnUnpivot", "valueColumnSet", "unpivotColumnSet", 
		"columnSetsToUnpivot", "columnUnpivot", "pivotIntos", "pivotOperator", 
		"aliasedRelationTarget", "aliasedRelation", "columnAliases", "partitionColumn", 
		"partitionColumns", "relationPrimary", "tableFunctionCall", "tableFunctionArgumentCopartition", 
		"tableFunctionArgumentName", "tableFunctionArgument", "tableArgument", 
		"tableArgumentRelation", "descriptorArgument", "descriptorField", "copartitionTables", 
		"expression", "booleanExpression", "predicate", "valueExpression", "primaryExpression", 
		"functionCallHead", "functionCallTail", "callArgument", "functionExtraArguments", 
		"dateDiffCall", "datePart", "functionName", "havingArgument", "limitArgument", 
		"namedParameter", "field", "processingMode", "nullTreatment", "string", 
		"comparisonOperator", "comparisonQuantifier", "booleanValue", "interval", 
		"intervalField", "normalForm", "typeIdentifier", "type_", "nonnullableType", 
		"rowField", "typeParameter", "whenClause", "filter", "mergeCase", "mergeUpdateClause", 
		"mergeInsertClause", "over", "windowFrame", "frameExtent", "frameBound", 
		"rowPattern", "patternPrimary", "patternQuantifier", "transactionMode", 
		"levelOfIsolation", "privilege", "qualifiedName", "pathExpression", "nonquotedIdentifier", 
		"dashedIdentifier", "maybeDashedIdentifier", "dashedPathExpression", "maybeDashedPathExpression", 
		"queryPeriod", "rangeType", "principal", "identifier", "pathComponent", 
		"standaloneIdentifier", "identifierList", "identifierSeq", "number", "nonReserved"
	];


	pub const _LITERAL_NAMES: [Option<&'static str>;421] = [
		None, Some("'`'"), Some("'=>'"), Some("'->'"), Some("'{-'"), Some("'-}'"), 
		Some("'{'"), Some("'}'"), Some("'ABORT'"), Some("'ABSENT'"), Some("'ADD'"), 
		Some("'ADMIN'"), Some("'AFTER'"), Some("'ALL'"), Some("'ALTER'"), Some("'ANALYZE'"), 
		Some("'AND'"), Some("'ANTI'"), Some("'ANY'"), Some("'ARRAY'"), Some("'AS'"), 
		Some("'ASC'"), Some("'AT'"), Some("'ATTACH'"), Some("'AUTHORIZATION'"), 
		Some("'AUTO'"), Some("'BACKUP'"), Some("'BEGIN'"), Some("'BERNOULLI'"), 
		Some("'BETWEEN'"), Some("'BOTH'"), Some("'BREAK'"), Some("'BY'"), Some("'BZIP2'"), 
		Some("'CALL'"), Some("'CANCEL'"), Some("'CASCADE'"), Some("'CASE'"), Some("'CASE_SENSITIVE'"), 
		Some("'CASE_INSENSITIVE'"), Some("'CAST'"), Some("'CATALOGS'"), Some("'CHARACTER'"), 
		Some("'CLONE'"), Some("'CLOSE'"), Some("'CLUSTER'"), Some("'COALESCE'"), 
		Some("'COLLATE'"), Some("'COLUMN'"), Some("'COLUMNS'"), Some("','"), Some("'COMMENT'"), 
		Some("'COMMIT'"), Some("'COMMITTED'"), Some("'COMPOUND'"), Some("'COMPRESSION'"), 
		Some("'CONDITIONAL'"), Some("'CONNECT'"), Some("'CONNECTION'"), Some("'CONSTRAINT'"), 
		Some("'CONTINUE'"), Some("'COPARTITION'"), Some("'COPY'"), Some("'COUNT'"), 
		Some("'CREATE'"), Some("'CROSS'"), Some("'CUBE'"), Some("'CURRENT'"), 
		Some("'CURRENT_ROLE'"), Some("'CUSTOM_HOLIDAY'"), Some("'DATA'"), Some("'DATABASE'"), 
		Some("'DATASHARE'"), Some("'DATE'"), Some("'DATETIME'"), Some("'DAY'"), 
		Some("'DAYOFWEEK'"), Some("'DAYOFYEAR'"), Some("'DATETIME_DIFF'"), Some("'DATE_DIFF'"), 
		Some("'DEALLOCATE'"), Some("'DECLARE'"), Some("'DEFAULT'"), Some("'DEFAULTS'"), 
		Some("'DEFINE'"), Some("'DEFINER'"), Some("'DELETE'"), Some("'DELIMITED'"), 
		Some("'DELIMITER'"), Some("'DENY'"), Some("'DESC'"), Some("'DESCRIBE'"), 
		Some("'DESCRIPTOR'"), Some("'DETERMINISTIC'"), Some("'DISTINCT'"), Some("'DISTKEY'"), 
		Some("'DISTRIBUTED'"), Some("'DISTSTYLE'"), Some("'DETACH'"), Some("'DO'"), 
		Some("'DOUBLE'"), Some("'DROP'"), Some("'ELSE'"), Some("'ELSEIF'"), Some("'EMPTY'"), 
		Some("'ENCODE'"), Some("'ENCODING'"), Some("'END'"), Some("'ERROR'"), 
		Some("'ESCAPE'"), Some("'EVEN'"), Some("'EXCEPT'"), Some("'EXCEPTION'"), 
		Some("'EXCLUDE'"), Some("'EXCLUDING'"), Some("'EXECUTE'"), Some("'EXISTS'"), 
		Some("'EXPLAIN'"), Some("'EXTERNAL'"), Some("'EXTRACT'"), Some("'FALSE'"), 
		Some("'FETCH'"), Some("'FIELDS'"), Some("'FILTER'"), Some("'FINAL'"), 
		Some("'FIRST'"), Some("'FOLLOWING'"), Some("'FOR'"), Some("'FORMAT'"), 
		Some("'FRIDAY'"), Some("'FROM'"), Some("'FULL'"), Some("'FUNCTION'"), 
		Some("'FUNCTIONS'"), Some("'GENERATED'"), Some("'GRACE'"), Some("'GRANT'"), 
		Some("'GRANTED'"), Some("'GRANTS'"), Some("'GRAPHVIZ'"), Some("'GROUP'"), 
		Some("'GROUPING'"), Some("'GROUPS'"), Some("'GZIP'"), Some("'HAVING'"), 
		Some("'HEADER'"), Some("'HOUR'"), Some("'IDENTITY'"), Some("'IF'"), Some("'IGNORE'"), 
		Some("'IMMEDIATE'"), Some("'IN'"), Some("'INCLUDE'"), Some("'INCLUDING'"), 
		Some("'INITIAL'"), Some("'INNER'"), Some("'INPUT'"), Some("'INPUTFORMAT'"), 
		Some("'INTERLEAVED'"), Some("'INSERT'"), Some("'INTERSECT'"), Some("'INTERVAL'"), 
		Some("'INTO'"), Some("'INVOKER'"), Some("'IO'"), Some("'IS'"), Some("'ISOLATION'"), 
		Some("'ISOWEEK'"), Some("'ISOYEAR'"), Some("'ITERATE'"), Some("'ILIKE'"), 
		Some("'JOIN'"), Some("'JSON'"), Some("'KEEP'"), Some("'KEY'"), Some("'KEYS'"), 
		Some("'LAMBDA'"), Some("'LANGUAGE'"), Some("'LEAVE'"), Some("'LAST'"), 
		Some("'LATERAL'"), Some("'LEADING'"), Some("'LEFT'"), Some("'LEVEL'"), 
		Some("'LIBRARY'"), Some("'LIKE'"), Some("'LIMIT'"), Some("'LINES'"), Some("'LISTAGG'"), 
		Some("'LOCAL'"), Some("'LOCATION'"), Some("'LOCK'"), Some("'LOGICAL'"), 
		Some("'LOOP'"), Some("'MAP'"), Some("'MASKING'"), Some("'MATCH'"), Some("'MATCHED'"), 
		Some("'MATCHES'"), Some("'MATCH_RECOGNIZE'"), Some("'MATERIALIZED'"), 
		Some("'MAX'"), Some("'MEASURES'"), Some("'MERGE'"), Some("'MESSAGE'"), 
		Some("'MICROSECOND'"), Some("'MILLISECOND'"), Some("'MIN'"), Some("'MINUS'"), 
		Some("'MINUTE'"), Some("'MODEL'"), Some("'MONDAY'"), Some("'MONTH'"), 
		Some("'NAME'"), Some("'NATURAL'"), Some("'NEXT'"), Some("'NFC'"), Some("'NFD'"), 
		Some("'NFKC'"), Some("'NFKD'"), Some("'NO'"), Some("'NONE'"), Some("'NORMALIZE'"), 
		Some("'NOT'"), Some("'NULL'"), Some("'NULLS'"), Some("'OBJECT'"), Some("'OF'"), 
		Some("'OFFSET'"), Some("'OMIT'"), Some("'ON'"), Some("'ONE'"), Some("'ONLY'"), 
		Some("'OPTION'"), Some("'OPTIONS'"), Some("'OR'"), Some("'ORDER'"), Some("'OUTER'"), 
		Some("'OUTPUT'"), Some("'OUTPUTFORMAT'"), Some("'OVER'"), Some("'OVERFLOW'"), 
		Some("'PARTITION'"), Some("'PARTITIONED'"), Some("'PARTITIONS'"), Some("'PASSING'"), 
		Some("'PAST'"), Some("'PATH'"), Some("'PATTERN'"), Some("'PER'"), Some("'PERCENT'"), 
		Some("'PERIOD'"), Some("'PERMUTE'"), Some("'PIVOT'"), Some("'POSITION'"), 
		Some("'PRECEDING'"), Some("'PRECISION'"), Some("'PREPARE'"), Some("'PRIOR'"), 
		Some("'PROCEDURE'"), Some("'PRIVILEGES'"), Some("'PROPERTIES'"), Some("'PRUNE'"), 
		Some("'QUALIFY'"), Some("'QUARTER'"), Some("'QUOTES'"), Some("'RAISE'"), 
		Some("'RANGE'"), Some("'READ'"), Some("'RECURSIVE'"), Some("'REFRESH'"), 
		Some("'RENAME'"), Some("'REPEATABLE'"), Some("'REPLACE'"), Some("'RESET'"), 
		Some("'RESPECT'"), Some("'RESTRICT'"), Some("'RETURN'"), Some("'RETURNING'"), 
		Some("'REMOTE'"), Some("'REPEAT'"), Some("'RETURNS'"), Some("'REVOKE'"), 
		Some("'RIGHT'"), Some("'RLS'"), Some("'ROLE'"), Some("'ROLES'"), Some("'ROLLBACK'"), 
		Some("'ROLLUP'"), Some("'ROW'"), Some("'ROWS'"), Some("'RUNNING'"), Some("'SAFE'"), 
		Some("'SAFE_CAST'"), Some("'SATURDAY'"), Some("'SCALAR'"), Some("'SECOND'"), 
		Some("'SCHEMA'"), Some("'SCHEMAS'"), Some("'SECURITY'"), Some("'SEEK'"), 
		Some("'SELECT'"), Some("'SEMI'"), Some("'SERDE'"), Some("'SERDEPROPERTIES'"), 
		Some("'SERIALIZABLE'"), Some("'SESSION'"), Some("'SET'"), Some("'SETS'"), 
		Some("'SHOW'"), Some("'SIMILAR'"), Some("'SNAPSHOT'"), Some("'SOME'"), 
		Some("'SORTKEY'"), Some("'START'"), Some("'STATS'"), Some("'STORED'"), 
		Some("'STRUCT'"), Some("'SUBSET'"), Some("'SUBSTRING'"), Some("'SUNDAY'"), 
		Some("'SYSTEM'"), Some("'SYSTEM_TIME'"), Some("'TABLE'"), Some("'TABLES'"), 
		Some("'TABLESAMPLE'"), Some("'TEMP'"), Some("'TEMPORARY'"), Some("'TERMINATED'"), 
		Some("'TEXT'"), Some("'STRING'"), Some("'THEN'"), Some("'THURSDAY'"), 
		Some("'TIES'"), Some("'TIME'"), Some("'TIMESTAMP'"), Some("'TIMESTAMP_DIFF'"), 
		Some("'TO'"), Some("'TOP'"), Some("'TRAILING'"), Some("'TARGET'"), Some("'SOURCE'"), 
		Some("'TRAINING_DATA'"), Some("'TRANSACTION'"), Some("'TRANSFORM'"), Some("'TRIM'"), 
		Some("'TRUE'"), Some("'TRUNCATE'"), Some("'TRY_CAST'"), Some("'TUPLE'"), 
		Some("'TUESDAY'"), Some("'TYPE'"), Some("'UESCAPE'"), Some("'UNBOUNDED'"), 
		Some("'UNCOMMITTED'"), Some("'UNCONDITIONAL'"), Some("'UNION'"), Some("'UNKNOWN'"), 
		Some("'UNLOAD'"), Some("'UNMATCHED'"), Some("'UNNEST'"), Some("'UNPIVOT'"), 
		Some("'UNSIGNED'"), Some("'UNTIL'"), Some("'UPDATE'"), Some("'USE'"), 
		Some("'USER'"), Some("'USING'"), Some("'UTF16'"), Some("'UTF32'"), Some("'UTF8'"), 
		Some("'VACUUM'"), Some("'VALIDATE'"), Some("'VALUE'"), Some("'VALUES'"), 
		Some("'VARYING'"), Some("'VERBOSE'"), Some("'VERSION'"), Some("'VIEW'"), 
		Some("'WEDNESDAY'"), Some("'WEEK'"), Some("'WHEN'"), Some("'WHERE'"), 
		Some("'WHILE'"), Some("'WINDOW'"), Some("'WITH'"), Some("'WITHOUT'"), 
		Some("'WORK'"), Some("'WRAPPER'"), Some("'WRITE'"), Some("'XZ'"), Some("'YEAR'"), 
		Some("'YES'"), Some("'ZONE'"), Some("'ZSTD'"), Some("'('"), Some("')'"), 
		Some("'['"), Some("']'"), Some("'.'"), Some("'='"), None, Some("'<'"), 
		Some("'<='"), Some("'>'"), Some("'>='"), Some("'+'"), Some("'-'"), Some("'*'"), 
		Some("'/'"), Some("'%'"), Some("'||'"), Some("'?'"), Some("';'"), Some("':'"), 
		Some("'$'"), Some("'&'"), Some("'|'"), Some("'^'"), Some("'<<'"), Some("'~'")
	];
	pub const _SYMBOLIC_NAMES: [Option<&'static str>;441]  = [
		None, None, None, None, None, None, None, None, Some("ABORT"), Some("ABSENT"), 
		Some("ADD"), Some("ADMIN"), Some("AFTER"), Some("ALL"), Some("ALTER"), 
		Some("ANALYZE"), Some("AND"), Some("ANTI"), Some("ANY"), Some("ARRAY"), 
		Some("AS"), Some("ASC"), Some("AT"), Some("ATTACH"), Some("AUTHORIZATION"), 
		Some("AUTO"), Some("BACKUP"), Some("BEGIN"), Some("BERNOULLI"), Some("BETWEEN"), 
		Some("BOTH"), Some("BREAK"), Some("BY"), Some("BZIP2"), Some("CALL"), 
		Some("CANCEL"), Some("CASCADE"), Some("CASE"), Some("CASE_SENSITIVE"), 
		Some("CASE_INSENSITIVE"), Some("CAST"), Some("CATALOGS"), Some("CHARACTER"), 
		Some("CLONE"), Some("CLOSE"), Some("CLUSTER"), Some("COALESCE"), Some("COLLATE"), 
		Some("COLUMN"), Some("COLUMNS"), Some("COMMA"), Some("COMMENT"), Some("COMMIT"), 
		Some("COMMITTED"), Some("COMPOUND"), Some("COMPRESSION"), Some("CONDITIONAL"), 
		Some("CONNECT"), Some("CONNECTION"), Some("CONSTRAINT"), Some("CONTINUE"), 
		Some("COPARTITION"), Some("COPY"), Some("COUNT"), Some("CREATE"), Some("CROSS"), 
		Some("CUBE"), Some("CURRENT"), Some("CURRENT_ROLE"), Some("CUSTOM_HOLIDAY"), 
		Some("DATA"), Some("DATABASE"), Some("DATASHARE"), Some("DATE"), Some("DATETIME"), 
		Some("DAY"), Some("DAYOFWEEK"), Some("DAYOFYEAR"), Some("DATETIME_DIFF"), 
		Some("DATE_DIFF"), Some("DEALLOCATE"), Some("DECLARE"), Some("DEFAULT"), 
		Some("DEFAULTS"), Some("DEFINE"), Some("DEFINER"), Some("DELETE"), Some("DELIMITED"), 
		Some("DELIMITER"), Some("DENY"), Some("DESC"), Some("DESCRIBE"), Some("DESCRIPTOR"), 
		Some("DETERMINISTIC"), Some("DISTINCT"), Some("DISTKEY"), Some("DISTRIBUTED"), 
		Some("DISTSTYLE"), Some("DETACH"), Some("DO"), Some("DOUBLE"), Some("DROP"), 
		Some("ELSE"), Some("ELSEIF"), Some("EMPTY"), Some("ENCODE"), Some("ENCODING"), 
		Some("END"), Some("ERROR"), Some("ESCAPE"), Some("EVEN"), Some("EXCEPT"), 
		Some("EXCEPTION"), Some("EXCLUDE"), Some("EXCLUDING"), Some("EXECUTE"), 
		Some("EXISTS"), Some("EXPLAIN"), Some("EXTERNAL"), Some("EXTRACT"), Some("FALSE"), 
		Some("FETCH"), Some("FIELDS"), Some("FILTER"), Some("FINAL"), Some("FIRST"), 
		Some("FOLLOWING"), Some("FOR"), Some("FORMAT"), Some("FRIDAY"), Some("FROM"), 
		Some("FULL"), Some("FUNCTION"), Some("FUNCTIONS"), Some("GENERATED"), 
		Some("GRACE"), Some("GRANT"), Some("GRANTED"), Some("GRANTS"), Some("GRAPHVIZ"), 
		Some("GROUP"), Some("GROUPING"), Some("GROUPS"), Some("GZIP"), Some("HAVING"), 
		Some("HEADER"), Some("HOUR"), Some("IDENTITY"), Some("IF"), Some("IGNORE"), 
		Some("IMMEDIATE"), Some("IN"), Some("INCLUDE"), Some("INCLUDING"), Some("INITIAL"), 
		Some("INNER"), Some("INPUT"), Some("INPUTFORMAT"), Some("INTERLEAVED"), 
		Some("INSERT"), Some("INTERSECT"), Some("INTERVAL"), Some("INTO"), Some("INVOKER"), 
		Some("IO"), Some("IS"), Some("ISOLATION"), Some("ISOWEEK"), Some("ISOYEAR"), 
		Some("ITERATE"), Some("ILIKE"), Some("JOIN"), Some("JSON"), Some("KEEP"), 
		Some("KEY"), Some("KEYS"), Some("LAMBDA"), Some("LANGUAGE"), Some("LEAVE"), 
		Some("LAST"), Some("LATERAL"), Some("LEADING"), Some("LEFT"), Some("LEVEL"), 
		Some("LIBRARY"), Some("LIKE"), Some("LIMIT"), Some("LINES"), Some("LISTAGG"), 
		Some("LOCAL"), Some("LOCATION"), Some("LOCK"), Some("LOGICAL"), Some("LOOP"), 
		Some("MAP"), Some("MASKING"), Some("MATCH"), Some("MATCHED"), Some("MATCHES"), 
		Some("MATCH_RECOGNIZE"), Some("MATERIALIZED"), Some("MAX"), Some("MEASURES"), 
		Some("MERGE"), Some("MESSAGE"), Some("MICROSECOND"), Some("MILLISECOND"), 
		Some("MIN"), Some("MINUS_KW"), Some("MINUTE"), Some("MODEL"), Some("MONDAY"), 
		Some("MONTH"), Some("NAME"), Some("NATURAL"), Some("NEXT"), Some("NFC"), 
		Some("NFD"), Some("NFKC"), Some("NFKD"), Some("NO"), Some("NONE"), Some("NORMALIZE"), 
		Some("NOT"), Some("NULL"), Some("NULLS"), Some("OBJECT"), Some("OF"), 
		Some("OFFSET"), Some("OMIT"), Some("ON"), Some("ONE"), Some("ONLY"), Some("OPTION"), 
		Some("OPTIONS"), Some("OR"), Some("ORDER"), Some("OUTER"), Some("OUTPUT"), 
		Some("OUTPUTFORMAT"), Some("OVER"), Some("OVERFLOW"), Some("PARTITION"), 
		Some("PARTITIONED"), Some("PARTITIONS"), Some("PASSING"), Some("PAST"), 
		Some("PATH"), Some("PATTERN"), Some("PER"), Some("PERCENT_KW"), Some("PERIOD"), 
		Some("PERMUTE"), Some("PIVOT"), Some("POSITION"), Some("PRECEDING"), Some("PRECISION"), 
		Some("PREPARE"), Some("PRIOR"), Some("PROCEDURE"), Some("PRIVILEGES"), 
		Some("PROPERTIES"), Some("PRUNE"), Some("QUALIFY"), Some("QUARTER"), Some("QUOTES"), 
		Some("RAISE"), Some("RANGE"), Some("READ"), Some("RECURSIVE"), Some("REFRESH"), 
		Some("RENAME"), Some("REPEATABLE"), Some("REPLACE"), Some("RESET"), Some("RESPECT"), 
		Some("RESTRICT"), Some("RETURN"), Some("RETURNING"), Some("REMOTE"), Some("REPEAT"), 
		Some("RETURNS"), Some("REVOKE"), Some("RIGHT"), Some("RLS"), Some("ROLE"), 
		Some("ROLES"), Some("ROLLBACK"), Some("ROLLUP"), Some("ROW"), Some("ROWS"), 
		Some("RUNNING"), Some("SAFE"), Some("SAFE_CAST"), Some("SATURDAY"), Some("SCALAR"), 
		Some("SECOND"), Some("SCHEMA"), Some("SCHEMAS"), Some("SECURITY"), Some("SEEK"), 
		Some("SELECT"), Some("SEMI"), Some("SERDE"), Some("SERDEPROPERTIES"), 
		Some("SERIALIZABLE"), Some("SESSION"), Some("SET"), Some("SETS"), Some("SHOW"), 
		Some("SIMILAR"), Some("SNAPSHOT"), Some("SOME"), Some("SORTKEY"), Some("START"), 
		Some("STATS"), Some("STORED"), Some("STRUCT"), Some("SUBSET"), Some("SUBSTRING"), 
		Some("SUNDAY"), Some("SYSTEM"), Some("SYSTEM_TIME"), Some("TABLE"), Some("TABLES"), 
		Some("TABLESAMPLE"), Some("TEMP"), Some("TEMPORARY"), Some("TERMINATED"), 
		Some("TEXT"), Some("STRING_KW"), Some("THEN"), Some("THURSDAY"), Some("TIES"), 
		Some("TIME"), Some("TIMESTAMP"), Some("TIMESTAMP_DIFF"), Some("TO"), Some("TOP"), 
		Some("TRAILING"), Some("TARGET"), Some("SOURCE"), Some("TRAINING_DATA"), 
		Some("TRANSACTION"), Some("TRANSFORM"), Some("TRIM"), Some("TRUE"), Some("TRUNCATE"), 
		Some("TRY_CAST"), Some("TUPLE"), Some("TUESDAY"), Some("TYPE"), Some("UESCAPE"), 
		Some("UNBOUNDED"), Some("UNCOMMITTED"), Some("UNCONDITIONAL"), Some("UNION"), 
		Some("UNKNOWN"), Some("UNLOAD"), Some("UNMATCHED"), Some("UNNEST"), Some("UNPIVOT"), 
		Some("UNSIGNED"), Some("UNTIL"), Some("UPDATE"), Some("USE"), Some("USER"), 
		Some("USING"), Some("UTF16"), Some("UTF32"), Some("UTF8"), Some("VACUUM"), 
		Some("VALIDATE"), Some("VALUE"), Some("VALUES"), Some("VARYING"), Some("VERBOSE"), 
		Some("VERSION"), Some("VIEW"), Some("WEDNESDAY"), Some("WEEK"), Some("WHEN"), 
		Some("WHERE"), Some("WHILE"), Some("WINDOW"), Some("WITH"), Some("WITHOUT"), 
		Some("WORK"), Some("WRAPPER"), Some("WRITE"), Some("XZ"), Some("YEAR"), 
		Some("YES"), Some("ZONE"), Some("ZSTD"), Some("LPAREN"), Some("RPAREN"), 
		Some("LBRACKET"), Some("RBRACKET"), Some("DOT"), Some("EQ"), Some("NEQ"), 
		Some("LT"), Some("LTE"), Some("GT"), Some("GTE"), Some("PLUS"), Some("MINUS"), 
		Some("ASTERISK"), Some("SLASH"), Some("PERCENT"), Some("CONCAT"), Some("QUESTION_MARK"), 
		Some("SEMI_COLON"), Some("COLON"), Some("DOLLAR"), Some("BITWISE_AND"), 
		Some("BITWISE_OR"), Some("BITWISE_XOR"), Some("BITWISE_SHIFT_LEFT"), Some("POSIX"), 
		Some("ESCAPE_SEQUENCE"), Some("QUOTED_STRING"), Some("TRIPLE_QUOTED_STRING"), 
		Some("RAW_QUOTED_STRING"), Some("RAW_TRIPLE_QUOTED_STRING"), Some("BINARY_LITERAL"), 
		Some("INTEGER_VALUE"), Some("HEXADECIMAL_VALUE"), Some("DECIMAL_VALUE"), 
		Some("DOUBLE_VALUE"), Some("IDENTIFIER"), Some("BACKQUOTED_IDENTIFIER"), 
		Some("VARIABLE"), Some("SIMPLE_COMMENT"), Some("BIG_QUERY_SIMPLE_COMMENT"), 
		Some("BRACKETED_COMMENT"), Some("WS"), Some("OTHER_WS"), Some("UNPAIRED_TOKEN"), 
		Some("UNRECOGNIZED")
	];
	thread_local!{
	    static _shared_context_cache: Rc<PredictionContextCache> = Rc::new(PredictionContextCache::new());
		static VOCABULARY: Box<dyn Vocabulary> = Box::new(VocabularyImpl::new(_LITERAL_NAMES.iter(), _SYMBOLIC_NAMES.iter(), None));
	}


type BaseParserType<'input, I> =
	BaseParser<'input,BigqueryParserExt<'input>, I, BigqueryParserContextType , dyn BigqueryListener<'input> + 'input >;

type TokenType<'input> = <LocalTokenFactory<'input> as TokenFactory<'input>>::Tok;

pub type LocalTokenFactory<'input> = antlr_rust::token_factory::ArenaCommonFactory<'input>;

pub type BigqueryTreeWalker<'input,'a> =
	ParseTreeWalker<'input, 'a, BigqueryParserContextType , dyn BigqueryListener<'input> + 'a>;

/// Parser for Bigquery grammar
pub struct BigqueryParser<'input,I,H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	base:BaseParserType<'input,I>,
	interpreter:Rc<ParserATNSimulator>,
	_shared_context_cache: Box<PredictionContextCache>,
    pub err_handler: H,
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn get_serialized_atn() -> &'static str { _serializedATN }

    pub fn set_error_strategy(&mut self, strategy: H) {
        self.err_handler = strategy
    }

    pub fn with_strategy(input: I, strategy: H) -> Self {
		antlr_rust::recognizer::check_version("0","3");
        let interpreter = Rc::new(ParserATNSimulator::new(
            _ATN.with(|atn| atn.clone()),
            _decision_to_DFA.with(|decision| decision.clone()),
            _shared_context_cache.with(|ctx| ctx.clone()),
        ));
		Self {
			base: BaseParser::new_base_parser(
				input,
				Rc::clone(&interpreter),
				BigqueryParserExt{
					_pd: Default::default(),
				}
			),
			interpreter,
            _shared_context_cache: Box::new(PredictionContextCache::new()),
            err_handler: strategy,
        }
    }

    pub fn add_error_listener(&mut self, listener: Box<(dyn ErrorListener<'input, BaseParser<'input, BigqueryParserExt<'input>, I, BigqueryParserContextType, (dyn BigqueryListener<'input> + 'input)>> + 'static)>) {
        self.base.add_error_listener(listener)
    }

	pub fn remove_error_listeners(&mut self) {
        self.base.remove_error_listeners()
    }
}

type DynStrategy<'input,I> = Box<dyn ErrorStrategy<'input,BaseParserType<'input,I>> + 'input>;

impl<'input, I> BigqueryParser<'input, I, DynStrategy<'input,I>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn with_dyn_strategy(input: I) -> Self{
    	Self::with_strategy(input,Box::new(DefaultErrorStrategy::new()))
    }
}

impl<'input, I> BigqueryParser<'input, I, DefaultErrorStrategy<'input,BigqueryParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn new(input: I) -> Self{
    	Self::with_strategy(input,DefaultErrorStrategy::new())
    }
}

/// Trait for monomorphized trait object that corresponds to the nodes of parse tree generated for BigqueryParser
pub trait BigqueryParserContext<'input>:
	for<'x> Listenable<dyn BigqueryListener<'input> + 'x > + 
	for<'x> Visitable<dyn BigqueryVisitor<'input> + 'x > + 
	ParserRuleContext<'input, TF=LocalTokenFactory<'input>, Ctx=BigqueryParserContextType>
{}

antlr_rust::coerce_from!{ 'input : BigqueryParserContext<'input> }

impl<'input, 'x, T> VisitableDyn<T> for dyn BigqueryParserContext<'input> + 'input
where
    T: BigqueryVisitor<'input> + 'x,
{
    fn accept_dyn(&self, visitor: &mut T) {
        self.accept(visitor as &mut (dyn BigqueryVisitor<'input> + 'x))
    }
}

impl<'input> BigqueryParserContext<'input> for TerminalNode<'input,BigqueryParserContextType> {}
impl<'input> BigqueryParserContext<'input> for ErrorNode<'input,BigqueryParserContextType> {}

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn BigqueryParserContext<'input> + 'input }

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn BigqueryListener<'input> + 'input }

pub struct BigqueryParserContextType;
antlr_rust::tid!{BigqueryParserContextType}

impl<'input> ParserNodeType<'input> for BigqueryParserContextType{
	type TF = LocalTokenFactory<'input>;
	type Type = dyn BigqueryParserContext<'input> + 'input;
}

impl<'input, I, H> Deref for BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    type Target = BaseParserType<'input,I>;

    fn deref(&self) -> &Self::Target {
        &self.base
    }
}

impl<'input, I, H> DerefMut for BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.base
    }
}

pub struct BigqueryParserExt<'input>{
	_pd: PhantomData<&'input str>,
}

impl<'input> BigqueryParserExt<'input>{
}
antlr_rust::tid! { BigqueryParserExt<'a> }

impl<'input> TokenAware<'input> for BigqueryParserExt<'input>{
	type TF = LocalTokenFactory<'input>;
}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> ParserRecog<'input, BaseParserType<'input,I>> for BigqueryParserExt<'input>{}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> Actions<'input, BaseParserType<'input,I>> for BigqueryParserExt<'input>{
	fn get_grammar_file_name(&self) -> & str{ "Bigquery.g4"}

   	fn get_rule_names(&self) -> &[& str] {&ruleNames}

   	fn get_vocabulary(&self) -> &dyn Vocabulary { VOCABULARY.with(|v| unsafe { std::mem::transmute(&**v) }) }
	fn sempred(_localctx: Option<&(dyn BigqueryParserContext<'input> + 'input)>, rule_index: isize, pred_index: isize,
			   recog:&mut BaseParserType<'input,I>
	)->bool{
		match rule_index {
					63 => BigqueryParser::<'input,I,_>::joinedRelation_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					107 => BigqueryParser::<'input,I,_>::booleanExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					109 => BigqueryParser::<'input,I,_>::valueExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					110 => BigqueryParser::<'input,I,_>::primaryExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					133 => BigqueryParser::<'input,I,_>::nonnullableType_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					145 => BigqueryParser::<'input,I,_>::rowPattern_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					154 => BigqueryParser::<'input,I,_>::dashedIdentifier_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
			_ => true
		}
	}
}

impl<'input, I> BigqueryParser<'input, I, DefaultErrorStrategy<'input,BigqueryParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
	fn joinedRelation_sempred(_localctx: Option<&JoinedRelationContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				0=>{
					recog.precpred(None, 2)
				}
			_ => true
		}
	}
	fn booleanExpression_sempred(_localctx: Option<&BooleanExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				1=>{
					recog.precpred(None, 2)
				}
				2=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
	fn valueExpression_sempred(_localctx: Option<&ValueExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				3=>{
					recog.precpred(None, 5)
				}
				4=>{
					recog.precpred(None, 4)
				}
				5=>{
					recog.precpred(None, 3)
				}
				6=>{
					recog.precpred(None, 2)
				}
				7=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
	fn primaryExpression_sempred(_localctx: Option<&PrimaryExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				8=>{
					recog.precpred(None, 7)
				}
				9=>{
					recog.precpred(None, 6)
				}
			_ => true
		}
	}
	fn nonnullableType_sempred(_localctx: Option<&NonnullableTypeContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				10=>{
					recog.precpred(None, 2)
				}
			_ => true
		}
	}
	fn rowPattern_sempred(_localctx: Option<&RowPatternContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				11=>{
					recog.precpred(None, 2)
				}
				12=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
	fn dashedIdentifier_sempred(_localctx: Option<&DashedIdentifierContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				13=>{
					recog.precpred(None, 5)
				}
				14=>{
					recog.precpred(None, 3)
				}
				15=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
}
//------------------- multipleStatement ----------------
pub type MultipleStatementContextAll<'input> = MultipleStatementContext<'input>;


pub type MultipleStatementContext<'input> = BaseParserRuleContext<'input,MultipleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct MultipleStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for MultipleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MultipleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multipleStatement(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_multipleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MultipleStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_multipleStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multipleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multipleStatement }
}
antlr_rust::tid!{MultipleStatementContextExt<'a>}

impl<'input> MultipleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultipleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultipleStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultipleStatementContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<MultipleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement_all(&self) ->  Vec<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn statement(&self, i: usize) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SEMI_COLON, i)
}

}

impl<'input> MultipleStatementContextAttrs<'input> for MultipleStatementContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multipleStatement(&mut self,)
	-> Result<Rc<MultipleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultipleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 0, RULE_multipleStatement);
        let mut _localctx: Rc<MultipleStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(337);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ALTER) | (1usize << ANALYZE) | (1usize << BEGIN) | (1usize << BREAK))) != 0) || ((((_la - 34)) & !0x3f) == 0 && ((1usize << (_la - 34)) & ((1usize << (CALL - 34)) | (1usize << (CASE - 34)) | (1usize << (COMMENT - 34)) | (1usize << (COMMIT - 34)) | (1usize << (CONTINUE - 34)) | (1usize << (CREATE - 34)))) != 0) || ((((_la - 80)) & !0x3f) == 0 && ((1usize << (_la - 80)) & ((1usize << (DEALLOCATE - 80)) | (1usize << (DECLARE - 80)) | (1usize << (DELETE - 80)) | (1usize << (DENY - 80)) | (1usize << (DESC - 80)) | (1usize << (DESCRIBE - 80)) | (1usize << (DROP - 80)))) != 0) || ((((_la - 115)) & !0x3f) == 0 && ((1usize << (_la - 115)) & ((1usize << (EXECUTE - 115)) | (1usize << (FOR - 115)) | (1usize << (GRANT - 115)))) != 0) || ((((_la - 148)) & !0x3f) == 0 && ((1usize << (_la - 148)) & ((1usize << (IF - 148)) | (1usize << (INSERT - 148)) | (1usize << (ITERATE - 148)) | (1usize << (LEAVE - 148)))) != 0) || _la==LOOP || _la==MERGE || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PREPARE - 257)) | (1usize << (RAISE - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RESET - 257)) | (1usize << (RETURN - 257)) | (1usize << (REPEAT - 257)) | (1usize << (REVOKE - 257)) | (1usize << (ROLLBACK - 257)))) != 0) || ((((_la - 301)) & !0x3f) == 0 && ((1usize << (_la - 301)) & ((1usize << (SELECT - 301)) | (1usize << (SET - 301)) | (1usize << (SHOW - 301)) | (1usize << (START - 301)) | (1usize << (TABLE - 301)))) != 0) || ((((_la - 347)) & !0x3f) == 0 && ((1usize << (_la - 347)) & ((1usize << (TRUNCATE - 347)) | (1usize << (UPDATE - 347)) | (1usize << (USE - 347)) | (1usize << (VALUES - 347)))) != 0) || ((((_la - 383)) & !0x3f) == 0 && ((1usize << (_la - 383)) & ((1usize << (WHILE - 383)) | (1usize << (WITH - 383)) | (1usize << (LPAREN - 383)))) != 0) {
				{
				/*InvokeRule statement*/
				recog.base.set_state(336);
				recog.statement()?;

				}
			}

			recog.base.set_state(345);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==SEMI_COLON {
				{
				{
				recog.base.set_state(339);
				recog.base.match_token(SEMI_COLON,&mut recog.err_handler)?;

				recog.base.set_state(341);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ALTER) | (1usize << ANALYZE) | (1usize << BEGIN) | (1usize << BREAK))) != 0) || ((((_la - 34)) & !0x3f) == 0 && ((1usize << (_la - 34)) & ((1usize << (CALL - 34)) | (1usize << (CASE - 34)) | (1usize << (COMMENT - 34)) | (1usize << (COMMIT - 34)) | (1usize << (CONTINUE - 34)) | (1usize << (CREATE - 34)))) != 0) || ((((_la - 80)) & !0x3f) == 0 && ((1usize << (_la - 80)) & ((1usize << (DEALLOCATE - 80)) | (1usize << (DECLARE - 80)) | (1usize << (DELETE - 80)) | (1usize << (DENY - 80)) | (1usize << (DESC - 80)) | (1usize << (DESCRIBE - 80)) | (1usize << (DROP - 80)))) != 0) || ((((_la - 115)) & !0x3f) == 0 && ((1usize << (_la - 115)) & ((1usize << (EXECUTE - 115)) | (1usize << (FOR - 115)) | (1usize << (GRANT - 115)))) != 0) || ((((_la - 148)) & !0x3f) == 0 && ((1usize << (_la - 148)) & ((1usize << (IF - 148)) | (1usize << (INSERT - 148)) | (1usize << (ITERATE - 148)) | (1usize << (LEAVE - 148)))) != 0) || _la==LOOP || _la==MERGE || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PREPARE - 257)) | (1usize << (RAISE - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RESET - 257)) | (1usize << (RETURN - 257)) | (1usize << (REPEAT - 257)) | (1usize << (REVOKE - 257)) | (1usize << (ROLLBACK - 257)))) != 0) || ((((_la - 301)) & !0x3f) == 0 && ((1usize << (_la - 301)) & ((1usize << (SELECT - 301)) | (1usize << (SET - 301)) | (1usize << (SHOW - 301)) | (1usize << (START - 301)) | (1usize << (TABLE - 301)))) != 0) || ((((_la - 347)) & !0x3f) == 0 && ((1usize << (_la - 347)) & ((1usize << (TRUNCATE - 347)) | (1usize << (UPDATE - 347)) | (1usize << (USE - 347)) | (1usize << (VALUES - 347)))) != 0) || ((((_la - 383)) & !0x3f) == 0 && ((1usize << (_la - 383)) & ((1usize << (WHILE - 383)) | (1usize << (WITH - 383)) | (1usize << (LPAREN - 383)))) != 0) {
					{
					/*InvokeRule statement*/
					recog.base.set_state(340);
					recog.statement()?;

					}
				}

				}
				}
				recog.base.set_state(347);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(348);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleStatement ----------------
pub type SingleStatementContextAll<'input> = SingleStatementContext<'input>;


pub type SingleStatementContext<'input> = BaseParserRuleContext<'input,SingleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SingleStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SingleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SingleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleStatement(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_singleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SingleStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_singleStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleStatement }
}
antlr_rust::tid!{SingleStatementContextExt<'a>}

impl<'input> SingleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleStatementContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SingleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SEMI_COLON
/// Returns `None` if there is no child corresponding to token SEMI_COLON
fn SEMI_COLON(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SEMI_COLON, 0)
}

}

impl<'input> SingleStatementContextAttrs<'input> for SingleStatementContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleStatement(&mut self,)
	-> Result<Rc<SingleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 2, RULE_singleStatement);
        let mut _localctx: Rc<SingleStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(351);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ALTER) | (1usize << ANALYZE) | (1usize << BEGIN) | (1usize << BREAK))) != 0) || ((((_la - 34)) & !0x3f) == 0 && ((1usize << (_la - 34)) & ((1usize << (CALL - 34)) | (1usize << (CASE - 34)) | (1usize << (COMMENT - 34)) | (1usize << (COMMIT - 34)) | (1usize << (CONTINUE - 34)) | (1usize << (CREATE - 34)))) != 0) || ((((_la - 80)) & !0x3f) == 0 && ((1usize << (_la - 80)) & ((1usize << (DEALLOCATE - 80)) | (1usize << (DECLARE - 80)) | (1usize << (DELETE - 80)) | (1usize << (DENY - 80)) | (1usize << (DESC - 80)) | (1usize << (DESCRIBE - 80)) | (1usize << (DROP - 80)))) != 0) || ((((_la - 115)) & !0x3f) == 0 && ((1usize << (_la - 115)) & ((1usize << (EXECUTE - 115)) | (1usize << (FOR - 115)) | (1usize << (GRANT - 115)))) != 0) || ((((_la - 148)) & !0x3f) == 0 && ((1usize << (_la - 148)) & ((1usize << (IF - 148)) | (1usize << (INSERT - 148)) | (1usize << (ITERATE - 148)) | (1usize << (LEAVE - 148)))) != 0) || _la==LOOP || _la==MERGE || ((((_la - 257)) & !0x3f) == 0 && ((1usize << (_la - 257)) & ((1usize << (PREPARE - 257)) | (1usize << (RAISE - 257)) | (1usize << (REFRESH - 257)) | (1usize << (RESET - 257)) | (1usize << (RETURN - 257)) | (1usize << (REPEAT - 257)) | (1usize << (REVOKE - 257)) | (1usize << (ROLLBACK - 257)))) != 0) || ((((_la - 301)) & !0x3f) == 0 && ((1usize << (_la - 301)) & ((1usize << (SELECT - 301)) | (1usize << (SET - 301)) | (1usize << (SHOW - 301)) | (1usize << (START - 301)) | (1usize << (TABLE - 301)))) != 0) || ((((_la - 347)) & !0x3f) == 0 && ((1usize << (_la - 347)) & ((1usize << (TRUNCATE - 347)) | (1usize << (UPDATE - 347)) | (1usize << (USE - 347)) | (1usize << (VALUES - 347)))) != 0) || ((((_la - 383)) & !0x3f) == 0 && ((1usize << (_la - 383)) & ((1usize << (WHILE - 383)) | (1usize << (WITH - 383)) | (1usize << (LPAREN - 383)))) != 0) {
				{
				/*InvokeRule statement*/
				recog.base.set_state(350);
				recog.statement()?;

				}
			}

			recog.base.set_state(354);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SEMI_COLON {
				{
				recog.base.set_state(353);
				recog.base.match_token(SEMI_COLON,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(356);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneExpression ----------------
pub type StandaloneExpressionContextAll<'input> = StandaloneExpressionContext<'input>;


pub type StandaloneExpressionContext<'input> = BaseParserRuleContext<'input,StandaloneExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for StandaloneExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StandaloneExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneExpression(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_standaloneExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StandaloneExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_standaloneExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneExpression }
}
antlr_rust::tid!{StandaloneExpressionContextExt<'a>}

impl<'input> StandaloneExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<StandaloneExpressionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneExpressionContextAttrs<'input> for StandaloneExpressionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneExpression(&mut self,)
	-> Result<Rc<StandaloneExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 4, RULE_standaloneExpression);
        let mut _localctx: Rc<StandaloneExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(358);
			recog.expression()?;

			recog.base.set_state(359);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneQualifiedName ----------------
pub type StandaloneQualifiedNameContextAll<'input> = StandaloneQualifiedNameContext<'input>;


pub type StandaloneQualifiedNameContext<'input> = BaseParserRuleContext<'input,StandaloneQualifiedNameContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneQualifiedNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for StandaloneQualifiedNameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StandaloneQualifiedNameContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneQualifiedName(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_standaloneQualifiedName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StandaloneQualifiedNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_standaloneQualifiedName(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneQualifiedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneQualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneQualifiedName }
}
antlr_rust::tid!{StandaloneQualifiedNameContextExt<'a>}

impl<'input> StandaloneQualifiedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneQualifiedNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneQualifiedNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneQualifiedNameContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<StandaloneQualifiedNameContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneQualifiedNameContextAttrs<'input> for StandaloneQualifiedNameContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneQualifiedName(&mut self,)
	-> Result<Rc<StandaloneQualifiedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneQualifiedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 6, RULE_standaloneQualifiedName);
        let mut _localctx: Rc<StandaloneQualifiedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(361);
			recog.qualifiedName()?;

			recog.base.set_state(362);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneType ----------------
pub type StandaloneTypeContextAll<'input> = StandaloneTypeContext<'input>;


pub type StandaloneTypeContext<'input> = BaseParserRuleContext<'input,StandaloneTypeContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for StandaloneTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StandaloneTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneType(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_standaloneType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StandaloneTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_standaloneType(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneType }
}
antlr_rust::tid!{StandaloneTypeContextExt<'a>}

impl<'input> StandaloneTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneTypeContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<StandaloneTypeContextExt<'input>>{

fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneTypeContextAttrs<'input> for StandaloneTypeContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneType(&mut self,)
	-> Result<Rc<StandaloneTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 8, RULE_standaloneType);
        let mut _localctx: Rc<StandaloneTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule type_*/
			recog.base.set_state(364);
			recog.type_()?;

			recog.base.set_state(365);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- statementBlock ----------------
pub type StatementBlockContextAll<'input> = StatementBlockContext<'input>;


pub type StatementBlockContext<'input> = BaseParserRuleContext<'input,StatementBlockContextExt<'input>>;

#[derive(Clone)]
pub struct StatementBlockContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for StatementBlockContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StatementBlockContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_statementBlock(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_statementBlock(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StatementBlockContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_statementBlock(self);
	}
}

impl<'input> CustomRuleContext<'input> for StatementBlockContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statementBlock }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statementBlock }
}
antlr_rust::tid!{StatementBlockContextExt<'a>}

impl<'input> StatementBlockContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StatementBlockContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StatementBlockContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StatementBlockContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<StatementBlockContextExt<'input>>{

fn statement_all(&self) ->  Vec<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn statement(&self, i: usize) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SEMI_COLON, i)
}

}

impl<'input> StatementBlockContextAttrs<'input> for StatementBlockContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn statementBlock(&mut self,)
	-> Result<Rc<StatementBlockContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StatementBlockContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 10, RULE_statementBlock);
        let mut _localctx: Rc<StatementBlockContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule statement*/
			recog.base.set_state(367);
			recog.statement()?;

			recog.base.set_state(372);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(5,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(368);
					recog.base.match_token(SEMI_COLON,&mut recog.err_handler)?;

					/*InvokeRule statement*/
					recog.base.set_state(369);
					recog.statement()?;

					}
					} 
				}
				recog.base.set_state(374);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(5,&mut recog.base)?;
			}
			recog.base.set_state(375);
			recog.base.match_token(SEMI_COLON,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- statement ----------------
#[derive(Debug)]
pub enum StatementContextAll<'input>{
	PrepareContext(PrepareContext<'input>),
	DeclareContext(DeclareContext<'input>),
	SetMaterializedViewPropertiesContext(SetMaterializedViewPropertiesContext<'input>),
	UseContext(UseContext<'input>),
	DeallocateContext(DeallocateContext<'input>),
	RollbackTransactionContext(RollbackTransactionContext<'input>),
	RenameTableContext(RenameTableContext<'input>),
	CommitContext(CommitContext<'input>),
	CreateRoleContext(CreateRoleContext<'input>),
	DropViewContext(DropViewContext<'input>),
	WhileContext(WhileContext<'input>),
	DropColumnContext(DropColumnContext<'input>),
	SetViewAuthorizationContext(SetViewAuthorizationContext<'input>),
	BeginExceptionContext(BeginExceptionContext<'input>),
	LoopContext(LoopContext<'input>),
	LeaveContext(LeaveContext<'input>),
	ContinueContext(ContinueContext<'input>),
	MergeContext(MergeContext<'input>),
	RaiseContext(RaiseContext<'input>),
	RenameColumnContext(RenameColumnContext<'input>),
	IfContext(IfContext<'input>),
	ShowColumnsContext(ShowColumnsContext<'input>),
	CaseContext(CaseContext<'input>),
	ForInContext(ForInContext<'input>),
	AddColumnContext(AddColumnContext<'input>),
	DenyContext(DenyContext<'input>),
	InsertIntoContext(InsertIntoContext<'input>),
	CreateSchemaContext(CreateSchemaContext<'input>),
	ExecuteContext(ExecuteContext<'input>),
	CreateJSFunctionContext(CreateJSFunctionContext<'input>),
	RenameSchemaContext(RenameSchemaContext<'input>),
	BeginTransactionContext(BeginTransactionContext<'input>),
	CommitTransactionContext(CommitTransactionContext<'input>),
	AnalyzeContext(AnalyzeContext<'input>),
	ResetContext(ResetContext<'input>),
	CreateSnapshotTableContext(CreateSnapshotTableContext<'input>),
	DropSchemaContext(DropSchemaContext<'input>),
	BeginContext(BeginContext<'input>),
	SetTableAuthorizationContext(SetTableAuthorizationContext<'input>),
	DropContext(DropContext<'input>),
	StartTransactionContext(StartTransactionContext<'input>),
	BigqueryCreateModelContext(BigqueryCreateModelContext<'input>),
	ShowContext(ShowContext<'input>),
	RevokeContext(RevokeContext<'input>),
	UpdateContext(UpdateContext<'input>),
	TableExecuteContext(TableExecuteContext<'input>),
	DeleteContext(DeleteContext<'input>),
	DescribeInputContext(DescribeInputContext<'input>),
	BigqueryCreateMaterializedViewContext(BigqueryCreateMaterializedViewContext<'input>),
	SetColumnTypeContext(SetColumnTypeContext<'input>),
	StatementDefaultContext(StatementDefaultContext<'input>),
	RepeatContext(RepeatContext<'input>),
	TruncateTableContext(TruncateTableContext<'input>),
	RenameMaterializedViewContext(RenameMaterializedViewContext<'input>),
	DropTableContext(DropTableContext<'input>),
	CreateRemoteFunctionContext(CreateRemoteFunctionContext<'input>),
	SetSchemaAuthorizationContext(SetSchemaAuthorizationContext<'input>),
	RollbackContext(RollbackContext<'input>),
	SetContext(SetContext<'input>),
	CreateSqlFunctionContext(CreateSqlFunctionContext<'input>),
	BreakContext(BreakContext<'input>),
	BigqueryCreateExternalTableContext(BigqueryCreateExternalTableContext<'input>),
	ExecuteImmediateContext(ExecuteImmediateContext<'input>),
	BigqueryCreateViewContext(BigqueryCreateViewContext<'input>),
	RenameViewContext(RenameViewContext<'input>),
	CallContext(CallContext<'input>),
	RefreshMaterializedViewContext(RefreshMaterializedViewContext<'input>),
	BigqueryCreateTableContext(BigqueryCreateTableContext<'input>),
	CommentContext(CommentContext<'input>),
	DescribeOutputContext(DescribeOutputContext<'input>),
	GrantContext(GrantContext<'input>),
	SetTablePropertiesContext(SetTablePropertiesContext<'input>),
	ReturnContext(ReturnContext<'input>),
Error(StatementContext<'input>)
}
antlr_rust::tid!{StatementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StatementContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for StatementContextAll<'input>{}

impl<'input> Deref for StatementContextAll<'input>{
	type Target = dyn StatementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StatementContextAll::*;
		match self{
			PrepareContext(inner) => inner,
			DeclareContext(inner) => inner,
			SetMaterializedViewPropertiesContext(inner) => inner,
			UseContext(inner) => inner,
			DeallocateContext(inner) => inner,
			RollbackTransactionContext(inner) => inner,
			RenameTableContext(inner) => inner,
			CommitContext(inner) => inner,
			CreateRoleContext(inner) => inner,
			DropViewContext(inner) => inner,
			WhileContext(inner) => inner,
			DropColumnContext(inner) => inner,
			SetViewAuthorizationContext(inner) => inner,
			BeginExceptionContext(inner) => inner,
			LoopContext(inner) => inner,
			LeaveContext(inner) => inner,
			ContinueContext(inner) => inner,
			MergeContext(inner) => inner,
			RaiseContext(inner) => inner,
			RenameColumnContext(inner) => inner,
			IfContext(inner) => inner,
			ShowColumnsContext(inner) => inner,
			CaseContext(inner) => inner,
			ForInContext(inner) => inner,
			AddColumnContext(inner) => inner,
			DenyContext(inner) => inner,
			InsertIntoContext(inner) => inner,
			CreateSchemaContext(inner) => inner,
			ExecuteContext(inner) => inner,
			CreateJSFunctionContext(inner) => inner,
			RenameSchemaContext(inner) => inner,
			BeginTransactionContext(inner) => inner,
			CommitTransactionContext(inner) => inner,
			AnalyzeContext(inner) => inner,
			ResetContext(inner) => inner,
			CreateSnapshotTableContext(inner) => inner,
			DropSchemaContext(inner) => inner,
			BeginContext(inner) => inner,
			SetTableAuthorizationContext(inner) => inner,
			DropContext(inner) => inner,
			StartTransactionContext(inner) => inner,
			BigqueryCreateModelContext(inner) => inner,
			ShowContext(inner) => inner,
			RevokeContext(inner) => inner,
			UpdateContext(inner) => inner,
			TableExecuteContext(inner) => inner,
			DeleteContext(inner) => inner,
			DescribeInputContext(inner) => inner,
			BigqueryCreateMaterializedViewContext(inner) => inner,
			SetColumnTypeContext(inner) => inner,
			StatementDefaultContext(inner) => inner,
			RepeatContext(inner) => inner,
			TruncateTableContext(inner) => inner,
			RenameMaterializedViewContext(inner) => inner,
			DropTableContext(inner) => inner,
			CreateRemoteFunctionContext(inner) => inner,
			SetSchemaAuthorizationContext(inner) => inner,
			RollbackContext(inner) => inner,
			SetContext(inner) => inner,
			CreateSqlFunctionContext(inner) => inner,
			BreakContext(inner) => inner,
			BigqueryCreateExternalTableContext(inner) => inner,
			ExecuteImmediateContext(inner) => inner,
			BigqueryCreateViewContext(inner) => inner,
			RenameViewContext(inner) => inner,
			CallContext(inner) => inner,
			RefreshMaterializedViewContext(inner) => inner,
			BigqueryCreateTableContext(inner) => inner,
			CommentContext(inner) => inner,
			DescribeOutputContext(inner) => inner,
			GrantContext(inner) => inner,
			SetTablePropertiesContext(inner) => inner,
			ReturnContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StatementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StatementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StatementContext<'input> = BaseParserRuleContext<'input,StatementContextExt<'input>>;

#[derive(Clone)]
pub struct StatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for StatementContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StatementContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StatementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}
antlr_rust::tid!{StatementContextExt<'a>}

impl<'input> StatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StatementContextAll<'input>> {
		Rc::new(
		StatementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StatementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StatementContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<StatementContextExt<'input>>{


}

impl<'input> StatementContextAttrs<'input> for StatementContext<'input>{}

pub type PrepareContext<'input> = BaseParserRuleContext<'input,PrepareContextExt<'input>>;

pub trait PrepareContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PREPARE
	/// Returns `None` if there is no child corresponding to token PREPARE
	fn PREPARE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PREPARE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> PrepareContextAttrs<'input> for PrepareContext<'input>{}

pub struct PrepareContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrepareContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PrepareContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PrepareContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_prepare(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_prepare(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PrepareContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_prepare(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrepareContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for PrepareContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for PrepareContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for PrepareContext<'input> {}

impl<'input> PrepareContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::PrepareContext(
				BaseParserRuleContext::copy_from(ctx,PrepareContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DeclareContext<'input> = BaseParserRuleContext<'input,DeclareContextExt<'input>>;

pub trait DeclareContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DECLARE
	/// Returns `None` if there is no child corresponding to token DECLARE
	fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DECLARE, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DEFAULT
	/// Returns `None` if there is no child corresponding to token DEFAULT
	fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DEFAULT, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DeclareContextAttrs<'input> for DeclareContext<'input>{}

pub struct DeclareContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeclareContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DeclareContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DeclareContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_declare(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_declare(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DeclareContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_declare(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclareContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DeclareContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DeclareContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DeclareContext<'input> {}

impl<'input> DeclareContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DeclareContext(
				BaseParserRuleContext::copy_from(ctx,DeclareContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetMaterializedViewPropertiesContext<'input> = BaseParserRuleContext<'input,SetMaterializedViewPropertiesContextExt<'input>>;

pub trait SetMaterializedViewPropertiesContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROPERTIES
	/// Returns `None` if there is no child corresponding to token PROPERTIES
	fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PROPERTIES, 0)
	}
	fn propertyAssignments(&self) -> Option<Rc<PropertyAssignmentsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetMaterializedViewPropertiesContextAttrs<'input> for SetMaterializedViewPropertiesContext<'input>{}

pub struct SetMaterializedViewPropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetMaterializedViewPropertiesContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SetMaterializedViewPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetMaterializedViewPropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setMaterializedViewProperties(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_setMaterializedViewProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetMaterializedViewPropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setMaterializedViewProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetMaterializedViewPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetMaterializedViewPropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetMaterializedViewPropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetMaterializedViewPropertiesContext<'input> {}

impl<'input> SetMaterializedViewPropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetMaterializedViewPropertiesContext(
				BaseParserRuleContext::copy_from(ctx,SetMaterializedViewPropertiesContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UseContext<'input> = BaseParserRuleContext<'input,UseContextExt<'input>>;

pub trait UseContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token USE
	/// Returns `None` if there is no child corresponding to token USE
	fn USE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(USE, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
}

impl<'input> UseContextAttrs<'input> for UseContext<'input>{}

pub struct UseContextExt<'input>{
	base:StatementContextExt<'input>,
	pub schema: Option<Rc<IdentifierContextAll<'input>>>,
	pub catalog: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UseContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UseContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_use(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_use(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_use(self);
	}
}

impl<'input> CustomRuleContext<'input> for UseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UseContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UseContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UseContext<'input> {}

impl<'input> UseContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UseContext(
				BaseParserRuleContext::copy_from(ctx,UseContextExt{
        			schema:None, catalog:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DeallocateContext<'input> = BaseParserRuleContext<'input,DeallocateContextExt<'input>>;

pub trait DeallocateContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DEALLOCATE
	/// Returns `None` if there is no child corresponding to token DEALLOCATE
	fn DEALLOCATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DEALLOCATE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DeallocateContextAttrs<'input> for DeallocateContext<'input>{}

pub struct DeallocateContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeallocateContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DeallocateContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DeallocateContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_deallocate(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_deallocate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DeallocateContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_deallocate(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeallocateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DeallocateContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DeallocateContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DeallocateContext<'input> {}

impl<'input> DeallocateContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DeallocateContext(
				BaseParserRuleContext::copy_from(ctx,DeallocateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RollbackTransactionContext<'input> = BaseParserRuleContext<'input,RollbackTransactionContextExt<'input>>;

pub trait RollbackTransactionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLLBACK
	/// Returns `None` if there is no child corresponding to token ROLLBACK
	fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ROLLBACK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRANSACTION
	/// Returns `None` if there is no child corresponding to token TRANSACTION
	fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRANSACTION, 0)
	}
}

impl<'input> RollbackTransactionContextAttrs<'input> for RollbackTransactionContext<'input>{}

pub struct RollbackTransactionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RollbackTransactionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RollbackTransactionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RollbackTransactionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rollbackTransaction(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_rollbackTransaction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RollbackTransactionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rollbackTransaction(self);
	}
}

impl<'input> CustomRuleContext<'input> for RollbackTransactionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RollbackTransactionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RollbackTransactionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RollbackTransactionContext<'input> {}

impl<'input> RollbackTransactionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RollbackTransactionContext(
				BaseParserRuleContext::copy_from(ctx,RollbackTransactionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameTableContext<'input> = BaseParserRuleContext<'input,RenameTableContextExt<'input>>;

pub trait RenameTableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> RenameTableContextAttrs<'input> for RenameTableContext<'input>{}

pub struct RenameTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub to: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameTableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RenameTableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RenameTableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameTable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_renameTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RenameTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_renameTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameTableContext<'input> {}

impl<'input> RenameTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameTableContext(
				BaseParserRuleContext::copy_from(ctx,RenameTableContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommitContext<'input> = BaseParserRuleContext<'input,CommitContextExt<'input>>;

pub trait CommitContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMIT
	/// Returns `None` if there is no child corresponding to token COMMIT
	fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMIT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CommitContextAttrs<'input> for CommitContext<'input>{}

pub struct CommitContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommitContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CommitContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CommitContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_commit(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_commit(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CommitContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_commit(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommitContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommitContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommitContext<'input> {}

impl<'input> CommitContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommitContext(
				BaseParserRuleContext::copy_from(ctx,CommitContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateRoleContext<'input> = BaseParserRuleContext<'input,CreateRoleContextExt<'input>>;

pub trait CreateRoleContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROLE
	/// Returns `None` if there is no child corresponding to token ROLE
	fn ROLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ROLE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateRoleContextAttrs<'input> for CreateRoleContext<'input>{}

pub struct CreateRoleContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateRoleContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CreateRoleContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CreateRoleContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createRole(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_createRole(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CreateRoleContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_createRole(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateRoleContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateRoleContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateRoleContext<'input> {}

impl<'input> CreateRoleContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateRoleContext(
				BaseParserRuleContext::copy_from(ctx,CreateRoleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropViewContext<'input> = BaseParserRuleContext<'input,DropViewContextExt<'input>>;

pub trait DropViewContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DropViewContextAttrs<'input> for DropViewContext<'input>{}

pub struct DropViewContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropViewContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DropViewContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DropViewContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropView(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_dropView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DropViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dropView(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropViewContext<'input> {}

impl<'input> DropViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropViewContext(
				BaseParserRuleContext::copy_from(ctx,DropViewContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type WhileContext<'input> = BaseParserRuleContext<'input,WhileContextExt<'input>>;

pub trait WhileContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token WHILE in current rule
	fn WHILE_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token WHILE, starting from 0.
	/// Returns `None` if number of children corresponding to token WHILE is less or equal than `i`.
	fn WHILE(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WHILE, i)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DO
	/// Returns `None` if there is no child corresponding to token DO
	fn DO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DO, 0)
	}
	fn statementBlock(&self) -> Option<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
}

impl<'input> WhileContextAttrs<'input> for WhileContext<'input>{}

pub struct WhileContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{WhileContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for WhileContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for WhileContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_while(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_while(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for WhileContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_while(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhileContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for WhileContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for WhileContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for WhileContext<'input> {}

impl<'input> WhileContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::WhileContext(
				BaseParserRuleContext::copy_from(ctx,WhileContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropColumnContext<'input> = BaseParserRuleContext<'input,DropColumnContextExt<'input>>;

pub trait DropColumnContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
}

impl<'input> DropColumnContextAttrs<'input> for DropColumnContext<'input>{}

pub struct DropColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub column: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropColumnContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DropColumnContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DropColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropColumn(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_dropColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DropColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dropColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropColumnContext<'input> {}

impl<'input> DropColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropColumnContext(
				BaseParserRuleContext::copy_from(ctx,DropColumnContextExt{
        			tableName:None, column:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetViewAuthorizationContext<'input> = BaseParserRuleContext<'input,SetViewAuthorizationContextExt<'input>>;

pub trait SetViewAuthorizationContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetViewAuthorizationContextAttrs<'input> for SetViewAuthorizationContext<'input>{}

pub struct SetViewAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetViewAuthorizationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SetViewAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetViewAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setViewAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_setViewAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetViewAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setViewAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetViewAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetViewAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetViewAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetViewAuthorizationContext<'input> {}

impl<'input> SetViewAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetViewAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetViewAuthorizationContextExt{
        			from:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BeginExceptionContext<'input> = BaseParserRuleContext<'input,BeginExceptionContextExt<'input>>;

pub trait BeginExceptionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BEGIN
	/// Returns `None` if there is no child corresponding to token BEGIN
	fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BEGIN, 0)
	}
	fn statementBlock_all(&self) ->  Vec<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn statementBlock(&self, i: usize) -> Option<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token EXCEPTION
	/// Returns `None` if there is no child corresponding to token EXCEPTION
	fn EXCEPTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXCEPTION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WHEN
	/// Returns `None` if there is no child corresponding to token WHEN
	fn WHEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WHEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ERROR
	/// Returns `None` if there is no child corresponding to token ERROR
	fn ERROR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ERROR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token THEN
	/// Returns `None` if there is no child corresponding to token THEN
	fn THEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(THEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
}

impl<'input> BeginExceptionContextAttrs<'input> for BeginExceptionContext<'input>{}

pub struct BeginExceptionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BeginExceptionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BeginExceptionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BeginExceptionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_beginException(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_beginException(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BeginExceptionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_beginException(self);
	}
}

impl<'input> CustomRuleContext<'input> for BeginExceptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BeginExceptionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BeginExceptionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BeginExceptionContext<'input> {}

impl<'input> BeginExceptionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BeginExceptionContext(
				BaseParserRuleContext::copy_from(ctx,BeginExceptionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LoopContext<'input> = BaseParserRuleContext<'input,LoopContextExt<'input>>;

pub trait LoopContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token LOOP in current rule
	fn LOOP_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LOOP, starting from 0.
	/// Returns `None` if number of children corresponding to token LOOP is less or equal than `i`.
	fn LOOP(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LOOP, i)
	}
	fn statementBlock(&self) -> Option<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
}

impl<'input> LoopContextAttrs<'input> for LoopContext<'input>{}

pub struct LoopContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LoopContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for LoopContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LoopContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_loop(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_loop(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LoopContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_loop(self);
	}
}

impl<'input> CustomRuleContext<'input> for LoopContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for LoopContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for LoopContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for LoopContext<'input> {}

impl<'input> LoopContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::LoopContext(
				BaseParserRuleContext::copy_from(ctx,LoopContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LeaveContext<'input> = BaseParserRuleContext<'input,LeaveContextExt<'input>>;

pub trait LeaveContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEAVE
	/// Returns `None` if there is no child corresponding to token LEAVE
	fn LEAVE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LEAVE, 0)
	}
}

impl<'input> LeaveContextAttrs<'input> for LeaveContext<'input>{}

pub struct LeaveContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LeaveContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for LeaveContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LeaveContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_leave(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_leave(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LeaveContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_leave(self);
	}
}

impl<'input> CustomRuleContext<'input> for LeaveContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for LeaveContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for LeaveContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for LeaveContext<'input> {}

impl<'input> LeaveContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::LeaveContext(
				BaseParserRuleContext::copy_from(ctx,LeaveContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ContinueContext<'input> = BaseParserRuleContext<'input,ContinueContextExt<'input>>;

pub trait ContinueContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CONTINUE
	/// Returns `None` if there is no child corresponding to token CONTINUE
	fn CONTINUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CONTINUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ITERATE
	/// Returns `None` if there is no child corresponding to token ITERATE
	fn ITERATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ITERATE, 0)
	}
}

impl<'input> ContinueContextAttrs<'input> for ContinueContext<'input>{}

pub struct ContinueContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ContinueContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ContinueContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ContinueContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_continue(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_continue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ContinueContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_continue(self);
	}
}

impl<'input> CustomRuleContext<'input> for ContinueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ContinueContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ContinueContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ContinueContext<'input> {}

impl<'input> ContinueContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ContinueContext(
				BaseParserRuleContext::copy_from(ctx,ContinueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MergeContext<'input> = BaseParserRuleContext<'input,MergeContextExt<'input>>;

pub trait MergeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MERGE
	/// Returns `None` if there is no child corresponding to token MERGE
	fn MERGE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MERGE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USING
	/// Returns `None` if there is no child corresponding to token USING
	fn USING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(USING, 0)
	}
	fn aliasedRelation(&self) -> Option<Rc<AliasedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn mergeCase_all(&self) ->  Vec<Rc<MergeCaseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn mergeCase(&self, i: usize) -> Option<Rc<MergeCaseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> MergeContextAttrs<'input> for MergeContext<'input>{}

pub struct MergeContextExt<'input>{
	base:StatementContextExt<'input>,
	pub name: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MergeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for MergeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MergeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_merge(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_merge(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MergeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_merge(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for MergeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for MergeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for MergeContext<'input> {}

impl<'input> MergeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::MergeContext(
				BaseParserRuleContext::copy_from(ctx,MergeContextExt{
        			name:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RaiseContext<'input> = BaseParserRuleContext<'input,RaiseContextExt<'input>>;

pub trait RaiseContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RAISE
	/// Returns `None` if there is no child corresponding to token RAISE
	fn RAISE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RAISE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USING
	/// Returns `None` if there is no child corresponding to token USING
	fn USING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(USING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MESSAGE
	/// Returns `None` if there is no child corresponding to token MESSAGE
	fn MESSAGE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MESSAGE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RaiseContextAttrs<'input> for RaiseContext<'input>{}

pub struct RaiseContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RaiseContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RaiseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RaiseContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_raise(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_raise(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RaiseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_raise(self);
	}
}

impl<'input> CustomRuleContext<'input> for RaiseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RaiseContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RaiseContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RaiseContext<'input> {}

impl<'input> RaiseContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RaiseContext(
				BaseParserRuleContext::copy_from(ctx,RaiseContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameColumnContext<'input> = BaseParserRuleContext<'input,RenameColumnContextExt<'input>>;

pub trait RenameColumnContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
}

impl<'input> RenameColumnContextAttrs<'input> for RenameColumnContext<'input>{}

pub struct RenameColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub from: Option<Rc<IdentifierContextAll<'input>>>,
	pub to: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameColumnContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RenameColumnContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RenameColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameColumn(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_renameColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RenameColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_renameColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameColumnContext<'input> {}

impl<'input> RenameColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameColumnContext(
				BaseParserRuleContext::copy_from(ctx,RenameColumnContextExt{
        			tableName:None, from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IfContext<'input> = BaseParserRuleContext<'input,IfContextExt<'input>>;

pub trait IfContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token THEN in current rule
	fn THEN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token THEN, starting from 0.
	/// Returns `None` if number of children corresponding to token THEN is less or equal than `i`.
	fn THEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(THEN, i)
	}
	fn statementBlock_all(&self) ->  Vec<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn statementBlock(&self, i: usize) -> Option<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token ELSEIF in current rule
	fn ELSEIF_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ELSEIF, starting from 0.
	/// Returns `None` if number of children corresponding to token ELSEIF is less or equal than `i`.
	fn ELSEIF(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ELSEIF, i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
}

impl<'input> IfContextAttrs<'input> for IfContext<'input>{}

pub struct IfContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IfContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for IfContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IfContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_if(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_if(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IfContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_if(self);
	}
}

impl<'input> CustomRuleContext<'input> for IfContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for IfContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for IfContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for IfContext<'input> {}

impl<'input> IfContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::IfContext(
				BaseParserRuleContext::copy_from(ctx,IfContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowColumnsContext<'input> = BaseParserRuleContext<'input,ShowColumnsContextExt<'input>>;

pub trait ShowColumnsContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
}

impl<'input> ShowColumnsContextAttrs<'input> for ShowColumnsContext<'input>{}

pub struct ShowColumnsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowColumnsContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ShowColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ShowColumnsContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showColumns(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_showColumns(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ShowColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_showColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowColumnsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowColumnsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowColumnsContext<'input> {}

impl<'input> ShowColumnsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowColumnsContext(
				BaseParserRuleContext::copy_from(ctx,ShowColumnsContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CaseContext<'input> = BaseParserRuleContext<'input,CaseContextExt<'input>>;

pub trait CaseContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token CASE in current rule
	fn CASE_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token CASE, starting from 0.
	/// Returns `None` if number of children corresponding to token CASE is less or equal than `i`.
	fn CASE(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CASE, i)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token WHEN in current rule
	fn WHEN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token WHEN, starting from 0.
	/// Returns `None` if number of children corresponding to token WHEN is less or equal than `i`.
	fn WHEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WHEN, i)
	}
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token THEN in current rule
	fn THEN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token THEN, starting from 0.
	/// Returns `None` if number of children corresponding to token THEN is less or equal than `i`.
	fn THEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(THEN, i)
	}
	fn statementBlock_all(&self) ->  Vec<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn statementBlock(&self, i: usize) -> Option<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
}

impl<'input> CaseContextAttrs<'input> for CaseContext<'input>{}

pub struct CaseContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CaseContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CaseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CaseContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_case(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_case(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_case(self);
	}
}

impl<'input> CustomRuleContext<'input> for CaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CaseContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CaseContext<'input> {}

impl<'input> CaseContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CaseContext(
				BaseParserRuleContext::copy_from(ctx,CaseContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ForInContext<'input> = BaseParserRuleContext<'input,ForInContextExt<'input>>;

pub trait ForInContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token FOR in current rule
	fn FOR_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token FOR, starting from 0.
	/// Returns `None` if number of children corresponding to token FOR is less or equal than `i`.
	fn FOR(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FOR, i)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DO
	/// Returns `None` if there is no child corresponding to token DO
	fn DO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DO, 0)
	}
	fn statementBlock(&self) -> Option<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
}

impl<'input> ForInContextAttrs<'input> for ForInContext<'input>{}

pub struct ForInContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ForInContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ForInContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ForInContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_forIn(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_forIn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ForInContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_forIn(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForInContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ForInContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ForInContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ForInContext<'input> {}

impl<'input> ForInContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ForInContext(
				BaseParserRuleContext::copy_from(ctx,ForInContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AddColumnContext<'input> = BaseParserRuleContext<'input,AddColumnContextExt<'input>>;

pub trait AddColumnContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ADD
	/// Returns `None` if there is no child corresponding to token ADD
	fn ADD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn columnDefinition(&self) -> Option<Rc<ColumnDefinitionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> AddColumnContextAttrs<'input> for AddColumnContext<'input>{}

pub struct AddColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub column: Option<Rc<ColumnDefinitionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AddColumnContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for AddColumnContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for AddColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_addColumn(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_addColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for AddColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_addColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for AddColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AddColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AddColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AddColumnContext<'input> {}

impl<'input> AddColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AddColumnContext(
				BaseParserRuleContext::copy_from(ctx,AddColumnContextExt{
        			tableName:None, column:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DenyContext<'input> = BaseParserRuleContext<'input,DenyContextExt<'input>>;

pub trait DenyContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DENY
	/// Returns `None` if there is no child corresponding to token DENY
	fn DENY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DENY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn privilege_all(&self) ->  Vec<Rc<PrivilegeContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn privilege(&self, i: usize) -> Option<Rc<PrivilegeContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ALL
	/// Returns `None` if there is no child corresponding to token ALL
	fn ALL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PRIVILEGES
	/// Returns `None` if there is no child corresponding to token PRIVILEGES
	fn PRIVILEGES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PRIVILEGES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> DenyContextAttrs<'input> for DenyContext<'input>{}

pub struct DenyContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	pub grantee: Option<Rc<PrincipalContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DenyContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DenyContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DenyContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_deny(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_deny(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DenyContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_deny(self);
	}
}

impl<'input> CustomRuleContext<'input> for DenyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DenyContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DenyContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DenyContext<'input> {}

impl<'input> DenyContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DenyContext(
				BaseParserRuleContext::copy_from(ctx,DenyContextExt{
					tail:None, 
        			grantee:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertIntoContext<'input> = BaseParserRuleContext<'input,InsertIntoContextExt<'input>>;

pub trait InsertIntoContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn maybeDashedPathExpression(&self) -> Option<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InsertIntoContextAttrs<'input> for InsertIntoContext<'input>{}

pub struct InsertIntoContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertIntoContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for InsertIntoContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for InsertIntoContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertInto(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_insertInto(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for InsertIntoContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_insertInto(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertIntoContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for InsertIntoContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for InsertIntoContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for InsertIntoContext<'input> {}

impl<'input> InsertIntoContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::InsertIntoContext(
				BaseParserRuleContext::copy_from(ctx,InsertIntoContextExt{
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateSchemaContext<'input> = BaseParserRuleContext<'input,CreateSchemaContextExt<'input>>;

pub trait CreateSchemaContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateSchemaContextAttrs<'input> for CreateSchemaContext<'input>{}

pub struct CreateSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateSchemaContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CreateSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CreateSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createSchema(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_createSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CreateSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_createSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateSchemaContext<'input> {}

impl<'input> CreateSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateSchemaContext(
				BaseParserRuleContext::copy_from(ctx,CreateSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExecuteContext<'input> = BaseParserRuleContext<'input,ExecuteContextExt<'input>>;

pub trait ExecuteContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXECUTE
	/// Returns `None` if there is no child corresponding to token EXECUTE
	fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXECUTE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ExecuteContextAttrs<'input> for ExecuteContext<'input>{}

pub struct ExecuteContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExecuteContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ExecuteContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ExecuteContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_execute(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_execute(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ExecuteContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_execute(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExecuteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ExecuteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ExecuteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ExecuteContext<'input> {}

impl<'input> ExecuteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ExecuteContext(
				BaseParserRuleContext::copy_from(ctx,ExecuteContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateJSFunctionContext<'input> = BaseParserRuleContext<'input,CreateJSFunctionContextExt<'input>>;

pub trait CreateJSFunctionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNS
	/// Returns `None` if there is no child corresponding to token RETURNS
	fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RETURNS, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LANGUAGE
	/// Returns `None` if there is no child corresponding to token LANGUAGE
	fn LANGUAGE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LANGUAGE, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token NOT in current rule
	fn NOT_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token NOT, starting from 0.
	/// Returns `None` if number of children corresponding to token NOT is less or equal than `i`.
	fn NOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, i)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn namedParameter_all(&self) ->  Vec<Rc<NamedParameterContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn namedParameter(&self, i: usize) -> Option<Rc<NamedParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token DETERMINISTIC
	/// Returns `None` if there is no child corresponding to token DETERMINISTIC
	fn DETERMINISTIC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DETERMINISTIC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMP
	/// Returns `None` if there is no child corresponding to token TEMP
	fn TEMP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TEMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn columnOptionList(&self) -> Option<Rc<ColumnOptionListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CreateJSFunctionContextAttrs<'input> for CreateJSFunctionContext<'input>{}

pub struct CreateJSFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub name: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	pub body: Option<Rc<StringContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateJSFunctionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CreateJSFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CreateJSFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createJSFunction(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_createJSFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CreateJSFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_createJSFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateJSFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateJSFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateJSFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateJSFunctionContext<'input> {}

impl<'input> CreateJSFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateJSFunctionContext(
				BaseParserRuleContext::copy_from(ctx,CreateJSFunctionContextExt{
					tail:None, 
        			name:None, body:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameSchemaContext<'input> = BaseParserRuleContext<'input,RenameSchemaContextExt<'input>>;

pub trait RenameSchemaContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RenameSchemaContextAttrs<'input> for RenameSchemaContext<'input>{}

pub struct RenameSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameSchemaContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RenameSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RenameSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameSchema(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_renameSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RenameSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_renameSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameSchemaContext<'input> {}

impl<'input> RenameSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameSchemaContext(
				BaseParserRuleContext::copy_from(ctx,RenameSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BeginTransactionContext<'input> = BaseParserRuleContext<'input,BeginTransactionContextExt<'input>>;

pub trait BeginTransactionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BEGIN
	/// Returns `None` if there is no child corresponding to token BEGIN
	fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BEGIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRANSACTION
	/// Returns `None` if there is no child corresponding to token TRANSACTION
	fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRANSACTION, 0)
	}
}

impl<'input> BeginTransactionContextAttrs<'input> for BeginTransactionContext<'input>{}

pub struct BeginTransactionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BeginTransactionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BeginTransactionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BeginTransactionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_beginTransaction(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_beginTransaction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BeginTransactionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_beginTransaction(self);
	}
}

impl<'input> CustomRuleContext<'input> for BeginTransactionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BeginTransactionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BeginTransactionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BeginTransactionContext<'input> {}

impl<'input> BeginTransactionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BeginTransactionContext(
				BaseParserRuleContext::copy_from(ctx,BeginTransactionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommitTransactionContext<'input> = BaseParserRuleContext<'input,CommitTransactionContextExt<'input>>;

pub trait CommitTransactionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMIT
	/// Returns `None` if there is no child corresponding to token COMMIT
	fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMIT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRANSACTION
	/// Returns `None` if there is no child corresponding to token TRANSACTION
	fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRANSACTION, 0)
	}
}

impl<'input> CommitTransactionContextAttrs<'input> for CommitTransactionContext<'input>{}

pub struct CommitTransactionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommitTransactionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CommitTransactionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CommitTransactionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_commitTransaction(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_commitTransaction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CommitTransactionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_commitTransaction(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommitTransactionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommitTransactionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommitTransactionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommitTransactionContext<'input> {}

impl<'input> CommitTransactionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommitTransactionContext(
				BaseParserRuleContext::copy_from(ctx,CommitTransactionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AnalyzeContext<'input> = BaseParserRuleContext<'input,AnalyzeContextExt<'input>>;

pub trait AnalyzeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ANALYZE
	/// Returns `None` if there is no child corresponding to token ANALYZE
	fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ANALYZE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> AnalyzeContextAttrs<'input> for AnalyzeContext<'input>{}

pub struct AnalyzeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AnalyzeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for AnalyzeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for AnalyzeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_analyze(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_analyze(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for AnalyzeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_analyze(self);
	}
}

impl<'input> CustomRuleContext<'input> for AnalyzeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AnalyzeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AnalyzeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AnalyzeContext<'input> {}

impl<'input> AnalyzeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AnalyzeContext(
				BaseParserRuleContext::copy_from(ctx,AnalyzeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ResetContext<'input> = BaseParserRuleContext<'input,ResetContextExt<'input>>;

pub trait ResetContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RESET
	/// Returns `None` if there is no child corresponding to token RESET
	fn RESET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RESET, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ResetContextAttrs<'input> for ResetContext<'input>{}

pub struct ResetContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ResetContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ResetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ResetContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_reset(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_reset(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ResetContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_reset(self);
	}
}

impl<'input> CustomRuleContext<'input> for ResetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ResetContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ResetContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ResetContext<'input> {}

impl<'input> ResetContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ResetContext(
				BaseParserRuleContext::copy_from(ctx,ResetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateSnapshotTableContext<'input> = BaseParserRuleContext<'input,CreateSnapshotTableContextExt<'input>>;

pub trait CreateSnapshotTableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SNAPSHOT
	/// Returns `None` if there is no child corresponding to token SNAPSHOT
	fn SNAPSHOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SNAPSHOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CLONE
	/// Returns `None` if there is no child corresponding to token CLONE
	fn CLONE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CLONE, 0)
	}
	fn maybeDashedPathExpression_all(&self) ->  Vec<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn maybeDashedPathExpression(&self, i: usize) -> Option<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
	/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
	fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SYSTEM_TIME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OF
	/// Returns `None` if there is no child corresponding to token OF
	fn OF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OF, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CreateSnapshotTableContextAttrs<'input> for CreateSnapshotTableContext<'input>{}

pub struct CreateSnapshotTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	pub source: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateSnapshotTableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CreateSnapshotTableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CreateSnapshotTableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createSnapshotTable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_createSnapshotTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CreateSnapshotTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_createSnapshotTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateSnapshotTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateSnapshotTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateSnapshotTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateSnapshotTableContext<'input> {}

impl<'input> CreateSnapshotTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateSnapshotTableContext(
				BaseParserRuleContext::copy_from(ctx,CreateSnapshotTableContextExt{
        			dest:None, source:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropSchemaContext<'input> = BaseParserRuleContext<'input,DropSchemaContextExt<'input>>;

pub trait DropSchemaContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DropSchemaContextAttrs<'input> for DropSchemaContext<'input>{}

pub struct DropSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropSchemaContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DropSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DropSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropSchema(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_dropSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DropSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dropSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropSchemaContext<'input> {}

impl<'input> DropSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropSchemaContext(
				BaseParserRuleContext::copy_from(ctx,DropSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BeginContext<'input> = BaseParserRuleContext<'input,BeginContextExt<'input>>;

pub trait BeginContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BEGIN
	/// Returns `None` if there is no child corresponding to token BEGIN
	fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BEGIN, 0)
	}
	fn statementBlock(&self) -> Option<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
}

impl<'input> BeginContextAttrs<'input> for BeginContext<'input>{}

pub struct BeginContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BeginContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BeginContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BeginContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_begin(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_begin(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BeginContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_begin(self);
	}
}

impl<'input> CustomRuleContext<'input> for BeginContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BeginContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BeginContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BeginContext<'input> {}

impl<'input> BeginContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BeginContext(
				BaseParserRuleContext::copy_from(ctx,BeginContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTableAuthorizationContext<'input> = BaseParserRuleContext<'input,SetTableAuthorizationContextExt<'input>>;

pub trait SetTableAuthorizationContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTableAuthorizationContextAttrs<'input> for SetTableAuthorizationContext<'input>{}

pub struct SetTableAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTableAuthorizationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SetTableAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetTableAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_setTableAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetTableAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setTableAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTableAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTableAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTableAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTableAuthorizationContext<'input> {}

impl<'input> SetTableAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTableAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetTableAuthorizationContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropContext<'input> = BaseParserRuleContext<'input,DropContextExt<'input>>;

pub trait DropContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DropContextAttrs<'input> for DropContext<'input>{}

pub struct DropContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DropContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DropContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_drop(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_drop(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DropContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_drop(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropContext<'input> {}

impl<'input> DropContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropContext(
				BaseParserRuleContext::copy_from(ctx,DropContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StartTransactionContext<'input> = BaseParserRuleContext<'input,StartTransactionContextExt<'input>>;

pub trait StartTransactionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token START
	/// Returns `None` if there is no child corresponding to token START
	fn START(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(START, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRANSACTION
	/// Returns `None` if there is no child corresponding to token TRANSACTION
	fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRANSACTION, 0)
	}
	fn transactionMode_all(&self) ->  Vec<Rc<TransactionModeContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn transactionMode(&self, i: usize) -> Option<Rc<TransactionModeContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> StartTransactionContextAttrs<'input> for StartTransactionContext<'input>{}

pub struct StartTransactionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StartTransactionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for StartTransactionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StartTransactionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_startTransaction(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_startTransaction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StartTransactionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_startTransaction(self);
	}
}

impl<'input> CustomRuleContext<'input> for StartTransactionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for StartTransactionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for StartTransactionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for StartTransactionContext<'input> {}

impl<'input> StartTransactionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::StartTransactionContext(
				BaseParserRuleContext::copy_from(ctx,StartTransactionContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigqueryCreateModelContext<'input> = BaseParserRuleContext<'input,BigqueryCreateModelContextExt<'input>>;

pub trait BigqueryCreateModelContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MODEL
	/// Returns `None` if there is no child corresponding to token MODEL
	fn MODEL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MODEL, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token AS in current rule
	fn AS_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token AS, starting from 0.
	/// Returns `None` if number of children corresponding to token AS is less or equal than `i`.
	fn AS(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, i)
	}
	fn maybeDashedPathExpression(&self) -> Option<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TRAINING_DATA
	/// Returns `None` if there is no child corresponding to token TRAINING_DATA
	fn TRAINING_DATA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRAINING_DATA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CUSTOM_HOLIDAY
	/// Returns `None` if there is no child corresponding to token CUSTOM_HOLIDAY
	fn CUSTOM_HOLIDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CUSTOM_HOLIDAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRANSFORM
	/// Returns `None` if there is no child corresponding to token TRANSFORM
	fn TRANSFORM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRANSFORM, 0)
	}
	fn querySelectItems(&self) -> Option<Rc<QuerySelectItemsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token INPUT
	/// Returns `None` if there is no child corresponding to token INPUT
	fn INPUT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INPUT, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn type__all(&self) ->  Vec<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn type_(&self, i: usize) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OUTPUT
	/// Returns `None` if there is no child corresponding to token OUTPUT
	fn OUTPUT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OUTPUT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REMOTE
	/// Returns `None` if there is no child corresponding to token REMOTE
	fn REMOTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REMOTE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CONNECTION
	/// Returns `None` if there is no child corresponding to token CONNECTION
	fn CONNECTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CONNECTION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> BigqueryCreateModelContextAttrs<'input> for BigqueryCreateModelContext<'input>{}

pub struct BigqueryCreateModelContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigqueryCreateModelContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BigqueryCreateModelContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BigqueryCreateModelContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigqueryCreateModel(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_bigqueryCreateModel(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BigqueryCreateModelContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_bigqueryCreateModel(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigqueryCreateModelContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BigqueryCreateModelContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BigqueryCreateModelContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BigqueryCreateModelContext<'input> {}

impl<'input> BigqueryCreateModelContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BigqueryCreateModelContext(
				BaseParserRuleContext::copy_from(ctx,BigqueryCreateModelContextExt{
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowContext<'input> = BaseParserRuleContext<'input,ShowContextExt<'input>>;

pub trait ShowContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ShowContextAttrs<'input> for ShowContext<'input>{}

pub struct ShowContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ShowContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ShowContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_show(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_show(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ShowContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_show(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowContext<'input> {}

impl<'input> ShowContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowContext(
				BaseParserRuleContext::copy_from(ctx,ShowContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RevokeContext<'input> = BaseParserRuleContext<'input,RevokeContextExt<'input>>;

pub trait RevokeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REVOKE
	/// Returns `None` if there is no child corresponding to token REVOKE
	fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REVOKE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> RevokeContextAttrs<'input> for RevokeContext<'input>{}

pub struct RevokeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RevokeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RevokeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RevokeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_revoke(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_revoke(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RevokeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_revoke(self);
	}
}

impl<'input> CustomRuleContext<'input> for RevokeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RevokeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RevokeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RevokeContext<'input> {}

impl<'input> RevokeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RevokeContext(
				BaseParserRuleContext::copy_from(ctx,RevokeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UpdateContext<'input> = BaseParserRuleContext<'input,UpdateContextExt<'input>>;

pub trait UpdateContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UPDATE
	/// Returns `None` if there is no child corresponding to token UPDATE
	fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(UPDATE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> UpdateContextAttrs<'input> for UpdateContext<'input>{}

pub struct UpdateContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UpdateContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UpdateContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UpdateContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_update(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_update(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UpdateContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_update(self);
	}
}

impl<'input> CustomRuleContext<'input> for UpdateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UpdateContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UpdateContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UpdateContext<'input> {}

impl<'input> UpdateContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UpdateContext(
				BaseParserRuleContext::copy_from(ctx,UpdateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableExecuteContext<'input> = BaseParserRuleContext<'input,TableExecuteContextExt<'input>>;

pub trait TableExecuteContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXECUTE
	/// Returns `None` if there is no child corresponding to token EXECUTE
	fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXECUTE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WHERE
	/// Returns `None` if there is no child corresponding to token WHERE
	fn WHERE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WHERE, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> TableExecuteContextAttrs<'input> for TableExecuteContext<'input>{}

pub struct TableExecuteContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub procedureName: Option<Rc<IdentifierContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	pub where_: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableExecuteContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TableExecuteContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableExecuteContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableExecute(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_tableExecute(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableExecuteContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableExecute(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableExecuteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for TableExecuteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for TableExecuteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for TableExecuteContext<'input> {}

impl<'input> TableExecuteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::TableExecuteContext(
				BaseParserRuleContext::copy_from(ctx,TableExecuteContextExt{
					tail:None, 
        			tableName:None, procedureName:None, where_:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DeleteContext<'input> = BaseParserRuleContext<'input,DeleteContextExt<'input>>;

pub trait DeleteContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DELETE
	/// Returns `None` if there is no child corresponding to token DELETE
	fn DELETE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DELETE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DeleteContextAttrs<'input> for DeleteContext<'input>{}

pub struct DeleteContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeleteContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DeleteContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DeleteContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_delete(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_delete(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DeleteContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_delete(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeleteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DeleteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DeleteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DeleteContext<'input> {}

impl<'input> DeleteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DeleteContext(
				BaseParserRuleContext::copy_from(ctx,DeleteContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeInputContext<'input> = BaseParserRuleContext<'input,DescribeInputContextExt<'input>>;

pub trait DescribeInputContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INPUT
	/// Returns `None` if there is no child corresponding to token INPUT
	fn INPUT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INPUT, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DescribeInputContextAttrs<'input> for DescribeInputContext<'input>{}

pub struct DescribeInputContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeInputContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DescribeInputContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DescribeInputContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeInput(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_describeInput(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DescribeInputContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_describeInput(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeInputContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeInputContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeInputContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeInputContext<'input> {}

impl<'input> DescribeInputContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeInputContext(
				BaseParserRuleContext::copy_from(ctx,DescribeInputContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigqueryCreateMaterializedViewContext<'input> = BaseParserRuleContext<'input,BigqueryCreateMaterializedViewContextExt<'input>>;

pub trait BigqueryCreateMaterializedViewContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn maybeDashedPathExpression(&self) -> Option<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token CLUSTER
	/// Returns `None` if there is no child corresponding to token CLUSTER
	fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CLUSTER, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> BigqueryCreateMaterializedViewContextAttrs<'input> for BigqueryCreateMaterializedViewContext<'input>{}

pub struct BigqueryCreateMaterializedViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigqueryCreateMaterializedViewContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BigqueryCreateMaterializedViewContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BigqueryCreateMaterializedViewContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigqueryCreateMaterializedView(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_bigqueryCreateMaterializedView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BigqueryCreateMaterializedViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_bigqueryCreateMaterializedView(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigqueryCreateMaterializedViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BigqueryCreateMaterializedViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BigqueryCreateMaterializedViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BigqueryCreateMaterializedViewContext<'input> {}

impl<'input> BigqueryCreateMaterializedViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BigqueryCreateMaterializedViewContext(
				BaseParserRuleContext::copy_from(ctx,BigqueryCreateMaterializedViewContextExt{
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetColumnTypeContext<'input> = BaseParserRuleContext<'input,SetColumnTypeContextExt<'input>>;

pub trait SetColumnTypeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token ALTER in current rule
	fn ALTER_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ALTER, starting from 0.
	/// Returns `None` if number of children corresponding to token ALTER is less or equal than `i`.
	fn ALTER(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, i)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATA
	/// Returns `None` if there is no child corresponding to token DATA
	fn DATA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DATA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TYPE
	/// Returns `None` if there is no child corresponding to token TYPE
	fn TYPE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TYPE, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> SetColumnTypeContextAttrs<'input> for SetColumnTypeContext<'input>{}

pub struct SetColumnTypeContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub setColumnName: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetColumnTypeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SetColumnTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetColumnTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setColumnType(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_setColumnType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetColumnTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setColumnType(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetColumnTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetColumnTypeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetColumnTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetColumnTypeContext<'input> {}

impl<'input> SetColumnTypeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetColumnTypeContext(
				BaseParserRuleContext::copy_from(ctx,SetColumnTypeContextExt{
        			tableName:None, setColumnName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StatementDefaultContext<'input> = BaseParserRuleContext<'input,StatementDefaultContextExt<'input>>;

pub trait StatementDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StatementDefaultContextAttrs<'input> for StatementDefaultContext<'input>{}

pub struct StatementDefaultContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StatementDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for StatementDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StatementDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_statementDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_statementDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StatementDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_statementDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for StatementDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for StatementDefaultContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for StatementDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for StatementDefaultContext<'input> {}

impl<'input> StatementDefaultContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::StatementDefaultContext(
				BaseParserRuleContext::copy_from(ctx,StatementDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RepeatContext<'input> = BaseParserRuleContext<'input,RepeatContextExt<'input>>;

pub trait RepeatContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token REPEAT in current rule
	fn REPEAT_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token REPEAT, starting from 0.
	/// Returns `None` if number of children corresponding to token REPEAT is less or equal than `i`.
	fn REPEAT(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPEAT, i)
	}
	fn statementBlock(&self) -> Option<Rc<StatementBlockContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token UNTIL
	/// Returns `None` if there is no child corresponding to token UNTIL
	fn UNTIL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(UNTIL, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
}

impl<'input> RepeatContextAttrs<'input> for RepeatContext<'input>{}

pub struct RepeatContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RepeatContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RepeatContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RepeatContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_repeat(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_repeat(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RepeatContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_repeat(self);
	}
}

impl<'input> CustomRuleContext<'input> for RepeatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RepeatContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RepeatContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RepeatContext<'input> {}

impl<'input> RepeatContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RepeatContext(
				BaseParserRuleContext::copy_from(ctx,RepeatContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TruncateTableContext<'input> = BaseParserRuleContext<'input,TruncateTableContextExt<'input>>;

pub trait TruncateTableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRUNCATE
	/// Returns `None` if there is no child corresponding to token TRUNCATE
	fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRUNCATE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> TruncateTableContextAttrs<'input> for TruncateTableContext<'input>{}

pub struct TruncateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TruncateTableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TruncateTableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TruncateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_truncateTable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_truncateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TruncateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_truncateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for TruncateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for TruncateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for TruncateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for TruncateTableContext<'input> {}

impl<'input> TruncateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::TruncateTableContext(
				BaseParserRuleContext::copy_from(ctx,TruncateTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameMaterializedViewContext<'input> = BaseParserRuleContext<'input,RenameMaterializedViewContextExt<'input>>;

pub trait RenameMaterializedViewContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> RenameMaterializedViewContextAttrs<'input> for RenameMaterializedViewContext<'input>{}

pub struct RenameMaterializedViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub to: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameMaterializedViewContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RenameMaterializedViewContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RenameMaterializedViewContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameMaterializedView(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_renameMaterializedView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RenameMaterializedViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_renameMaterializedView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameMaterializedViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameMaterializedViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameMaterializedViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameMaterializedViewContext<'input> {}

impl<'input> RenameMaterializedViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameMaterializedViewContext(
				BaseParserRuleContext::copy_from(ctx,RenameMaterializedViewContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropTableContext<'input> = BaseParserRuleContext<'input,DropTableContextExt<'input>>;

pub trait DropTableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DropTableContextAttrs<'input> for DropTableContext<'input>{}

pub struct DropTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropTableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DropTableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DropTableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropTable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_dropTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DropTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dropTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropTableContext<'input> {}

impl<'input> DropTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropTableContext(
				BaseParserRuleContext::copy_from(ctx,DropTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateRemoteFunctionContext<'input> = BaseParserRuleContext<'input,CreateRemoteFunctionContextExt<'input>>;

pub trait CreateRemoteFunctionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNS
	/// Returns `None` if there is no child corresponding to token RETURNS
	fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RETURNS, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token REMOTE
	/// Returns `None` if there is no child corresponding to token REMOTE
	fn REMOTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REMOTE, 0)
	}
	fn connectionSpec(&self) -> Option<Rc<ConnectionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn namedParameter_all(&self) ->  Vec<Rc<NamedParameterContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn namedParameter(&self, i: usize) -> Option<Rc<NamedParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn columnOptionList(&self) -> Option<Rc<ColumnOptionListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> CreateRemoteFunctionContextAttrs<'input> for CreateRemoteFunctionContext<'input>{}

pub struct CreateRemoteFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub name: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateRemoteFunctionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CreateRemoteFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CreateRemoteFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createRemoteFunction(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_createRemoteFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CreateRemoteFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_createRemoteFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateRemoteFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateRemoteFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateRemoteFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateRemoteFunctionContext<'input> {}

impl<'input> CreateRemoteFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateRemoteFunctionContext(
				BaseParserRuleContext::copy_from(ctx,CreateRemoteFunctionContextExt{
					tail:None, 
        			name:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetSchemaAuthorizationContext<'input> = BaseParserRuleContext<'input,SetSchemaAuthorizationContextExt<'input>>;

pub trait SetSchemaAuthorizationContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetSchemaAuthorizationContextAttrs<'input> for SetSchemaAuthorizationContext<'input>{}

pub struct SetSchemaAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetSchemaAuthorizationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SetSchemaAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetSchemaAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setSchemaAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_setSchemaAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetSchemaAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setSchemaAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetSchemaAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetSchemaAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetSchemaAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetSchemaAuthorizationContext<'input> {}

impl<'input> SetSchemaAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetSchemaAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetSchemaAuthorizationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RollbackContext<'input> = BaseParserRuleContext<'input,RollbackContextExt<'input>>;

pub trait RollbackContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLLBACK
	/// Returns `None` if there is no child corresponding to token ROLLBACK
	fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ROLLBACK, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> RollbackContextAttrs<'input> for RollbackContext<'input>{}

pub struct RollbackContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RollbackContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RollbackContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RollbackContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rollback(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_rollback(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RollbackContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rollback(self);
	}
}

impl<'input> CustomRuleContext<'input> for RollbackContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RollbackContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RollbackContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RollbackContext<'input> {}

impl<'input> RollbackContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RollbackContext(
				BaseParserRuleContext::copy_from(ctx,RollbackContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetContext<'input> = BaseParserRuleContext<'input,SetContextExt<'input>>;

pub trait SetContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> SetContextAttrs<'input> for SetContext<'input>{}

pub struct SetContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_set(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_set(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_set(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetContext<'input> {}

impl<'input> SetContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetContext(
				BaseParserRuleContext::copy_from(ctx,SetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateSqlFunctionContext<'input> = BaseParserRuleContext<'input,CreateSqlFunctionContextExt<'input>>;

pub trait CreateSqlFunctionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn namedParameter_all(&self) ->  Vec<Rc<NamedParameterContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn namedParameter(&self, i: usize) -> Option<Rc<NamedParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNS
	/// Returns `None` if there is no child corresponding to token RETURNS
	fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RETURNS, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn columnOptionList(&self) -> Option<Rc<ColumnOptionListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMP
	/// Returns `None` if there is no child corresponding to token TEMP
	fn TEMP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TEMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> CreateSqlFunctionContextAttrs<'input> for CreateSqlFunctionContext<'input>{}

pub struct CreateSqlFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub name: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	pub body: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateSqlFunctionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CreateSqlFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CreateSqlFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createSqlFunction(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_createSqlFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CreateSqlFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_createSqlFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateSqlFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateSqlFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateSqlFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateSqlFunctionContext<'input> {}

impl<'input> CreateSqlFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateSqlFunctionContext(
				BaseParserRuleContext::copy_from(ctx,CreateSqlFunctionContextExt{
					tail:None, 
        			name:None, body:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BreakContext<'input> = BaseParserRuleContext<'input,BreakContextExt<'input>>;

pub trait BreakContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BREAK
	/// Returns `None` if there is no child corresponding to token BREAK
	fn BREAK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BREAK, 0)
	}
}

impl<'input> BreakContextAttrs<'input> for BreakContext<'input>{}

pub struct BreakContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BreakContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BreakContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BreakContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_break(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_break(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BreakContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_break(self);
	}
}

impl<'input> CustomRuleContext<'input> for BreakContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BreakContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BreakContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BreakContext<'input> {}

impl<'input> BreakContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BreakContext(
				BaseParserRuleContext::copy_from(ctx,BreakContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigqueryCreateExternalTableContext<'input> = BaseParserRuleContext<'input,BigqueryCreateExternalTableContextExt<'input>>;

pub trait BigqueryCreateExternalTableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTERNAL
	/// Returns `None` if there is no child corresponding to token EXTERNAL
	fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXTERNAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn maybeDashedPathExpression(&self) -> Option<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn tableElements(&self) -> Option<Rc<TableElementsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn connectionSpec(&self) -> Option<Rc<ConnectionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	fn partitionColumns(&self) -> Option<Rc<PartitionColumnsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
}

impl<'input> BigqueryCreateExternalTableContextAttrs<'input> for BigqueryCreateExternalTableContext<'input>{}

pub struct BigqueryCreateExternalTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigqueryCreateExternalTableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BigqueryCreateExternalTableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BigqueryCreateExternalTableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigqueryCreateExternalTable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_bigqueryCreateExternalTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BigqueryCreateExternalTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_bigqueryCreateExternalTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigqueryCreateExternalTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BigqueryCreateExternalTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BigqueryCreateExternalTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BigqueryCreateExternalTableContext<'input> {}

impl<'input> BigqueryCreateExternalTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BigqueryCreateExternalTableContext(
				BaseParserRuleContext::copy_from(ctx,BigqueryCreateExternalTableContextExt{
					COMMA:None, 
        			tail:Vec::new(), 
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExecuteImmediateContext<'input> = BaseParserRuleContext<'input,ExecuteImmediateContextExt<'input>>;

pub trait ExecuteImmediateContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXECUTE
	/// Returns `None` if there is no child corresponding to token EXECUTE
	fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXECUTE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IMMEDIATE
	/// Returns `None` if there is no child corresponding to token IMMEDIATE
	fn IMMEDIATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IMMEDIATE, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token USING
	/// Returns `None` if there is no child corresponding to token USING
	fn USING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(USING, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ExecuteImmediateContextAttrs<'input> for ExecuteImmediateContext<'input>{}

pub struct ExecuteImmediateContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExecuteImmediateContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ExecuteImmediateContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ExecuteImmediateContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_executeImmediate(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_executeImmediate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ExecuteImmediateContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_executeImmediate(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExecuteImmediateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ExecuteImmediateContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ExecuteImmediateContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ExecuteImmediateContext<'input> {}

impl<'input> ExecuteImmediateContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ExecuteImmediateContext(
				BaseParserRuleContext::copy_from(ctx,ExecuteImmediateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigqueryCreateViewContext<'input> = BaseParserRuleContext<'input,BigqueryCreateViewContextExt<'input>>;

pub trait BigqueryCreateViewContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn maybeDashedPathExpression(&self) -> Option<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> BigqueryCreateViewContextAttrs<'input> for BigqueryCreateViewContext<'input>{}

pub struct BigqueryCreateViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigqueryCreateViewContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BigqueryCreateViewContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BigqueryCreateViewContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigqueryCreateView(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_bigqueryCreateView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BigqueryCreateViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_bigqueryCreateView(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigqueryCreateViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BigqueryCreateViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BigqueryCreateViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BigqueryCreateViewContext<'input> {}

impl<'input> BigqueryCreateViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BigqueryCreateViewContext(
				BaseParserRuleContext::copy_from(ctx,BigqueryCreateViewContextExt{
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameViewContext<'input> = BaseParserRuleContext<'input,RenameViewContextExt<'input>>;

pub trait RenameViewContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> RenameViewContextAttrs<'input> for RenameViewContext<'input>{}

pub struct RenameViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub to: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameViewContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RenameViewContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RenameViewContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameView(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_renameView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RenameViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_renameView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameViewContext<'input> {}

impl<'input> RenameViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameViewContext(
				BaseParserRuleContext::copy_from(ctx,RenameViewContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CallContext<'input> = BaseParserRuleContext<'input,CallContextExt<'input>>;

pub trait CallContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CALL
	/// Returns `None` if there is no child corresponding to token CALL
	fn CALL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CALL, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CallContextAttrs<'input> for CallContext<'input>{}

pub struct CallContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CallContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CallContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CallContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_call(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_call(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CallContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_call(self);
	}
}

impl<'input> CustomRuleContext<'input> for CallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CallContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CallContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CallContext<'input> {}

impl<'input> CallContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CallContext(
				BaseParserRuleContext::copy_from(ctx,CallContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RefreshMaterializedViewContext<'input> = BaseParserRuleContext<'input,RefreshMaterializedViewContextExt<'input>>;

pub trait RefreshMaterializedViewContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REFRESH
	/// Returns `None` if there is no child corresponding to token REFRESH
	fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REFRESH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RefreshMaterializedViewContextAttrs<'input> for RefreshMaterializedViewContext<'input>{}

pub struct RefreshMaterializedViewContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RefreshMaterializedViewContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RefreshMaterializedViewContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RefreshMaterializedViewContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_refreshMaterializedView(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_refreshMaterializedView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RefreshMaterializedViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_refreshMaterializedView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RefreshMaterializedViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RefreshMaterializedViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RefreshMaterializedViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RefreshMaterializedViewContext<'input> {}

impl<'input> RefreshMaterializedViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RefreshMaterializedViewContext(
				BaseParserRuleContext::copy_from(ctx,RefreshMaterializedViewContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigqueryCreateTableContext<'input> = BaseParserRuleContext<'input,BigqueryCreateTableContextExt<'input>>;

pub trait BigqueryCreateTableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn maybeDashedPathExpression_all(&self) ->  Vec<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn maybeDashedPathExpression(&self, i: usize) -> Option<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn tableElements(&self) -> Option<Rc<TableElementsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DEFAULT
	/// Returns `None` if there is no child corresponding to token DEFAULT
	fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DEFAULT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLLATE
	/// Returns `None` if there is no child corresponding to token COLLATE
	fn COLLATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COLLATE, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token CLUSTER
	/// Returns `None` if there is no child corresponding to token CLUSTER
	fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CLUSTER, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token AS in current rule
	fn AS_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token AS, starting from 0.
	/// Returns `None` if number of children corresponding to token AS is less or equal than `i`.
	fn AS(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, i)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMP
	/// Returns `None` if there is no child corresponding to token TEMP
	fn TEMP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TEMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CLONE
	/// Returns `None` if there is no child corresponding to token CLONE
	fn CLONE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CLONE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COPY
	/// Returns `None` if there is no child corresponding to token COPY
	fn COPY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COPY, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
	/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
	fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SYSTEM_TIME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OF
	/// Returns `None` if there is no child corresponding to token OF
	fn OF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OF, 0)
	}
}

impl<'input> BigqueryCreateTableContextAttrs<'input> for BigqueryCreateTableContext<'input>{}

pub struct BigqueryCreateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	pub source: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigqueryCreateTableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BigqueryCreateTableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BigqueryCreateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigqueryCreateTable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_bigqueryCreateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BigqueryCreateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_bigqueryCreateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigqueryCreateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for BigqueryCreateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for BigqueryCreateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for BigqueryCreateTableContext<'input> {}

impl<'input> BigqueryCreateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::BigqueryCreateTableContext(
				BaseParserRuleContext::copy_from(ctx,BigqueryCreateTableContextExt{
					tail:None, 
        			dest:None, source:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommentContext<'input> = BaseParserRuleContext<'input,CommentContextExt<'input>>;

pub trait CommentContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMENT
	/// Returns `None` if there is no child corresponding to token COMMENT
	fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMENT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CommentContextAttrs<'input> for CommentContext<'input>{}

pub struct CommentContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommentContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CommentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CommentContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_comment(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_comment(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CommentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_comment(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommentContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommentContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommentContext<'input> {}

impl<'input> CommentContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommentContext(
				BaseParserRuleContext::copy_from(ctx,CommentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeOutputContext<'input> = BaseParserRuleContext<'input,DescribeOutputContextExt<'input>>;

pub trait DescribeOutputContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OUTPUT
	/// Returns `None` if there is no child corresponding to token OUTPUT
	fn OUTPUT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OUTPUT, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DescribeOutputContextAttrs<'input> for DescribeOutputContext<'input>{}

pub struct DescribeOutputContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeOutputContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DescribeOutputContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DescribeOutputContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeOutput(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_describeOutput(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DescribeOutputContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_describeOutput(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeOutputContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeOutputContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeOutputContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeOutputContext<'input> {}

impl<'input> DescribeOutputContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeOutputContext(
				BaseParserRuleContext::copy_from(ctx,DescribeOutputContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GrantContext<'input> = BaseParserRuleContext<'input,GrantContextExt<'input>>;

pub trait GrantContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token GRANT
	/// Returns `None` if there is no child corresponding to token GRANT
	fn GRANT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(GRANT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> GrantContextAttrs<'input> for GrantContext<'input>{}

pub struct GrantContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrantContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for GrantContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GrantContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grant(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_grant(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GrantContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_grant(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrantContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for GrantContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for GrantContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for GrantContext<'input> {}

impl<'input> GrantContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::GrantContext(
				BaseParserRuleContext::copy_from(ctx,GrantContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTablePropertiesContext<'input> = BaseParserRuleContext<'input,SetTablePropertiesContextExt<'input>>;

pub trait SetTablePropertiesContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROPERTIES
	/// Returns `None` if there is no child corresponding to token PROPERTIES
	fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PROPERTIES, 0)
	}
	fn propertyAssignments(&self) -> Option<Rc<PropertyAssignmentsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTablePropertiesContextAttrs<'input> for SetTablePropertiesContext<'input>{}

pub struct SetTablePropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTablePropertiesContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SetTablePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetTablePropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableProperties(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_setTableProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetTablePropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setTableProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTablePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTablePropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTablePropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTablePropertiesContext<'input> {}

impl<'input> SetTablePropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTablePropertiesContext(
				BaseParserRuleContext::copy_from(ctx,SetTablePropertiesContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ReturnContext<'input> = BaseParserRuleContext<'input,ReturnContextExt<'input>>;

pub trait ReturnContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RETURN
	/// Returns `None` if there is no child corresponding to token RETURN
	fn RETURN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RETURN, 0)
	}
}

impl<'input> ReturnContextAttrs<'input> for ReturnContext<'input>{}

pub struct ReturnContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ReturnContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ReturnContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ReturnContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_return(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_return(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ReturnContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_return(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReturnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ReturnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ReturnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ReturnContext<'input> {}

impl<'input> ReturnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ReturnContext(
				BaseParserRuleContext::copy_from(ctx,ReturnContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn statement(&mut self,)
	-> Result<Rc<StatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 12, RULE_statement);
        let mut _localctx: Rc<StatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1317);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(135,&mut recog.base)? {
				1 =>{
					let tmp = StatementDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule query*/
					recog.base.set_state(377);
					recog.query()?;

					}
				}
			,
				2 =>{
					let tmp = UseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(378);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(379);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.schema = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				3 =>{
					let tmp = UseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(380);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(381);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.catalog = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(382);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(383);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.schema = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				4 =>{
					let tmp = DropSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(385);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(386);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					recog.base.set_state(389);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(387);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(388);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(391);
					recog.qualifiedName()?;

					recog.base.set_state(395);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(392);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(397);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				5 =>{
					let tmp = RenameSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(398);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(399);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(400);
					recog.qualifiedName()?;

					recog.base.set_state(401);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(402);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(403);
					recog.identifier()?;

					}
				}
			,
				6 =>{
					let tmp = SetSchemaAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(405);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(406);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(407);
					recog.qualifiedName()?;

					recog.base.set_state(408);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(409);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(410);
					recog.principal()?;

					}
				}
			,
				7 =>{
					let tmp = DropTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(412);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(413);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(414);
					recog.qualifiedName()?;

					}
				}
			,
				8 =>{
					let tmp = DropViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(415);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(416);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(417);
					recog.qualifiedName()?;

					}
				}
			,
				9 =>{
					let tmp = BigqueryCreateExternalTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(418);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(421);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(419);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(420);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(423);
					recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

					recog.base.set_state(424);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(428);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(425);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(426);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(427);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(430);
					let tmp = recog.maybeDashedPathExpression()?;
					if let StatementContextAll::BigqueryCreateExternalTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(438);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(431);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule tableElements*/
						recog.base.set_state(432);
						recog.tableElements()?;

						recog.base.set_state(434);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(433);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::BigqueryCreateExternalTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

							let temp = if let StatementContextAll::BigqueryCreateExternalTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let StatementContextAll::BigqueryCreateExternalTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail.push(temp); } else {unreachable!("cant cast");}  
							}
						}

						recog.base.set_state(436);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(441);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(12,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule connectionSpec*/
							recog.base.set_state(440);
							recog.connectionSpec()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(449);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						recog.base.set_state(443);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						recog.base.set_state(444);
						recog.base.match_token(PARTITION,&mut recog.err_handler)?;

						recog.base.set_state(445);
						recog.base.match_token(COLUMNS,&mut recog.err_handler)?;

						recog.base.set_state(447);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==LPAREN {
							{
							/*InvokeRule partitionColumns*/
							recog.base.set_state(446);
							recog.partitionColumns()?;

							}
						}

						}
					}

					recog.base.set_state(451);
					recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

					/*InvokeRule properties*/
					recog.base.set_state(452);
					recog.properties()?;

					}
				}
			,
				10 =>{
					let tmp = BigqueryCreateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(454);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(457);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(455);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(456);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(460);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TEMP || _la==TEMPORARY {
						{
						recog.base.set_state(459);
						_la = recog.base.input.la(1);
						if { !(_la==TEMP || _la==TEMPORARY) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(462);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(466);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(463);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(464);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(465);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(468);
					let tmp = recog.maybeDashedPathExpression()?;
					if let StatementContextAll::BigqueryCreateTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(480);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 COPY | LIKE 
						=> {
					    	{
					    	{
					    	recog.base.set_state(469);
					    	_la = recog.base.input.la(1);
					    	if { !(_la==COPY || _la==LIKE) } {
					    		recog.err_handler.recover_inline(&mut recog.base)?;

					    	}
					    	else {
					    		if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					    		recog.err_handler.report_match(&mut recog.base);
					    		recog.base.consume(&mut recog.err_handler);
					    	}
					    	/*InvokeRule maybeDashedPathExpression*/
					    	recog.base.set_state(470);
					    	let tmp = recog.maybeDashedPathExpression()?;
					    	if let StatementContextAll::BigqueryCreateTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					    	ctx.source = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					    	}
					    	}
					    }

					 CLONE 
						=> {
					    	{
					    	{
					    	recog.base.set_state(471);
					    	recog.base.match_token(CLONE,&mut recog.err_handler)?;

					    	/*InvokeRule maybeDashedPathExpression*/
					    	recog.base.set_state(472);
					    	let tmp = recog.maybeDashedPathExpression()?;
					    	if let StatementContextAll::BigqueryCreateTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					    	ctx.source = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					    	recog.base.set_state(478);
					    	recog.err_handler.sync(&mut recog.base)?;
					    	_la = recog.base.input.la(1);
					    	if _la==FOR {
					    		{
					    		recog.base.set_state(473);
					    		recog.base.match_token(FOR,&mut recog.err_handler)?;

					    		recog.base.set_state(474);
					    		recog.base.match_token(SYSTEM_TIME,&mut recog.err_handler)?;

					    		recog.base.set_state(475);
					    		recog.base.match_token(AS,&mut recog.err_handler)?;

					    		recog.base.set_state(476);
					    		recog.base.match_token(OF,&mut recog.err_handler)?;

					    		/*InvokeRule expression*/
					    		recog.base.set_state(477);
					    		recog.expression()?;

					    		}
					    	}

					    	}
					    	}
					    }

					 EOF | AS | CLUSTER | DEFAULT | OPTIONS | PARTITION | LPAREN | SEMI_COLON 
						=> {
					    }

						_ => {}
					}
					recog.base.set_state(489);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(482);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule tableElements*/
						recog.base.set_state(483);
						recog.tableElements()?;

						recog.base.set_state(485);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(484);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::BigqueryCreateTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						recog.base.set_state(487);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(494);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==DEFAULT {
						{
						recog.base.set_state(491);
						recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

						recog.base.set_state(492);
						recog.base.match_token(COLLATE,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(493);
						recog.string()?;

						}
					}

					recog.base.set_state(499);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						recog.base.set_state(496);
						recog.base.match_token(PARTITION,&mut recog.err_handler)?;

						recog.base.set_state(497);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(498);
						recog.expression()?;

						}
					}

					recog.base.set_state(511);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==CLUSTER {
						{
						recog.base.set_state(501);
						recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

						recog.base.set_state(502);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(503);
						recog.identifier()?;

						recog.base.set_state(508);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(504);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(505);
							recog.identifier()?;

							}
							}
							recog.base.set_state(510);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					recog.base.set_state(515);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(513);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(514);
						recog.properties()?;

						}
					}

					recog.base.set_state(519);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(517);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						/*InvokeRule query*/
						recog.base.set_state(518);
						recog.query()?;

						}
					}

					}
				}
			,
				11 =>{
					let tmp = CreateSnapshotTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(521);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(522);
					recog.base.match_token(SNAPSHOT,&mut recog.err_handler)?;

					recog.base.set_state(523);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(527);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(524);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(525);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(526);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(529);
					let tmp = recog.maybeDashedPathExpression()?;
					if let StatementContextAll::CreateSnapshotTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(530);
					recog.base.match_token(CLONE,&mut recog.err_handler)?;

					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(531);
					let tmp = recog.maybeDashedPathExpression()?;
					if let StatementContextAll::CreateSnapshotTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.source = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(537);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(532);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						recog.base.set_state(533);
						recog.base.match_token(SYSTEM_TIME,&mut recog.err_handler)?;

						recog.base.set_state(534);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						recog.base.set_state(535);
						recog.base.match_token(OF,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(536);
						recog.expression()?;

						}
					}

					recog.base.set_state(541);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(539);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(540);
						recog.properties()?;

						}
					}

					}
				}
			,
				12 =>{
					let tmp = InsertIntoContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 12);
					_localctx = tmp;
					{
					recog.base.set_state(543);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(545);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INTO {
						{
						recog.base.set_state(544);
						recog.base.match_token(INTO,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(547);
					let tmp = recog.maybeDashedPathExpression()?;
					if let StatementContextAll::InsertIntoContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(549);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(32,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(548);
							recog.columnAliases()?;

							}
						}

						_ => {}
					}
					/*InvokeRule query*/
					recog.base.set_state(551);
					recog.query()?;

					}
				}
			,
				13 =>{
					let tmp = BigqueryCreateMaterializedViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 13);
					_localctx = tmp;
					{
					recog.base.set_state(553);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(556);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(554);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(555);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(558);
					recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(559);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(563);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(560);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(561);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(562);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(565);
					let tmp = recog.maybeDashedPathExpression()?;
					if let StatementContextAll::BigqueryCreateMaterializedViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(569);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						recog.base.set_state(566);
						recog.base.match_token(PARTITION,&mut recog.err_handler)?;

						recog.base.set_state(567);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(568);
						recog.expression()?;

						}
					}

					recog.base.set_state(581);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==CLUSTER {
						{
						recog.base.set_state(571);
						recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

						recog.base.set_state(572);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(573);
						recog.identifier()?;

						recog.base.set_state(578);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(574);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(575);
							recog.identifier()?;

							}
							}
							recog.base.set_state(580);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					recog.base.set_state(585);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(583);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(584);
						recog.properties()?;

						}
					}

					recog.base.set_state(587);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(588);
					recog.query()?;

					}
				}
			,
				14 =>{
					let tmp = BigqueryCreateViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 14);
					_localctx = tmp;
					{
					recog.base.set_state(590);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(593);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(591);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(592);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(595);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(599);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(596);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(597);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(598);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(601);
					let tmp = recog.maybeDashedPathExpression()?;
					if let StatementContextAll::BigqueryCreateViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(603);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(41,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(602);
							recog.columnAliases()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(607);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(605);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(606);
						recog.properties()?;

						}
					}

					recog.base.set_state(609);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(610);
					recog.query()?;

					}
				}
			,
				15 =>{
					let tmp = ShowColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 15);
					_localctx = tmp;
					{
					recog.base.set_state(612);
					_la = recog.base.input.la(1);
					if { !(_la==DESC || _la==DESCRIBE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(613);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::ShowColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				16 =>{
					let tmp = ShowColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 16);
					_localctx = tmp;
					{
					recog.base.set_state(614);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(615);
					recog.base.match_token(COLUMNS,&mut recog.err_handler)?;

					recog.base.set_state(616);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(617);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::ShowColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				17 =>{
					let tmp = MergeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 17);
					_localctx = tmp;
					{
					recog.base.set_state(618);
					recog.base.match_token(MERGE,&mut recog.err_handler)?;

					recog.base.set_state(620);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INTO {
						{
						recog.base.set_state(619);
						recog.base.match_token(INTO,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(622);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::MergeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(627);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << AS) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						recog.base.set_state(624);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==AS {
							{
							recog.base.set_state(623);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						/*InvokeRule identifier*/
						recog.base.set_state(626);
						recog.identifier()?;

						}
					}

					recog.base.set_state(629);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					/*InvokeRule aliasedRelation*/
					recog.base.set_state(630);
					recog.aliasedRelation()?;

					recog.base.set_state(631);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(632);
					recog.booleanExpression_rec(0)?;

					recog.base.set_state(634); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule mergeCase*/
						recog.base.set_state(633);
						recog.mergeCase()?;

						}
						}
						recog.base.set_state(636); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					}
				}
			,
				18 =>{
					let tmp = CreateSqlFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 18);
					_localctx = tmp;
					{
					recog.base.set_state(638);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(641);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(639);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(640);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(644);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TEMP || _la==TEMPORARY {
						{
						recog.base.set_state(643);
						_la = recog.base.input.la(1);
						if { !(_la==TEMP || _la==TEMPORARY) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(646);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(650);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(647);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(648);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(649);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(652);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::CreateSqlFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(653);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(665);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						/*InvokeRule namedParameter*/
						recog.base.set_state(654);
						recog.namedParameter()?;

						recog.base.set_state(659);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(50,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(655);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule namedParameter*/
								recog.base.set_state(656);
								recog.namedParameter()?;

								}
								} 
							}
							recog.base.set_state(661);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(50,&mut recog.base)?;
						}
						recog.base.set_state(663);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(662);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::CreateSqlFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(667);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(670);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==RETURNS {
						{
						recog.base.set_state(668);
						recog.base.match_token(RETURNS,&mut recog.err_handler)?;

						/*InvokeRule type_*/
						recog.base.set_state(669);
						recog.type_()?;

						}
					}

					recog.base.set_state(672);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(673);
					let tmp = recog.expression()?;
					if let StatementContextAll::CreateSqlFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.body = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(679);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(674);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						recog.base.set_state(675);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule columnOptionList*/
						recog.base.set_state(676);
						recog.columnOptionList()?;

						recog.base.set_state(677);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				19 =>{
					let tmp = CreateJSFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 19);
					_localctx = tmp;
					{
					recog.base.set_state(681);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(684);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(682);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(683);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(687);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TEMP || _la==TEMPORARY {
						{
						recog.base.set_state(686);
						_la = recog.base.input.la(1);
						if { !(_la==TEMP || _la==TEMPORARY) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(689);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(693);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(690);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(691);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(692);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(695);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::CreateJSFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(696);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(708);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						/*InvokeRule namedParameter*/
						recog.base.set_state(697);
						recog.namedParameter()?;

						recog.base.set_state(702);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(58,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(698);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule namedParameter*/
								recog.base.set_state(699);
								recog.namedParameter()?;

								}
								} 
							}
							recog.base.set_state(704);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(58,&mut recog.base)?;
						}
						recog.base.set_state(706);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(705);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::CreateJSFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(710);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(711);
					recog.base.match_token(RETURNS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(712);
					recog.type_()?;

					recog.base.set_state(716);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 DETERMINISTIC 
						=> {
					    	{
					    	recog.base.set_state(713);
					    	recog.base.match_token(DETERMINISTIC,&mut recog.err_handler)?;

					    	}
					    }

					 NOT 
						=> {
					    	{
					    	recog.base.set_state(714);
					    	recog.base.match_token(NOT,&mut recog.err_handler)?;

					    	recog.base.set_state(715);
					    	recog.base.match_token(DETERMINISTIC,&mut recog.err_handler)?;

					    	}
					    }

					 LANGUAGE 
						=> {
					    }

						_ => {}
					}
					recog.base.set_state(718);
					recog.base.match_token(LANGUAGE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(719);
					recog.identifier()?;

					recog.base.set_state(738);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(64,&mut recog.base)? {
						1 =>{
							{
							{
							recog.base.set_state(725);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==OPTIONS {
								{
								recog.base.set_state(720);
								recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

								recog.base.set_state(721);
								recog.base.match_token(LPAREN,&mut recog.err_handler)?;

								/*InvokeRule columnOptionList*/
								recog.base.set_state(722);
								recog.columnOptionList()?;

								recog.base.set_state(723);
								recog.base.match_token(RPAREN,&mut recog.err_handler)?;

								}
							}

							recog.base.set_state(727);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							/*InvokeRule string*/
							recog.base.set_state(728);
							let tmp = recog.string()?;
							if let StatementContextAll::CreateJSFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.body = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
							}
						}
					,
						2 =>{
							{
							{
							recog.base.set_state(729);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							/*InvokeRule string*/
							recog.base.set_state(730);
							let tmp = recog.string()?;
							if let StatementContextAll::CreateJSFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.body = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(736);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==OPTIONS {
								{
								recog.base.set_state(731);
								recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

								recog.base.set_state(732);
								recog.base.match_token(LPAREN,&mut recog.err_handler)?;

								/*InvokeRule columnOptionList*/
								recog.base.set_state(733);
								recog.columnOptionList()?;

								recog.base.set_state(734);
								recog.base.match_token(RPAREN,&mut recog.err_handler)?;

								}
							}

							}
							}
						}

						_ => {}
					}
					}
				}
			,
				20 =>{
					let tmp = CreateRemoteFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 20);
					_localctx = tmp;
					{
					recog.base.set_state(740);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(743);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(741);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(742);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(745);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(749);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(746);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(747);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(748);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(751);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::CreateRemoteFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(752);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(764);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						/*InvokeRule namedParameter*/
						recog.base.set_state(753);
						recog.namedParameter()?;

						recog.base.set_state(758);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(67,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(754);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule namedParameter*/
								recog.base.set_state(755);
								recog.namedParameter()?;

								}
								} 
							}
							recog.base.set_state(760);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(67,&mut recog.base)?;
						}
						recog.base.set_state(762);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(761);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::CreateRemoteFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(766);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(767);
					recog.base.match_token(RETURNS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(768);
					recog.type_()?;

					recog.base.set_state(769);
					recog.base.match_token(REMOTE,&mut recog.err_handler)?;

					/*InvokeRule connectionSpec*/
					recog.base.set_state(770);
					recog.connectionSpec()?;

					recog.base.set_state(776);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(771);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						recog.base.set_state(772);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule columnOptionList*/
						recog.base.set_state(773);
						recog.columnOptionList()?;

						recog.base.set_state(774);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				21 =>{
					let tmp = BigqueryCreateModelContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 21);
					_localctx = tmp;
					{
					recog.base.set_state(778);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(781);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(779);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(780);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(783);
					recog.base.match_token(MODEL,&mut recog.err_handler)?;

					recog.base.set_state(787);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(784);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(785);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(786);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(789);
					let tmp = recog.maybeDashedPathExpression()?;
					if let StatementContextAll::BigqueryCreateModelContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(792);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TRANSFORM {
						{
						recog.base.set_state(790);
						recog.base.match_token(TRANSFORM,&mut recog.err_handler)?;

						/*InvokeRule querySelectItems*/
						recog.base.set_state(791);
						recog.querySelectItems()?;

						}
					}

					recog.base.set_state(801);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INPUT {
						{
						recog.base.set_state(794);
						recog.base.match_token(INPUT,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(795);
						recog.identifier()?;

						/*InvokeRule type_*/
						recog.base.set_state(796);
						recog.type_()?;

						recog.base.set_state(797);
						recog.base.match_token(OUTPUT,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(798);
						recog.identifier()?;

						/*InvokeRule type_*/
						recog.base.set_state(799);
						recog.type_()?;

						}
					}

					recog.base.set_state(810);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==REMOTE {
						{
						recog.base.set_state(803);
						recog.base.match_token(REMOTE,&mut recog.err_handler)?;

						recog.base.set_state(804);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						recog.base.set_state(805);
						recog.base.match_token(CONNECTION,&mut recog.err_handler)?;

						recog.base.set_state(806);
						recog.base.match_token(T__0,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(807);
						recog.identifier()?;

						recog.base.set_state(808);
						recog.base.match_token(T__0,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(814);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(812);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(813);
						recog.properties()?;

						}
					}

					recog.base.set_state(816);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(830);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 SELECT | TABLE | VALUES | WITH | LPAREN 
						=> {
							{
							/*InvokeRule query*/
							recog.base.set_state(817);
							recog.query()?;

							}
						}

					 TRAINING_DATA 
						=> {
							{
							recog.base.set_state(818);
							recog.base.match_token(TRAINING_DATA,&mut recog.err_handler)?;

							recog.base.set_state(819);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							recog.base.set_state(820);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(821);
							recog.query()?;

							recog.base.set_state(822);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

					 CUSTOM_HOLIDAY 
						=> {
							{
							recog.base.set_state(824);
							recog.base.match_token(CUSTOM_HOLIDAY,&mut recog.err_handler)?;

							recog.base.set_state(825);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							recog.base.set_state(826);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(827);
							recog.query()?;

							recog.base.set_state(828);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}
			,
				22 =>{
					let tmp = DeclareContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 22);
					_localctx = tmp;
					{
					recog.base.set_state(832);
					recog.base.match_token(DECLARE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(833);
					recog.identifier()?;

					recog.base.set_state(838);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(834);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(835);
						recog.identifier()?;

						}
						}
						recog.base.set_state(840);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(842);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (DOLLAR - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						/*InvokeRule type_*/
						recog.base.set_state(841);
						recog.type_()?;

						}
					}

					recog.base.set_state(846);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==DEFAULT {
						{
						recog.base.set_state(844);
						recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(845);
						recog.expression()?;

						}
					}

					}
				}
			,
				23 =>{
					let tmp = ExecuteImmediateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 23);
					_localctx = tmp;
					{
					recog.base.set_state(848);
					recog.base.match_token(EXECUTE,&mut recog.err_handler)?;

					recog.base.set_state(849);
					recog.base.match_token(IMMEDIATE,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(850);
					recog.expression()?;

					recog.base.set_state(860);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INTO {
						{
						recog.base.set_state(851);
						recog.base.match_token(INTO,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(852);
						recog.identifier()?;

						recog.base.set_state(857);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(853);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(854);
							recog.identifier()?;

							}
							}
							recog.base.set_state(859);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					recog.base.set_state(871);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						recog.base.set_state(862);
						recog.base.match_token(USING,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(863);
						recog.identifier()?;

						recog.base.set_state(868);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(864);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(865);
							recog.identifier()?;

							}
							}
							recog.base.set_state(870);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					}
				}
			,
				24 =>{
					let tmp = BeginContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 24);
					_localctx = tmp;
					{
					recog.base.set_state(873);
					recog.base.match_token(BEGIN,&mut recog.err_handler)?;

					/*InvokeRule statementBlock*/
					recog.base.set_state(874);
					recog.statementBlock()?;

					recog.base.set_state(875);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				25 =>{
					let tmp = BeginExceptionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 25);
					_localctx = tmp;
					{
					recog.base.set_state(877);
					recog.base.match_token(BEGIN,&mut recog.err_handler)?;

					/*InvokeRule statementBlock*/
					recog.base.set_state(878);
					recog.statementBlock()?;

					recog.base.set_state(879);
					recog.base.match_token(EXCEPTION,&mut recog.err_handler)?;

					recog.base.set_state(880);
					recog.base.match_token(WHEN,&mut recog.err_handler)?;

					recog.base.set_state(881);
					recog.base.match_token(ERROR,&mut recog.err_handler)?;

					recog.base.set_state(882);
					recog.base.match_token(THEN,&mut recog.err_handler)?;

					/*InvokeRule statementBlock*/
					recog.base.set_state(883);
					recog.statementBlock()?;

					recog.base.set_state(884);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				26 =>{
					let tmp = CaseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 26);
					_localctx = tmp;
					{
					recog.base.set_state(886);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					recog.base.set_state(888);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(887);
						recog.expression()?;

						}
					}

					recog.base.set_state(895); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						recog.base.set_state(890);
						recog.base.match_token(WHEN,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(891);
						recog.booleanExpression_rec(0)?;

						recog.base.set_state(892);
						recog.base.match_token(THEN,&mut recog.err_handler)?;

						/*InvokeRule statementBlock*/
						recog.base.set_state(893);
						recog.statementBlock()?;

						}
						}
						recog.base.set_state(897); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(901);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(899);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule statementBlock*/
						recog.base.set_state(900);
						recog.statementBlock()?;

						}
					}

					recog.base.set_state(903);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(904);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					}
				}
			,
				27 =>{
					let tmp = IfContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 27);
					_localctx = tmp;
					{
					recog.base.set_state(906);
					recog.base.match_token(IF,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(907);
					recog.booleanExpression_rec(0)?;

					recog.base.set_state(908);
					recog.base.match_token(THEN,&mut recog.err_handler)?;

					/*InvokeRule statementBlock*/
					recog.base.set_state(909);
					recog.statementBlock()?;

					recog.base.set_state(917);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==ELSEIF {
						{
						{
						recog.base.set_state(910);
						recog.base.match_token(ELSEIF,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(911);
						recog.booleanExpression_rec(0)?;

						recog.base.set_state(912);
						recog.base.match_token(THEN,&mut recog.err_handler)?;

						/*InvokeRule statementBlock*/
						recog.base.set_state(913);
						recog.statementBlock()?;

						}
						}
						recog.base.set_state(919);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(922);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(920);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule statementBlock*/
						recog.base.set_state(921);
						recog.statementBlock()?;

						}
					}

					recog.base.set_state(924);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(925);
					recog.base.match_token(IF,&mut recog.err_handler)?;

					}
				}
			,
				28 =>{
					let tmp = LoopContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 28);
					_localctx = tmp;
					{
					recog.base.set_state(927);
					recog.base.match_token(LOOP,&mut recog.err_handler)?;

					/*InvokeRule statementBlock*/
					recog.base.set_state(928);
					recog.statementBlock()?;

					recog.base.set_state(929);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(930);
					recog.base.match_token(LOOP,&mut recog.err_handler)?;

					}
				}
			,
				29 =>{
					let tmp = RepeatContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 29);
					_localctx = tmp;
					{
					recog.base.set_state(932);
					recog.base.match_token(REPEAT,&mut recog.err_handler)?;

					/*InvokeRule statementBlock*/
					recog.base.set_state(933);
					recog.statementBlock()?;

					recog.base.set_state(934);
					recog.base.match_token(UNTIL,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(935);
					recog.booleanExpression_rec(0)?;

					recog.base.set_state(936);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(937);
					recog.base.match_token(REPEAT,&mut recog.err_handler)?;

					}
				}
			,
				30 =>{
					let tmp = WhileContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 30);
					_localctx = tmp;
					{
					recog.base.set_state(939);
					recog.base.match_token(WHILE,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(940);
					recog.booleanExpression_rec(0)?;

					recog.base.set_state(941);
					recog.base.match_token(DO,&mut recog.err_handler)?;

					/*InvokeRule statementBlock*/
					recog.base.set_state(942);
					recog.statementBlock()?;

					recog.base.set_state(943);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(944);
					recog.base.match_token(WHILE,&mut recog.err_handler)?;

					}
				}
			,
				31 =>{
					let tmp = BreakContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 31);
					_localctx = tmp;
					{
					recog.base.set_state(946);
					recog.base.match_token(BREAK,&mut recog.err_handler)?;

					}
				}
			,
				32 =>{
					let tmp = LeaveContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 32);
					_localctx = tmp;
					{
					recog.base.set_state(947);
					recog.base.match_token(LEAVE,&mut recog.err_handler)?;

					}
				}
			,
				33 =>{
					let tmp = ContinueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 33);
					_localctx = tmp;
					{
					recog.base.set_state(948);
					recog.base.match_token(CONTINUE,&mut recog.err_handler)?;

					}
				}
			,
				34 =>{
					let tmp = ContinueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 34);
					_localctx = tmp;
					{
					recog.base.set_state(949);
					recog.base.match_token(ITERATE,&mut recog.err_handler)?;

					}
				}
			,
				35 =>{
					let tmp = ForInContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 35);
					_localctx = tmp;
					{
					recog.base.set_state(950);
					recog.base.match_token(FOR,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(951);
					recog.identifier()?;

					recog.base.set_state(952);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(953);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(954);
					recog.query()?;

					recog.base.set_state(955);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(956);
					recog.base.match_token(DO,&mut recog.err_handler)?;

					/*InvokeRule statementBlock*/
					recog.base.set_state(957);
					recog.statementBlock()?;

					recog.base.set_state(958);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(959);
					recog.base.match_token(FOR,&mut recog.err_handler)?;

					}
				}
			,
				36 =>{
					let tmp = RaiseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 36);
					_localctx = tmp;
					{
					recog.base.set_state(961);
					recog.base.match_token(RAISE,&mut recog.err_handler)?;

					recog.base.set_state(966);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						recog.base.set_state(962);
						recog.base.match_token(USING,&mut recog.err_handler)?;

						recog.base.set_state(963);
						recog.base.match_token(MESSAGE,&mut recog.err_handler)?;

						recog.base.set_state(964);
						recog.base.match_token(EQ,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(965);
						recog.string()?;

						}
					}

					}
				}
			,
				37 =>{
					let tmp = ReturnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 37);
					_localctx = tmp;
					{
					recog.base.set_state(968);
					recog.base.match_token(RETURN,&mut recog.err_handler)?;

					}
				}
			,
				38 =>{
					let tmp = BeginTransactionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 38);
					_localctx = tmp;
					{
					recog.base.set_state(969);
					recog.base.match_token(BEGIN,&mut recog.err_handler)?;

					recog.base.set_state(971);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TRANSACTION {
						{
						recog.base.set_state(970);
						recog.base.match_token(TRANSACTION,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				39 =>{
					let tmp = CommitTransactionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 39);
					_localctx = tmp;
					{
					recog.base.set_state(973);
					recog.base.match_token(COMMIT,&mut recog.err_handler)?;

					recog.base.set_state(975);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TRANSACTION {
						{
						recog.base.set_state(974);
						recog.base.match_token(TRANSACTION,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				40 =>{
					let tmp = RollbackTransactionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 40);
					_localctx = tmp;
					{
					recog.base.set_state(977);
					recog.base.match_token(ROLLBACK,&mut recog.err_handler)?;

					recog.base.set_state(979);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TRANSACTION {
						{
						recog.base.set_state(978);
						recog.base.match_token(TRANSACTION,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				41 =>{
					let tmp = SetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 41);
					_localctx = tmp;
					{
					recog.base.set_state(981);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(985);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(982);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(987);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				42 =>{
					let tmp = CreateSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 42);
					_localctx = tmp;
					{
					recog.base.set_state(988);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(991);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(989);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(990);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(993);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					recog.base.set_state(997);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(994);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(999);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				43 =>{
					let tmp = DropContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 43);
					_localctx = tmp;
					{
					recog.base.set_state(1000);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1004);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1001);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1006);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				44 =>{
					let tmp = DeleteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 44);
					_localctx = tmp;
					{
					recog.base.set_state(1007);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					recog.base.set_state(1011);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1008);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1013);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				45 =>{
					let tmp = TruncateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 45);
					_localctx = tmp;
					{
					recog.base.set_state(1014);
					recog.base.match_token(TRUNCATE,&mut recog.err_handler)?;

					recog.base.set_state(1018);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1015);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1020);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				46 =>{
					let tmp = CommentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 46);
					_localctx = tmp;
					{
					recog.base.set_state(1021);
					recog.base.match_token(COMMENT,&mut recog.err_handler)?;

					recog.base.set_state(1025);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1022);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1027);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				47 =>{
					let tmp = RenameTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 47);
					_localctx = tmp;
					{
					recog.base.set_state(1028);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1029);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1032);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1030);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1031);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1034);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1035);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(1036);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1037);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				48 =>{
					let tmp = AddColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 48);
					_localctx = tmp;
					{
					recog.base.set_state(1039);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1040);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1043);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1041);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1042);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1045);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::AddColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1046);
					recog.base.match_token(ADD,&mut recog.err_handler)?;

					recog.base.set_state(1047);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(1051);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1048);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1049);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(1050);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule columnDefinition*/
					recog.base.set_state(1053);
					let tmp = recog.columnDefinition()?;
					if let StatementContextAll::AddColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.column = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				49 =>{
					let tmp = RenameColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 49);
					_localctx = tmp;
					{
					recog.base.set_state(1055);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1056);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1059);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1057);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1058);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1061);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1062);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(1063);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(1066);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1064);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1065);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule identifier*/
					recog.base.set_state(1068);
					let tmp = recog.identifier()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1069);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1070);
					let tmp = recog.identifier()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				50 =>{
					let tmp = DropColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 50);
					_localctx = tmp;
					{
					recog.base.set_state(1072);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1073);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1076);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1074);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1075);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1078);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::DropColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1079);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1080);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(1083);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1081);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1082);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1085);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::DropColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.column = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				51 =>{
					let tmp = SetColumnTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 51);
					_localctx = tmp;
					{
					recog.base.set_state(1087);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1088);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1091);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1089);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1090);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1093);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetColumnTypeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1094);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1095);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1096);
					let tmp = recog.identifier()?;
					if let StatementContextAll::SetColumnTypeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.setColumnName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1097);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1098);
					recog.base.match_token(DATA,&mut recog.err_handler)?;

					recog.base.set_state(1099);
					recog.base.match_token(TYPE,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(1100);
					recog.type_()?;

					}
				}
			,
				52 =>{
					let tmp = SetTableAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 52);
					_localctx = tmp;
					{
					recog.base.set_state(1102);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1103);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1104);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetTableAuthorizationContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1105);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1106);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(1107);
					recog.principal()?;

					}
				}
			,
				53 =>{
					let tmp = SetTablePropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 53);
					_localctx = tmp;
					{
					recog.base.set_state(1109);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1110);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1111);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetTablePropertiesContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1112);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1113);
					recog.base.match_token(PROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule propertyAssignments*/
					recog.base.set_state(1114);
					recog.propertyAssignments()?;

					}
				}
			,
				54 =>{
					let tmp = TableExecuteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 54);
					_localctx = tmp;
					{
					recog.base.set_state(1116);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1117);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1118);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1119);
					recog.base.match_token(EXECUTE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1120);
					let tmp = recog.identifier()?;
					if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.procedureName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1136);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(1121);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(1130);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
							{
							/*InvokeRule callArgument*/
							recog.base.set_state(1122);
							recog.callArgument()?;

							recog.base.set_state(1127);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(109,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(1123);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule callArgument*/
									recog.base.set_state(1124);
									recog.callArgument()?;

									}
									} 
								}
								recog.base.set_state(1129);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(109,&mut recog.base)?;
							}
							}
						}

						recog.base.set_state(1133);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(1132);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						recog.base.set_state(1135);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1140);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						recog.base.set_state(1138);
						recog.base.match_token(WHERE,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(1139);
						let tmp = recog.booleanExpression_rec(0)?;
						if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.where_ = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					}
				}
			,
				55 =>{
					let tmp = AnalyzeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 55);
					_localctx = tmp;
					{
					recog.base.set_state(1142);
					recog.base.match_token(ANALYZE,&mut recog.err_handler)?;

					recog.base.set_state(1146);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1143);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1148);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				56 =>{
					let tmp = RefreshMaterializedViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 56);
					_localctx = tmp;
					{
					recog.base.set_state(1149);
					recog.base.match_token(REFRESH,&mut recog.err_handler)?;

					recog.base.set_state(1150);
					recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(1151);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1152);
					recog.qualifiedName()?;

					}
				}
			,
				57 =>{
					let tmp = RenameMaterializedViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 57);
					_localctx = tmp;
					{
					recog.base.set_state(1153);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1154);
					recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(1155);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(1158);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1156);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1157);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1160);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameMaterializedViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1161);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(1162);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1163);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameMaterializedViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				58 =>{
					let tmp = SetMaterializedViewPropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 58);
					_localctx = tmp;
					{
					recog.base.set_state(1165);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1166);
					recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(1167);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1168);
					recog.qualifiedName()?;

					recog.base.set_state(1169);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1170);
					recog.base.match_token(PROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule propertyAssignments*/
					recog.base.set_state(1171);
					recog.propertyAssignments()?;

					}
				}
			,
				59 =>{
					let tmp = RenameViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 59);
					_localctx = tmp;
					{
					recog.base.set_state(1173);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1174);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1175);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1176);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(1177);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1178);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				60 =>{
					let tmp = SetViewAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 60);
					_localctx = tmp;
					{
					recog.base.set_state(1180);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1181);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1182);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetViewAuthorizationContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1183);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1184);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(1185);
					recog.principal()?;

					}
				}
			,
				61 =>{
					let tmp = CallContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 61);
					_localctx = tmp;
					{
					recog.base.set_state(1187);
					recog.base.match_token(CALL,&mut recog.err_handler)?;

					recog.base.set_state(1191);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1188);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1193);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				62 =>{
					let tmp = CreateRoleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 62);
					_localctx = tmp;
					{
					recog.base.set_state(1194);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1195);
					recog.base.match_token(ROLE,&mut recog.err_handler)?;

					recog.base.set_state(1199);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1196);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1201);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				63 =>{
					let tmp = GrantContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 63);
					_localctx = tmp;
					{
					recog.base.set_state(1202);
					recog.base.match_token(GRANT,&mut recog.err_handler)?;

					recog.base.set_state(1206);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1203);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1208);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				64 =>{
					let tmp = RevokeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 64);
					_localctx = tmp;
					{
					recog.base.set_state(1209);
					recog.base.match_token(REVOKE,&mut recog.err_handler)?;

					recog.base.set_state(1213);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1210);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1215);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				65 =>{
					let tmp = DenyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 65);
					_localctx = tmp;
					{
					recog.base.set_state(1216);
					recog.base.match_token(DENY,&mut recog.err_handler)?;

					recog.base.set_state(1230);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 CREATE | DELETE | INSERT | SELECT | UPDATE 
						=> {
							{
							/*InvokeRule privilege*/
							recog.base.set_state(1217);
							recog.privilege()?;

							recog.base.set_state(1222);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(120,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(1218);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule privilege*/
									recog.base.set_state(1219);
									recog.privilege()?;

									}
									} 
								}
								recog.base.set_state(1224);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(120,&mut recog.base)?;
							}
							recog.base.set_state(1226);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(1225);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let StatementContextAll::DenyContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							}
						}

					 ALL 
						=> {
							{
							recog.base.set_state(1228);
							recog.base.match_token(ALL,&mut recog.err_handler)?;

							recog.base.set_state(1229);
							recog.base.match_token(PRIVILEGES,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					recog.base.set_state(1232);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					recog.base.set_state(1234);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(123,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1233);
							_la = recog.base.input.la(1);
							if { !(_la==SCHEMA || _la==TABLE) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(1236);
					recog.qualifiedName()?;

					recog.base.set_state(1237);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(1238);
					let tmp = recog.principal()?;
					if let StatementContextAll::DenyContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.grantee = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				66 =>{
					let tmp = ShowContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 66);
					_localctx = tmp;
					{
					recog.base.set_state(1240);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1244);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1241);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1246);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				67 =>{
					let tmp = ResetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 67);
					_localctx = tmp;
					{
					recog.base.set_state(1247);
					recog.base.match_token(RESET,&mut recog.err_handler)?;

					recog.base.set_state(1251);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1248);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1253);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				68 =>{
					let tmp = StartTransactionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 68);
					_localctx = tmp;
					{
					recog.base.set_state(1254);
					recog.base.match_token(START,&mut recog.err_handler)?;

					recog.base.set_state(1255);
					recog.base.match_token(TRANSACTION,&mut recog.err_handler)?;

					recog.base.set_state(1267);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ISOLATION || _la==READ {
						{
						/*InvokeRule transactionMode*/
						recog.base.set_state(1256);
						recog.transactionMode()?;

						recog.base.set_state(1261);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(126,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(1257);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule transactionMode*/
								recog.base.set_state(1258);
								recog.transactionMode()?;

								}
								} 
							}
							recog.base.set_state(1263);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(126,&mut recog.base)?;
						}
						recog.base.set_state(1265);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(1264);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::StartTransactionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					}
				}
			,
				69 =>{
					let tmp = CommitContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 69);
					_localctx = tmp;
					{
					recog.base.set_state(1269);
					recog.base.match_token(COMMIT,&mut recog.err_handler)?;

					recog.base.set_state(1273);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1270);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1275);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				70 =>{
					let tmp = RollbackContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 70);
					_localctx = tmp;
					{
					recog.base.set_state(1276);
					recog.base.match_token(ROLLBACK,&mut recog.err_handler)?;

					recog.base.set_state(1280);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1277);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1282);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				71 =>{
					let tmp = PrepareContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 71);
					_localctx = tmp;
					{
					recog.base.set_state(1283);
					recog.base.match_token(PREPARE,&mut recog.err_handler)?;

					recog.base.set_state(1287);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1284);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1289);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				72 =>{
					let tmp = DeallocateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 72);
					_localctx = tmp;
					{
					recog.base.set_state(1290);
					recog.base.match_token(DEALLOCATE,&mut recog.err_handler)?;

					recog.base.set_state(1294);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1291);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1296);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				73 =>{
					let tmp = ExecuteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 73);
					_localctx = tmp;
					{
					recog.base.set_state(1297);
					recog.base.match_token(EXECUTE,&mut recog.err_handler)?;

					recog.base.set_state(1301);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1298);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1303);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				74 =>{
					let tmp = DescribeInputContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 74);
					_localctx = tmp;
					{
					recog.base.set_state(1304);
					recog.base.match_token(DESCRIBE,&mut recog.err_handler)?;

					recog.base.set_state(1305);
					recog.base.match_token(INPUT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1306);
					recog.identifier()?;

					}
				}
			,
				75 =>{
					let tmp = DescribeOutputContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 75);
					_localctx = tmp;
					{
					recog.base.set_state(1307);
					recog.base.match_token(DESCRIBE,&mut recog.err_handler)?;

					recog.base.set_state(1308);
					recog.base.match_token(OUTPUT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1309);
					recog.identifier()?;

					}
				}
			,
				76 =>{
					let tmp = UpdateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 76);
					_localctx = tmp;
					{
					recog.base.set_state(1310);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(1314);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << T__4) | (1usize << T__5) | (1usize << T__6) | (1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BETWEEN) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BZIP2 - 32)) | (1usize << (CALL - 32)) | (1usize << (CANCEL - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CASE_SENSITIVE - 32)) | (1usize << (CASE_INSENSITIVE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLONE - 32)) | (1usize << (CLOSE - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (COALESCE - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMMITTED - 32)) | (1usize << (COMPOUND - 32)) | (1usize << (COMPRESSION - 32)) | (1usize << (CONDITIONAL - 32)) | (1usize << (CONNECT - 32)) | (1usize << (CONNECTION - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTINUE - 32)) | (1usize << (COPARTITION - 32)) | (1usize << (COPY - 32)) | (1usize << (COUNT - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_ROLE - 64)) | (1usize << (CUSTOM_HOLIDAY - 64)) | (1usize << (DATA - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATASHARE - 64)) | (1usize << (DATE - 64)) | (1usize << (DATETIME - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYOFWEEK - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATETIME_DIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DEALLOCATE - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFAULTS - 64)) | (1usize << (DEFINE - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DELIMITER - 64)) | (1usize << (DENY - 64)) | (1usize << (DESC - 64)) | (1usize << (DESCRIBE - 64)) | (1usize << (DESCRIPTOR - 64)) | (1usize << (DETERMINISTIC - 64)) | (1usize << (DISTINCT - 64)) | (1usize << (DISTKEY - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DISTRIBUTED - 96)) | (1usize << (DISTSTYLE - 96)) | (1usize << (DETACH - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (EMPTY - 96)) | (1usize << (ENCODE - 96)) | (1usize << (ENCODING - 96)) | (1usize << (END - 96)) | (1usize << (ERROR - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (EVEN - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCEPTION - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXCLUDING - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FINAL - 96)) | (1usize << (FIRST - 96)) | (1usize << (FOLLOWING - 96)) | (1usize << (FOR - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FORMAT - 128)) | (1usize << (FRIDAY - 128)) | (1usize << (FROM - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GRACE - 128)) | (1usize << (GRANT - 128)) | (1usize << (GRANTED - 128)) | (1usize << (GRANTS - 128)) | (1usize << (GRAPHVIZ - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (GROUPS - 128)) | (1usize << (GZIP - 128)) | (1usize << (HAVING - 128)) | (1usize << (HEADER - 128)) | (1usize << (HOUR - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INCLUDING - 128)) | (1usize << (INITIAL - 128)) | (1usize << (INNER - 128)) | (1usize << (INPUT - 128)) | (1usize << (INPUTFORMAT - 128)) | (1usize << (INTERLEAVED - 128)) | (1usize << (INSERT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IO - 160)) | (1usize << (IS - 160)) | (1usize << (ISOLATION - 160)) | (1usize << (ISOWEEK - 160)) | (1usize << (ISOYEAR - 160)) | (1usize << (ITERATE - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (JSON - 160)) | (1usize << (KEEP - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LAMBDA - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LEAVE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LEVEL - 160)) | (1usize << (LIBRARY - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LOGICAL - 192)) | (1usize << (LOOP - 192)) | (1usize << (MAP - 192)) | (1usize << (MASKING - 192)) | (1usize << (MATCH - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATCHES - 192)) | (1usize << (MATCH_RECOGNIZE - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURES - 192)) | (1usize << (MERGE - 192)) | (1usize << (MESSAGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MIN - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MODEL - 192)) | (1usize << (MONDAY - 192)) | (1usize << (MONTH - 192)) | (1usize << (NAME - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NEXT - 192)) | (1usize << (NFC - 192)) | (1usize << (NFD - 192)) | (1usize << (NFKC - 192)) | (1usize << (NFKD - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NORMALIZE - 192)) | (1usize << (NOT - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (OBJECT - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (OMIT - 224)) | (1usize << (ON - 224)) | (1usize << (ONE - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERFLOW - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PASSING - 224)) | (1usize << (PAST - 224)) | (1usize << (PATH - 224)) | (1usize << (PATTERN - 224)) | (1usize << (PER - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERIOD - 224)) | (1usize << (PERMUTE - 224)) | (1usize << (PIVOT - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PRECISION - 256)) | (1usize << (PREPARE - 256)) | (1usize << (PRIOR - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PRIVILEGES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PRUNE - 256)) | (1usize << (QUALIFY - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUOTES - 256)) | (1usize << (RAISE - 256)) | (1usize << (RANGE - 256)) | (1usize << (READ - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNING - 256)) | (1usize << (REMOTE - 256)) | (1usize << (REPEAT - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLS - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (RUNNING - 288)) | (1usize << (SAFE - 288)) | (1usize << (SAFE_CAST - 288)) | (1usize << (SATURDAY - 288)) | (1usize << (SCALAR - 288)) | (1usize << (SECOND - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEEK - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SERIALIZABLE - 288)) | (1usize << (SESSION - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHOW - 288)) | (1usize << (SIMILAR - 288)) | (1usize << (SNAPSHOT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORTKEY - 288)) | (1usize << (START - 288)) | (1usize << (STATS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSET - 288)) | (1usize << (SUBSTRING - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUNDAY - 320)) | (1usize << (SYSTEM - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (TEXT - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (THURSDAY - 320)) | (1usize << (TIES - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMP_DIFF - 320)) | (1usize << (TO - 320)) | (1usize << (TOP - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TARGET - 320)) | (1usize << (SOURCE - 320)) | (1usize << (TRAINING_DATA - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)) | (1usize << (TUPLE - 320)) | (1usize << (TUESDAY - 320)) | (1usize << (TYPE - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (UESCAPE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCOMMITTED - 352)) | (1usize << (UNCONDITIONAL - 352)) | (1usize << (UNION - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOAD - 352)) | (1usize << (UNMATCHED - 352)) | (1usize << (UNNEST - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSIGNED - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (UTF16 - 352)) | (1usize << (UTF32 - 352)) | (1usize << (UTF8 - 352)) | (1usize << (VACUUM - 352)) | (1usize << (VALIDATE - 352)) | (1usize << (VALUE - 352)) | (1usize << (VALUES - 352)) | (1usize << (VARYING - 352)) | (1usize << (VERBOSE - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (WEDNESDAY - 352)) | (1usize << (WEEK - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (WINDOW - 384)) | (1usize << (WITH - 384)) | (1usize << (WITHOUT - 384)) | (1usize << (WORK - 384)) | (1usize << (WRAPPER - 384)) | (1usize << (WRITE - 384)) | (1usize << (XZ - 384)) | (1usize << (YEAR - 384)) | (1usize << (YES - 384)) | (1usize << (ZONE - 384)) | (1usize << (ZSTD - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)) | (1usize << (BITWISE_SHIFT_LEFT - 416)) | (1usize << (POSIX - 416)) | (1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (QUOTED_STRING - 416)) | (1usize << (TRIPLE_QUOTED_STRING - 416)) | (1usize << (RAW_QUOTED_STRING - 416)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 416)) | (1usize << (BINARY_LITERAL - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (HEXADECIMAL_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BIG_QUERY_SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (OTHER_WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(1311);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(1316);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableElements ----------------
pub type TableElementsContextAll<'input> = TableElementsContext<'input>;


pub type TableElementsContext<'input> = BaseParserRuleContext<'input,TableElementsContextExt<'input>>;

#[derive(Clone)]
pub struct TableElementsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TableElementsContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableElementsContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableElements(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_tableElements(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableElementsContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableElements(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableElementsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableElements }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableElements }
}
antlr_rust::tid!{TableElementsContextExt<'a>}

impl<'input> TableElementsContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableElementsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableElementsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableElementsContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TableElementsContextExt<'input>>{

fn tableElement_all(&self) ->  Vec<Rc<TableElementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tableElement(&self, i: usize) -> Option<Rc<TableElementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableElementsContextAttrs<'input> for TableElementsContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableElements(&mut self,)
	-> Result<Rc<TableElementsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableElementsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 14, RULE_tableElements);
        let mut _localctx: Rc<TableElementsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableElement*/
			recog.base.set_state(1319);
			recog.tableElement()?;

			recog.base.set_state(1324);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(136,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1320);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule tableElement*/
					recog.base.set_state(1321);
					recog.tableElement()?;

					}
					} 
				}
				recog.base.set_state(1326);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(136,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpressionSeq ----------------
pub type NamedExpressionSeqContextAll<'input> = NamedExpressionSeqContext<'input>;


pub type NamedExpressionSeqContext<'input> = BaseParserRuleContext<'input,NamedExpressionSeqContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionSeqContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NamedExpressionSeqContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NamedExpressionSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpressionSeq(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_namedExpressionSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NamedExpressionSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_namedExpressionSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpressionSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpressionSeq }
}
antlr_rust::tid!{NamedExpressionSeqContextExt<'a>}

impl<'input> NamedExpressionSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionSeqContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionSeqContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NamedExpressionSeqContextExt<'input>>{

fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NamedExpressionSeqContextAttrs<'input> for NamedExpressionSeqContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpressionSeq(&mut self,)
	-> Result<Rc<NamedExpressionSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 16, RULE_namedExpressionSeq);
        let mut _localctx: Rc<NamedExpressionSeqContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(1327);
			recog.namedExpression()?;

			recog.base.set_state(1332);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1328);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1329);
				recog.namedExpression()?;

				}
				}
				recog.base.set_state(1334);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpression ----------------
pub type NamedExpressionContextAll<'input> = NamedExpressionContext<'input>;


pub type NamedExpressionContext<'input> = BaseParserRuleContext<'input,NamedExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NamedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NamedExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpression(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_namedExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NamedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_namedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpression }
}
antlr_rust::tid!{NamedExpressionContextExt<'a>}

impl<'input> NamedExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NamedExpressionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedExpressionContextAttrs<'input> for NamedExpressionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpression(&mut self,)
	-> Result<Rc<NamedExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 18, RULE_namedExpression);
        let mut _localctx: Rc<NamedExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(1335);
			recog.expression()?;

			recog.base.set_state(1343);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << AS) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
				{
				recog.base.set_state(1337);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==AS {
					{
					recog.base.set_state(1336);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					}
				}

				recog.base.set_state(1341);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ATTACH |
				 AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK | BZIP2 |
				 CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE | CATALOGS |
				 CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN | COLUMNS |
				 COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
				 CONNECT | CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY |
				 COUNT | CURRENT_ROLE | CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE |
				 DATE | DATETIME | DAY | DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF |
				 DEALLOCATE | DECLARE | DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER |
				 DENY | DESCRIBE | DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED |
				 DISTSTYLE | DETACH | DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE |
				 ENCODING | ERROR | EVEN | EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN |
				 EXTERNAL | FIELDS | FILTER | FINAL | FIRST | FORMAT | FRIDAY | FUNCTION |
				 FUNCTIONS | GENERATED | GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ |
				 GZIP | HEADER | HOUR | IDENTITY | IMMEDIATE | INCLUDE | INCLUDING |
				 INITIAL | INPUT | INPUTFORMAT | INTERLEAVED | INSERT | INVOKER | IO |
				 ISOLATION | ISOWEEK | ISOYEAR | ITERATE | ILIKE | JSON | KEEP | KEY |
				 KEYS | LAMBDA | LANGUAGE | LEAVE | LAST | LEADING | LEVEL | LIBRARY |
				 LINES | LISTAGG | LOCAL | LOCATION | LOCK | LOGICAL | LOOP | MAP | MASKING |
				 MATCH | MATCHED | MATCHES | MATERIALIZED | MAX | MEASURES | MESSAGE |
				 MICROSECOND | MILLISECOND | MIN | MINUS_KW | MINUTE | MODEL | MONDAY |
				 MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD | NONE | NORMALIZE | OBJECT |
				 OFFSET | OMIT | ONE | ONLY | OPTION | OPTIONS | OUTPUT | OUTPUTFORMAT |
				 OVERFLOW | PARTITIONED | PARTITIONS | PASSING | PAST | PATH | PATTERN |
				 PER | PERCENT_KW | PERIOD | PERMUTE | PIVOT | POSITION | PRECISION |
				 PREPARE | PRIOR | PROCEDURE | PRIVILEGES | PROPERTIES | PRUNE | QUARTER |
				 QUOTES | RAISE | READ | REFRESH | RENAME | REPEATABLE | REPLACE | RESET |
				 RESTRICT | RETURN | RETURNING | REMOTE | REPEAT | RETURNS | REVOKE |
				 RLS | ROLE | ROLES | ROLLBACK | ROW | RUNNING | SAFE | SAFE_CAST | SATURDAY |
				 SCALAR | SECOND | SCHEMA | SCHEMAS | SECURITY | SEEK | SEMI | SERDE |
				 SERDEPROPERTIES | SERIALIZABLE | SESSION | SETS | SHOW | SIMILAR | SNAPSHOT |
				 SORTKEY | START | STATS | STORED | SUBSET | SUBSTRING | SUNDAY | SYSTEM |
				 SYSTEM_TIME | TABLE | TABLES | TEMP | TEMPORARY | TERMINATED | TEXT |
				 STRING_KW | THURSDAY | TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF | TOP |
				 TRAILING | TARGET | SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM |
				 TRIM | TRUNCATE | TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED |
				 UNCONDITIONAL | UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED |
				 UNTIL | UPDATE | USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE |
				 VALUE | VALUES | VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK |
				 WHILE | WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE |
				 ZSTD | IDENTIFIER | BACKQUOTED_IDENTIFIER 
					=> {
						{
						/*InvokeRule identifier*/
						recog.base.set_state(1339);
						let tmp = recog.identifier()?;
						 cast_mut::<_,NamedExpressionContext >(&mut _localctx).name = Some(tmp.clone());
						  

						}
					}

				 LPAREN 
					=> {
						{
						/*InvokeRule identifierList*/
						recog.base.set_state(1340);
						recog.identifierList()?;

						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotNullClause ----------------
pub type UnpivotNullClauseContextAll<'input> = UnpivotNullClauseContext<'input>;


pub type UnpivotNullClauseContext<'input> = BaseParserRuleContext<'input,UnpivotNullClauseContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotNullClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for UnpivotNullClauseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnpivotNullClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotNullClause(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_unpivotNullClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnpivotNullClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unpivotNullClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotNullClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotNullClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotNullClause }
}
antlr_rust::tid!{UnpivotNullClauseContextExt<'a>}

impl<'input> UnpivotNullClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotNullClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotNullClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotNullClauseContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<UnpivotNullClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}

}

impl<'input> UnpivotNullClauseContextAttrs<'input> for UnpivotNullClauseContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotNullClause(&mut self,)
	-> Result<Rc<UnpivotNullClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotNullClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 20, RULE_unpivotNullClause);
        let mut _localctx: Rc<UnpivotNullClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1345);
			_la = recog.base.input.la(1);
			if { !(_la==EXCLUDE || _la==INCLUDE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1346);
			recog.base.match_token(NULLS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- locationSpec ----------------
pub type LocationSpecContextAll<'input> = LocationSpecContext<'input>;


pub type LocationSpecContext<'input> = BaseParserRuleContext<'input,LocationSpecContextExt<'input>>;

#[derive(Clone)]
pub struct LocationSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for LocationSpecContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LocationSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_locationSpec(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_locationSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LocationSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_locationSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for LocationSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_locationSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_locationSpec }
}
antlr_rust::tid!{LocationSpecContextExt<'a>}

impl<'input> LocationSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LocationSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LocationSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LocationSpecContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<LocationSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LocationSpecContextAttrs<'input> for LocationSpecContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn locationSpec(&mut self,)
	-> Result<Rc<LocationSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LocationSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 22, RULE_locationSpec);
        let mut _localctx: Rc<LocationSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1348);
			recog.base.match_token(LOCATION,&mut recog.err_handler)?;

			/*InvokeRule string*/
			recog.base.set_state(1349);
			recog.string()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- connectionSpec ----------------
pub type ConnectionSpecContextAll<'input> = ConnectionSpecContext<'input>;


pub type ConnectionSpecContext<'input> = BaseParserRuleContext<'input,ConnectionSpecContextExt<'input>>;

#[derive(Clone)]
pub struct ConnectionSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ConnectionSpecContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ConnectionSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_connectionSpec(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_connectionSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ConnectionSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_connectionSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConnectionSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_connectionSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_connectionSpec }
}
antlr_rust::tid!{ConnectionSpecContextExt<'a>}

impl<'input> ConnectionSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConnectionSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConnectionSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConnectionSpecContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ConnectionSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token CONNECTION
/// Returns `None` if there is no child corresponding to token CONNECTION
fn CONNECTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CONNECTION, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ConnectionSpecContextAttrs<'input> for ConnectionSpecContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn connectionSpec(&mut self,)
	-> Result<Rc<ConnectionSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConnectionSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 24, RULE_connectionSpec);
        let mut _localctx: Rc<ConnectionSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1351);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(1352);
			recog.base.match_token(CONNECTION,&mut recog.err_handler)?;

			/*InvokeRule qualifiedName*/
			recog.base.set_state(1353);
			recog.qualifiedName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- query ----------------
pub type QueryContextAll<'input> = QueryContext<'input>;


pub type QueryContext<'input> = BaseParserRuleContext<'input,QueryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QueryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_query(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_query(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_query(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_query }
	//fn type_rule_index() -> usize where Self: Sized { RULE_query }
}
antlr_rust::tid!{QueryContextExt<'a>}

impl<'input> QueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QueryContextExt<'input>>{

fn queryNoWith(&self) -> Option<Rc<QueryNoWithContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn with(&self) -> Option<Rc<WithContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryContextAttrs<'input> for QueryContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn query(&mut self,)
	-> Result<Rc<QueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 26, RULE_query);
        let mut _localctx: Rc<QueryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1356);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WITH {
				{
				/*InvokeRule with*/
				recog.base.set_state(1355);
				recog.with()?;

				}
			}

			/*InvokeRule queryNoWith*/
			recog.base.set_state(1358);
			recog.queryNoWith()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- with ----------------
pub type WithContextAll<'input> = WithContext<'input>;


pub type WithContext<'input> = BaseParserRuleContext<'input,WithContextExt<'input>>;

#[derive(Clone)]
pub struct WithContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for WithContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for WithContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_with(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_with(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for WithContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_with(self);
	}
}

impl<'input> CustomRuleContext<'input> for WithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_with }
	//fn type_rule_index() -> usize where Self: Sized { RULE_with }
}
antlr_rust::tid!{WithContextExt<'a>}

impl<'input> WithContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WithContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WithContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WithContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<WithContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn namedQuery_all(&self) ->  Vec<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedQuery(&self, i: usize) -> Option<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RECURSIVE
/// Returns `None` if there is no child corresponding to token RECURSIVE
fn RECURSIVE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RECURSIVE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WithContextAttrs<'input> for WithContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn with(&mut self,)
	-> Result<Rc<WithContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WithContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 28, RULE_with);
        let mut _localctx: Rc<WithContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1360);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(1362);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==RECURSIVE {
				{
				recog.base.set_state(1361);
				recog.base.match_token(RECURSIVE,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule namedQuery*/
			recog.base.set_state(1364);
			recog.namedQuery()?;

			recog.base.set_state(1369);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1365);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedQuery*/
				recog.base.set_state(1366);
				recog.namedQuery()?;

				}
				}
				recog.base.set_state(1371);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableElement ----------------
pub type TableElementContextAll<'input> = TableElementContext<'input>;


pub type TableElementContext<'input> = BaseParserRuleContext<'input,TableElementContextExt<'input>>;

#[derive(Clone)]
pub struct TableElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TableElementContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableElementContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableElement(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_tableElement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableElementContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableElement(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableElement }
}
antlr_rust::tid!{TableElementContextExt<'a>}

impl<'input> TableElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableElementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableElementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableElementContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TableElementContextExt<'input>>{

fn columnDefinition(&self) -> Option<Rc<ColumnDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableElementContextAttrs<'input> for TableElementContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableElement(&mut self,)
	-> Result<Rc<TableElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 30, RULE_tableElement);
        let mut _localctx: Rc<TableElementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnDefinition*/
			recog.base.set_state(1372);
			recog.columnDefinition()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnDefinition ----------------
pub type ColumnDefinitionContextAll<'input> = ColumnDefinitionContext<'input>;


pub type ColumnDefinitionContext<'input> = BaseParserRuleContext<'input,ColumnDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnDefinition }
}
antlr_rust::tid!{ColumnDefinitionContextExt<'a>}

impl<'input> ColumnDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnDefinitionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnDefinitionContextExt<'input>>{

fn fieldDefinition(&self) -> Option<Rc<FieldDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnDefinitionContextAttrs<'input> for ColumnDefinitionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnDefinition(&mut self,)
	-> Result<Rc<ColumnDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 32, RULE_columnDefinition);
        let mut _localctx: Rc<ColumnDefinitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule fieldDefinition*/
			recog.base.set_state(1374);
			recog.fieldDefinition()?;

			recog.base.set_state(1377);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WITH {
				{
				recog.base.set_state(1375);
				recog.base.match_token(WITH,&mut recog.err_handler)?;

				/*InvokeRule properties*/
				recog.base.set_state(1376);
				recog.properties()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fieldDefinition ----------------
pub type FieldDefinitionContextAll<'input> = FieldDefinitionContext<'input>;


pub type FieldDefinitionContext<'input> = BaseParserRuleContext<'input,FieldDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct FieldDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FieldDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FieldDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fieldDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_fieldDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FieldDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_fieldDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for FieldDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fieldDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fieldDefinition }
}
antlr_rust::tid!{FieldDefinitionContextExt<'a>}

impl<'input> FieldDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FieldDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FieldDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FieldDefinitionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FieldDefinitionContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnSchemaWithMetadata(&self) -> Option<Rc<ColumnSchemaWithMetadataContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FieldDefinitionContextAttrs<'input> for FieldDefinitionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fieldDefinition(&mut self,)
	-> Result<Rc<FieldDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FieldDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 34, RULE_fieldDefinition);
        let mut _localctx: Rc<FieldDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnName*/
			recog.base.set_state(1379);
			recog.columnName()?;

			/*InvokeRule columnSchemaWithMetadata*/
			recog.base.set_state(1380);
			recog.columnSchemaWithMetadata()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnName ----------------
pub type ColumnNameContextAll<'input> = ColumnNameContext<'input>;


pub type ColumnNameContext<'input> = BaseParserRuleContext<'input,ColumnNameContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnNameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnNameContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnName(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnName(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnName }
}
antlr_rust::tid!{ColumnNameContextExt<'a>}

impl<'input> ColumnNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnNameContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameContextAttrs<'input> for ColumnNameContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnName(&mut self,)
	-> Result<Rc<ColumnNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 36, RULE_columnName);
        let mut _localctx: Rc<ColumnNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1382);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameComponent ----------------
pub type ColumnNameComponentContextAll<'input> = ColumnNameComponentContext<'input>;


pub type ColumnNameComponentContext<'input> = BaseParserRuleContext<'input,ColumnNameComponentContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameComponentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnNameComponentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnNameComponentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameComponent(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnNameComponent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnNameComponentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnNameComponent(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnNameComponentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameComponent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameComponent }
}
antlr_rust::tid!{ColumnNameComponentContextExt<'a>}

impl<'input> ColumnNameComponentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameComponentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameComponentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameComponentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnNameComponentContextExt<'input>>{

fn pathComponent(&self) -> Option<Rc<PathComponentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameComponentContextAttrs<'input> for ColumnNameComponentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameComponent(&mut self,)
	-> Result<Rc<ColumnNameComponentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameComponentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 38, RULE_columnNameComponent);
        let mut _localctx: Rc<ColumnNameComponentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule pathComponent*/
			recog.base.set_state(1384);
			recog.pathComponent()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnSchemaWithMetadata ----------------
pub type ColumnSchemaWithMetadataContextAll<'input> = ColumnSchemaWithMetadataContext<'input>;


pub type ColumnSchemaWithMetadataContext<'input> = BaseParserRuleContext<'input,ColumnSchemaWithMetadataContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnSchemaWithMetadataContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnSchemaWithMetadataContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnSchemaWithMetadataContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnSchemaWithMetadata(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnSchemaWithMetadata(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnSchemaWithMetadataContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnSchemaWithMetadata(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaWithMetadataContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchemaWithMetadata }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchemaWithMetadata }
}
antlr_rust::tid!{ColumnSchemaWithMetadataContextExt<'a>}

impl<'input> ColumnSchemaWithMetadataContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnSchemaWithMetadataContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnSchemaWithMetadataContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnSchemaWithMetadataContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnSchemaWithMetadataContextExt<'input>>{

fn columnSchema(&self) -> Option<Rc<ColumnSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONS
/// Returns `None` if there is no child corresponding to token OPTIONS
fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
fn columnOptionList(&self) -> Option<Rc<ColumnOptionListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnSchemaWithMetadataContextAttrs<'input> for ColumnSchemaWithMetadataContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnSchemaWithMetadata(&mut self,)
	-> Result<Rc<ColumnSchemaWithMetadataContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnSchemaWithMetadataContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 40, RULE_columnSchemaWithMetadata);
        let mut _localctx: Rc<ColumnSchemaWithMetadataContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnSchema*/
			recog.base.set_state(1386);
			recog.columnSchema()?;

			recog.base.set_state(1391);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==NOT || _la==NULL {
				{
				recog.base.set_state(1388);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==NOT {
					{
					recog.base.set_state(1387);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					}
				}

				recog.base.set_state(1390);
				recog.base.match_token(NULL,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1399);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==OPTIONS {
				{
				recog.base.set_state(1393);
				recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

				recog.base.set_state(1394);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				recog.base.set_state(1396);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
					{
					/*InvokeRule columnOptionList*/
					recog.base.set_state(1395);
					recog.columnOptionList()?;

					}
				}

				recog.base.set_state(1398);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnOptionList ----------------
pub type ColumnOptionListContextAll<'input> = ColumnOptionListContext<'input>;


pub type ColumnOptionListContext<'input> = BaseParserRuleContext<'input,ColumnOptionListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnOptionListContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnOptionListContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnOptionListContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnOptionList(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnOptionList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnOptionListContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnOptionList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnOptionListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnOptionList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnOptionList }
}
antlr_rust::tid!{ColumnOptionListContextExt<'a>}

impl<'input> ColumnOptionListContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnOptionListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnOptionListContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnOptionListContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnOptionListContextExt<'input>>{

fn columnOption_all(&self) ->  Vec<Rc<ColumnOptionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnOption(&self, i: usize) -> Option<Rc<ColumnOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnOptionListContextAttrs<'input> for ColumnOptionListContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnOptionList(&mut self,)
	-> Result<Rc<ColumnOptionListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnOptionListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 42, RULE_columnOptionList);
        let mut _localctx: Rc<ColumnOptionListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnOption*/
			recog.base.set_state(1401);
			recog.columnOption()?;

			recog.base.set_state(1406);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(149,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1402);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule columnOption*/
					recog.base.set_state(1403);
					recog.columnOption()?;

					}
					} 
				}
				recog.base.set_state(1408);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(149,&mut recog.base)?;
			}
			recog.base.set_state(1410);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1409);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnOptionListContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnOption ----------------
pub type ColumnOptionContextAll<'input> = ColumnOptionContext<'input>;


pub type ColumnOptionContext<'input> = BaseParserRuleContext<'input,ColumnOptionContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnOptionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnOptionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnOption(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnOptionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnOption(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnOption }
}
antlr_rust::tid!{ColumnOptionContextExt<'a>}

impl<'input> ColumnOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnOptionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnOptionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnOptionContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnOptionContextAttrs<'input> for ColumnOptionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnOption(&mut self,)
	-> Result<Rc<ColumnOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 44, RULE_columnOption);
        let mut _localctx: Rc<ColumnOptionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1412);
			recog.identifier()?;

			recog.base.set_state(1413);
			recog.base.match_token(EQ,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1414);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnSchema ----------------
#[derive(Debug)]
pub enum ColumnSchemaContextAll<'input>{
	ColumnSchemaSimpleTypeContext(ColumnSchemaSimpleTypeContext<'input>),
	ColumnSchemaArrayContext(ColumnSchemaArrayContext<'input>),
	ColumnSchemaStructContext(ColumnSchemaStructContext<'input>),
Error(ColumnSchemaContext<'input>)
}
antlr_rust::tid!{ColumnSchemaContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ColumnSchemaContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for ColumnSchemaContextAll<'input>{}

impl<'input> Deref for ColumnSchemaContextAll<'input>{
	type Target = dyn ColumnSchemaContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ColumnSchemaContextAll::*;
		match self{
			ColumnSchemaSimpleTypeContext(inner) => inner,
			ColumnSchemaArrayContext(inner) => inner,
			ColumnSchemaStructContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnSchemaContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnSchemaContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ColumnSchemaContext<'input> = BaseParserRuleContext<'input,ColumnSchemaContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnSchemaContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnSchemaContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnSchemaContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchema }
}
antlr_rust::tid!{ColumnSchemaContextExt<'a>}

impl<'input> ColumnSchemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnSchemaContextAll<'input>> {
		Rc::new(
		ColumnSchemaContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnSchemaContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ColumnSchemaContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnSchemaContextExt<'input>>{


}

impl<'input> ColumnSchemaContextAttrs<'input> for ColumnSchemaContext<'input>{}

pub type ColumnSchemaSimpleTypeContext<'input> = BaseParserRuleContext<'input,ColumnSchemaSimpleTypeContextExt<'input>>;

pub trait ColumnSchemaSimpleTypeContextAttrs<'input>: BigqueryParserContext<'input>{
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ColumnSchemaSimpleTypeContextAttrs<'input> for ColumnSchemaSimpleTypeContext<'input>{}

pub struct ColumnSchemaSimpleTypeContextExt<'input>{
	base:ColumnSchemaContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnSchemaSimpleTypeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ColumnSchemaSimpleTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnSchemaSimpleTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnSchemaSimpleType(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_columnSchemaSimpleType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnSchemaSimpleTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnSchemaSimpleType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaSimpleTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchema }
}

impl<'input> Borrow<ColumnSchemaContextExt<'input>> for ColumnSchemaSimpleTypeContext<'input>{
	fn borrow(&self) -> &ColumnSchemaContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnSchemaContextExt<'input>> for ColumnSchemaSimpleTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnSchemaContextExt<'input> { &mut self.base }
}

impl<'input> ColumnSchemaContextAttrs<'input> for ColumnSchemaSimpleTypeContext<'input> {}

impl<'input> ColumnSchemaSimpleTypeContextExt<'input>{
	fn new(ctx: &dyn ColumnSchemaContextAttrs<'input>) -> Rc<ColumnSchemaContextAll<'input>>  {
		Rc::new(
			ColumnSchemaContextAll::ColumnSchemaSimpleTypeContext(
				BaseParserRuleContext::copy_from(ctx,ColumnSchemaSimpleTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ColumnSchemaArrayContext<'input> = BaseParserRuleContext<'input,ColumnSchemaArrayContextExt<'input>>;

pub trait ColumnSchemaArrayContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	fn arrayElementSchema(&self) -> Option<Rc<ArrayElementSchemaContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
}

impl<'input> ColumnSchemaArrayContextAttrs<'input> for ColumnSchemaArrayContext<'input>{}

pub struct ColumnSchemaArrayContextExt<'input>{
	base:ColumnSchemaContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnSchemaArrayContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ColumnSchemaArrayContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnSchemaArrayContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnSchemaArray(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_columnSchemaArray(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnSchemaArrayContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnSchemaArray(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaArrayContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchema }
}

impl<'input> Borrow<ColumnSchemaContextExt<'input>> for ColumnSchemaArrayContext<'input>{
	fn borrow(&self) -> &ColumnSchemaContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnSchemaContextExt<'input>> for ColumnSchemaArrayContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnSchemaContextExt<'input> { &mut self.base }
}

impl<'input> ColumnSchemaContextAttrs<'input> for ColumnSchemaArrayContext<'input> {}

impl<'input> ColumnSchemaArrayContextExt<'input>{
	fn new(ctx: &dyn ColumnSchemaContextAttrs<'input>) -> Rc<ColumnSchemaContextAll<'input>>  {
		Rc::new(
			ColumnSchemaContextAll::ColumnSchemaArrayContext(
				BaseParserRuleContext::copy_from(ctx,ColumnSchemaArrayContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ColumnSchemaStructContext<'input> = BaseParserRuleContext<'input,ColumnSchemaStructContextExt<'input>>;

pub trait ColumnSchemaStructContextAttrs<'input>: BigqueryParserContext<'input>{
	fn structDefinition(&self) -> Option<Rc<StructDefinitionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ColumnSchemaStructContextAttrs<'input> for ColumnSchemaStructContext<'input>{}

pub struct ColumnSchemaStructContextExt<'input>{
	base:ColumnSchemaContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnSchemaStructContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ColumnSchemaStructContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnSchemaStructContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnSchemaStruct(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_columnSchemaStruct(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnSchemaStructContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnSchemaStruct(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaStructContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchema }
}

impl<'input> Borrow<ColumnSchemaContextExt<'input>> for ColumnSchemaStructContext<'input>{
	fn borrow(&self) -> &ColumnSchemaContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnSchemaContextExt<'input>> for ColumnSchemaStructContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnSchemaContextExt<'input> { &mut self.base }
}

impl<'input> ColumnSchemaContextAttrs<'input> for ColumnSchemaStructContext<'input> {}

impl<'input> ColumnSchemaStructContextExt<'input>{
	fn new(ctx: &dyn ColumnSchemaContextAttrs<'input>) -> Rc<ColumnSchemaContextAll<'input>>  {
		Rc::new(
			ColumnSchemaContextAll::ColumnSchemaStructContext(
				BaseParserRuleContext::copy_from(ctx,ColumnSchemaStructContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnSchema(&mut self,)
	-> Result<Rc<ColumnSchemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnSchemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 46, RULE_columnSchema);
        let mut _localctx: Rc<ColumnSchemaContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1423);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(151,&mut recog.base)? {
				1 =>{
					let tmp = ColumnSchemaSimpleTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule type_*/
					recog.base.set_state(1416);
					recog.type_()?;

					}
				}
			,
				2 =>{
					let tmp = ColumnSchemaStructContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule structDefinition*/
					recog.base.set_state(1417);
					recog.structDefinition()?;

					}
				}
			,
				3 =>{
					let tmp = ColumnSchemaArrayContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(1418);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(1419);
					recog.base.match_token(LT,&mut recog.err_handler)?;

					/*InvokeRule arrayElementSchema*/
					recog.base.set_state(1420);
					recog.arrayElementSchema()?;

					recog.base.set_state(1421);
					recog.base.match_token(GT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fieldList ----------------
pub type FieldListContextAll<'input> = FieldListContext<'input>;


pub type FieldListContext<'input> = BaseParserRuleContext<'input,FieldListContextExt<'input>>;

#[derive(Clone)]
pub struct FieldListContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FieldListContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FieldListContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fieldList(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_fieldList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FieldListContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_fieldList(self);
	}
}

impl<'input> CustomRuleContext<'input> for FieldListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fieldList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fieldList }
}
antlr_rust::tid!{FieldListContextExt<'a>}

impl<'input> FieldListContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FieldListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FieldListContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FieldListContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FieldListContextExt<'input>>{

fn fieldDefinition_all(&self) ->  Vec<Rc<FieldDefinitionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn fieldDefinition(&self, i: usize) -> Option<Rc<FieldDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> FieldListContextAttrs<'input> for FieldListContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fieldList(&mut self,)
	-> Result<Rc<FieldListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FieldListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 48, RULE_fieldList);
        let mut _localctx: Rc<FieldListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule fieldDefinition*/
			recog.base.set_state(1425);
			recog.fieldDefinition()?;

			recog.base.set_state(1430);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(152,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1426);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule fieldDefinition*/
					recog.base.set_state(1427);
					recog.fieldDefinition()?;

					}
					} 
				}
				recog.base.set_state(1432);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(152,&mut recog.base)?;
			}
			recog.base.set_state(1434);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1433);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,FieldListContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- arrayElementSchema ----------------
pub type ArrayElementSchemaContextAll<'input> = ArrayElementSchemaContext<'input>;


pub type ArrayElementSchemaContext<'input> = BaseParserRuleContext<'input,ArrayElementSchemaContextExt<'input>>;

#[derive(Clone)]
pub struct ArrayElementSchemaContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ArrayElementSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ArrayElementSchemaContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_arrayElementSchema(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_arrayElementSchema(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ArrayElementSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_arrayElementSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArrayElementSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_arrayElementSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_arrayElementSchema }
}
antlr_rust::tid!{ArrayElementSchemaContextExt<'a>}

impl<'input> ArrayElementSchemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ArrayElementSchemaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ArrayElementSchemaContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ArrayElementSchemaContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ArrayElementSchemaContextExt<'input>>{

fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn structDefinition(&self) -> Option<Rc<StructDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}

}

impl<'input> ArrayElementSchemaContextAttrs<'input> for ArrayElementSchemaContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn arrayElementSchema(&mut self,)
	-> Result<Rc<ArrayElementSchemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ArrayElementSchemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 50, RULE_arrayElementSchema);
        let mut _localctx: Rc<ArrayElementSchemaContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1442);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(155,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule type_*/
					recog.base.set_state(1436);
					recog.type_()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule structDefinition*/
					recog.base.set_state(1437);
					recog.structDefinition()?;

					recog.base.set_state(1440);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(1438);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(1439);
						recog.base.match_token(NULL,&mut recog.err_handler)?;

						}
					}

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- structDefinition ----------------
pub type StructDefinitionContextAll<'input> = StructDefinitionContext<'input>;


pub type StructDefinitionContext<'input> = BaseParserRuleContext<'input,StructDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct StructDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for StructDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StructDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_structDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_structDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StructDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_structDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for StructDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_structDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_structDefinition }
}
antlr_rust::tid!{StructDefinitionContextExt<'a>}

impl<'input> StructDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StructDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StructDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StructDefinitionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<StructDefinitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STRUCT
/// Returns `None` if there is no child corresponding to token STRUCT
fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token LT
/// Returns `None` if there is no child corresponding to token LT
fn LT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LT, 0)
}
fn fieldList(&self) -> Option<Rc<FieldListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token GT
/// Returns `None` if there is no child corresponding to token GT
fn GT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GT, 0)
}

}

impl<'input> StructDefinitionContextAttrs<'input> for StructDefinitionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn structDefinition(&mut self,)
	-> Result<Rc<StructDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StructDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 52, RULE_structDefinition);
        let mut _localctx: Rc<StructDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1444);
			recog.base.match_token(STRUCT,&mut recog.err_handler)?;

			recog.base.set_state(1445);
			recog.base.match_token(LT,&mut recog.err_handler)?;

			/*InvokeRule fieldList*/
			recog.base.set_state(1446);
			recog.fieldList()?;

			recog.base.set_state(1447);
			recog.base.match_token(GT,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- properties ----------------
pub type PropertiesContextAll<'input> = PropertiesContext<'input>;


pub type PropertiesContext<'input> = BaseParserRuleContext<'input,PropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct PropertiesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_properties(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_properties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_properties(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_properties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_properties }
}
antlr_rust::tid!{PropertiesContextExt<'a>}

impl<'input> PropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertiesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertiesContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn propertyAssignments(&self) -> Option<Rc<PropertyAssignmentsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertiesContextAttrs<'input> for PropertiesContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn properties(&mut self,)
	-> Result<Rc<PropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 54, RULE_properties);
        let mut _localctx: Rc<PropertiesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1449);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(1451);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
				{
				/*InvokeRule propertyAssignments*/
				recog.base.set_state(1450);
				recog.propertyAssignments()?;

				}
			}

			recog.base.set_state(1453);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyAssignments ----------------
pub type PropertyAssignmentsContextAll<'input> = PropertyAssignmentsContext<'input>;


pub type PropertyAssignmentsContext<'input> = BaseParserRuleContext<'input,PropertyAssignmentsContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyAssignmentsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PropertyAssignmentsContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PropertyAssignmentsContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyAssignments(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_propertyAssignments(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PropertyAssignmentsContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_propertyAssignments(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyAssignmentsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyAssignments }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyAssignments }
}
antlr_rust::tid!{PropertyAssignmentsContextExt<'a>}

impl<'input> PropertyAssignmentsContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyAssignmentsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyAssignmentsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyAssignmentsContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PropertyAssignmentsContextExt<'input>>{

fn property_all(&self) ->  Vec<Rc<PropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn property(&self, i: usize) -> Option<Rc<PropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PropertyAssignmentsContextAttrs<'input> for PropertyAssignmentsContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyAssignments(&mut self,)
	-> Result<Rc<PropertyAssignmentsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyAssignmentsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 56, RULE_propertyAssignments);
        let mut _localctx: Rc<PropertyAssignmentsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule property*/
			recog.base.set_state(1455);
			recog.property()?;

			recog.base.set_state(1460);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(157,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1456);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule property*/
					recog.base.set_state(1457);
					recog.property()?;

					}
					} 
				}
				recog.base.set_state(1462);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(157,&mut recog.base)?;
			}
			recog.base.set_state(1464);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1463);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,PropertyAssignmentsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- property ----------------
#[derive(Debug)]
pub enum PropertyContextAll<'input>{
	DefaultPropertyContext(DefaultPropertyContext<'input>),
	NestedPropertyContext(NestedPropertyContext<'input>),
Error(PropertyContext<'input>)
}
antlr_rust::tid!{PropertyContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PropertyContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PropertyContextAll<'input>{}

impl<'input> Deref for PropertyContextAll<'input>{
	type Target = dyn PropertyContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PropertyContextAll::*;
		match self{
			DefaultPropertyContext(inner) => inner,
			NestedPropertyContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PropertyContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PropertyContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PropertyContext<'input> = BaseParserRuleContext<'input,PropertyContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PropertyContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PropertyContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PropertyContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}
antlr_rust::tid!{PropertyContextExt<'a>}

impl<'input> PropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyContextAll<'input>> {
		Rc::new(
		PropertyContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PropertyContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PropertyContextExt<'input>>{


}

impl<'input> PropertyContextAttrs<'input> for PropertyContext<'input>{}

pub type DefaultPropertyContext<'input> = BaseParserRuleContext<'input,DefaultPropertyContextExt<'input>>;

pub trait DefaultPropertyContextAttrs<'input>: BigqueryParserContext<'input>{
	fn propertyKey(&self) -> Option<Rc<PropertyKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn propertyValue(&self) -> Option<Rc<PropertyValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DefaultPropertyContextAttrs<'input> for DefaultPropertyContext<'input>{}

pub struct DefaultPropertyContextExt<'input>{
	base:PropertyContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultPropertyContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DefaultPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DefaultPropertyContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultProperty(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_defaultProperty(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DefaultPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_defaultProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}

impl<'input> Borrow<PropertyContextExt<'input>> for DefaultPropertyContext<'input>{
	fn borrow(&self) -> &PropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyContextExt<'input>> for DefaultPropertyContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyContextExt<'input> { &mut self.base }
}

impl<'input> PropertyContextAttrs<'input> for DefaultPropertyContext<'input> {}

impl<'input> DefaultPropertyContextExt<'input>{
	fn new(ctx: &dyn PropertyContextAttrs<'input>) -> Rc<PropertyContextAll<'input>>  {
		Rc::new(
			PropertyContextAll::DefaultPropertyContext(
				BaseParserRuleContext::copy_from(ctx,DefaultPropertyContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NestedPropertyContext<'input> = BaseParserRuleContext<'input,NestedPropertyContextExt<'input>>;

pub trait NestedPropertyContextAttrs<'input>: BigqueryParserContext<'input>{
	fn propertyKey(&self) -> Option<Rc<PropertyKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn property_all(&self) ->  Vec<Rc<PropertyContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn property(&self, i: usize) -> Option<Rc<PropertyContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> NestedPropertyContextAttrs<'input> for NestedPropertyContext<'input>{}

pub struct NestedPropertyContextExt<'input>{
	base:PropertyContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NestedPropertyContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for NestedPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NestedPropertyContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nestedProperty(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_nestedProperty(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NestedPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_nestedProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for NestedPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}

impl<'input> Borrow<PropertyContextExt<'input>> for NestedPropertyContext<'input>{
	fn borrow(&self) -> &PropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyContextExt<'input>> for NestedPropertyContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyContextExt<'input> { &mut self.base }
}

impl<'input> PropertyContextAttrs<'input> for NestedPropertyContext<'input> {}

impl<'input> NestedPropertyContextExt<'input>{
	fn new(ctx: &dyn PropertyContextAttrs<'input>) -> Rc<PropertyContextAll<'input>>  {
		Rc::new(
			PropertyContextAll::NestedPropertyContext(
				BaseParserRuleContext::copy_from(ctx,NestedPropertyContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn property(&mut self,)
	-> Result<Rc<PropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 58, RULE_property);
        let mut _localctx: Rc<PropertyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1481);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(160,&mut recog.base)? {
				1 =>{
					let tmp = NestedPropertyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule propertyKey*/
					recog.base.set_state(1466);
					recog.propertyKey()?;

					recog.base.set_state(1467);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					recog.base.set_state(1468);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1472);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						{
						/*InvokeRule property*/
						recog.base.set_state(1469);
						recog.property()?;

						}
						}
						recog.base.set_state(1474);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1475);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = DefaultPropertyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule propertyKey*/
					recog.base.set_state(1477);
					recog.propertyKey()?;

					recog.base.set_state(1478);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule propertyValue*/
					recog.base.set_state(1479);
					recog.propertyValue()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyKey ----------------
pub type PropertyKeyContextAll<'input> = PropertyKeyContext<'input>;


pub type PropertyKeyContext<'input> = BaseParserRuleContext<'input,PropertyKeyContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyKeyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PropertyKeyContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PropertyKeyContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyKey(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_propertyKey(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PropertyKeyContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_propertyKey(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyKeyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyKey }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyKey }
}
antlr_rust::tid!{PropertyKeyContextExt<'a>}

impl<'input> PropertyKeyContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyKeyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyKeyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyKeyContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PropertyKeyContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertyKeyContextAttrs<'input> for PropertyKeyContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyKey(&mut self,)
	-> Result<Rc<PropertyKeyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyKeyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 60, RULE_propertyKey);
        let mut _localctx: Rc<PropertyKeyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1483);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyValue ----------------
#[derive(Debug)]
pub enum PropertyValueContextAll<'input>{
	ExpressionPropertyValueContext(ExpressionPropertyValueContext<'input>),
	DefaultPropertyValueContext(DefaultPropertyValueContext<'input>),
	IdentifierPropertyValueContext(IdentifierPropertyValueContext<'input>),
Error(PropertyValueContext<'input>)
}
antlr_rust::tid!{PropertyValueContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PropertyValueContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PropertyValueContextAll<'input>{}

impl<'input> Deref for PropertyValueContextAll<'input>{
	type Target = dyn PropertyValueContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PropertyValueContextAll::*;
		match self{
			ExpressionPropertyValueContext(inner) => inner,
			DefaultPropertyValueContext(inner) => inner,
			IdentifierPropertyValueContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PropertyValueContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PropertyValueContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PropertyValueContext<'input> = BaseParserRuleContext<'input,PropertyValueContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PropertyValueContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PropertyValueContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}
antlr_rust::tid!{PropertyValueContextExt<'a>}

impl<'input> PropertyValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyValueContextAll<'input>> {
		Rc::new(
		PropertyValueContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyValueContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PropertyValueContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PropertyValueContextExt<'input>>{


}

impl<'input> PropertyValueContextAttrs<'input> for PropertyValueContext<'input>{}

pub type ExpressionPropertyValueContext<'input> = BaseParserRuleContext<'input,ExpressionPropertyValueContextExt<'input>>;

pub trait ExpressionPropertyValueContextAttrs<'input>: BigqueryParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExpressionPropertyValueContextAttrs<'input> for ExpressionPropertyValueContext<'input>{}

pub struct ExpressionPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExpressionPropertyValueContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ExpressionPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ExpressionPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_expressionPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_expressionPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ExpressionPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_expressionPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for ExpressionPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for ExpressionPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for ExpressionPropertyValueContext<'input> {}

impl<'input> ExpressionPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::ExpressionPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,ExpressionPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DefaultPropertyValueContext<'input> = BaseParserRuleContext<'input,DefaultPropertyValueContextExt<'input>>;

pub trait DefaultPropertyValueContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DEFAULT
	/// Returns `None` if there is no child corresponding to token DEFAULT
	fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DEFAULT, 0)
	}
}

impl<'input> DefaultPropertyValueContextAttrs<'input> for DefaultPropertyValueContext<'input>{}

pub struct DefaultPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultPropertyValueContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DefaultPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DefaultPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_defaultPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DefaultPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_defaultPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for DefaultPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for DefaultPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for DefaultPropertyValueContext<'input> {}

impl<'input> DefaultPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::DefaultPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,DefaultPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IdentifierPropertyValueContext<'input> = BaseParserRuleContext<'input,IdentifierPropertyValueContextExt<'input>>;

pub trait IdentifierPropertyValueContextAttrs<'input>: BigqueryParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IdentifierPropertyValueContextAttrs<'input> for IdentifierPropertyValueContext<'input>{}

pub struct IdentifierPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IdentifierPropertyValueContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for IdentifierPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IdentifierPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_identifierPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_identifierPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IdentifierPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_identifierPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for IdentifierPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for IdentifierPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for IdentifierPropertyValueContext<'input> {}

impl<'input> IdentifierPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::IdentifierPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,IdentifierPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyValue(&mut self,)
	-> Result<Rc<PropertyValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 62, RULE_propertyValue);
        let mut _localctx: Rc<PropertyValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1488);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(161,&mut recog.base)? {
				1 =>{
					let tmp = DefaultPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1485);
					recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = IdentifierPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1486);
					recog.identifier()?;

					}
				}
			,
				3 =>{
					let tmp = ExpressionPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(1487);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryNoWith ----------------
pub type QueryNoWithContextAll<'input> = QueryNoWithContext<'input>;


pub type QueryNoWithContext<'input> = BaseParserRuleContext<'input,QueryNoWithContextExt<'input>>;

#[derive(Clone)]
pub struct QueryNoWithContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QueryNoWithContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryNoWithContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryNoWith(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_queryNoWith(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryNoWithContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_queryNoWith(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryNoWithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryNoWith }
}
antlr_rust::tid!{QueryNoWithContextExt<'a>}

impl<'input> QueryNoWithContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryNoWithContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryNoWithContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryNoWithContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QueryNoWithContextExt<'input>>{

fn queryLimit(&self) -> Option<Rc<QueryLimitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryNoWithContextAttrs<'input> for QueryNoWithContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryNoWith(&mut self,)
	-> Result<Rc<QueryNoWithContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryNoWithContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 64, RULE_queryNoWith);
        let mut _localctx: Rc<QueryNoWithContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryLimit*/
			recog.base.set_state(1490);
			recog.queryLimit()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryLimit ----------------
pub type QueryLimitContextAll<'input> = QueryLimitContext<'input>;


pub type QueryLimitContext<'input> = BaseParserRuleContext<'input,QueryLimitContextExt<'input>>;

#[derive(Clone)]
pub struct QueryLimitContextExt<'input>{
	pub limit: Option<Rc<LimitRowCountContextAll<'input>>>,
	pub offset: Option<Rc<RowCountContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QueryLimitContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryLimitContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryLimit(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_queryLimit(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryLimitContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_queryLimit(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryLimitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimit }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimit }
}
antlr_rust::tid!{QueryLimitContextExt<'a>}

impl<'input> QueryLimitContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryLimitContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryLimitContextExt{
				limit: None, offset: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryLimitContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QueryLimitContextExt<'input>>{

fn queryLimitTarget(&self) -> Option<Rc<QueryLimitTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
fn limitRowCount(&self) -> Option<Rc<LimitRowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
fn rowCount(&self) -> Option<Rc<RowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryLimitContextAttrs<'input> for QueryLimitContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryLimit(&mut self,)
	-> Result<Rc<QueryLimitContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryLimitContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 66, RULE_queryLimit);
        let mut _localctx: Rc<QueryLimitContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryLimitTarget*/
			recog.base.set_state(1492);
			recog.queryLimitTarget()?;

			recog.base.set_state(1499);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LIMIT {
				{
				recog.base.set_state(1493);
				recog.base.match_token(LIMIT,&mut recog.err_handler)?;

				/*InvokeRule limitRowCount*/
				recog.base.set_state(1494);
				let tmp = recog.limitRowCount()?;
				 cast_mut::<_,QueryLimitContext >(&mut _localctx).limit = Some(tmp.clone());
				  

				recog.base.set_state(1497);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==OFFSET {
					{
					recog.base.set_state(1495);
					recog.base.match_token(OFFSET,&mut recog.err_handler)?;

					/*InvokeRule rowCount*/
					recog.base.set_state(1496);
					let tmp = recog.rowCount()?;
					 cast_mut::<_,QueryLimitContext >(&mut _localctx).offset = Some(tmp.clone());
					  

					}
				}

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryLimitTarget ----------------
#[derive(Debug)]
pub enum QueryLimitTargetContextAll<'input>{
	QueryLimitTargetDefaultContext(QueryLimitTargetDefaultContext<'input>),
Error(QueryLimitTargetContext<'input>)
}
antlr_rust::tid!{QueryLimitTargetContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QueryLimitTargetContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for QueryLimitTargetContextAll<'input>{}

impl<'input> Deref for QueryLimitTargetContextAll<'input>{
	type Target = dyn QueryLimitTargetContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QueryLimitTargetContextAll::*;
		match self{
			QueryLimitTargetDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryLimitTargetContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryLimitTargetContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QueryLimitTargetContext<'input> = BaseParserRuleContext<'input,QueryLimitTargetContextExt<'input>>;

#[derive(Clone)]
pub struct QueryLimitTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QueryLimitTargetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryLimitTargetContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryLimitTargetContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QueryLimitTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimitTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimitTarget }
}
antlr_rust::tid!{QueryLimitTargetContextExt<'a>}

impl<'input> QueryLimitTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryLimitTargetContextAll<'input>> {
		Rc::new(
		QueryLimitTargetContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryLimitTargetContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QueryLimitTargetContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QueryLimitTargetContextExt<'input>>{


}

impl<'input> QueryLimitTargetContextAttrs<'input> for QueryLimitTargetContext<'input>{}

pub type QueryLimitTargetDefaultContext<'input> = BaseParserRuleContext<'input,QueryLimitTargetDefaultContextExt<'input>>;

pub trait QueryLimitTargetDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn queryTerm(&self) -> Option<Rc<QueryTermContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn orderBy(&self) -> Option<Rc<OrderByContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QueryLimitTargetDefaultContextAttrs<'input> for QueryLimitTargetDefaultContext<'input>{}

pub struct QueryLimitTargetDefaultContextExt<'input>{
	base:QueryLimitTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QueryLimitTargetDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for QueryLimitTargetDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryLimitTargetDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_queryLimitTargetDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_queryLimitTargetDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryLimitTargetDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_queryLimitTargetDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryLimitTargetDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimitTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimitTarget }
}

impl<'input> Borrow<QueryLimitTargetContextExt<'input>> for QueryLimitTargetDefaultContext<'input>{
	fn borrow(&self) -> &QueryLimitTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryLimitTargetContextExt<'input>> for QueryLimitTargetDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryLimitTargetContextExt<'input> { &mut self.base }
}

impl<'input> QueryLimitTargetContextAttrs<'input> for QueryLimitTargetDefaultContext<'input> {}

impl<'input> QueryLimitTargetDefaultContextExt<'input>{
	fn new(ctx: &dyn QueryLimitTargetContextAttrs<'input>) -> Rc<QueryLimitTargetContextAll<'input>>  {
		Rc::new(
			QueryLimitTargetContextAll::QueryLimitTargetDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QueryLimitTargetDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryLimitTarget(&mut self,)
	-> Result<Rc<QueryLimitTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryLimitTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 68, RULE_queryLimitTarget);
        let mut _localctx: Rc<QueryLimitTargetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = QueryLimitTargetDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule queryTerm*/
			recog.base.set_state(1501);
			recog.queryTerm()?;

			recog.base.set_state(1503);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				/*InvokeRule orderBy*/
				recog.base.set_state(1502);
				recog.orderBy()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- limitRowCount ----------------
pub type LimitRowCountContextAll<'input> = LimitRowCountContext<'input>;


pub type LimitRowCountContext<'input> = BaseParserRuleContext<'input,LimitRowCountContextExt<'input>>;

#[derive(Clone)]
pub struct LimitRowCountContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for LimitRowCountContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LimitRowCountContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_limitRowCount(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_limitRowCount(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LimitRowCountContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_limitRowCount(self);
	}
}

impl<'input> CustomRuleContext<'input> for LimitRowCountContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_limitRowCount }
	//fn type_rule_index() -> usize where Self: Sized { RULE_limitRowCount }
}
antlr_rust::tid!{LimitRowCountContextExt<'a>}

impl<'input> LimitRowCountContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LimitRowCountContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LimitRowCountContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LimitRowCountContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<LimitRowCountContextExt<'input>>{

fn rowCount(&self) -> Option<Rc<RowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LimitRowCountContextAttrs<'input> for LimitRowCountContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn limitRowCount(&mut self,)
	-> Result<Rc<LimitRowCountContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LimitRowCountContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 70, RULE_limitRowCount);
        let mut _localctx: Rc<LimitRowCountContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule rowCount*/
			recog.base.set_state(1505);
			recog.rowCount()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowCount ----------------
pub type RowCountContextAll<'input> = RowCountContext<'input>;


pub type RowCountContext<'input> = BaseParserRuleContext<'input,RowCountContextExt<'input>>;

#[derive(Clone)]
pub struct RowCountContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for RowCountContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RowCountContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowCount(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_rowCount(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RowCountContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rowCount(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowCountContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowCount }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowCount }
}
antlr_rust::tid!{RowCountContextExt<'a>}

impl<'input> RowCountContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowCountContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowCountContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowCountContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<RowCountContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}

}

impl<'input> RowCountContextAttrs<'input> for RowCountContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowCount(&mut self,)
	-> Result<Rc<RowCountContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowCountContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 72, RULE_rowCount);
        let mut _localctx: Rc<RowCountContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1507);
			recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryTerm ----------------
pub type QueryTermContextAll<'input> = QueryTermContext<'input>;


pub type QueryTermContext<'input> = BaseParserRuleContext<'input,QueryTermContextExt<'input>>;

#[derive(Clone)]
pub struct QueryTermContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QueryTermContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryTermContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryTerm(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_queryTerm(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryTermContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_queryTerm(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryTermContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryTerm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryTerm }
}
antlr_rust::tid!{QueryTermContextExt<'a>}

impl<'input> QueryTermContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryTermContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryTermContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryTermContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QueryTermContextExt<'input>>{

fn setOperation(&self) -> Option<Rc<SetOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryTermContextAttrs<'input> for QueryTermContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryTerm(&mut self,)
	-> Result<Rc<QueryTermContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryTermContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 74, RULE_queryTerm);
        let mut _localctx: Rc<QueryTermContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule setOperation*/
			recog.base.set_state(1509);
			recog.setOperation()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperation ----------------
pub type SetOperationContextAll<'input> = SetOperationContext<'input>;


pub type SetOperationContext<'input> = BaseParserRuleContext<'input,SetOperationContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperationContextExt<'input>{
	pub left: Option<Rc<SetOperationIntersectContextAll<'input>>>,
	pub setOperationIntersect: Option<Rc<SetOperationIntersectContextAll<'input>>>,
	pub right:Vec<Rc<SetOperationIntersectContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SetOperationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperation(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_setOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperation }
}
antlr_rust::tid!{SetOperationContextExt<'a>}

impl<'input> SetOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperationContextExt{
				left: None, setOperationIntersect: None, 
				right: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SetOperationContextExt<'input>>{

fn setOperationIntersect_all(&self) ->  Vec<Rc<SetOperationIntersectContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setOperationIntersect(&self, i: usize) -> Option<Rc<SetOperationIntersectContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setOperator_all(&self) ->  Vec<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setOperator(&self, i: usize) -> Option<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SetOperationContextAttrs<'input> for SetOperationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperation(&mut self,)
	-> Result<Rc<SetOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 76, RULE_setOperation);
        let mut _localctx: Rc<SetOperationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule setOperationIntersect*/
			recog.base.set_state(1511);
			let tmp = recog.setOperationIntersect()?;
			 cast_mut::<_,SetOperationContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(1517);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==EXCEPT || _la==FULL || ((((_la - 155)) & !0x3f) == 0 && ((1usize << (_la - 155)) & ((1usize << (INNER - 155)) | (1usize << (INTERSECT - 155)) | (1usize << (LEFT - 155)))) != 0) || _la==OUTER || _la==UNION {
				{
				{
				/*InvokeRule setOperator*/
				recog.base.set_state(1512);
				recog.setOperator()?;

				/*InvokeRule setOperationIntersect*/
				recog.base.set_state(1513);
				let tmp = recog.setOperationIntersect()?;
				 cast_mut::<_,SetOperationContext >(&mut _localctx).setOperationIntersect = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SetOperationContext >(&mut _localctx).setOperationIntersect.clone().unwrap()
				 ;
				 cast_mut::<_,SetOperationContext >(&mut _localctx).right.push(temp);
				  
				}
				}
				recog.base.set_state(1519);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperator ----------------
pub type SetOperatorContextAll<'input> = SetOperatorContext<'input>;


pub type SetOperatorContext<'input> = BaseParserRuleContext<'input,SetOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SetOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperator(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_setOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperator }
}
antlr_rust::tid!{SetOperatorContextExt<'a>}

impl<'input> SetOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperatorContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SetOperatorContextExt<'input>>{

fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token NAME
/// Returns `None` if there is no child corresponding to token NAME
fn NAME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NAME, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}

}

impl<'input> SetOperatorContextAttrs<'input> for SetOperatorContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperator(&mut self,)
	-> Result<Rc<SetOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 78, RULE_setOperator);
        let mut _localctx: Rc<SetOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1527);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INNER 
				=> {
					{
					recog.base.set_state(1520);
					recog.base.match_token(INNER,&mut recog.err_handler)?;

					}
				}

			 EXCEPT | FULL | INTERSECT | LEFT | OUTER | UNION 
				=> {
					{
					recog.base.set_state(1522);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FULL || _la==LEFT {
						{
						recog.base.set_state(1521);
						_la = recog.base.input.la(1);
						if { !(_la==FULL || _la==LEFT) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(1525);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(1524);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(1529);
			_la = recog.base.input.la(1);
			if { !(_la==EXCEPT || _la==INTERSECT || _la==UNION) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule setQuantifier*/
			recog.base.set_state(1530);
			recog.setQuantifier()?;

			recog.base.set_state(1533);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==BY {
				{
				recog.base.set_state(1531);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(1532);
				recog.base.match_token(NAME,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperationIntersect ----------------
pub type SetOperationIntersectContextAll<'input> = SetOperationIntersectContext<'input>;


pub type SetOperationIntersectContext<'input> = BaseParserRuleContext<'input,SetOperationIntersectContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperationIntersectContextExt<'input>{
	pub left: Option<Rc<QueryPrimaryContextAll<'input>>>,
	pub queryPrimary: Option<Rc<QueryPrimaryContextAll<'input>>>,
	pub right:Vec<Rc<QueryPrimaryContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SetOperationIntersectContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetOperationIntersectContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperationIntersect(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_setOperationIntersect(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetOperationIntersectContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setOperationIntersect(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperationIntersectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperationIntersect }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperationIntersect }
}
antlr_rust::tid!{SetOperationIntersectContextExt<'a>}

impl<'input> SetOperationIntersectContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperationIntersectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperationIntersectContextExt{
				left: None, queryPrimary: None, 
				right: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperationIntersectContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SetOperationIntersectContextExt<'input>>{

fn queryPrimary_all(&self) ->  Vec<Rc<QueryPrimaryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn queryPrimary(&self, i: usize) -> Option<Rc<QueryPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setIntersectOperator_all(&self) ->  Vec<Rc<SetIntersectOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setIntersectOperator(&self, i: usize) -> Option<Rc<SetIntersectOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SetOperationIntersectContextAttrs<'input> for SetOperationIntersectContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperationIntersect(&mut self,)
	-> Result<Rc<SetOperationIntersectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperationIntersectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 80, RULE_setOperationIntersect);
        let mut _localctx: Rc<SetOperationIntersectContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryPrimary*/
			recog.base.set_state(1535);
			let tmp = recog.queryPrimary()?;
			 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(1541);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(170,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule setIntersectOperator*/
					recog.base.set_state(1536);
					recog.setIntersectOperator()?;

					/*InvokeRule queryPrimary*/
					recog.base.set_state(1537);
					let tmp = recog.queryPrimary()?;
					 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).queryPrimary = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).queryPrimary.clone().unwrap()
					 ;
					 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).right.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1543);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(170,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setIntersectOperator ----------------
pub type SetIntersectOperatorContextAll<'input> = SetIntersectOperatorContext<'input>;


pub type SetIntersectOperatorContext<'input> = BaseParserRuleContext<'input,SetIntersectOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SetIntersectOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SetIntersectOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetIntersectOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setIntersectOperator(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_setIntersectOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetIntersectOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setIntersectOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetIntersectOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setIntersectOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setIntersectOperator }
}
antlr_rust::tid!{SetIntersectOperatorContextExt<'a>}

impl<'input> SetIntersectOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetIntersectOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetIntersectOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetIntersectOperatorContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SetIntersectOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetIntersectOperatorContextAttrs<'input> for SetIntersectOperatorContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setIntersectOperator(&mut self,)
	-> Result<Rc<SetIntersectOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetIntersectOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 82, RULE_setIntersectOperator);
        let mut _localctx: Rc<SetIntersectOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1544);
			recog.base.match_token(INTERSECT,&mut recog.err_handler)?;

			recog.base.set_state(1546);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ALL || _la==DISTINCT {
				{
				/*InvokeRule setQuantifier*/
				recog.base.set_state(1545);
				recog.setQuantifier()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setQuantifier ----------------
pub type SetQuantifierContextAll<'input> = SetQuantifierContext<'input>;


pub type SetQuantifierContext<'input> = BaseParserRuleContext<'input,SetQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct SetQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SetQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SetQuantifierContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setQuantifier(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_setQuantifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SetQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_setQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setQuantifier }
}
antlr_rust::tid!{SetQuantifierContextExt<'a>}

impl<'input> SetQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetQuantifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetQuantifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetQuantifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SetQuantifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}

}

impl<'input> SetQuantifierContextAttrs<'input> for SetQuantifierContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setQuantifier(&mut self,)
	-> Result<Rc<SetQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 84, RULE_setQuantifier);
        let mut _localctx: Rc<SetQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1548);
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==DISTINCT) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- inlineTable ----------------
pub type InlineTableContextAll<'input> = InlineTableContext<'input>;


pub type InlineTableContext<'input> = BaseParserRuleContext<'input,InlineTableContextExt<'input>>;

#[derive(Clone)]
pub struct InlineTableContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for InlineTableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for InlineTableContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_inlineTable(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_inlineTable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for InlineTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_inlineTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_inlineTable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_inlineTable }
}
antlr_rust::tid!{InlineTableContextExt<'a>}

impl<'input> InlineTableContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InlineTableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InlineTableContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait InlineTableContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<InlineTableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> InlineTableContextAttrs<'input> for InlineTableContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn inlineTable(&mut self,)
	-> Result<Rc<InlineTableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InlineTableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 86, RULE_inlineTable);
        let mut _localctx: Rc<InlineTableContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1550);
			recog.base.match_token(VALUES,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1551);
			recog.expression()?;

			recog.base.set_state(1556);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(172,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1552);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1553);
					recog.expression()?;

					}
					} 
				}
				recog.base.set_state(1558);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(172,&mut recog.base)?;
			}
			recog.base.set_state(1560);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1559);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,InlineTableContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryPrimary ----------------
#[derive(Debug)]
pub enum QueryPrimaryContextAll<'input>{
	SubqueryContext(SubqueryContext<'input>),
	QueryPrimaryDefaultContext(QueryPrimaryDefaultContext<'input>),
	InlineTableDefault1Context(InlineTableDefault1Context<'input>),
	TableContext(TableContext<'input>),
Error(QueryPrimaryContext<'input>)
}
antlr_rust::tid!{QueryPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QueryPrimaryContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for QueryPrimaryContextAll<'input>{}

impl<'input> Deref for QueryPrimaryContextAll<'input>{
	type Target = dyn QueryPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QueryPrimaryContextAll::*;
		match self{
			SubqueryContext(inner) => inner,
			QueryPrimaryDefaultContext(inner) => inner,
			InlineTableDefault1Context(inner) => inner,
			TableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QueryPrimaryContext<'input> = BaseParserRuleContext<'input,QueryPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QueryPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QueryPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}
antlr_rust::tid!{QueryPrimaryContextExt<'a>}

impl<'input> QueryPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryPrimaryContextAll<'input>> {
		Rc::new(
		QueryPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QueryPrimaryContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QueryPrimaryContextExt<'input>>{


}

impl<'input> QueryPrimaryContextAttrs<'input> for QueryPrimaryContext<'input>{}

pub type SubqueryContext<'input> = BaseParserRuleContext<'input,SubqueryContextExt<'input>>;

pub trait SubqueryContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SubqueryContextAttrs<'input> for SubqueryContext<'input>{}

pub struct SubqueryContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	pub query_: Option<Rc<QueryContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SubqueryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SubqueryContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subquery(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_subquery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SubqueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_subquery(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for SubqueryContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for SubqueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for SubqueryContext<'input> {}

impl<'input> SubqueryContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::SubqueryContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryContextExt{
        			query_:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QueryPrimaryDefaultContext<'input> = BaseParserRuleContext<'input,QueryPrimaryDefaultContextExt<'input>>;

pub trait QueryPrimaryDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn querySpecification(&self) -> Option<Rc<QuerySpecificationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QueryPrimaryDefaultContextAttrs<'input> for QueryPrimaryDefaultContext<'input>{}

pub struct QueryPrimaryDefaultContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QueryPrimaryDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for QueryPrimaryDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryPrimaryDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_queryPrimaryDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_queryPrimaryDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryPrimaryDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_queryPrimaryDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryPrimaryDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for QueryPrimaryDefaultContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for QueryPrimaryDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for QueryPrimaryDefaultContext<'input> {}

impl<'input> QueryPrimaryDefaultContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::QueryPrimaryDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QueryPrimaryDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InlineTableDefault1Context<'input> = BaseParserRuleContext<'input,InlineTableDefault1ContextExt<'input>>;

pub trait InlineTableDefault1ContextAttrs<'input>: BigqueryParserContext<'input>{
	fn inlineTable(&self) -> Option<Rc<InlineTableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InlineTableDefault1ContextAttrs<'input> for InlineTableDefault1Context<'input>{}

pub struct InlineTableDefault1ContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InlineTableDefault1ContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for InlineTableDefault1Context<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for InlineTableDefault1Context<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inlineTableDefault1(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_inlineTableDefault1(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for InlineTableDefault1Context<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_inlineTableDefault1(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableDefault1ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for InlineTableDefault1Context<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for InlineTableDefault1Context<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for InlineTableDefault1Context<'input> {}

impl<'input> InlineTableDefault1ContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::InlineTableDefault1Context(
				BaseParserRuleContext::copy_from(ctx,InlineTableDefault1ContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableContext<'input> = BaseParserRuleContext<'input,TableContextExt<'input>>;

pub trait TableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn pathExpression(&self) -> Option<Rc<PathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableContextAttrs<'input> for TableContext<'input>{}

pub struct TableContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_table(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_table(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_table(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for TableContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for TableContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for TableContext<'input> {}

impl<'input> TableContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::TableContext(
				BaseParserRuleContext::copy_from(ctx,TableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryPrimary(&mut self,)
	-> Result<Rc<QueryPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 88, RULE_queryPrimary);
        let mut _localctx: Rc<QueryPrimaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1570);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 SELECT 
				=> {
					let tmp = QueryPrimaryDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule querySpecification*/
					recog.base.set_state(1562);
					recog.querySpecification()?;

					}
				}

			 TABLE 
				=> {
					let tmp = TableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1563);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule pathExpression*/
					recog.base.set_state(1564);
					recog.pathExpression()?;

					}
				}

			 VALUES 
				=> {
					let tmp = InlineTableDefault1ContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule inlineTable*/
					recog.base.set_state(1565);
					recog.inlineTable()?;

					}
				}

			 LPAREN 
				=> {
					let tmp = SubqueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(1566);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(1567);
					let tmp = recog.query()?;
					if let QueryPrimaryContextAll::SubqueryContext(ctx) = cast_mut::<_,QueryPrimaryContextAll >(&mut _localctx){
					ctx.query_ = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1568);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sortItem ----------------
pub type SortItemContextAll<'input> = SortItemContext<'input>;


pub type SortItemContext<'input> = BaseParserRuleContext<'input,SortItemContextExt<'input>>;

#[derive(Clone)]
pub struct SortItemContextExt<'input>{
	pub ordering: Option<TokenType<'input>>,
	pub nullOrdering: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SortItemContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SortItemContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sortItem(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_sortItem(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SortItemContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_sortItem(self);
	}
}

impl<'input> CustomRuleContext<'input> for SortItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sortItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sortItem }
}
antlr_rust::tid!{SortItemContextExt<'a>}

impl<'input> SortItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SortItemContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SortItemContextExt{
				ordering: None, nullOrdering: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SortItemContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SortItemContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}

}

impl<'input> SortItemContextAttrs<'input> for SortItemContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sortItem(&mut self,)
	-> Result<Rc<SortItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SortItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 90, RULE_sortItem);
        let mut _localctx: Rc<SortItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(1572);
			recog.expression()?;

			recog.base.set_state(1574);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASC || _la==DESC {
				{
				recog.base.set_state(1573);
				 cast_mut::<_,SortItemContext >(&mut _localctx).ordering = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==ASC || _la==DESC) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,SortItemContext >(&mut _localctx).ordering = Some(tmp);
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			recog.base.set_state(1578);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==NULLS {
				{
				recog.base.set_state(1576);
				recog.base.match_token(NULLS,&mut recog.err_handler)?;

				recog.base.set_state(1577);
				 cast_mut::<_,SortItemContext >(&mut _localctx).nullOrdering = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==FIRST || _la==LAST) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,SortItemContext >(&mut _localctx).nullOrdering = Some(tmp);
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- querySpecification ----------------
pub type QuerySpecificationContextAll<'input> = QuerySpecificationContext<'input>;


pub type QuerySpecificationContext<'input> = BaseParserRuleContext<'input,QuerySpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct QuerySpecificationContextExt<'input>{
	pub where_: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub having: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub qualify: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QuerySpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QuerySpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_querySpecification(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_querySpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QuerySpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_querySpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuerySpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySpecification }
}
antlr_rust::tid!{QuerySpecificationContextExt<'a>}

impl<'input> QuerySpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuerySpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuerySpecificationContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				where_: None, having: None, qualify: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QuerySpecificationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QuerySpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
fn querySelectItems(&self) -> Option<Rc<QuerySelectItemsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
fn relation(&self) -> Option<Rc<RelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn aggregationClause(&self) -> Option<Rc<AggregationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
/// Retrieves first TerminalNode corresponding to token QUALIFY
/// Returns `None` if there is no child corresponding to token QUALIFY
fn QUALIFY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(QUALIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
fn windowDefinition_all(&self) ->  Vec<Rc<WindowDefinitionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn windowDefinition(&self, i: usize) -> Option<Rc<WindowDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token STRUCT
/// Returns `None` if there is no child corresponding to token STRUCT
fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUE
/// Returns `None` if there is no child corresponding to token VALUE
fn VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VALUE, 0)
}
fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QuerySpecificationContextAttrs<'input> for QuerySpecificationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn querySpecification(&mut self,)
	-> Result<Rc<QuerySpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuerySpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 92, RULE_querySpecification);
        let mut _localctx: Rc<QuerySpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1580);
			recog.base.match_token(SELECT,&mut recog.err_handler)?;

			recog.base.set_state(1582);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ALL || _la==DISTINCT {
				{
				/*InvokeRule setQuantifier*/
				recog.base.set_state(1581);
				recog.setQuantifier()?;

				}
			}

			recog.base.set_state(1586);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(1584);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				recog.base.set_state(1585);
				_la = recog.base.input.la(1);
				if { !(_la==STRUCT || _la==VALUE) } {
					recog.err_handler.recover_inline(&mut recog.base)?;

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			/*InvokeRule querySelectItems*/
			recog.base.set_state(1588);
			recog.querySelectItems()?;

			recog.base.set_state(1591);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==FROM {
				{
				recog.base.set_state(1589);
				recog.base.match_token(FROM,&mut recog.err_handler)?;

				/*InvokeRule relation*/
				recog.base.set_state(1590);
				recog.relation()?;

				}
			}

			recog.base.set_state(1595);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WHERE {
				{
				recog.base.set_state(1593);
				recog.base.match_token(WHERE,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1594);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).where_ = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1598);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==GROUP {
				{
				/*InvokeRule aggregationClause*/
				recog.base.set_state(1597);
				recog.aggregationClause()?;

				}
			}

			recog.base.set_state(1602);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==HAVING {
				{
				recog.base.set_state(1600);
				recog.base.match_token(HAVING,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1601);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).having = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1606);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==QUALIFY {
				{
				recog.base.set_state(1604);
				recog.base.match_token(QUALIFY,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1605);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).qualify = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1620);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WINDOW {
				{
				recog.base.set_state(1608);
				recog.base.match_token(WINDOW,&mut recog.err_handler)?;

				/*InvokeRule windowDefinition*/
				recog.base.set_state(1609);
				recog.windowDefinition()?;

				recog.base.set_state(1614);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(184,&mut recog.base)?;
				while { _alt!=2 && _alt!=INVALID_ALT } {
					if _alt==1 {
						{
						{
						recog.base.set_state(1610);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule windowDefinition*/
						recog.base.set_state(1611);
						recog.windowDefinition()?;

						}
						} 
					}
					recog.base.set_state(1616);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(184,&mut recog.base)?;
				}
				recog.base.set_state(1618);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==COMMA {
					{
					recog.base.set_state(1617);
					let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
					 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).COMMA = Some(tmp);
					  

					let temp =  cast_mut::<_,QuerySpecificationContext >(&mut _localctx).COMMA.clone().unwrap()
					 ;
					 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).tail.push(temp);
					  
					}
				}

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replaceDefinition ----------------
pub type ReplaceDefinitionContextAll<'input> = ReplaceDefinitionContext<'input>;


pub type ReplaceDefinitionContext<'input> = BaseParserRuleContext<'input,ReplaceDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct ReplaceDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ReplaceDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ReplaceDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replaceDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_replaceDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ReplaceDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_replaceDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReplaceDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replaceDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replaceDefinition }
}
antlr_rust::tid!{ReplaceDefinitionContextExt<'a>}

impl<'input> ReplaceDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplaceDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplaceDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplaceDefinitionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ReplaceDefinitionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> ReplaceDefinitionContextAttrs<'input> for ReplaceDefinitionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replaceDefinition(&mut self,)
	-> Result<Rc<ReplaceDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplaceDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 94, RULE_replaceDefinition);
        let mut _localctx: Rc<ReplaceDefinitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(1622);
			recog.expression()?;

			recog.base.set_state(1624);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(1623);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule identifier*/
			recog.base.set_state(1626);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- querySelectItems ----------------
pub type QuerySelectItemsContextAll<'input> = QuerySelectItemsContext<'input>;


pub type QuerySelectItemsContext<'input> = BaseParserRuleContext<'input,QuerySelectItemsContextExt<'input>>;

#[derive(Clone)]
pub struct QuerySelectItemsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QuerySelectItemsContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QuerySelectItemsContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_querySelectItems(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_querySelectItems(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QuerySelectItemsContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_querySelectItems(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuerySelectItemsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySelectItems }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySelectItems }
}
antlr_rust::tid!{QuerySelectItemsContextExt<'a>}

impl<'input> QuerySelectItemsContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuerySelectItemsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuerySelectItemsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QuerySelectItemsContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QuerySelectItemsContextExt<'input>>{

fn selectItem_all(&self) ->  Vec<Rc<SelectItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn selectItem(&self, i: usize) -> Option<Rc<SelectItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QuerySelectItemsContextAttrs<'input> for QuerySelectItemsContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn querySelectItems(&mut self,)
	-> Result<Rc<QuerySelectItemsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuerySelectItemsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 96, RULE_querySelectItems);
        let mut _localctx: Rc<QuerySelectItemsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule selectItem*/
			recog.base.set_state(1628);
			recog.selectItem()?;

			recog.base.set_state(1633);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(188,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1629);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule selectItem*/
					recog.base.set_state(1630);
					recog.selectItem()?;

					}
					} 
				}
				recog.base.set_state(1635);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(188,&mut recog.base)?;
			}
			recog.base.set_state(1637);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1636);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,QuerySelectItemsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aggregationClause ----------------
pub type AggregationClauseContextAll<'input> = AggregationClauseContext<'input>;


pub type AggregationClauseContext<'input> = BaseParserRuleContext<'input,AggregationClauseContextExt<'input>>;

#[derive(Clone)]
pub struct AggregationClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for AggregationClauseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for AggregationClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aggregationClause(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_aggregationClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for AggregationClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_aggregationClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for AggregationClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aggregationClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aggregationClause }
}
antlr_rust::tid!{AggregationClauseContextExt<'a>}

impl<'input> AggregationClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AggregationClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AggregationClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AggregationClauseContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<AggregationClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GROUP
/// Returns `None` if there is no child corresponding to token GROUP
fn GROUP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn groupBy(&self) -> Option<Rc<GroupByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AggregationClauseContextAttrs<'input> for AggregationClauseContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aggregationClause(&mut self,)
	-> Result<Rc<AggregationClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AggregationClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 98, RULE_aggregationClause);
        let mut _localctx: Rc<AggregationClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1639);
			recog.base.match_token(GROUP,&mut recog.err_handler)?;

			recog.base.set_state(1640);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule groupBy*/
			recog.base.set_state(1641);
			recog.groupBy()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupBy ----------------
#[derive(Debug)]
pub enum GroupByContextAll<'input>{
	GroupByAllContext(GroupByAllContext<'input>),
	GroupByDefaultContext(GroupByDefaultContext<'input>),
Error(GroupByContext<'input>)
}
antlr_rust::tid!{GroupByContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GroupByContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for GroupByContextAll<'input>{}

impl<'input> Deref for GroupByContextAll<'input>{
	type Target = dyn GroupByContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GroupByContextAll::*;
		match self{
			GroupByAllContext(inner) => inner,
			GroupByDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GroupByContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GroupByContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GroupByContext<'input> = BaseParserRuleContext<'input,GroupByContextExt<'input>>;

#[derive(Clone)]
pub struct GroupByContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for GroupByContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GroupByContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GroupByContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GroupByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}
antlr_rust::tid!{GroupByContextExt<'a>}

impl<'input> GroupByContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupByContextAll<'input>> {
		Rc::new(
		GroupByContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupByContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GroupByContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<GroupByContextExt<'input>>{


}

impl<'input> GroupByContextAttrs<'input> for GroupByContext<'input>{}

pub type GroupByAllContext<'input> = BaseParserRuleContext<'input,GroupByAllContextExt<'input>>;

pub trait GroupByAllContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALL
	/// Returns `None` if there is no child corresponding to token ALL
	fn ALL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALL, 0)
	}
}

impl<'input> GroupByAllContextAttrs<'input> for GroupByAllContext<'input>{}

pub struct GroupByAllContextExt<'input>{
	base:GroupByContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GroupByAllContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for GroupByAllContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GroupByAllContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_groupByAll(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_groupByAll(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GroupByAllContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_groupByAll(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupByAllContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}

impl<'input> Borrow<GroupByContextExt<'input>> for GroupByAllContext<'input>{
	fn borrow(&self) -> &GroupByContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupByContextExt<'input>> for GroupByAllContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupByContextExt<'input> { &mut self.base }
}

impl<'input> GroupByContextAttrs<'input> for GroupByAllContext<'input> {}

impl<'input> GroupByAllContextExt<'input>{
	fn new(ctx: &dyn GroupByContextAttrs<'input>) -> Rc<GroupByContextAll<'input>>  {
		Rc::new(
			GroupByContextAll::GroupByAllContext(
				BaseParserRuleContext::copy_from(ctx,GroupByAllContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GroupByDefaultContext<'input> = BaseParserRuleContext<'input,GroupByDefaultContextExt<'input>>;

pub trait GroupByDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn groupingElement_all(&self) ->  Vec<Rc<GroupingElementContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn groupingElement(&self, i: usize) -> Option<Rc<GroupingElementContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> GroupByDefaultContextAttrs<'input> for GroupByDefaultContext<'input>{}

pub struct GroupByDefaultContextExt<'input>{
	base:GroupByContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GroupByDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for GroupByDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GroupByDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_groupByDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_groupByDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GroupByDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_groupByDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupByDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}

impl<'input> Borrow<GroupByContextExt<'input>> for GroupByDefaultContext<'input>{
	fn borrow(&self) -> &GroupByContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupByContextExt<'input>> for GroupByDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupByContextExt<'input> { &mut self.base }
}

impl<'input> GroupByContextAttrs<'input> for GroupByDefaultContext<'input> {}

impl<'input> GroupByDefaultContextExt<'input>{
	fn new(ctx: &dyn GroupByContextAttrs<'input>) -> Rc<GroupByContextAll<'input>>  {
		Rc::new(
			GroupByContextAll::GroupByDefaultContext(
				BaseParserRuleContext::copy_from(ctx,GroupByDefaultContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupBy(&mut self,)
	-> Result<Rc<GroupByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 100, RULE_groupBy);
        let mut _localctx: Rc<GroupByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1658);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(193,&mut recog.base)? {
				1 =>{
					let tmp = GroupByAllContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1643);
					recog.base.match_token(ALL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = GroupByDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1645);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ALL || _la==DISTINCT {
						{
						/*InvokeRule setQuantifier*/
						recog.base.set_state(1644);
						recog.setQuantifier()?;

						}
					}

					/*InvokeRule groupingElement*/
					recog.base.set_state(1647);
					recog.groupingElement()?;

					recog.base.set_state(1652);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(191,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(1648);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule groupingElement*/
							recog.base.set_state(1649);
							recog.groupingElement()?;

							}
							} 
						}
						recog.base.set_state(1654);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(191,&mut recog.base)?;
					}
					recog.base.set_state(1656);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(1655);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let GroupByContextAll::GroupByDefaultContext(ctx) = cast_mut::<_,GroupByContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingElement ----------------
#[derive(Debug)]
pub enum GroupingElementContextAll<'input>{
	MultipleGroupingSetsContext(MultipleGroupingSetsContext<'input>),
	SingleGroupingSetContext(SingleGroupingSetContext<'input>),
	CubeContext(CubeContext<'input>),
	RollupContext(RollupContext<'input>),
Error(GroupingElementContext<'input>)
}
antlr_rust::tid!{GroupingElementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GroupingElementContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for GroupingElementContextAll<'input>{}

impl<'input> Deref for GroupingElementContextAll<'input>{
	type Target = dyn GroupingElementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GroupingElementContextAll::*;
		match self{
			MultipleGroupingSetsContext(inner) => inner,
			SingleGroupingSetContext(inner) => inner,
			CubeContext(inner) => inner,
			RollupContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GroupingElementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GroupingElementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GroupingElementContext<'input> = BaseParserRuleContext<'input,GroupingElementContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for GroupingElementContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GroupingElementContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GroupingElementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GroupingElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}
antlr_rust::tid!{GroupingElementContextExt<'a>}

impl<'input> GroupingElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingElementContextAll<'input>> {
		Rc::new(
		GroupingElementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingElementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GroupingElementContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<GroupingElementContextExt<'input>>{


}

impl<'input> GroupingElementContextAttrs<'input> for GroupingElementContext<'input>{}

pub type MultipleGroupingSetsContext<'input> = BaseParserRuleContext<'input,MultipleGroupingSetsContextExt<'input>>;

pub trait MultipleGroupingSetsContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token GROUPING
	/// Returns `None` if there is no child corresponding to token GROUPING
	fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(GROUPING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SETS
	/// Returns `None` if there is no child corresponding to token SETS
	fn SETS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SETS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn groupingSet_all(&self) ->  Vec<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn groupingSet(&self, i: usize) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> MultipleGroupingSetsContextAttrs<'input> for MultipleGroupingSetsContext<'input>{}

pub struct MultipleGroupingSetsContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MultipleGroupingSetsContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for MultipleGroupingSetsContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MultipleGroupingSetsContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_multipleGroupingSets(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_multipleGroupingSets(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MultipleGroupingSetsContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_multipleGroupingSets(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipleGroupingSetsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for MultipleGroupingSetsContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for MultipleGroupingSetsContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for MultipleGroupingSetsContext<'input> {}

impl<'input> MultipleGroupingSetsContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::MultipleGroupingSetsContext(
				BaseParserRuleContext::copy_from(ctx,MultipleGroupingSetsContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SingleGroupingSetContext<'input> = BaseParserRuleContext<'input,SingleGroupingSetContextExt<'input>>;

pub trait SingleGroupingSetContextAttrs<'input>: BigqueryParserContext<'input>{
	fn groupingSet(&self) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SingleGroupingSetContextAttrs<'input> for SingleGroupingSetContext<'input>{}

pub struct SingleGroupingSetContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleGroupingSetContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SingleGroupingSetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SingleGroupingSetContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleGroupingSet(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_singleGroupingSet(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SingleGroupingSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_singleGroupingSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleGroupingSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for SingleGroupingSetContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for SingleGroupingSetContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for SingleGroupingSetContext<'input> {}

impl<'input> SingleGroupingSetContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::SingleGroupingSetContext(
				BaseParserRuleContext::copy_from(ctx,SingleGroupingSetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CubeContext<'input> = BaseParserRuleContext<'input,CubeContextExt<'input>>;

pub trait CubeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CUBE
	/// Returns `None` if there is no child corresponding to token CUBE
	fn CUBE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CUBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> CubeContextAttrs<'input> for CubeContext<'input>{}

pub struct CubeContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CubeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CubeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CubeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_cube(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_cube(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CubeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_cube(self);
	}
}

impl<'input> CustomRuleContext<'input> for CubeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for CubeContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for CubeContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for CubeContext<'input> {}

impl<'input> CubeContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::CubeContext(
				BaseParserRuleContext::copy_from(ctx,CubeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RollupContext<'input> = BaseParserRuleContext<'input,RollupContextExt<'input>>;

pub trait RollupContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLLUP
	/// Returns `None` if there is no child corresponding to token ROLLUP
	fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ROLLUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> RollupContextAttrs<'input> for RollupContext<'input>{}

pub struct RollupContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RollupContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RollupContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RollupContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rollup(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_rollup(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RollupContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rollup(self);
	}
}

impl<'input> CustomRuleContext<'input> for RollupContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for RollupContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for RollupContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for RollupContext<'input> {}

impl<'input> RollupContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::RollupContext(
				BaseParserRuleContext::copy_from(ctx,RollupContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingElement(&mut self,)
	-> Result<Rc<GroupingElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 102, RULE_groupingElement);
        let mut _localctx: Rc<GroupingElementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1709);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(202,&mut recog.base)? {
				1 =>{
					let tmp = RollupContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1660);
					recog.base.match_token(ROLLUP,&mut recog.err_handler)?;

					recog.base.set_state(1661);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1673);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(1662);
						recog.expression()?;

						recog.base.set_state(1667);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(194,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(1663);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(1664);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(1669);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(194,&mut recog.base)?;
						}
						recog.base.set_state(1671);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(1670);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let GroupingElementContextAll::RollupContext(ctx) = cast_mut::<_,GroupingElementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(1675);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = CubeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1676);
					recog.base.match_token(CUBE,&mut recog.err_handler)?;

					recog.base.set_state(1677);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1689);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(1678);
						recog.expression()?;

						recog.base.set_state(1683);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(197,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(1679);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(1680);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(1685);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(197,&mut recog.base)?;
						}
						recog.base.set_state(1687);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(1686);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let GroupingElementContextAll::CubeContext(ctx) = cast_mut::<_,GroupingElementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(1691);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = MultipleGroupingSetsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(1692);
					recog.base.match_token(GROUPING,&mut recog.err_handler)?;

					recog.base.set_state(1693);
					recog.base.match_token(SETS,&mut recog.err_handler)?;

					recog.base.set_state(1694);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule groupingSet*/
					recog.base.set_state(1695);
					recog.groupingSet()?;

					recog.base.set_state(1700);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(200,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(1696);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule groupingSet*/
							recog.base.set_state(1697);
							recog.groupingSet()?;

							}
							} 
						}
						recog.base.set_state(1702);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(200,&mut recog.base)?;
					}
					recog.base.set_state(1704);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(1703);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let GroupingElementContextAll::MultipleGroupingSetsContext(ctx) = cast_mut::<_,GroupingElementContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(1706);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = SingleGroupingSetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule groupingSet*/
					recog.base.set_state(1708);
					recog.groupingSet()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingSet ----------------
pub type GroupingSetContextAll<'input> = GroupingSetContext<'input>;


pub type GroupingSetContext<'input> = BaseParserRuleContext<'input,GroupingSetContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingSetContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for GroupingSetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GroupingSetContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingSet(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_groupingSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GroupingSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_groupingSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupingSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingSet }
}
antlr_rust::tid!{GroupingSetContextExt<'a>}

impl<'input> GroupingSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingSetContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingSetContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<GroupingSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> GroupingSetContextAttrs<'input> for GroupingSetContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingSet(&mut self,)
	-> Result<Rc<GroupingSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 104, RULE_groupingSet);
        let mut _localctx: Rc<GroupingSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1727);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(206,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1711);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1720);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(1712);
						recog.expression()?;

						recog.base.set_state(1717);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(203,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(1713);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(1714);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(1719);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(203,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(1723);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(1722);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,GroupingSetContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(1725);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expression*/
					recog.base.set_state(1726);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowDefinition ----------------
pub type WindowDefinitionContextAll<'input> = WindowDefinitionContext<'input>;


pub type WindowDefinitionContext<'input> = BaseParserRuleContext<'input,WindowDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct WindowDefinitionContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for WindowDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for WindowDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_windowDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for WindowDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_windowDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowDefinition }
}
antlr_rust::tid!{WindowDefinitionContextExt<'a>}

impl<'input> WindowDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowDefinitionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowDefinitionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<WindowDefinitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn windowSpecification(&self) -> Option<Rc<WindowSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowDefinitionContextAttrs<'input> for WindowDefinitionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowDefinition(&mut self,)
	-> Result<Rc<WindowDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 106, RULE_windowDefinition);
        let mut _localctx: Rc<WindowDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1729);
			let tmp = recog.identifier()?;
			 cast_mut::<_,WindowDefinitionContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(1730);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(1731);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule windowSpecification*/
			recog.base.set_state(1732);
			recog.windowSpecification()?;

			recog.base.set_state(1733);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowSpecification ----------------
pub type WindowSpecificationContextAll<'input> = WindowSpecificationContext<'input>;


pub type WindowSpecificationContext<'input> = BaseParserRuleContext<'input,WindowSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct WindowSpecificationContextExt<'input>{
	pub existingWindowName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for WindowSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for WindowSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowSpecification(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_windowSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for WindowSpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_windowSpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpecification }
}
antlr_rust::tid!{WindowSpecificationContextExt<'a>}

impl<'input> WindowSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowSpecificationContextExt{
				existingWindowName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowSpecificationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<WindowSpecificationContextExt<'input>>{

fn windowSpecificationPartitionBy(&self) -> Option<Rc<WindowSpecificationPartitionByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderBy(&self) -> Option<Rc<OrderByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn windowFrame(&self) -> Option<Rc<WindowFrameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowSpecificationContextAttrs<'input> for WindowSpecificationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowSpecification(&mut self,)
	-> Result<Rc<WindowSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 108, RULE_windowSpecification);
        let mut _localctx: Rc<WindowSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1736);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
				{
				/*InvokeRule identifier*/
				recog.base.set_state(1735);
				let tmp = recog.identifier()?;
				 cast_mut::<_,WindowSpecificationContext >(&mut _localctx).existingWindowName = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1739);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PARTITION {
				{
				/*InvokeRule windowSpecificationPartitionBy*/
				recog.base.set_state(1738);
				recog.windowSpecificationPartitionBy()?;

				}
			}

			recog.base.set_state(1742);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				/*InvokeRule orderBy*/
				recog.base.set_state(1741);
				recog.orderBy()?;

				}
			}

			recog.base.set_state(1745);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==GROUPS || _la==RANGE || _la==ROWS {
				{
				/*InvokeRule windowFrame*/
				recog.base.set_state(1744);
				recog.windowFrame()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowSpecificationPartitionBy ----------------
pub type WindowSpecificationPartitionByContextAll<'input> = WindowSpecificationPartitionByContext<'input>;


pub type WindowSpecificationPartitionByContext<'input> = BaseParserRuleContext<'input,WindowSpecificationPartitionByContextExt<'input>>;

#[derive(Clone)]
pub struct WindowSpecificationPartitionByContextExt<'input>{
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub partition:Vec<Rc<ExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for WindowSpecificationPartitionByContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for WindowSpecificationPartitionByContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowSpecificationPartitionBy(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_windowSpecificationPartitionBy(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for WindowSpecificationPartitionByContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_windowSpecificationPartitionBy(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowSpecificationPartitionByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpecificationPartitionBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpecificationPartitionBy }
}
antlr_rust::tid!{WindowSpecificationPartitionByContextExt<'a>}

impl<'input> WindowSpecificationPartitionByContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowSpecificationPartitionByContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowSpecificationPartitionByContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				expression: None, 
				partition: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowSpecificationPartitionByContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<WindowSpecificationPartitionByContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WindowSpecificationPartitionByContextAttrs<'input> for WindowSpecificationPartitionByContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowSpecificationPartitionBy(&mut self,)
	-> Result<Rc<WindowSpecificationPartitionByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowSpecificationPartitionByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 110, RULE_windowSpecificationPartitionBy);
        let mut _localctx: Rc<WindowSpecificationPartitionByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1747);
			recog.base.match_token(PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(1748);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1749);
			let tmp = recog.expression()?;
			 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression.clone().unwrap()
			 ;
			 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).partition.push(temp);
			  
			recog.base.set_state(1754);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(211,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1750);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1751);
					let tmp = recog.expression()?;
					 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).partition.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1756);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(211,&mut recog.base)?;
			}
			recog.base.set_state(1758);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1757);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderBy ----------------
pub type OrderByContextAll<'input> = OrderByContext<'input>;


pub type OrderByContext<'input> = BaseParserRuleContext<'input,OrderByContextExt<'input>>;

#[derive(Clone)]
pub struct OrderByContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for OrderByContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for OrderByContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderBy(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_orderBy(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for OrderByContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_orderBy(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrderByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderBy }
}
antlr_rust::tid!{OrderByContextExt<'a>}

impl<'input> OrderByContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderByContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderByContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderByContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<OrderByContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> OrderByContextAttrs<'input> for OrderByContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderBy(&mut self,)
	-> Result<Rc<OrderByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 112, RULE_orderBy);
        let mut _localctx: Rc<OrderByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1760);
			recog.base.match_token(ORDER,&mut recog.err_handler)?;

			recog.base.set_state(1761);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule sortItem*/
			recog.base.set_state(1762);
			recog.sortItem()?;

			recog.base.set_state(1767);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(213,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1763);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(1764);
					recog.sortItem()?;

					}
					} 
				}
				recog.base.set_state(1769);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(213,&mut recog.base)?;
			}
			recog.base.set_state(1771);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1770);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,OrderByContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,OrderByContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,OrderByContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedQuery ----------------
pub type NamedQueryContextAll<'input> = NamedQueryContext<'input>;


pub type NamedQueryContext<'input> = BaseParserRuleContext<'input,NamedQueryContextExt<'input>>;

#[derive(Clone)]
pub struct NamedQueryContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NamedQueryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NamedQueryContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedQuery(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_namedQuery(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NamedQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_namedQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedQuery }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedQuery }
}
antlr_rust::tid!{NamedQueryContextExt<'a>}

impl<'input> NamedQueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedQueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedQueryContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedQueryContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NamedQueryContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedQueryContextAttrs<'input> for NamedQueryContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedQuery(&mut self,)
	-> Result<Rc<NamedQueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedQueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 114, RULE_namedQuery);
        let mut _localctx: Rc<NamedQueryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1773);
			let tmp = recog.identifier()?;
			 cast_mut::<_,NamedQueryContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(1774);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(1775);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule query*/
			recog.base.set_state(1776);
			recog.query()?;

			recog.base.set_state(1777);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectItemAlias ----------------
pub type SelectItemAliasContextAll<'input> = SelectItemAliasContext<'input>;


pub type SelectItemAliasContext<'input> = BaseParserRuleContext<'input,SelectItemAliasContextExt<'input>>;

#[derive(Clone)]
pub struct SelectItemAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SelectItemAliasContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SelectItemAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectItemAlias(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_selectItemAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SelectItemAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_selectItemAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectItemAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItemAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItemAlias }
}
antlr_rust::tid!{SelectItemAliasContextExt<'a>}

impl<'input> SelectItemAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectItemAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectItemAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectItemAliasContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SelectItemAliasContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SelectItemAliasContextAttrs<'input> for SelectItemAliasContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectItemAlias(&mut self,)
	-> Result<Rc<SelectItemAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectItemAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 116, RULE_selectItemAlias);
        let mut _localctx: Rc<SelectItemAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnName*/
			recog.base.set_state(1779);
			recog.columnName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectItem ----------------
#[derive(Debug)]
pub enum SelectItemContextAll<'input>{
	SelectSingleContext(SelectSingleContext<'input>),
	SelectMultiContext(SelectMultiContext<'input>),
Error(SelectItemContext<'input>)
}
antlr_rust::tid!{SelectItemContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SelectItemContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for SelectItemContextAll<'input>{}

impl<'input> Deref for SelectItemContextAll<'input>{
	type Target = dyn SelectItemContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SelectItemContextAll::*;
		match self{
			SelectSingleContext(inner) => inner,
			SelectMultiContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SelectItemContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SelectItemContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SelectItemContext<'input> = BaseParserRuleContext<'input,SelectItemContextExt<'input>>;

#[derive(Clone)]
pub struct SelectItemContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SelectItemContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SelectItemContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SelectItemContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SelectItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}
antlr_rust::tid!{SelectItemContextExt<'a>}

impl<'input> SelectItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectItemContextAll<'input>> {
		Rc::new(
		SelectItemContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectItemContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SelectItemContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SelectItemContextExt<'input>>{


}

impl<'input> SelectItemContextAttrs<'input> for SelectItemContext<'input>{}

pub type SelectSingleContext<'input> = BaseParserRuleContext<'input,SelectSingleContextExt<'input>>;

pub trait SelectSingleContextAttrs<'input>: BigqueryParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn selectItemAlias(&self) -> Option<Rc<SelectItemAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> SelectSingleContextAttrs<'input> for SelectSingleContext<'input>{}

pub struct SelectSingleContextExt<'input>{
	base:SelectItemContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SelectSingleContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SelectSingleContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SelectSingleContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_selectSingle(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_selectSingle(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SelectSingleContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_selectSingle(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectSingleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}

impl<'input> Borrow<SelectItemContextExt<'input>> for SelectSingleContext<'input>{
	fn borrow(&self) -> &SelectItemContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SelectItemContextExt<'input>> for SelectSingleContext<'input>{
	fn borrow_mut(&mut self) -> &mut SelectItemContextExt<'input> { &mut self.base }
}

impl<'input> SelectItemContextAttrs<'input> for SelectSingleContext<'input> {}

impl<'input> SelectSingleContextExt<'input>{
	fn new(ctx: &dyn SelectItemContextAttrs<'input>) -> Rc<SelectItemContextAll<'input>>  {
		Rc::new(
			SelectItemContextAll::SelectSingleContext(
				BaseParserRuleContext::copy_from(ctx,SelectSingleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SelectMultiContext<'input> = BaseParserRuleContext<'input,SelectMultiContextExt<'input>>;

pub trait SelectMultiContextAttrs<'input>: BigqueryParserContext<'input>{
	fn multiSelect(&self) -> Option<Rc<MultiSelectContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SelectMultiContextAttrs<'input> for SelectMultiContext<'input>{}

pub struct SelectMultiContextExt<'input>{
	base:SelectItemContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SelectMultiContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SelectMultiContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SelectMultiContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_selectMulti(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_selectMulti(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SelectMultiContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_selectMulti(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectMultiContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}

impl<'input> Borrow<SelectItemContextExt<'input>> for SelectMultiContext<'input>{
	fn borrow(&self) -> &SelectItemContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SelectItemContextExt<'input>> for SelectMultiContext<'input>{
	fn borrow_mut(&mut self) -> &mut SelectItemContextExt<'input> { &mut self.base }
}

impl<'input> SelectItemContextAttrs<'input> for SelectMultiContext<'input> {}

impl<'input> SelectMultiContextExt<'input>{
	fn new(ctx: &dyn SelectItemContextAttrs<'input>) -> Rc<SelectItemContextAll<'input>>  {
		Rc::new(
			SelectItemContextAll::SelectMultiContext(
				BaseParserRuleContext::copy_from(ctx,SelectMultiContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectItem(&mut self,)
	-> Result<Rc<SelectItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 118, RULE_selectItem);
        let mut _localctx: Rc<SelectItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1789);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(217,&mut recog.base)? {
				1 =>{
					let tmp = SelectSingleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(1781);
					recog.expression()?;

					recog.base.set_state(1786);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(216,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1783);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==AS {
								{
								recog.base.set_state(1782);
								recog.base.match_token(AS,&mut recog.err_handler)?;

								}
							}

							/*InvokeRule selectItemAlias*/
							recog.base.set_state(1785);
							recog.selectItemAlias()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = SelectMultiContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule multiSelect*/
					recog.base.set_state(1788);
					recog.multiSelect()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiSelect ----------------
pub type MultiSelectContextAll<'input> = MultiSelectContext<'input>;


pub type MultiSelectContext<'input> = BaseParserRuleContext<'input,MultiSelectContextExt<'input>>;

#[derive(Clone)]
pub struct MultiSelectContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for MultiSelectContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MultiSelectContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiSelect(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_multiSelect(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MultiSelectContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_multiSelect(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiSelectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiSelect }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiSelect }
}
antlr_rust::tid!{MultiSelectContextExt<'a>}

impl<'input> MultiSelectContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiSelectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiSelectContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiSelectContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<MultiSelectContextExt<'input>>{

fn selectStar(&self) -> Option<Rc<SelectStarContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn replaceDefinition_all(&self) ->  Vec<Rc<ReplaceDefinitionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn replaceDefinition(&self, i: usize) -> Option<Rc<ReplaceDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> MultiSelectContextAttrs<'input> for MultiSelectContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiSelect(&mut self,)
	-> Result<Rc<MultiSelectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiSelectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 120, RULE_multiSelect);
        let mut _localctx: Rc<MultiSelectContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule selectStar*/
			recog.base.set_state(1791);
			recog.selectStar()?;

			recog.base.set_state(1794);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(218,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1792);
					recog.base.match_token(EXCEPT,&mut recog.err_handler)?;

					/*InvokeRule identifierList*/
					recog.base.set_state(1793);
					recog.identifierList()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(1808);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==REPLACE {
				{
				recog.base.set_state(1796);
				recog.base.match_token(REPLACE,&mut recog.err_handler)?;

				recog.base.set_state(1797);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule replaceDefinition*/
				recog.base.set_state(1798);
				recog.replaceDefinition()?;

				recog.base.set_state(1803);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1799);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule replaceDefinition*/
					recog.base.set_state(1800);
					recog.replaceDefinition()?;

					}
					}
					recog.base.set_state(1805);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				recog.base.set_state(1806);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectStar ----------------
pub type SelectStarContextAll<'input> = SelectStarContext<'input>;


pub type SelectStarContext<'input> = BaseParserRuleContext<'input,SelectStarContextExt<'input>>;

#[derive(Clone)]
pub struct SelectStarContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SelectStarContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SelectStarContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectStar(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_selectStar(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SelectStarContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_selectStar(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectStarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectStar }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectStar }
}
antlr_rust::tid!{SelectStarContextExt<'a>}

impl<'input> SelectStarContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectStarContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectStarContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectStarContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SelectStarContextExt<'input>>{

fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}

}

impl<'input> SelectStarContextAttrs<'input> for SelectStarContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectStar(&mut self,)
	-> Result<Rc<SelectStarContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectStarContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 122, RULE_selectStar);
        let mut _localctx: Rc<SelectStarContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1815);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ARRAY |
			 ATTACH | AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK |
			 BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT |
			 CURRENT_ROLE | CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE |
			 DATETIME | DAY | DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF |
			 DEALLOCATE | DECLARE | DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER |
			 DENY | DESCRIBE | DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED |
			 DISTSTYLE | DETACH | DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING |
			 ERROR | EVEN | EXCEPTION | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL |
			 EXTRACT | FALSE | FIELDS | FILTER | FINAL | FIRST | FORMAT | FRIDAY |
			 FUNCTION | FUNCTIONS | GENERATED | GRACE | GRANT | GRANTED | GRANTS |
			 GRAPHVIZ | GROUPING | GZIP | HEADER | HOUR | IDENTITY | IF | IMMEDIATE |
			 INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INTERLEAVED | INSERT |
			 INTERVAL | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR | ITERATE | ILIKE |
			 JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE | LAST | LEADING |
			 LEFT | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION | LOCK |
			 LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | NULL | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION |
			 OPTIONS | OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS |
			 PASSING | PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE |
			 PIVOT | POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES |
			 PROPERTIES | PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME |
			 REPEATABLE | REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE |
			 REPEAT | RETURNS | REVOKE | RIGHT | RLS | ROLE | ROLES | ROLLBACK | ROW |
			 RUNNING | SAFE | SAFE_CAST | SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS |
			 SECURITY | SEEK | SEMI | SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION |
			 SETS | SHOW | SIMILAR | SNAPSHOT | SORTKEY | START | STATS | STORED |
			 STRUCT | SUBSET | SUBSTRING | SUNDAY | SYSTEM | SYSTEM_TIME | TABLE |
			 TABLES | TEMP | TEMPORARY | TERMINATED | TEXT | STRING_KW | THURSDAY |
			 TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF | TOP | TRAILING | TARGET |
			 SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM | TRIM | TRUE | TRUNCATE |
			 TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED | UNCONDITIONAL |
			 UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL | UPDATE |
			 USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES |
			 VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE | WITHOUT |
			 WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | LPAREN | LBRACKET |
			 MINUS | QUOTED_STRING | TRIPLE_QUOTED_STRING | RAW_QUOTED_STRING | RAW_TRIPLE_QUOTED_STRING |
			 BINARY_LITERAL | INTEGER_VALUE | HEXADECIMAL_VALUE | DECIMAL_VALUE |
			 DOUBLE_VALUE | IDENTIFIER | BACKQUOTED_IDENTIFIER | VARIABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule primaryExpression*/
					recog.base.set_state(1810);
					recog.primaryExpression_rec(0)?;

					recog.base.set_state(1811);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					recog.base.set_state(1812);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}

			 ASTERISK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1814);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relation ----------------
pub type RelationContextAll<'input> = RelationContext<'input>;


pub type RelationContext<'input> = BaseParserRuleContext<'input,RelationContextExt<'input>>;

#[derive(Clone)]
pub struct RelationContextExt<'input>{
	pub target: Option<Rc<JoinedRelationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for RelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RelationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relation(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_relation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_relation(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relation }
}
antlr_rust::tid!{RelationContextExt<'a>}

impl<'input> RelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationContextExt{
				target: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RelationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<RelationContextExt<'input>>{

fn joinedRelation(&self) -> Option<Rc<JoinedRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RelationContextAttrs<'input> for RelationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relation(&mut self,)
	-> Result<Rc<RelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 124, RULE_relation);
        let mut _localctx: Rc<RelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule joinedRelation*/
			recog.base.set_state(1817);
			let tmp = recog.joinedRelation_rec(0)?;
			 cast_mut::<_,RelationContext >(&mut _localctx).target = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinedRelation ----------------
#[derive(Debug)]
pub enum JoinedRelationContextAll<'input>{
	RelationDefaultContext(RelationDefaultContext<'input>),
	JoinRelationContext(JoinRelationContext<'input>),
Error(JoinedRelationContext<'input>)
}
antlr_rust::tid!{JoinedRelationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for JoinedRelationContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for JoinedRelationContextAll<'input>{}

impl<'input> Deref for JoinedRelationContextAll<'input>{
	type Target = dyn JoinedRelationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use JoinedRelationContextAll::*;
		match self{
			RelationDefaultContext(inner) => inner,
			JoinRelationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for JoinedRelationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for JoinedRelationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type JoinedRelationContext<'input> = BaseParserRuleContext<'input,JoinedRelationContextExt<'input>>;

#[derive(Clone)]
pub struct JoinedRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for JoinedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for JoinedRelationContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for JoinedRelationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for JoinedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinedRelation }
}
antlr_rust::tid!{JoinedRelationContextExt<'a>}

impl<'input> JoinedRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinedRelationContextAll<'input>> {
		Rc::new(
		JoinedRelationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinedRelationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait JoinedRelationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<JoinedRelationContextExt<'input>>{


}

impl<'input> JoinedRelationContextAttrs<'input> for JoinedRelationContext<'input>{}

pub type RelationDefaultContext<'input> = BaseParserRuleContext<'input,RelationDefaultContextExt<'input>>;

pub trait RelationDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn noJoinRelation(&self) -> Option<Rc<NoJoinRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RelationDefaultContextAttrs<'input> for RelationDefaultContext<'input>{}

pub struct RelationDefaultContextExt<'input>{
	base:JoinedRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RelationDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RelationDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RelationDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_relationDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_relationDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RelationDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_relationDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinedRelation }
}

impl<'input> Borrow<JoinedRelationContextExt<'input>> for RelationDefaultContext<'input>{
	fn borrow(&self) -> &JoinedRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<JoinedRelationContextExt<'input>> for RelationDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut JoinedRelationContextExt<'input> { &mut self.base }
}

impl<'input> JoinedRelationContextAttrs<'input> for RelationDefaultContext<'input> {}

impl<'input> RelationDefaultContextExt<'input>{
	fn new(ctx: &dyn JoinedRelationContextAttrs<'input>) -> Rc<JoinedRelationContextAll<'input>>  {
		Rc::new(
			JoinedRelationContextAll::RelationDefaultContext(
				BaseParserRuleContext::copy_from(ctx,RelationDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JoinRelationContext<'input> = BaseParserRuleContext<'input,JoinRelationContextExt<'input>>;

pub trait JoinRelationContextAttrs<'input>: BigqueryParserContext<'input>{
	fn joinedRelation(&self) -> Option<Rc<JoinedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token CROSS
	/// Returns `None` if there is no child corresponding to token CROSS
	fn CROSS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CROSS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token JOIN
	/// Returns `None` if there is no child corresponding to token JOIN
	fn JOIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(JOIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
	fn joinType(&self) -> Option<Rc<JoinTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NATURAL
	/// Returns `None` if there is no child corresponding to token NATURAL
	fn NATURAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NATURAL, 0)
	}
	fn noJoinRelation(&self) -> Option<Rc<NoJoinRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn joinCriteria(&self) -> Option<Rc<JoinCriteriaContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> JoinRelationContextAttrs<'input> for JoinRelationContext<'input>{}

pub struct JoinRelationContextExt<'input>{
	base:JoinedRelationContextExt<'input>,
	pub left: Option<Rc<JoinedRelationContextAll<'input>>>,
	pub right: Option<Rc<NoJoinRelationContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JoinRelationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for JoinRelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for JoinRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_joinRelation(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_joinRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for JoinRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_joinRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinedRelation }
}

impl<'input> Borrow<JoinedRelationContextExt<'input>> for JoinRelationContext<'input>{
	fn borrow(&self) -> &JoinedRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<JoinedRelationContextExt<'input>> for JoinRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut JoinedRelationContextExt<'input> { &mut self.base }
}

impl<'input> JoinedRelationContextAttrs<'input> for JoinRelationContext<'input> {}

impl<'input> JoinRelationContextExt<'input>{
	fn new(ctx: &dyn JoinedRelationContextAttrs<'input>) -> Rc<JoinedRelationContextAll<'input>>  {
		Rc::new(
			JoinedRelationContextAll::JoinRelationContext(
				BaseParserRuleContext::copy_from(ctx,JoinRelationContextExt{
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  joinedRelation(&mut self,)
	-> Result<Rc<JoinedRelationContextAll<'input>>,ANTLRError> {
		self.joinedRelation_rec(0)
	}

	fn joinedRelation_rec(&mut self, _p: isize)
	-> Result<Rc<JoinedRelationContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = JoinedRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 126, RULE_joinedRelation, _p);
	    let mut _localctx: Rc<JoinedRelationContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 126;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			{
			let mut tmp = RelationDefaultContextExt::new(&**_localctx);
			recog.ctx = Some(tmp.clone());
			_localctx = tmp;
			_prevctx = _localctx.clone();


			/*InvokeRule noJoinRelation*/
			recog.base.set_state(1820);
			recog.noJoinRelation()?;

			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(1846);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(225,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					{
					/*recRuleLabeledAltStartAction*/
					let mut tmp = JoinRelationContextExt::new(&**JoinedRelationContextExt::new(_parentctx.clone(), _parentState));
					if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut tmp){
						ctx.left = Some(_prevctx.clone());
					} else {unreachable!("cant cast");}
					recog.push_new_recursion_context(tmp.clone(), _startState, RULE_joinedRelation);
					_localctx = tmp;
					recog.base.set_state(1822);
					if !({recog.precpred(None, 2)}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
					}
					recog.base.set_state(1842);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 CROSS 
						=> {
							{
							recog.base.set_state(1823);
							recog.base.match_token(CROSS,&mut recog.err_handler)?;

							recog.base.set_state(1824);
							recog.base.match_token(JOIN,&mut recog.err_handler)?;

							/*InvokeRule noJoinRelation*/
							recog.base.set_state(1825);
							let tmp = recog.noJoinRelation()?;
							if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(1827);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(222,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule joinCriteria*/
									recog.base.set_state(1826);
									recog.joinCriteria()?;

									}
								}

								_ => {}
							}
							}
						}

					 COMMA 
						=> {
							{
							recog.base.set_state(1829);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule noJoinRelation*/
							recog.base.set_state(1830);
							let tmp = recog.noJoinRelation()?;
							if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

					 FULL | INNER | JOIN | LEFT | RIGHT 
						=> {
							{
							/*InvokeRule joinType*/
							recog.base.set_state(1831);
							recog.joinType()?;

							recog.base.set_state(1832);
							recog.base.match_token(JOIN,&mut recog.err_handler)?;

							/*InvokeRule noJoinRelation*/
							recog.base.set_state(1833);
							let tmp = recog.noJoinRelation()?;
							if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(1835);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(223,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule joinCriteria*/
									recog.base.set_state(1834);
									recog.joinCriteria()?;

									}
								}

								_ => {}
							}
							}
						}

					 NATURAL 
						=> {
							{
							recog.base.set_state(1837);
							recog.base.match_token(NATURAL,&mut recog.err_handler)?;

							/*InvokeRule joinType*/
							recog.base.set_state(1838);
							recog.joinType()?;

							recog.base.set_state(1839);
							recog.base.match_token(JOIN,&mut recog.err_handler)?;

							/*InvokeRule noJoinRelation*/
							recog.base.set_state(1840);
							let tmp = recog.noJoinRelation()?;
							if let JoinedRelationContextAll::JoinRelationContext(ctx) = cast_mut::<_,JoinedRelationContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
					} 
				}
				recog.base.set_state(1848);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(225,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- noJoinRelation ----------------
pub type NoJoinRelationContextAll<'input> = NoJoinRelationContext<'input>;


pub type NoJoinRelationContext<'input> = BaseParserRuleContext<'input,NoJoinRelationContextExt<'input>>;

#[derive(Clone)]
pub struct NoJoinRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NoJoinRelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NoJoinRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_noJoinRelation(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_noJoinRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NoJoinRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_noJoinRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for NoJoinRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_noJoinRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_noJoinRelation }
}
antlr_rust::tid!{NoJoinRelationContextExt<'a>}

impl<'input> NoJoinRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NoJoinRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NoJoinRelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NoJoinRelationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NoJoinRelationContextExt<'input>>{

fn sampledRelation(&self) -> Option<Rc<SampledRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn joinedRelation(&self) -> Option<Rc<JoinedRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> NoJoinRelationContextAttrs<'input> for NoJoinRelationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn noJoinRelation(&mut self,)
	-> Result<Rc<NoJoinRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NoJoinRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 128, RULE_noJoinRelation);
        let mut _localctx: Rc<NoJoinRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1854);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(226,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule sampledRelation*/
					recog.base.set_state(1849);
					recog.sampledRelation()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1850);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule joinedRelation*/
					recog.base.set_state(1851);
					recog.joinedRelation_rec(0)?;

					recog.base.set_state(1852);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinType ----------------
pub type JoinTypeContextAll<'input> = JoinTypeContext<'input>;


pub type JoinTypeContext<'input> = BaseParserRuleContext<'input,JoinTypeContextExt<'input>>;

#[derive(Clone)]
pub struct JoinTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for JoinTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for JoinTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinType(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_joinType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for JoinTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_joinType(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinType }
}
antlr_rust::tid!{JoinTypeContextExt<'a>}

impl<'input> JoinTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinTypeContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<JoinTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}

}

impl<'input> JoinTypeContextAttrs<'input> for JoinTypeContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinType(&mut self,)
	-> Result<Rc<JoinTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 130, RULE_joinType);
        let mut _localctx: Rc<JoinTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1871);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INNER | JOIN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1857);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INNER {
						{
						recog.base.set_state(1856);
						recog.base.match_token(INNER,&mut recog.err_handler)?;

						}
					}

					}
				}

			 LEFT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1859);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					recog.base.set_state(1861);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(1860);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}

			 RIGHT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1863);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					recog.base.set_state(1865);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(1864);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}

			 FULL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(1867);
					recog.base.match_token(FULL,&mut recog.err_handler)?;

					recog.base.set_state(1869);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(1868);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinCriteria ----------------
pub type JoinCriteriaContextAll<'input> = JoinCriteriaContext<'input>;


pub type JoinCriteriaContext<'input> = BaseParserRuleContext<'input,JoinCriteriaContextExt<'input>>;

#[derive(Clone)]
pub struct JoinCriteriaContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for JoinCriteriaContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for JoinCriteriaContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinCriteria(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_joinCriteria(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for JoinCriteriaContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_joinCriteria(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinCriteriaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinCriteria }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinCriteria }
}
antlr_rust::tid!{JoinCriteriaContextExt<'a>}

impl<'input> JoinCriteriaContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinCriteriaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinCriteriaContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinCriteriaContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<JoinCriteriaContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> JoinCriteriaContextAttrs<'input> for JoinCriteriaContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinCriteria(&mut self,)
	-> Result<Rc<JoinCriteriaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinCriteriaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 132, RULE_joinCriteria);
        let mut _localctx: Rc<JoinCriteriaContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1890);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ON 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1873);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(1874);
					recog.booleanExpression_rec(0)?;

					}
				}

			 USING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1875);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					recog.base.set_state(1876);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1877);
					recog.identifier()?;

					recog.base.set_state(1882);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(232,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(1878);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(1879);
							recog.identifier()?;

							}
							} 
						}
						recog.base.set_state(1884);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(232,&mut recog.base)?;
					}
					recog.base.set_state(1886);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(1885);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,JoinCriteriaContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(1888);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampledRelationTarget ----------------
pub type SampledRelationTargetContextAll<'input> = SampledRelationTargetContext<'input>;


pub type SampledRelationTargetContext<'input> = BaseParserRuleContext<'input,SampledRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct SampledRelationTargetContextExt<'input>{
	pub target: Option<Rc<PivotedRelationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SampledRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SampledRelationTargetContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampledRelationTarget(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_sampledRelationTarget(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SampledRelationTargetContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_sampledRelationTarget(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampledRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampledRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampledRelationTarget }
}
antlr_rust::tid!{SampledRelationTargetContextExt<'a>}

impl<'input> SampledRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampledRelationTargetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampledRelationTargetContextExt{
				target: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SampledRelationTargetContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SampledRelationTargetContextExt<'input>>{

fn pivotedRelation(&self) -> Option<Rc<PivotedRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SampledRelationTargetContextAttrs<'input> for SampledRelationTargetContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampledRelationTarget(&mut self,)
	-> Result<Rc<SampledRelationTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampledRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 134, RULE_sampledRelationTarget);
        let mut _localctx: Rc<SampledRelationTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule pivotedRelation*/
			recog.base.set_state(1892);
			let tmp = recog.pivotedRelation()?;
			 cast_mut::<_,SampledRelationTargetContext >(&mut _localctx).target = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampledRelation ----------------
pub type SampledRelationContextAll<'input> = SampledRelationContext<'input>;


pub type SampledRelationContext<'input> = BaseParserRuleContext<'input,SampledRelationContextExt<'input>>;

#[derive(Clone)]
pub struct SampledRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SampledRelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SampledRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampledRelation(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_sampledRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SampledRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_sampledRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampledRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampledRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampledRelation }
}
antlr_rust::tid!{SampledRelationContextExt<'a>}

impl<'input> SampledRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampledRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampledRelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SampledRelationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SampledRelationContextExt<'input>>{

fn sampledRelationTarget(&self) -> Option<Rc<SampledRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sampleOperator(&self) -> Option<Rc<SampleOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SampledRelationContextAttrs<'input> for SampledRelationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampledRelation(&mut self,)
	-> Result<Rc<SampledRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampledRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 136, RULE_sampledRelation);
        let mut _localctx: Rc<SampledRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule sampledRelationTarget*/
			recog.base.set_state(1894);
			recog.sampledRelationTarget()?;

			recog.base.set_state(1896);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(235,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule sampleOperator*/
					recog.base.set_state(1895);
					recog.sampleOperator()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampleOperator ----------------
pub type SampleOperatorContextAll<'input> = SampleOperatorContext<'input>;


pub type SampleOperatorContext<'input> = BaseParserRuleContext<'input,SampleOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SampleOperatorContextExt<'input>{
	pub percentage: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SampleOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SampleOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampleOperator(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_sampleOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SampleOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_sampleOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleOperator }
}
antlr_rust::tid!{SampleOperatorContextExt<'a>}

impl<'input> SampleOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleOperatorContextExt{
				percentage: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SampleOperatorContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SampleOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
fn sampleMethod(&self) -> Option<Rc<SampleMethodContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENT_KW
/// Returns `None` if there is no child corresponding to token PERCENT_KW
fn PERCENT_KW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PERCENT_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SampleOperatorContextAttrs<'input> for SampleOperatorContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampleOperator(&mut self,)
	-> Result<Rc<SampleOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 138, RULE_sampleOperator);
        let mut _localctx: Rc<SampleOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1898);
			recog.base.match_token(TABLESAMPLE,&mut recog.err_handler)?;

			/*InvokeRule sampleMethod*/
			recog.base.set_state(1899);
			recog.sampleMethod()?;

			recog.base.set_state(1900);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1901);
			let tmp = recog.expression()?;
			 cast_mut::<_,SampleOperatorContext >(&mut _localctx).percentage = Some(tmp.clone());
			  

			recog.base.set_state(1902);
			recog.base.match_token(PERCENT_KW,&mut recog.err_handler)?;

			recog.base.set_state(1903);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampleMethod ----------------
pub type SampleMethodContextAll<'input> = SampleMethodContext<'input>;


pub type SampleMethodContext<'input> = BaseParserRuleContext<'input,SampleMethodContextExt<'input>>;

#[derive(Clone)]
pub struct SampleMethodContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SampleMethodContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SampleMethodContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampleMethod(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_sampleMethod(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SampleMethodContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_sampleMethod(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleMethodContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}
antlr_rust::tid!{SampleMethodContextExt<'a>}

impl<'input> SampleMethodContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleMethodContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleMethodContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SampleMethodContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SampleMethodContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BERNOULLI
/// Returns `None` if there is no child corresponding to token BERNOULLI
fn BERNOULLI(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BERNOULLI, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM
/// Returns `None` if there is no child corresponding to token SYSTEM
fn SYSTEM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM, 0)
}

}

impl<'input> SampleMethodContextAttrs<'input> for SampleMethodContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampleMethod(&mut self,)
	-> Result<Rc<SampleMethodContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleMethodContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 140, RULE_sampleMethod);
        let mut _localctx: Rc<SampleMethodContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1905);
			_la = recog.base.input.la(1);
			if { !(_la==BERNOULLI || _la==SYSTEM) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- trimsSpecification ----------------
pub type TrimsSpecificationContextAll<'input> = TrimsSpecificationContext<'input>;


pub type TrimsSpecificationContext<'input> = BaseParserRuleContext<'input,TrimsSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct TrimsSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TrimsSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TrimsSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_trimsSpecification(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_trimsSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TrimsSpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_trimsSpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for TrimsSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_trimsSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_trimsSpecification }
}
antlr_rust::tid!{TrimsSpecificationContextExt<'a>}

impl<'input> TrimsSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TrimsSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TrimsSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TrimsSpecificationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TrimsSpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEADING
/// Returns `None` if there is no child corresponding to token LEADING
fn LEADING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LEADING, 0)
}
/// Retrieves first TerminalNode corresponding to token TRAILING
/// Returns `None` if there is no child corresponding to token TRAILING
fn TRAILING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRAILING, 0)
}
/// Retrieves first TerminalNode corresponding to token BOTH
/// Returns `None` if there is no child corresponding to token BOTH
fn BOTH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BOTH, 0)
}

}

impl<'input> TrimsSpecificationContextAttrs<'input> for TrimsSpecificationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn trimsSpecification(&mut self,)
	-> Result<Rc<TrimsSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TrimsSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 142, RULE_trimsSpecification);
        let mut _localctx: Rc<TrimsSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1907);
			_la = recog.base.input.la(1);
			if { !(_la==BOTH || _la==LEADING || _la==TRAILING) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- listAggOverflowBehavior ----------------
pub type ListAggOverflowBehaviorContextAll<'input> = ListAggOverflowBehaviorContext<'input>;


pub type ListAggOverflowBehaviorContext<'input> = BaseParserRuleContext<'input,ListAggOverflowBehaviorContextExt<'input>>;

#[derive(Clone)]
pub struct ListAggOverflowBehaviorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ListAggOverflowBehaviorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ListAggOverflowBehaviorContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_listAggOverflowBehavior(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_listAggOverflowBehavior(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ListAggOverflowBehaviorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_listAggOverflowBehavior(self);
	}
}

impl<'input> CustomRuleContext<'input> for ListAggOverflowBehaviorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_listAggOverflowBehavior }
	//fn type_rule_index() -> usize where Self: Sized { RULE_listAggOverflowBehavior }
}
antlr_rust::tid!{ListAggOverflowBehaviorContextExt<'a>}

impl<'input> ListAggOverflowBehaviorContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ListAggOverflowBehaviorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ListAggOverflowBehaviorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ListAggOverflowBehaviorContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ListAggOverflowBehaviorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ERROR
/// Returns `None` if there is no child corresponding to token ERROR
fn ERROR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ERROR, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUNCATE
/// Returns `None` if there is no child corresponding to token TRUNCATE
fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRUNCATE, 0)
}
fn listaggCountIndication(&self) -> Option<Rc<ListaggCountIndicationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ListAggOverflowBehaviorContextAttrs<'input> for ListAggOverflowBehaviorContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn listAggOverflowBehavior(&mut self,)
	-> Result<Rc<ListAggOverflowBehaviorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ListAggOverflowBehaviorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 144, RULE_listAggOverflowBehavior);
        let mut _localctx: Rc<ListAggOverflowBehaviorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1915);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ERROR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1909);
					recog.base.match_token(ERROR,&mut recog.err_handler)?;

					}
				}

			 TRUNCATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1910);
					recog.base.match_token(TRUNCATE,&mut recog.err_handler)?;

					recog.base.set_state(1912);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)))) != 0) {
						{
						/*InvokeRule string*/
						recog.base.set_state(1911);
						recog.string()?;

						}
					}

					/*InvokeRule listaggCountIndication*/
					recog.base.set_state(1914);
					recog.listaggCountIndication()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- listaggCountIndication ----------------
pub type ListaggCountIndicationContextAll<'input> = ListaggCountIndicationContext<'input>;


pub type ListaggCountIndicationContext<'input> = BaseParserRuleContext<'input,ListaggCountIndicationContextExt<'input>>;

#[derive(Clone)]
pub struct ListaggCountIndicationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ListaggCountIndicationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ListaggCountIndicationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_listaggCountIndication(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_listaggCountIndication(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ListaggCountIndicationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_listaggCountIndication(self);
	}
}

impl<'input> CustomRuleContext<'input> for ListaggCountIndicationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_listaggCountIndication }
	//fn type_rule_index() -> usize where Self: Sized { RULE_listaggCountIndication }
}
antlr_rust::tid!{ListaggCountIndicationContextExt<'a>}

impl<'input> ListaggCountIndicationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ListaggCountIndicationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ListaggCountIndicationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ListaggCountIndicationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ListaggCountIndicationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token COUNT
/// Returns `None` if there is no child corresponding to token COUNT
fn COUNT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COUNT, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHOUT
/// Returns `None` if there is no child corresponding to token WITHOUT
fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WITHOUT, 0)
}

}

impl<'input> ListaggCountIndicationContextAttrs<'input> for ListaggCountIndicationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn listaggCountIndication(&mut self,)
	-> Result<Rc<ListaggCountIndicationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ListaggCountIndicationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 146, RULE_listaggCountIndication);
        let mut _localctx: Rc<ListaggCountIndicationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1921);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 WITH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1917);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(1918);
					recog.base.match_token(COUNT,&mut recog.err_handler)?;

					}
				}

			 WITHOUT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1919);
					recog.base.match_token(WITHOUT,&mut recog.err_handler)?;

					recog.base.set_state(1920);
					recog.base.match_token(COUNT,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- variableDefinition ----------------
pub type VariableDefinitionContextAll<'input> = VariableDefinitionContext<'input>;


pub type VariableDefinitionContext<'input> = BaseParserRuleContext<'input,VariableDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct VariableDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for VariableDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for VariableDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_variableDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_variableDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for VariableDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_variableDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for VariableDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_variableDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_variableDefinition }
}
antlr_rust::tid!{VariableDefinitionContextExt<'a>}

impl<'input> VariableDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VariableDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VariableDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VariableDefinitionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<VariableDefinitionContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> VariableDefinitionContextAttrs<'input> for VariableDefinitionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn variableDefinition(&mut self,)
	-> Result<Rc<VariableDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VariableDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 148, RULE_variableDefinition);
        let mut _localctx: Rc<VariableDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1923);
			recog.identifier()?;

			recog.base.set_state(1924);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1925);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotedRelationTarget ----------------
pub type PivotedRelationTargetContextAll<'input> = PivotedRelationTargetContext<'input>;


pub type PivotedRelationTargetContext<'input> = BaseParserRuleContext<'input,PivotedRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct PivotedRelationTargetContextExt<'input>{
	pub target: Option<Rc<RelationPrimaryContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PivotedRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotedRelationTargetContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotedRelationTarget(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_pivotedRelationTarget(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotedRelationTargetContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pivotedRelationTarget(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotedRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotedRelationTarget }
}
antlr_rust::tid!{PivotedRelationTargetContextExt<'a>}

impl<'input> PivotedRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotedRelationTargetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotedRelationTargetContextExt{
				target: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotedRelationTargetContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PivotedRelationTargetContextExt<'input>>{

fn relationPrimary(&self) -> Option<Rc<RelationPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PivotedRelationTargetContextAttrs<'input> for PivotedRelationTargetContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotedRelationTarget(&mut self,)
	-> Result<Rc<PivotedRelationTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotedRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 150, RULE_pivotedRelationTarget);
        let mut _localctx: Rc<PivotedRelationTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule relationPrimary*/
			recog.base.set_state(1927);
			let tmp = recog.relationPrimary()?;
			 cast_mut::<_,PivotedRelationTargetContext >(&mut _localctx).target = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotedRelation ----------------
pub type PivotedRelationContextAll<'input> = PivotedRelationContext<'input>;


pub type PivotedRelationContext<'input> = BaseParserRuleContext<'input,PivotedRelationContextExt<'input>>;

#[derive(Clone)]
pub struct PivotedRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PivotedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotedRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotedRelation(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_pivotedRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotedRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pivotedRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotedRelation }
}
antlr_rust::tid!{PivotedRelationContextExt<'a>}

impl<'input> PivotedRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotedRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotedRelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotedRelationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PivotedRelationContextExt<'input>>{

fn pivotedRelationTarget(&self) -> Option<Rc<PivotedRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn pivotOperator_all(&self) ->  Vec<Rc<PivotOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn pivotOperator(&self, i: usize) -> Option<Rc<PivotOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PivotedRelationContextAttrs<'input> for PivotedRelationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotedRelation(&mut self,)
	-> Result<Rc<PivotedRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotedRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 152, RULE_pivotedRelation);
        let mut _localctx: Rc<PivotedRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule pivotedRelationTarget*/
			recog.base.set_state(1929);
			recog.pivotedRelationTarget()?;

			recog.base.set_state(1933);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(239,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule pivotOperator*/
					recog.base.set_state(1930);
					recog.pivotOperator()?;

					}
					} 
				}
				recog.base.set_state(1935);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(239,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotAggregates ----------------
pub type PivotAggregatesContextAll<'input> = PivotAggregatesContext<'input>;


pub type PivotAggregatesContext<'input> = BaseParserRuleContext<'input,PivotAggregatesContextExt<'input>>;

#[derive(Clone)]
pub struct PivotAggregatesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PivotAggregatesContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotAggregatesContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotAggregates(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_pivotAggregates(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotAggregatesContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pivotAggregates(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotAggregatesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotAggregates }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotAggregates }
}
antlr_rust::tid!{PivotAggregatesContextExt<'a>}

impl<'input> PivotAggregatesContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotAggregatesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotAggregatesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotAggregatesContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PivotAggregatesContextExt<'input>>{

fn namedExpressionSeq(&self) -> Option<Rc<NamedExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PivotAggregatesContextAttrs<'input> for PivotAggregatesContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotAggregates(&mut self,)
	-> Result<Rc<PivotAggregatesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotAggregatesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 154, RULE_pivotAggregates);
        let mut _localctx: Rc<PivotAggregatesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpressionSeq*/
			recog.base.set_state(1936);
			recog.namedExpressionSeq()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotFrom ----------------
pub type PivotFromContextAll<'input> = PivotFromContext<'input>;


pub type PivotFromContext<'input> = BaseParserRuleContext<'input,PivotFromContextExt<'input>>;

#[derive(Clone)]
pub struct PivotFromContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PivotFromContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotFromContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotFrom(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_pivotFrom(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotFromContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pivotFrom(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotFromContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotFrom }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotFrom }
}
antlr_rust::tid!{PivotFromContextExt<'a>}

impl<'input> PivotFromContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotFromContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotFromContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotFromContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PivotFromContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PivotFromContextAttrs<'input> for PivotFromContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotFrom(&mut self,)
	-> Result<Rc<PivotFromContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotFromContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 156, RULE_pivotFrom);
        let mut _localctx: Rc<PivotFromContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(1938);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotInto ----------------
#[derive(Debug)]
pub enum PivotIntoContextAll<'input>{
	PivotIntoNamedExpressionContext(PivotIntoNamedExpressionContext<'input>),
Error(PivotIntoContext<'input>)
}
antlr_rust::tid!{PivotIntoContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotIntoContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PivotIntoContextAll<'input>{}

impl<'input> Deref for PivotIntoContextAll<'input>{
	type Target = dyn PivotIntoContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotIntoContextAll::*;
		match self{
			PivotIntoNamedExpressionContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotIntoContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotIntoContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotIntoContext<'input> = BaseParserRuleContext<'input,PivotIntoContextExt<'input>>;

#[derive(Clone)]
pub struct PivotIntoContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PivotIntoContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotIntoContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotIntoContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotIntoContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotInto }
}
antlr_rust::tid!{PivotIntoContextExt<'a>}

impl<'input> PivotIntoContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotIntoContextAll<'input>> {
		Rc::new(
		PivotIntoContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotIntoContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotIntoContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PivotIntoContextExt<'input>>{


}

impl<'input> PivotIntoContextAttrs<'input> for PivotIntoContext<'input>{}

pub type PivotIntoNamedExpressionContext<'input> = BaseParserRuleContext<'input,PivotIntoNamedExpressionContextExt<'input>>;

pub trait PivotIntoNamedExpressionContextAttrs<'input>: BigqueryParserContext<'input>{
	fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PivotIntoNamedExpressionContextAttrs<'input> for PivotIntoNamedExpressionContext<'input>{}

pub struct PivotIntoNamedExpressionContextExt<'input>{
	base:PivotIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotIntoNamedExpressionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PivotIntoNamedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotIntoNamedExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivotIntoNamedExpression(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_pivotIntoNamedExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotIntoNamedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pivotIntoNamedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotIntoNamedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotInto }
}

impl<'input> Borrow<PivotIntoContextExt<'input>> for PivotIntoNamedExpressionContext<'input>{
	fn borrow(&self) -> &PivotIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotIntoContextExt<'input>> for PivotIntoNamedExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotIntoContextExt<'input> { &mut self.base }
}

impl<'input> PivotIntoContextAttrs<'input> for PivotIntoNamedExpressionContext<'input> {}

impl<'input> PivotIntoNamedExpressionContextExt<'input>{
	fn new(ctx: &dyn PivotIntoContextAttrs<'input>) -> Rc<PivotIntoContextAll<'input>>  {
		Rc::new(
			PivotIntoContextAll::PivotIntoNamedExpressionContext(
				BaseParserRuleContext::copy_from(ctx,PivotIntoNamedExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotInto(&mut self,)
	-> Result<Rc<PivotIntoContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotIntoContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 158, RULE_pivotInto);
        let mut _localctx: Rc<PivotIntoContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = PivotIntoNamedExpressionContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(1940);
			recog.namedExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotAsAlias ----------------
pub type PivotAsAliasContextAll<'input> = PivotAsAliasContext<'input>;


pub type PivotAsAliasContext<'input> = BaseParserRuleContext<'input,PivotAsAliasContextExt<'input>>;

#[derive(Clone)]
pub struct PivotAsAliasContextExt<'input>{
	pub alias: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PivotAsAliasContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotAsAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotAsAlias(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_pivotAsAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotAsAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pivotAsAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotAsAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotAsAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotAsAlias }
}
antlr_rust::tid!{PivotAsAliasContextExt<'a>}

impl<'input> PivotAsAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotAsAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotAsAliasContextExt{
				alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotAsAliasContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PivotAsAliasContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> PivotAsAliasContextAttrs<'input> for PivotAsAliasContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotAsAlias(&mut self,)
	-> Result<Rc<PivotAsAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotAsAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 160, RULE_pivotAsAlias);
        let mut _localctx: Rc<PivotAsAliasContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1946);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(241,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1943);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(1942);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule identifier*/
					recog.base.set_state(1945);
					let tmp = recog.identifier()?;
					 cast_mut::<_,PivotAsAliasContext >(&mut _localctx).alias = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleColumnUnpivot ----------------
pub type SingleColumnUnpivotContextAll<'input> = SingleColumnUnpivotContext<'input>;


pub type SingleColumnUnpivotContext<'input> = BaseParserRuleContext<'input,SingleColumnUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct SingleColumnUnpivotContextExt<'input>{
	pub valuesColumn: Option<Rc<IdentifierContextAll<'input>>>,
	pub nameColumn: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for SingleColumnUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SingleColumnUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleColumnUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_singleColumnUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SingleColumnUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_singleColumnUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleColumnUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleColumnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleColumnUnpivot }
}
antlr_rust::tid!{SingleColumnUnpivotContextExt<'a>}

impl<'input> SingleColumnUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleColumnUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleColumnUnpivotContextExt{
				valuesColumn: None, nameColumn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleColumnUnpivotContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<SingleColumnUnpivotContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnsToUnpivot(&self) -> Option<Rc<ColumnsToUnpivotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SingleColumnUnpivotContextAttrs<'input> for SingleColumnUnpivotContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleColumnUnpivot(&mut self,)
	-> Result<Rc<SingleColumnUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleColumnUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 162, RULE_singleColumnUnpivot);
        let mut _localctx: Rc<SingleColumnUnpivotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1948);
			let tmp = recog.identifier()?;
			 cast_mut::<_,SingleColumnUnpivotContext >(&mut _localctx).valuesColumn = Some(tmp.clone());
			  

			recog.base.set_state(1949);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(1950);
			let tmp = recog.identifier()?;
			 cast_mut::<_,SingleColumnUnpivotContext >(&mut _localctx).nameColumn = Some(tmp.clone());
			  

			recog.base.set_state(1951);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(1952);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnsToUnpivot*/
			recog.base.set_state(1953);
			recog.columnsToUnpivot()?;

			recog.base.set_state(1954);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnsToUnpivot ----------------
pub type ColumnsToUnpivotContextAll<'input> = ColumnsToUnpivotContext<'input>;


pub type ColumnsToUnpivotContext<'input> = BaseParserRuleContext<'input,ColumnsToUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnsToUnpivotContextExt<'input>{
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub unpivotCol:Vec<Rc<IdentifierContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnsToUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnsToUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnsToUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnsToUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnsToUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnsToUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnsToUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnsToUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnsToUnpivot }
}
antlr_rust::tid!{ColumnsToUnpivotContextExt<'a>}

impl<'input> ColumnsToUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnsToUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnsToUnpivotContextExt{
				tail: None, 
				identifier: None, 
				unpivotCol: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnsToUnpivotContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnsToUnpivotContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn unpivotAlias_all(&self) ->  Vec<Rc<UnpivotAliasContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unpivotAlias(&self, i: usize) -> Option<Rc<UnpivotAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves all `TerminalNode`s corresponding to token AS in current rule
fn AS_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token AS, starting from 0.
/// Returns `None` if number of children corresponding to token AS is less or equal than `i`.
fn AS(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, i)
}

}

impl<'input> ColumnsToUnpivotContextAttrs<'input> for ColumnsToUnpivotContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnsToUnpivot(&mut self,)
	-> Result<Rc<ColumnsToUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnsToUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 164, RULE_columnsToUnpivot);
        let mut _localctx: Rc<ColumnsToUnpivotContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1956);
			let tmp = recog.identifier()?;
			 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier.clone().unwrap()
			 ;
			 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).unpivotCol.push(temp);
			  
			recog.base.set_state(1961);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS || ((((_la - 407)) & !0x3f) == 0 && ((1usize << (_la - 407)) & ((1usize << (MINUS - 407)) | (1usize << (QUOTED_STRING - 407)) | (1usize << (TRIPLE_QUOTED_STRING - 407)) | (1usize << (RAW_QUOTED_STRING - 407)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 407)) | (1usize << (INTEGER_VALUE - 407)) | (1usize << (HEXADECIMAL_VALUE - 407)) | (1usize << (DECIMAL_VALUE - 407)) | (1usize << (DOUBLE_VALUE - 407)))) != 0) {
				{
				recog.base.set_state(1958);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==AS {
					{
					recog.base.set_state(1957);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					}
				}

				/*InvokeRule unpivotAlias*/
				recog.base.set_state(1960);
				recog.unpivotAlias()?;

				}
			}

			recog.base.set_state(1973);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(246,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1963);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1964);
					let tmp = recog.identifier()?;
					 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier.clone().unwrap()
					 ;
					 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).unpivotCol.push(temp);
					  
					recog.base.set_state(1969);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS || ((((_la - 407)) & !0x3f) == 0 && ((1usize << (_la - 407)) & ((1usize << (MINUS - 407)) | (1usize << (QUOTED_STRING - 407)) | (1usize << (TRIPLE_QUOTED_STRING - 407)) | (1usize << (RAW_QUOTED_STRING - 407)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 407)) | (1usize << (INTEGER_VALUE - 407)) | (1usize << (HEXADECIMAL_VALUE - 407)) | (1usize << (DECIMAL_VALUE - 407)) | (1usize << (DOUBLE_VALUE - 407)))) != 0) {
						{
						recog.base.set_state(1966);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==AS {
							{
							recog.base.set_state(1965);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						/*InvokeRule unpivotAlias*/
						recog.base.set_state(1968);
						recog.unpivotAlias()?;

						}
					}

					}
					} 
				}
				recog.base.set_state(1975);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(246,&mut recog.base)?;
			}
			recog.base.set_state(1977);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1976);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotAlias ----------------
pub type UnpivotAliasContextAll<'input> = UnpivotAliasContext<'input>;


pub type UnpivotAliasContext<'input> = BaseParserRuleContext<'input,UnpivotAliasContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for UnpivotAliasContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnpivotAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotAlias(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_unpivotAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnpivotAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unpivotAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotAlias }
}
antlr_rust::tid!{UnpivotAliasContextExt<'a>}

impl<'input> UnpivotAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotAliasContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<UnpivotAliasContextExt<'input>>{

fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnpivotAliasContextAttrs<'input> for UnpivotAliasContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotAlias(&mut self,)
	-> Result<Rc<UnpivotAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 166, RULE_unpivotAlias);
        let mut _localctx: Rc<UnpivotAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1981);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 MINUS | INTEGER_VALUE | HEXADECIMAL_VALUE | DECIMAL_VALUE | DOUBLE_VALUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule number*/
					recog.base.set_state(1979);
					recog.number()?;

					}
				}

			 QUOTED_STRING | TRIPLE_QUOTED_STRING | RAW_QUOTED_STRING | RAW_TRIPLE_QUOTED_STRING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule string*/
					recog.base.set_state(1980);
					recog.string()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiColumnUnpivot ----------------
pub type MultiColumnUnpivotContextAll<'input> = MultiColumnUnpivotContext<'input>;


pub type MultiColumnUnpivotContext<'input> = BaseParserRuleContext<'input,MultiColumnUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct MultiColumnUnpivotContextExt<'input>{
	pub nameColumn: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for MultiColumnUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MultiColumnUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiColumnUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_multiColumnUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MultiColumnUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_multiColumnUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiColumnUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiColumnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiColumnUnpivot }
}
antlr_rust::tid!{MultiColumnUnpivotContextExt<'a>}

impl<'input> MultiColumnUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiColumnUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiColumnUnpivotContextExt{
				nameColumn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiColumnUnpivotContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<MultiColumnUnpivotContextExt<'input>>{

fn valueColumnSet(&self) -> Option<Rc<ValueColumnSetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnSetsToUnpivot(&self) -> Option<Rc<ColumnSetsToUnpivotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MultiColumnUnpivotContextAttrs<'input> for MultiColumnUnpivotContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiColumnUnpivot(&mut self,)
	-> Result<Rc<MultiColumnUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiColumnUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 168, RULE_multiColumnUnpivot);
        let mut _localctx: Rc<MultiColumnUnpivotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule valueColumnSet*/
			recog.base.set_state(1983);
			recog.valueColumnSet()?;

			recog.base.set_state(1984);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(1985);
			let tmp = recog.identifier()?;
			 cast_mut::<_,MultiColumnUnpivotContext >(&mut _localctx).nameColumn = Some(tmp.clone());
			  

			recog.base.set_state(1986);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(1987);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnSetsToUnpivot*/
			recog.base.set_state(1988);
			recog.columnSetsToUnpivot()?;

			recog.base.set_state(1989);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valueColumnSet ----------------
pub type ValueColumnSetContextAll<'input> = ValueColumnSetContext<'input>;


pub type ValueColumnSetContext<'input> = BaseParserRuleContext<'input,ValueColumnSetContextExt<'input>>;

#[derive(Clone)]
pub struct ValueColumnSetContextExt<'input>{
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub valueColumn:Vec<Rc<IdentifierContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ValueColumnSetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ValueColumnSetContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_valueColumnSet(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_valueColumnSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ValueColumnSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_valueColumnSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for ValueColumnSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueColumnSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueColumnSet }
}
antlr_rust::tid!{ValueColumnSetContextExt<'a>}

impl<'input> ValueColumnSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValueColumnSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValueColumnSetContextExt{
				tail: None, 
				identifier: None, 
				valueColumn: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ValueColumnSetContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ValueColumnSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ValueColumnSetContextAttrs<'input> for ValueColumnSetContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn valueColumnSet(&mut self,)
	-> Result<Rc<ValueColumnSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ValueColumnSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 170, RULE_valueColumnSet);
        let mut _localctx: Rc<ValueColumnSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1991);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(1992);
			let tmp = recog.identifier()?;
			 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).identifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ValueColumnSetContext >(&mut _localctx).identifier.clone().unwrap()
			 ;
			 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).valueColumn.push(temp);
			  
			recog.base.set_state(1997);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(249,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1993);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1994);
					let tmp = recog.identifier()?;
					 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).identifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ValueColumnSetContext >(&mut _localctx).identifier.clone().unwrap()
					 ;
					 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).valueColumn.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1999);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(249,&mut recog.base)?;
			}
			recog.base.set_state(2001);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2000);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			recog.base.set_state(2003);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotColumnSet ----------------
pub type UnpivotColumnSetContextAll<'input> = UnpivotColumnSetContext<'input>;


pub type UnpivotColumnSetContext<'input> = BaseParserRuleContext<'input,UnpivotColumnSetContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotColumnSetContextExt<'input>{
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub unpivotColumns:Vec<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for UnpivotColumnSetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnpivotColumnSetContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotColumnSet(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_unpivotColumnSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnpivotColumnSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unpivotColumnSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotColumnSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotColumnSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotColumnSet }
}
antlr_rust::tid!{UnpivotColumnSetContextExt<'a>}

impl<'input> UnpivotColumnSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotColumnSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotColumnSetContextExt{
				identifier: None, 
				unpivotColumns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotColumnSetContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<UnpivotColumnSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn unpivotAlias(&self) -> Option<Rc<UnpivotAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> UnpivotColumnSetContextAttrs<'input> for UnpivotColumnSetContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotColumnSet(&mut self,)
	-> Result<Rc<UnpivotColumnSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotColumnSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 172, RULE_unpivotColumnSet);
        let mut _localctx: Rc<UnpivotColumnSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2005);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(2006);
			let tmp = recog.identifier()?;
			 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).identifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).identifier.clone().unwrap()
			 ;
			 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumns.push(temp);
			  
			recog.base.set_state(2011);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2007);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule identifier*/
				recog.base.set_state(2008);
				let tmp = recog.identifier()?;
				 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).identifier = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).identifier.clone().unwrap()
				 ;
				 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumns.push(temp);
				  
				}
				}
				recog.base.set_state(2013);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2014);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2019);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS || ((((_la - 407)) & !0x3f) == 0 && ((1usize << (_la - 407)) & ((1usize << (MINUS - 407)) | (1usize << (QUOTED_STRING - 407)) | (1usize << (TRIPLE_QUOTED_STRING - 407)) | (1usize << (RAW_QUOTED_STRING - 407)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 407)) | (1usize << (INTEGER_VALUE - 407)) | (1usize << (HEXADECIMAL_VALUE - 407)) | (1usize << (DECIMAL_VALUE - 407)) | (1usize << (DOUBLE_VALUE - 407)))) != 0) {
				{
				recog.base.set_state(2016);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==AS {
					{
					recog.base.set_state(2015);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					}
				}

				/*InvokeRule unpivotAlias*/
				recog.base.set_state(2018);
				recog.unpivotAlias()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnSetsToUnpivot ----------------
pub type ColumnSetsToUnpivotContextAll<'input> = ColumnSetsToUnpivotContext<'input>;


pub type ColumnSetsToUnpivotContext<'input> = BaseParserRuleContext<'input,ColumnSetsToUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnSetsToUnpivotContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnSetsToUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnSetsToUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnSetsToUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnSetsToUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnSetsToUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnSetsToUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSetsToUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSetsToUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSetsToUnpivot }
}
antlr_rust::tid!{ColumnSetsToUnpivotContextExt<'a>}

impl<'input> ColumnSetsToUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnSetsToUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnSetsToUnpivotContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnSetsToUnpivotContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnSetsToUnpivotContextExt<'input>>{

fn unpivotColumnSet_all(&self) ->  Vec<Rc<UnpivotColumnSetContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unpivotColumnSet(&self, i: usize) -> Option<Rc<UnpivotColumnSetContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnSetsToUnpivotContextAttrs<'input> for ColumnSetsToUnpivotContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnSetsToUnpivot(&mut self,)
	-> Result<Rc<ColumnSetsToUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnSetsToUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 174, RULE_columnSetsToUnpivot);
        let mut _localctx: Rc<ColumnSetsToUnpivotContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule unpivotColumnSet*/
			recog.base.set_state(2021);
			recog.unpivotColumnSet()?;

			recog.base.set_state(2026);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(254,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2022);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule unpivotColumnSet*/
					recog.base.set_state(2023);
					recog.unpivotColumnSet()?;

					}
					} 
				}
				recog.base.set_state(2028);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(254,&mut recog.base)?;
			}
			recog.base.set_state(2030);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2029);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnUnpivot ----------------
#[derive(Debug)]
pub enum ColumnUnpivotContextAll<'input>{
	MultiColumnUnpivotDefaultContext(MultiColumnUnpivotDefaultContext<'input>),
	SingleColumnUnpivotDefaultContext(SingleColumnUnpivotDefaultContext<'input>),
Error(ColumnUnpivotContext<'input>)
}
antlr_rust::tid!{ColumnUnpivotContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ColumnUnpivotContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for ColumnUnpivotContextAll<'input>{}

impl<'input> Deref for ColumnUnpivotContextAll<'input>{
	type Target = dyn ColumnUnpivotContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ColumnUnpivotContextAll::*;
		match self{
			MultiColumnUnpivotDefaultContext(inner) => inner,
			SingleColumnUnpivotDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnUnpivotContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnUnpivotContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ColumnUnpivotContext<'input> = BaseParserRuleContext<'input,ColumnUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnUnpivotContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnUnpivotContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnUnpivotContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ColumnUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnUnpivot }
}
antlr_rust::tid!{ColumnUnpivotContextExt<'a>}

impl<'input> ColumnUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnUnpivotContextAll<'input>> {
		Rc::new(
		ColumnUnpivotContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnUnpivotContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ColumnUnpivotContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnUnpivotContextExt<'input>>{


}

impl<'input> ColumnUnpivotContextAttrs<'input> for ColumnUnpivotContext<'input>{}

pub type MultiColumnUnpivotDefaultContext<'input> = BaseParserRuleContext<'input,MultiColumnUnpivotDefaultContextExt<'input>>;

pub trait MultiColumnUnpivotDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn multiColumnUnpivot(&self) -> Option<Rc<MultiColumnUnpivotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MultiColumnUnpivotDefaultContextAttrs<'input> for MultiColumnUnpivotDefaultContext<'input>{}

pub struct MultiColumnUnpivotDefaultContextExt<'input>{
	base:ColumnUnpivotContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MultiColumnUnpivotDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for MultiColumnUnpivotDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MultiColumnUnpivotDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_multiColumnUnpivotDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_multiColumnUnpivotDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MultiColumnUnpivotDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_multiColumnUnpivotDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiColumnUnpivotDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnUnpivot }
}

impl<'input> Borrow<ColumnUnpivotContextExt<'input>> for MultiColumnUnpivotDefaultContext<'input>{
	fn borrow(&self) -> &ColumnUnpivotContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnUnpivotContextExt<'input>> for MultiColumnUnpivotDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnUnpivotContextExt<'input> { &mut self.base }
}

impl<'input> ColumnUnpivotContextAttrs<'input> for MultiColumnUnpivotDefaultContext<'input> {}

impl<'input> MultiColumnUnpivotDefaultContextExt<'input>{
	fn new(ctx: &dyn ColumnUnpivotContextAttrs<'input>) -> Rc<ColumnUnpivotContextAll<'input>>  {
		Rc::new(
			ColumnUnpivotContextAll::MultiColumnUnpivotDefaultContext(
				BaseParserRuleContext::copy_from(ctx,MultiColumnUnpivotDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SingleColumnUnpivotDefaultContext<'input> = BaseParserRuleContext<'input,SingleColumnUnpivotDefaultContextExt<'input>>;

pub trait SingleColumnUnpivotDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn singleColumnUnpivot(&self) -> Option<Rc<SingleColumnUnpivotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SingleColumnUnpivotDefaultContextAttrs<'input> for SingleColumnUnpivotDefaultContext<'input>{}

pub struct SingleColumnUnpivotDefaultContextExt<'input>{
	base:ColumnUnpivotContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleColumnUnpivotDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SingleColumnUnpivotDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SingleColumnUnpivotDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleColumnUnpivotDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_singleColumnUnpivotDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SingleColumnUnpivotDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_singleColumnUnpivotDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleColumnUnpivotDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnUnpivot }
}

impl<'input> Borrow<ColumnUnpivotContextExt<'input>> for SingleColumnUnpivotDefaultContext<'input>{
	fn borrow(&self) -> &ColumnUnpivotContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnUnpivotContextExt<'input>> for SingleColumnUnpivotDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnUnpivotContextExt<'input> { &mut self.base }
}

impl<'input> ColumnUnpivotContextAttrs<'input> for SingleColumnUnpivotDefaultContext<'input> {}

impl<'input> SingleColumnUnpivotDefaultContextExt<'input>{
	fn new(ctx: &dyn ColumnUnpivotContextAttrs<'input>) -> Rc<ColumnUnpivotContextAll<'input>>  {
		Rc::new(
			ColumnUnpivotContextAll::SingleColumnUnpivotDefaultContext(
				BaseParserRuleContext::copy_from(ctx,SingleColumnUnpivotDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnUnpivot(&mut self,)
	-> Result<Rc<ColumnUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 176, RULE_columnUnpivot);
        let mut _localctx: Rc<ColumnUnpivotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2034);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ATTACH |
			 AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK | BZIP2 |
			 CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE | CATALOGS |
			 CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL | CONNECT |
			 CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT | CURRENT_ROLE |
			 CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE | DATETIME | DAY |
			 DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF | DEALLOCATE | DECLARE |
			 DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESCRIBE |
			 DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH |
			 DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING | ERROR | EVEN |
			 EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL | FIELDS | FILTER |
			 FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS | GENERATED |
			 GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER | HOUR |
			 IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT |
			 INTERLEAVED | INSERT | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR |
			 ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE |
			 LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION |
			 LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION | OPTIONS |
			 OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS | PASSING |
			 PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE | PIVOT |
			 POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES | PROPERTIES |
			 PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME | REPEATABLE |
			 REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE | REPEAT | RETURNS |
			 REVOKE | RLS | ROLE | ROLES | ROLLBACK | ROW | RUNNING | SAFE | SAFE_CAST |
			 SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS | SECURITY | SEEK | SEMI |
			 SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION | SETS | SHOW | SIMILAR |
			 SNAPSHOT | SORTKEY | START | STATS | STORED | SUBSET | SUBSTRING | SUNDAY |
			 SYSTEM | SYSTEM_TIME | TABLE | TABLES | TEMP | TEMPORARY | TERMINATED |
			 TEXT | STRING_KW | THURSDAY | TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF |
			 TOP | TRAILING | TARGET | SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM |
			 TRIM | TRUNCATE | TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED |
			 UNCONDITIONAL | UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL |
			 UPDATE | USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE |
			 VALUES | VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE |
			 WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | IDENTIFIER |
			 BACKQUOTED_IDENTIFIER 
				=> {
					let tmp = SingleColumnUnpivotDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule singleColumnUnpivot*/
					recog.base.set_state(2032);
					recog.singleColumnUnpivot()?;

					}
				}

			 LPAREN 
				=> {
					let tmp = MultiColumnUnpivotDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule multiColumnUnpivot*/
					recog.base.set_state(2033);
					recog.multiColumnUnpivot()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotIntos ----------------
#[derive(Debug)]
pub enum PivotIntosContextAll<'input>{
	PivotIntosDefaultContext(PivotIntosDefaultContext<'input>),
Error(PivotIntosContext<'input>)
}
antlr_rust::tid!{PivotIntosContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotIntosContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PivotIntosContextAll<'input>{}

impl<'input> Deref for PivotIntosContextAll<'input>{
	type Target = dyn PivotIntosContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotIntosContextAll::*;
		match self{
			PivotIntosDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotIntosContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotIntosContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotIntosContext<'input> = BaseParserRuleContext<'input,PivotIntosContextExt<'input>>;

#[derive(Clone)]
pub struct PivotIntosContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PivotIntosContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotIntosContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotIntosContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotIntosContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotIntos }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotIntos }
}
antlr_rust::tid!{PivotIntosContextExt<'a>}

impl<'input> PivotIntosContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotIntosContextAll<'input>> {
		Rc::new(
		PivotIntosContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotIntosContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotIntosContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PivotIntosContextExt<'input>>{


}

impl<'input> PivotIntosContextAttrs<'input> for PivotIntosContext<'input>{}

pub type PivotIntosDefaultContext<'input> = BaseParserRuleContext<'input,PivotIntosDefaultContextExt<'input>>;

pub trait PivotIntosDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn pivotInto_all(&self) ->  Vec<Rc<PivotIntoContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn pivotInto(&self, i: usize) -> Option<Rc<PivotIntoContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PivotIntosDefaultContextAttrs<'input> for PivotIntosDefaultContext<'input>{}

pub struct PivotIntosDefaultContextExt<'input>{
	base:PivotIntosContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotIntosDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PivotIntosDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotIntosDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivotIntosDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_pivotIntosDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotIntosDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pivotIntosDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotIntosDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotIntos }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotIntos }
}

impl<'input> Borrow<PivotIntosContextExt<'input>> for PivotIntosDefaultContext<'input>{
	fn borrow(&self) -> &PivotIntosContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotIntosContextExt<'input>> for PivotIntosDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotIntosContextExt<'input> { &mut self.base }
}

impl<'input> PivotIntosContextAttrs<'input> for PivotIntosDefaultContext<'input> {}

impl<'input> PivotIntosDefaultContextExt<'input>{
	fn new(ctx: &dyn PivotIntosContextAttrs<'input>) -> Rc<PivotIntosContextAll<'input>>  {
		Rc::new(
			PivotIntosContextAll::PivotIntosDefaultContext(
				BaseParserRuleContext::copy_from(ctx,PivotIntosDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotIntos(&mut self,)
	-> Result<Rc<PivotIntosContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotIntosContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 178, RULE_pivotIntos);
        let mut _localctx: Rc<PivotIntosContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = PivotIntosDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule pivotInto*/
			recog.base.set_state(2036);
			recog.pivotInto()?;

			recog.base.set_state(2041);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(257,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2037);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule pivotInto*/
					recog.base.set_state(2038);
					recog.pivotInto()?;

					}
					} 
				}
				recog.base.set_state(2043);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(257,&mut recog.base)?;
			}
			recog.base.set_state(2045);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2044);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotOperator ----------------
#[derive(Debug)]
pub enum PivotOperatorContextAll<'input>{
	UnpivotContext(UnpivotContext<'input>),
	PivotContext(PivotContext<'input>),
Error(PivotOperatorContext<'input>)
}
antlr_rust::tid!{PivotOperatorContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotOperatorContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PivotOperatorContextAll<'input>{}

impl<'input> Deref for PivotOperatorContextAll<'input>{
	type Target = dyn PivotOperatorContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotOperatorContextAll::*;
		match self{
			UnpivotContext(inner) => inner,
			PivotContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotOperatorContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotOperatorContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotOperatorContext<'input> = BaseParserRuleContext<'input,PivotOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PivotOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PivotOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotOperatorContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotOperatorContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}
antlr_rust::tid!{PivotOperatorContextExt<'a>}

impl<'input> PivotOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotOperatorContextAll<'input>> {
		Rc::new(
		PivotOperatorContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotOperatorContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotOperatorContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PivotOperatorContextExt<'input>>{


}

impl<'input> PivotOperatorContextAttrs<'input> for PivotOperatorContext<'input>{}

pub type UnpivotContext<'input> = BaseParserRuleContext<'input,UnpivotContextExt<'input>>;

pub trait UnpivotContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNPIVOT
	/// Returns `None` if there is no child corresponding to token UNPIVOT
	fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(UNPIVOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn columnUnpivot(&self) -> Option<Rc<ColumnUnpivotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn pivotAsAlias(&self) -> Option<Rc<PivotAsAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn unpivotNullClause(&self) -> Option<Rc<UnpivotNullClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnpivotContextAttrs<'input> for UnpivotContext<'input>{}

pub struct UnpivotContextExt<'input>{
	base:PivotOperatorContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnpivotContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnpivotContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unpivot(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_unpivot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}

impl<'input> Borrow<PivotOperatorContextExt<'input>> for UnpivotContext<'input>{
	fn borrow(&self) -> &PivotOperatorContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotOperatorContextExt<'input>> for UnpivotContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotOperatorContextExt<'input> { &mut self.base }
}

impl<'input> PivotOperatorContextAttrs<'input> for UnpivotContext<'input> {}

impl<'input> UnpivotContextExt<'input>{
	fn new(ctx: &dyn PivotOperatorContextAttrs<'input>) -> Rc<PivotOperatorContextAll<'input>>  {
		Rc::new(
			PivotOperatorContextAll::UnpivotContext(
				BaseParserRuleContext::copy_from(ctx,UnpivotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PivotContext<'input> = BaseParserRuleContext<'input,PivotContextExt<'input>>;

pub trait PivotContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PIVOT
	/// Returns `None` if there is no child corresponding to token PIVOT
	fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PIVOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	fn pivotAggregates(&self) -> Option<Rc<PivotAggregatesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
	fn pivotFrom(&self) -> Option<Rc<PivotFromContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	fn pivotIntos(&self) -> Option<Rc<PivotIntosContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	fn pivotAsAlias(&self) -> Option<Rc<PivotAsAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PivotContextAttrs<'input> for PivotContext<'input>{}

pub struct PivotContextExt<'input>{
	base:PivotOperatorContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PivotContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PivotContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivot(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_pivot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}

impl<'input> Borrow<PivotOperatorContextExt<'input>> for PivotContext<'input>{
	fn borrow(&self) -> &PivotOperatorContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotOperatorContextExt<'input>> for PivotContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotOperatorContextExt<'input> { &mut self.base }
}

impl<'input> PivotOperatorContextAttrs<'input> for PivotContext<'input> {}

impl<'input> PivotContextExt<'input>{
	fn new(ctx: &dyn PivotOperatorContextAttrs<'input>) -> Rc<PivotOperatorContextAll<'input>>  {
		Rc::new(
			PivotOperatorContextAll::PivotContext(
				BaseParserRuleContext::copy_from(ctx,PivotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotOperator(&mut self,)
	-> Result<Rc<PivotOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 180, RULE_pivotOperator);
        let mut _localctx: Rc<PivotOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2068);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 PIVOT 
				=> {
					let tmp = PivotContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2047);
					recog.base.match_token(PIVOT,&mut recog.err_handler)?;

					recog.base.set_state(2048);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotAggregates*/
					recog.base.set_state(2049);
					recog.pivotAggregates()?;

					recog.base.set_state(2050);
					recog.base.match_token(FOR,&mut recog.err_handler)?;

					/*InvokeRule pivotFrom*/
					recog.base.set_state(2051);
					recog.pivotFrom()?;

					recog.base.set_state(2052);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2053);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotIntos*/
					recog.base.set_state(2054);
					recog.pivotIntos()?;

					recog.base.set_state(2055);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2056);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotAsAlias*/
					recog.base.set_state(2057);
					recog.pivotAsAlias()?;

					}
				}

			 UNPIVOT 
				=> {
					let tmp = UnpivotContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2059);
					recog.base.match_token(UNPIVOT,&mut recog.err_handler)?;

					recog.base.set_state(2061);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EXCLUDE || _la==INCLUDE {
						{
						/*InvokeRule unpivotNullClause*/
						recog.base.set_state(2060);
						recog.unpivotNullClause()?;

						}
					}

					recog.base.set_state(2063);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule columnUnpivot*/
					recog.base.set_state(2064);
					recog.columnUnpivot()?;

					recog.base.set_state(2065);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotAsAlias*/
					recog.base.set_state(2066);
					recog.pivotAsAlias()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aliasedRelationTarget ----------------
#[derive(Debug)]
pub enum AliasedRelationTargetContextAll<'input>{
	SubqueryRelationContext(SubqueryRelationContext<'input>),
	TableNameContext(TableNameContext<'input>),
Error(AliasedRelationTargetContext<'input>)
}
antlr_rust::tid!{AliasedRelationTargetContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for AliasedRelationTargetContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for AliasedRelationTargetContextAll<'input>{}

impl<'input> Deref for AliasedRelationTargetContextAll<'input>{
	type Target = dyn AliasedRelationTargetContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use AliasedRelationTargetContextAll::*;
		match self{
			SubqueryRelationContext(inner) => inner,
			TableNameContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for AliasedRelationTargetContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for AliasedRelationTargetContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type AliasedRelationTargetContext<'input> = BaseParserRuleContext<'input,AliasedRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct AliasedRelationTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for AliasedRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for AliasedRelationTargetContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for AliasedRelationTargetContext<'input>{
}

impl<'input> CustomRuleContext<'input> for AliasedRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}
antlr_rust::tid!{AliasedRelationTargetContextExt<'a>}

impl<'input> AliasedRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AliasedRelationTargetContextAll<'input>> {
		Rc::new(
		AliasedRelationTargetContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AliasedRelationTargetContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait AliasedRelationTargetContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<AliasedRelationTargetContextExt<'input>>{


}

impl<'input> AliasedRelationTargetContextAttrs<'input> for AliasedRelationTargetContext<'input>{}

pub type SubqueryRelationContext<'input> = BaseParserRuleContext<'input,SubqueryRelationContextExt<'input>>;

pub trait SubqueryRelationContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> SubqueryRelationContextAttrs<'input> for SubqueryRelationContext<'input>{}

pub struct SubqueryRelationContextExt<'input>{
	base:AliasedRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryRelationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SubqueryRelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SubqueryRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subqueryRelation(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_subqueryRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SubqueryRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_subqueryRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}

impl<'input> Borrow<AliasedRelationTargetContextExt<'input>> for SubqueryRelationContext<'input>{
	fn borrow(&self) -> &AliasedRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<AliasedRelationTargetContextExt<'input>> for SubqueryRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut AliasedRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> AliasedRelationTargetContextAttrs<'input> for SubqueryRelationContext<'input> {}

impl<'input> SubqueryRelationContextExt<'input>{
	fn new(ctx: &dyn AliasedRelationTargetContextAttrs<'input>) -> Rc<AliasedRelationTargetContextAll<'input>>  {
		Rc::new(
			AliasedRelationTargetContextAll::SubqueryRelationContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryRelationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableNameContext<'input> = BaseParserRuleContext<'input,TableNameContextExt<'input>>;

pub trait TableNameContextAttrs<'input>: BigqueryParserContext<'input>{
	fn maybeDashedPathExpression(&self) -> Option<Rc<MaybeDashedPathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableNameContextAttrs<'input> for TableNameContext<'input>{}

pub struct TableNameContextExt<'input>{
	base:AliasedRelationTargetContextExt<'input>,
	pub tableNameRef: Option<Rc<MaybeDashedPathExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableNameContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TableNameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableNameContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableName(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_tableName(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableName(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}

impl<'input> Borrow<AliasedRelationTargetContextExt<'input>> for TableNameContext<'input>{
	fn borrow(&self) -> &AliasedRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<AliasedRelationTargetContextExt<'input>> for TableNameContext<'input>{
	fn borrow_mut(&mut self) -> &mut AliasedRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> AliasedRelationTargetContextAttrs<'input> for TableNameContext<'input> {}

impl<'input> TableNameContextExt<'input>{
	fn new(ctx: &dyn AliasedRelationTargetContextAttrs<'input>) -> Rc<AliasedRelationTargetContextAll<'input>>  {
		Rc::new(
			AliasedRelationTargetContextAll::TableNameContext(
				BaseParserRuleContext::copy_from(ctx,TableNameContextExt{
        			tableNameRef:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aliasedRelationTarget(&mut self,)
	-> Result<Rc<AliasedRelationTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AliasedRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 182, RULE_aliasedRelationTarget);
        let mut _localctx: Rc<AliasedRelationTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2075);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ATTACH |
			 AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK | BZIP2 |
			 CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE | CATALOGS |
			 CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL | CONNECT |
			 CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT | CURRENT_ROLE |
			 CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE | DATETIME | DAY |
			 DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF | DEALLOCATE | DECLARE |
			 DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESCRIBE |
			 DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH |
			 DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING | ERROR | EVEN |
			 EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL | FIELDS | FILTER |
			 FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS | GENERATED |
			 GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER | HOUR |
			 IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT |
			 INTERLEAVED | INSERT | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR |
			 ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE |
			 LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION |
			 LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION | OPTIONS |
			 OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS | PASSING |
			 PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE | PIVOT |
			 POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES | PROPERTIES |
			 PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME | REPEATABLE |
			 REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE | REPEAT | RETURNS |
			 REVOKE | RLS | ROLE | ROLES | ROLLBACK | ROW | RUNNING | SAFE | SAFE_CAST |
			 SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS | SECURITY | SEEK | SEMI |
			 SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION | SETS | SHOW | SIMILAR |
			 SNAPSHOT | SORTKEY | START | STATS | STORED | SUBSET | SUBSTRING | SUNDAY |
			 SYSTEM | SYSTEM_TIME | TABLE | TABLES | TEMP | TEMPORARY | TERMINATED |
			 TEXT | STRING_KW | THURSDAY | TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF |
			 TOP | TRAILING | TARGET | SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM |
			 TRIM | TRUNCATE | TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED |
			 UNCONDITIONAL | UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL |
			 UPDATE | USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE |
			 VALUES | VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE |
			 WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | IDENTIFIER |
			 BACKQUOTED_IDENTIFIER 
				=> {
					let tmp = TableNameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule maybeDashedPathExpression*/
					recog.base.set_state(2070);
					let tmp = recog.maybeDashedPathExpression()?;
					if let AliasedRelationTargetContextAll::TableNameContext(ctx) = cast_mut::<_,AliasedRelationTargetContextAll >(&mut _localctx){
					ctx.tableNameRef = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}

			 LPAREN 
				=> {
					let tmp = SubqueryRelationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2071);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2072);
					recog.query()?;

					recog.base.set_state(2073);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aliasedRelation ----------------
pub type AliasedRelationContextAll<'input> = AliasedRelationContext<'input>;


pub type AliasedRelationContext<'input> = BaseParserRuleContext<'input,AliasedRelationContextExt<'input>>;

#[derive(Clone)]
pub struct AliasedRelationContextExt<'input>{
	pub alias: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for AliasedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for AliasedRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aliasedRelation(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_aliasedRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for AliasedRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_aliasedRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for AliasedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelation }
}
antlr_rust::tid!{AliasedRelationContextExt<'a>}

impl<'input> AliasedRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AliasedRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AliasedRelationContextExt{
				alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AliasedRelationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<AliasedRelationContextExt<'input>>{

fn aliasedRelationTarget(&self) -> Option<Rc<AliasedRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> AliasedRelationContextAttrs<'input> for AliasedRelationContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aliasedRelation(&mut self,)
	-> Result<Rc<AliasedRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AliasedRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 184, RULE_aliasedRelation);
        let mut _localctx: Rc<AliasedRelationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule aliasedRelationTarget*/
			recog.base.set_state(2077);
			recog.aliasedRelationTarget()?;

			recog.base.set_state(2082);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(263,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2079);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(2078);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule identifier*/
					recog.base.set_state(2081);
					let tmp = recog.identifier()?;
					 cast_mut::<_,AliasedRelationContext >(&mut _localctx).alias = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnAliases ----------------
pub type ColumnAliasesContextAll<'input> = ColumnAliasesContext<'input>;


pub type ColumnAliasesContext<'input> = BaseParserRuleContext<'input,ColumnAliasesContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnAliasesContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ColumnAliasesContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnAliasesContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnAliases(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_columnAliases(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnAliasesContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnAliases(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnAliasesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnAliases }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnAliases }
}
antlr_rust::tid!{ColumnAliasesContextExt<'a>}

impl<'input> ColumnAliasesContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnAliasesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnAliasesContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnAliasesContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ColumnAliasesContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token OPTIONS in current rule
fn OPTIONS_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token OPTIONS, starting from 0.
/// Returns `None` if number of children corresponding to token OPTIONS is less or equal than `i`.
fn OPTIONS(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, i)
}
fn properties_all(&self) ->  Vec<Rc<PropertiesContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn properties(&self, i: usize) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnAliasesContextAttrs<'input> for ColumnAliasesContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnAliases(&mut self,)
	-> Result<Rc<ColumnAliasesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnAliasesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 186, RULE_columnAliases);
        let mut _localctx: Rc<ColumnAliasesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2111);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ATTACH |
			 AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK | BZIP2 |
			 CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE | CATALOGS |
			 CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL | CONNECT |
			 CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT | CURRENT_ROLE |
			 CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE | DATETIME | DAY |
			 DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF | DEALLOCATE | DECLARE |
			 DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESCRIBE |
			 DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH |
			 DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING | ERROR | EVEN |
			 EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL | FIELDS | FILTER |
			 FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS | GENERATED |
			 GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER | HOUR |
			 IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT |
			 INTERLEAVED | INSERT | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR |
			 ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE |
			 LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION |
			 LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION | OPTIONS |
			 OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS | PASSING |
			 PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE | PIVOT |
			 POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES | PROPERTIES |
			 PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME | REPEATABLE |
			 REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE | REPEAT | RETURNS |
			 REVOKE | RLS | ROLE | ROLES | ROLLBACK | ROW | RUNNING | SAFE | SAFE_CAST |
			 SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS | SECURITY | SEEK | SEMI |
			 SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION | SETS | SHOW | SIMILAR |
			 SNAPSHOT | SORTKEY | START | STATS | STORED | SUBSET | SUBSTRING | SUNDAY |
			 SYSTEM | SYSTEM_TIME | TABLE | TABLES | TEMP | TEMPORARY | TERMINATED |
			 TEXT | STRING_KW | THURSDAY | TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF |
			 TOP | TRAILING | TARGET | SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM |
			 TRIM | TRUNCATE | TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED |
			 UNCONDITIONAL | UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL |
			 UPDATE | USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE |
			 VALUES | VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE |
			 WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | IDENTIFIER |
			 BACKQUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2084);
					recog.identifier()?;

					recog.base.set_state(2087);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(264,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2085);
							recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

							/*InvokeRule properties*/
							recog.base.set_state(2086);
							recog.properties()?;

							}
						}

						_ => {}
					}
					}
				}

			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2089);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(2090);
					recog.identifier()?;

					recog.base.set_state(2093);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(2091);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(2092);
						recog.properties()?;

						}
					}

					recog.base.set_state(2103);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(267,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2095);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(2096);
							recog.identifier()?;

							recog.base.set_state(2099);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==OPTIONS {
								{
								recog.base.set_state(2097);
								recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

								/*InvokeRule properties*/
								recog.base.set_state(2098);
								recog.properties()?;

								}
							}

							}
							} 
						}
						recog.base.set_state(2105);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(267,&mut recog.base)?;
					}
					recog.base.set_state(2107);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2106);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,ColumnAliasesContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(2109);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionColumn ----------------
pub type PartitionColumnContextAll<'input> = PartitionColumnContext<'input>;


pub type PartitionColumnContext<'input> = BaseParserRuleContext<'input,PartitionColumnContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionColumnContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PartitionColumnContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PartitionColumnContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionColumn(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_partitionColumn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PartitionColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_partitionColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionColumn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionColumn }
}
antlr_rust::tid!{PartitionColumnContextExt<'a>}

impl<'input> PartitionColumnContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionColumnContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionColumnContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionColumnContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PartitionColumnContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionColumnContextAttrs<'input> for PartitionColumnContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionColumn(&mut self,)
	-> Result<Rc<PartitionColumnContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionColumnContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 188, RULE_partitionColumn);
        let mut _localctx: Rc<PartitionColumnContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2113);
			recog.identifier()?;

			/*InvokeRule type_*/
			recog.base.set_state(2114);
			recog.type_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionColumns ----------------
pub type PartitionColumnsContextAll<'input> = PartitionColumnsContext<'input>;


pub type PartitionColumnsContext<'input> = BaseParserRuleContext<'input,PartitionColumnsContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionColumnsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PartitionColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PartitionColumnsContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionColumns(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_partitionColumns(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PartitionColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_partitionColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionColumns }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionColumns }
}
antlr_rust::tid!{PartitionColumnsContextExt<'a>}

impl<'input> PartitionColumnsContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionColumnsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionColumnsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionColumnsContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PartitionColumnsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn partitionColumn_all(&self) ->  Vec<Rc<PartitionColumnContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionColumn(&self, i: usize) -> Option<Rc<PartitionColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionColumnsContextAttrs<'input> for PartitionColumnsContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionColumns(&mut self,)
	-> Result<Rc<PartitionColumnsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionColumnsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 190, RULE_partitionColumns);
        let mut _localctx: Rc<PartitionColumnsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2116);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule partitionColumn*/
			recog.base.set_state(2117);
			recog.partitionColumn()?;

			recog.base.set_state(2122);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(270,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2118);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule partitionColumn*/
					recog.base.set_state(2119);
					recog.partitionColumn()?;

					}
					} 
				}
				recog.base.set_state(2124);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(270,&mut recog.base)?;
			}
			recog.base.set_state(2126);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2125);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,PartitionColumnsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			recog.base.set_state(2128);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relationPrimary ----------------
#[derive(Debug)]
pub enum RelationPrimaryContextAll<'input>{
	AliasedContext(AliasedContext<'input>),
	UnnestContext(UnnestContext<'input>),
	TableFunctionInvocationContext(TableFunctionInvocationContext<'input>),
Error(RelationPrimaryContext<'input>)
}
antlr_rust::tid!{RelationPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RelationPrimaryContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for RelationPrimaryContextAll<'input>{}

impl<'input> Deref for RelationPrimaryContextAll<'input>{
	type Target = dyn RelationPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RelationPrimaryContextAll::*;
		match self{
			AliasedContext(inner) => inner,
			UnnestContext(inner) => inner,
			TableFunctionInvocationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RelationPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RelationPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RelationPrimaryContext<'input> = BaseParserRuleContext<'input,RelationPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct RelationPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for RelationPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RelationPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RelationPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RelationPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}
antlr_rust::tid!{RelationPrimaryContextExt<'a>}

impl<'input> RelationPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationPrimaryContextAll<'input>> {
		Rc::new(
		RelationPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RelationPrimaryContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<RelationPrimaryContextExt<'input>>{


}

impl<'input> RelationPrimaryContextAttrs<'input> for RelationPrimaryContext<'input>{}

pub type AliasedContext<'input> = BaseParserRuleContext<'input,AliasedContextExt<'input>>;

pub trait AliasedContextAttrs<'input>: BigqueryParserContext<'input>{
	fn aliasedRelation(&self) -> Option<Rc<AliasedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AliasedContextAttrs<'input> for AliasedContext<'input>{}

pub struct AliasedContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AliasedContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for AliasedContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for AliasedContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_aliased(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_aliased(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for AliasedContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_aliased(self);
	}
}

impl<'input> CustomRuleContext<'input> for AliasedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for AliasedContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for AliasedContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for AliasedContext<'input> {}

impl<'input> AliasedContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::AliasedContext(
				BaseParserRuleContext::copy_from(ctx,AliasedContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnnestContext<'input> = BaseParserRuleContext<'input,UnnestContextExt<'input>>;

pub trait UnnestContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNNEST
	/// Returns `None` if there is no child corresponding to token UNNEST
	fn UNNEST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(UNNEST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OFFSET
	/// Returns `None` if there is no child corresponding to token OFFSET
	fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OFFSET, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token AS in current rule
	fn AS_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token AS, starting from 0.
	/// Returns `None` if number of children corresponding to token AS is less or equal than `i`.
	fn AS(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, i)
	}
}

impl<'input> UnnestContextAttrs<'input> for UnnestContext<'input>{}

pub struct UnnestContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	pub alias1: Option<Rc<IdentifierContextAll<'input>>>,
	pub alias2: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnnestContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UnnestContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnnestContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unnest(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_unnest(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnnestContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unnest(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnnestContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for UnnestContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for UnnestContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for UnnestContext<'input> {}

impl<'input> UnnestContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::UnnestContext(
				BaseParserRuleContext::copy_from(ctx,UnnestContextExt{
					tail:None, 
        			alias1:None, alias2:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableFunctionInvocationContext<'input> = BaseParserRuleContext<'input,TableFunctionInvocationContextExt<'input>>;

pub trait TableFunctionInvocationContextAttrs<'input>: BigqueryParserContext<'input>{
	fn tableFunctionCall(&self) -> Option<Rc<TableFunctionCallContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableFunctionInvocationContextAttrs<'input> for TableFunctionInvocationContext<'input>{}

pub struct TableFunctionInvocationContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableFunctionInvocationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TableFunctionInvocationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableFunctionInvocationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableFunctionInvocation(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_tableFunctionInvocation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableFunctionInvocationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionInvocation(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionInvocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for TableFunctionInvocationContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for TableFunctionInvocationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for TableFunctionInvocationContext<'input> {}

impl<'input> TableFunctionInvocationContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::TableFunctionInvocationContext(
				BaseParserRuleContext::copy_from(ctx,TableFunctionInvocationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relationPrimary(&mut self,)
	-> Result<Rc<RelationPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 192, RULE_relationPrimary);
        let mut _localctx: Rc<RelationPrimaryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2162);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(279,&mut recog.base)? {
				1 =>{
					let tmp = AliasedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule aliasedRelation*/
					recog.base.set_state(2130);
					recog.aliasedRelation()?;

					}
				}
			,
				2 =>{
					let tmp = UnnestContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2131);
					recog.base.match_token(UNNEST,&mut recog.err_handler)?;

					recog.base.set_state(2132);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2133);
					recog.expression()?;

					recog.base.set_state(2138);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(272,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2134);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2135);
							recog.expression()?;

							}
							} 
						}
						recog.base.set_state(2140);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(272,&mut recog.base)?;
					}
					recog.base.set_state(2142);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2141);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let RelationPrimaryContextAll::UnnestContext(ctx) = cast_mut::<_,RelationPrimaryContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2144);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2149);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(275,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2146);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==AS {
								{
								recog.base.set_state(2145);
								recog.base.match_token(AS,&mut recog.err_handler)?;

								}
							}

							/*InvokeRule identifier*/
							recog.base.set_state(2148);
							let tmp = recog.identifier()?;
							if let RelationPrimaryContextAll::UnnestContext(ctx) = cast_mut::<_,RelationPrimaryContextAll >(&mut _localctx){
							ctx.alias1 = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(2159);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(278,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2151);
							recog.base.match_token(WITH,&mut recog.err_handler)?;

							recog.base.set_state(2152);
							recog.base.match_token(OFFSET,&mut recog.err_handler)?;

							recog.base.set_state(2157);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(277,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(2154);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
									if _la==AS {
										{
										recog.base.set_state(2153);
										recog.base.match_token(AS,&mut recog.err_handler)?;

										}
									}

									/*InvokeRule identifier*/
									recog.base.set_state(2156);
									let tmp = recog.identifier()?;
									if let RelationPrimaryContextAll::UnnestContext(ctx) = cast_mut::<_,RelationPrimaryContextAll >(&mut _localctx){
									ctx.alias2 = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					}
				}
			,
				3 =>{
					let tmp = TableFunctionInvocationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule tableFunctionCall*/
					recog.base.set_state(2161);
					recog.tableFunctionCall()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionCall ----------------
#[derive(Debug)]
pub enum TableFunctionCallContextAll<'input>{
	DefaultTableFunctionCallContext(DefaultTableFunctionCallContext<'input>),
Error(TableFunctionCallContext<'input>)
}
antlr_rust::tid!{TableFunctionCallContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TableFunctionCallContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for TableFunctionCallContextAll<'input>{}

impl<'input> Deref for TableFunctionCallContextAll<'input>{
	type Target = dyn TableFunctionCallContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TableFunctionCallContextAll::*;
		match self{
			DefaultTableFunctionCallContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableFunctionCallContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableFunctionCallContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TableFunctionCallContext<'input> = BaseParserRuleContext<'input,TableFunctionCallContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionCallContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TableFunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableFunctionCallContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableFunctionCallContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TableFunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionCall }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionCall }
}
antlr_rust::tid!{TableFunctionCallContextExt<'a>}

impl<'input> TableFunctionCallContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionCallContextAll<'input>> {
		Rc::new(
		TableFunctionCallContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionCallContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TableFunctionCallContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TableFunctionCallContextExt<'input>>{


}

impl<'input> TableFunctionCallContextAttrs<'input> for TableFunctionCallContext<'input>{}

pub type DefaultTableFunctionCallContext<'input> = BaseParserRuleContext<'input,DefaultTableFunctionCallContextExt<'input>>;

pub trait DefaultTableFunctionCallContextAttrs<'input>: BigqueryParserContext<'input>{
	fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn tableFunctionArgument_all(&self) ->  Vec<Rc<TableFunctionArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn tableFunctionArgument(&self, i: usize) -> Option<Rc<TableFunctionArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn tableFunctionArgumentCopartition(&self) -> Option<Rc<TableFunctionArgumentCopartitionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> DefaultTableFunctionCallContextAttrs<'input> for DefaultTableFunctionCallContext<'input>{}

pub struct DefaultTableFunctionCallContextExt<'input>{
	base:TableFunctionCallContextExt<'input>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultTableFunctionCallContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DefaultTableFunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DefaultTableFunctionCallContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultTableFunctionCall(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_defaultTableFunctionCall(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DefaultTableFunctionCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_defaultTableFunctionCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultTableFunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionCall }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionCall }
}

impl<'input> Borrow<TableFunctionCallContextExt<'input>> for DefaultTableFunctionCallContext<'input>{
	fn borrow(&self) -> &TableFunctionCallContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableFunctionCallContextExt<'input>> for DefaultTableFunctionCallContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableFunctionCallContextExt<'input> { &mut self.base }
}

impl<'input> TableFunctionCallContextAttrs<'input> for DefaultTableFunctionCallContext<'input> {}

impl<'input> DefaultTableFunctionCallContextExt<'input>{
	fn new(ctx: &dyn TableFunctionCallContextAttrs<'input>) -> Rc<TableFunctionCallContextAll<'input>>  {
		Rc::new(
			TableFunctionCallContextAll::DefaultTableFunctionCallContext(
				BaseParserRuleContext::copy_from(ctx,DefaultTableFunctionCallContextExt{
					COMMA:None, 
        			tail:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionCall(&mut self,)
	-> Result<Rc<TableFunctionCallContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionCallContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 194, RULE_tableFunctionCall);
        let mut _localctx: Rc<TableFunctionCallContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = DefaultTableFunctionCallContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule functionName*/
			recog.base.set_state(2164);
			recog.functionName()?;

			recog.base.set_state(2165);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2177);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(282,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule tableFunctionArgument*/
					recog.base.set_state(2166);
					recog.tableFunctionArgument()?;

					recog.base.set_state(2171);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(280,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2167);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule tableFunctionArgument*/
							recog.base.set_state(2168);
							recog.tableFunctionArgument()?;

							}
							} 
						}
						recog.base.set_state(2173);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(280,&mut recog.base)?;
					}
					recog.base.set_state(2175);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2174);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
						ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

						let temp = if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
						ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
						ctx.tail.push(temp); } else {unreachable!("cant cast");}  
						}
					}

					}
				}

				_ => {}
			}
			recog.base.set_state(2180);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COPARTITION {
				{
				/*InvokeRule tableFunctionArgumentCopartition*/
				recog.base.set_state(2179);
				recog.tableFunctionArgumentCopartition()?;

				}
			}

			recog.base.set_state(2182);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2184);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(284,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule over*/
					recog.base.set_state(2183);
					recog.over()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionArgumentCopartition ----------------
pub type TableFunctionArgumentCopartitionContextAll<'input> = TableFunctionArgumentCopartitionContext<'input>;


pub type TableFunctionArgumentCopartitionContext<'input> = BaseParserRuleContext<'input,TableFunctionArgumentCopartitionContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionArgumentCopartitionContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TableFunctionArgumentCopartitionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableFunctionArgumentCopartitionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFunctionArgumentCopartition(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_tableFunctionArgumentCopartition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableFunctionArgumentCopartitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionArgumentCopartition(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionArgumentCopartitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionArgumentCopartition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionArgumentCopartition }
}
antlr_rust::tid!{TableFunctionArgumentCopartitionContextExt<'a>}

impl<'input> TableFunctionArgumentCopartitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionArgumentCopartitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionArgumentCopartitionContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFunctionArgumentCopartitionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TableFunctionArgumentCopartitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COPARTITION
/// Returns `None` if there is no child corresponding to token COPARTITION
fn COPARTITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COPARTITION, 0)
}
fn copartitionTables_all(&self) ->  Vec<Rc<CopartitionTablesContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn copartitionTables(&self, i: usize) -> Option<Rc<CopartitionTablesContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableFunctionArgumentCopartitionContextAttrs<'input> for TableFunctionArgumentCopartitionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionArgumentCopartition(&mut self,)
	-> Result<Rc<TableFunctionArgumentCopartitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionArgumentCopartitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 196, RULE_tableFunctionArgumentCopartition);
        let mut _localctx: Rc<TableFunctionArgumentCopartitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2186);
			recog.base.match_token(COPARTITION,&mut recog.err_handler)?;

			/*InvokeRule copartitionTables*/
			recog.base.set_state(2187);
			recog.copartitionTables()?;

			recog.base.set_state(2192);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(285,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2188);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule copartitionTables*/
					recog.base.set_state(2189);
					recog.copartitionTables()?;

					}
					} 
				}
				recog.base.set_state(2194);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(285,&mut recog.base)?;
			}
			recog.base.set_state(2196);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2195);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,TableFunctionArgumentCopartitionContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,TableFunctionArgumentCopartitionContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,TableFunctionArgumentCopartitionContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionArgumentName ----------------
pub type TableFunctionArgumentNameContextAll<'input> = TableFunctionArgumentNameContext<'input>;


pub type TableFunctionArgumentNameContext<'input> = BaseParserRuleContext<'input,TableFunctionArgumentNameContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionArgumentNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TableFunctionArgumentNameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableFunctionArgumentNameContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFunctionArgumentName(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_tableFunctionArgumentName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableFunctionArgumentNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionArgumentName(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionArgumentNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionArgumentName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionArgumentName }
}
antlr_rust::tid!{TableFunctionArgumentNameContextExt<'a>}

impl<'input> TableFunctionArgumentNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionArgumentNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionArgumentNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFunctionArgumentNameContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TableFunctionArgumentNameContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableFunctionArgumentNameContextAttrs<'input> for TableFunctionArgumentNameContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionArgumentName(&mut self,)
	-> Result<Rc<TableFunctionArgumentNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionArgumentNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 198, RULE_tableFunctionArgumentName);
        let mut _localctx: Rc<TableFunctionArgumentNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2198);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionArgument ----------------
pub type TableFunctionArgumentContextAll<'input> = TableFunctionArgumentContext<'input>;


pub type TableFunctionArgumentContext<'input> = BaseParserRuleContext<'input,TableFunctionArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TableFunctionArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableFunctionArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFunctionArgument(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_tableFunctionArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableFunctionArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionArgument }
}
antlr_rust::tid!{TableFunctionArgumentContextExt<'a>}

impl<'input> TableFunctionArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFunctionArgumentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TableFunctionArgumentContextExt<'input>>{

fn tableArgument(&self) -> Option<Rc<TableArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn descriptorArgument(&self) -> Option<Rc<DescriptorArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableFunctionArgumentName(&self) -> Option<Rc<TableFunctionArgumentNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableFunctionArgumentContextAttrs<'input> for TableFunctionArgumentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionArgument(&mut self,)
	-> Result<Rc<TableFunctionArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 200, RULE_tableFunctionArgument);
        let mut _localctx: Rc<TableFunctionArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2203);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(287,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule tableFunctionArgumentName*/
					recog.base.set_state(2200);
					recog.tableFunctionArgumentName()?;

					recog.base.set_state(2201);
					recog.base.match_token(T__1,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			recog.base.set_state(2208);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(288,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule tableArgument*/
					recog.base.set_state(2205);
					recog.tableArgument()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule descriptorArgument*/
					recog.base.set_state(2206);
					recog.descriptorArgument()?;

					}
				}
			,
				3 =>{
					{
					/*InvokeRule expression*/
					recog.base.set_state(2207);
					recog.expression()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableArgument ----------------
pub type TableArgumentContextAll<'input> = TableArgumentContext<'input>;


pub type TableArgumentContext<'input> = BaseParserRuleContext<'input,TableArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct TableArgumentContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TableArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableArgument(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_tableArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgument }
}
antlr_rust::tid!{TableArgumentContextExt<'a>}

impl<'input> TableArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableArgumentContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableArgumentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TableArgumentContextExt<'input>>{

fn tableArgumentRelation(&self) -> Option<Rc<TableArgumentRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves first TerminalNode corresponding to token PRUNE
/// Returns `None` if there is no child corresponding to token PRUNE
fn PRUNE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PRUNE, 0)
}
/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token EMPTY
/// Returns `None` if there is no child corresponding to token EMPTY
fn EMPTY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EMPTY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEEP
/// Returns `None` if there is no child corresponding to token KEEP
fn KEEP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(KEEP, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableArgumentContextAttrs<'input> for TableArgumentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableArgument(&mut self,)
	-> Result<Rc<TableArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 202, RULE_tableArgument);
        let mut _localctx: Rc<TableArgumentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableArgumentRelation*/
			recog.base.set_state(2210);
			recog.tableArgumentRelation()?;

			recog.base.set_state(2231);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PARTITION {
				{
				recog.base.set_state(2211);
				recog.base.match_token(PARTITION,&mut recog.err_handler)?;

				recog.base.set_state(2212);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(2229);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(292,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(2213);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(2225);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
							{
							/*InvokeRule expression*/
							recog.base.set_state(2214);
							recog.expression()?;

							recog.base.set_state(2219);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(289,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2215);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(2216);
									recog.expression()?;

									}
									} 
								}
								recog.base.set_state(2221);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(289,&mut recog.base)?;
							}
							recog.base.set_state(2223);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2222);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								 cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA = Some(tmp);
								  

								let temp =  cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA.clone().unwrap()
								 ;
								 cast_mut::<_,TableArgumentContext >(&mut _localctx).tail.push(temp);
								  
								}
							}

							}
						}

						recog.base.set_state(2227);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule expression*/
						recog.base.set_state(2228);
						recog.expression()?;

						}
					}

					_ => {}
				}
				}
			}

			recog.base.set_state(2239);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 PRUNE 
				=> {
			    	{
			    	recog.base.set_state(2233);
			    	recog.base.match_token(PRUNE,&mut recog.err_handler)?;

			    	recog.base.set_state(2234);
			    	recog.base.match_token(WHEN,&mut recog.err_handler)?;

			    	recog.base.set_state(2235);
			    	recog.base.match_token(EMPTY,&mut recog.err_handler)?;

			    	}
			    }

			 KEEP 
				=> {
			    	{
			    	recog.base.set_state(2236);
			    	recog.base.match_token(KEEP,&mut recog.err_handler)?;

			    	recog.base.set_state(2237);
			    	recog.base.match_token(WHEN,&mut recog.err_handler)?;

			    	recog.base.set_state(2238);
			    	recog.base.match_token(EMPTY,&mut recog.err_handler)?;

			    	}
			    }

			 COMMA | COPARTITION | ORDER | RPAREN 
				=> {
			    }

				_ => {}
			}
			recog.base.set_state(2260);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				recog.base.set_state(2241);
				recog.base.match_token(ORDER,&mut recog.err_handler)?;

				recog.base.set_state(2242);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(2258);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(297,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(2243);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule sortItem*/
						recog.base.set_state(2244);
						recog.sortItem()?;

						recog.base.set_state(2249);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(295,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(2245);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule sortItem*/
								recog.base.set_state(2246);
								recog.sortItem()?;

								}
								} 
							}
							recog.base.set_state(2251);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(295,&mut recog.base)?;
						}
						recog.base.set_state(2253);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(2252);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							 cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA = Some(tmp);
							  

							let temp =  cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA.clone().unwrap()
							 ;
							 cast_mut::<_,TableArgumentContext >(&mut _localctx).tail.push(temp);
							  
							}
						}

						recog.base.set_state(2255);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule sortItem*/
						recog.base.set_state(2257);
						recog.sortItem()?;

						}
					}

					_ => {}
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableArgumentRelation ----------------
#[derive(Debug)]
pub enum TableArgumentRelationContextAll<'input>{
	TableArgumentQueryContext(TableArgumentQueryContext<'input>),
	TableArgumentTableContext(TableArgumentTableContext<'input>),
Error(TableArgumentRelationContext<'input>)
}
antlr_rust::tid!{TableArgumentRelationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TableArgumentRelationContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for TableArgumentRelationContextAll<'input>{}

impl<'input> Deref for TableArgumentRelationContextAll<'input>{
	type Target = dyn TableArgumentRelationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TableArgumentRelationContextAll::*;
		match self{
			TableArgumentQueryContext(inner) => inner,
			TableArgumentTableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableArgumentRelationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableArgumentRelationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TableArgumentRelationContext<'input> = BaseParserRuleContext<'input,TableArgumentRelationContextExt<'input>>;

#[derive(Clone)]
pub struct TableArgumentRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TableArgumentRelationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableArgumentRelationContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableArgumentRelationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TableArgumentRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}
antlr_rust::tid!{TableArgumentRelationContextExt<'a>}

impl<'input> TableArgumentRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableArgumentRelationContextAll<'input>> {
		Rc::new(
		TableArgumentRelationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableArgumentRelationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TableArgumentRelationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TableArgumentRelationContextExt<'input>>{


}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentRelationContext<'input>{}

pub type TableArgumentQueryContext<'input> = BaseParserRuleContext<'input,TableArgumentQueryContextExt<'input>>;

pub trait TableArgumentQueryContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableArgumentQueryContextAttrs<'input> for TableArgumentQueryContext<'input>{}

pub struct TableArgumentQueryContextExt<'input>{
	base:TableArgumentRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableArgumentQueryContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TableArgumentQueryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableArgumentQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableArgumentQuery(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_tableArgumentQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableArgumentQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableArgumentQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}

impl<'input> Borrow<TableArgumentRelationContextExt<'input>> for TableArgumentQueryContext<'input>{
	fn borrow(&self) -> &TableArgumentRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableArgumentRelationContextExt<'input>> for TableArgumentQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableArgumentRelationContextExt<'input> { &mut self.base }
}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentQueryContext<'input> {}

impl<'input> TableArgumentQueryContextExt<'input>{
	fn new(ctx: &dyn TableArgumentRelationContextAttrs<'input>) -> Rc<TableArgumentRelationContextAll<'input>>  {
		Rc::new(
			TableArgumentRelationContextAll::TableArgumentQueryContext(
				BaseParserRuleContext::copy_from(ctx,TableArgumentQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableArgumentTableContext<'input> = BaseParserRuleContext<'input,TableArgumentTableContextExt<'input>>;

pub trait TableArgumentTableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableArgumentTableContextAttrs<'input> for TableArgumentTableContext<'input>{}

pub struct TableArgumentTableContextExt<'input>{
	base:TableArgumentRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableArgumentTableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TableArgumentTableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TableArgumentTableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableArgumentTable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_tableArgumentTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TableArgumentTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tableArgumentTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}

impl<'input> Borrow<TableArgumentRelationContextExt<'input>> for TableArgumentTableContext<'input>{
	fn borrow(&self) -> &TableArgumentRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableArgumentRelationContextExt<'input>> for TableArgumentTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableArgumentRelationContextExt<'input> { &mut self.base }
}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentTableContext<'input> {}

impl<'input> TableArgumentTableContextExt<'input>{
	fn new(ctx: &dyn TableArgumentRelationContextAttrs<'input>) -> Rc<TableArgumentRelationContextAll<'input>>  {
		Rc::new(
			TableArgumentRelationContextAll::TableArgumentTableContext(
				BaseParserRuleContext::copy_from(ctx,TableArgumentTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableArgumentRelation(&mut self,)
	-> Result<Rc<TableArgumentRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableArgumentRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 204, RULE_tableArgumentRelation);
        let mut _localctx: Rc<TableArgumentRelationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2277);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(302,&mut recog.base)? {
				1 =>{
					let tmp = TableArgumentTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2262);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(2263);
					recog.qualifiedName()?;

					}
				}
			,
				2 =>{
					let tmp = TableArgumentQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2264);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(2265);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2266);
					recog.query()?;

					recog.base.set_state(2267);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2275);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(301,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2269);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==AS {
								{
								recog.base.set_state(2268);
								recog.base.match_token(AS,&mut recog.err_handler)?;

								}
							}

							/*InvokeRule identifier*/
							recog.base.set_state(2271);
							recog.identifier()?;

							recog.base.set_state(2273);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(300,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule columnAliases*/
									recog.base.set_state(2272);
									recog.columnAliases()?;

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- descriptorArgument ----------------
pub type DescriptorArgumentContextAll<'input> = DescriptorArgumentContext<'input>;


pub type DescriptorArgumentContext<'input> = BaseParserRuleContext<'input,DescriptorArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct DescriptorArgumentContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for DescriptorArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DescriptorArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_descriptorArgument(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_descriptorArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DescriptorArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_descriptorArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescriptorArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_descriptorArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_descriptorArgument }
}
antlr_rust::tid!{DescriptorArgumentContextExt<'a>}

impl<'input> DescriptorArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DescriptorArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DescriptorArgumentContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DescriptorArgumentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<DescriptorArgumentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DESCRIPTOR
/// Returns `None` if there is no child corresponding to token DESCRIPTOR
fn DESCRIPTOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DESCRIPTOR, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn descriptorField_all(&self) ->  Vec<Rc<DescriptorFieldContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn descriptorField(&self, i: usize) -> Option<Rc<DescriptorFieldContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token CAST
/// Returns `None` if there is no child corresponding to token CAST
fn CAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> DescriptorArgumentContextAttrs<'input> for DescriptorArgumentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn descriptorArgument(&mut self,)
	-> Result<Rc<DescriptorArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DescriptorArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 206, RULE_descriptorArgument);
        let mut _localctx: Rc<DescriptorArgumentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2300);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DESCRIPTOR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2279);
					recog.base.match_token(DESCRIPTOR,&mut recog.err_handler)?;

					recog.base.set_state(2280);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule descriptorField*/
					recog.base.set_state(2281);
					recog.descriptorField()?;

					recog.base.set_state(2286);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(303,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2282);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule descriptorField*/
							recog.base.set_state(2283);
							recog.descriptorField()?;

							}
							} 
						}
						recog.base.set_state(2288);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(303,&mut recog.base)?;
					}
					recog.base.set_state(2290);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2289);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,DescriptorArgumentContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(2292);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

			 CAST 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2294);
					recog.base.match_token(CAST,&mut recog.err_handler)?;

					recog.base.set_state(2295);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2296);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					recog.base.set_state(2297);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(2298);
					recog.base.match_token(DESCRIPTOR,&mut recog.err_handler)?;

					recog.base.set_state(2299);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- descriptorField ----------------
pub type DescriptorFieldContextAll<'input> = DescriptorFieldContext<'input>;


pub type DescriptorFieldContext<'input> = BaseParserRuleContext<'input,DescriptorFieldContextExt<'input>>;

#[derive(Clone)]
pub struct DescriptorFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for DescriptorFieldContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DescriptorFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_descriptorField(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_descriptorField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DescriptorFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_descriptorField(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescriptorFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_descriptorField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_descriptorField }
}
antlr_rust::tid!{DescriptorFieldContextExt<'a>}

impl<'input> DescriptorFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DescriptorFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DescriptorFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DescriptorFieldContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<DescriptorFieldContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DescriptorFieldContextAttrs<'input> for DescriptorFieldContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn descriptorField(&mut self,)
	-> Result<Rc<DescriptorFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DescriptorFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 208, RULE_descriptorField);
        let mut _localctx: Rc<DescriptorFieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2302);
			recog.identifier()?;

			recog.base.set_state(2304);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (DOLLAR - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
				{
				/*InvokeRule type_*/
				recog.base.set_state(2303);
				recog.type_()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- copartitionTables ----------------
pub type CopartitionTablesContextAll<'input> = CopartitionTablesContext<'input>;


pub type CopartitionTablesContext<'input> = BaseParserRuleContext<'input,CopartitionTablesContextExt<'input>>;

#[derive(Clone)]
pub struct CopartitionTablesContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for CopartitionTablesContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CopartitionTablesContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_copartitionTables(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_copartitionTables(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CopartitionTablesContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_copartitionTables(self);
	}
}

impl<'input> CustomRuleContext<'input> for CopartitionTablesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_copartitionTables }
	//fn type_rule_index() -> usize where Self: Sized { RULE_copartitionTables }
}
antlr_rust::tid!{CopartitionTablesContextExt<'a>}

impl<'input> CopartitionTablesContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CopartitionTablesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CopartitionTablesContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CopartitionTablesContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<CopartitionTablesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> CopartitionTablesContextAttrs<'input> for CopartitionTablesContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn copartitionTables(&mut self,)
	-> Result<Rc<CopartitionTablesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CopartitionTablesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 210, RULE_copartitionTables);
        let mut _localctx: Rc<CopartitionTablesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2306);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule qualifiedName*/
			recog.base.set_state(2307);
			recog.qualifiedName()?;

			recog.base.set_state(2308);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule qualifiedName*/
			recog.base.set_state(2309);
			recog.qualifiedName()?;

			recog.base.set_state(2314);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(307,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2310);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(2311);
					recog.qualifiedName()?;

					}
					} 
				}
				recog.base.set_state(2316);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(307,&mut recog.base)?;
			}
			recog.base.set_state(2318);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2317);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,CopartitionTablesContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			recog.base.set_state(2320);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expression ----------------
pub type ExpressionContextAll<'input> = ExpressionContext<'input>;


pub type ExpressionContext<'input> = BaseParserRuleContext<'input,ExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expression(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_expression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expression }
}
antlr_rust::tid!{ExpressionContextExt<'a>}

impl<'input> ExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ExpressionContextExt<'input>>{

fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionContextAttrs<'input> for ExpressionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expression(&mut self,)
	-> Result<Rc<ExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 212, RULE_expression);
        let mut _localctx: Rc<ExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule booleanExpression*/
			recog.base.set_state(2322);
			recog.booleanExpression_rec(0)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanExpression ----------------
#[derive(Debug)]
pub enum BooleanExpressionContextAll<'input>{
	LogicalNotContext(LogicalNotContext<'input>),
	PredicatedContext(PredicatedContext<'input>),
	OrContext(OrContext<'input>),
	AndContext(AndContext<'input>),
Error(BooleanExpressionContext<'input>)
}
antlr_rust::tid!{BooleanExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for BooleanExpressionContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for BooleanExpressionContextAll<'input>{}

impl<'input> Deref for BooleanExpressionContextAll<'input>{
	type Target = dyn BooleanExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use BooleanExpressionContextAll::*;
		match self{
			LogicalNotContext(inner) => inner,
			PredicatedContext(inner) => inner,
			OrContext(inner) => inner,
			AndContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BooleanExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BooleanExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type BooleanExpressionContext<'input> = BaseParserRuleContext<'input,BooleanExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for BooleanExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BooleanExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BooleanExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for BooleanExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}
antlr_rust::tid!{BooleanExpressionContextExt<'a>}

impl<'input> BooleanExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanExpressionContextAll<'input>> {
		Rc::new(
		BooleanExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait BooleanExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<BooleanExpressionContextExt<'input>>{


}

impl<'input> BooleanExpressionContextAttrs<'input> for BooleanExpressionContext<'input>{}

pub type LogicalNotContext<'input> = BaseParserRuleContext<'input,LogicalNotContextExt<'input>>;

pub trait LogicalNotContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> LogicalNotContextAttrs<'input> for LogicalNotContext<'input>{}

pub struct LogicalNotContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LogicalNotContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for LogicalNotContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LogicalNotContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_logicalNot(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_logicalNot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LogicalNotContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_logicalNot(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalNotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for LogicalNotContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for LogicalNotContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for LogicalNotContext<'input> {}

impl<'input> LogicalNotContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::LogicalNotContext(
				BaseParserRuleContext::copy_from(ctx,LogicalNotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PredicatedContext<'input> = BaseParserRuleContext<'input,PredicatedContextExt<'input>>;

pub trait PredicatedContextAttrs<'input>: BigqueryParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn predicate(&self) -> Option<Rc<PredicateContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PredicatedContextAttrs<'input> for PredicatedContext<'input>{}

pub struct PredicatedContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub pred: Option<Rc<PredicateContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PredicatedContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PredicatedContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PredicatedContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_predicated(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_predicated(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PredicatedContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_predicated(self);
	}
}

impl<'input> CustomRuleContext<'input> for PredicatedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for PredicatedContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for PredicatedContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for PredicatedContext<'input> {}

impl<'input> PredicatedContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::PredicatedContext(
				BaseParserRuleContext::copy_from(ctx,PredicatedContextExt{
        			left:None, pred:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type OrContext<'input> = BaseParserRuleContext<'input,OrContextExt<'input>>;

pub trait OrContextAttrs<'input>: BigqueryParserContext<'input>{
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
}

impl<'input> OrContextAttrs<'input> for OrContext<'input>{}

pub struct OrContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OrContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for OrContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for OrContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_or(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_or(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for OrContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_or(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for OrContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for OrContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for OrContext<'input> {}

impl<'input> OrContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::OrContext(
				BaseParserRuleContext::copy_from(ctx,OrContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AndContext<'input> = BaseParserRuleContext<'input,AndContextExt<'input>>;

pub trait AndContextAttrs<'input>: BigqueryParserContext<'input>{
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
}

impl<'input> AndContextAttrs<'input> for AndContext<'input>{}

pub struct AndContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AndContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for AndContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for AndContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_and(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_and(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for AndContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_and(self);
	}
}

impl<'input> CustomRuleContext<'input> for AndContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for AndContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for AndContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for AndContext<'input> {}

impl<'input> AndContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::AndContext(
				BaseParserRuleContext::copy_from(ctx,AndContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  booleanExpression(&mut self,)
	-> Result<Rc<BooleanExpressionContextAll<'input>>,ANTLRError> {
		self.booleanExpression_rec(0)
	}

	fn booleanExpression_rec(&mut self, _p: isize)
	-> Result<Rc<BooleanExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = BooleanExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 214, RULE_booleanExpression, _p);
	    let mut _localctx: Rc<BooleanExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 214;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2331);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ARRAY |
			 ATTACH | AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK |
			 BZIP2 | CALL | CANCEL | CASCADE | CASE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CAST | CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT |
			 CURRENT_ROLE | CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE |
			 DATETIME | DAY | DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF |
			 DEALLOCATE | DECLARE | DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER |
			 DENY | DESCRIBE | DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED |
			 DISTSTYLE | DETACH | DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING |
			 ERROR | EVEN | EXCEPTION | EXCLUDING | EXECUTE | EXISTS | EXPLAIN | EXTERNAL |
			 EXTRACT | FALSE | FIELDS | FILTER | FINAL | FIRST | FORMAT | FRIDAY |
			 FUNCTION | FUNCTIONS | GENERATED | GRACE | GRANT | GRANTED | GRANTS |
			 GRAPHVIZ | GROUPING | GZIP | HEADER | HOUR | IDENTITY | IF | IMMEDIATE |
			 INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT | INTERLEAVED | INSERT |
			 INTERVAL | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR | ITERATE | ILIKE |
			 JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE | LAST | LEADING |
			 LEFT | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION | LOCK |
			 LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | NULL | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION |
			 OPTIONS | OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS |
			 PASSING | PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE |
			 PIVOT | POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES |
			 PROPERTIES | PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME |
			 REPEATABLE | REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE |
			 REPEAT | RETURNS | REVOKE | RIGHT | RLS | ROLE | ROLES | ROLLBACK | ROW |
			 RUNNING | SAFE | SAFE_CAST | SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS |
			 SECURITY | SEEK | SEMI | SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION |
			 SETS | SHOW | SIMILAR | SNAPSHOT | SORTKEY | START | STATS | STORED |
			 STRUCT | SUBSET | SUBSTRING | SUNDAY | SYSTEM | SYSTEM_TIME | TABLE |
			 TABLES | TEMP | TEMPORARY | TERMINATED | TEXT | STRING_KW | THURSDAY |
			 TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF | TOP | TRAILING | TARGET |
			 SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM | TRIM | TRUE | TRUNCATE |
			 TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED | UNCONDITIONAL |
			 UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL | UPDATE |
			 USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES |
			 VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE | WITHOUT |
			 WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | LPAREN | LBRACKET |
			 PLUS | MINUS | POSIX | QUOTED_STRING | TRIPLE_QUOTED_STRING | RAW_QUOTED_STRING |
			 RAW_TRIPLE_QUOTED_STRING | BINARY_LITERAL | INTEGER_VALUE | HEXADECIMAL_VALUE |
			 DECIMAL_VALUE | DOUBLE_VALUE | IDENTIFIER | BACKQUOTED_IDENTIFIER | VARIABLE 
				=> {
					{
					let mut tmp = PredicatedContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					/*InvokeRule valueExpression*/
					recog.base.set_state(2325);
					let tmp = recog.valueExpression_rec(0)?;
					if let BooleanExpressionContextAll::PredicatedContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
					ctx.left = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2327);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(309,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule predicate*/
							recog.base.set_state(2326);
							let tmp = recog.predicate()?;
							if let BooleanExpressionContextAll::PredicatedContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
							ctx.pred = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}

			 NOT 
				=> {
					{
					let mut tmp = LogicalNotContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2329);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(2330);
					recog.booleanExpression_rec(3)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2341);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(312,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(2339);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(311,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = AndContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(2333);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(2334);
							recog.base.match_token(AND,&mut recog.err_handler)?;

							/*InvokeRule booleanExpression*/
							recog.base.set_state(2335);
							recog.booleanExpression_rec(3)?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = OrContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(2336);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(2337);
							recog.base.match_token(OR,&mut recog.err_handler)?;

							/*InvokeRule booleanExpression*/
							recog.base.set_state(2338);
							recog.booleanExpression_rec(2)?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(2343);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(312,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- predicate ----------------
#[derive(Debug)]
pub enum PredicateContextAll<'input>{
	InUnnestContext(InUnnestContext<'input>),
	UnknownPredicateContext(UnknownPredicateContext<'input>),
	ComparisonContext(ComparisonContext<'input>),
	QuantifiedLikeContext(QuantifiedLikeContext<'input>),
	LikeContext(LikeContext<'input>),
	InSubqueryContext(InSubqueryContext<'input>),
	DistinctFromContext(DistinctFromContext<'input>),
	FalsePredicateContext(FalsePredicateContext<'input>),
	TruePredicateContext(TruePredicateContext<'input>),
	InListContext(InListContext<'input>),
	NullPredicateContext(NullPredicateContext<'input>),
	BetweenContext(BetweenContext<'input>),
	QuantifiedComparisonContext(QuantifiedComparisonContext<'input>),
Error(PredicateContext<'input>)
}
antlr_rust::tid!{PredicateContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PredicateContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PredicateContextAll<'input>{}

impl<'input> Deref for PredicateContextAll<'input>{
	type Target = dyn PredicateContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PredicateContextAll::*;
		match self{
			InUnnestContext(inner) => inner,
			UnknownPredicateContext(inner) => inner,
			ComparisonContext(inner) => inner,
			QuantifiedLikeContext(inner) => inner,
			LikeContext(inner) => inner,
			InSubqueryContext(inner) => inner,
			DistinctFromContext(inner) => inner,
			FalsePredicateContext(inner) => inner,
			TruePredicateContext(inner) => inner,
			InListContext(inner) => inner,
			NullPredicateContext(inner) => inner,
			BetweenContext(inner) => inner,
			QuantifiedComparisonContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PredicateContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PredicateContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PredicateContext<'input> = BaseParserRuleContext<'input,PredicateContextExt<'input>>;

#[derive(Clone)]
pub struct PredicateContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PredicateContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PredicateContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PredicateContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}
antlr_rust::tid!{PredicateContextExt<'a>}

impl<'input> PredicateContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PredicateContextAll<'input>> {
		Rc::new(
		PredicateContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PredicateContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PredicateContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PredicateContextExt<'input>>{


}

impl<'input> PredicateContextAttrs<'input> for PredicateContext<'input>{}

pub type InUnnestContext<'input> = BaseParserRuleContext<'input,InUnnestContextExt<'input>>;

pub trait InUnnestContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UNNEST
	/// Returns `None` if there is no child corresponding to token UNNEST
	fn UNNEST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(UNNEST, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> InUnnestContextAttrs<'input> for InUnnestContext<'input>{}

pub struct InUnnestContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InUnnestContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for InUnnestContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for InUnnestContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inUnnest(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_inUnnest(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for InUnnestContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_inUnnest(self);
	}
}

impl<'input> CustomRuleContext<'input> for InUnnestContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for InUnnestContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for InUnnestContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for InUnnestContext<'input> {}

impl<'input> InUnnestContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::InUnnestContext(
				BaseParserRuleContext::copy_from(ctx,InUnnestContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnknownPredicateContext<'input> = BaseParserRuleContext<'input,UnknownPredicateContextExt<'input>>;

pub trait UnknownPredicateContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UNKNOWN
	/// Returns `None` if there is no child corresponding to token UNKNOWN
	fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(UNKNOWN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> UnknownPredicateContextAttrs<'input> for UnknownPredicateContext<'input>{}

pub struct UnknownPredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnknownPredicateContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UnknownPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnknownPredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unknownPredicate(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_unknownPredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnknownPredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unknownPredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnknownPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for UnknownPredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for UnknownPredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for UnknownPredicateContext<'input> {}

impl<'input> UnknownPredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::UnknownPredicateContext(
				BaseParserRuleContext::copy_from(ctx,UnknownPredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ComparisonContext<'input> = BaseParserRuleContext<'input,ComparisonContextExt<'input>>;

pub trait ComparisonContextAttrs<'input>: BigqueryParserContext<'input>{
	fn comparisonOperator(&self) -> Option<Rc<ComparisonOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ComparisonContextAttrs<'input> for ComparisonContext<'input>{}

pub struct ComparisonContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ComparisonContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ComparisonContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ComparisonContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_comparison(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_comparison(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ComparisonContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_comparison(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for ComparisonContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for ComparisonContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for ComparisonContext<'input> {}

impl<'input> ComparisonContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::ComparisonContext(
				BaseParserRuleContext::copy_from(ctx,ComparisonContextExt{
        			right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QuantifiedLikeContext<'input> = BaseParserRuleContext<'input,QuantifiedLikeContextExt<'input>>;

pub trait QuantifiedLikeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ALL
	/// Returns `None` if there is no child corresponding to token ALL
	fn ALL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ALL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ANY
	/// Returns `None` if there is no child corresponding to token ANY
	fn ANY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ANY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SOME
	/// Returns `None` if there is no child corresponding to token SOME
	fn SOME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SOME, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> QuantifiedLikeContextAttrs<'input> for QuantifiedLikeContext<'input>{}

pub struct QuantifiedLikeContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub valueExpression: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub pattern:Vec<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuantifiedLikeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for QuantifiedLikeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QuantifiedLikeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quantifiedLike(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_quantifiedLike(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QuantifiedLikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_quantifiedLike(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuantifiedLikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for QuantifiedLikeContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for QuantifiedLikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for QuantifiedLikeContext<'input> {}

impl<'input> QuantifiedLikeContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::QuantifiedLikeContext(
				BaseParserRuleContext::copy_from(ctx,QuantifiedLikeContextExt{
        			valueExpression:None, 
        			pattern:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LikeContext<'input> = BaseParserRuleContext<'input,LikeContextExt<'input>>;

pub trait LikeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> LikeContextAttrs<'input> for LikeContext<'input>{}

pub struct LikeContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub pattern: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LikeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for LikeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LikeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_like(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_like(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_like(self);
	}
}

impl<'input> CustomRuleContext<'input> for LikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for LikeContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for LikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for LikeContext<'input> {}

impl<'input> LikeContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::LikeContext(
				BaseParserRuleContext::copy_from(ctx,LikeContextExt{
        			pattern:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InSubqueryContext<'input> = BaseParserRuleContext<'input,InSubqueryContextExt<'input>>;

pub trait InSubqueryContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> InSubqueryContextAttrs<'input> for InSubqueryContext<'input>{}

pub struct InSubqueryContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InSubqueryContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for InSubqueryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for InSubqueryContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inSubquery(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_inSubquery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for InSubqueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_inSubquery(self);
	}
}

impl<'input> CustomRuleContext<'input> for InSubqueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for InSubqueryContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for InSubqueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for InSubqueryContext<'input> {}

impl<'input> InSubqueryContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::InSubqueryContext(
				BaseParserRuleContext::copy_from(ctx,InSubqueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DistinctFromContext<'input> = BaseParserRuleContext<'input,DistinctFromContextExt<'input>>;

pub trait DistinctFromContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DISTINCT
	/// Returns `None` if there is no child corresponding to token DISTINCT
	fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DISTINCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> DistinctFromContextAttrs<'input> for DistinctFromContext<'input>{}

pub struct DistinctFromContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DistinctFromContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DistinctFromContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DistinctFromContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_distinctFrom(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_distinctFrom(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DistinctFromContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_distinctFrom(self);
	}
}

impl<'input> CustomRuleContext<'input> for DistinctFromContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for DistinctFromContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for DistinctFromContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for DistinctFromContext<'input> {}

impl<'input> DistinctFromContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::DistinctFromContext(
				BaseParserRuleContext::copy_from(ctx,DistinctFromContextExt{
        			right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FalsePredicateContext<'input> = BaseParserRuleContext<'input,FalsePredicateContextExt<'input>>;

pub trait FalsePredicateContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FALSE
	/// Returns `None` if there is no child corresponding to token FALSE
	fn FALSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FALSE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> FalsePredicateContextAttrs<'input> for FalsePredicateContext<'input>{}

pub struct FalsePredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FalsePredicateContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for FalsePredicateContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FalsePredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_falsePredicate(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_falsePredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FalsePredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_falsePredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for FalsePredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for FalsePredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for FalsePredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for FalsePredicateContext<'input> {}

impl<'input> FalsePredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::FalsePredicateContext(
				BaseParserRuleContext::copy_from(ctx,FalsePredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TruePredicateContext<'input> = BaseParserRuleContext<'input,TruePredicateContextExt<'input>>;

pub trait TruePredicateContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRUE
	/// Returns `None` if there is no child corresponding to token TRUE
	fn TRUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> TruePredicateContextAttrs<'input> for TruePredicateContext<'input>{}

pub struct TruePredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TruePredicateContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TruePredicateContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TruePredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_truePredicate(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_truePredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TruePredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_truePredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for TruePredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for TruePredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for TruePredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for TruePredicateContext<'input> {}

impl<'input> TruePredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::TruePredicateContext(
				BaseParserRuleContext::copy_from(ctx,TruePredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InListContext<'input> = BaseParserRuleContext<'input,InListContextExt<'input>>;

pub trait InListContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> InListContextAttrs<'input> for InListContext<'input>{}

pub struct InListContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InListContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for InListContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for InListContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inList(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_inList(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for InListContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_inList(self);
	}
}

impl<'input> CustomRuleContext<'input> for InListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for InListContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for InListContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for InListContext<'input> {}

impl<'input> InListContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::InListContext(
				BaseParserRuleContext::copy_from(ctx,InListContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NullPredicateContext<'input> = BaseParserRuleContext<'input,NullPredicateContextExt<'input>>;

pub trait NullPredicateContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> NullPredicateContextAttrs<'input> for NullPredicateContext<'input>{}

pub struct NullPredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NullPredicateContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for NullPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NullPredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nullPredicate(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_nullPredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NullPredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_nullPredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for NullPredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for NullPredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for NullPredicateContext<'input> {}

impl<'input> NullPredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::NullPredicateContext(
				BaseParserRuleContext::copy_from(ctx,NullPredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BetweenContext<'input> = BaseParserRuleContext<'input,BetweenContextExt<'input>>;

pub trait BetweenContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BETWEEN
	/// Returns `None` if there is no child corresponding to token BETWEEN
	fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BETWEEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> BetweenContextAttrs<'input> for BetweenContext<'input>{}

pub struct BetweenContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub lower: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub upper: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BetweenContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BetweenContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BetweenContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_between(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_between(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BetweenContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_between(self);
	}
}

impl<'input> CustomRuleContext<'input> for BetweenContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for BetweenContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for BetweenContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for BetweenContext<'input> {}

impl<'input> BetweenContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::BetweenContext(
				BaseParserRuleContext::copy_from(ctx,BetweenContextExt{
        			lower:None, upper:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QuantifiedComparisonContext<'input> = BaseParserRuleContext<'input,QuantifiedComparisonContextExt<'input>>;

pub trait QuantifiedComparisonContextAttrs<'input>: BigqueryParserContext<'input>{
	fn comparisonOperator(&self) -> Option<Rc<ComparisonOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn comparisonQuantifier(&self) -> Option<Rc<ComparisonQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> QuantifiedComparisonContextAttrs<'input> for QuantifiedComparisonContext<'input>{}

pub struct QuantifiedComparisonContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuantifiedComparisonContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for QuantifiedComparisonContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QuantifiedComparisonContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quantifiedComparison(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_quantifiedComparison(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QuantifiedComparisonContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_quantifiedComparison(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuantifiedComparisonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for QuantifiedComparisonContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for QuantifiedComparisonContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for QuantifiedComparisonContext<'input> {}

impl<'input> QuantifiedComparisonContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::QuantifiedComparisonContext(
				BaseParserRuleContext::copy_from(ctx,QuantifiedComparisonContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn predicate(&mut self,)
	-> Result<Rc<PredicateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PredicateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 216, RULE_predicate);
        let mut _localctx: Rc<PredicateContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2441);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(327,&mut recog.base)? {
				1 =>{
					let tmp = ComparisonContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule comparisonOperator*/
					recog.base.set_state(2344);
					recog.comparisonOperator()?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2345);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::ComparisonContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = QuantifiedComparisonContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule comparisonOperator*/
					recog.base.set_state(2347);
					recog.comparisonOperator()?;

					/*InvokeRule comparisonQuantifier*/
					recog.base.set_state(2348);
					recog.comparisonQuantifier()?;

					recog.base.set_state(2349);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2350);
					recog.query()?;

					recog.base.set_state(2351);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = BetweenContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2354);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2353);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2356);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2357);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::BetweenContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.lower = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2358);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2359);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::BetweenContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.upper = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				4 =>{
					let tmp = InListContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(2362);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2361);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2364);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2365);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2366);
					recog.expression()?;

					recog.base.set_state(2371);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(315,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2367);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2368);
							recog.expression()?;

							}
							} 
						}
						recog.base.set_state(2373);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(315,&mut recog.base)?;
					}
					recog.base.set_state(2375);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2374);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PredicateContextAll::InListContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2377);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = InUnnestContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(2380);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2379);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2382);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2383);
					recog.base.match_token(UNNEST,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2384);
					recog.valueExpression_rec(0)?;

					}
				}
			,
				6 =>{
					let tmp = InSubqueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(2386);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2385);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2388);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2389);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2390);
					recog.query()?;

					recog.base.set_state(2391);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = QuantifiedLikeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(2394);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2393);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2396);
					recog.base.match_token(LIKE,&mut recog.err_handler)?;

					recog.base.set_state(2397);
					_la = recog.base.input.la(1);
					if { !(_la==ALL || _la==ANY || _la==SOME) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2398);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2399);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.valueExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.valueExpression.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.pattern.push(temp); } else {unreachable!("cant cast");}  
					recog.base.set_state(2404);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2400);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule valueExpression*/
						recog.base.set_state(2401);
						let tmp = recog.valueExpression_rec(0)?;
						if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.valueExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.valueExpression.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.pattern.push(temp); } else {unreachable!("cant cast");}  
						}
						}
						recog.base.set_state(2406);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2407);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					let tmp = LikeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(2410);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2409);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2412);
					recog.base.match_token(LIKE,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2413);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::LikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				9 =>{
					let tmp = NullPredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(2414);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2416);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2415);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2418);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					let tmp = DistinctFromContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(2419);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2421);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2420);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2423);
					recog.base.match_token(DISTINCT,&mut recog.err_handler)?;

					recog.base.set_state(2424);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2425);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::DistinctFromContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				11 =>{
					let tmp = TruePredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(2426);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2428);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2427);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2430);
					recog.base.match_token(TRUE,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					let tmp = FalsePredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 12);
					_localctx = tmp;
					{
					recog.base.set_state(2431);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2433);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2432);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2435);
					recog.base.match_token(FALSE,&mut recog.err_handler)?;

					}
				}
			,
				13 =>{
					let tmp = UnknownPredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 13);
					_localctx = tmp;
					{
					recog.base.set_state(2436);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2438);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2437);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2440);
					recog.base.match_token(UNKNOWN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valueExpression ----------------
#[derive(Debug)]
pub enum ValueExpressionContextAll<'input>{
	ValueExpressionDefaultContext(ValueExpressionDefaultContext<'input>),
	ConcatenationContext(ConcatenationContext<'input>),
	ArithmeticBinaryContext(ArithmeticBinaryContext<'input>),
	ArithmeticUnaryContext(ArithmeticUnaryContext<'input>),
Error(ValueExpressionContext<'input>)
}
antlr_rust::tid!{ValueExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ValueExpressionContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for ValueExpressionContextAll<'input>{}

impl<'input> Deref for ValueExpressionContextAll<'input>{
	type Target = dyn ValueExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ValueExpressionContextAll::*;
		match self{
			ValueExpressionDefaultContext(inner) => inner,
			ConcatenationContext(inner) => inner,
			ArithmeticBinaryContext(inner) => inner,
			ArithmeticUnaryContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ValueExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ValueExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ValueExpressionContext<'input> = BaseParserRuleContext<'input,ValueExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ValueExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ValueExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ValueExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ValueExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ValueExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}
antlr_rust::tid!{ValueExpressionContextExt<'a>}

impl<'input> ValueExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValueExpressionContextAll<'input>> {
		Rc::new(
		ValueExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValueExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ValueExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ValueExpressionContextExt<'input>>{


}

impl<'input> ValueExpressionContextAttrs<'input> for ValueExpressionContext<'input>{}

pub type ValueExpressionDefaultContext<'input> = BaseParserRuleContext<'input,ValueExpressionDefaultContextExt<'input>>;

pub trait ValueExpressionDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ValueExpressionDefaultContextAttrs<'input> for ValueExpressionDefaultContext<'input>{}

pub struct ValueExpressionDefaultContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ValueExpressionDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ValueExpressionDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ValueExpressionDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_valueExpressionDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_valueExpressionDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ValueExpressionDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_valueExpressionDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for ValueExpressionDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ValueExpressionDefaultContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ValueExpressionDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ValueExpressionDefaultContext<'input> {}

impl<'input> ValueExpressionDefaultContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ValueExpressionDefaultContext(
				BaseParserRuleContext::copy_from(ctx,ValueExpressionDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ConcatenationContext<'input> = BaseParserRuleContext<'input,ConcatenationContextExt<'input>>;

pub trait ConcatenationContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CONCAT
	/// Returns `None` if there is no child corresponding to token CONCAT
	fn CONCAT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CONCAT, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> ConcatenationContextAttrs<'input> for ConcatenationContext<'input>{}

pub struct ConcatenationContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ConcatenationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ConcatenationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ConcatenationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_concatenation(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_concatenation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ConcatenationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_concatenation(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConcatenationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ConcatenationContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ConcatenationContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ConcatenationContext<'input> {}

impl<'input> ConcatenationContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ConcatenationContext(
				BaseParserRuleContext::copy_from(ctx,ConcatenationContextExt{
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArithmeticBinaryContext<'input> = BaseParserRuleContext<'input,ArithmeticBinaryContextExt<'input>>;

pub trait ArithmeticBinaryContextAttrs<'input>: BigqueryParserContext<'input>{
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SLASH
	/// Returns `None` if there is no child corresponding to token SLASH
	fn SLASH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SLASH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_SHIFT_LEFT
	/// Returns `None` if there is no child corresponding to token BITWISE_SHIFT_LEFT
	fn BITWISE_SHIFT_LEFT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_SHIFT_LEFT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_AND
	/// Returns `None` if there is no child corresponding to token BITWISE_AND
	fn BITWISE_AND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_AND, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_OR
	/// Returns `None` if there is no child corresponding to token BITWISE_OR
	fn BITWISE_OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_XOR
	/// Returns `None` if there is no child corresponding to token BITWISE_XOR
	fn BITWISE_XOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_XOR, 0)
	}
}

impl<'input> ArithmeticBinaryContextAttrs<'input> for ArithmeticBinaryContext<'input>{}

pub struct ArithmeticBinaryContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub operator: Option<TokenType<'input>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArithmeticBinaryContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ArithmeticBinaryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ArithmeticBinaryContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arithmeticBinary(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_arithmeticBinary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ArithmeticBinaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_arithmeticBinary(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticBinaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ArithmeticBinaryContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ArithmeticBinaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ArithmeticBinaryContext<'input> {}

impl<'input> ArithmeticBinaryContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ArithmeticBinaryContext(
				BaseParserRuleContext::copy_from(ctx,ArithmeticBinaryContextExt{
					operator:None, 
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArithmeticUnaryContext<'input> = BaseParserRuleContext<'input,ArithmeticUnaryContextExt<'input>>;

pub trait ArithmeticUnaryContextAttrs<'input>: BigqueryParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX
	/// Returns `None` if there is no child corresponding to token POSIX
	fn POSIX(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(POSIX, 0)
	}
}

impl<'input> ArithmeticUnaryContextAttrs<'input> for ArithmeticUnaryContext<'input>{}

pub struct ArithmeticUnaryContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub operator: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArithmeticUnaryContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ArithmeticUnaryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ArithmeticUnaryContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arithmeticUnary(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_arithmeticUnary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ArithmeticUnaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_arithmeticUnary(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticUnaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ArithmeticUnaryContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ArithmeticUnaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ArithmeticUnaryContext<'input> {}

impl<'input> ArithmeticUnaryContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ArithmeticUnaryContext(
				BaseParserRuleContext::copy_from(ctx,ArithmeticUnaryContextExt{
					operator:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  valueExpression(&mut self,)
	-> Result<Rc<ValueExpressionContextAll<'input>>,ANTLRError> {
		self.valueExpression_rec(0)
	}

	fn valueExpression_rec(&mut self, _p: isize)
	-> Result<Rc<ValueExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = ValueExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 218, RULE_valueExpression, _p);
	    let mut _localctx: Rc<ValueExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 218;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2447);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(328,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = ValueExpressionDefaultContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					/*InvokeRule primaryExpression*/
					recog.base.set_state(2444);
					recog.primaryExpression_rec(0)?;

					}
				}
			,
				2 =>{
					{
					let mut tmp = ArithmeticUnaryContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2445);
					if let ValueExpressionContextAll::ArithmeticUnaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
					ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(((((_la - 406)) & !0x3f) == 0 && ((1usize << (_la - 406)) & ((1usize << (PLUS - 406)) | (1usize << (MINUS - 406)) | (1usize << (POSIX - 406)))) != 0)) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let ValueExpressionContextAll::ArithmeticUnaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
						ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2446);
					recog.valueExpression_rec(6)?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2466);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(330,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(2464);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(329,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2449);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							recog.base.set_state(2450);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==ASTERISK || _la==SLASH) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2451);
							let tmp = recog.valueExpression_rec(6)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2452);
							if !({recog.precpred(None, 4)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 4)".to_owned()), None))?;
							}
							recog.base.set_state(2453);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==PLUS || _la==MINUS) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2454);
							let tmp = recog.valueExpression_rec(5)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ConcatenationContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ConcatenationContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2455);
							if !({recog.precpred(None, 3)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 3)".to_owned()), None))?;
							}
							recog.base.set_state(2456);
							recog.base.match_token(CONCAT,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(2457);
							let tmp = recog.valueExpression_rec(4)?;
							if let ValueExpressionContextAll::ConcatenationContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						4 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2458);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(2459);
							let tmp = recog.base.match_token(BITWISE_SHIFT_LEFT,&mut recog.err_handler)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							/*InvokeRule valueExpression*/
							recog.base.set_state(2460);
							let tmp = recog.valueExpression_rec(3)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						5 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2461);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(2462);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (BITWISE_AND - 416)) | (1usize << (BITWISE_OR - 416)) | (1usize << (BITWISE_XOR - 416)))) != 0)) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2463);
							let tmp = recog.valueExpression_rec(2)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(2468);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(330,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- primaryExpression ----------------
#[derive(Debug)]
pub enum PrimaryExpressionContextAll<'input>{
	DateDiffContext(DateDiffContext<'input>),
	DereferenceContext(DereferenceContext<'input>),
	StructConstructorContext(StructConstructorContext<'input>),
	TypeConstructorContext(TypeConstructorContext<'input>),
	BigqueryArrayConstructorContext(BigqueryArrayConstructorContext<'input>),
	SubstringContext(SubstringContext<'input>),
	CountStarContext(CountStarContext<'input>),
	CastContext(CastContext<'input>),
	LambdaContext(LambdaContext<'input>),
	ParenthesizedExpressionContext(ParenthesizedExpressionContext<'input>),
	TrimContext(TrimContext<'input>),
	ArrayContext(ArrayContext<'input>),
	NormalizeContext(NormalizeContext<'input>),
	IntervalLiteralContext(IntervalLiteralContext<'input>),
	NumericLiteralContext(NumericLiteralContext<'input>),
	BooleanLiteralContext(BooleanLiteralContext<'input>),
	SimpleCaseContext(SimpleCaseContext<'input>),
	ColumnReferenceContext(ColumnReferenceContext<'input>),
	NullLiteralContext(NullLiteralContext<'input>),
	RowConstructorContext(RowConstructorContext<'input>),
	SubscriptContext(SubscriptContext<'input>),
	CoalesceContext(CoalesceContext<'input>),
	ArraySubqueryContext(ArraySubqueryContext<'input>),
	SubqueryExpressionContext(SubqueryExpressionContext<'input>),
	BinaryLiteralContext(BinaryLiteralContext<'input>),
	BigqueryExtractContext(BigqueryExtractContext<'input>),
	MeasureContext(MeasureContext<'input>),
	StringLiteralContext(StringLiteralContext<'input>),
	FunctionCallContext(FunctionCallContext<'input>),
	VariableContext(VariableContext<'input>),
	ExistsContext(ExistsContext<'input>),
	SearchedCaseContext(SearchedCaseContext<'input>),
Error(PrimaryExpressionContext<'input>)
}
antlr_rust::tid!{PrimaryExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PrimaryExpressionContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PrimaryExpressionContextAll<'input>{}

impl<'input> Deref for PrimaryExpressionContextAll<'input>{
	type Target = dyn PrimaryExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PrimaryExpressionContextAll::*;
		match self{
			DateDiffContext(inner) => inner,
			DereferenceContext(inner) => inner,
			StructConstructorContext(inner) => inner,
			TypeConstructorContext(inner) => inner,
			BigqueryArrayConstructorContext(inner) => inner,
			SubstringContext(inner) => inner,
			CountStarContext(inner) => inner,
			CastContext(inner) => inner,
			LambdaContext(inner) => inner,
			ParenthesizedExpressionContext(inner) => inner,
			TrimContext(inner) => inner,
			ArrayContext(inner) => inner,
			NormalizeContext(inner) => inner,
			IntervalLiteralContext(inner) => inner,
			NumericLiteralContext(inner) => inner,
			BooleanLiteralContext(inner) => inner,
			SimpleCaseContext(inner) => inner,
			ColumnReferenceContext(inner) => inner,
			NullLiteralContext(inner) => inner,
			RowConstructorContext(inner) => inner,
			SubscriptContext(inner) => inner,
			CoalesceContext(inner) => inner,
			ArraySubqueryContext(inner) => inner,
			SubqueryExpressionContext(inner) => inner,
			BinaryLiteralContext(inner) => inner,
			BigqueryExtractContext(inner) => inner,
			MeasureContext(inner) => inner,
			StringLiteralContext(inner) => inner,
			FunctionCallContext(inner) => inner,
			VariableContext(inner) => inner,
			ExistsContext(inner) => inner,
			SearchedCaseContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PrimaryExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PrimaryExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PrimaryExpressionContext<'input> = BaseParserRuleContext<'input,PrimaryExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrimaryExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PrimaryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PrimaryExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PrimaryExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PrimaryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}
antlr_rust::tid!{PrimaryExpressionContextExt<'a>}

impl<'input> PrimaryExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrimaryExpressionContextAll<'input>> {
		Rc::new(
		PrimaryExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrimaryExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PrimaryExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PrimaryExpressionContextExt<'input>>{


}

impl<'input> PrimaryExpressionContextAttrs<'input> for PrimaryExpressionContext<'input>{}

pub type DateDiffContext<'input> = BaseParserRuleContext<'input,DateDiffContextExt<'input>>;

pub trait DateDiffContextAttrs<'input>: BigqueryParserContext<'input>{
	fn dateDiffCall(&self) -> Option<Rc<DateDiffCallContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DateDiffContextAttrs<'input> for DateDiffContext<'input>{}

pub struct DateDiffContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DateDiffContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DateDiffContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DateDiffContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dateDiff(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_dateDiff(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DateDiffContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dateDiff(self);
	}
}

impl<'input> CustomRuleContext<'input> for DateDiffContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for DateDiffContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for DateDiffContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for DateDiffContext<'input> {}

impl<'input> DateDiffContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::DateDiffContext(
				BaseParserRuleContext::copy_from(ctx,DateDiffContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DereferenceContext<'input> = BaseParserRuleContext<'input,DereferenceContextExt<'input>>;

pub trait DereferenceContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn columnNameComponent(&self) -> Option<Rc<ColumnNameComponentContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DereferenceContextAttrs<'input> for DereferenceContext<'input>{}

pub struct DereferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub base_: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub fieldName: Option<Rc<ColumnNameComponentContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DereferenceContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DereferenceContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DereferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dereference(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_dereference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DereferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dereference(self);
	}
}

impl<'input> CustomRuleContext<'input> for DereferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for DereferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for DereferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for DereferenceContext<'input> {}

impl<'input> DereferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::DereferenceContext(
				BaseParserRuleContext::copy_from(ctx,DereferenceContextExt{
        			base_:None, fieldName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StructConstructorContext<'input> = BaseParserRuleContext<'input,StructConstructorContextExt<'input>>;

pub trait StructConstructorContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STRUCT
	/// Returns `None` if there is no child corresponding to token STRUCT
	fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(STRUCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	fn rowField_all(&self) ->  Vec<Rc<RowFieldContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowField(&self, i: usize) -> Option<Rc<RowFieldContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
	fn field_all(&self) ->  Vec<Rc<FieldContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn field(&self, i: usize) -> Option<Rc<FieldContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> StructConstructorContextAttrs<'input> for StructConstructorContext<'input>{}

pub struct StructConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StructConstructorContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for StructConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StructConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_structConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_structConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StructConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_structConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for StructConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for StructConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for StructConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for StructConstructorContext<'input> {}

impl<'input> StructConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::StructConstructorContext(
				BaseParserRuleContext::copy_from(ctx,StructConstructorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TypeConstructorContext<'input> = BaseParserRuleContext<'input,TypeConstructorContextExt<'input>>;

pub trait TypeConstructorContextAttrs<'input>: BigqueryParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DOUBLE
	/// Returns `None` if there is no child corresponding to token DOUBLE
	fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DOUBLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECISION
	/// Returns `None` if there is no child corresponding to token PRECISION
	fn PRECISION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PRECISION, 0)
	}
}

impl<'input> TypeConstructorContextAttrs<'input> for TypeConstructorContext<'input>{}

pub struct TypeConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TypeConstructorContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TypeConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TypeConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_typeConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_typeConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TypeConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_typeConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TypeConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TypeConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TypeConstructorContext<'input> {}

impl<'input> TypeConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TypeConstructorContext(
				BaseParserRuleContext::copy_from(ctx,TypeConstructorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigqueryArrayConstructorContext<'input> = BaseParserRuleContext<'input,BigqueryArrayConstructorContextExt<'input>>;

pub trait BigqueryArrayConstructorContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> BigqueryArrayConstructorContextAttrs<'input> for BigqueryArrayConstructorContext<'input>{}

pub struct BigqueryArrayConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigqueryArrayConstructorContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BigqueryArrayConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BigqueryArrayConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigqueryArrayConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_bigqueryArrayConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BigqueryArrayConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_bigqueryArrayConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigqueryArrayConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for BigqueryArrayConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for BigqueryArrayConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for BigqueryArrayConstructorContext<'input> {}

impl<'input> BigqueryArrayConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::BigqueryArrayConstructorContext(
				BaseParserRuleContext::copy_from(ctx,BigqueryArrayConstructorContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubstringContext<'input> = BaseParserRuleContext<'input,SubstringContextExt<'input>>;

pub trait SubstringContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SUBSTRING
	/// Returns `None` if there is no child corresponding to token SUBSTRING
	fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SUBSTRING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
}

impl<'input> SubstringContextAttrs<'input> for SubstringContext<'input>{}

pub struct SubstringContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubstringContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SubstringContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SubstringContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_substring(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_substring(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SubstringContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_substring(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubstringContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubstringContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubstringContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubstringContext<'input> {}

impl<'input> SubstringContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubstringContext(
				BaseParserRuleContext::copy_from(ctx,SubstringContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CountStarContext<'input> = BaseParserRuleContext<'input,CountStarContextExt<'input>>;

pub trait CountStarContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COUNT
	/// Returns `None` if there is no child corresponding to token COUNT
	fn COUNT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COUNT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn functionCallTail(&self) -> Option<Rc<FunctionCallTailContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CountStarContextAttrs<'input> for CountStarContext<'input>{}

pub struct CountStarContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CountStarContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CountStarContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CountStarContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_countStar(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_countStar(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CountStarContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_countStar(self);
	}
}

impl<'input> CustomRuleContext<'input> for CountStarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CountStarContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CountStarContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CountStarContext<'input> {}

impl<'input> CountStarContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CountStarContext(
				BaseParserRuleContext::copy_from(ctx,CountStarContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CastContext<'input> = BaseParserRuleContext<'input,CastContextExt<'input>>;

pub trait CastContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CAST
	/// Returns `None` if there is no child corresponding to token CAST
	fn CAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CAST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMAT
	/// Returns `None` if there is no child corresponding to token FORMAT
	fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FORMAT, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SAFE_CAST
	/// Returns `None` if there is no child corresponding to token SAFE_CAST
	fn SAFE_CAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SAFE_CAST, 0)
	}
}

impl<'input> CastContextAttrs<'input> for CastContext<'input>{}

pub struct CastContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CastContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CastContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CastContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_cast(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_cast(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CastContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_cast(self);
	}
}

impl<'input> CustomRuleContext<'input> for CastContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CastContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CastContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CastContext<'input> {}

impl<'input> CastContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CastContext(
				BaseParserRuleContext::copy_from(ctx,CastContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LambdaContext<'input> = BaseParserRuleContext<'input,LambdaContextExt<'input>>;

pub trait LambdaContextAttrs<'input>: BigqueryParserContext<'input>{
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> LambdaContextAttrs<'input> for LambdaContext<'input>{}

pub struct LambdaContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LambdaContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for LambdaContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LambdaContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_lambda(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_lambda(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LambdaContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_lambda(self);
	}
}

impl<'input> CustomRuleContext<'input> for LambdaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for LambdaContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for LambdaContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for LambdaContext<'input> {}

impl<'input> LambdaContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::LambdaContext(
				BaseParserRuleContext::copy_from(ctx,LambdaContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ParenthesizedExpressionContext<'input> = BaseParserRuleContext<'input,ParenthesizedExpressionContextExt<'input>>;

pub trait ParenthesizedExpressionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ParenthesizedExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input>{}

pub struct ParenthesizedExpressionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ParenthesizedExpressionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ParenthesizedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_parenthesizedExpression(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_parenthesizedExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_parenthesizedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParenthesizedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ParenthesizedExpressionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ParenthesizedExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input> {}

impl<'input> ParenthesizedExpressionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ParenthesizedExpressionContext(
				BaseParserRuleContext::copy_from(ctx,ParenthesizedExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TrimContext<'input> = BaseParserRuleContext<'input,TrimContextExt<'input>>;

pub trait TrimContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRIM
	/// Returns `None` if there is no child corresponding to token TRIM
	fn TRIM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRIM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn trimsSpecification(&self) -> Option<Rc<TrimsSpecificationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> TrimContextAttrs<'input> for TrimContext<'input>{}

pub struct TrimContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub trimChar: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub trimSource: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TrimContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TrimContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TrimContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_trim(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_trim(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TrimContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_trim(self);
	}
}

impl<'input> CustomRuleContext<'input> for TrimContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TrimContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TrimContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TrimContext<'input> {}

impl<'input> TrimContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TrimContext(
				BaseParserRuleContext::copy_from(ctx,TrimContextExt{
					tail:None, 
        			trimChar:None, trimSource:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArrayContext<'input> = BaseParserRuleContext<'input,ArrayContextExt<'input>>;

pub trait ArrayContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ArrayContextAttrs<'input> for ArrayContext<'input>{}

pub struct ArrayContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArrayContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ArrayContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ArrayContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_array(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_array(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ArrayContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_array(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArrayContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ArrayContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ArrayContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ArrayContext<'input> {}

impl<'input> ArrayContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ArrayContext(
				BaseParserRuleContext::copy_from(ctx,ArrayContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NormalizeContext<'input> = BaseParserRuleContext<'input,NormalizeContextExt<'input>>;

pub trait NormalizeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NORMALIZE
	/// Returns `None` if there is no child corresponding to token NORMALIZE
	fn NORMALIZE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NORMALIZE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	fn normalForm(&self) -> Option<Rc<NormalFormContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NormalizeContextAttrs<'input> for NormalizeContext<'input>{}

pub struct NormalizeContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NormalizeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for NormalizeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NormalizeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_normalize(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_normalize(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NormalizeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_normalize(self);
	}
}

impl<'input> CustomRuleContext<'input> for NormalizeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for NormalizeContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for NormalizeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for NormalizeContext<'input> {}

impl<'input> NormalizeContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::NormalizeContext(
				BaseParserRuleContext::copy_from(ctx,NormalizeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntervalLiteralContext<'input> = BaseParserRuleContext<'input,IntervalLiteralContextExt<'input>>;

pub trait IntervalLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IntervalLiteralContextAttrs<'input> for IntervalLiteralContext<'input>{}

pub struct IntervalLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntervalLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for IntervalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IntervalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_intervalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_intervalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IntervalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_intervalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for IntervalLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for IntervalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for IntervalLiteralContext<'input> {}

impl<'input> IntervalLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::IntervalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IntervalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NumericLiteralContext<'input> = BaseParserRuleContext<'input,NumericLiteralContextExt<'input>>;

pub trait NumericLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NumericLiteralContextAttrs<'input> for NumericLiteralContext<'input>{}

pub struct NumericLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NumericLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for NumericLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NumericLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_numericLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_numericLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NumericLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_numericLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NumericLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for NumericLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for NumericLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for NumericLiteralContext<'input> {}

impl<'input> NumericLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::NumericLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NumericLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BooleanLiteralContext<'input> = BaseParserRuleContext<'input,BooleanLiteralContextExt<'input>>;

pub trait BooleanLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	fn booleanValue(&self) -> Option<Rc<BooleanValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> BooleanLiteralContextAttrs<'input> for BooleanLiteralContext<'input>{}

pub struct BooleanLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BooleanLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BooleanLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BooleanLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_booleanLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_booleanLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BooleanLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_booleanLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for BooleanLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for BooleanLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for BooleanLiteralContext<'input> {}

impl<'input> BooleanLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::BooleanLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BooleanLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SimpleCaseContext<'input> = BaseParserRuleContext<'input,SimpleCaseContextExt<'input>>;

pub trait SimpleCaseContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CASE
	/// Returns `None` if there is no child corresponding to token CASE
	fn CASE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CASE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn whenClause_all(&self) ->  Vec<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn whenClause(&self, i: usize) -> Option<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
}

impl<'input> SimpleCaseContextAttrs<'input> for SimpleCaseContext<'input>{}

pub struct SimpleCaseContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub operand: Option<Rc<ExpressionContextAll<'input>>>,
	pub elseExpression: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SimpleCaseContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SimpleCaseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SimpleCaseContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_simpleCase(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_simpleCase(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SimpleCaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_simpleCase(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SimpleCaseContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SimpleCaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SimpleCaseContext<'input> {}

impl<'input> SimpleCaseContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SimpleCaseContext(
				BaseParserRuleContext::copy_from(ctx,SimpleCaseContextExt{
        			operand:None, elseExpression:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ColumnReferenceContext<'input> = BaseParserRuleContext<'input,ColumnReferenceContextExt<'input>>;

pub trait ColumnReferenceContextAttrs<'input>: BigqueryParserContext<'input>{
	fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ColumnReferenceContextAttrs<'input> for ColumnReferenceContext<'input>{}

pub struct ColumnReferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnReferenceContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ColumnReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ColumnReferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnReference(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_columnReference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ColumnReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_columnReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ColumnReferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ColumnReferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ColumnReferenceContext<'input> {}

impl<'input> ColumnReferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ColumnReferenceContext(
				BaseParserRuleContext::copy_from(ctx,ColumnReferenceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NullLiteralContext<'input> = BaseParserRuleContext<'input,NullLiteralContextExt<'input>>;

pub trait NullLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
}

impl<'input> NullLiteralContextAttrs<'input> for NullLiteralContext<'input>{}

pub struct NullLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NullLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for NullLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NullLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nullLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_nullLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NullLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_nullLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for NullLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for NullLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for NullLiteralContext<'input> {}

impl<'input> NullLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::NullLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NullLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RowConstructorContext<'input> = BaseParserRuleContext<'input,RowConstructorContextExt<'input>>;

pub trait RowConstructorContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> RowConstructorContextAttrs<'input> for RowConstructorContext<'input>{}

pub struct RowConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowConstructorContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RowConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RowConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_rowConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RowConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rowConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for RowConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for RowConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for RowConstructorContext<'input> {}

impl<'input> RowConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::RowConstructorContext(
				BaseParserRuleContext::copy_from(ctx,RowConstructorContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubscriptContext<'input> = BaseParserRuleContext<'input,SubscriptContextExt<'input>>;

pub trait SubscriptContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SubscriptContextAttrs<'input> for SubscriptContext<'input>{}

pub struct SubscriptContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub value: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub index: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubscriptContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SubscriptContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SubscriptContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subscript(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_subscript(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SubscriptContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_subscript(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubscriptContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubscriptContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubscriptContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubscriptContext<'input> {}

impl<'input> SubscriptContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubscriptContext(
				BaseParserRuleContext::copy_from(ctx,SubscriptContextExt{
        			value:None, index:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CoalesceContext<'input> = BaseParserRuleContext<'input,CoalesceContextExt<'input>>;

pub trait CoalesceContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COALESCE
	/// Returns `None` if there is no child corresponding to token COALESCE
	fn COALESCE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COALESCE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> CoalesceContextAttrs<'input> for CoalesceContext<'input>{}

pub struct CoalesceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CoalesceContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CoalesceContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CoalesceContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_coalesce(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_coalesce(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CoalesceContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_coalesce(self);
	}
}

impl<'input> CustomRuleContext<'input> for CoalesceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CoalesceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CoalesceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CoalesceContext<'input> {}

impl<'input> CoalesceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CoalesceContext(
				BaseParserRuleContext::copy_from(ctx,CoalesceContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArraySubqueryContext<'input> = BaseParserRuleContext<'input,ArraySubqueryContextExt<'input>>;

pub trait ArraySubqueryContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ArraySubqueryContextAttrs<'input> for ArraySubqueryContext<'input>{}

pub struct ArraySubqueryContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArraySubqueryContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ArraySubqueryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ArraySubqueryContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arraySubquery(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_arraySubquery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ArraySubqueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_arraySubquery(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArraySubqueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ArraySubqueryContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ArraySubqueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ArraySubqueryContext<'input> {}

impl<'input> ArraySubqueryContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ArraySubqueryContext(
				BaseParserRuleContext::copy_from(ctx,ArraySubqueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubqueryExpressionContext<'input> = BaseParserRuleContext<'input,SubqueryExpressionContextExt<'input>>;

pub trait SubqueryExpressionContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> SubqueryExpressionContextAttrs<'input> for SubqueryExpressionContext<'input>{}

pub struct SubqueryExpressionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryExpressionContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SubqueryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SubqueryExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subqueryExpression(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_subqueryExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SubqueryExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_subqueryExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubqueryExpressionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubqueryExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubqueryExpressionContext<'input> {}

impl<'input> SubqueryExpressionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubqueryExpressionContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BinaryLiteralContext<'input> = BaseParserRuleContext<'input,BinaryLiteralContextExt<'input>>;

pub trait BinaryLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BINARY_LITERAL
	/// Returns `None` if there is no child corresponding to token BINARY_LITERAL
	fn BINARY_LITERAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BINARY_LITERAL, 0)
	}
}

impl<'input> BinaryLiteralContextAttrs<'input> for BinaryLiteralContext<'input>{}

pub struct BinaryLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BinaryLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BinaryLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BinaryLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_binaryLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_binaryLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BinaryLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_binaryLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BinaryLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for BinaryLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for BinaryLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for BinaryLiteralContext<'input> {}

impl<'input> BinaryLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::BinaryLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BinaryLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigqueryExtractContext<'input> = BaseParserRuleContext<'input,BigqueryExtractContextExt<'input>>;

pub trait BigqueryExtractContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXTRACT
	/// Returns `None` if there is no child corresponding to token EXTRACT
	fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXTRACT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn datePart(&self) -> Option<Rc<DatePartContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AT
	/// Returns `None` if there is no child corresponding to token AT
	fn AT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TIME
	/// Returns `None` if there is no child corresponding to token TIME
	fn TIME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TIME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ZONE
	/// Returns `None` if there is no child corresponding to token ZONE
	fn ZONE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ZONE, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> BigqueryExtractContextAttrs<'input> for BigqueryExtractContext<'input>{}

pub struct BigqueryExtractContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigqueryExtractContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BigqueryExtractContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BigqueryExtractContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigqueryExtract(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_bigqueryExtract(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BigqueryExtractContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_bigqueryExtract(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigqueryExtractContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for BigqueryExtractContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for BigqueryExtractContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for BigqueryExtractContext<'input> {}

impl<'input> BigqueryExtractContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::BigqueryExtractContext(
				BaseParserRuleContext::copy_from(ctx,BigqueryExtractContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MeasureContext<'input> = BaseParserRuleContext<'input,MeasureContextExt<'input>>;

pub trait MeasureContextAttrs<'input>: BigqueryParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MeasureContextAttrs<'input> for MeasureContext<'input>{}

pub struct MeasureContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MeasureContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for MeasureContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MeasureContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_measure(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_measure(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MeasureContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_measure(self);
	}
}

impl<'input> CustomRuleContext<'input> for MeasureContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for MeasureContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for MeasureContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for MeasureContext<'input> {}

impl<'input> MeasureContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::MeasureContext(
				BaseParserRuleContext::copy_from(ctx,MeasureContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StringLiteralContext<'input> = BaseParserRuleContext<'input,StringLiteralContextExt<'input>>;

pub trait StringLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StringLiteralContextAttrs<'input> for StringLiteralContext<'input>{}

pub struct StringLiteralContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StringLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for StringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_stringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_stringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_stringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for StringLiteralContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for StringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for StringLiteralContext<'input> {}

impl<'input> StringLiteralContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::StringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,StringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionCallContext<'input> = BaseParserRuleContext<'input,FunctionCallContextExt<'input>>;

pub trait FunctionCallContextAttrs<'input>: BigqueryParserContext<'input>{
	fn functionCallHead(&self) -> Option<Rc<FunctionCallHeadContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn functionCallTail(&self) -> Option<Rc<FunctionCallTailContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn functionExtraArguments(&self) -> Option<Rc<FunctionExtraArgumentsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> FunctionCallContextAttrs<'input> for FunctionCallContext<'input>{}

pub struct FunctionCallContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionCallContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for FunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FunctionCallContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionCall(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_functionCall(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FunctionCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_functionCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FunctionCallContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FunctionCallContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FunctionCallContext<'input> {}

impl<'input> FunctionCallContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FunctionCallContext(
				BaseParserRuleContext::copy_from(ctx,FunctionCallContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type VariableContext<'input> = BaseParserRuleContext<'input,VariableContextExt<'input>>;

pub trait VariableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token VARIABLE
	/// Returns `None` if there is no child corresponding to token VARIABLE
	fn VARIABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(VARIABLE, 0)
	}
}

impl<'input> VariableContextAttrs<'input> for VariableContext<'input>{}

pub struct VariableContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{VariableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for VariableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for VariableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_variable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_variable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for VariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_variable(self);
	}
}

impl<'input> CustomRuleContext<'input> for VariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for VariableContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for VariableContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for VariableContext<'input> {}

impl<'input> VariableContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::VariableContext(
				BaseParserRuleContext::copy_from(ctx,VariableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExistsContext<'input> = BaseParserRuleContext<'input,ExistsContextExt<'input>>;

pub trait ExistsContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ExistsContextAttrs<'input> for ExistsContext<'input>{}

pub struct ExistsContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExistsContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ExistsContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ExistsContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_exists(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_exists(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ExistsContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_exists(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExistsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ExistsContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ExistsContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ExistsContext<'input> {}

impl<'input> ExistsContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ExistsContext(
				BaseParserRuleContext::copy_from(ctx,ExistsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SearchedCaseContext<'input> = BaseParserRuleContext<'input,SearchedCaseContextExt<'input>>;

pub trait SearchedCaseContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CASE
	/// Returns `None` if there is no child corresponding to token CASE
	fn CASE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CASE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn whenClause_all(&self) ->  Vec<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn whenClause(&self, i: usize) -> Option<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SearchedCaseContextAttrs<'input> for SearchedCaseContext<'input>{}

pub struct SearchedCaseContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub elseExpression: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SearchedCaseContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SearchedCaseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SearchedCaseContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_searchedCase(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_searchedCase(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SearchedCaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_searchedCase(self);
	}
}

impl<'input> CustomRuleContext<'input> for SearchedCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SearchedCaseContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SearchedCaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SearchedCaseContext<'input> {}

impl<'input> SearchedCaseContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SearchedCaseContext(
				BaseParserRuleContext::copy_from(ctx,SearchedCaseContextExt{
        			elseExpression:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  primaryExpression(&mut self,)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		self.primaryExpression_rec(0)
	}

	fn primaryExpression_rec(&mut self, _p: isize)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = PrimaryExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 220, RULE_primaryExpression, _p);
	    let mut _localctx: Rc<PrimaryExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 220;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2764);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(368,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = NullLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					recog.base.set_state(2470);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					{
					let mut tmp = IntervalLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule interval*/
					recog.base.set_state(2471);
					recog.interval()?;

					}
				}
			,
				3 =>{
					{
					let mut tmp = NumericLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule number*/
					recog.base.set_state(2472);
					recog.number()?;

					}
				}
			,
				4 =>{
					{
					let mut tmp = BooleanLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule booleanValue*/
					recog.base.set_state(2473);
					recog.booleanValue()?;

					}
				}
			,
				5 =>{
					{
					let mut tmp = StringLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule string*/
					recog.base.set_state(2474);
					recog.string()?;

					}
				}
			,
				6 =>{
					{
					let mut tmp = BinaryLiteralContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2475);
					recog.base.match_token(BINARY_LITERAL,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					{
					let mut tmp = TypeConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(2476);
					recog.identifier()?;

					/*InvokeRule string*/
					recog.base.set_state(2477);
					recog.string()?;

					}
				}
			,
				8 =>{
					{
					let mut tmp = TypeConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2479);
					recog.base.match_token(DOUBLE,&mut recog.err_handler)?;

					recog.base.set_state(2480);
					recog.base.match_token(PRECISION,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(2481);
					recog.string()?;

					}
				}
			,
				9 =>{
					{
					let mut tmp = RowConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2482);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2483);
					recog.expression()?;

					recog.base.set_state(2486); 
					recog.err_handler.sync(&mut recog.base)?;
					_alt = 1;
					loop {
						match _alt {
						    x if x == 1=>
							{
							{
							recog.base.set_state(2484);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2485);
							recog.expression()?;

							}
							}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						recog.base.set_state(2488); 
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(331,&mut recog.base)?;
						if _alt==2 || _alt==INVALID_ALT { break }
					}
					recog.base.set_state(2491);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2490);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::RowConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2493);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					{
					let mut tmp = StructConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2495);
					recog.base.match_token(STRUCT,&mut recog.err_handler)?;

					recog.base.set_state(2507);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LT {
						{
						recog.base.set_state(2496);
						recog.base.match_token(LT,&mut recog.err_handler)?;

						/*InvokeRule rowField*/
						recog.base.set_state(2497);
						recog.rowField()?;

						recog.base.set_state(2502);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(2498);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule rowField*/
							recog.base.set_state(2499);
							recog.rowField()?;

							}
							}
							recog.base.set_state(2504);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						recog.base.set_state(2505);
						recog.base.match_token(GT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2509);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2518);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						/*InvokeRule field*/
						recog.base.set_state(2510);
						recog.field()?;

						recog.base.set_state(2515);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(2511);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule field*/
							recog.base.set_state(2512);
							recog.field()?;

							}
							}
							recog.base.set_state(2517);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					recog.base.set_state(2520);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					{
					let mut tmp = ExistsContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2521);
					recog.base.match_token(EXISTS,&mut recog.err_handler)?;

					recog.base.set_state(2522);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2523);
					recog.query()?;

					recog.base.set_state(2524);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					{
					let mut tmp = SimpleCaseContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2526);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2527);
					let tmp = recog.expression()?;
					if let PrimaryExpressionContextAll::SimpleCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.operand = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2529); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule whenClause*/
						recog.base.set_state(2528);
						recog.whenClause()?;

						}
						}
						recog.base.set_state(2531); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(2535);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(2533);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(2534);
						let tmp = recog.expression()?;
						if let PrimaryExpressionContextAll::SimpleCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.elseExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2537);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				13 =>{
					{
					let mut tmp = SearchedCaseContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2539);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					recog.base.set_state(2541); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule whenClause*/
						recog.base.set_state(2540);
						recog.whenClause()?;

						}
						}
						recog.base.set_state(2543); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(2547);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(2545);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(2546);
						let tmp = recog.expression()?;
						if let PrimaryExpressionContextAll::SearchedCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.elseExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2549);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				14 =>{
					{
					let mut tmp = CastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2551);
					recog.base.match_token(CAST,&mut recog.err_handler)?;

					recog.base.set_state(2552);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2553);
					recog.expression()?;

					recog.base.set_state(2554);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(2555);
					recog.type_()?;

					recog.base.set_state(2558);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FORMAT {
						{
						recog.base.set_state(2556);
						recog.base.match_token(FORMAT,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(2557);
						recog.string()?;

						}
					}

					recog.base.set_state(2560);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				15 =>{
					{
					let mut tmp = CastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2562);
					recog.base.match_token(SAFE_CAST,&mut recog.err_handler)?;

					recog.base.set_state(2563);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2564);
					recog.expression()?;

					recog.base.set_state(2565);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(2566);
					recog.type_()?;

					recog.base.set_state(2569);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FORMAT {
						{
						recog.base.set_state(2567);
						recog.base.match_token(FORMAT,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(2568);
						recog.string()?;

						}
					}

					recog.base.set_state(2571);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				16 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2573);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(2574);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					{
					recog.base.set_state(2576);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(343,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule trimsSpecification*/
							recog.base.set_state(2575);
							recog.trimsSpecification()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2579);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						/*InvokeRule valueExpression*/
						recog.base.set_state(2578);
						let tmp = recog.valueExpression_rec(0)?;
						if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2581);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2583);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2584);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				17 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2586);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(2587);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2595);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(347,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule trimsSpecification*/
							recog.base.set_state(2588);
							recog.trimsSpecification()?;

							recog.base.set_state(2590);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(345,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule valueExpression*/
									recog.base.set_state(2589);
									let tmp = recog.valueExpression_rec(0)?;
									if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
									ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									}
								}

								_ => {}
							}
							recog.base.set_state(2593);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==FROM {
								{
								recog.base.set_state(2592);
								recog.base.match_token(FROM,&mut recog.err_handler)?;

								}
							}

							}
						}

						_ => {}
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2597);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2598);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				18 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2600);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(2601);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2602);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2603);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2604);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2606);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2605);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2608);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				19 =>{
					{
					let mut tmp = SubstringContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2610);
					recog.base.match_token(SUBSTRING,&mut recog.err_handler)?;

					recog.base.set_state(2611);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2612);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(2613);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2614);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(2617);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(2615);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						/*InvokeRule valueExpression*/
						recog.base.set_state(2616);
						recog.valueExpression_rec(0)?;

						}
					}

					recog.base.set_state(2619);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				20 =>{
					{
					let mut tmp = NormalizeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2621);
					recog.base.match_token(NORMALIZE,&mut recog.err_handler)?;

					recog.base.set_state(2622);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2623);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(2626);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(350,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2624);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule normalForm*/
							recog.base.set_state(2625);
							recog.normalForm()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2629);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2628);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::NormalizeContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2631);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				21 =>{
					{
					let mut tmp = BigqueryExtractContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2633);
					recog.base.match_token(EXTRACT,&mut recog.err_handler)?;

					recog.base.set_state(2634);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule datePart*/
					recog.base.set_state(2635);
					recog.datePart()?;

					recog.base.set_state(2636);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2637);
					recog.expression()?;

					recog.base.set_state(2642);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AT {
						{
						recog.base.set_state(2638);
						recog.base.match_token(AT,&mut recog.err_handler)?;

						recog.base.set_state(2639);
						recog.base.match_token(TIME,&mut recog.err_handler)?;

						recog.base.set_state(2640);
						recog.base.match_token(ZONE,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(2641);
						recog.string()?;

						}
					}

					recog.base.set_state(2644);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				22 =>{
					{
					let mut tmp = CoalesceContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2646);
					recog.base.match_token(COALESCE,&mut recog.err_handler)?;

					recog.base.set_state(2647);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule callArgument*/
					recog.base.set_state(2648);
					recog.callArgument()?;

					recog.base.set_state(2653);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(353,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2649);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule callArgument*/
							recog.base.set_state(2650);
							recog.callArgument()?;

							}
							} 
						}
						recog.base.set_state(2655);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(353,&mut recog.base)?;
					}
					recog.base.set_state(2657);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2656);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::CoalesceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2659);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				23 =>{
					{
					let mut tmp = DateDiffContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule dateDiffCall*/
					recog.base.set_state(2661);
					recog.dateDiffCall()?;

					}
				}
			,
				24 =>{
					{
					let mut tmp = CountStarContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2662);
					recog.base.match_token(COUNT,&mut recog.err_handler)?;

					recog.base.set_state(2663);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2664);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(2665);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule functionCallTail*/
					recog.base.set_state(2666);
					recog.functionCallTail()?;

					}
				}
			,
				25 =>{
					{
					let mut tmp = FunctionCallContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule functionCallHead*/
					recog.base.set_state(2667);
					recog.functionCallHead()?;

					/*InvokeRule functionName*/
					recog.base.set_state(2668);
					recog.functionName()?;

					recog.base.set_state(2669);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					{
					recog.base.set_state(2681);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTINCT - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						recog.base.set_state(2671);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==ALL || _la==DISTINCT {
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(2670);
							recog.setQuantifier()?;

							}
						}

						/*InvokeRule callArgument*/
						recog.base.set_state(2673);
						recog.callArgument()?;

						recog.base.set_state(2678);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(2674);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule callArgument*/
							recog.base.set_state(2675);
							recog.callArgument()?;

							}
							}
							recog.base.set_state(2680);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					/*InvokeRule functionExtraArguments*/
					recog.base.set_state(2683);
					recog.functionExtraArguments()?;

					}
					recog.base.set_state(2685);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule functionCallTail*/
					recog.base.set_state(2686);
					recog.functionCallTail()?;

					}
				}
			,
				26 =>{
					{
					let mut tmp = MeasureContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(2688);
					recog.identifier()?;

					/*InvokeRule over*/
					recog.base.set_state(2689);
					recog.over()?;

					}
				}
			,
				27 =>{
					{
					let mut tmp = LambdaContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(2691);
					recog.identifier()?;

					recog.base.set_state(2692);
					recog.base.match_token(T__2,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2693);
					recog.expression()?;

					}
				}
			,
				28 =>{
					{
					let mut tmp = LambdaContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2695);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2704);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						/*InvokeRule identifier*/
						recog.base.set_state(2696);
						recog.identifier()?;

						recog.base.set_state(2701);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(358,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(2697);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule identifier*/
								recog.base.set_state(2698);
								recog.identifier()?;

								}
								} 
							}
							recog.base.set_state(2703);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(358,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(2707);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2706);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::LambdaContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2709);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2710);
					recog.base.match_token(T__2,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2711);
					recog.expression()?;

					}
				}
			,
				29 =>{
					{
					let mut tmp = SubqueryExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2712);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2713);
					recog.query()?;

					recog.base.set_state(2714);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				30 =>{
					{
					let mut tmp = BigqueryArrayConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2716);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(2721);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LT {
						{
						recog.base.set_state(2717);
						recog.base.match_token(LT,&mut recog.err_handler)?;

						/*InvokeRule type_*/
						recog.base.set_state(2718);
						recog.type_()?;

						recog.base.set_state(2719);
						recog.base.match_token(GT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2723);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(2732);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(2724);
						recog.expression()?;

						recog.base.set_state(2729);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(362,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(2725);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(2726);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(2731);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(362,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(2735);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2734);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::BigqueryArrayConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2737);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				31 =>{
					{
					let mut tmp = ColumnReferenceContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule columnName*/
					recog.base.set_state(2738);
					recog.columnName()?;

					}
				}
			,
				32 =>{
					{
					let mut tmp = ParenthesizedExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2739);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2740);
					recog.expression()?;

					recog.base.set_state(2741);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				33 =>{
					{
					let mut tmp = ArrayContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2743);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(2755);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ARRAY) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CAST - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXISTS - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (EXTRACT - 100)) | (1usize << (FALSE - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GROUPING - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IF - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INTERVAL - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEFT - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (NOT - 196)) | (1usize << (NULL - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RIGHT - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (STRUCT - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUE - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)) | (1usize << (LPAREN - 389)) | (1usize << (LBRACKET - 389)) | (1usize << (PLUS - 389)) | (1usize << (MINUS - 389)) | (1usize << (POSIX - 389)))) != 0) || ((((_la - 422)) & !0x3f) == 0 && ((1usize << (_la - 422)) & ((1usize << (QUOTED_STRING - 422)) | (1usize << (TRIPLE_QUOTED_STRING - 422)) | (1usize << (RAW_QUOTED_STRING - 422)) | (1usize << (RAW_TRIPLE_QUOTED_STRING - 422)) | (1usize << (BINARY_LITERAL - 422)) | (1usize << (INTEGER_VALUE - 422)) | (1usize << (HEXADECIMAL_VALUE - 422)) | (1usize << (DECIMAL_VALUE - 422)) | (1usize << (DOUBLE_VALUE - 422)) | (1usize << (IDENTIFIER - 422)) | (1usize << (BACKQUOTED_IDENTIFIER - 422)) | (1usize << (VARIABLE - 422)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(2744);
						recog.expression()?;

						recog.base.set_state(2749);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(365,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(2745);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(2746);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(2751);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(365,&mut recog.base)?;
						}
						recog.base.set_state(2753);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(2752);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let PrimaryExpressionContextAll::ArrayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(2757);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				34 =>{
					{
					let mut tmp = VariableContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2758);
					recog.base.match_token(VARIABLE,&mut recog.err_handler)?;

					}
				}
			,
				35 =>{
					{
					let mut tmp = ArraySubqueryContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2759);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(2760);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2761);
					recog.query()?;

					recog.base.set_state(2762);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2776);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(370,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(2774);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(369,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = SubscriptContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::SubscriptContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.value = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(2766);
							if !({recog.precpred(None, 7)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 7)".to_owned()), None))?;
							}
							recog.base.set_state(2767);
							recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(2768);
							let tmp = recog.valueExpression_rec(0)?;
							if let PrimaryExpressionContextAll::SubscriptContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.index = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(2769);
							recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = DereferenceContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::DereferenceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.base_ = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(2771);
							if !({recog.precpred(None, 6)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 6)".to_owned()), None))?;
							}
							recog.base.set_state(2772);
							recog.base.match_token(DOT,&mut recog.err_handler)?;

							/*InvokeRule columnNameComponent*/
							recog.base.set_state(2773);
							let tmp = recog.columnNameComponent()?;
							if let PrimaryExpressionContextAll::DereferenceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.fieldName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(2778);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(370,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- functionCallHead ----------------
pub type FunctionCallHeadContextAll<'input> = FunctionCallHeadContext<'input>;


pub type FunctionCallHeadContext<'input> = BaseParserRuleContext<'input,FunctionCallHeadContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallHeadContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FunctionCallHeadContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FunctionCallHeadContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallHead(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_functionCallHead(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FunctionCallHeadContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_functionCallHead(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallHeadContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallHead }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallHead }
}
antlr_rust::tid!{FunctionCallHeadContextExt<'a>}

impl<'input> FunctionCallHeadContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallHeadContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallHeadContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallHeadContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FunctionCallHeadContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SAFE
/// Returns `None` if there is no child corresponding to token SAFE
fn SAFE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SAFE, 0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}

}

impl<'input> FunctionCallHeadContextAttrs<'input> for FunctionCallHeadContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallHead(&mut self,)
	-> Result<Rc<FunctionCallHeadContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallHeadContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 222, RULE_functionCallHead);
        let mut _localctx: Rc<FunctionCallHeadContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2781);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(371,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2779);
					recog.base.match_token(SAFE,&mut recog.err_handler)?;

					recog.base.set_state(2780);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallTail ----------------
pub type FunctionCallTailContextAll<'input> = FunctionCallTailContext<'input>;


pub type FunctionCallTailContext<'input> = BaseParserRuleContext<'input,FunctionCallTailContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallTailContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FunctionCallTailContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FunctionCallTailContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallTail(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_functionCallTail(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FunctionCallTailContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_functionCallTail(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallTailContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallTail }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallTail }
}
antlr_rust::tid!{FunctionCallTailContextExt<'a>}

impl<'input> FunctionCallTailContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallTailContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallTailContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallTailContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FunctionCallTailContextExt<'input>>{

fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallTailContextAttrs<'input> for FunctionCallTailContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallTail(&mut self,)
	-> Result<Rc<FunctionCallTailContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallTailContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 224, RULE_functionCallTail);
        let mut _localctx: Rc<FunctionCallTailContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2784);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(372,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule over*/
					recog.base.set_state(2783);
					recog.over()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- callArgument ----------------
#[derive(Debug)]
pub enum CallArgumentContextAll<'input>{
	PositionalArgumentContext(PositionalArgumentContext<'input>),
	NamedArgumentContext(NamedArgumentContext<'input>),
Error(CallArgumentContext<'input>)
}
antlr_rust::tid!{CallArgumentContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for CallArgumentContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for CallArgumentContextAll<'input>{}

impl<'input> Deref for CallArgumentContextAll<'input>{
	type Target = dyn CallArgumentContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use CallArgumentContextAll::*;
		match self{
			PositionalArgumentContext(inner) => inner,
			NamedArgumentContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CallArgumentContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CallArgumentContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type CallArgumentContext<'input> = BaseParserRuleContext<'input,CallArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct CallArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for CallArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CallArgumentContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CallArgumentContext<'input>{
}

impl<'input> CustomRuleContext<'input> for CallArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}
antlr_rust::tid!{CallArgumentContextExt<'a>}

impl<'input> CallArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CallArgumentContextAll<'input>> {
		Rc::new(
		CallArgumentContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CallArgumentContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait CallArgumentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<CallArgumentContextExt<'input>>{


}

impl<'input> CallArgumentContextAttrs<'input> for CallArgumentContext<'input>{}

pub type PositionalArgumentContext<'input> = BaseParserRuleContext<'input,PositionalArgumentContextExt<'input>>;

pub trait PositionalArgumentContextAttrs<'input>: BigqueryParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PositionalArgumentContextAttrs<'input> for PositionalArgumentContext<'input>{}

pub struct PositionalArgumentContextExt<'input>{
	base:CallArgumentContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PositionalArgumentContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PositionalArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PositionalArgumentContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_positionalArgument(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_positionalArgument(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PositionalArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_positionalArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for PositionalArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}

impl<'input> Borrow<CallArgumentContextExt<'input>> for PositionalArgumentContext<'input>{
	fn borrow(&self) -> &CallArgumentContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CallArgumentContextExt<'input>> for PositionalArgumentContext<'input>{
	fn borrow_mut(&mut self) -> &mut CallArgumentContextExt<'input> { &mut self.base }
}

impl<'input> CallArgumentContextAttrs<'input> for PositionalArgumentContext<'input> {}

impl<'input> PositionalArgumentContextExt<'input>{
	fn new(ctx: &dyn CallArgumentContextAttrs<'input>) -> Rc<CallArgumentContextAll<'input>>  {
		Rc::new(
			CallArgumentContextAll::PositionalArgumentContext(
				BaseParserRuleContext::copy_from(ctx,PositionalArgumentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NamedArgumentContext<'input> = BaseParserRuleContext<'input,NamedArgumentContextExt<'input>>;

pub trait NamedArgumentContextAttrs<'input>: BigqueryParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NamedArgumentContextAttrs<'input> for NamedArgumentContext<'input>{}

pub struct NamedArgumentContextExt<'input>{
	base:CallArgumentContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NamedArgumentContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for NamedArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NamedArgumentContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_namedArgument(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_namedArgument(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NamedArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_namedArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}

impl<'input> Borrow<CallArgumentContextExt<'input>> for NamedArgumentContext<'input>{
	fn borrow(&self) -> &CallArgumentContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CallArgumentContextExt<'input>> for NamedArgumentContext<'input>{
	fn borrow_mut(&mut self) -> &mut CallArgumentContextExt<'input> { &mut self.base }
}

impl<'input> CallArgumentContextAttrs<'input> for NamedArgumentContext<'input> {}

impl<'input> NamedArgumentContextExt<'input>{
	fn new(ctx: &dyn CallArgumentContextAttrs<'input>) -> Rc<CallArgumentContextAll<'input>>  {
		Rc::new(
			CallArgumentContextAll::NamedArgumentContext(
				BaseParserRuleContext::copy_from(ctx,NamedArgumentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn callArgument(&mut self,)
	-> Result<Rc<CallArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CallArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 226, RULE_callArgument);
        let mut _localctx: Rc<CallArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2791);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(373,&mut recog.base)? {
				1 =>{
					let tmp = PositionalArgumentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(2786);
					recog.expression()?;

					}
				}
			,
				2 =>{
					let tmp = NamedArgumentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2787);
					recog.identifier()?;

					recog.base.set_state(2788);
					recog.base.match_token(T__1,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2789);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionExtraArguments ----------------
pub type FunctionExtraArgumentsContextAll<'input> = FunctionExtraArgumentsContext<'input>;


pub type FunctionExtraArgumentsContext<'input> = BaseParserRuleContext<'input,FunctionExtraArgumentsContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionExtraArgumentsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FunctionExtraArgumentsContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FunctionExtraArgumentsContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionExtraArguments(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_functionExtraArguments(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FunctionExtraArgumentsContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_functionExtraArguments(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionExtraArgumentsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionExtraArguments }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionExtraArguments }
}
antlr_rust::tid!{FunctionExtraArgumentsContextExt<'a>}

impl<'input> FunctionExtraArgumentsContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionExtraArgumentsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionExtraArgumentsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionExtraArgumentsContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FunctionExtraArgumentsContextExt<'input>>{

fn nullTreatment(&self) -> Option<Rc<NullTreatmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn havingArgument(&self) -> Option<Rc<HavingArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn limitArgument(&self) -> Option<Rc<LimitArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> FunctionExtraArgumentsContextAttrs<'input> for FunctionExtraArgumentsContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionExtraArguments(&mut self,)
	-> Result<Rc<FunctionExtraArgumentsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionExtraArgumentsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 228, RULE_functionExtraArguments);
        let mut _localctx: Rc<FunctionExtraArgumentsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2794);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==IGNORE || _la==RESPECT {
				{
				/*InvokeRule nullTreatment*/
				recog.base.set_state(2793);
				recog.nullTreatment()?;

				}
			}

			recog.base.set_state(2797);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==HAVING {
				{
				/*InvokeRule havingArgument*/
				recog.base.set_state(2796);
				recog.havingArgument()?;

				}
			}

			recog.base.set_state(2809);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				recog.base.set_state(2799);
				recog.base.match_token(ORDER,&mut recog.err_handler)?;

				recog.base.set_state(2800);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule sortItem*/
				recog.base.set_state(2801);
				recog.sortItem()?;

				recog.base.set_state(2806);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(2802);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(2803);
					recog.sortItem()?;

					}
					}
					recog.base.set_state(2808);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(2812);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LIMIT {
				{
				/*InvokeRule limitArgument*/
				recog.base.set_state(2811);
				recog.limitArgument()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dateDiffCall ----------------
pub type DateDiffCallContextAll<'input> = DateDiffCallContext<'input>;


pub type DateDiffCallContext<'input> = BaseParserRuleContext<'input,DateDiffCallContextExt<'input>>;

#[derive(Clone)]
pub struct DateDiffCallContextExt<'input>{
	pub left: Option<Rc<ExpressionContextAll<'input>>>,
	pub right: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for DateDiffCallContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DateDiffCallContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dateDiffCall(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_dateDiffCall(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DateDiffCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dateDiffCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for DateDiffCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dateDiffCall }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dateDiffCall }
}
antlr_rust::tid!{DateDiffCallContextExt<'a>}

impl<'input> DateDiffCallContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DateDiffCallContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DateDiffCallContextExt{
				left: None, right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DateDiffCallContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<DateDiffCallContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn datePart(&self) -> Option<Rc<DatePartContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE_DIFF
/// Returns `None` if there is no child corresponding to token DATE_DIFF
fn DATE_DIFF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATE_DIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DATETIME_DIFF
/// Returns `None` if there is no child corresponding to token DATETIME_DIFF
fn DATETIME_DIFF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATETIME_DIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_DIFF
/// Returns `None` if there is no child corresponding to token TIMESTAMP_DIFF
fn TIMESTAMP_DIFF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_DIFF, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> DateDiffCallContextAttrs<'input> for DateDiffCallContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dateDiffCall(&mut self,)
	-> Result<Rc<DateDiffCallContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DateDiffCallContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 230, RULE_dateDiffCall);
        let mut _localctx: Rc<DateDiffCallContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2814);
			_la = recog.base.input.la(1);
			if { !(_la==DATETIME_DIFF || _la==DATE_DIFF || _la==TIMESTAMP_DIFF) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2815);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2816);
			let tmp = recog.expression()?;
			 cast_mut::<_,DateDiffCallContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(2817);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2818);
			let tmp = recog.expression()?;
			 cast_mut::<_,DateDiffCallContext >(&mut _localctx).right = Some(tmp.clone());
			  

			recog.base.set_state(2819);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule datePart*/
			recog.base.set_state(2820);
			recog.datePart()?;

			recog.base.set_state(2821);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- datePart ----------------
pub type DatePartContextAll<'input> = DatePartContext<'input>;


pub type DatePartContext<'input> = BaseParserRuleContext<'input,DatePartContextExt<'input>>;

#[derive(Clone)]
pub struct DatePartContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for DatePartContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DatePartContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_datePart(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_datePart(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DatePartContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_datePart(self);
	}
}

impl<'input> CustomRuleContext<'input> for DatePartContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_datePart }
	//fn type_rule_index() -> usize where Self: Sized { RULE_datePart }
}
antlr_rust::tid!{DatePartContextExt<'a>}

impl<'input> DatePartContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DatePartContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DatePartContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DatePartContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<DatePartContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYOFWEEK
/// Returns `None` if there is no child corresponding to token DAYOFWEEK
fn DAYOFWEEK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DAYOFWEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYOFYEAR
/// Returns `None` if there is no child corresponding to token DAYOFYEAR
fn DAYOFYEAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DAYOFYEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token SUNDAY
/// Returns `None` if there is no child corresponding to token SUNDAY
fn SUNDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SUNDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token MONDAY
/// Returns `None` if there is no child corresponding to token MONDAY
fn MONDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MONDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token TUESDAY
/// Returns `None` if there is no child corresponding to token TUESDAY
fn TUESDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TUESDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token WEDNESDAY
/// Returns `None` if there is no child corresponding to token WEDNESDAY
fn WEDNESDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WEDNESDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token THURSDAY
/// Returns `None` if there is no child corresponding to token THURSDAY
fn THURSDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(THURSDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token FRIDAY
/// Returns `None` if there is no child corresponding to token FRIDAY
fn FRIDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FRIDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token SATURDAY
/// Returns `None` if there is no child corresponding to token SATURDAY
fn SATURDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SATURDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token ISOWEEK
/// Returns `None` if there is no child corresponding to token ISOWEEK
fn ISOWEEK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ISOWEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token QUARTER
/// Returns `None` if there is no child corresponding to token QUARTER
fn QUARTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token ISOYEAR
/// Returns `None` if there is no child corresponding to token ISOYEAR
fn ISOYEAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ISOYEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token DATETIME
/// Returns `None` if there is no child corresponding to token DATETIME
fn DATETIME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATETIME, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}

}

impl<'input> DatePartContextAttrs<'input> for DatePartContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn datePart(&mut self,)
	-> Result<Rc<DatePartContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DatePartContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 232, RULE_datePart);
        let mut _localctx: Rc<DatePartContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2845);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 MICROSECOND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2823);
					recog.base.match_token(MICROSECOND,&mut recog.err_handler)?;

					}
				}

			 MILLISECOND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2824);
					recog.base.match_token(MILLISECOND,&mut recog.err_handler)?;

					}
				}

			 SECOND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(2825);
					recog.base.match_token(SECOND,&mut recog.err_handler)?;

					}
				}

			 MINUTE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(2826);
					recog.base.match_token(MINUTE,&mut recog.err_handler)?;

					}
				}

			 HOUR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(2827);
					recog.base.match_token(HOUR,&mut recog.err_handler)?;

					}
				}

			 DAY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(2828);
					recog.base.match_token(DAY,&mut recog.err_handler)?;

					}
				}

			 DAYOFWEEK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(2829);
					recog.base.match_token(DAYOFWEEK,&mut recog.err_handler)?;

					}
				}

			 DAYOFYEAR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(2830);
					recog.base.match_token(DAYOFYEAR,&mut recog.err_handler)?;

					}
				}

			 WEEK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(2831);
					recog.base.match_token(WEEK,&mut recog.err_handler)?;

					recog.base.set_state(2835);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(2832);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(2833);
						_la = recog.base.input.la(1);
						if { !(_la==FRIDAY || _la==MONDAY || _la==SATURDAY || _la==SUNDAY || _la==THURSDAY || _la==TUESDAY || _la==WEDNESDAY) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						recog.base.set_state(2834);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					}
				}

			 ISOWEEK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					recog.base.set_state(2837);
					recog.base.match_token(ISOWEEK,&mut recog.err_handler)?;

					}
				}

			 MONTH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					recog.base.set_state(2838);
					recog.base.match_token(MONTH,&mut recog.err_handler)?;

					}
				}

			 QUARTER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					recog.base.set_state(2839);
					recog.base.match_token(QUARTER,&mut recog.err_handler)?;

					}
				}

			 YEAR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					recog.base.set_state(2840);
					recog.base.match_token(YEAR,&mut recog.err_handler)?;

					}
				}

			 ISOYEAR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					recog.base.set_state(2841);
					recog.base.match_token(ISOYEAR,&mut recog.err_handler)?;

					}
				}

			 DATETIME 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					recog.base.set_state(2842);
					recog.base.match_token(DATETIME,&mut recog.err_handler)?;

					}
				}

			 DATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					recog.base.set_state(2843);
					recog.base.match_token(DATE,&mut recog.err_handler)?;

					}
				}

			 TIME 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					recog.base.set_state(2844);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionName ----------------
pub type FunctionNameContextAll<'input> = FunctionNameContext<'input>;


pub type FunctionNameContext<'input> = BaseParserRuleContext<'input,FunctionNameContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FunctionNameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FunctionNameContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionName(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_functionName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FunctionNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_functionName(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionName }
}
antlr_rust::tid!{FunctionNameContextExt<'a>}

impl<'input> FunctionNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionNameContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FunctionNameContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}

}

impl<'input> FunctionNameContextAttrs<'input> for FunctionNameContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionName(&mut self,)
	-> Result<Rc<FunctionNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 234, RULE_functionName);
        let mut _localctx: Rc<FunctionNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2853);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(381,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(2847);
					recog.qualifiedName()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2848);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(2849);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(2850);
					recog.base.match_token(IF,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(2851);
					recog.base.match_token(REPLACE,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(2852);
					recog.base.match_token(GROUPING,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- havingArgument ----------------
pub type HavingArgumentContextAll<'input> = HavingArgumentContext<'input>;


pub type HavingArgumentContext<'input> = BaseParserRuleContext<'input,HavingArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct HavingArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for HavingArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for HavingArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_havingArgument(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_havingArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for HavingArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_havingArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for HavingArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_havingArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_havingArgument }
}
antlr_rust::tid!{HavingArgumentContextExt<'a>}

impl<'input> HavingArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HavingArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HavingArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HavingArgumentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<HavingArgumentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token MIN
/// Returns `None` if there is no child corresponding to token MIN
fn MIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MIN, 0)
}
/// Retrieves first TerminalNode corresponding to token MAX
/// Returns `None` if there is no child corresponding to token MAX
fn MAX(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MAX, 0)
}

}

impl<'input> HavingArgumentContextAttrs<'input> for HavingArgumentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn havingArgument(&mut self,)
	-> Result<Rc<HavingArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HavingArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 236, RULE_havingArgument);
        let mut _localctx: Rc<HavingArgumentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2855);
			recog.base.match_token(HAVING,&mut recog.err_handler)?;

			recog.base.set_state(2856);
			_la = recog.base.input.la(1);
			if { !(_la==MAX || _la==MIN) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule expression*/
			recog.base.set_state(2857);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- limitArgument ----------------
pub type LimitArgumentContextAll<'input> = LimitArgumentContext<'input>;


pub type LimitArgumentContext<'input> = BaseParserRuleContext<'input,LimitArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct LimitArgumentContextExt<'input>{
	pub limit: Option<Rc<LimitRowCountContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for LimitArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LimitArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_limitArgument(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_limitArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LimitArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_limitArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for LimitArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_limitArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_limitArgument }
}
antlr_rust::tid!{LimitArgumentContextExt<'a>}

impl<'input> LimitArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LimitArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LimitArgumentContextExt{
				limit: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LimitArgumentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<LimitArgumentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
fn limitRowCount(&self) -> Option<Rc<LimitRowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LimitArgumentContextAttrs<'input> for LimitArgumentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn limitArgument(&mut self,)
	-> Result<Rc<LimitArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LimitArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 238, RULE_limitArgument);
        let mut _localctx: Rc<LimitArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2859);
			recog.base.match_token(LIMIT,&mut recog.err_handler)?;

			/*InvokeRule limitRowCount*/
			recog.base.set_state(2860);
			let tmp = recog.limitRowCount()?;
			 cast_mut::<_,LimitArgumentContext >(&mut _localctx).limit = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedParameter ----------------
pub type NamedParameterContextAll<'input> = NamedParameterContext<'input>;


pub type NamedParameterContext<'input> = BaseParserRuleContext<'input,NamedParameterContextExt<'input>>;

#[derive(Clone)]
pub struct NamedParameterContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NamedParameterContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NamedParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedParameter(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_namedParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NamedParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_namedParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedParameter }
}
antlr_rust::tid!{NamedParameterContextExt<'a>}

impl<'input> NamedParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedParameterContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedParameterContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NamedParameterContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}

}

impl<'input> NamedParameterContextAttrs<'input> for NamedParameterContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedParameter(&mut self,)
	-> Result<Rc<NamedParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 240, RULE_namedParameter);
        let mut _localctx: Rc<NamedParameterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2862);
			let tmp = recog.identifier()?;
			 cast_mut::<_,NamedParameterContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(2866);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ARRAY |
			 ATTACH | AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK |
			 BZIP2 | CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT |
			 CURRENT_ROLE | CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE |
			 DATETIME | DAY | DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF |
			 DEALLOCATE | DECLARE | DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER |
			 DENY | DESCRIBE | DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED |
			 DISTSTYLE | DETACH | DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING |
			 ERROR | EVEN | EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL |
			 FIELDS | FILTER | FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS |
			 GENERATED | GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER |
			 HOUR | IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT |
			 INPUTFORMAT | INTERLEAVED | INSERT | INTERVAL | INVOKER | IO | ISOLATION |
			 ISOWEEK | ISOYEAR | ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA |
			 LANGUAGE | LEAVE | LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG |
			 LOCAL | LOCATION | LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED |
			 MATCHES | MATERIALIZED | MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND |
			 MIN | MINUS_KW | MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC |
			 NFD | NFKC | NFKD | NONE | NORMALIZE | NULL | OBJECT | OFFSET | OMIT |
			 ONE | ONLY | OPTION | OPTIONS | OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD |
			 PERMUTE | PIVOT | POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE |
			 PRIVILEGES | PROPERTIES | PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH |
			 RENAME | REPEATABLE | REPLACE | RESET | RESTRICT | RETURN | RETURNING |
			 REMOTE | REPEAT | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROW | RUNNING | SAFE | SAFE_CAST | SATURDAY | SCALAR | SECOND | SCHEMA |
			 SCHEMAS | SECURITY | SEEK | SEMI | SERDE | SERDEPROPERTIES | SERIALIZABLE |
			 SESSION | SETS | SHOW | SIMILAR | SNAPSHOT | SORTKEY | START | STATS |
			 STORED | STRUCT | SUBSET | SUBSTRING | SUNDAY | SYSTEM | SYSTEM_TIME |
			 TABLE | TABLES | TEMP | TEMPORARY | TERMINATED | TEXT | STRING_KW | THURSDAY |
			 TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF | TOP | TRAILING | TARGET |
			 SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM | TRIM | TRUNCATE |
			 TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED | UNCONDITIONAL |
			 UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL | UPDATE |
			 USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES |
			 VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE | WITHOUT |
			 WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | DOLLAR | IDENTIFIER |
			 BACKQUOTED_IDENTIFIER 
				=> {
					{
					/*InvokeRule type_*/
					recog.base.set_state(2863);
					recog.type_()?;

					}
				}

			 ANY 
				=> {
					{
					recog.base.set_state(2864);
					recog.base.match_token(ANY,&mut recog.err_handler)?;

					recog.base.set_state(2865);
					recog.base.match_token(TYPE,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- field ----------------
pub type FieldContextAll<'input> = FieldContext<'input>;


pub type FieldContext<'input> = BaseParserRuleContext<'input,FieldContextExt<'input>>;

#[derive(Clone)]
pub struct FieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FieldContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FieldContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_field(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_field(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_field(self);
	}
}

impl<'input> CustomRuleContext<'input> for FieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_field }
	//fn type_rule_index() -> usize where Self: Sized { RULE_field }
}
antlr_rust::tid!{FieldContextExt<'a>}

impl<'input> FieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FieldContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FieldContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FieldContextAttrs<'input> for FieldContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn field(&mut self,)
	-> Result<Rc<FieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 242, RULE_field);
        let mut _localctx: Rc<FieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(2868);
			recog.expression()?;

			recog.base.set_state(2871);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(2869);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				/*InvokeRule identifier*/
				recog.base.set_state(2870);
				recog.identifier()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- processingMode ----------------
pub type ProcessingModeContextAll<'input> = ProcessingModeContext<'input>;


pub type ProcessingModeContext<'input> = BaseParserRuleContext<'input,ProcessingModeContextExt<'input>>;

#[derive(Clone)]
pub struct ProcessingModeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ProcessingModeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ProcessingModeContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_processingMode(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_processingMode(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ProcessingModeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_processingMode(self);
	}
}

impl<'input> CustomRuleContext<'input> for ProcessingModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_processingMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_processingMode }
}
antlr_rust::tid!{ProcessingModeContextExt<'a>}

impl<'input> ProcessingModeContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProcessingModeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProcessingModeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ProcessingModeContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ProcessingModeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RUNNING
/// Returns `None` if there is no child corresponding to token RUNNING
fn RUNNING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RUNNING, 0)
}
/// Retrieves first TerminalNode corresponding to token FINAL
/// Returns `None` if there is no child corresponding to token FINAL
fn FINAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FINAL, 0)
}

}

impl<'input> ProcessingModeContextAttrs<'input> for ProcessingModeContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn processingMode(&mut self,)
	-> Result<Rc<ProcessingModeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProcessingModeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 244, RULE_processingMode);
        let mut _localctx: Rc<ProcessingModeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2873);
			_la = recog.base.input.la(1);
			if { !(_la==FINAL || _la==RUNNING) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nullTreatment ----------------
pub type NullTreatmentContextAll<'input> = NullTreatmentContext<'input>;


pub type NullTreatmentContext<'input> = BaseParserRuleContext<'input,NullTreatmentContextExt<'input>>;

#[derive(Clone)]
pub struct NullTreatmentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NullTreatmentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NullTreatmentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nullTreatment(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_nullTreatment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NullTreatmentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_nullTreatment(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullTreatmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nullTreatment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nullTreatment }
}
antlr_rust::tid!{NullTreatmentContextExt<'a>}

impl<'input> NullTreatmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NullTreatmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NullTreatmentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NullTreatmentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NullTreatmentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IGNORE
/// Returns `None` if there is no child corresponding to token IGNORE
fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token RESPECT
/// Returns `None` if there is no child corresponding to token RESPECT
fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RESPECT, 0)
}

}

impl<'input> NullTreatmentContextAttrs<'input> for NullTreatmentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nullTreatment(&mut self,)
	-> Result<Rc<NullTreatmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NullTreatmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 246, RULE_nullTreatment);
        let mut _localctx: Rc<NullTreatmentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2879);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IGNORE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2875);
					recog.base.match_token(IGNORE,&mut recog.err_handler)?;

					recog.base.set_state(2876);
					recog.base.match_token(NULLS,&mut recog.err_handler)?;

					}
				}

			 RESPECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2877);
					recog.base.match_token(RESPECT,&mut recog.err_handler)?;

					recog.base.set_state(2878);
					recog.base.match_token(NULLS,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- string ----------------
#[derive(Debug)]
pub enum StringContextAll<'input>{
	QuotedStringLiteralContext(QuotedStringLiteralContext<'input>),
	TripleQuotedStringLiteralContext(TripleQuotedStringLiteralContext<'input>),
	RawTripleQuotedStringLiteralContext(RawTripleQuotedStringLiteralContext<'input>),
	RawStringLiteralContext(RawStringLiteralContext<'input>),
Error(StringContext<'input>)
}
antlr_rust::tid!{StringContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StringContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for StringContextAll<'input>{}

impl<'input> Deref for StringContextAll<'input>{
	type Target = dyn StringContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StringContextAll::*;
		match self{
			QuotedStringLiteralContext(inner) => inner,
			TripleQuotedStringLiteralContext(inner) => inner,
			RawTripleQuotedStringLiteralContext(inner) => inner,
			RawStringLiteralContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StringContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StringContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StringContext<'input> = BaseParserRuleContext<'input,StringContextExt<'input>>;

#[derive(Clone)]
pub struct StringContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for StringContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StringContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StringContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StringContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}
antlr_rust::tid!{StringContextExt<'a>}

impl<'input> StringContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringContextAll<'input>> {
		Rc::new(
		StringContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StringContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<StringContextExt<'input>>{


}

impl<'input> StringContextAttrs<'input> for StringContext<'input>{}

pub type QuotedStringLiteralContext<'input> = BaseParserRuleContext<'input,QuotedStringLiteralContextExt<'input>>;

pub trait QuotedStringLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token QUOTED_STRING
	/// Returns `None` if there is no child corresponding to token QUOTED_STRING
	fn QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(QUOTED_STRING, 0)
	}
}

impl<'input> QuotedStringLiteralContextAttrs<'input> for QuotedStringLiteralContext<'input>{}

pub struct QuotedStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuotedStringLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for QuotedStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QuotedStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quotedStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_quotedStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QuotedStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_quotedStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuotedStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for QuotedStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for QuotedStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for QuotedStringLiteralContext<'input> {}

impl<'input> QuotedStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::QuotedStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,QuotedStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TripleQuotedStringLiteralContext<'input> = BaseParserRuleContext<'input,TripleQuotedStringLiteralContextExt<'input>>;

pub trait TripleQuotedStringLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRIPLE_QUOTED_STRING
	/// Returns `None` if there is no child corresponding to token TRIPLE_QUOTED_STRING
	fn TRIPLE_QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TRIPLE_QUOTED_STRING, 0)
	}
}

impl<'input> TripleQuotedStringLiteralContextAttrs<'input> for TripleQuotedStringLiteralContext<'input>{}

pub struct TripleQuotedStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TripleQuotedStringLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TripleQuotedStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TripleQuotedStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tripleQuotedStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_tripleQuotedStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TripleQuotedStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_tripleQuotedStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for TripleQuotedStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for TripleQuotedStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for TripleQuotedStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for TripleQuotedStringLiteralContext<'input> {}

impl<'input> TripleQuotedStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::TripleQuotedStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,TripleQuotedStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RawTripleQuotedStringLiteralContext<'input> = BaseParserRuleContext<'input,RawTripleQuotedStringLiteralContextExt<'input>>;

pub trait RawTripleQuotedStringLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RAW_TRIPLE_QUOTED_STRING
	/// Returns `None` if there is no child corresponding to token RAW_TRIPLE_QUOTED_STRING
	fn RAW_TRIPLE_QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RAW_TRIPLE_QUOTED_STRING, 0)
	}
}

impl<'input> RawTripleQuotedStringLiteralContextAttrs<'input> for RawTripleQuotedStringLiteralContext<'input>{}

pub struct RawTripleQuotedStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RawTripleQuotedStringLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RawTripleQuotedStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RawTripleQuotedStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rawTripleQuotedStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_rawTripleQuotedStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RawTripleQuotedStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rawTripleQuotedStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for RawTripleQuotedStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for RawTripleQuotedStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for RawTripleQuotedStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for RawTripleQuotedStringLiteralContext<'input> {}

impl<'input> RawTripleQuotedStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::RawTripleQuotedStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,RawTripleQuotedStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RawStringLiteralContext<'input> = BaseParserRuleContext<'input,RawStringLiteralContextExt<'input>>;

pub trait RawStringLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RAW_QUOTED_STRING
	/// Returns `None` if there is no child corresponding to token RAW_QUOTED_STRING
	fn RAW_QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RAW_QUOTED_STRING, 0)
	}
}

impl<'input> RawStringLiteralContextAttrs<'input> for RawStringLiteralContext<'input>{}

pub struct RawStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RawStringLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RawStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RawStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rawStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_rawStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RawStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rawStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for RawStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for RawStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for RawStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for RawStringLiteralContext<'input> {}

impl<'input> RawStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::RawStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,RawStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn string(&mut self,)
	-> Result<Rc<StringContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 248, RULE_string);
        let mut _localctx: Rc<StringContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2885);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 QUOTED_STRING 
				=> {
					let tmp = QuotedStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2881);
					recog.base.match_token(QUOTED_STRING,&mut recog.err_handler)?;

					}
				}

			 TRIPLE_QUOTED_STRING 
				=> {
					let tmp = TripleQuotedStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2882);
					recog.base.match_token(TRIPLE_QUOTED_STRING,&mut recog.err_handler)?;

					}
				}

			 RAW_QUOTED_STRING 
				=> {
					let tmp = RawStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2883);
					recog.base.match_token(RAW_QUOTED_STRING,&mut recog.err_handler)?;

					}
				}

			 RAW_TRIPLE_QUOTED_STRING 
				=> {
					let tmp = RawTripleQuotedStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(2884);
					recog.base.match_token(RAW_TRIPLE_QUOTED_STRING,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comparisonOperator ----------------
pub type ComparisonOperatorContextAll<'input> = ComparisonOperatorContext<'input>;


pub type ComparisonOperatorContext<'input> = BaseParserRuleContext<'input,ComparisonOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ComparisonOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ComparisonOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comparisonOperator(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_comparisonOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ComparisonOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_comparisonOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonOperator }
}
antlr_rust::tid!{ComparisonOperatorContextExt<'a>}

impl<'input> ComparisonOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComparisonOperatorContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ComparisonOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
/// Retrieves first TerminalNode corresponding to token NEQ
/// Returns `None` if there is no child corresponding to token NEQ
fn NEQ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NEQ, 0)
}
/// Retrieves first TerminalNode corresponding to token LT
/// Returns `None` if there is no child corresponding to token LT
fn LT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LT, 0)
}
/// Retrieves first TerminalNode corresponding to token LTE
/// Returns `None` if there is no child corresponding to token LTE
fn LTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LTE, 0)
}
/// Retrieves first TerminalNode corresponding to token GT
/// Returns `None` if there is no child corresponding to token GT
fn GT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GT, 0)
}
/// Retrieves first TerminalNode corresponding to token GTE
/// Returns `None` if there is no child corresponding to token GTE
fn GTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GTE, 0)
}

}

impl<'input> ComparisonOperatorContextAttrs<'input> for ComparisonOperatorContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonOperator(&mut self,)
	-> Result<Rc<ComparisonOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 250, RULE_comparisonOperator);
        let mut _localctx: Rc<ComparisonOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2887);
			_la = recog.base.input.la(1);
			if { !(((((_la - 400)) & !0x3f) == 0 && ((1usize << (_la - 400)) & ((1usize << (EQ - 400)) | (1usize << (NEQ - 400)) | (1usize << (LT - 400)) | (1usize << (LTE - 400)) | (1usize << (GT - 400)) | (1usize << (GTE - 400)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comparisonQuantifier ----------------
pub type ComparisonQuantifierContextAll<'input> = ComparisonQuantifierContext<'input>;


pub type ComparisonQuantifierContext<'input> = BaseParserRuleContext<'input,ComparisonQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for ComparisonQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ComparisonQuantifierContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comparisonQuantifier(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_comparisonQuantifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ComparisonQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_comparisonQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonQuantifier }
}
antlr_rust::tid!{ComparisonQuantifierContextExt<'a>}

impl<'input> ComparisonQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonQuantifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonQuantifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComparisonQuantifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<ComparisonQuantifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token SOME
/// Returns `None` if there is no child corresponding to token SOME
fn SOME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}

}

impl<'input> ComparisonQuantifierContextAttrs<'input> for ComparisonQuantifierContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonQuantifier(&mut self,)
	-> Result<Rc<ComparisonQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 252, RULE_comparisonQuantifier);
        let mut _localctx: Rc<ComparisonQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2889);
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==ANY || _la==SOME) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanValue ----------------
pub type BooleanValueContextAll<'input> = BooleanValueContext<'input>;


pub type BooleanValueContext<'input> = BaseParserRuleContext<'input,BooleanValueContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for BooleanValueContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BooleanValueContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_booleanValue(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_booleanValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BooleanValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_booleanValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanValue }
}
antlr_rust::tid!{BooleanValueContextExt<'a>}

impl<'input> BooleanValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BooleanValueContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<BooleanValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}

}

impl<'input> BooleanValueContextAttrs<'input> for BooleanValueContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn booleanValue(&mut self,)
	-> Result<Rc<BooleanValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BooleanValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 254, RULE_booleanValue);
        let mut _localctx: Rc<BooleanValueContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2891);
			_la = recog.base.input.la(1);
			if { !(_la==FALSE || _la==TRUE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- interval ----------------
pub type IntervalContextAll<'input> = IntervalContext<'input>;


pub type IntervalContext<'input> = BaseParserRuleContext<'input,IntervalContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalContextExt<'input>{
	pub from: Option<Rc<IntervalFieldContextAll<'input>>>,
	pub to: Option<Rc<IntervalFieldContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for IntervalContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_interval(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_interval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_interval(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_interval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_interval }
}
antlr_rust::tid!{IntervalContextExt<'a>}

impl<'input> IntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalContextExt{
				from: None, to: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<IntervalContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn intervalField_all(&self) ->  Vec<Rc<IntervalFieldContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn intervalField(&self, i: usize) -> Option<Rc<IntervalFieldContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}

}

impl<'input> IntervalContextAttrs<'input> for IntervalContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn interval(&mut self,)
	-> Result<Rc<IntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 256, RULE_interval);
        let mut _localctx: Rc<IntervalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2893);
			recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2894);
			recog.expression()?;

			/*InvokeRule intervalField*/
			recog.base.set_state(2895);
			let tmp = recog.intervalField()?;
			 cast_mut::<_,IntervalContext >(&mut _localctx).from = Some(tmp.clone());
			  

			recog.base.set_state(2898);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(386,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2896);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule intervalField*/
					recog.base.set_state(2897);
					let tmp = recog.intervalField()?;
					 cast_mut::<_,IntervalContext >(&mut _localctx).to = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalField ----------------
pub type IntervalFieldContextAll<'input> = IntervalFieldContext<'input>;


pub type IntervalFieldContext<'input> = BaseParserRuleContext<'input,IntervalFieldContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for IntervalFieldContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IntervalFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalField(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_intervalField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IntervalFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_intervalField(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalField }
}
antlr_rust::tid!{IntervalFieldContextExt<'a>}

impl<'input> IntervalFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalFieldContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<IntervalFieldContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token QUARTER
/// Returns `None` if there is no child corresponding to token QUARTER
fn QUARTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}

}

impl<'input> IntervalFieldContextAttrs<'input> for IntervalFieldContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalField(&mut self,)
	-> Result<Rc<IntervalFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 258, RULE_intervalField);
        let mut _localctx: Rc<IntervalFieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2900);
			_la = recog.base.input.la(1);
			if { !(_la==DAY || _la==HOUR || ((((_la - 205)) & !0x3f) == 0 && ((1usize << (_la - 205)) & ((1usize << (MICROSECOND - 205)) | (1usize << (MILLISECOND - 205)) | (1usize << (MINUTE - 205)) | (1usize << (MONTH - 205)))) != 0) || _la==QUARTER || _la==SECOND || _la==WEEK || _la==YEAR) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- normalForm ----------------
pub type NormalFormContextAll<'input> = NormalFormContext<'input>;


pub type NormalFormContext<'input> = BaseParserRuleContext<'input,NormalFormContextExt<'input>>;

#[derive(Clone)]
pub struct NormalFormContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NormalFormContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NormalFormContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_normalForm(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_normalForm(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NormalFormContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_normalForm(self);
	}
}

impl<'input> CustomRuleContext<'input> for NormalFormContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_normalForm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_normalForm }
}
antlr_rust::tid!{NormalFormContextExt<'a>}

impl<'input> NormalFormContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NormalFormContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NormalFormContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NormalFormContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NormalFormContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NFD
/// Returns `None` if there is no child corresponding to token NFD
fn NFD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NFD, 0)
}
/// Retrieves first TerminalNode corresponding to token NFC
/// Returns `None` if there is no child corresponding to token NFC
fn NFC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NFC, 0)
}
/// Retrieves first TerminalNode corresponding to token NFKD
/// Returns `None` if there is no child corresponding to token NFKD
fn NFKD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NFKD, 0)
}
/// Retrieves first TerminalNode corresponding to token NFKC
/// Returns `None` if there is no child corresponding to token NFKC
fn NFKC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NFKC, 0)
}

}

impl<'input> NormalFormContextAttrs<'input> for NormalFormContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn normalForm(&mut self,)
	-> Result<Rc<NormalFormContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NormalFormContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 260, RULE_normalForm);
        let mut _localctx: Rc<NormalFormContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2902);
			_la = recog.base.input.la(1);
			if { !(((((_la - 216)) & !0x3f) == 0 && ((1usize << (_la - 216)) & ((1usize << (NFC - 216)) | (1usize << (NFD - 216)) | (1usize << (NFKC - 216)) | (1usize << (NFKD - 216)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- typeIdentifier ----------------
pub type TypeIdentifierContextAll<'input> = TypeIdentifierContext<'input>;


pub type TypeIdentifierContext<'input> = BaseParserRuleContext<'input,TypeIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct TypeIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TypeIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TypeIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_typeIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_typeIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TypeIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_typeIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_typeIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_typeIdentifier }
}
antlr_rust::tid!{TypeIdentifierContextExt<'a>}

impl<'input> TypeIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TypeIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TypeIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TypeIdentifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TypeIdentifierContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TypeIdentifierContextAttrs<'input> for TypeIdentifierContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn typeIdentifier(&mut self,)
	-> Result<Rc<TypeIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TypeIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 262, RULE_typeIdentifier);
        let mut _localctx: Rc<TypeIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2904);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- type_ ----------------
#[derive(Debug)]
pub enum Type_ContextAll<'input>{
	TypeNotNullContext(TypeNotNullContext<'input>),
	TypeNullContext(TypeNullContext<'input>),
Error(Type_Context<'input>)
}
antlr_rust::tid!{Type_ContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for Type_ContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for Type_ContextAll<'input>{}

impl<'input> Deref for Type_ContextAll<'input>{
	type Target = dyn Type_ContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use Type_ContextAll::*;
		match self{
			TypeNotNullContext(inner) => inner,
			TypeNullContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for Type_ContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for Type_ContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type Type_Context<'input> = BaseParserRuleContext<'input,Type_ContextExt<'input>>;

#[derive(Clone)]
pub struct Type_ContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for Type_Context<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for Type_Context<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for Type_Context<'input>{
}

impl<'input> CustomRuleContext<'input> for Type_ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}
antlr_rust::tid!{Type_ContextExt<'a>}

impl<'input> Type_ContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Type_ContextAll<'input>> {
		Rc::new(
		Type_ContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Type_ContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait Type_ContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<Type_ContextExt<'input>>{


}

impl<'input> Type_ContextAttrs<'input> for Type_Context<'input>{}

pub type TypeNotNullContext<'input> = BaseParserRuleContext<'input,TypeNotNullContextExt<'input>>;

pub trait TypeNotNullContextAttrs<'input>: BigqueryParserContext<'input>{
	fn nonnullableType(&self) -> Option<Rc<NonnullableTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
}

impl<'input> TypeNotNullContextAttrs<'input> for TypeNotNullContext<'input>{}

pub struct TypeNotNullContextExt<'input>{
	base:Type_ContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TypeNotNullContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TypeNotNullContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TypeNotNullContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_typeNotNull(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_typeNotNull(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TypeNotNullContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_typeNotNull(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeNotNullContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for TypeNotNullContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for TypeNotNullContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for TypeNotNullContext<'input> {}

impl<'input> TypeNotNullContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::TypeNotNullContext(
				BaseParserRuleContext::copy_from(ctx,TypeNotNullContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TypeNullContext<'input> = BaseParserRuleContext<'input,TypeNullContextExt<'input>>;

pub trait TypeNullContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
}

impl<'input> TypeNullContextAttrs<'input> for TypeNullContext<'input>{}

pub struct TypeNullContextExt<'input>{
	base:Type_ContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TypeNullContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TypeNullContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TypeNullContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_typeNull(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_typeNull(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TypeNullContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_typeNull(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeNullContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for TypeNullContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for TypeNullContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for TypeNullContext<'input> {}

impl<'input> TypeNullContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::TypeNullContext(
				BaseParserRuleContext::copy_from(ctx,TypeNullContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn type_(&mut self,)
	-> Result<Rc<Type_ContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Type_ContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 264, RULE_type_);
        let mut _localctx: Rc<Type_ContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2912);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ARRAY |
			 ATTACH | AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK |
			 BZIP2 | CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT |
			 CURRENT_ROLE | CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE |
			 DATETIME | DAY | DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF |
			 DEALLOCATE | DECLARE | DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER |
			 DENY | DESCRIBE | DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED |
			 DISTSTYLE | DETACH | DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING |
			 ERROR | EVEN | EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL |
			 FIELDS | FILTER | FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS |
			 GENERATED | GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER |
			 HOUR | IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT |
			 INPUTFORMAT | INTERLEAVED | INSERT | INTERVAL | INVOKER | IO | ISOLATION |
			 ISOWEEK | ISOYEAR | ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA |
			 LANGUAGE | LEAVE | LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG |
			 LOCAL | LOCATION | LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED |
			 MATCHES | MATERIALIZED | MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND |
			 MIN | MINUS_KW | MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC |
			 NFD | NFKC | NFKD | NONE | NORMALIZE | OBJECT | OFFSET | OMIT | ONE |
			 ONLY | OPTION | OPTIONS | OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD |
			 PERMUTE | PIVOT | POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE |
			 PRIVILEGES | PROPERTIES | PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH |
			 RENAME | REPEATABLE | REPLACE | RESET | RESTRICT | RETURN | RETURNING |
			 REMOTE | REPEAT | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROW | RUNNING | SAFE | SAFE_CAST | SATURDAY | SCALAR | SECOND | SCHEMA |
			 SCHEMAS | SECURITY | SEEK | SEMI | SERDE | SERDEPROPERTIES | SERIALIZABLE |
			 SESSION | SETS | SHOW | SIMILAR | SNAPSHOT | SORTKEY | START | STATS |
			 STORED | STRUCT | SUBSET | SUBSTRING | SUNDAY | SYSTEM | SYSTEM_TIME |
			 TABLE | TABLES | TEMP | TEMPORARY | TERMINATED | TEXT | STRING_KW | THURSDAY |
			 TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF | TOP | TRAILING | TARGET |
			 SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM | TRIM | TRUNCATE |
			 TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED | UNCONDITIONAL |
			 UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL | UPDATE |
			 USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES |
			 VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE | WITHOUT |
			 WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | DOLLAR | IDENTIFIER |
			 BACKQUOTED_IDENTIFIER 
				=> {
					let tmp = TypeNotNullContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule nonnullableType*/
					recog.base.set_state(2906);
					recog.nonnullableType_rec(0)?;

					recog.base.set_state(2909);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(387,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2907);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(2908);
							recog.base.match_token(NULL,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

			 NULL 
				=> {
					let tmp = TypeNullContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2911);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonnullableType ----------------
#[derive(Debug)]
pub enum NonnullableTypeContextAll<'input>{
	IntervalTypeContext(IntervalTypeContext<'input>),
	FunctionSignatureGenericTypeContext(FunctionSignatureGenericTypeContext<'input>),
	LegacyArrayTypeContext(LegacyArrayTypeContext<'input>),
	BigqueryTypeContext(BigqueryTypeContext<'input>),
	LegacyStructTypeContext(LegacyStructTypeContext<'input>),
	PrimitiveTypeContext(PrimitiveTypeContext<'input>),
Error(NonnullableTypeContext<'input>)
}
antlr_rust::tid!{NonnullableTypeContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for NonnullableTypeContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for NonnullableTypeContextAll<'input>{}

impl<'input> Deref for NonnullableTypeContextAll<'input>{
	type Target = dyn NonnullableTypeContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use NonnullableTypeContextAll::*;
		match self{
			IntervalTypeContext(inner) => inner,
			FunctionSignatureGenericTypeContext(inner) => inner,
			LegacyArrayTypeContext(inner) => inner,
			BigqueryTypeContext(inner) => inner,
			LegacyStructTypeContext(inner) => inner,
			PrimitiveTypeContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NonnullableTypeContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NonnullableTypeContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type NonnullableTypeContext<'input> = BaseParserRuleContext<'input,NonnullableTypeContextExt<'input>>;

#[derive(Clone)]
pub struct NonnullableTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NonnullableTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NonnullableTypeContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NonnullableTypeContext<'input>{
}

impl<'input> CustomRuleContext<'input> for NonnullableTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}
antlr_rust::tid!{NonnullableTypeContextExt<'a>}

impl<'input> NonnullableTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonnullableTypeContextAll<'input>> {
		Rc::new(
		NonnullableTypeContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonnullableTypeContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait NonnullableTypeContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NonnullableTypeContextExt<'input>>{


}

impl<'input> NonnullableTypeContextAttrs<'input> for NonnullableTypeContext<'input>{}

pub type IntervalTypeContext<'input> = BaseParserRuleContext<'input,IntervalTypeContextExt<'input>>;

pub trait IntervalTypeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTERVAL
	/// Returns `None` if there is no child corresponding to token INTERVAL
	fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INTERVAL, 0)
	}
}

impl<'input> IntervalTypeContextAttrs<'input> for IntervalTypeContext<'input>{}

pub struct IntervalTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntervalTypeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for IntervalTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IntervalTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_intervalType(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_intervalType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IntervalTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_intervalType(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for IntervalTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for IntervalTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for IntervalTypeContext<'input> {}

impl<'input> IntervalTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::IntervalTypeContext(
				BaseParserRuleContext::copy_from(ctx,IntervalTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionSignatureGenericTypeContext<'input> = BaseParserRuleContext<'input,FunctionSignatureGenericTypeContextExt<'input>>;

pub trait FunctionSignatureGenericTypeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOLLAR
	/// Returns `None` if there is no child corresponding to token DOLLAR
	fn DOLLAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
}

impl<'input> FunctionSignatureGenericTypeContextAttrs<'input> for FunctionSignatureGenericTypeContext<'input>{}

pub struct FunctionSignatureGenericTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionSignatureGenericTypeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for FunctionSignatureGenericTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FunctionSignatureGenericTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionSignatureGenericType(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_functionSignatureGenericType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FunctionSignatureGenericTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_functionSignatureGenericType(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionSignatureGenericTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for FunctionSignatureGenericTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for FunctionSignatureGenericTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for FunctionSignatureGenericTypeContext<'input> {}

impl<'input> FunctionSignatureGenericTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::FunctionSignatureGenericTypeContext(
				BaseParserRuleContext::copy_from(ctx,FunctionSignatureGenericTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LegacyArrayTypeContext<'input> = BaseParserRuleContext<'input,LegacyArrayTypeContextExt<'input>>;

pub trait LegacyArrayTypeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
}

impl<'input> LegacyArrayTypeContextAttrs<'input> for LegacyArrayTypeContext<'input>{}

pub struct LegacyArrayTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LegacyArrayTypeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for LegacyArrayTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LegacyArrayTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_legacyArrayType(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_legacyArrayType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LegacyArrayTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_legacyArrayType(self);
	}
}

impl<'input> CustomRuleContext<'input> for LegacyArrayTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for LegacyArrayTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for LegacyArrayTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for LegacyArrayTypeContext<'input> {}

impl<'input> LegacyArrayTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::LegacyArrayTypeContext(
				BaseParserRuleContext::copy_from(ctx,LegacyArrayTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigqueryTypeContext<'input> = BaseParserRuleContext<'input,BigqueryTypeContextExt<'input>>;

pub trait BigqueryTypeContextAttrs<'input>: BigqueryParserContext<'input>{
	fn nonnullableType(&self) -> Option<Rc<NonnullableTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COLLATE
	/// Returns `None` if there is no child corresponding to token COLLATE
	fn COLLATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COLLATE, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> BigqueryTypeContextAttrs<'input> for BigqueryTypeContext<'input>{}

pub struct BigqueryTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigqueryTypeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BigqueryTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BigqueryTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigqueryType(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_bigqueryType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BigqueryTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_bigqueryType(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigqueryTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for BigqueryTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for BigqueryTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for BigqueryTypeContext<'input> {}

impl<'input> BigqueryTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::BigqueryTypeContext(
				BaseParserRuleContext::copy_from(ctx,BigqueryTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LegacyStructTypeContext<'input> = BaseParserRuleContext<'input,LegacyStructTypeContextExt<'input>>;

pub trait LegacyStructTypeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STRUCT
	/// Returns `None` if there is no child corresponding to token STRUCT
	fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(STRUCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	fn rowField_all(&self) ->  Vec<Rc<RowFieldContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowField(&self, i: usize) -> Option<Rc<RowFieldContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> LegacyStructTypeContextAttrs<'input> for LegacyStructTypeContext<'input>{}

pub struct LegacyStructTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LegacyStructTypeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for LegacyStructTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LegacyStructTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_legacyStructType(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_legacyStructType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LegacyStructTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_legacyStructType(self);
	}
}

impl<'input> CustomRuleContext<'input> for LegacyStructTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for LegacyStructTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for LegacyStructTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for LegacyStructTypeContext<'input> {}

impl<'input> LegacyStructTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::LegacyStructTypeContext(
				BaseParserRuleContext::copy_from(ctx,LegacyStructTypeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrimitiveTypeContext<'input> = BaseParserRuleContext<'input,PrimitiveTypeContextExt<'input>>;

pub trait PrimitiveTypeContextAttrs<'input>: BigqueryParserContext<'input>{
	fn typeIdentifier(&self) -> Option<Rc<TypeIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn typeParameter_all(&self) ->  Vec<Rc<TypeParameterContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn typeParameter(&self, i: usize) -> Option<Rc<TypeParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PrimitiveTypeContextAttrs<'input> for PrimitiveTypeContext<'input>{}

pub struct PrimitiveTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrimitiveTypeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PrimitiveTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PrimitiveTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_primitiveType(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_primitiveType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PrimitiveTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_primitiveType(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrimitiveTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for PrimitiveTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for PrimitiveTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for PrimitiveTypeContext<'input> {}

impl<'input> PrimitiveTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::PrimitiveTypeContext(
				BaseParserRuleContext::copy_from(ctx,PrimitiveTypeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  nonnullableType(&mut self,)
	-> Result<Rc<NonnullableTypeContextAll<'input>>,ANTLRError> {
		self.nonnullableType_rec(0)
	}

	fn nonnullableType_rec(&mut self, _p: isize)
	-> Result<Rc<NonnullableTypeContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = NonnullableTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 266, RULE_nonnullableType, _p);
	    let mut _localctx: Rc<NonnullableTypeContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 266;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2955);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DOLLAR 
				=> {
					{
					let mut tmp = FunctionSignatureGenericTypeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					recog.base.set_state(2915);
					recog.base.match_token(DOLLAR,&mut recog.err_handler)?;

					recog.base.set_state(2916);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}

			 ARRAY 
				=> {
					{
					let mut tmp = LegacyArrayTypeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2917);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(2918);
					recog.base.match_token(LT,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(2919);
					recog.type_()?;

					recog.base.set_state(2920);
					recog.base.match_token(GT,&mut recog.err_handler)?;

					}
				}

			 STRUCT 
				=> {
					{
					let mut tmp = LegacyStructTypeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2922);
					recog.base.match_token(STRUCT,&mut recog.err_handler)?;

					recog.base.set_state(2923);
					recog.base.match_token(LT,&mut recog.err_handler)?;

					/*InvokeRule rowField*/
					recog.base.set_state(2924);
					recog.rowField()?;

					recog.base.set_state(2929);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(389,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2925);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule rowField*/
							recog.base.set_state(2926);
							recog.rowField()?;

							}
							} 
						}
						recog.base.set_state(2931);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(389,&mut recog.base)?;
					}
					recog.base.set_state(2933);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2932);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let NonnullableTypeContextAll::LegacyStructTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2935);
					recog.base.match_token(GT,&mut recog.err_handler)?;

					}
				}

			 INTERVAL 
				=> {
					{
					let mut tmp = IntervalTypeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2937);
					recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

					}
				}

			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ATTACH |
			 AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK | BZIP2 |
			 CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE | CATALOGS |
			 CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL | CONNECT |
			 CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT | CURRENT_ROLE |
			 CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE | DATETIME | DAY |
			 DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF | DEALLOCATE | DECLARE |
			 DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESCRIBE |
			 DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH |
			 DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING | ERROR | EVEN |
			 EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL | FIELDS | FILTER |
			 FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS | GENERATED |
			 GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER | HOUR |
			 IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT |
			 INTERLEAVED | INSERT | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR |
			 ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE |
			 LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION |
			 LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION | OPTIONS |
			 OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS | PASSING |
			 PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE | PIVOT |
			 POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES | PROPERTIES |
			 PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME | REPEATABLE |
			 REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE | REPEAT | RETURNS |
			 REVOKE | RLS | ROLE | ROLES | ROLLBACK | ROW | RUNNING | SAFE | SAFE_CAST |
			 SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS | SECURITY | SEEK | SEMI |
			 SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION | SETS | SHOW | SIMILAR |
			 SNAPSHOT | SORTKEY | START | STATS | STORED | SUBSET | SUBSTRING | SUNDAY |
			 SYSTEM | SYSTEM_TIME | TABLE | TABLES | TEMP | TEMPORARY | TERMINATED |
			 TEXT | STRING_KW | THURSDAY | TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF |
			 TOP | TRAILING | TARGET | SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM |
			 TRIM | TRUNCATE | TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED |
			 UNCONDITIONAL | UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL |
			 UPDATE | USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE |
			 VALUES | VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE |
			 WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | IDENTIFIER |
			 BACKQUOTED_IDENTIFIER 
				=> {
					{
					let mut tmp = PrimitiveTypeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule typeIdentifier*/
					recog.base.set_state(2938);
					recog.typeIdentifier()?;

					recog.base.set_state(2953);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(393,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2939);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule typeParameter*/
							recog.base.set_state(2940);
							recog.typeParameter()?;

							recog.base.set_state(2945);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(391,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2941);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule typeParameter*/
									recog.base.set_state(2942);
									recog.typeParameter()?;

									}
									} 
								}
								recog.base.set_state(2947);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(391,&mut recog.base)?;
							}
							recog.base.set_state(2949);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2948);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let NonnullableTypeContextAll::PrimitiveTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							recog.base.set_state(2951);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2962);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(395,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					{
					/*recRuleLabeledAltStartAction*/
					let mut tmp = BigqueryTypeContextExt::new(&**NonnullableTypeContextExt::new(_parentctx.clone(), _parentState));
					recog.push_new_recursion_context(tmp.clone(), _startState, RULE_nonnullableType);
					_localctx = tmp;
					recog.base.set_state(2957);
					if !({recog.precpred(None, 2)}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
					}
					recog.base.set_state(2958);
					recog.base.match_token(COLLATE,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(2959);
					recog.string()?;

					}
					} 
				}
				recog.base.set_state(2964);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(395,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- rowField ----------------
pub type RowFieldContextAll<'input> = RowFieldContext<'input>;


pub type RowFieldContext<'input> = BaseParserRuleContext<'input,RowFieldContextExt<'input>>;

#[derive(Clone)]
pub struct RowFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for RowFieldContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RowFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowField(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_rowField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RowFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rowField(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowField }
}
antlr_rust::tid!{RowFieldContextExt<'a>}

impl<'input> RowFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowFieldContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<RowFieldContextExt<'input>>{

fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RowFieldContextAttrs<'input> for RowFieldContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowField(&mut self,)
	-> Result<Rc<RowFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 268, RULE_rowField);
        let mut _localctx: Rc<RowFieldContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2969);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(396,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule type_*/
					recog.base.set_state(2965);
					recog.type_()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2966);
					recog.identifier()?;

					/*InvokeRule type_*/
					recog.base.set_state(2967);
					recog.type_()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- typeParameter ----------------
pub type TypeParameterContextAll<'input> = TypeParameterContext<'input>;


pub type TypeParameterContext<'input> = BaseParserRuleContext<'input,TypeParameterContextExt<'input>>;

#[derive(Clone)]
pub struct TypeParameterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TypeParameterContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TypeParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_typeParameter(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_typeParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TypeParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_typeParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_typeParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_typeParameter }
}
antlr_rust::tid!{TypeParameterContextExt<'a>}

impl<'input> TypeParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TypeParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TypeParameterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TypeParameterContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TypeParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TypeParameterContextAttrs<'input> for TypeParameterContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn typeParameter(&mut self,)
	-> Result<Rc<TypeParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TypeParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 270, RULE_typeParameter);
        let mut _localctx: Rc<TypeParameterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2973);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INTEGER_VALUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2971);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}

			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ARRAY |
			 ATTACH | AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK |
			 BZIP2 | CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE |
			 CATALOGS | CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN |
			 COLUMNS | COMMENT | COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL |
			 CONNECT | CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT |
			 CURRENT_ROLE | CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE |
			 DATETIME | DAY | DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF |
			 DEALLOCATE | DECLARE | DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER |
			 DENY | DESCRIBE | DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED |
			 DISTSTYLE | DETACH | DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING |
			 ERROR | EVEN | EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL |
			 FIELDS | FILTER | FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS |
			 GENERATED | GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER |
			 HOUR | IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT |
			 INPUTFORMAT | INTERLEAVED | INSERT | INTERVAL | INVOKER | IO | ISOLATION |
			 ISOWEEK | ISOYEAR | ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA |
			 LANGUAGE | LEAVE | LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG |
			 LOCAL | LOCATION | LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED |
			 MATCHES | MATERIALIZED | MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND |
			 MIN | MINUS_KW | MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC |
			 NFD | NFKC | NFKD | NONE | NORMALIZE | NULL | OBJECT | OFFSET | OMIT |
			 ONE | ONLY | OPTION | OPTIONS | OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED |
			 PARTITIONS | PASSING | PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD |
			 PERMUTE | PIVOT | POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE |
			 PRIVILEGES | PROPERTIES | PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH |
			 RENAME | REPEATABLE | REPLACE | RESET | RESTRICT | RETURN | RETURNING |
			 REMOTE | REPEAT | RETURNS | REVOKE | RLS | ROLE | ROLES | ROLLBACK |
			 ROW | RUNNING | SAFE | SAFE_CAST | SATURDAY | SCALAR | SECOND | SCHEMA |
			 SCHEMAS | SECURITY | SEEK | SEMI | SERDE | SERDEPROPERTIES | SERIALIZABLE |
			 SESSION | SETS | SHOW | SIMILAR | SNAPSHOT | SORTKEY | START | STATS |
			 STORED | STRUCT | SUBSET | SUBSTRING | SUNDAY | SYSTEM | SYSTEM_TIME |
			 TABLE | TABLES | TEMP | TEMPORARY | TERMINATED | TEXT | STRING_KW | THURSDAY |
			 TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF | TOP | TRAILING | TARGET |
			 SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM | TRIM | TRUNCATE |
			 TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED | UNCONDITIONAL |
			 UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL | UPDATE |
			 USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE | VALUES |
			 VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE | WITHOUT |
			 WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | DOLLAR | IDENTIFIER |
			 BACKQUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule type_*/
					recog.base.set_state(2972);
					recog.type_()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenClause ----------------
pub type WhenClauseContextAll<'input> = WhenClauseContext<'input>;


pub type WhenClauseContext<'input> = BaseParserRuleContext<'input,WhenClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhenClauseContextExt<'input>{
	pub condition: Option<Rc<ExpressionContextAll<'input>>>,
	pub result: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for WhenClauseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for WhenClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenClause(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_whenClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for WhenClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_whenClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhenClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenClause }
}
antlr_rust::tid!{WhenClauseContextExt<'a>}

impl<'input> WhenClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenClauseContextExt{
				condition: None, result: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenClauseContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<WhenClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> WhenClauseContextAttrs<'input> for WhenClauseContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenClause(&mut self,)
	-> Result<Rc<WhenClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 272, RULE_whenClause);
        let mut _localctx: Rc<WhenClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2975);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2976);
			let tmp = recog.expression()?;
			 cast_mut::<_,WhenClauseContext >(&mut _localctx).condition = Some(tmp.clone());
			  

			recog.base.set_state(2977);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2978);
			let tmp = recog.expression()?;
			 cast_mut::<_,WhenClauseContext >(&mut _localctx).result = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- filter ----------------
pub type FilterContextAll<'input> = FilterContext<'input>;


pub type FilterContext<'input> = BaseParserRuleContext<'input,FilterContextExt<'input>>;

#[derive(Clone)]
pub struct FilterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FilterContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FilterContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_filter(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_filter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FilterContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_filter(self);
	}
}

impl<'input> CustomRuleContext<'input> for FilterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_filter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_filter }
}
antlr_rust::tid!{FilterContextExt<'a>}

impl<'input> FilterContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FilterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FilterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FilterContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FilterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> FilterContextAttrs<'input> for FilterContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn filter(&mut self,)
	-> Result<Rc<FilterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FilterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 274, RULE_filter);
        let mut _localctx: Rc<FilterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2980);
			recog.base.match_token(FILTER,&mut recog.err_handler)?;

			recog.base.set_state(2981);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2982);
			recog.base.match_token(WHERE,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(2983);
			recog.booleanExpression_rec(0)?;

			recog.base.set_state(2984);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mergeCase ----------------
#[derive(Debug)]
pub enum MergeCaseContextAll<'input>{
	MergeCaseMatchedContext(MergeCaseMatchedContext<'input>),
	MergeCaseNotMatchedContext(MergeCaseNotMatchedContext<'input>),
	MergeCaseNotMatchedBySourceContext(MergeCaseNotMatchedBySourceContext<'input>),
Error(MergeCaseContext<'input>)
}
antlr_rust::tid!{MergeCaseContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for MergeCaseContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for MergeCaseContextAll<'input>{}

impl<'input> Deref for MergeCaseContextAll<'input>{
	type Target = dyn MergeCaseContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use MergeCaseContextAll::*;
		match self{
			MergeCaseMatchedContext(inner) => inner,
			MergeCaseNotMatchedContext(inner) => inner,
			MergeCaseNotMatchedBySourceContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MergeCaseContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MergeCaseContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type MergeCaseContext<'input> = BaseParserRuleContext<'input,MergeCaseContextExt<'input>>;

#[derive(Clone)]
pub struct MergeCaseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for MergeCaseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MergeCaseContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MergeCaseContext<'input>{
}

impl<'input> CustomRuleContext<'input> for MergeCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mergeCase }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mergeCase }
}
antlr_rust::tid!{MergeCaseContextExt<'a>}

impl<'input> MergeCaseContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MergeCaseContextAll<'input>> {
		Rc::new(
		MergeCaseContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MergeCaseContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait MergeCaseContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<MergeCaseContextExt<'input>>{


}

impl<'input> MergeCaseContextAttrs<'input> for MergeCaseContext<'input>{}

pub type MergeCaseMatchedContext<'input> = BaseParserRuleContext<'input,MergeCaseMatchedContextExt<'input>>;

pub trait MergeCaseMatchedContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token WHEN
	/// Returns `None` if there is no child corresponding to token WHEN
	fn WHEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WHEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATCHED
	/// Returns `None` if there is no child corresponding to token MATCHED
	fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MATCHED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token THEN
	/// Returns `None` if there is no child corresponding to token THEN
	fn THEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(THEN, 0)
	}
	fn mergeUpdateClause(&self) -> Option<Rc<MergeUpdateClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DELETE
	/// Returns `None` if there is no child corresponding to token DELETE
	fn DELETE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DELETE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MergeCaseMatchedContextAttrs<'input> for MergeCaseMatchedContext<'input>{}

pub struct MergeCaseMatchedContextExt<'input>{
	base:MergeCaseContextExt<'input>,
	pub condition: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MergeCaseMatchedContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for MergeCaseMatchedContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MergeCaseMatchedContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_mergeCaseMatched(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_mergeCaseMatched(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MergeCaseMatchedContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_mergeCaseMatched(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeCaseMatchedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mergeCase }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mergeCase }
}

impl<'input> Borrow<MergeCaseContextExt<'input>> for MergeCaseMatchedContext<'input>{
	fn borrow(&self) -> &MergeCaseContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<MergeCaseContextExt<'input>> for MergeCaseMatchedContext<'input>{
	fn borrow_mut(&mut self) -> &mut MergeCaseContextExt<'input> { &mut self.base }
}

impl<'input> MergeCaseContextAttrs<'input> for MergeCaseMatchedContext<'input> {}

impl<'input> MergeCaseMatchedContextExt<'input>{
	fn new(ctx: &dyn MergeCaseContextAttrs<'input>) -> Rc<MergeCaseContextAll<'input>>  {
		Rc::new(
			MergeCaseContextAll::MergeCaseMatchedContext(
				BaseParserRuleContext::copy_from(ctx,MergeCaseMatchedContextExt{
        			condition:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MergeCaseNotMatchedContext<'input> = BaseParserRuleContext<'input,MergeCaseNotMatchedContextExt<'input>>;

pub trait MergeCaseNotMatchedContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token WHEN
	/// Returns `None` if there is no child corresponding to token WHEN
	fn WHEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WHEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATCHED
	/// Returns `None` if there is no child corresponding to token MATCHED
	fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MATCHED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token THEN
	/// Returns `None` if there is no child corresponding to token THEN
	fn THEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(THEN, 0)
	}
	fn mergeInsertClause(&self) -> Option<Rc<MergeInsertClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DELETE
	/// Returns `None` if there is no child corresponding to token DELETE
	fn DELETE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DELETE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TARGET
	/// Returns `None` if there is no child corresponding to token TARGET
	fn TARGET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(TARGET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MergeCaseNotMatchedContextAttrs<'input> for MergeCaseNotMatchedContext<'input>{}

pub struct MergeCaseNotMatchedContextExt<'input>{
	base:MergeCaseContextExt<'input>,
	pub condition: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MergeCaseNotMatchedContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for MergeCaseNotMatchedContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MergeCaseNotMatchedContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_mergeCaseNotMatched(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_mergeCaseNotMatched(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MergeCaseNotMatchedContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_mergeCaseNotMatched(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeCaseNotMatchedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mergeCase }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mergeCase }
}

impl<'input> Borrow<MergeCaseContextExt<'input>> for MergeCaseNotMatchedContext<'input>{
	fn borrow(&self) -> &MergeCaseContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<MergeCaseContextExt<'input>> for MergeCaseNotMatchedContext<'input>{
	fn borrow_mut(&mut self) -> &mut MergeCaseContextExt<'input> { &mut self.base }
}

impl<'input> MergeCaseContextAttrs<'input> for MergeCaseNotMatchedContext<'input> {}

impl<'input> MergeCaseNotMatchedContextExt<'input>{
	fn new(ctx: &dyn MergeCaseContextAttrs<'input>) -> Rc<MergeCaseContextAll<'input>>  {
		Rc::new(
			MergeCaseContextAll::MergeCaseNotMatchedContext(
				BaseParserRuleContext::copy_from(ctx,MergeCaseNotMatchedContextExt{
        			condition:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MergeCaseNotMatchedBySourceContext<'input> = BaseParserRuleContext<'input,MergeCaseNotMatchedBySourceContextExt<'input>>;

pub trait MergeCaseNotMatchedBySourceContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token WHEN
	/// Returns `None` if there is no child corresponding to token WHEN
	fn WHEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WHEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATCHED
	/// Returns `None` if there is no child corresponding to token MATCHED
	fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MATCHED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SOURCE
	/// Returns `None` if there is no child corresponding to token SOURCE
	fn SOURCE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SOURCE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token THEN
	/// Returns `None` if there is no child corresponding to token THEN
	fn THEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(THEN, 0)
	}
	fn mergeUpdateClause(&self) -> Option<Rc<MergeUpdateClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DELETE
	/// Returns `None` if there is no child corresponding to token DELETE
	fn DELETE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DELETE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MergeCaseNotMatchedBySourceContextAttrs<'input> for MergeCaseNotMatchedBySourceContext<'input>{}

pub struct MergeCaseNotMatchedBySourceContextExt<'input>{
	base:MergeCaseContextExt<'input>,
	pub condition: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MergeCaseNotMatchedBySourceContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for MergeCaseNotMatchedBySourceContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MergeCaseNotMatchedBySourceContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_mergeCaseNotMatchedBySource(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_mergeCaseNotMatchedBySource(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MergeCaseNotMatchedBySourceContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_mergeCaseNotMatchedBySource(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeCaseNotMatchedBySourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mergeCase }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mergeCase }
}

impl<'input> Borrow<MergeCaseContextExt<'input>> for MergeCaseNotMatchedBySourceContext<'input>{
	fn borrow(&self) -> &MergeCaseContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<MergeCaseContextExt<'input>> for MergeCaseNotMatchedBySourceContext<'input>{
	fn borrow_mut(&mut self) -> &mut MergeCaseContextExt<'input> { &mut self.base }
}

impl<'input> MergeCaseContextAttrs<'input> for MergeCaseNotMatchedBySourceContext<'input> {}

impl<'input> MergeCaseNotMatchedBySourceContextExt<'input>{
	fn new(ctx: &dyn MergeCaseContextAttrs<'input>) -> Rc<MergeCaseContextAll<'input>>  {
		Rc::new(
			MergeCaseContextAll::MergeCaseNotMatchedBySourceContext(
				BaseParserRuleContext::copy_from(ctx,MergeCaseNotMatchedBySourceContextExt{
        			condition:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mergeCase(&mut self,)
	-> Result<Rc<MergeCaseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MergeCaseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 276, RULE_mergeCase);
        let mut _localctx: Rc<MergeCaseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3027);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(405,&mut recog.base)? {
				1 =>{
					let tmp = MergeCaseMatchedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2986);
					recog.base.match_token(WHEN,&mut recog.err_handler)?;

					recog.base.set_state(2987);
					recog.base.match_token(MATCHED,&mut recog.err_handler)?;

					recog.base.set_state(2990);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AND {
						{
						recog.base.set_state(2988);
						recog.base.match_token(AND,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(2989);
						let tmp = recog.booleanExpression_rec(0)?;
						if let MergeCaseContextAll::MergeCaseMatchedContext(ctx) = cast_mut::<_,MergeCaseContextAll >(&mut _localctx){
						ctx.condition = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2992);
					recog.base.match_token(THEN,&mut recog.err_handler)?;

					recog.base.set_state(2995);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 UPDATE 
						=> {
							{
							/*InvokeRule mergeUpdateClause*/
							recog.base.set_state(2993);
							recog.mergeUpdateClause()?;

							}
						}

					 DELETE 
						=> {
							{
							recog.base.set_state(2994);
							recog.base.match_token(DELETE,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}
			,
				2 =>{
					let tmp = MergeCaseNotMatchedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2997);
					recog.base.match_token(WHEN,&mut recog.err_handler)?;

					recog.base.set_state(2998);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					recog.base.set_state(2999);
					recog.base.match_token(MATCHED,&mut recog.err_handler)?;

					recog.base.set_state(3002);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BY {
						{
						recog.base.set_state(3000);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						recog.base.set_state(3001);
						recog.base.match_token(TARGET,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3006);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AND {
						{
						recog.base.set_state(3004);
						recog.base.match_token(AND,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(3005);
						let tmp = recog.booleanExpression_rec(0)?;
						if let MergeCaseContextAll::MergeCaseNotMatchedContext(ctx) = cast_mut::<_,MergeCaseContextAll >(&mut _localctx){
						ctx.condition = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3008);
					recog.base.match_token(THEN,&mut recog.err_handler)?;

					recog.base.set_state(3011);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 INSERT 
						=> {
							{
							/*InvokeRule mergeInsertClause*/
							recog.base.set_state(3009);
							recog.mergeInsertClause()?;

							}
						}

					 DELETE 
						=> {
							{
							recog.base.set_state(3010);
							recog.base.match_token(DELETE,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}
			,
				3 =>{
					let tmp = MergeCaseNotMatchedBySourceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3013);
					recog.base.match_token(WHEN,&mut recog.err_handler)?;

					recog.base.set_state(3014);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					recog.base.set_state(3015);
					recog.base.match_token(MATCHED,&mut recog.err_handler)?;

					recog.base.set_state(3016);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					recog.base.set_state(3017);
					recog.base.match_token(SOURCE,&mut recog.err_handler)?;

					recog.base.set_state(3020);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AND {
						{
						recog.base.set_state(3018);
						recog.base.match_token(AND,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(3019);
						let tmp = recog.booleanExpression_rec(0)?;
						if let MergeCaseContextAll::MergeCaseNotMatchedBySourceContext(ctx) = cast_mut::<_,MergeCaseContextAll >(&mut _localctx){
						ctx.condition = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3022);
					recog.base.match_token(THEN,&mut recog.err_handler)?;

					recog.base.set_state(3025);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 UPDATE 
						=> {
							{
							/*InvokeRule mergeUpdateClause*/
							recog.base.set_state(3023);
							recog.mergeUpdateClause()?;

							}
						}

					 DELETE 
						=> {
							{
							recog.base.set_state(3024);
							recog.base.match_token(DELETE,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mergeUpdateClause ----------------
pub type MergeUpdateClauseContextAll<'input> = MergeUpdateClauseContext<'input>;


pub type MergeUpdateClauseContext<'input> = BaseParserRuleContext<'input,MergeUpdateClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MergeUpdateClauseContextExt<'input>{
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub targets:Vec<Rc<ExpressionContextAll<'input>>>,
	pub values:Vec<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for MergeUpdateClauseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MergeUpdateClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mergeUpdateClause(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_mergeUpdateClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MergeUpdateClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_mergeUpdateClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeUpdateClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mergeUpdateClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mergeUpdateClause }
}
antlr_rust::tid!{MergeUpdateClauseContextExt<'a>}

impl<'input> MergeUpdateClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MergeUpdateClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MergeUpdateClauseContextExt{
				expression: None, 
				targets: Vec::new(), values: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MergeUpdateClauseContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<MergeUpdateClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token EQ in current rule
fn EQ_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token EQ, starting from 0.
/// Returns `None` if number of children corresponding to token EQ is less or equal than `i`.
fn EQ(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EQ, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> MergeUpdateClauseContextAttrs<'input> for MergeUpdateClauseContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mergeUpdateClause(&mut self,)
	-> Result<Rc<MergeUpdateClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MergeUpdateClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 278, RULE_mergeUpdateClause);
        let mut _localctx: Rc<MergeUpdateClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3029);
			recog.base.match_token(UPDATE,&mut recog.err_handler)?;

			recog.base.set_state(3030);
			recog.base.match_token(SET,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3031);
			let tmp = recog.expression()?;
			 cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).expression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).expression.clone().unwrap()
			 ;
			 cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).targets.push(temp);
			  
			recog.base.set_state(3032);
			recog.base.match_token(EQ,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3033);
			let tmp = recog.expression()?;
			 cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).expression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).expression.clone().unwrap()
			 ;
			 cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).values.push(temp);
			  
			recog.base.set_state(3041);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3034);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(3035);
				let tmp = recog.expression()?;
				 cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).expression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).expression.clone().unwrap()
				 ;
				 cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).targets.push(temp);
				  
				recog.base.set_state(3036);
				recog.base.match_token(EQ,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(3037);
				let tmp = recog.expression()?;
				 cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).expression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).expression.clone().unwrap()
				 ;
				 cast_mut::<_,MergeUpdateClauseContext >(&mut _localctx).values.push(temp);
				  
				}
				}
				recog.base.set_state(3043);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mergeInsertClause ----------------
pub type MergeInsertClauseContextAll<'input> = MergeInsertClauseContext<'input>;


pub type MergeInsertClauseContext<'input> = BaseParserRuleContext<'input,MergeInsertClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MergeInsertClauseContextExt<'input>{
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub targets:Vec<Rc<ExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	pub values:Vec<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for MergeInsertClauseContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MergeInsertClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mergeInsertClause(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_mergeInsertClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MergeInsertClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_mergeInsertClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeInsertClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mergeInsertClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mergeInsertClause }
}
antlr_rust::tid!{MergeInsertClauseContextExt<'a>}

impl<'input> MergeInsertClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MergeInsertClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MergeInsertClauseContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				expression: None, 
				targets: Vec::new(), values: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MergeInsertClauseContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<MergeInsertClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> MergeInsertClauseContextAttrs<'input> for MergeInsertClauseContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mergeInsertClause(&mut self,)
	-> Result<Rc<MergeInsertClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MergeInsertClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 280, RULE_mergeInsertClause);
        let mut _localctx: Rc<MergeInsertClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3044);
			recog.base.match_token(INSERT,&mut recog.err_handler)?;

			recog.base.set_state(3059);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LPAREN {
				{
				recog.base.set_state(3045);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(3046);
				let tmp = recog.expression()?;
				 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).expression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).expression.clone().unwrap()
				 ;
				 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).targets.push(temp);
				  
				recog.base.set_state(3051);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(407,&mut recog.base)?;
				while { _alt!=2 && _alt!=INVALID_ALT } {
					if _alt==1 {
						{
						{
						recog.base.set_state(3047);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(3048);
						let tmp = recog.expression()?;
						 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).expression = Some(tmp.clone());
						  

						let temp =  cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).expression.clone().unwrap()
						 ;
						 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).targets.push(temp);
						  
						}
						} 
					}
					recog.base.set_state(3053);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(407,&mut recog.base)?;
				}
				recog.base.set_state(3055);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==COMMA {
					{
					recog.base.set_state(3054);
					let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
					 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).COMMA = Some(tmp);
					  

					let temp =  cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).COMMA.clone().unwrap()
					 ;
					 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).tail.push(temp);
					  
					}
				}

				recog.base.set_state(3057);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(3061);
			recog.base.match_token(VALUES,&mut recog.err_handler)?;

			recog.base.set_state(3062);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3063);
			let tmp = recog.expression()?;
			 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).expression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).expression.clone().unwrap()
			 ;
			 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).values.push(temp);
			  
			recog.base.set_state(3068);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(410,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3064);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3065);
					let tmp = recog.expression()?;
					 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).values.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(3070);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(410,&mut recog.base)?;
			}
			recog.base.set_state(3072);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(3071);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,MergeInsertClauseContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			recog.base.set_state(3074);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- over ----------------
pub type OverContextAll<'input> = OverContext<'input>;


pub type OverContext<'input> = BaseParserRuleContext<'input,OverContextExt<'input>>;

#[derive(Clone)]
pub struct OverContextExt<'input>{
	pub windowName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for OverContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for OverContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_over(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_over(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for OverContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_over(self);
	}
}

impl<'input> CustomRuleContext<'input> for OverContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_over }
	//fn type_rule_index() -> usize where Self: Sized { RULE_over }
}
antlr_rust::tid!{OverContextExt<'a>}

impl<'input> OverContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OverContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OverContextExt{
				windowName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait OverContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<OverContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OVER
/// Returns `None` if there is no child corresponding to token OVER
fn OVER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn windowSpecification(&self) -> Option<Rc<WindowSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> OverContextAttrs<'input> for OverContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn over(&mut self,)
	-> Result<Rc<OverContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OverContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 282, RULE_over);
        let mut _localctx: Rc<OverContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3076);
			recog.base.match_token(OVER,&mut recog.err_handler)?;

			recog.base.set_state(3082);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ATTACH |
			 AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK | BZIP2 |
			 CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE | CATALOGS |
			 CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL | CONNECT |
			 CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT | CURRENT_ROLE |
			 CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE | DATETIME | DAY |
			 DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF | DEALLOCATE | DECLARE |
			 DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESCRIBE |
			 DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH |
			 DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING | ERROR | EVEN |
			 EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL | FIELDS | FILTER |
			 FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS | GENERATED |
			 GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER | HOUR |
			 IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT |
			 INTERLEAVED | INSERT | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR |
			 ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE |
			 LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION |
			 LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION | OPTIONS |
			 OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS | PASSING |
			 PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE | PIVOT |
			 POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES | PROPERTIES |
			 PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME | REPEATABLE |
			 REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE | REPEAT | RETURNS |
			 REVOKE | RLS | ROLE | ROLES | ROLLBACK | ROW | RUNNING | SAFE | SAFE_CAST |
			 SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS | SECURITY | SEEK | SEMI |
			 SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION | SETS | SHOW | SIMILAR |
			 SNAPSHOT | SORTKEY | START | STATS | STORED | SUBSET | SUBSTRING | SUNDAY |
			 SYSTEM | SYSTEM_TIME | TABLE | TABLES | TEMP | TEMPORARY | TERMINATED |
			 TEXT | STRING_KW | THURSDAY | TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF |
			 TOP | TRAILING | TARGET | SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM |
			 TRIM | TRUNCATE | TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED |
			 UNCONDITIONAL | UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL |
			 UPDATE | USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE |
			 VALUES | VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE |
			 WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD | IDENTIFIER |
			 BACKQUOTED_IDENTIFIER 
				=> {
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3077);
					let tmp = recog.identifier()?;
					 cast_mut::<_,OverContext >(&mut _localctx).windowName = Some(tmp.clone());
					  

					}
				}

			 LPAREN 
				=> {
					{
					recog.base.set_state(3078);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule windowSpecification*/
					recog.base.set_state(3079);
					recog.windowSpecification()?;

					recog.base.set_state(3080);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowFrame ----------------
pub type WindowFrameContextAll<'input> = WindowFrameContext<'input>;


pub type WindowFrameContext<'input> = BaseParserRuleContext<'input,WindowFrameContextExt<'input>>;

#[derive(Clone)]
pub struct WindowFrameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for WindowFrameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for WindowFrameContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowFrame(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_windowFrame(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for WindowFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_windowFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowFrame }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowFrame }
}
antlr_rust::tid!{WindowFrameContextExt<'a>}

impl<'input> WindowFrameContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowFrameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowFrameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowFrameContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<WindowFrameContextExt<'input>>{

fn frameExtent(&self) -> Option<Rc<FrameExtentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowFrameContextAttrs<'input> for WindowFrameContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowFrame(&mut self,)
	-> Result<Rc<WindowFrameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowFrameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 284, RULE_windowFrame);
        let mut _localctx: Rc<WindowFrameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule frameExtent*/
			recog.base.set_state(3084);
			recog.frameExtent()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- frameExtent ----------------
pub type FrameExtentContextAll<'input> = FrameExtentContext<'input>;


pub type FrameExtentContext<'input> = BaseParserRuleContext<'input,FrameExtentContextExt<'input>>;

#[derive(Clone)]
pub struct FrameExtentContextExt<'input>{
	pub frameType: Option<TokenType<'input>>,
	pub start: Option<Rc<FrameBoundContextAll<'input>>>,
	pub end: Option<Rc<FrameBoundContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FrameExtentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FrameExtentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_frameExtent(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_frameExtent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FrameExtentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_frameExtent(self);
	}
}

impl<'input> CustomRuleContext<'input> for FrameExtentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameExtent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameExtent }
}
antlr_rust::tid!{FrameExtentContextExt<'a>}

impl<'input> FrameExtentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FrameExtentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FrameExtentContextExt{
				frameType: None, 
				start: None, end: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FrameExtentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FrameExtentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
fn frameBound_all(&self) ->  Vec<Rc<FrameBoundContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn frameBound(&self, i: usize) -> Option<Rc<FrameBoundContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPS
/// Returns `None` if there is no child corresponding to token GROUPS
fn GROUPS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GROUPS, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}

}

impl<'input> FrameExtentContextAttrs<'input> for FrameExtentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn frameExtent(&mut self,)
	-> Result<Rc<FrameExtentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FrameExtentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 286, RULE_frameExtent);
        let mut _localctx: Rc<FrameExtentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3110);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(413,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3086);
					let tmp = recog.base.match_token(RANGE,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(3087);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3088);
					let tmp = recog.base.match_token(ROWS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(3089);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3090);
					let tmp = recog.base.match_token(GROUPS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(3091);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3092);
					let tmp = recog.base.match_token(RANGE,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					recog.base.set_state(3093);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3094);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(3095);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3096);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3098);
					let tmp = recog.base.match_token(ROWS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					recog.base.set_state(3099);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3100);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(3101);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3102);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(3104);
					let tmp = recog.base.match_token(GROUPS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					recog.base.set_state(3105);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3106);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(3107);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3108);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- frameBound ----------------
#[derive(Debug)]
pub enum FrameBoundContextAll<'input>{
	BoundedFrameContext(BoundedFrameContext<'input>),
	UnboundedFrameContext(UnboundedFrameContext<'input>),
	CurrentRowBoundContext(CurrentRowBoundContext<'input>),
Error(FrameBoundContext<'input>)
}
antlr_rust::tid!{FrameBoundContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for FrameBoundContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for FrameBoundContextAll<'input>{}

impl<'input> Deref for FrameBoundContextAll<'input>{
	type Target = dyn FrameBoundContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use FrameBoundContextAll::*;
		match self{
			BoundedFrameContext(inner) => inner,
			UnboundedFrameContext(inner) => inner,
			CurrentRowBoundContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FrameBoundContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FrameBoundContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type FrameBoundContext<'input> = BaseParserRuleContext<'input,FrameBoundContextExt<'input>>;

#[derive(Clone)]
pub struct FrameBoundContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for FrameBoundContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for FrameBoundContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for FrameBoundContext<'input>{
}

impl<'input> CustomRuleContext<'input> for FrameBoundContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}
antlr_rust::tid!{FrameBoundContextExt<'a>}

impl<'input> FrameBoundContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FrameBoundContextAll<'input>> {
		Rc::new(
		FrameBoundContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FrameBoundContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait FrameBoundContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<FrameBoundContextExt<'input>>{


}

impl<'input> FrameBoundContextAttrs<'input> for FrameBoundContext<'input>{}

pub type BoundedFrameContext<'input> = BaseParserRuleContext<'input,BoundedFrameContextExt<'input>>;

pub trait BoundedFrameContextAttrs<'input>: BigqueryParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECEDING
	/// Returns `None` if there is no child corresponding to token PRECEDING
	fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PRECEDING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOLLOWING
	/// Returns `None` if there is no child corresponding to token FOLLOWING
	fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FOLLOWING, 0)
	}
}

impl<'input> BoundedFrameContextAttrs<'input> for BoundedFrameContext<'input>{}

pub struct BoundedFrameContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	pub boundType: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BoundedFrameContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BoundedFrameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BoundedFrameContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_boundedFrame(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_boundedFrame(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BoundedFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_boundedFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for BoundedFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for BoundedFrameContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for BoundedFrameContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for BoundedFrameContext<'input> {}

impl<'input> BoundedFrameContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::BoundedFrameContext(
				BaseParserRuleContext::copy_from(ctx,BoundedFrameContextExt{
					boundType:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnboundedFrameContext<'input> = BaseParserRuleContext<'input,UnboundedFrameContextExt<'input>>;

pub trait UnboundedFrameContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNBOUNDED
	/// Returns `None` if there is no child corresponding to token UNBOUNDED
	fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(UNBOUNDED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECEDING
	/// Returns `None` if there is no child corresponding to token PRECEDING
	fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PRECEDING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOLLOWING
	/// Returns `None` if there is no child corresponding to token FOLLOWING
	fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(FOLLOWING, 0)
	}
}

impl<'input> UnboundedFrameContextAttrs<'input> for UnboundedFrameContext<'input>{}

pub struct UnboundedFrameContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	pub boundType: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnboundedFrameContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UnboundedFrameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnboundedFrameContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unboundedFrame(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_unboundedFrame(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnboundedFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unboundedFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnboundedFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for UnboundedFrameContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for UnboundedFrameContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for UnboundedFrameContext<'input> {}

impl<'input> UnboundedFrameContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::UnboundedFrameContext(
				BaseParserRuleContext::copy_from(ctx,UnboundedFrameContextExt{
					boundType:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CurrentRowBoundContext<'input> = BaseParserRuleContext<'input,CurrentRowBoundContextExt<'input>>;

pub trait CurrentRowBoundContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CURRENT
	/// Returns `None` if there is no child corresponding to token CURRENT
	fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(CURRENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
}

impl<'input> CurrentRowBoundContextAttrs<'input> for CurrentRowBoundContext<'input>{}

pub struct CurrentRowBoundContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CurrentRowBoundContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for CurrentRowBoundContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for CurrentRowBoundContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_currentRowBound(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_currentRowBound(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for CurrentRowBoundContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_currentRowBound(self);
	}
}

impl<'input> CustomRuleContext<'input> for CurrentRowBoundContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for CurrentRowBoundContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for CurrentRowBoundContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for CurrentRowBoundContext<'input> {}

impl<'input> CurrentRowBoundContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::CurrentRowBoundContext(
				BaseParserRuleContext::copy_from(ctx,CurrentRowBoundContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn frameBound(&mut self,)
	-> Result<Rc<FrameBoundContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FrameBoundContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 288, RULE_frameBound);
        let mut _localctx: Rc<FrameBoundContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3121);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(414,&mut recog.base)? {
				1 =>{
					let tmp = UnboundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3112);
					recog.base.match_token(UNBOUNDED,&mut recog.err_handler)?;

					recog.base.set_state(3113);
					let tmp = recog.base.match_token(PRECEDING,&mut recog.err_handler)?;
					if let FrameBoundContextAll::UnboundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = UnboundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3114);
					recog.base.match_token(UNBOUNDED,&mut recog.err_handler)?;

					recog.base.set_state(3115);
					let tmp = recog.base.match_token(FOLLOWING,&mut recog.err_handler)?;
					if let FrameBoundContextAll::UnboundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
				}
			,
				3 =>{
					let tmp = CurrentRowBoundContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3116);
					recog.base.match_token(CURRENT,&mut recog.err_handler)?;

					recog.base.set_state(3117);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = BoundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(3118);
					recog.expression()?;

					recog.base.set_state(3119);
					if let FrameBoundContextAll::BoundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==FOLLOWING || _la==PRECEDING) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let FrameBoundContextAll::BoundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
						ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowPattern ----------------
#[derive(Debug)]
pub enum RowPatternContextAll<'input>{
	QuantifiedPrimaryContext(QuantifiedPrimaryContext<'input>),
	PatternConcatenationContext(PatternConcatenationContext<'input>),
	PatternAlternationContext(PatternAlternationContext<'input>),
Error(RowPatternContext<'input>)
}
antlr_rust::tid!{RowPatternContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RowPatternContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for RowPatternContextAll<'input>{}

impl<'input> Deref for RowPatternContextAll<'input>{
	type Target = dyn RowPatternContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RowPatternContextAll::*;
		match self{
			QuantifiedPrimaryContext(inner) => inner,
			PatternConcatenationContext(inner) => inner,
			PatternAlternationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RowPatternContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RowPatternContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RowPatternContext<'input> = BaseParserRuleContext<'input,RowPatternContextExt<'input>>;

#[derive(Clone)]
pub struct RowPatternContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for RowPatternContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RowPatternContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RowPatternContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RowPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowPattern }
}
antlr_rust::tid!{RowPatternContextExt<'a>}

impl<'input> RowPatternContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowPatternContextAll<'input>> {
		Rc::new(
		RowPatternContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowPatternContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RowPatternContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<RowPatternContextExt<'input>>{


}

impl<'input> RowPatternContextAttrs<'input> for RowPatternContext<'input>{}

pub type QuantifiedPrimaryContext<'input> = BaseParserRuleContext<'input,QuantifiedPrimaryContextExt<'input>>;

pub trait QuantifiedPrimaryContextAttrs<'input>: BigqueryParserContext<'input>{
	fn patternPrimary(&self) -> Option<Rc<PatternPrimaryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn patternQuantifier(&self) -> Option<Rc<PatternQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QuantifiedPrimaryContextAttrs<'input> for QuantifiedPrimaryContext<'input>{}

pub struct QuantifiedPrimaryContextExt<'input>{
	base:RowPatternContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuantifiedPrimaryContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for QuantifiedPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QuantifiedPrimaryContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quantifiedPrimary(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_quantifiedPrimary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QuantifiedPrimaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_quantifiedPrimary(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuantifiedPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowPattern }
}

impl<'input> Borrow<RowPatternContextExt<'input>> for QuantifiedPrimaryContext<'input>{
	fn borrow(&self) -> &RowPatternContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowPatternContextExt<'input>> for QuantifiedPrimaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowPatternContextExt<'input> { &mut self.base }
}

impl<'input> RowPatternContextAttrs<'input> for QuantifiedPrimaryContext<'input> {}

impl<'input> QuantifiedPrimaryContextExt<'input>{
	fn new(ctx: &dyn RowPatternContextAttrs<'input>) -> Rc<RowPatternContextAll<'input>>  {
		Rc::new(
			RowPatternContextAll::QuantifiedPrimaryContext(
				BaseParserRuleContext::copy_from(ctx,QuantifiedPrimaryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PatternConcatenationContext<'input> = BaseParserRuleContext<'input,PatternConcatenationContextExt<'input>>;

pub trait PatternConcatenationContextAttrs<'input>: BigqueryParserContext<'input>{
	fn rowPattern_all(&self) ->  Vec<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowPattern(&self, i: usize) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> PatternConcatenationContextAttrs<'input> for PatternConcatenationContext<'input>{}

pub struct PatternConcatenationContextExt<'input>{
	base:RowPatternContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PatternConcatenationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PatternConcatenationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PatternConcatenationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_patternConcatenation(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_patternConcatenation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PatternConcatenationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_patternConcatenation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PatternConcatenationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowPattern }
}

impl<'input> Borrow<RowPatternContextExt<'input>> for PatternConcatenationContext<'input>{
	fn borrow(&self) -> &RowPatternContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowPatternContextExt<'input>> for PatternConcatenationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowPatternContextExt<'input> { &mut self.base }
}

impl<'input> RowPatternContextAttrs<'input> for PatternConcatenationContext<'input> {}

impl<'input> PatternConcatenationContextExt<'input>{
	fn new(ctx: &dyn RowPatternContextAttrs<'input>) -> Rc<RowPatternContextAll<'input>>  {
		Rc::new(
			RowPatternContextAll::PatternConcatenationContext(
				BaseParserRuleContext::copy_from(ctx,PatternConcatenationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PatternAlternationContext<'input> = BaseParserRuleContext<'input,PatternAlternationContextExt<'input>>;

pub trait PatternAlternationContextAttrs<'input>: BigqueryParserContext<'input>{
	fn rowPattern_all(&self) ->  Vec<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowPattern(&self, i: usize) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_OR
	/// Returns `None` if there is no child corresponding to token BITWISE_OR
	fn BITWISE_OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_OR, 0)
	}
}

impl<'input> PatternAlternationContextAttrs<'input> for PatternAlternationContext<'input>{}

pub struct PatternAlternationContextExt<'input>{
	base:RowPatternContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PatternAlternationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PatternAlternationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PatternAlternationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_patternAlternation(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_patternAlternation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PatternAlternationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_patternAlternation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PatternAlternationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowPattern }
}

impl<'input> Borrow<RowPatternContextExt<'input>> for PatternAlternationContext<'input>{
	fn borrow(&self) -> &RowPatternContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowPatternContextExt<'input>> for PatternAlternationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowPatternContextExt<'input> { &mut self.base }
}

impl<'input> RowPatternContextAttrs<'input> for PatternAlternationContext<'input> {}

impl<'input> PatternAlternationContextExt<'input>{
	fn new(ctx: &dyn RowPatternContextAttrs<'input>) -> Rc<RowPatternContextAll<'input>>  {
		Rc::new(
			RowPatternContextAll::PatternAlternationContext(
				BaseParserRuleContext::copy_from(ctx,PatternAlternationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  rowPattern(&mut self,)
	-> Result<Rc<RowPatternContextAll<'input>>,ANTLRError> {
		self.rowPattern_rec(0)
	}

	fn rowPattern_rec(&mut self, _p: isize)
	-> Result<Rc<RowPatternContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = RowPatternContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 290, RULE_rowPattern, _p);
	    let mut _localctx: Rc<RowPatternContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 290;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			{
			let mut tmp = QuantifiedPrimaryContextExt::new(&**_localctx);
			recog.ctx = Some(tmp.clone());
			_localctx = tmp;
			_prevctx = _localctx.clone();


			/*InvokeRule patternPrimary*/
			recog.base.set_state(3124);
			recog.patternPrimary()?;

			recog.base.set_state(3126);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(415,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule patternQuantifier*/
					recog.base.set_state(3125);
					recog.patternQuantifier()?;

					}
				}

				_ => {}
			}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(3135);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(417,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(3133);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(416,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = PatternConcatenationContextExt::new(&**RowPatternContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_rowPattern);
							_localctx = tmp;
							recog.base.set_state(3128);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							/*InvokeRule rowPattern*/
							recog.base.set_state(3129);
							recog.rowPattern_rec(3)?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = PatternAlternationContextExt::new(&**RowPatternContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_rowPattern);
							_localctx = tmp;
							recog.base.set_state(3130);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(3131);
							recog.base.match_token(BITWISE_OR,&mut recog.err_handler)?;

							/*InvokeRule rowPattern*/
							recog.base.set_state(3132);
							recog.rowPattern_rec(2)?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(3137);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(417,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- patternPrimary ----------------
#[derive(Debug)]
pub enum PatternPrimaryContextAll<'input>{
	PatternPermutationContext(PatternPermutationContext<'input>),
	PartitionEndAnchorContext(PartitionEndAnchorContext<'input>),
	PatternVariableContext(PatternVariableContext<'input>),
	ExcludedPatternContext(ExcludedPatternContext<'input>),
	PartitionStartAnchorContext(PartitionStartAnchorContext<'input>),
	EmptyPatternContext(EmptyPatternContext<'input>),
	GroupedPatternContext(GroupedPatternContext<'input>),
Error(PatternPrimaryContext<'input>)
}
antlr_rust::tid!{PatternPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PatternPrimaryContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PatternPrimaryContextAll<'input>{}

impl<'input> Deref for PatternPrimaryContextAll<'input>{
	type Target = dyn PatternPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PatternPrimaryContextAll::*;
		match self{
			PatternPermutationContext(inner) => inner,
			PartitionEndAnchorContext(inner) => inner,
			PatternVariableContext(inner) => inner,
			ExcludedPatternContext(inner) => inner,
			PartitionStartAnchorContext(inner) => inner,
			EmptyPatternContext(inner) => inner,
			GroupedPatternContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PatternPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PatternPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PatternPrimaryContext<'input> = BaseParserRuleContext<'input,PatternPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct PatternPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PatternPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PatternPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PatternPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PatternPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}
antlr_rust::tid!{PatternPrimaryContextExt<'a>}

impl<'input> PatternPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PatternPrimaryContextAll<'input>> {
		Rc::new(
		PatternPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PatternPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PatternPrimaryContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PatternPrimaryContextExt<'input>>{


}

impl<'input> PatternPrimaryContextAttrs<'input> for PatternPrimaryContext<'input>{}

pub type PatternPermutationContext<'input> = BaseParserRuleContext<'input,PatternPermutationContextExt<'input>>;

pub trait PatternPermutationContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PERMUTE
	/// Returns `None` if there is no child corresponding to token PERMUTE
	fn PERMUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PERMUTE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn rowPattern_all(&self) ->  Vec<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowPattern(&self, i: usize) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PatternPermutationContextAttrs<'input> for PatternPermutationContext<'input>{}

pub struct PatternPermutationContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PatternPermutationContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PatternPermutationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PatternPermutationContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_patternPermutation(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_patternPermutation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PatternPermutationContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_patternPermutation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PatternPermutationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for PatternPermutationContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for PatternPermutationContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for PatternPermutationContext<'input> {}

impl<'input> PatternPermutationContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::PatternPermutationContext(
				BaseParserRuleContext::copy_from(ctx,PatternPermutationContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PartitionEndAnchorContext<'input> = BaseParserRuleContext<'input,PartitionEndAnchorContextExt<'input>>;

pub trait PartitionEndAnchorContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOLLAR
	/// Returns `None` if there is no child corresponding to token DOLLAR
	fn DOLLAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR, 0)
	}
}

impl<'input> PartitionEndAnchorContextAttrs<'input> for PartitionEndAnchorContext<'input>{}

pub struct PartitionEndAnchorContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PartitionEndAnchorContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PartitionEndAnchorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PartitionEndAnchorContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_partitionEndAnchor(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_partitionEndAnchor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PartitionEndAnchorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_partitionEndAnchor(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionEndAnchorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for PartitionEndAnchorContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for PartitionEndAnchorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for PartitionEndAnchorContext<'input> {}

impl<'input> PartitionEndAnchorContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::PartitionEndAnchorContext(
				BaseParserRuleContext::copy_from(ctx,PartitionEndAnchorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PatternVariableContext<'input> = BaseParserRuleContext<'input,PatternVariableContextExt<'input>>;

pub trait PatternVariableContextAttrs<'input>: BigqueryParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PatternVariableContextAttrs<'input> for PatternVariableContext<'input>{}

pub struct PatternVariableContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PatternVariableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PatternVariableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PatternVariableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_patternVariable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_patternVariable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PatternVariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_patternVariable(self);
	}
}

impl<'input> CustomRuleContext<'input> for PatternVariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for PatternVariableContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for PatternVariableContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for PatternVariableContext<'input> {}

impl<'input> PatternVariableContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::PatternVariableContext(
				BaseParserRuleContext::copy_from(ctx,PatternVariableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExcludedPatternContext<'input> = BaseParserRuleContext<'input,ExcludedPatternContextExt<'input>>;

pub trait ExcludedPatternContextAttrs<'input>: BigqueryParserContext<'input>{
	fn rowPattern(&self) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExcludedPatternContextAttrs<'input> for ExcludedPatternContext<'input>{}

pub struct ExcludedPatternContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExcludedPatternContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ExcludedPatternContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ExcludedPatternContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_excludedPattern(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_excludedPattern(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ExcludedPatternContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_excludedPattern(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExcludedPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for ExcludedPatternContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for ExcludedPatternContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for ExcludedPatternContext<'input> {}

impl<'input> ExcludedPatternContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::ExcludedPatternContext(
				BaseParserRuleContext::copy_from(ctx,ExcludedPatternContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PartitionStartAnchorContext<'input> = BaseParserRuleContext<'input,PartitionStartAnchorContextExt<'input>>;

pub trait PartitionStartAnchorContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BITWISE_XOR
	/// Returns `None` if there is no child corresponding to token BITWISE_XOR
	fn BITWISE_XOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_XOR, 0)
	}
}

impl<'input> PartitionStartAnchorContextAttrs<'input> for PartitionStartAnchorContext<'input>{}

pub struct PartitionStartAnchorContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PartitionStartAnchorContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for PartitionStartAnchorContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PartitionStartAnchorContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_partitionStartAnchor(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_partitionStartAnchor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PartitionStartAnchorContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_partitionStartAnchor(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionStartAnchorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for PartitionStartAnchorContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for PartitionStartAnchorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for PartitionStartAnchorContext<'input> {}

impl<'input> PartitionStartAnchorContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::PartitionStartAnchorContext(
				BaseParserRuleContext::copy_from(ctx,PartitionStartAnchorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type EmptyPatternContext<'input> = BaseParserRuleContext<'input,EmptyPatternContextExt<'input>>;

pub trait EmptyPatternContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> EmptyPatternContextAttrs<'input> for EmptyPatternContext<'input>{}

pub struct EmptyPatternContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{EmptyPatternContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for EmptyPatternContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for EmptyPatternContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_emptyPattern(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_emptyPattern(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for EmptyPatternContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_emptyPattern(self);
	}
}

impl<'input> CustomRuleContext<'input> for EmptyPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for EmptyPatternContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for EmptyPatternContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for EmptyPatternContext<'input> {}

impl<'input> EmptyPatternContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::EmptyPatternContext(
				BaseParserRuleContext::copy_from(ctx,EmptyPatternContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GroupedPatternContext<'input> = BaseParserRuleContext<'input,GroupedPatternContextExt<'input>>;

pub trait GroupedPatternContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn rowPattern(&self) -> Option<Rc<RowPatternContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> GroupedPatternContextAttrs<'input> for GroupedPatternContext<'input>{}

pub struct GroupedPatternContextExt<'input>{
	base:PatternPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GroupedPatternContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for GroupedPatternContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for GroupedPatternContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_groupedPattern(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_groupedPattern(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for GroupedPatternContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_groupedPattern(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupedPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternPrimary }
}

impl<'input> Borrow<PatternPrimaryContextExt<'input>> for GroupedPatternContext<'input>{
	fn borrow(&self) -> &PatternPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternPrimaryContextExt<'input>> for GroupedPatternContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> PatternPrimaryContextAttrs<'input> for GroupedPatternContext<'input> {}

impl<'input> GroupedPatternContextExt<'input>{
	fn new(ctx: &dyn PatternPrimaryContextAttrs<'input>) -> Rc<PatternPrimaryContextAll<'input>>  {
		Rc::new(
			PatternPrimaryContextAll::GroupedPatternContext(
				BaseParserRuleContext::copy_from(ctx,GroupedPatternContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn patternPrimary(&mut self,)
	-> Result<Rc<PatternPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PatternPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 292, RULE_patternPrimary);
        let mut _localctx: Rc<PatternPrimaryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(3166);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(420,&mut recog.base)? {
				1 =>{
					let tmp = PatternVariableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3138);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					let tmp = EmptyPatternContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3139);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3140);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = PatternPermutationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3141);
					recog.base.match_token(PERMUTE,&mut recog.err_handler)?;

					recog.base.set_state(3142);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule rowPattern*/
					recog.base.set_state(3143);
					recog.rowPattern_rec(0)?;

					recog.base.set_state(3148);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(418,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(3144);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule rowPattern*/
							recog.base.set_state(3145);
							recog.rowPattern_rec(0)?;

							}
							} 
						}
						recog.base.set_state(3150);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(418,&mut recog.base)?;
					}
					recog.base.set_state(3152);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3151);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PatternPrimaryContextAll::PatternPermutationContext(ctx) = cast_mut::<_,PatternPrimaryContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3154);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = GroupedPatternContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3156);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule rowPattern*/
					recog.base.set_state(3157);
					recog.rowPattern_rec(0)?;

					recog.base.set_state(3158);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = PartitionStartAnchorContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(3160);
					recog.base.match_token(BITWISE_XOR,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					let tmp = PartitionEndAnchorContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(3161);
					recog.base.match_token(DOLLAR,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = ExcludedPatternContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(3162);
					recog.base.match_token(T__3,&mut recog.err_handler)?;

					/*InvokeRule rowPattern*/
					recog.base.set_state(3163);
					recog.rowPattern_rec(0)?;

					recog.base.set_state(3164);
					recog.base.match_token(T__4,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- patternQuantifier ----------------
#[derive(Debug)]
pub enum PatternQuantifierContextAll<'input>{
	ZeroOrMoreQuantifierContext(ZeroOrMoreQuantifierContext<'input>),
	OneOrMoreQuantifierContext(OneOrMoreQuantifierContext<'input>),
	ZeroOrOneQuantifierContext(ZeroOrOneQuantifierContext<'input>),
	RangeQuantifierContext(RangeQuantifierContext<'input>),
Error(PatternQuantifierContext<'input>)
}
antlr_rust::tid!{PatternQuantifierContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PatternQuantifierContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PatternQuantifierContextAll<'input>{}

impl<'input> Deref for PatternQuantifierContextAll<'input>{
	type Target = dyn PatternQuantifierContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PatternQuantifierContextAll::*;
		match self{
			ZeroOrMoreQuantifierContext(inner) => inner,
			OneOrMoreQuantifierContext(inner) => inner,
			ZeroOrOneQuantifierContext(inner) => inner,
			RangeQuantifierContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PatternQuantifierContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PatternQuantifierContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PatternQuantifierContext<'input> = BaseParserRuleContext<'input,PatternQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct PatternQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PatternQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PatternQuantifierContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PatternQuantifierContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PatternQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}
antlr_rust::tid!{PatternQuantifierContextExt<'a>}

impl<'input> PatternQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PatternQuantifierContextAll<'input>> {
		Rc::new(
		PatternQuantifierContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PatternQuantifierContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PatternQuantifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PatternQuantifierContextExt<'input>>{


}

impl<'input> PatternQuantifierContextAttrs<'input> for PatternQuantifierContext<'input>{}

pub type ZeroOrMoreQuantifierContext<'input> = BaseParserRuleContext<'input,ZeroOrMoreQuantifierContextExt<'input>>;

pub trait ZeroOrMoreQuantifierContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token QUESTION_MARK
	/// Returns `None` if there is no child corresponding to token QUESTION_MARK
	fn QUESTION_MARK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, 0)
	}
}

impl<'input> ZeroOrMoreQuantifierContextAttrs<'input> for ZeroOrMoreQuantifierContext<'input>{}

pub struct ZeroOrMoreQuantifierContextExt<'input>{
	base:PatternQuantifierContextExt<'input>,
	pub reluctant: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ZeroOrMoreQuantifierContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ZeroOrMoreQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ZeroOrMoreQuantifierContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_zeroOrMoreQuantifier(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_zeroOrMoreQuantifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ZeroOrMoreQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_zeroOrMoreQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for ZeroOrMoreQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}

impl<'input> Borrow<PatternQuantifierContextExt<'input>> for ZeroOrMoreQuantifierContext<'input>{
	fn borrow(&self) -> &PatternQuantifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternQuantifierContextExt<'input>> for ZeroOrMoreQuantifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternQuantifierContextExt<'input> { &mut self.base }
}

impl<'input> PatternQuantifierContextAttrs<'input> for ZeroOrMoreQuantifierContext<'input> {}

impl<'input> ZeroOrMoreQuantifierContextExt<'input>{
	fn new(ctx: &dyn PatternQuantifierContextAttrs<'input>) -> Rc<PatternQuantifierContextAll<'input>>  {
		Rc::new(
			PatternQuantifierContextAll::ZeroOrMoreQuantifierContext(
				BaseParserRuleContext::copy_from(ctx,ZeroOrMoreQuantifierContextExt{
					reluctant:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type OneOrMoreQuantifierContext<'input> = BaseParserRuleContext<'input,OneOrMoreQuantifierContextExt<'input>>;

pub trait OneOrMoreQuantifierContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token QUESTION_MARK
	/// Returns `None` if there is no child corresponding to token QUESTION_MARK
	fn QUESTION_MARK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, 0)
	}
}

impl<'input> OneOrMoreQuantifierContextAttrs<'input> for OneOrMoreQuantifierContext<'input>{}

pub struct OneOrMoreQuantifierContextExt<'input>{
	base:PatternQuantifierContextExt<'input>,
	pub reluctant: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OneOrMoreQuantifierContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for OneOrMoreQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for OneOrMoreQuantifierContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_oneOrMoreQuantifier(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_oneOrMoreQuantifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for OneOrMoreQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_oneOrMoreQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for OneOrMoreQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}

impl<'input> Borrow<PatternQuantifierContextExt<'input>> for OneOrMoreQuantifierContext<'input>{
	fn borrow(&self) -> &PatternQuantifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternQuantifierContextExt<'input>> for OneOrMoreQuantifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternQuantifierContextExt<'input> { &mut self.base }
}

impl<'input> PatternQuantifierContextAttrs<'input> for OneOrMoreQuantifierContext<'input> {}

impl<'input> OneOrMoreQuantifierContextExt<'input>{
	fn new(ctx: &dyn PatternQuantifierContextAttrs<'input>) -> Rc<PatternQuantifierContextAll<'input>>  {
		Rc::new(
			PatternQuantifierContextAll::OneOrMoreQuantifierContext(
				BaseParserRuleContext::copy_from(ctx,OneOrMoreQuantifierContextExt{
					reluctant:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ZeroOrOneQuantifierContext<'input> = BaseParserRuleContext<'input,ZeroOrOneQuantifierContextExt<'input>>;

pub trait ZeroOrOneQuantifierContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token QUESTION_MARK in current rule
	fn QUESTION_MARK_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token QUESTION_MARK, starting from 0.
	/// Returns `None` if number of children corresponding to token QUESTION_MARK is less or equal than `i`.
	fn QUESTION_MARK(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, i)
	}
}

impl<'input> ZeroOrOneQuantifierContextAttrs<'input> for ZeroOrOneQuantifierContext<'input>{}

pub struct ZeroOrOneQuantifierContextExt<'input>{
	base:PatternQuantifierContextExt<'input>,
	pub reluctant: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ZeroOrOneQuantifierContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ZeroOrOneQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ZeroOrOneQuantifierContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_zeroOrOneQuantifier(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_zeroOrOneQuantifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ZeroOrOneQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_zeroOrOneQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for ZeroOrOneQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}

impl<'input> Borrow<PatternQuantifierContextExt<'input>> for ZeroOrOneQuantifierContext<'input>{
	fn borrow(&self) -> &PatternQuantifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternQuantifierContextExt<'input>> for ZeroOrOneQuantifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternQuantifierContextExt<'input> { &mut self.base }
}

impl<'input> PatternQuantifierContextAttrs<'input> for ZeroOrOneQuantifierContext<'input> {}

impl<'input> ZeroOrOneQuantifierContextExt<'input>{
	fn new(ctx: &dyn PatternQuantifierContextAttrs<'input>) -> Rc<PatternQuantifierContextAll<'input>>  {
		Rc::new(
			PatternQuantifierContextAll::ZeroOrOneQuantifierContext(
				BaseParserRuleContext::copy_from(ctx,ZeroOrOneQuantifierContextExt{
					reluctant:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RangeQuantifierContext<'input> = BaseParserRuleContext<'input,RangeQuantifierContextExt<'input>>;

pub trait RangeQuantifierContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token INTEGER_VALUE in current rule
	fn INTEGER_VALUE_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token INTEGER_VALUE, starting from 0.
	/// Returns `None` if number of children corresponding to token INTEGER_VALUE is less or equal than `i`.
	fn INTEGER_VALUE(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, i)
	}
	/// Retrieves first TerminalNode corresponding to token QUESTION_MARK
	/// Returns `None` if there is no child corresponding to token QUESTION_MARK
	fn QUESTION_MARK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> RangeQuantifierContextAttrs<'input> for RangeQuantifierContext<'input>{}

pub struct RangeQuantifierContextExt<'input>{
	base:PatternQuantifierContextExt<'input>,
	pub exactly: Option<TokenType<'input>>,
	pub reluctant: Option<TokenType<'input>>,
	pub atLeast: Option<TokenType<'input>>,
	pub atMost: Option<TokenType<'input>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RangeQuantifierContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RangeQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RangeQuantifierContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rangeQuantifier(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_rangeQuantifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RangeQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rangeQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for RangeQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_patternQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_patternQuantifier }
}

impl<'input> Borrow<PatternQuantifierContextExt<'input>> for RangeQuantifierContext<'input>{
	fn borrow(&self) -> &PatternQuantifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PatternQuantifierContextExt<'input>> for RangeQuantifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut PatternQuantifierContextExt<'input> { &mut self.base }
}

impl<'input> PatternQuantifierContextAttrs<'input> for RangeQuantifierContext<'input> {}

impl<'input> RangeQuantifierContextExt<'input>{
	fn new(ctx: &dyn PatternQuantifierContextAttrs<'input>) -> Rc<PatternQuantifierContextAll<'input>>  {
		Rc::new(
			PatternQuantifierContextAll::RangeQuantifierContext(
				BaseParserRuleContext::copy_from(ctx,RangeQuantifierContextExt{
					exactly:None, reluctant:None, atLeast:None, atMost:None, tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn patternQuantifier(&mut self,)
	-> Result<Rc<PatternQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PatternQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 294, RULE_patternQuantifier);
        let mut _localctx: Rc<PatternQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3201);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(429,&mut recog.base)? {
				1 =>{
					let tmp = ZeroOrMoreQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3168);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(3170);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(421,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3169);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::ZeroOrMoreQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = OneOrMoreQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3172);
					recog.base.match_token(PLUS,&mut recog.err_handler)?;

					recog.base.set_state(3174);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(422,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3173);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::OneOrMoreQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				3 =>{
					let tmp = ZeroOrOneQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3176);
					recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;

					recog.base.set_state(3178);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(423,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3177);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::ZeroOrOneQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				4 =>{
					let tmp = RangeQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3180);
					recog.base.match_token(T__5,&mut recog.err_handler)?;

					recog.base.set_state(3181);
					let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
					if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
					ctx.exactly = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(3182);
					recog.base.match_token(T__6,&mut recog.err_handler)?;

					recog.base.set_state(3184);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(424,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3183);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				5 =>{
					let tmp = RangeQuantifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(3186);
					recog.base.match_token(T__5,&mut recog.err_handler)?;

					recog.base.set_state(3188);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INTEGER_VALUE {
						{
						recog.base.set_state(3187);
						let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
						if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
						ctx.atLeast = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3190);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					recog.base.set_state(3192);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INTEGER_VALUE {
						{
						recog.base.set_state(3191);
						let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
						if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
						ctx.atMost = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3195);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3194);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3197);
					recog.base.match_token(T__6,&mut recog.err_handler)?;

					recog.base.set_state(3199);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(428,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3198);
							let tmp = recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;
							if let PatternQuantifierContextAll::RangeQuantifierContext(ctx) = cast_mut::<_,PatternQuantifierContextAll >(&mut _localctx){
							ctx.reluctant = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transactionMode ----------------
#[derive(Debug)]
pub enum TransactionModeContextAll<'input>{
	TransactionAccessModeContext(TransactionAccessModeContext<'input>),
	IsolationLevelContext(IsolationLevelContext<'input>),
Error(TransactionModeContext<'input>)
}
antlr_rust::tid!{TransactionModeContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TransactionModeContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for TransactionModeContextAll<'input>{}

impl<'input> Deref for TransactionModeContextAll<'input>{
	type Target = dyn TransactionModeContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TransactionModeContextAll::*;
		match self{
			TransactionAccessModeContext(inner) => inner,
			IsolationLevelContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TransactionModeContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TransactionModeContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TransactionModeContext<'input> = BaseParserRuleContext<'input,TransactionModeContextExt<'input>>;

#[derive(Clone)]
pub struct TransactionModeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for TransactionModeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TransactionModeContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TransactionModeContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TransactionModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transactionMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transactionMode }
}
antlr_rust::tid!{TransactionModeContextExt<'a>}

impl<'input> TransactionModeContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransactionModeContextAll<'input>> {
		Rc::new(
		TransactionModeContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransactionModeContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TransactionModeContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<TransactionModeContextExt<'input>>{


}

impl<'input> TransactionModeContextAttrs<'input> for TransactionModeContext<'input>{}

pub type TransactionAccessModeContext<'input> = BaseParserRuleContext<'input,TransactionAccessModeContextExt<'input>>;

pub trait TransactionAccessModeContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token READ
	/// Returns `None` if there is no child corresponding to token READ
	fn READ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(READ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ONLY
	/// Returns `None` if there is no child corresponding to token ONLY
	fn ONLY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ONLY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WRITE
	/// Returns `None` if there is no child corresponding to token WRITE
	fn WRITE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(WRITE, 0)
	}
}

impl<'input> TransactionAccessModeContextAttrs<'input> for TransactionAccessModeContext<'input>{}

pub struct TransactionAccessModeContextExt<'input>{
	base:TransactionModeContextExt<'input>,
	pub accessMode: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TransactionAccessModeContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for TransactionAccessModeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for TransactionAccessModeContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_transactionAccessMode(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_transactionAccessMode(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for TransactionAccessModeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_transactionAccessMode(self);
	}
}

impl<'input> CustomRuleContext<'input> for TransactionAccessModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transactionMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transactionMode }
}

impl<'input> Borrow<TransactionModeContextExt<'input>> for TransactionAccessModeContext<'input>{
	fn borrow(&self) -> &TransactionModeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TransactionModeContextExt<'input>> for TransactionAccessModeContext<'input>{
	fn borrow_mut(&mut self) -> &mut TransactionModeContextExt<'input> { &mut self.base }
}

impl<'input> TransactionModeContextAttrs<'input> for TransactionAccessModeContext<'input> {}

impl<'input> TransactionAccessModeContextExt<'input>{
	fn new(ctx: &dyn TransactionModeContextAttrs<'input>) -> Rc<TransactionModeContextAll<'input>>  {
		Rc::new(
			TransactionModeContextAll::TransactionAccessModeContext(
				BaseParserRuleContext::copy_from(ctx,TransactionAccessModeContextExt{
					accessMode:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IsolationLevelContext<'input> = BaseParserRuleContext<'input,IsolationLevelContextExt<'input>>;

pub trait IsolationLevelContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ISOLATION
	/// Returns `None` if there is no child corresponding to token ISOLATION
	fn ISOLATION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ISOLATION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEVEL
	/// Returns `None` if there is no child corresponding to token LEVEL
	fn LEVEL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(LEVEL, 0)
	}
	fn levelOfIsolation(&self) -> Option<Rc<LevelOfIsolationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IsolationLevelContextAttrs<'input> for IsolationLevelContext<'input>{}

pub struct IsolationLevelContextExt<'input>{
	base:TransactionModeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IsolationLevelContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for IsolationLevelContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IsolationLevelContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_isolationLevel(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_isolationLevel(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IsolationLevelContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_isolationLevel(self);
	}
}

impl<'input> CustomRuleContext<'input> for IsolationLevelContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transactionMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transactionMode }
}

impl<'input> Borrow<TransactionModeContextExt<'input>> for IsolationLevelContext<'input>{
	fn borrow(&self) -> &TransactionModeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TransactionModeContextExt<'input>> for IsolationLevelContext<'input>{
	fn borrow_mut(&mut self) -> &mut TransactionModeContextExt<'input> { &mut self.base }
}

impl<'input> TransactionModeContextAttrs<'input> for IsolationLevelContext<'input> {}

impl<'input> IsolationLevelContextExt<'input>{
	fn new(ctx: &dyn TransactionModeContextAttrs<'input>) -> Rc<TransactionModeContextAll<'input>>  {
		Rc::new(
			TransactionModeContextAll::IsolationLevelContext(
				BaseParserRuleContext::copy_from(ctx,IsolationLevelContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transactionMode(&mut self,)
	-> Result<Rc<TransactionModeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransactionModeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 296, RULE_transactionMode);
        let mut _localctx: Rc<TransactionModeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3208);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ISOLATION 
				=> {
					let tmp = IsolationLevelContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3203);
					recog.base.match_token(ISOLATION,&mut recog.err_handler)?;

					recog.base.set_state(3204);
					recog.base.match_token(LEVEL,&mut recog.err_handler)?;

					/*InvokeRule levelOfIsolation*/
					recog.base.set_state(3205);
					recog.levelOfIsolation()?;

					}
				}

			 READ 
				=> {
					let tmp = TransactionAccessModeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3206);
					recog.base.match_token(READ,&mut recog.err_handler)?;

					recog.base.set_state(3207);
					if let TransactionModeContextAll::TransactionAccessModeContext(ctx) = cast_mut::<_,TransactionModeContextAll >(&mut _localctx){
					ctx.accessMode = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==ONLY || _la==WRITE) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let TransactionModeContextAll::TransactionAccessModeContext(ctx) = cast_mut::<_,TransactionModeContextAll >(&mut _localctx){
						ctx.accessMode = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- levelOfIsolation ----------------
#[derive(Debug)]
pub enum LevelOfIsolationContextAll<'input>{
	ReadUncommittedContext(ReadUncommittedContext<'input>),
	SerializableContext(SerializableContext<'input>),
	ReadCommittedContext(ReadCommittedContext<'input>),
	RepeatableReadContext(RepeatableReadContext<'input>),
Error(LevelOfIsolationContext<'input>)
}
antlr_rust::tid!{LevelOfIsolationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for LevelOfIsolationContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for LevelOfIsolationContextAll<'input>{}

impl<'input> Deref for LevelOfIsolationContextAll<'input>{
	type Target = dyn LevelOfIsolationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use LevelOfIsolationContextAll::*;
		match self{
			ReadUncommittedContext(inner) => inner,
			SerializableContext(inner) => inner,
			ReadCommittedContext(inner) => inner,
			RepeatableReadContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LevelOfIsolationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LevelOfIsolationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type LevelOfIsolationContext<'input> = BaseParserRuleContext<'input,LevelOfIsolationContextExt<'input>>;

#[derive(Clone)]
pub struct LevelOfIsolationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for LevelOfIsolationContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for LevelOfIsolationContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for LevelOfIsolationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for LevelOfIsolationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}
antlr_rust::tid!{LevelOfIsolationContextExt<'a>}

impl<'input> LevelOfIsolationContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LevelOfIsolationContextAll<'input>> {
		Rc::new(
		LevelOfIsolationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LevelOfIsolationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait LevelOfIsolationContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<LevelOfIsolationContextExt<'input>>{


}

impl<'input> LevelOfIsolationContextAttrs<'input> for LevelOfIsolationContext<'input>{}

pub type ReadUncommittedContext<'input> = BaseParserRuleContext<'input,ReadUncommittedContextExt<'input>>;

pub trait ReadUncommittedContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token READ
	/// Returns `None` if there is no child corresponding to token READ
	fn READ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(READ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UNCOMMITTED
	/// Returns `None` if there is no child corresponding to token UNCOMMITTED
	fn UNCOMMITTED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(UNCOMMITTED, 0)
	}
}

impl<'input> ReadUncommittedContextAttrs<'input> for ReadUncommittedContext<'input>{}

pub struct ReadUncommittedContextExt<'input>{
	base:LevelOfIsolationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ReadUncommittedContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ReadUncommittedContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ReadUncommittedContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_readUncommitted(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_readUncommitted(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ReadUncommittedContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_readUncommitted(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReadUncommittedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}

impl<'input> Borrow<LevelOfIsolationContextExt<'input>> for ReadUncommittedContext<'input>{
	fn borrow(&self) -> &LevelOfIsolationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LevelOfIsolationContextExt<'input>> for ReadUncommittedContext<'input>{
	fn borrow_mut(&mut self) -> &mut LevelOfIsolationContextExt<'input> { &mut self.base }
}

impl<'input> LevelOfIsolationContextAttrs<'input> for ReadUncommittedContext<'input> {}

impl<'input> ReadUncommittedContextExt<'input>{
	fn new(ctx: &dyn LevelOfIsolationContextAttrs<'input>) -> Rc<LevelOfIsolationContextAll<'input>>  {
		Rc::new(
			LevelOfIsolationContextAll::ReadUncommittedContext(
				BaseParserRuleContext::copy_from(ctx,ReadUncommittedContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SerializableContext<'input> = BaseParserRuleContext<'input,SerializableContextExt<'input>>;

pub trait SerializableContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SERIALIZABLE
	/// Returns `None` if there is no child corresponding to token SERIALIZABLE
	fn SERIALIZABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(SERIALIZABLE, 0)
	}
}

impl<'input> SerializableContextAttrs<'input> for SerializableContext<'input>{}

pub struct SerializableContextExt<'input>{
	base:LevelOfIsolationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SerializableContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for SerializableContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for SerializableContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_serializable(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_serializable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for SerializableContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_serializable(self);
	}
}

impl<'input> CustomRuleContext<'input> for SerializableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}

impl<'input> Borrow<LevelOfIsolationContextExt<'input>> for SerializableContext<'input>{
	fn borrow(&self) -> &LevelOfIsolationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LevelOfIsolationContextExt<'input>> for SerializableContext<'input>{
	fn borrow_mut(&mut self) -> &mut LevelOfIsolationContextExt<'input> { &mut self.base }
}

impl<'input> LevelOfIsolationContextAttrs<'input> for SerializableContext<'input> {}

impl<'input> SerializableContextExt<'input>{
	fn new(ctx: &dyn LevelOfIsolationContextAttrs<'input>) -> Rc<LevelOfIsolationContextAll<'input>>  {
		Rc::new(
			LevelOfIsolationContextAll::SerializableContext(
				BaseParserRuleContext::copy_from(ctx,SerializableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ReadCommittedContext<'input> = BaseParserRuleContext<'input,ReadCommittedContextExt<'input>>;

pub trait ReadCommittedContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token READ
	/// Returns `None` if there is no child corresponding to token READ
	fn READ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(READ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMITTED
	/// Returns `None` if there is no child corresponding to token COMMITTED
	fn COMMITTED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(COMMITTED, 0)
	}
}

impl<'input> ReadCommittedContextAttrs<'input> for ReadCommittedContext<'input>{}

pub struct ReadCommittedContextExt<'input>{
	base:LevelOfIsolationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ReadCommittedContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for ReadCommittedContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for ReadCommittedContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_readCommitted(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_readCommitted(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for ReadCommittedContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_readCommitted(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReadCommittedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}

impl<'input> Borrow<LevelOfIsolationContextExt<'input>> for ReadCommittedContext<'input>{
	fn borrow(&self) -> &LevelOfIsolationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LevelOfIsolationContextExt<'input>> for ReadCommittedContext<'input>{
	fn borrow_mut(&mut self) -> &mut LevelOfIsolationContextExt<'input> { &mut self.base }
}

impl<'input> LevelOfIsolationContextAttrs<'input> for ReadCommittedContext<'input> {}

impl<'input> ReadCommittedContextExt<'input>{
	fn new(ctx: &dyn LevelOfIsolationContextAttrs<'input>) -> Rc<LevelOfIsolationContextAll<'input>>  {
		Rc::new(
			LevelOfIsolationContextAll::ReadCommittedContext(
				BaseParserRuleContext::copy_from(ctx,ReadCommittedContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RepeatableReadContext<'input> = BaseParserRuleContext<'input,RepeatableReadContextExt<'input>>;

pub trait RepeatableReadContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REPEATABLE
	/// Returns `None` if there is no child corresponding to token REPEATABLE
	fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(REPEATABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token READ
	/// Returns `None` if there is no child corresponding to token READ
	fn READ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(READ, 0)
	}
}

impl<'input> RepeatableReadContextAttrs<'input> for RepeatableReadContext<'input>{}

pub struct RepeatableReadContextExt<'input>{
	base:LevelOfIsolationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RepeatableReadContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RepeatableReadContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RepeatableReadContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_repeatableRead(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_repeatableRead(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RepeatableReadContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_repeatableRead(self);
	}
}

impl<'input> CustomRuleContext<'input> for RepeatableReadContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}

impl<'input> Borrow<LevelOfIsolationContextExt<'input>> for RepeatableReadContext<'input>{
	fn borrow(&self) -> &LevelOfIsolationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LevelOfIsolationContextExt<'input>> for RepeatableReadContext<'input>{
	fn borrow_mut(&mut self) -> &mut LevelOfIsolationContextExt<'input> { &mut self.base }
}

impl<'input> LevelOfIsolationContextAttrs<'input> for RepeatableReadContext<'input> {}

impl<'input> RepeatableReadContextExt<'input>{
	fn new(ctx: &dyn LevelOfIsolationContextAttrs<'input>) -> Rc<LevelOfIsolationContextAll<'input>>  {
		Rc::new(
			LevelOfIsolationContextAll::RepeatableReadContext(
				BaseParserRuleContext::copy_from(ctx,RepeatableReadContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn levelOfIsolation(&mut self,)
	-> Result<Rc<LevelOfIsolationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LevelOfIsolationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 298, RULE_levelOfIsolation);
        let mut _localctx: Rc<LevelOfIsolationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3217);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(431,&mut recog.base)? {
				1 =>{
					let tmp = ReadUncommittedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3210);
					recog.base.match_token(READ,&mut recog.err_handler)?;

					recog.base.set_state(3211);
					recog.base.match_token(UNCOMMITTED,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = ReadCommittedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3212);
					recog.base.match_token(READ,&mut recog.err_handler)?;

					recog.base.set_state(3213);
					recog.base.match_token(COMMITTED,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = RepeatableReadContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3214);
					recog.base.match_token(REPEATABLE,&mut recog.err_handler)?;

					recog.base.set_state(3215);
					recog.base.match_token(READ,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = SerializableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3216);
					recog.base.match_token(SERIALIZABLE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privilege ----------------
pub type PrivilegeContextAll<'input> = PrivilegeContext<'input>;


pub type PrivilegeContext<'input> = BaseParserRuleContext<'input,PrivilegeContextExt<'input>>;

#[derive(Clone)]
pub struct PrivilegeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PrivilegeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PrivilegeContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privilege(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_privilege(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PrivilegeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_privilege(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrivilegeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privilege }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privilege }
}
antlr_rust::tid!{PrivilegeContextExt<'a>}

impl<'input> PrivilegeContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivilegeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivilegeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivilegeContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PrivilegeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}

}

impl<'input> PrivilegeContextAttrs<'input> for PrivilegeContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privilege(&mut self,)
	-> Result<Rc<PrivilegeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivilegeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 300, RULE_privilege);
        let mut _localctx: Rc<PrivilegeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3219);
			_la = recog.base.input.la(1);
			if { !(_la==CREATE || _la==DELETE || _la==INSERT || _la==SELECT || _la==UPDATE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- qualifiedName ----------------
#[derive(Debug)]
pub enum QualifiedNameContextAll<'input>{
	QualifiedNameDefaultContext(QualifiedNameDefaultContext<'input>),
Error(QualifiedNameContext<'input>)
}
antlr_rust::tid!{QualifiedNameContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QualifiedNameContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for QualifiedNameContextAll<'input>{}

impl<'input> Deref for QualifiedNameContextAll<'input>{
	type Target = dyn QualifiedNameContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QualifiedNameContextAll::*;
		match self{
			QualifiedNameDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QualifiedNameContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QualifiedNameContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QualifiedNameContext<'input> = BaseParserRuleContext<'input,QualifiedNameContextExt<'input>>;

#[derive(Clone)]
pub struct QualifiedNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QualifiedNameContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QualifiedNameContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QualifiedNameContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QualifiedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedName }
}
antlr_rust::tid!{QualifiedNameContextExt<'a>}

impl<'input> QualifiedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QualifiedNameContextAll<'input>> {
		Rc::new(
		QualifiedNameContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QualifiedNameContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QualifiedNameContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QualifiedNameContextExt<'input>>{


}

impl<'input> QualifiedNameContextAttrs<'input> for QualifiedNameContext<'input>{}

pub type QualifiedNameDefaultContext<'input> = BaseParserRuleContext<'input,QualifiedNameDefaultContextExt<'input>>;

pub trait QualifiedNameDefaultContextAttrs<'input>: BigqueryParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
	fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
	/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
	fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DOT, i)
	}
	fn pathComponent_all(&self) ->  Vec<Rc<PathComponentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn pathComponent(&self, i: usize) -> Option<Rc<PathComponentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> QualifiedNameDefaultContextAttrs<'input> for QualifiedNameDefaultContext<'input>{}

pub struct QualifiedNameDefaultContextExt<'input>{
	base:QualifiedNameContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QualifiedNameDefaultContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for QualifiedNameDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QualifiedNameDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_qualifiedNameDefault(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_qualifiedNameDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QualifiedNameDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_qualifiedNameDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QualifiedNameDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedName }
}

impl<'input> Borrow<QualifiedNameContextExt<'input>> for QualifiedNameDefaultContext<'input>{
	fn borrow(&self) -> &QualifiedNameContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QualifiedNameContextExt<'input>> for QualifiedNameDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QualifiedNameContextExt<'input> { &mut self.base }
}

impl<'input> QualifiedNameContextAttrs<'input> for QualifiedNameDefaultContext<'input> {}

impl<'input> QualifiedNameDefaultContextExt<'input>{
	fn new(ctx: &dyn QualifiedNameContextAttrs<'input>) -> Rc<QualifiedNameContextAll<'input>>  {
		Rc::new(
			QualifiedNameContextAll::QualifiedNameDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QualifiedNameDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn qualifiedName(&mut self,)
	-> Result<Rc<QualifiedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QualifiedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 302, RULE_qualifiedName);
        let mut _localctx: Rc<QualifiedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = QualifiedNameDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3221);
			recog.identifier()?;

			recog.base.set_state(3226);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(432,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3222);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule pathComponent*/
					recog.base.set_state(3223);
					recog.pathComponent()?;

					}
					} 
				}
				recog.base.set_state(3228);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(432,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pathExpression ----------------
pub type PathExpressionContextAll<'input> = PathExpressionContext<'input>;


pub type PathExpressionContext<'input> = BaseParserRuleContext<'input,PathExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PathExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PathExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PathExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pathExpression(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_pathExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PathExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pathExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for PathExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pathExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pathExpression }
}
antlr_rust::tid!{PathExpressionContextExt<'a>}

impl<'input> PathExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PathExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PathExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PathExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PathExpressionContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PathExpressionContextAttrs<'input> for PathExpressionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pathExpression(&mut self,)
	-> Result<Rc<PathExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PathExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 304, RULE_pathExpression);
        let mut _localctx: Rc<PathExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(3229);
			recog.qualifiedName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonquotedIdentifier ----------------
pub type NonquotedIdentifierContextAll<'input> = NonquotedIdentifierContext<'input>;


pub type NonquotedIdentifierContext<'input> = BaseParserRuleContext<'input,NonquotedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct NonquotedIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NonquotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NonquotedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonquotedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_nonquotedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NonquotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_nonquotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for NonquotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonquotedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonquotedIdentifier }
}
antlr_rust::tid!{NonquotedIdentifierContextExt<'a>}

impl<'input> NonquotedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonquotedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonquotedIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NonquotedIdentifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NonquotedIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}
fn nonReserved(&self) -> Option<Rc<NonReservedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NonquotedIdentifierContextAttrs<'input> for NonquotedIdentifierContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonquotedIdentifier(&mut self,)
	-> Result<Rc<NonquotedIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonquotedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 306, RULE_nonquotedIdentifier);
        let mut _localctx: Rc<NonquotedIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3233);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3231);
					recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;

					}
				}

			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ATTACH |
			 AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK | BZIP2 |
			 CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE | CATALOGS |
			 CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL | CONNECT |
			 CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT | CURRENT_ROLE |
			 CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE | DATETIME | DAY |
			 DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF | DEALLOCATE | DECLARE |
			 DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESCRIBE |
			 DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH |
			 DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING | ERROR | EVEN |
			 EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL | FIELDS | FILTER |
			 FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS | GENERATED |
			 GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER | HOUR |
			 IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT |
			 INTERLEAVED | INSERT | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR |
			 ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE |
			 LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION |
			 LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION | OPTIONS |
			 OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS | PASSING |
			 PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE | PIVOT |
			 POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES | PROPERTIES |
			 PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME | REPEATABLE |
			 REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE | REPEAT | RETURNS |
			 REVOKE | RLS | ROLE | ROLES | ROLLBACK | ROW | RUNNING | SAFE | SAFE_CAST |
			 SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS | SECURITY | SEEK | SEMI |
			 SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION | SETS | SHOW | SIMILAR |
			 SNAPSHOT | SORTKEY | START | STATS | STORED | SUBSET | SUBSTRING | SUNDAY |
			 SYSTEM | SYSTEM_TIME | TABLE | TABLES | TEMP | TEMPORARY | TERMINATED |
			 TEXT | STRING_KW | THURSDAY | TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF |
			 TOP | TRAILING | TARGET | SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM |
			 TRIM | TRUNCATE | TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED |
			 UNCONDITIONAL | UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL |
			 UPDATE | USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE |
			 VALUES | VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE |
			 WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule nonReserved*/
					recog.base.set_state(3232);
					recog.nonReserved()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dashedIdentifier ----------------
pub type DashedIdentifierContextAll<'input> = DashedIdentifierContext<'input>;


pub type DashedIdentifierContext<'input> = BaseParserRuleContext<'input,DashedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct DashedIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for DashedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DashedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dashedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_dashedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DashedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dashedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for DashedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dashedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dashedIdentifier }
}
antlr_rust::tid!{DashedIdentifierContextExt<'a>}

impl<'input> DashedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DashedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DashedIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DashedIdentifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<DashedIdentifierContextExt<'input>>{

fn nonquotedIdentifier_all(&self) ->  Vec<Rc<NonquotedIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn nonquotedIdentifier(&self, i: usize) -> Option<Rc<NonquotedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL_VALUE, 0)
}
fn dashedIdentifier(&self) -> Option<Rc<DashedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DashedIdentifierContextAttrs<'input> for DashedIdentifierContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  dashedIdentifier(&mut self,)
	-> Result<Rc<DashedIdentifierContextAll<'input>>,ANTLRError> {
		self.dashedIdentifier_rec(0)
	}

	fn dashedIdentifier_rec(&mut self, _p: isize)
	-> Result<Rc<DashedIdentifierContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = DashedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 308, RULE_dashedIdentifier, _p);
	    let mut _localctx: Rc<DashedIdentifierContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 308;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3249);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(434,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule nonquotedIdentifier*/
					recog.base.set_state(3236);
					recog.nonquotedIdentifier()?;

					recog.base.set_state(3237);
					recog.base.match_token(MINUS,&mut recog.err_handler)?;

					/*InvokeRule nonquotedIdentifier*/
					recog.base.set_state(3238);
					recog.nonquotedIdentifier()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule nonquotedIdentifier*/
					recog.base.set_state(3240);
					recog.nonquotedIdentifier()?;

					recog.base.set_state(3241);
					recog.base.match_token(MINUS,&mut recog.err_handler)?;

					recog.base.set_state(3242);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					{
					/*InvokeRule nonquotedIdentifier*/
					recog.base.set_state(3244);
					recog.nonquotedIdentifier()?;

					recog.base.set_state(3245);
					recog.base.match_token(MINUS,&mut recog.err_handler)?;

					recog.base.set_state(3246);
					recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

					/*InvokeRule nonquotedIdentifier*/
					recog.base.set_state(3247);
					recog.nonquotedIdentifier()?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(3263);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(436,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(3261);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(435,&mut recog.base)? {
						1 =>{
							{
							/*recRuleAltStartAction*/
							let mut tmp = DashedIdentifierContextExt::new(_parentctx.clone(), _parentState);
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_dashedIdentifier);
							_localctx = tmp;
							recog.base.set_state(3251);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							recog.base.set_state(3252);
							recog.base.match_token(MINUS,&mut recog.err_handler)?;

							/*InvokeRule nonquotedIdentifier*/
							recog.base.set_state(3253);
							recog.nonquotedIdentifier()?;

							}
						}
					,
						2 =>{
							{
							/*recRuleAltStartAction*/
							let mut tmp = DashedIdentifierContextExt::new(_parentctx.clone(), _parentState);
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_dashedIdentifier);
							_localctx = tmp;
							recog.base.set_state(3254);
							if !({recog.precpred(None, 3)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 3)".to_owned()), None))?;
							}
							recog.base.set_state(3255);
							recog.base.match_token(MINUS,&mut recog.err_handler)?;

							recog.base.set_state(3256);
							recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

							}
						}
					,
						3 =>{
							{
							/*recRuleAltStartAction*/
							let mut tmp = DashedIdentifierContextExt::new(_parentctx.clone(), _parentState);
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_dashedIdentifier);
							_localctx = tmp;
							recog.base.set_state(3257);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(3258);
							recog.base.match_token(MINUS,&mut recog.err_handler)?;

							recog.base.set_state(3259);
							recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

							/*InvokeRule nonquotedIdentifier*/
							recog.base.set_state(3260);
							recog.nonquotedIdentifier()?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(3265);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(436,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- maybeDashedIdentifier ----------------
pub type MaybeDashedIdentifierContextAll<'input> = MaybeDashedIdentifierContext<'input>;


pub type MaybeDashedIdentifierContext<'input> = BaseParserRuleContext<'input,MaybeDashedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct MaybeDashedIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for MaybeDashedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MaybeDashedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_maybeDashedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_maybeDashedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MaybeDashedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_maybeDashedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for MaybeDashedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_maybeDashedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_maybeDashedIdentifier }
}
antlr_rust::tid!{MaybeDashedIdentifierContextExt<'a>}

impl<'input> MaybeDashedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MaybeDashedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MaybeDashedIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MaybeDashedIdentifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<MaybeDashedIdentifierContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dashedIdentifier(&self) -> Option<Rc<DashedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MaybeDashedIdentifierContextAttrs<'input> for MaybeDashedIdentifierContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn maybeDashedIdentifier(&mut self,)
	-> Result<Rc<MaybeDashedIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MaybeDashedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 310, RULE_maybeDashedIdentifier);
        let mut _localctx: Rc<MaybeDashedIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3268);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(437,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3266);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule dashedIdentifier*/
					recog.base.set_state(3267);
					recog.dashedIdentifier_rec(0)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dashedPathExpression ----------------
pub type DashedPathExpressionContextAll<'input> = DashedPathExpressionContext<'input>;


pub type DashedPathExpressionContext<'input> = BaseParserRuleContext<'input,DashedPathExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct DashedPathExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for DashedPathExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DashedPathExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dashedPathExpression(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_dashedPathExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DashedPathExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_dashedPathExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DashedPathExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dashedPathExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dashedPathExpression }
}
antlr_rust::tid!{DashedPathExpressionContextExt<'a>}

impl<'input> DashedPathExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DashedPathExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DashedPathExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DashedPathExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<DashedPathExpressionContextExt<'input>>{

fn dashedIdentifier(&self) -> Option<Rc<DashedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}
fn pathComponent_all(&self) ->  Vec<Rc<PathComponentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn pathComponent(&self, i: usize) -> Option<Rc<PathComponentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> DashedPathExpressionContextAttrs<'input> for DashedPathExpressionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dashedPathExpression(&mut self,)
	-> Result<Rc<DashedPathExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DashedPathExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 312, RULE_dashedPathExpression);
        let mut _localctx: Rc<DashedPathExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule dashedIdentifier*/
			recog.base.set_state(3270);
			recog.dashedIdentifier_rec(0)?;

			recog.base.set_state(3275);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(438,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3271);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule pathComponent*/
					recog.base.set_state(3272);
					recog.pathComponent()?;

					}
					} 
				}
				recog.base.set_state(3277);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(438,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- maybeDashedPathExpression ----------------
pub type MaybeDashedPathExpressionContextAll<'input> = MaybeDashedPathExpressionContext<'input>;


pub type MaybeDashedPathExpressionContext<'input> = BaseParserRuleContext<'input,MaybeDashedPathExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct MaybeDashedPathExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for MaybeDashedPathExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for MaybeDashedPathExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_maybeDashedPathExpression(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_maybeDashedPathExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for MaybeDashedPathExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_maybeDashedPathExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for MaybeDashedPathExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_maybeDashedPathExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_maybeDashedPathExpression }
}
antlr_rust::tid!{MaybeDashedPathExpressionContextExt<'a>}

impl<'input> MaybeDashedPathExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MaybeDashedPathExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MaybeDashedPathExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MaybeDashedPathExpressionContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<MaybeDashedPathExpressionContextExt<'input>>{

fn pathExpression(&self) -> Option<Rc<PathExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dashedPathExpression(&self) -> Option<Rc<DashedPathExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MaybeDashedPathExpressionContextAttrs<'input> for MaybeDashedPathExpressionContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn maybeDashedPathExpression(&mut self,)
	-> Result<Rc<MaybeDashedPathExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MaybeDashedPathExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 314, RULE_maybeDashedPathExpression);
        let mut _localctx: Rc<MaybeDashedPathExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3280);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(439,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule pathExpression*/
					recog.base.set_state(3278);
					recog.pathExpression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule dashedPathExpression*/
					recog.base.set_state(3279);
					recog.dashedPathExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryPeriod ----------------
pub type QueryPeriodContextAll<'input> = QueryPeriodContext<'input>;


pub type QueryPeriodContext<'input> = BaseParserRuleContext<'input,QueryPeriodContextExt<'input>>;

#[derive(Clone)]
pub struct QueryPeriodContextExt<'input>{
	pub end: Option<Rc<ValueExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for QueryPeriodContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for QueryPeriodContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryPeriod(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_queryPeriod(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for QueryPeriodContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_queryPeriod(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryPeriodContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPeriod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPeriod }
}
antlr_rust::tid!{QueryPeriodContextExt<'a>}

impl<'input> QueryPeriodContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryPeriodContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryPeriodContextExt{
				end: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryPeriodContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<QueryPeriodContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
fn rangeType(&self) -> Option<Rc<RangeTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryPeriodContextAttrs<'input> for QueryPeriodContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryPeriod(&mut self,)
	-> Result<Rc<QueryPeriodContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryPeriodContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 316, RULE_queryPeriod);
        let mut _localctx: Rc<QueryPeriodContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3282);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule rangeType*/
			recog.base.set_state(3283);
			recog.rangeType()?;

			recog.base.set_state(3284);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(3285);
			recog.base.match_token(OF,&mut recog.err_handler)?;

			/*InvokeRule valueExpression*/
			recog.base.set_state(3286);
			let tmp = recog.valueExpression_rec(0)?;
			 cast_mut::<_,QueryPeriodContext >(&mut _localctx).end = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rangeType ----------------
pub type RangeTypeContextAll<'input> = RangeTypeContext<'input>;


pub type RangeTypeContext<'input> = BaseParserRuleContext<'input,RangeTypeContextExt<'input>>;

#[derive(Clone)]
pub struct RangeTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for RangeTypeContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RangeTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rangeType(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_rangeType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RangeTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rangeType(self);
	}
}

impl<'input> CustomRuleContext<'input> for RangeTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rangeType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rangeType }
}
antlr_rust::tid!{RangeTypeContextExt<'a>}

impl<'input> RangeTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RangeTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RangeTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RangeTypeContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<RangeTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}

}

impl<'input> RangeTypeContextAttrs<'input> for RangeTypeContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rangeType(&mut self,)
	-> Result<Rc<RangeTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RangeTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 318, RULE_rangeType);
        let mut _localctx: Rc<RangeTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3288);
			_la = recog.base.input.la(1);
			if { !(_la==TIMESTAMP || _la==VERSION) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- principal ----------------
#[derive(Debug)]
pub enum PrincipalContextAll<'input>{
	UnspecifiedPrincipalContext(UnspecifiedPrincipalContext<'input>),
	UserPrincipalContext(UserPrincipalContext<'input>),
	RolePrincipalContext(RolePrincipalContext<'input>),
Error(PrincipalContext<'input>)
}
antlr_rust::tid!{PrincipalContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PrincipalContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for PrincipalContextAll<'input>{}

impl<'input> Deref for PrincipalContextAll<'input>{
	type Target = dyn PrincipalContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PrincipalContextAll::*;
		match self{
			UnspecifiedPrincipalContext(inner) => inner,
			UserPrincipalContext(inner) => inner,
			RolePrincipalContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PrincipalContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PrincipalContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PrincipalContext<'input> = BaseParserRuleContext<'input,PrincipalContextExt<'input>>;

#[derive(Clone)]
pub struct PrincipalContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PrincipalContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PrincipalContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}
antlr_rust::tid!{PrincipalContextExt<'a>}

impl<'input> PrincipalContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrincipalContextAll<'input>> {
		Rc::new(
		PrincipalContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrincipalContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PrincipalContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PrincipalContextExt<'input>>{


}

impl<'input> PrincipalContextAttrs<'input> for PrincipalContext<'input>{}

pub type UnspecifiedPrincipalContext<'input> = BaseParserRuleContext<'input,UnspecifiedPrincipalContextExt<'input>>;

pub trait UnspecifiedPrincipalContextAttrs<'input>: BigqueryParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnspecifiedPrincipalContextAttrs<'input> for UnspecifiedPrincipalContext<'input>{}

pub struct UnspecifiedPrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnspecifiedPrincipalContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UnspecifiedPrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnspecifiedPrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unspecifiedPrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_unspecifiedPrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnspecifiedPrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unspecifiedPrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnspecifiedPrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for UnspecifiedPrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for UnspecifiedPrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for UnspecifiedPrincipalContext<'input> {}

impl<'input> UnspecifiedPrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::UnspecifiedPrincipalContext(
				BaseParserRuleContext::copy_from(ctx,UnspecifiedPrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UserPrincipalContext<'input> = BaseParserRuleContext<'input,UserPrincipalContextExt<'input>>;

pub trait UserPrincipalContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token USER
	/// Returns `None` if there is no child corresponding to token USER
	fn USER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(USER, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UserPrincipalContextAttrs<'input> for UserPrincipalContext<'input>{}

pub struct UserPrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UserPrincipalContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UserPrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UserPrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_userPrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_userPrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UserPrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_userPrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for UserPrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for UserPrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for UserPrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for UserPrincipalContext<'input> {}

impl<'input> UserPrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::UserPrincipalContext(
				BaseParserRuleContext::copy_from(ctx,UserPrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RolePrincipalContext<'input> = BaseParserRuleContext<'input,RolePrincipalContextExt<'input>>;

pub trait RolePrincipalContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLE
	/// Returns `None` if there is no child corresponding to token ROLE
	fn ROLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(ROLE, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RolePrincipalContextAttrs<'input> for RolePrincipalContext<'input>{}

pub struct RolePrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RolePrincipalContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for RolePrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for RolePrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rolePrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_rolePrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for RolePrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_rolePrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for RolePrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for RolePrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for RolePrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for RolePrincipalContext<'input> {}

impl<'input> RolePrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::RolePrincipalContext(
				BaseParserRuleContext::copy_from(ctx,RolePrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn principal(&mut self,)
	-> Result<Rc<PrincipalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrincipalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 320, RULE_principal);
        let mut _localctx: Rc<PrincipalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3295);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(440,&mut recog.base)? {
				1 =>{
					let tmp = UnspecifiedPrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3290);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					let tmp = UserPrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3291);
					recog.base.match_token(USER,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3292);
					recog.identifier()?;

					}
				}
			,
				3 =>{
					let tmp = RolePrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3293);
					recog.base.match_token(ROLE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3294);
					recog.identifier()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifier ----------------
#[derive(Debug)]
pub enum IdentifierContextAll<'input>{
	BackQuotedIdentifierContext(BackQuotedIdentifierContext<'input>),
	UnquotedIdentifierContext(UnquotedIdentifierContext<'input>),
Error(IdentifierContext<'input>)
}
antlr_rust::tid!{IdentifierContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for IdentifierContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for IdentifierContextAll<'input>{}

impl<'input> Deref for IdentifierContextAll<'input>{
	type Target = dyn IdentifierContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use IdentifierContextAll::*;
		match self{
			BackQuotedIdentifierContext(inner) => inner,
			UnquotedIdentifierContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IdentifierContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IdentifierContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type IdentifierContext<'input> = BaseParserRuleContext<'input,IdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for IdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IdentifierContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IdentifierContext<'input>{
}

impl<'input> CustomRuleContext<'input> for IdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}
antlr_rust::tid!{IdentifierContextExt<'a>}

impl<'input> IdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierContextAll<'input>> {
		Rc::new(
		IdentifierContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait IdentifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<IdentifierContextExt<'input>>{


}

impl<'input> IdentifierContextAttrs<'input> for IdentifierContext<'input>{}

pub type BackQuotedIdentifierContext<'input> = BaseParserRuleContext<'input,BackQuotedIdentifierContextExt<'input>>;

pub trait BackQuotedIdentifierContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BACKQUOTED_IDENTIFIER
	/// Returns `None` if there is no child corresponding to token BACKQUOTED_IDENTIFIER
	fn BACKQUOTED_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(BACKQUOTED_IDENTIFIER, 0)
	}
}

impl<'input> BackQuotedIdentifierContextAttrs<'input> for BackQuotedIdentifierContext<'input>{}

pub struct BackQuotedIdentifierContextExt<'input>{
	base:IdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BackQuotedIdentifierContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for BackQuotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for BackQuotedIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_backQuotedIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_backQuotedIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for BackQuotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_backQuotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for BackQuotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}

impl<'input> Borrow<IdentifierContextExt<'input>> for BackQuotedIdentifierContext<'input>{
	fn borrow(&self) -> &IdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IdentifierContextExt<'input>> for BackQuotedIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut IdentifierContextExt<'input> { &mut self.base }
}

impl<'input> IdentifierContextAttrs<'input> for BackQuotedIdentifierContext<'input> {}

impl<'input> BackQuotedIdentifierContextExt<'input>{
	fn new(ctx: &dyn IdentifierContextAttrs<'input>) -> Rc<IdentifierContextAll<'input>>  {
		Rc::new(
			IdentifierContextAll::BackQuotedIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,BackQuotedIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnquotedIdentifierContext<'input> = BaseParserRuleContext<'input,UnquotedIdentifierContextExt<'input>>;

pub trait UnquotedIdentifierContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IDENTIFIER
	/// Returns `None` if there is no child corresponding to token IDENTIFIER
	fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(IDENTIFIER, 0)
	}
	fn nonReserved(&self) -> Option<Rc<NonReservedContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnquotedIdentifierContextAttrs<'input> for UnquotedIdentifierContext<'input>{}

pub struct UnquotedIdentifierContextExt<'input>{
	base:IdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnquotedIdentifierContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for UnquotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for UnquotedIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unquotedIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_unquotedIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for UnquotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_unquotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnquotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}

impl<'input> Borrow<IdentifierContextExt<'input>> for UnquotedIdentifierContext<'input>{
	fn borrow(&self) -> &IdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IdentifierContextExt<'input>> for UnquotedIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut IdentifierContextExt<'input> { &mut self.base }
}

impl<'input> IdentifierContextAttrs<'input> for UnquotedIdentifierContext<'input> {}

impl<'input> UnquotedIdentifierContextExt<'input>{
	fn new(ctx: &dyn IdentifierContextAttrs<'input>) -> Rc<IdentifierContextAll<'input>>  {
		Rc::new(
			IdentifierContextAll::UnquotedIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,UnquotedIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifier(&mut self,)
	-> Result<Rc<IdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 322, RULE_identifier);
        let mut _localctx: Rc<IdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3300);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IDENTIFIER 
				=> {
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3297);
					recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;

					}
				}

			 ABORT | ABSENT | ADD | ADMIN | AFTER | ALTER | ANALYZE | ANTI | ATTACH |
			 AUTHORIZATION | AUTO | BACKUP | BEGIN | BERNOULLI | BOTH | BREAK | BZIP2 |
			 CALL | CANCEL | CASCADE | CASE_SENSITIVE | CASE_INSENSITIVE | CATALOGS |
			 CHARACTER | CLONE | CLOSE | CLUSTER | COALESCE | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMMITTED | COMPOUND | COMPRESSION | CONDITIONAL | CONNECT |
			 CONNECTION | CONSTRAINT | CONTINUE | COPARTITION | COPY | COUNT | CURRENT_ROLE |
			 CUSTOM_HOLIDAY | DATA | DATABASE | DATASHARE | DATE | DATETIME | DAY |
			 DAYOFWEEK | DAYOFYEAR | DATETIME_DIFF | DATE_DIFF | DEALLOCATE | DECLARE |
			 DEFAULTS | DEFINER | DELETE | DELIMITED | DELIMITER | DENY | DESCRIBE |
			 DESCRIPTOR | DETERMINISTIC | DISTKEY | DISTRIBUTED | DISTSTYLE | DETACH |
			 DO | DOUBLE | DROP | ELSEIF | EMPTY | ENCODE | ENCODING | ERROR | EVEN |
			 EXCEPTION | EXCLUDING | EXECUTE | EXPLAIN | EXTERNAL | FIELDS | FILTER |
			 FINAL | FIRST | FORMAT | FRIDAY | FUNCTION | FUNCTIONS | GENERATED |
			 GRACE | GRANT | GRANTED | GRANTS | GRAPHVIZ | GZIP | HEADER | HOUR |
			 IDENTITY | IMMEDIATE | INCLUDE | INCLUDING | INITIAL | INPUT | INPUTFORMAT |
			 INTERLEAVED | INSERT | INVOKER | IO | ISOLATION | ISOWEEK | ISOYEAR |
			 ITERATE | ILIKE | JSON | KEEP | KEY | KEYS | LAMBDA | LANGUAGE | LEAVE |
			 LAST | LEADING | LEVEL | LIBRARY | LINES | LISTAGG | LOCAL | LOCATION |
			 LOCK | LOGICAL | LOOP | MAP | MASKING | MATCH | MATCHED | MATCHES | MATERIALIZED |
			 MAX | MEASURES | MESSAGE | MICROSECOND | MILLISECOND | MIN | MINUS_KW |
			 MINUTE | MODEL | MONDAY | MONTH | NAME | NEXT | NFC | NFD | NFKC | NFKD |
			 NONE | NORMALIZE | OBJECT | OFFSET | OMIT | ONE | ONLY | OPTION | OPTIONS |
			 OUTPUT | OUTPUTFORMAT | OVERFLOW | PARTITIONED | PARTITIONS | PASSING |
			 PAST | PATH | PATTERN | PER | PERCENT_KW | PERIOD | PERMUTE | PIVOT |
			 POSITION | PRECISION | PREPARE | PRIOR | PROCEDURE | PRIVILEGES | PROPERTIES |
			 PRUNE | QUARTER | QUOTES | RAISE | READ | REFRESH | RENAME | REPEATABLE |
			 REPLACE | RESET | RESTRICT | RETURN | RETURNING | REMOTE | REPEAT | RETURNS |
			 REVOKE | RLS | ROLE | ROLES | ROLLBACK | ROW | RUNNING | SAFE | SAFE_CAST |
			 SATURDAY | SCALAR | SECOND | SCHEMA | SCHEMAS | SECURITY | SEEK | SEMI |
			 SERDE | SERDEPROPERTIES | SERIALIZABLE | SESSION | SETS | SHOW | SIMILAR |
			 SNAPSHOT | SORTKEY | START | STATS | STORED | SUBSET | SUBSTRING | SUNDAY |
			 SYSTEM | SYSTEM_TIME | TABLE | TABLES | TEMP | TEMPORARY | TERMINATED |
			 TEXT | STRING_KW | THURSDAY | TIES | TIME | TIMESTAMP | TIMESTAMP_DIFF |
			 TOP | TRAILING | TARGET | SOURCE | TRAINING_DATA | TRANSACTION | TRANSFORM |
			 TRIM | TRUNCATE | TRY_CAST | TUPLE | TUESDAY | TYPE | UESCAPE | UNCOMMITTED |
			 UNCONDITIONAL | UNKNOWN | UNLOAD | UNMATCHED | UNPIVOT | UNSIGNED | UNTIL |
			 UPDATE | USE | USER | UTF16 | UTF32 | UTF8 | VACUUM | VALIDATE | VALUE |
			 VALUES | VARYING | VERBOSE | VERSION | VIEW | WEDNESDAY | WEEK | WHILE |
			 WITHOUT | WORK | WRAPPER | WRITE | XZ | YEAR | YES | ZONE | ZSTD 
				=> {
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule nonReserved*/
					recog.base.set_state(3298);
					recog.nonReserved()?;

					}
				}

			 BACKQUOTED_IDENTIFIER 
				=> {
					let tmp = BackQuotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3299);
					recog.base.match_token(BACKQUOTED_IDENTIFIER,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pathComponent ----------------
pub type PathComponentContextAll<'input> = PathComponentContext<'input>;


pub type PathComponentContext<'input> = BaseParserRuleContext<'input,PathComponentContextExt<'input>>;

#[derive(Clone)]
pub struct PathComponentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for PathComponentContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for PathComponentContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pathComponent(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_pathComponent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for PathComponentContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_pathComponent(self);
	}
}

impl<'input> CustomRuleContext<'input> for PathComponentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pathComponent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pathComponent }
}
antlr_rust::tid!{PathComponentContextExt<'a>}

impl<'input> PathComponentContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PathComponentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PathComponentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PathComponentContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<PathComponentContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAY
/// Returns `None` if there is no child corresponding to token ARRAY
fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token AT
/// Returns `None` if there is no child corresponding to token AT
fn AT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AT, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token CASE
/// Returns `None` if there is no child corresponding to token CASE
fn CASE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CASE, 0)
}
/// Retrieves first TerminalNode corresponding to token CAST
/// Returns `None` if there is no child corresponding to token CAST
fn CAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLATE
/// Returns `None` if there is no child corresponding to token COLLATE
fn COLLATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COLLATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSS
/// Returns `None` if there is no child corresponding to token CROSS
fn CROSS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CROSS, 0)
}
/// Retrieves first TerminalNode corresponding to token CUBE
/// Returns `None` if there is no child corresponding to token CUBE
fn CUBE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CUBE, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT
/// Returns `None` if there is no child corresponding to token CURRENT
fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINE
/// Returns `None` if there is no child corresponding to token DEFINE
fn DEFINE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DEFINE, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token ELSE
/// Returns `None` if there is no child corresponding to token ELSE
fn ELSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ELSE, 0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
/// Retrieves first TerminalNode corresponding to token ESCAPE
/// Returns `None` if there is no child corresponding to token ESCAPE
fn ESCAPE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ESCAPE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXISTS
/// Returns `None` if there is no child corresponding to token EXISTS
fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXISTS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTRACT
/// Returns `None` if there is no child corresponding to token EXTRACT
fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXTRACT, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}
/// Retrieves first TerminalNode corresponding to token FETCH
/// Returns `None` if there is no child corresponding to token FETCH
fn FETCH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FETCH, 0)
}
/// Retrieves first TerminalNode corresponding to token FOLLOWING
/// Returns `None` if there is no child corresponding to token FOLLOWING
fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FOLLOWING, 0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUP
/// Returns `None` if there is no child corresponding to token GROUP
fn GROUP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPS
/// Returns `None` if there is no child corresponding to token GROUPS
fn GROUPS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GROUPS, 0)
}
/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
/// Retrieves first TerminalNode corresponding to token IGNORE
/// Returns `None` if there is no child corresponding to token IGNORE
fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token INTO
/// Returns `None` if there is no child corresponding to token INTO
fn INTO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token IS
/// Returns `None` if there is no child corresponding to token IS
fn IS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IS, 0)
}
/// Retrieves first TerminalNode corresponding to token JOIN
/// Returns `None` if there is no child corresponding to token JOIN
fn JOIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(JOIN, 0)
}
/// Retrieves first TerminalNode corresponding to token LATERAL
/// Returns `None` if there is no child corresponding to token LATERAL
fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LATERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token LIKE
/// Returns `None` if there is no child corresponding to token LIKE
fn LIKE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCH_RECOGNIZE
/// Returns `None` if there is no child corresponding to token MATCH_RECOGNIZE
fn MATCH_RECOGNIZE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MATCH_RECOGNIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token MERGE
/// Returns `None` if there is no child corresponding to token MERGE
fn MERGE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MERGE, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS_KW
/// Returns `None` if there is no child corresponding to token MINUS_KW
fn MINUS_KW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MINUS_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token NATURAL
/// Returns `None` if there is no child corresponding to token NATURAL
fn NATURAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NATURAL, 0)
}
/// Retrieves first TerminalNode corresponding to token NO
/// Returns `None` if there is no child corresponding to token NO
fn NO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NO, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
/// Retrieves first TerminalNode corresponding to token OR
/// Returns `None` if there is no child corresponding to token OR
fn OR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OR, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token OVER
/// Returns `None` if there is no child corresponding to token OVER
fn OVER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PRECEDING
/// Returns `None` if there is no child corresponding to token PRECEDING
fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PRECEDING, 0)
}
/// Retrieves first TerminalNode corresponding to token QUALIFY
/// Returns `None` if there is no child corresponding to token QUALIFY
fn QUALIFY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(QUALIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token RECURSIVE
/// Returns `None` if there is no child corresponding to token RECURSIVE
fn RECURSIVE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RECURSIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token RESPECT
/// Returns `None` if there is no child corresponding to token RESPECT
fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RESPECT, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLUP
/// Returns `None` if there is no child corresponding to token ROLLUP
fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token SOME
/// Returns `None` if there is no child corresponding to token SOME
fn SOME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token STRUCT
/// Returns `None` if there is no child corresponding to token STRUCT
fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNBOUNDED
/// Returns `None` if there is no child corresponding to token UNBOUNDED
fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNBOUNDED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token UNNEST
/// Returns `None` if there is no child corresponding to token UNNEST
fn UNNEST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNNEST, 0)
}
/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}

}

impl<'input> PathComponentContextAttrs<'input> for PathComponentContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pathComponent(&mut self,)
	-> Result<Rc<PathComponentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PathComponentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 324, RULE_pathComponent);
        let mut _localctx: Rc<PathComponentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3392);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(442,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3302);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3303);
					recog.base.match_token(ALL,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3304);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3305);
					recog.base.match_token(ANY,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3306);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(3307);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(3308);
					recog.base.match_token(ASC,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(3309);
					recog.base.match_token(AT,&mut recog.err_handler)?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(3310);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					recog.base.set_state(3311);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					recog.base.set_state(3312);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					recog.base.set_state(3313);
					recog.base.match_token(CAST,&mut recog.err_handler)?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					recog.base.set_state(3314);
					recog.base.match_token(COLLATE,&mut recog.err_handler)?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					recog.base.set_state(3315);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					}
				}
			,
				15 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					recog.base.set_state(3316);
					recog.base.match_token(CROSS,&mut recog.err_handler)?;

					}
				}
			,
				16 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					recog.base.set_state(3317);
					recog.base.match_token(CUBE,&mut recog.err_handler)?;

					}
				}
			,
				17 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					recog.base.set_state(3318);
					recog.base.match_token(CURRENT,&mut recog.err_handler)?;

					}
				}
			,
				18 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 18);
					recog.base.enter_outer_alt(None, 18);
					{
					recog.base.set_state(3319);
					recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

					}
				}
			,
				19 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 19);
					recog.base.enter_outer_alt(None, 19);
					{
					recog.base.set_state(3320);
					recog.base.match_token(DEFINE,&mut recog.err_handler)?;

					}
				}
			,
				20 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 20);
					recog.base.enter_outer_alt(None, 20);
					{
					recog.base.set_state(3321);
					recog.base.match_token(DESC,&mut recog.err_handler)?;

					}
				}
			,
				21 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 21);
					recog.base.enter_outer_alt(None, 21);
					{
					recog.base.set_state(3322);
					recog.base.match_token(DISTINCT,&mut recog.err_handler)?;

					}
				}
			,
				22 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 22);
					recog.base.enter_outer_alt(None, 22);
					{
					recog.base.set_state(3323);
					recog.base.match_token(ELSE,&mut recog.err_handler)?;

					}
				}
			,
				23 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 23);
					recog.base.enter_outer_alt(None, 23);
					{
					recog.base.set_state(3324);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				24 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 24);
					recog.base.enter_outer_alt(None, 24);
					{
					recog.base.set_state(3325);
					recog.base.match_token(ESCAPE,&mut recog.err_handler)?;

					}
				}
			,
				25 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 25);
					recog.base.enter_outer_alt(None, 25);
					{
					recog.base.set_state(3326);
					recog.base.match_token(EXCEPT,&mut recog.err_handler)?;

					}
				}
			,
				26 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 26);
					recog.base.enter_outer_alt(None, 26);
					{
					recog.base.set_state(3327);
					recog.base.match_token(EXCLUDE,&mut recog.err_handler)?;

					}
				}
			,
				27 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 27);
					recog.base.enter_outer_alt(None, 27);
					{
					recog.base.set_state(3328);
					recog.base.match_token(EXISTS,&mut recog.err_handler)?;

					}
				}
			,
				28 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 28);
					recog.base.enter_outer_alt(None, 28);
					{
					recog.base.set_state(3329);
					recog.base.match_token(EXTRACT,&mut recog.err_handler)?;

					}
				}
			,
				29 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 29);
					recog.base.enter_outer_alt(None, 29);
					{
					recog.base.set_state(3330);
					recog.base.match_token(FALSE,&mut recog.err_handler)?;

					}
				}
			,
				30 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 30);
					recog.base.enter_outer_alt(None, 30);
					{
					recog.base.set_state(3331);
					recog.base.match_token(FETCH,&mut recog.err_handler)?;

					}
				}
			,
				31 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 31);
					recog.base.enter_outer_alt(None, 31);
					{
					recog.base.set_state(3332);
					recog.base.match_token(FOLLOWING,&mut recog.err_handler)?;

					}
				}
			,
				32 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 32);
					recog.base.enter_outer_alt(None, 32);
					{
					recog.base.set_state(3333);
					recog.base.match_token(FOR,&mut recog.err_handler)?;

					}
				}
			,
				33 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 33);
					recog.base.enter_outer_alt(None, 33);
					{
					recog.base.set_state(3334);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					}
				}
			,
				34 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 34);
					recog.base.enter_outer_alt(None, 34);
					{
					recog.base.set_state(3335);
					recog.base.match_token(FULL,&mut recog.err_handler)?;

					}
				}
			,
				35 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 35);
					recog.base.enter_outer_alt(None, 35);
					{
					recog.base.set_state(3336);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					}
				}
			,
				36 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 36);
					recog.base.enter_outer_alt(None, 36);
					{
					recog.base.set_state(3337);
					recog.base.match_token(GROUPING,&mut recog.err_handler)?;

					}
				}
			,
				37 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 37);
					recog.base.enter_outer_alt(None, 37);
					{
					recog.base.set_state(3338);
					recog.base.match_token(GROUPS,&mut recog.err_handler)?;

					}
				}
			,
				38 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 38);
					recog.base.enter_outer_alt(None, 38);
					{
					recog.base.set_state(3339);
					recog.base.match_token(HAVING,&mut recog.err_handler)?;

					}
				}
			,
				39 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 39);
					recog.base.enter_outer_alt(None, 39);
					{
					recog.base.set_state(3340);
					recog.base.match_token(IF,&mut recog.err_handler)?;

					}
				}
			,
				40 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 40);
					recog.base.enter_outer_alt(None, 40);
					{
					recog.base.set_state(3341);
					recog.base.match_token(IGNORE,&mut recog.err_handler)?;

					}
				}
			,
				41 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 41);
					recog.base.enter_outer_alt(None, 41);
					{
					recog.base.set_state(3342);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					}
				}
			,
				42 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 42);
					recog.base.enter_outer_alt(None, 42);
					{
					recog.base.set_state(3343);
					recog.base.match_token(INNER,&mut recog.err_handler)?;

					}
				}
			,
				43 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 43);
					recog.base.enter_outer_alt(None, 43);
					{
					recog.base.set_state(3344);
					recog.base.match_token(INTERSECT,&mut recog.err_handler)?;

					}
				}
			,
				44 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 44);
					recog.base.enter_outer_alt(None, 44);
					{
					recog.base.set_state(3345);
					recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

					}
				}
			,
				45 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 45);
					recog.base.enter_outer_alt(None, 45);
					{
					recog.base.set_state(3346);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					}
				}
			,
				46 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 46);
					recog.base.enter_outer_alt(None, 46);
					{
					recog.base.set_state(3347);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					}
				}
			,
				47 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 47);
					recog.base.enter_outer_alt(None, 47);
					{
					recog.base.set_state(3348);
					recog.base.match_token(JOIN,&mut recog.err_handler)?;

					}
				}
			,
				48 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 48);
					recog.base.enter_outer_alt(None, 48);
					{
					recog.base.set_state(3349);
					recog.base.match_token(LATERAL,&mut recog.err_handler)?;

					}
				}
			,
				49 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 49);
					recog.base.enter_outer_alt(None, 49);
					{
					recog.base.set_state(3350);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					}
				}
			,
				50 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 50);
					recog.base.enter_outer_alt(None, 50);
					{
					recog.base.set_state(3351);
					recog.base.match_token(LIKE,&mut recog.err_handler)?;

					}
				}
			,
				51 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 51);
					recog.base.enter_outer_alt(None, 51);
					{
					recog.base.set_state(3352);
					recog.base.match_token(LIMIT,&mut recog.err_handler)?;

					}
				}
			,
				52 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 52);
					recog.base.enter_outer_alt(None, 52);
					{
					recog.base.set_state(3353);
					recog.base.match_token(MATCH_RECOGNIZE,&mut recog.err_handler)?;

					}
				}
			,
				53 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 53);
					recog.base.enter_outer_alt(None, 53);
					{
					recog.base.set_state(3354);
					recog.base.match_token(MERGE,&mut recog.err_handler)?;

					}
				}
			,
				54 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 54);
					recog.base.enter_outer_alt(None, 54);
					{
					recog.base.set_state(3355);
					recog.base.match_token(MINUS_KW,&mut recog.err_handler)?;

					}
				}
			,
				55 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 55);
					recog.base.enter_outer_alt(None, 55);
					{
					recog.base.set_state(3356);
					recog.base.match_token(NATURAL,&mut recog.err_handler)?;

					}
				}
			,
				56 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 56);
					recog.base.enter_outer_alt(None, 56);
					{
					recog.base.set_state(3357);
					recog.base.match_token(NO,&mut recog.err_handler)?;

					}
				}
			,
				57 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 57);
					recog.base.enter_outer_alt(None, 57);
					{
					recog.base.set_state(3358);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					}
				}
			,
				58 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 58);
					recog.base.enter_outer_alt(None, 58);
					{
					recog.base.set_state(3359);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				59 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 59);
					recog.base.enter_outer_alt(None, 59);
					{
					recog.base.set_state(3360);
					recog.base.match_token(NULLS,&mut recog.err_handler)?;

					}
				}
			,
				60 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 60);
					recog.base.enter_outer_alt(None, 60);
					{
					recog.base.set_state(3361);
					recog.base.match_token(OF,&mut recog.err_handler)?;

					}
				}
			,
				61 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 61);
					recog.base.enter_outer_alt(None, 61);
					{
					recog.base.set_state(3362);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					}
				}
			,
				62 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 62);
					recog.base.enter_outer_alt(None, 62);
					{
					recog.base.set_state(3363);
					recog.base.match_token(OR,&mut recog.err_handler)?;

					}
				}
			,
				63 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 63);
					recog.base.enter_outer_alt(None, 63);
					{
					recog.base.set_state(3364);
					recog.base.match_token(ORDER,&mut recog.err_handler)?;

					}
				}
			,
				64 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 64);
					recog.base.enter_outer_alt(None, 64);
					{
					recog.base.set_state(3365);
					recog.base.match_token(OUTER,&mut recog.err_handler)?;

					}
				}
			,
				65 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 65);
					recog.base.enter_outer_alt(None, 65);
					{
					recog.base.set_state(3366);
					recog.base.match_token(OVER,&mut recog.err_handler)?;

					}
				}
			,
				66 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 66);
					recog.base.enter_outer_alt(None, 66);
					{
					recog.base.set_state(3367);
					recog.base.match_token(PARTITION,&mut recog.err_handler)?;

					}
				}
			,
				67 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 67);
					recog.base.enter_outer_alt(None, 67);
					{
					recog.base.set_state(3368);
					recog.base.match_token(PRECEDING,&mut recog.err_handler)?;

					}
				}
			,
				68 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 68);
					recog.base.enter_outer_alt(None, 68);
					{
					recog.base.set_state(3369);
					recog.base.match_token(QUALIFY,&mut recog.err_handler)?;

					}
				}
			,
				69 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 69);
					recog.base.enter_outer_alt(None, 69);
					{
					recog.base.set_state(3370);
					recog.base.match_token(RANGE,&mut recog.err_handler)?;

					}
				}
			,
				70 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 70);
					recog.base.enter_outer_alt(None, 70);
					{
					recog.base.set_state(3371);
					recog.base.match_token(RECURSIVE,&mut recog.err_handler)?;

					}
				}
			,
				71 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 71);
					recog.base.enter_outer_alt(None, 71);
					{
					recog.base.set_state(3372);
					recog.base.match_token(RESPECT,&mut recog.err_handler)?;

					}
				}
			,
				72 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 72);
					recog.base.enter_outer_alt(None, 72);
					{
					recog.base.set_state(3373);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					}
				}
			,
				73 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 73);
					recog.base.enter_outer_alt(None, 73);
					{
					recog.base.set_state(3374);
					recog.base.match_token(ROLLUP,&mut recog.err_handler)?;

					}
				}
			,
				74 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 74);
					recog.base.enter_outer_alt(None, 74);
					{
					recog.base.set_state(3375);
					recog.base.match_token(ROWS,&mut recog.err_handler)?;

					}
				}
			,
				75 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 75);
					recog.base.enter_outer_alt(None, 75);
					{
					recog.base.set_state(3376);
					recog.base.match_token(SELECT,&mut recog.err_handler)?;

					}
				}
			,
				76 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 76);
					recog.base.enter_outer_alt(None, 76);
					{
					recog.base.set_state(3377);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					}
				}
			,
				77 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 77);
					recog.base.enter_outer_alt(None, 77);
					{
					recog.base.set_state(3378);
					recog.base.match_token(SOME,&mut recog.err_handler)?;

					}
				}
			,
				78 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 78);
					recog.base.enter_outer_alt(None, 78);
					{
					recog.base.set_state(3379);
					recog.base.match_token(STRUCT,&mut recog.err_handler)?;

					}
				}
			,
				79 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 79);
					recog.base.enter_outer_alt(None, 79);
					{
					recog.base.set_state(3380);
					recog.base.match_token(TABLESAMPLE,&mut recog.err_handler)?;

					}
				}
			,
				80 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 80);
					recog.base.enter_outer_alt(None, 80);
					{
					recog.base.set_state(3381);
					recog.base.match_token(THEN,&mut recog.err_handler)?;

					}
				}
			,
				81 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 81);
					recog.base.enter_outer_alt(None, 81);
					{
					recog.base.set_state(3382);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					}
				}
			,
				82 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 82);
					recog.base.enter_outer_alt(None, 82);
					{
					recog.base.set_state(3383);
					recog.base.match_token(TRUE,&mut recog.err_handler)?;

					}
				}
			,
				83 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 83);
					recog.base.enter_outer_alt(None, 83);
					{
					recog.base.set_state(3384);
					recog.base.match_token(UNBOUNDED,&mut recog.err_handler)?;

					}
				}
			,
				84 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 84);
					recog.base.enter_outer_alt(None, 84);
					{
					recog.base.set_state(3385);
					recog.base.match_token(UNION,&mut recog.err_handler)?;

					}
				}
			,
				85 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 85);
					recog.base.enter_outer_alt(None, 85);
					{
					recog.base.set_state(3386);
					recog.base.match_token(UNNEST,&mut recog.err_handler)?;

					}
				}
			,
				86 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 86);
					recog.base.enter_outer_alt(None, 86);
					{
					recog.base.set_state(3387);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					}
				}
			,
				87 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 87);
					recog.base.enter_outer_alt(None, 87);
					{
					recog.base.set_state(3388);
					recog.base.match_token(WHEN,&mut recog.err_handler)?;

					}
				}
			,
				88 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 88);
					recog.base.enter_outer_alt(None, 88);
					{
					recog.base.set_state(3389);
					recog.base.match_token(WHERE,&mut recog.err_handler)?;

					}
				}
			,
				89 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 89);
					recog.base.enter_outer_alt(None, 89);
					{
					recog.base.set_state(3390);
					recog.base.match_token(WINDOW,&mut recog.err_handler)?;

					}
				}
			,
				90 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 90);
					recog.base.enter_outer_alt(None, 90);
					{
					recog.base.set_state(3391);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneIdentifier ----------------
pub type StandaloneIdentifierContextAll<'input> = StandaloneIdentifierContext<'input>;


pub type StandaloneIdentifierContext<'input> = BaseParserRuleContext<'input,StandaloneIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for StandaloneIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for StandaloneIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_standaloneIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for StandaloneIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_standaloneIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneIdentifier }
}
antlr_rust::tid!{StandaloneIdentifierContextExt<'a>}

impl<'input> StandaloneIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneIdentifierContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<StandaloneIdentifierContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneIdentifierContextAttrs<'input> for StandaloneIdentifierContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneIdentifier(&mut self,)
	-> Result<Rc<StandaloneIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 326, RULE_standaloneIdentifier);
        let mut _localctx: Rc<StandaloneIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3394);
			recog.identifier()?;

			recog.base.set_state(3395);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierList ----------------
pub type IdentifierListContextAll<'input> = IdentifierListContext<'input>;


pub type IdentifierListContext<'input> = BaseParserRuleContext<'input,IdentifierListContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for IdentifierListContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IdentifierListContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierList(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_identifierList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IdentifierListContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_identifierList(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierList }
}
antlr_rust::tid!{IdentifierListContextExt<'a>}

impl<'input> IdentifierListContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierListContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<IdentifierListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> IdentifierListContextAttrs<'input> for IdentifierListContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierList(&mut self,)
	-> Result<Rc<IdentifierListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 328, RULE_identifierList);
        let mut _localctx: Rc<IdentifierListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3397);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifierSeq*/
			recog.base.set_state(3398);
			recog.identifierSeq()?;

			recog.base.set_state(3399);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierSeq ----------------
pub type IdentifierSeqContextAll<'input> = IdentifierSeqContext<'input>;


pub type IdentifierSeqContext<'input> = BaseParserRuleContext<'input,IdentifierSeqContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierSeqContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for IdentifierSeqContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IdentifierSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierSeq(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_identifierSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IdentifierSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_identifierSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierSeq }
}
antlr_rust::tid!{IdentifierSeqContextExt<'a>}

impl<'input> IdentifierSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierSeqContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierSeqContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<IdentifierSeqContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,BigqueryParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> IdentifierSeqContextAttrs<'input> for IdentifierSeqContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierSeq(&mut self,)
	-> Result<Rc<IdentifierSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 330, RULE_identifierSeq);
        let mut _localctx: Rc<IdentifierSeqContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3401);
			recog.identifier()?;

			recog.base.set_state(3406);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3402);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule identifier*/
				recog.base.set_state(3403);
				recog.identifier()?;

				}
				}
				recog.base.set_state(3408);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- number ----------------
#[derive(Debug)]
pub enum NumberContextAll<'input>{
	DecimalLiteralContext(DecimalLiteralContext<'input>),
	DoubleLiteralContext(DoubleLiteralContext<'input>),
	IntegerLiteralContext(IntegerLiteralContext<'input>),
	HexadecimalLiteralContext(HexadecimalLiteralContext<'input>),
Error(NumberContext<'input>)
}
antlr_rust::tid!{NumberContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for NumberContextAll<'input>{}

impl<'input> BigqueryParserContext<'input> for NumberContextAll<'input>{}

impl<'input> Deref for NumberContextAll<'input>{
	type Target = dyn NumberContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use NumberContextAll::*;
		match self{
			DecimalLiteralContext(inner) => inner,
			DoubleLiteralContext(inner) => inner,
			IntegerLiteralContext(inner) => inner,
			HexadecimalLiteralContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NumberContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NumberContextAll<'input>{
    fn enter(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn BigqueryListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type NumberContext<'input> = BaseParserRuleContext<'input,NumberContextExt<'input>>;

#[derive(Clone)]
pub struct NumberContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NumberContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NumberContext<'input>{
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NumberContext<'input>{
}

impl<'input> CustomRuleContext<'input> for NumberContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}
antlr_rust::tid!{NumberContextExt<'a>}

impl<'input> NumberContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NumberContextAll<'input>> {
		Rc::new(
		NumberContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NumberContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait NumberContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NumberContextExt<'input>>{


}

impl<'input> NumberContextAttrs<'input> for NumberContext<'input>{}

pub type DecimalLiteralContext<'input> = BaseParserRuleContext<'input,DecimalLiteralContextExt<'input>>;

pub trait DecimalLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
	fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> DecimalLiteralContextAttrs<'input> for DecimalLiteralContext<'input>{}

pub struct DecimalLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DecimalLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DecimalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DecimalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_decimalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_decimalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DecimalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_decimalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DecimalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for DecimalLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for DecimalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for DecimalLiteralContext<'input> {}

impl<'input> DecimalLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::DecimalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DecimalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DoubleLiteralContext<'input> = BaseParserRuleContext<'input,DoubleLiteralContextExt<'input>>;

pub trait DoubleLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOUBLE_VALUE
	/// Returns `None` if there is no child corresponding to token DOUBLE_VALUE
	fn DOUBLE_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(DOUBLE_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> DoubleLiteralContextAttrs<'input> for DoubleLiteralContext<'input>{}

pub struct DoubleLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DoubleLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for DoubleLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for DoubleLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_doubleLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_doubleLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for DoubleLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_doubleLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DoubleLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for DoubleLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for DoubleLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for DoubleLiteralContext<'input> {}

impl<'input> DoubleLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::DoubleLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DoubleLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntegerLiteralContext<'input> = BaseParserRuleContext<'input,IntegerLiteralContextExt<'input>>;

pub trait IntegerLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> IntegerLiteralContextAttrs<'input> for IntegerLiteralContext<'input>{}

pub struct IntegerLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntegerLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for IntegerLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for IntegerLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_integerLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_integerLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for IntegerLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_integerLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntegerLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for IntegerLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for IntegerLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for IntegerLiteralContext<'input> {}

impl<'input> IntegerLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::IntegerLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IntegerLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type HexadecimalLiteralContext<'input> = BaseParserRuleContext<'input,HexadecimalLiteralContextExt<'input>>;

pub trait HexadecimalLiteralContextAttrs<'input>: BigqueryParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token HEXADECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token HEXADECIMAL_VALUE
	fn HEXADECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(HEXADECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> HexadecimalLiteralContextAttrs<'input> for HexadecimalLiteralContext<'input>{}

pub struct HexadecimalLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{HexadecimalLiteralContextExt<'a>}

impl<'input> BigqueryParserContext<'input> for HexadecimalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for HexadecimalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_hexadecimalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
		listener.exit_hexadecimalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for HexadecimalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_hexadecimalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for HexadecimalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for HexadecimalLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for HexadecimalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for HexadecimalLiteralContext<'input> {}

impl<'input> HexadecimalLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::HexadecimalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,HexadecimalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn number(&mut self,)
	-> Result<Rc<NumberContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NumberContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 332, RULE_number);
        let mut _localctx: Rc<NumberContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3425);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(448,&mut recog.base)? {
				1 =>{
					let tmp = DecimalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3410);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3409);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3412);
					recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = DoubleLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3414);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3413);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3416);
					recog.base.match_token(DOUBLE_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = IntegerLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3418);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3417);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3420);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = HexadecimalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3422);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3421);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3424);
					recog.base.match_token(HEXADECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonReserved ----------------
pub type NonReservedContextAll<'input> = NonReservedContext<'input>;


pub type NonReservedContext<'input> = BaseParserRuleContext<'input,NonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct NonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> BigqueryParserContext<'input> for NonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn BigqueryListener<'input> + 'a> for NonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonReserved(self);
		}
		fn exit(&self,listener: &mut (dyn BigqueryListener<'input> + 'a)) {
			listener.exit_nonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn BigqueryVisitor<'input> + 'a> for NonReservedContext<'input>{
	fn accept(&self,visitor: &mut (dyn BigqueryVisitor<'input> + 'a)) {
		visitor.visit_nonReserved(self);
	}
}

impl<'input> CustomRuleContext<'input> for NonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = BigqueryParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonReserved }
}
antlr_rust::tid!{NonReservedContextExt<'a>}

impl<'input> NonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn BigqueryParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NonReservedContextAttrs<'input>: BigqueryParserContext<'input> + BorrowMut<NonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ABORT
/// Returns `None` if there is no child corresponding to token ABORT
fn ABORT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ABORT, 0)
}
/// Retrieves first TerminalNode corresponding to token ABSENT
/// Returns `None` if there is no child corresponding to token ABSENT
fn ABSENT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ABSENT, 0)
}
/// Retrieves first TerminalNode corresponding to token ADD
/// Returns `None` if there is no child corresponding to token ADD
fn ADD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token ADMIN
/// Returns `None` if there is no child corresponding to token ADMIN
fn ADMIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ADMIN, 0)
}
/// Retrieves first TerminalNode corresponding to token AFTER
/// Returns `None` if there is no child corresponding to token AFTER
fn AFTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AFTER, 0)
}
/// Retrieves first TerminalNode corresponding to token ALTER
/// Returns `None` if there is no child corresponding to token ALTER
fn ALTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token ANALYZE
/// Returns `None` if there is no child corresponding to token ANALYZE
fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ANALYZE, 0)
}
/// Retrieves first TerminalNode corresponding to token ANTI
/// Returns `None` if there is no child corresponding to token ANTI
fn ANTI(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ANTI, 0)
}
/// Retrieves first TerminalNode corresponding to token ATTACH
/// Returns `None` if there is no child corresponding to token ATTACH
fn ATTACH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ATTACH, 0)
}
/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
/// Returns `None` if there is no child corresponding to token AUTHORIZATION
fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AUTHORIZATION, 0)
}
/// Retrieves first TerminalNode corresponding to token AUTO
/// Returns `None` if there is no child corresponding to token AUTO
fn AUTO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(AUTO, 0)
}
/// Retrieves first TerminalNode corresponding to token BACKUP
/// Returns `None` if there is no child corresponding to token BACKUP
fn BACKUP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BACKUP, 0)
}
/// Retrieves first TerminalNode corresponding to token BEGIN
/// Returns `None` if there is no child corresponding to token BEGIN
fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BEGIN, 0)
}
/// Retrieves first TerminalNode corresponding to token BERNOULLI
/// Returns `None` if there is no child corresponding to token BERNOULLI
fn BERNOULLI(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BERNOULLI, 0)
}
/// Retrieves first TerminalNode corresponding to token BOTH
/// Returns `None` if there is no child corresponding to token BOTH
fn BOTH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BOTH, 0)
}
/// Retrieves first TerminalNode corresponding to token BREAK
/// Returns `None` if there is no child corresponding to token BREAK
fn BREAK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BREAK, 0)
}
/// Retrieves first TerminalNode corresponding to token BZIP2
/// Returns `None` if there is no child corresponding to token BZIP2
fn BZIP2(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(BZIP2, 0)
}
/// Retrieves first TerminalNode corresponding to token CALL
/// Returns `None` if there is no child corresponding to token CALL
fn CALL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CALL, 0)
}
/// Retrieves first TerminalNode corresponding to token CANCEL
/// Returns `None` if there is no child corresponding to token CANCEL
fn CANCEL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CANCEL, 0)
}
/// Retrieves first TerminalNode corresponding to token CASCADE
/// Returns `None` if there is no child corresponding to token CASCADE
fn CASCADE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CASCADE, 0)
}
/// Retrieves first TerminalNode corresponding to token CASE_INSENSITIVE
/// Returns `None` if there is no child corresponding to token CASE_INSENSITIVE
fn CASE_INSENSITIVE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CASE_INSENSITIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token CASE_SENSITIVE
/// Returns `None` if there is no child corresponding to token CASE_SENSITIVE
fn CASE_SENSITIVE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CASE_SENSITIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token CATALOGS
/// Returns `None` if there is no child corresponding to token CATALOGS
fn CATALOGS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CATALOGS, 0)
}
/// Retrieves first TerminalNode corresponding to token CHARACTER
/// Returns `None` if there is no child corresponding to token CHARACTER
fn CHARACTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CHARACTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CLONE
/// Returns `None` if there is no child corresponding to token CLONE
fn CLONE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CLONE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSE
/// Returns `None` if there is no child corresponding to token CLOSE
fn CLOSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CLOSE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token COALESCE
/// Returns `None` if there is no child corresponding to token COALESCE
fn COALESCE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COALESCE, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMN
/// Returns `None` if there is no child corresponding to token COLUMN
fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMNS
/// Returns `None` if there is no child corresponding to token COLUMNS
fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMIT
/// Returns `None` if there is no child corresponding to token COMMIT
fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMITTED
/// Returns `None` if there is no child corresponding to token COMMITTED
fn COMMITTED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMMITTED, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPOUND
/// Returns `None` if there is no child corresponding to token COMPOUND
fn COMPOUND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMPOUND, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPRESSION
/// Returns `None` if there is no child corresponding to token COMPRESSION
fn COMPRESSION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COMPRESSION, 0)
}
/// Retrieves first TerminalNode corresponding to token CONDITIONAL
/// Returns `None` if there is no child corresponding to token CONDITIONAL
fn CONDITIONAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CONDITIONAL, 0)
}
/// Retrieves first TerminalNode corresponding to token CONNECT
/// Returns `None` if there is no child corresponding to token CONNECT
fn CONNECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CONNECT, 0)
}
/// Retrieves first TerminalNode corresponding to token CONNECTION
/// Returns `None` if there is no child corresponding to token CONNECTION
fn CONNECTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CONNECTION, 0)
}
/// Retrieves first TerminalNode corresponding to token CONSTRAINT
/// Returns `None` if there is no child corresponding to token CONSTRAINT
fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTINUE
/// Returns `None` if there is no child corresponding to token CONTINUE
fn CONTINUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CONTINUE, 0)
}
/// Retrieves first TerminalNode corresponding to token COPARTITION
/// Returns `None` if there is no child corresponding to token COPARTITION
fn COPARTITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COPARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token COPY
/// Returns `None` if there is no child corresponding to token COPY
fn COPY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COPY, 0)
}
/// Retrieves first TerminalNode corresponding to token COUNT
/// Returns `None` if there is no child corresponding to token COUNT
fn COUNT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(COUNT, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_ROLE
/// Returns `None` if there is no child corresponding to token CURRENT_ROLE
fn CURRENT_ROLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token CUSTOM_HOLIDAY
/// Returns `None` if there is no child corresponding to token CUSTOM_HOLIDAY
fn CUSTOM_HOLIDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(CUSTOM_HOLIDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DATA
/// Returns `None` if there is no child corresponding to token DATA
fn DATA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATASHARE
/// Returns `None` if there is no child corresponding to token DATASHARE
fn DATASHARE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATASHARE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATETIME
/// Returns `None` if there is no child corresponding to token DATETIME
fn DATETIME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATETIME, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE_DIFF
/// Returns `None` if there is no child corresponding to token DATE_DIFF
fn DATE_DIFF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATE_DIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DATETIME_DIFF
/// Returns `None` if there is no child corresponding to token DATETIME_DIFF
fn DATETIME_DIFF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DATETIME_DIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYOFWEEK
/// Returns `None` if there is no child corresponding to token DAYOFWEEK
fn DAYOFWEEK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DAYOFWEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYOFYEAR
/// Returns `None` if there is no child corresponding to token DAYOFYEAR
fn DAYOFYEAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DAYOFYEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token DEALLOCATE
/// Returns `None` if there is no child corresponding to token DEALLOCATE
fn DEALLOCATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DEALLOCATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULTS
/// Returns `None` if there is no child corresponding to token DEFAULTS
fn DEFAULTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DEFAULTS, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINER
/// Returns `None` if there is no child corresponding to token DEFINER
fn DEFINER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DEFINER, 0)
}
/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITED
/// Returns `None` if there is no child corresponding to token DELIMITED
fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DELIMITED, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITER
/// Returns `None` if there is no child corresponding to token DELIMITER
fn DELIMITER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DELIMITER, 0)
}
/// Retrieves first TerminalNode corresponding to token DENY
/// Returns `None` if there is no child corresponding to token DENY
fn DENY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DENY, 0)
}
/// Retrieves first TerminalNode corresponding to token DESCRIBE
/// Returns `None` if there is no child corresponding to token DESCRIBE
fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DESCRIBE, 0)
}
/// Retrieves first TerminalNode corresponding to token DESCRIPTOR
/// Returns `None` if there is no child corresponding to token DESCRIPTOR
fn DESCRIPTOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DESCRIPTOR, 0)
}
/// Retrieves first TerminalNode corresponding to token DETACH
/// Returns `None` if there is no child corresponding to token DETACH
fn DETACH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DETACH, 0)
}
/// Retrieves first TerminalNode corresponding to token DETERMINISTIC
/// Returns `None` if there is no child corresponding to token DETERMINISTIC
fn DETERMINISTIC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DETERMINISTIC, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTKEY
/// Returns `None` if there is no child corresponding to token DISTKEY
fn DISTKEY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DISTKEY, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTRIBUTED
/// Returns `None` if there is no child corresponding to token DISTRIBUTED
fn DISTRIBUTED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DISTRIBUTED, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTSTYLE
/// Returns `None` if there is no child corresponding to token DISTSTYLE
fn DISTSTYLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DISTSTYLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DO
/// Returns `None` if there is no child corresponding to token DO
fn DO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DO, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DROP
/// Returns `None` if there is no child corresponding to token DROP
fn DROP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token ELSEIF
/// Returns `None` if there is no child corresponding to token ELSEIF
fn ELSEIF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ELSEIF, 0)
}
/// Retrieves first TerminalNode corresponding to token EMPTY
/// Returns `None` if there is no child corresponding to token EMPTY
fn EMPTY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EMPTY, 0)
}
/// Retrieves first TerminalNode corresponding to token ENCODE
/// Returns `None` if there is no child corresponding to token ENCODE
fn ENCODE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ENCODE, 0)
}
/// Retrieves first TerminalNode corresponding to token ENCODING
/// Returns `None` if there is no child corresponding to token ENCODING
fn ENCODING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ENCODING, 0)
}
/// Retrieves first TerminalNode corresponding to token ERROR
/// Returns `None` if there is no child corresponding to token ERROR
fn ERROR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ERROR, 0)
}
/// Retrieves first TerminalNode corresponding to token EVEN
/// Returns `None` if there is no child corresponding to token EVEN
fn EVEN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EVEN, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPTION
/// Returns `None` if there is no child corresponding to token EXCEPTION
fn EXCEPTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXCEPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDING
/// Returns `None` if there is no child corresponding to token EXCLUDING
fn EXCLUDING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDING, 0)
}
/// Retrieves first TerminalNode corresponding to token EXECUTE
/// Returns `None` if there is no child corresponding to token EXECUTE
fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXECUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPLAIN
/// Returns `None` if there is no child corresponding to token EXPLAIN
fn EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXPLAIN, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTERNAL
/// Returns `None` if there is no child corresponding to token EXTERNAL
fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(EXTERNAL, 0)
}
/// Retrieves first TerminalNode corresponding to token FIELDS
/// Returns `None` if there is no child corresponding to token FIELDS
fn FIELDS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FIELDS, 0)
}
/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token FINAL
/// Returns `None` if there is no child corresponding to token FINAL
fn FINAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FINAL, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMAT
/// Returns `None` if there is no child corresponding to token FORMAT
fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FRIDAY
/// Returns `None` if there is no child corresponding to token FRIDAY
fn FRIDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FRIDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTION
/// Returns `None` if there is no child corresponding to token FUNCTION
fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FUNCTION, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTIONS
/// Returns `None` if there is no child corresponding to token FUNCTIONS
fn FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(FUNCTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token GENERATED
/// Returns `None` if there is no child corresponding to token GENERATED
fn GENERATED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GENERATED, 0)
}
/// Retrieves first TerminalNode corresponding to token GRACE
/// Returns `None` if there is no child corresponding to token GRACE
fn GRACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GRACE, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANT
/// Returns `None` if there is no child corresponding to token GRANT
fn GRANT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GRANT, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANTED
/// Returns `None` if there is no child corresponding to token GRANTED
fn GRANTED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GRANTED, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANTS
/// Returns `None` if there is no child corresponding to token GRANTS
fn GRANTS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GRANTS, 0)
}
/// Retrieves first TerminalNode corresponding to token GRAPHVIZ
/// Returns `None` if there is no child corresponding to token GRAPHVIZ
fn GRAPHVIZ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GRAPHVIZ, 0)
}
/// Retrieves first TerminalNode corresponding to token GZIP
/// Returns `None` if there is no child corresponding to token GZIP
fn GZIP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(GZIP, 0)
}
/// Retrieves first TerminalNode corresponding to token HEADER
/// Returns `None` if there is no child corresponding to token HEADER
fn HEADER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(HEADER, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTITY
/// Returns `None` if there is no child corresponding to token IDENTITY
fn IDENTITY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IDENTITY, 0)
}
/// Retrieves first TerminalNode corresponding to token ILIKE
/// Returns `None` if there is no child corresponding to token ILIKE
fn ILIKE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ILIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMMEDIATE
/// Returns `None` if there is no child corresponding to token IMMEDIATE
fn IMMEDIATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IMMEDIATE, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDING
/// Returns `None` if there is no child corresponding to token INCLUDING
fn INCLUDING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INCLUDING, 0)
}
/// Retrieves first TerminalNode corresponding to token INITIAL
/// Returns `None` if there is no child corresponding to token INITIAL
fn INITIAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INITIAL, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUT
/// Returns `None` if there is no child corresponding to token INPUT
fn INPUT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUTFORMAT
/// Returns `None` if there is no child corresponding to token INPUTFORMAT
fn INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERLEAVED
/// Returns `None` if there is no child corresponding to token INTERLEAVED
fn INTERLEAVED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INTERLEAVED, 0)
}
/// Retrieves first TerminalNode corresponding to token INVOKER
/// Returns `None` if there is no child corresponding to token INVOKER
fn INVOKER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(INVOKER, 0)
}
/// Retrieves first TerminalNode corresponding to token IO
/// Returns `None` if there is no child corresponding to token IO
fn IO(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(IO, 0)
}
/// Retrieves first TerminalNode corresponding to token ISOLATION
/// Returns `None` if there is no child corresponding to token ISOLATION
fn ISOLATION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ISOLATION, 0)
}
/// Retrieves first TerminalNode corresponding to token ISOWEEK
/// Returns `None` if there is no child corresponding to token ISOWEEK
fn ISOWEEK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ISOWEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token ISOYEAR
/// Returns `None` if there is no child corresponding to token ISOYEAR
fn ISOYEAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ISOYEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token ITERATE
/// Returns `None` if there is no child corresponding to token ITERATE
fn ITERATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ITERATE, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON
/// Returns `None` if there is no child corresponding to token JSON
fn JSON(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(JSON, 0)
}
/// Retrieves first TerminalNode corresponding to token KEEP
/// Returns `None` if there is no child corresponding to token KEEP
fn KEEP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(KEEP, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEYS
/// Returns `None` if there is no child corresponding to token KEYS
fn KEYS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(KEYS, 0)
}
/// Retrieves first TerminalNode corresponding to token LAMBDA
/// Returns `None` if there is no child corresponding to token LAMBDA
fn LAMBDA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LAMBDA, 0)
}
/// Retrieves first TerminalNode corresponding to token LANGUAGE
/// Returns `None` if there is no child corresponding to token LANGUAGE
fn LANGUAGE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LANGUAGE, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}
/// Retrieves first TerminalNode corresponding to token LEADING
/// Returns `None` if there is no child corresponding to token LEADING
fn LEADING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LEADING, 0)
}
/// Retrieves first TerminalNode corresponding to token LEAVE
/// Returns `None` if there is no child corresponding to token LEAVE
fn LEAVE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LEAVE, 0)
}
/// Retrieves first TerminalNode corresponding to token LEVEL
/// Returns `None` if there is no child corresponding to token LEVEL
fn LEVEL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LEVEL, 0)
}
/// Retrieves first TerminalNode corresponding to token LIBRARY
/// Returns `None` if there is no child corresponding to token LIBRARY
fn LIBRARY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LIBRARY, 0)
}
/// Retrieves first TerminalNode corresponding to token LINES
/// Returns `None` if there is no child corresponding to token LINES
fn LINES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LINES, 0)
}
/// Retrieves first TerminalNode corresponding to token LISTAGG
/// Returns `None` if there is no child corresponding to token LISTAGG
fn LISTAGG(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LISTAGG, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCAL
/// Returns `None` if there is no child corresponding to token LOCAL
fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LOCAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCK
/// Returns `None` if there is no child corresponding to token LOCK
fn LOCK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token LOGICAL
/// Returns `None` if there is no child corresponding to token LOGICAL
fn LOGICAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LOGICAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LOOP
/// Returns `None` if there is no child corresponding to token LOOP
fn LOOP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(LOOP, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token MASKING
/// Returns `None` if there is no child corresponding to token MASKING
fn MASKING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MASKING, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCH
/// Returns `None` if there is no child corresponding to token MATCH
fn MATCH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MATCH, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHES
/// Returns `None` if there is no child corresponding to token MATCHES
fn MATCHES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MATCHES, 0)
}
/// Retrieves first TerminalNode corresponding to token MATERIALIZED
/// Returns `None` if there is no child corresponding to token MATERIALIZED
fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token MAX
/// Returns `None` if there is no child corresponding to token MAX
fn MAX(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MAX, 0)
}
/// Retrieves first TerminalNode corresponding to token MEASURES
/// Returns `None` if there is no child corresponding to token MEASURES
fn MEASURES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MEASURES, 0)
}
/// Retrieves first TerminalNode corresponding to token MESSAGE
/// Returns `None` if there is no child corresponding to token MESSAGE
fn MESSAGE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MESSAGE, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MIN
/// Returns `None` if there is no child corresponding to token MIN
fn MIN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MIN, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS_KW
/// Returns `None` if there is no child corresponding to token MINUS_KW
fn MINUS_KW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MINUS_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token MONDAY
/// Returns `None` if there is no child corresponding to token MONDAY
fn MONDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MONDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token MODEL
/// Returns `None` if there is no child corresponding to token MODEL
fn MODEL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MODEL, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token NAME
/// Returns `None` if there is no child corresponding to token NAME
fn NAME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NAME, 0)
}
/// Retrieves first TerminalNode corresponding to token NEXT
/// Returns `None` if there is no child corresponding to token NEXT
fn NEXT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NEXT, 0)
}
/// Retrieves first TerminalNode corresponding to token NFC
/// Returns `None` if there is no child corresponding to token NFC
fn NFC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NFC, 0)
}
/// Retrieves first TerminalNode corresponding to token NFD
/// Returns `None` if there is no child corresponding to token NFD
fn NFD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NFD, 0)
}
/// Retrieves first TerminalNode corresponding to token NFKC
/// Returns `None` if there is no child corresponding to token NFKC
fn NFKC(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NFKC, 0)
}
/// Retrieves first TerminalNode corresponding to token NFKD
/// Returns `None` if there is no child corresponding to token NFKD
fn NFKD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NFKD, 0)
}
/// Retrieves first TerminalNode corresponding to token NONE
/// Returns `None` if there is no child corresponding to token NONE
fn NONE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NONE, 0)
}
/// Retrieves first TerminalNode corresponding to token NORMALIZE
/// Returns `None` if there is no child corresponding to token NORMALIZE
fn NORMALIZE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(NORMALIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token OBJECT
/// Returns `None` if there is no child corresponding to token OBJECT
fn OBJECT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OBJECT, 0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
/// Retrieves first TerminalNode corresponding to token OMIT
/// Returns `None` if there is no child corresponding to token OMIT
fn OMIT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token ONE
/// Returns `None` if there is no child corresponding to token ONE
fn ONE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ONE, 0)
}
/// Retrieves first TerminalNode corresponding to token ONLY
/// Returns `None` if there is no child corresponding to token ONLY
fn ONLY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ONLY, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTION
/// Returns `None` if there is no child corresponding to token OPTION
fn OPTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONS
/// Returns `None` if there is no child corresponding to token OPTIONS
fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTPUT
/// Returns `None` if there is no child corresponding to token OUTPUT
fn OUTPUT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OUTPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token OUTPUTFORMAT
fn OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OUTPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERFLOW
/// Returns `None` if there is no child corresponding to token OVERFLOW
fn OVERFLOW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(OVERFLOW, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONED
/// Returns `None` if there is no child corresponding to token PARTITIONED
fn PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONS
/// Returns `None` if there is no child corresponding to token PARTITIONS
fn PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token PASSING
/// Returns `None` if there is no child corresponding to token PASSING
fn PASSING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PASSING, 0)
}
/// Retrieves first TerminalNode corresponding to token PAST
/// Returns `None` if there is no child corresponding to token PAST
fn PAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PAST, 0)
}
/// Retrieves first TerminalNode corresponding to token PATH
/// Returns `None` if there is no child corresponding to token PATH
fn PATH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PATH, 0)
}
/// Retrieves first TerminalNode corresponding to token PATTERN
/// Returns `None` if there is no child corresponding to token PATTERN
fn PATTERN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PATTERN, 0)
}
/// Retrieves first TerminalNode corresponding to token PER
/// Returns `None` if there is no child corresponding to token PER
fn PER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PER, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENT_KW
/// Returns `None` if there is no child corresponding to token PERCENT_KW
fn PERCENT_KW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PERCENT_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token PERIOD
/// Returns `None` if there is no child corresponding to token PERIOD
fn PERIOD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PERIOD, 0)
}
/// Retrieves first TerminalNode corresponding to token PERMUTE
/// Returns `None` if there is no child corresponding to token PERMUTE
fn PERMUTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PERMUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token PIVOT
/// Returns `None` if there is no child corresponding to token PIVOT
fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token POSITION
/// Returns `None` if there is no child corresponding to token POSITION
fn POSITION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(POSITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PRECISION
/// Returns `None` if there is no child corresponding to token PRECISION
fn PRECISION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PRECISION, 0)
}
/// Retrieves first TerminalNode corresponding to token PREPARE
/// Returns `None` if there is no child corresponding to token PREPARE
fn PREPARE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PREPARE, 0)
}
/// Retrieves first TerminalNode corresponding to token PRIOR
/// Returns `None` if there is no child corresponding to token PRIOR
fn PRIOR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PRIOR, 0)
}
/// Retrieves first TerminalNode corresponding to token PRIVILEGES
/// Returns `None` if there is no child corresponding to token PRIVILEGES
fn PRIVILEGES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PRIVILEGES, 0)
}
/// Retrieves first TerminalNode corresponding to token PROCEDURE
/// Returns `None` if there is no child corresponding to token PROCEDURE
fn PROCEDURE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PROCEDURE, 0)
}
/// Retrieves first TerminalNode corresponding to token PROPERTIES
/// Returns `None` if there is no child corresponding to token PROPERTIES
fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token PRUNE
/// Returns `None` if there is no child corresponding to token PRUNE
fn PRUNE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(PRUNE, 0)
}
/// Retrieves first TerminalNode corresponding to token QUARTER
/// Returns `None` if there is no child corresponding to token QUARTER
fn QUARTER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token QUOTES
/// Returns `None` if there is no child corresponding to token QUOTES
fn QUOTES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(QUOTES, 0)
}
/// Retrieves first TerminalNode corresponding to token RAISE
/// Returns `None` if there is no child corresponding to token RAISE
fn RAISE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RAISE, 0)
}
/// Retrieves first TerminalNode corresponding to token READ
/// Returns `None` if there is no child corresponding to token READ
fn READ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(READ, 0)
}
/// Retrieves first TerminalNode corresponding to token REFRESH
/// Returns `None` if there is no child corresponding to token REFRESH
fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(REFRESH, 0)
}
/// Retrieves first TerminalNode corresponding to token REMOTE
/// Returns `None` if there is no child corresponding to token REMOTE
fn REMOTE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(REMOTE, 0)
}
/// Retrieves first TerminalNode corresponding to token RENAME
/// Returns `None` if there is no child corresponding to token RENAME
fn RENAME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token REPEAT
/// Returns `None` if there is no child corresponding to token REPEAT
fn REPEAT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(REPEAT, 0)
}
/// Retrieves first TerminalNode corresponding to token REPEATABLE
/// Returns `None` if there is no child corresponding to token REPEATABLE
fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(REPEATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token RESET
/// Returns `None` if there is no child corresponding to token RESET
fn RESET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RESET, 0)
}
/// Retrieves first TerminalNode corresponding to token RESTRICT
/// Returns `None` if there is no child corresponding to token RESTRICT
fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURN
/// Returns `None` if there is no child corresponding to token RETURN
fn RETURN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RETURN, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURNING
/// Returns `None` if there is no child corresponding to token RETURNING
fn RETURNING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RETURNING, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURNS
/// Returns `None` if there is no child corresponding to token RETURNS
fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RETURNS, 0)
}
/// Retrieves first TerminalNode corresponding to token REVOKE
/// Returns `None` if there is no child corresponding to token REVOKE
fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(REVOKE, 0)
}
/// Retrieves first TerminalNode corresponding to token RLS
/// Returns `None` if there is no child corresponding to token RLS
fn RLS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RLS, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLE
/// Returns `None` if there is no child corresponding to token ROLE
fn ROLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLES
/// Returns `None` if there is no child corresponding to token ROLES
fn ROLES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ROLES, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLBACK
/// Returns `None` if there is no child corresponding to token ROLLBACK
fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ROLLBACK, 0)
}
/// Retrieves first TerminalNode corresponding to token ROW
/// Returns `None` if there is no child corresponding to token ROW
fn ROW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token RUNNING
/// Returns `None` if there is no child corresponding to token RUNNING
fn RUNNING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(RUNNING, 0)
}
/// Retrieves first TerminalNode corresponding to token SAFE
/// Returns `None` if there is no child corresponding to token SAFE
fn SAFE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SAFE, 0)
}
/// Retrieves first TerminalNode corresponding to token SAFE_CAST
/// Returns `None` if there is no child corresponding to token SAFE_CAST
fn SAFE_CAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SAFE_CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token SATURDAY
/// Returns `None` if there is no child corresponding to token SATURDAY
fn SATURDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SATURDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token SCALAR
/// Returns `None` if there is no child corresponding to token SCALAR
fn SCALAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SCALAR, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMA
/// Returns `None` if there is no child corresponding to token SCHEMA
fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SCHEMA, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMAS
/// Returns `None` if there is no child corresponding to token SCHEMAS
fn SCHEMAS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SCHEMAS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token SECURITY
/// Returns `None` if there is no child corresponding to token SECURITY
fn SECURITY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SECURITY, 0)
}
/// Retrieves first TerminalNode corresponding to token SEEK
/// Returns `None` if there is no child corresponding to token SEEK
fn SEEK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token SEMI
/// Returns `None` if there is no child corresponding to token SEMI
fn SEMI(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDE
/// Returns `None` if there is no child corresponding to token SERDE
fn SERDE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SERDE, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SERDEPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token SERIALIZABLE
/// Returns `None` if there is no child corresponding to token SERIALIZABLE
fn SERIALIZABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SERIALIZABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token SESSION
/// Returns `None` if there is no child corresponding to token SESSION
fn SESSION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SESSION, 0)
}
/// Retrieves first TerminalNode corresponding to token SETS
/// Returns `None` if there is no child corresponding to token SETS
fn SETS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SETS, 0)
}
/// Retrieves first TerminalNode corresponding to token SHOW
/// Returns `None` if there is no child corresponding to token SHOW
fn SHOW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token SIMILAR
/// Returns `None` if there is no child corresponding to token SIMILAR
fn SIMILAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SIMILAR, 0)
}
/// Retrieves first TerminalNode corresponding to token SNAPSHOT
/// Returns `None` if there is no child corresponding to token SNAPSHOT
fn SNAPSHOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SNAPSHOT, 0)
}
/// Retrieves first TerminalNode corresponding to token SORTKEY
/// Returns `None` if there is no child corresponding to token SORTKEY
fn SORTKEY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SORTKEY, 0)
}
/// Retrieves first TerminalNode corresponding to token SOURCE
/// Returns `None` if there is no child corresponding to token SOURCE
fn SOURCE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token START
/// Returns `None` if there is no child corresponding to token START
fn START(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(START, 0)
}
/// Retrieves first TerminalNode corresponding to token STATS
/// Returns `None` if there is no child corresponding to token STATS
fn STATS(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(STATS, 0)
}
/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token STRING_KW
/// Returns `None` if there is no child corresponding to token STRING_KW
fn STRING_KW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(STRING_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSET
/// Returns `None` if there is no child corresponding to token SUBSET
fn SUBSET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SUBSET, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSTRING
/// Returns `None` if there is no child corresponding to token SUBSTRING
fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SUBSTRING, 0)
}
/// Retrieves first TerminalNode corresponding to token SUNDAY
/// Returns `None` if there is no child corresponding to token SUNDAY
fn SUNDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SUNDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM
/// Returns `None` if there is no child corresponding to token SYSTEM
fn SYSTEM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLES
/// Returns `None` if there is no child corresponding to token TABLES
fn TABLES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TABLES, 0)
}
/// Retrieves first TerminalNode corresponding to token TARGET
/// Returns `None` if there is no child corresponding to token TARGET
fn TARGET(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TARGET, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMP
/// Returns `None` if there is no child corresponding to token TEMP
fn TEMP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TEMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMPORARY
/// Returns `None` if there is no child corresponding to token TEMPORARY
fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token TERMINATED
/// Returns `None` if there is no child corresponding to token TERMINATED
fn TERMINATED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token TEXT
/// Returns `None` if there is no child corresponding to token TEXT
fn TEXT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TEXT, 0)
}
/// Retrieves first TerminalNode corresponding to token THURSDAY
/// Returns `None` if there is no child corresponding to token THURSDAY
fn THURSDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(THURSDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token TIES
/// Returns `None` if there is no child corresponding to token TIES
fn TIES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TIES, 0)
}
/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_DIFF
/// Returns `None` if there is no child corresponding to token TIMESTAMP_DIFF
fn TIMESTAMP_DIFF(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_DIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token TOP
/// Returns `None` if there is no child corresponding to token TOP
fn TOP(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TOP, 0)
}
/// Retrieves first TerminalNode corresponding to token TRAILING
/// Returns `None` if there is no child corresponding to token TRAILING
fn TRAILING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRAILING, 0)
}
/// Retrieves first TerminalNode corresponding to token TRAINING_DATA
/// Returns `None` if there is no child corresponding to token TRAINING_DATA
fn TRAINING_DATA(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRAINING_DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTION
/// Returns `None` if there is no child corresponding to token TRANSACTION
fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSFORM
/// Returns `None` if there is no child corresponding to token TRANSFORM
fn TRANSFORM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRANSFORM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRIM
/// Returns `None` if there is no child corresponding to token TRIM
fn TRIM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRIM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUNCATE
/// Returns `None` if there is no child corresponding to token TRUNCATE
fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRUNCATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRY_CAST
/// Returns `None` if there is no child corresponding to token TRY_CAST
fn TRY_CAST(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TRY_CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token TUESDAY
/// Returns `None` if there is no child corresponding to token TUESDAY
fn TUESDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TUESDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token TUPLE
/// Returns `None` if there is no child corresponding to token TUPLE
fn TUPLE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TUPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token UESCAPE
/// Returns `None` if there is no child corresponding to token UESCAPE
fn UESCAPE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UESCAPE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNCOMMITTED
/// Returns `None` if there is no child corresponding to token UNCOMMITTED
fn UNCOMMITTED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNCOMMITTED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNCONDITIONAL
/// Returns `None` if there is no child corresponding to token UNCONDITIONAL
fn UNCONDITIONAL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNCONDITIONAL, 0)
}
/// Retrieves first TerminalNode corresponding to token UNKNOWN
/// Returns `None` if there is no child corresponding to token UNKNOWN
fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNKNOWN, 0)
}
/// Retrieves first TerminalNode corresponding to token UNLOAD
/// Returns `None` if there is no child corresponding to token UNLOAD
fn UNLOAD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNLOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token UNMATCHED
/// Returns `None` if there is no child corresponding to token UNMATCHED
fn UNMATCHED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNMATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNPIVOT
/// Returns `None` if there is no child corresponding to token UNPIVOT
fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNPIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token UNSIGNED
/// Returns `None` if there is no child corresponding to token UNSIGNED
fn UNSIGNED(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNSIGNED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNTIL
/// Returns `None` if there is no child corresponding to token UNTIL
fn UNTIL(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UNTIL, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token USE
/// Returns `None` if there is no child corresponding to token USE
fn USE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(USE, 0)
}
/// Retrieves first TerminalNode corresponding to token USER
/// Returns `None` if there is no child corresponding to token USER
fn USER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(USER, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF16
/// Returns `None` if there is no child corresponding to token UTF16
fn UTF16(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UTF16, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF32
/// Returns `None` if there is no child corresponding to token UTF32
fn UTF32(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UTF32, 0)
}
/// Retrieves first TerminalNode corresponding to token UTF8
/// Returns `None` if there is no child corresponding to token UTF8
fn UTF8(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(UTF8, 0)
}
/// Retrieves first TerminalNode corresponding to token VACUUM
/// Returns `None` if there is no child corresponding to token VACUUM
fn VACUUM(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VACUUM, 0)
}
/// Retrieves first TerminalNode corresponding to token VALIDATE
/// Returns `None` if there is no child corresponding to token VALIDATE
fn VALIDATE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VALIDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUE
/// Returns `None` if there is no child corresponding to token VALUE
fn VALUE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
/// Retrieves first TerminalNode corresponding to token VARYING
/// Returns `None` if there is no child corresponding to token VARYING
fn VARYING(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VARYING, 0)
}
/// Retrieves first TerminalNode corresponding to token VERBOSE
/// Returns `None` if there is no child corresponding to token VERBOSE
fn VERBOSE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VERBOSE, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token WEDNESDAY
/// Returns `None` if there is no child corresponding to token WEDNESDAY
fn WEDNESDAY(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WEDNESDAY, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token WHILE
/// Returns `None` if there is no child corresponding to token WHILE
fn WHILE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WHILE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHOUT
/// Returns `None` if there is no child corresponding to token WITHOUT
fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WITHOUT, 0)
}
/// Retrieves first TerminalNode corresponding to token WORK
/// Returns `None` if there is no child corresponding to token WORK
fn WORK(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WORK, 0)
}
/// Retrieves first TerminalNode corresponding to token WRAPPER
/// Returns `None` if there is no child corresponding to token WRAPPER
fn WRAPPER(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WRAPPER, 0)
}
/// Retrieves first TerminalNode corresponding to token WRITE
/// Returns `None` if there is no child corresponding to token WRITE
fn WRITE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(WRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token XZ
/// Returns `None` if there is no child corresponding to token XZ
fn XZ(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(XZ, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token YES
/// Returns `None` if there is no child corresponding to token YES
fn YES(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(YES, 0)
}
/// Retrieves first TerminalNode corresponding to token ZONE
/// Returns `None` if there is no child corresponding to token ZONE
fn ZONE(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ZONE, 0)
}
/// Retrieves first TerminalNode corresponding to token ZSTD
/// Returns `None` if there is no child corresponding to token ZSTD
fn ZSTD(&self) -> Option<Rc<TerminalNode<'input,BigqueryParserContextType>>> where Self:Sized{
	self.get_token(ZSTD, 0)
}

}

impl<'input> NonReservedContextAttrs<'input> for NonReservedContext<'input>{}

impl<'input, I, H> BigqueryParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonReserved(&mut self,)
	-> Result<Rc<NonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 334, RULE_nonReserved);
        let mut _localctx: Rc<NonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3427);
			_la = recog.base.input.la(1);
			if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ABORT) | (1usize << ABSENT) | (1usize << ADD) | (1usize << ADMIN) | (1usize << AFTER) | (1usize << ALTER) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ATTACH) | (1usize << AUTHORIZATION) | (1usize << AUTO) | (1usize << BACKUP) | (1usize << BEGIN) | (1usize << BERNOULLI) | (1usize << BOTH) | (1usize << BREAK))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (BZIP2 - 33)) | (1usize << (CALL - 33)) | (1usize << (CANCEL - 33)) | (1usize << (CASCADE - 33)) | (1usize << (CASE_SENSITIVE - 33)) | (1usize << (CASE_INSENSITIVE - 33)) | (1usize << (CATALOGS - 33)) | (1usize << (CHARACTER - 33)) | (1usize << (CLONE - 33)) | (1usize << (CLOSE - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (COALESCE - 33)) | (1usize << (COLUMN - 33)) | (1usize << (COLUMNS - 33)) | (1usize << (COMMENT - 33)) | (1usize << (COMMIT - 33)) | (1usize << (COMMITTED - 33)) | (1usize << (COMPOUND - 33)) | (1usize << (COMPRESSION - 33)) | (1usize << (CONDITIONAL - 33)) | (1usize << (CONNECT - 33)) | (1usize << (CONNECTION - 33)) | (1usize << (CONSTRAINT - 33)) | (1usize << (CONTINUE - 33)) | (1usize << (COPARTITION - 33)) | (1usize << (COPY - 33)) | (1usize << (COUNT - 33)))) != 0) || ((((_la - 68)) & !0x3f) == 0 && ((1usize << (_la - 68)) & ((1usize << (CURRENT_ROLE - 68)) | (1usize << (CUSTOM_HOLIDAY - 68)) | (1usize << (DATA - 68)) | (1usize << (DATABASE - 68)) | (1usize << (DATASHARE - 68)) | (1usize << (DATE - 68)) | (1usize << (DATETIME - 68)) | (1usize << (DAY - 68)) | (1usize << (DAYOFWEEK - 68)) | (1usize << (DAYOFYEAR - 68)) | (1usize << (DATETIME_DIFF - 68)) | (1usize << (DATE_DIFF - 68)) | (1usize << (DEALLOCATE - 68)) | (1usize << (DECLARE - 68)) | (1usize << (DEFAULTS - 68)) | (1usize << (DEFINER - 68)) | (1usize << (DELETE - 68)) | (1usize << (DELIMITED - 68)) | (1usize << (DELIMITER - 68)) | (1usize << (DENY - 68)) | (1usize << (DESCRIBE - 68)) | (1usize << (DESCRIPTOR - 68)) | (1usize << (DETERMINISTIC - 68)) | (1usize << (DISTKEY - 68)) | (1usize << (DISTRIBUTED - 68)) | (1usize << (DISTSTYLE - 68)) | (1usize << (DETACH - 68)) | (1usize << (DO - 68)))) != 0) || ((((_la - 100)) & !0x3f) == 0 && ((1usize << (_la - 100)) & ((1usize << (DOUBLE - 100)) | (1usize << (DROP - 100)) | (1usize << (ELSEIF - 100)) | (1usize << (EMPTY - 100)) | (1usize << (ENCODE - 100)) | (1usize << (ENCODING - 100)) | (1usize << (ERROR - 100)) | (1usize << (EVEN - 100)) | (1usize << (EXCEPTION - 100)) | (1usize << (EXCLUDING - 100)) | (1usize << (EXECUTE - 100)) | (1usize << (EXPLAIN - 100)) | (1usize << (EXTERNAL - 100)) | (1usize << (FIELDS - 100)) | (1usize << (FILTER - 100)) | (1usize << (FINAL - 100)) | (1usize << (FIRST - 100)) | (1usize << (FORMAT - 100)) | (1usize << (FRIDAY - 100)))) != 0) || ((((_la - 132)) & !0x3f) == 0 && ((1usize << (_la - 132)) & ((1usize << (FUNCTION - 132)) | (1usize << (FUNCTIONS - 132)) | (1usize << (GENERATED - 132)) | (1usize << (GRACE - 132)) | (1usize << (GRANT - 132)) | (1usize << (GRANTED - 132)) | (1usize << (GRANTS - 132)) | (1usize << (GRAPHVIZ - 132)) | (1usize << (GZIP - 132)) | (1usize << (HEADER - 132)) | (1usize << (HOUR - 132)) | (1usize << (IDENTITY - 132)) | (1usize << (IMMEDIATE - 132)) | (1usize << (INCLUDE - 132)) | (1usize << (INCLUDING - 132)) | (1usize << (INITIAL - 132)) | (1usize << (INPUT - 132)) | (1usize << (INPUTFORMAT - 132)) | (1usize << (INTERLEAVED - 132)) | (1usize << (INSERT - 132)) | (1usize << (INVOKER - 132)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (IO - 164)) | (1usize << (ISOLATION - 164)) | (1usize << (ISOWEEK - 164)) | (1usize << (ISOYEAR - 164)) | (1usize << (ITERATE - 164)) | (1usize << (ILIKE - 164)) | (1usize << (JSON - 164)) | (1usize << (KEEP - 164)) | (1usize << (KEY - 164)) | (1usize << (KEYS - 164)) | (1usize << (LAMBDA - 164)) | (1usize << (LANGUAGE - 164)) | (1usize << (LEAVE - 164)) | (1usize << (LAST - 164)) | (1usize << (LEADING - 164)) | (1usize << (LEVEL - 164)) | (1usize << (LIBRARY - 164)) | (1usize << (LINES - 164)) | (1usize << (LISTAGG - 164)) | (1usize << (LOCAL - 164)) | (1usize << (LOCATION - 164)) | (1usize << (LOCK - 164)) | (1usize << (LOGICAL - 164)) | (1usize << (LOOP - 164)) | (1usize << (MAP - 164)) | (1usize << (MASKING - 164)))) != 0) || ((((_la - 196)) & !0x3f) == 0 && ((1usize << (_la - 196)) & ((1usize << (MATCH - 196)) | (1usize << (MATCHED - 196)) | (1usize << (MATCHES - 196)) | (1usize << (MATERIALIZED - 196)) | (1usize << (MAX - 196)) | (1usize << (MEASURES - 196)) | (1usize << (MESSAGE - 196)) | (1usize << (MICROSECOND - 196)) | (1usize << (MILLISECOND - 196)) | (1usize << (MIN - 196)) | (1usize << (MINUS_KW - 196)) | (1usize << (MINUTE - 196)) | (1usize << (MODEL - 196)) | (1usize << (MONDAY - 196)) | (1usize << (MONTH - 196)) | (1usize << (NAME - 196)) | (1usize << (NEXT - 196)) | (1usize << (NFC - 196)) | (1usize << (NFD - 196)) | (1usize << (NFKC - 196)) | (1usize << (NFKD - 196)) | (1usize << (NONE - 196)) | (1usize << (NORMALIZE - 196)) | (1usize << (OBJECT - 196)))) != 0) || ((((_la - 228)) & !0x3f) == 0 && ((1usize << (_la - 228)) & ((1usize << (OFFSET - 228)) | (1usize << (OMIT - 228)) | (1usize << (ONE - 228)) | (1usize << (ONLY - 228)) | (1usize << (OPTION - 228)) | (1usize << (OPTIONS - 228)) | (1usize << (OUTPUT - 228)) | (1usize << (OUTPUTFORMAT - 228)) | (1usize << (OVERFLOW - 228)) | (1usize << (PARTITIONED - 228)) | (1usize << (PARTITIONS - 228)) | (1usize << (PASSING - 228)) | (1usize << (PAST - 228)) | (1usize << (PATH - 228)) | (1usize << (PATTERN - 228)) | (1usize << (PER - 228)) | (1usize << (PERCENT_KW - 228)) | (1usize << (PERIOD - 228)) | (1usize << (PERMUTE - 228)) | (1usize << (PIVOT - 228)) | (1usize << (POSITION - 228)) | (1usize << (PRECISION - 228)) | (1usize << (PREPARE - 228)) | (1usize << (PRIOR - 228)) | (1usize << (PROCEDURE - 228)))) != 0) || ((((_la - 260)) & !0x3f) == 0 && ((1usize << (_la - 260)) & ((1usize << (PRIVILEGES - 260)) | (1usize << (PROPERTIES - 260)) | (1usize << (PRUNE - 260)) | (1usize << (QUARTER - 260)) | (1usize << (QUOTES - 260)) | (1usize << (RAISE - 260)) | (1usize << (READ - 260)) | (1usize << (REFRESH - 260)) | (1usize << (RENAME - 260)) | (1usize << (REPEATABLE - 260)) | (1usize << (REPLACE - 260)) | (1usize << (RESET - 260)) | (1usize << (RESTRICT - 260)) | (1usize << (RETURN - 260)) | (1usize << (RETURNING - 260)) | (1usize << (REMOTE - 260)) | (1usize << (REPEAT - 260)) | (1usize << (RETURNS - 260)) | (1usize << (REVOKE - 260)) | (1usize << (RLS - 260)) | (1usize << (ROLE - 260)) | (1usize << (ROLES - 260)) | (1usize << (ROLLBACK - 260)) | (1usize << (ROW - 260)) | (1usize << (RUNNING - 260)))) != 0) || ((((_la - 292)) & !0x3f) == 0 && ((1usize << (_la - 292)) & ((1usize << (SAFE - 292)) | (1usize << (SAFE_CAST - 292)) | (1usize << (SATURDAY - 292)) | (1usize << (SCALAR - 292)) | (1usize << (SECOND - 292)) | (1usize << (SCHEMA - 292)) | (1usize << (SCHEMAS - 292)) | (1usize << (SECURITY - 292)) | (1usize << (SEEK - 292)) | (1usize << (SEMI - 292)) | (1usize << (SERDE - 292)) | (1usize << (SERDEPROPERTIES - 292)) | (1usize << (SERIALIZABLE - 292)) | (1usize << (SESSION - 292)) | (1usize << (SETS - 292)) | (1usize << (SHOW - 292)) | (1usize << (SIMILAR - 292)) | (1usize << (SNAPSHOT - 292)) | (1usize << (SORTKEY - 292)) | (1usize << (START - 292)) | (1usize << (STATS - 292)) | (1usize << (STORED - 292)) | (1usize << (SUBSET - 292)) | (1usize << (SUBSTRING - 292)) | (1usize << (SUNDAY - 292)) | (1usize << (SYSTEM - 292)) | (1usize << (SYSTEM_TIME - 292)) | (1usize << (TABLE - 292)))) != 0) || ((((_la - 324)) & !0x3f) == 0 && ((1usize << (_la - 324)) & ((1usize << (TABLES - 324)) | (1usize << (TEMP - 324)) | (1usize << (TEMPORARY - 324)) | (1usize << (TERMINATED - 324)) | (1usize << (TEXT - 324)) | (1usize << (STRING_KW - 324)) | (1usize << (THURSDAY - 324)) | (1usize << (TIES - 324)) | (1usize << (TIME - 324)) | (1usize << (TIMESTAMP - 324)) | (1usize << (TIMESTAMP_DIFF - 324)) | (1usize << (TOP - 324)) | (1usize << (TRAILING - 324)) | (1usize << (TARGET - 324)) | (1usize << (SOURCE - 324)) | (1usize << (TRAINING_DATA - 324)) | (1usize << (TRANSACTION - 324)) | (1usize << (TRANSFORM - 324)) | (1usize << (TRIM - 324)) | (1usize << (TRUNCATE - 324)) | (1usize << (TRY_CAST - 324)) | (1usize << (TUPLE - 324)) | (1usize << (TUESDAY - 324)) | (1usize << (TYPE - 324)) | (1usize << (UESCAPE - 324)) | (1usize << (UNCOMMITTED - 324)) | (1usize << (UNCONDITIONAL - 324)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNKNOWN - 357)) | (1usize << (UNLOAD - 357)) | (1usize << (UNMATCHED - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSIGNED - 357)) | (1usize << (UNTIL - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (UTF16 - 357)) | (1usize << (UTF32 - 357)) | (1usize << (UTF8 - 357)) | (1usize << (VACUUM - 357)) | (1usize << (VALIDATE - 357)) | (1usize << (VALUE - 357)) | (1usize << (VALUES - 357)) | (1usize << (VARYING - 357)) | (1usize << (VERBOSE - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (WEDNESDAY - 357)) | (1usize << (WEEK - 357)) | (1usize << (WHILE - 357)) | (1usize << (WITHOUT - 357)) | (1usize << (WORK - 357)) | (1usize << (WRAPPER - 357)))) != 0) || ((((_la - 389)) & !0x3f) == 0 && ((1usize << (_la - 389)) & ((1usize << (WRITE - 389)) | (1usize << (XZ - 389)) | (1usize << (YEAR - 389)) | (1usize << (YES - 389)) | (1usize << (ZONE - 389)) | (1usize << (ZSTD - 389)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}

thread_local! {
    static _ATN: Rc<ATN> =
        Rc::new(ATNDeserializer::new(None).deserialize(_serializedATN.chars()));
    static _decision_to_DFA: Rc<Vec<RefCell<DFA>>> = {
        let mut dfa = Vec::new();
        let size = _ATN.with(|atn| atn.decision_to_state.len());
        for i in 0..size {
            dfa.push(DFA::new(_ATN.with(|atn| atn.clone()), _ATN.with(|atn| atn
            .get_decision_state(i)), i as isize).into())
        }
        Rc::new(dfa)
    };
}



const _serializedATN:&'static str =
	"\x03\u{608b}\u{a72a}\u{8133}\u{b9ed}\u{417c}\u{3be7}\u{7786}\u{5964}\x03\
	\u{1ba}\u{d68}\x04\x02\x09\x02\x04\x03\x09\x03\x04\x04\x09\x04\x04\x05\x09\
	\x05\x04\x06\x09\x06\x04\x07\x09\x07\x04\x08\x09\x08\x04\x09\x09\x09\x04\
	\x0a\x09\x0a\x04\x0b\x09\x0b\x04\x0c\x09\x0c\x04\x0d\x09\x0d\x04\x0e\x09\
	\x0e\x04\x0f\x09\x0f\x04\x10\x09\x10\x04\x11\x09\x11\x04\x12\x09\x12\x04\
	\x13\x09\x13\x04\x14\x09\x14\x04\x15\x09\x15\x04\x16\x09\x16\x04\x17\x09\
	\x17\x04\x18\x09\x18\x04\x19\x09\x19\x04\x1a\x09\x1a\x04\x1b\x09\x1b\x04\
	\x1c\x09\x1c\x04\x1d\x09\x1d\x04\x1e\x09\x1e\x04\x1f\x09\x1f\x04\x20\x09\
	\x20\x04\x21\x09\x21\x04\x22\x09\x22\x04\x23\x09\x23\x04\x24\x09\x24\x04\
	\x25\x09\x25\x04\x26\x09\x26\x04\x27\x09\x27\x04\x28\x09\x28\x04\x29\x09\
	\x29\x04\x2a\x09\x2a\x04\x2b\x09\x2b\x04\x2c\x09\x2c\x04\x2d\x09\x2d\x04\
	\x2e\x09\x2e\x04\x2f\x09\x2f\x04\x30\x09\x30\x04\x31\x09\x31\x04\x32\x09\
	\x32\x04\x33\x09\x33\x04\x34\x09\x34\x04\x35\x09\x35\x04\x36\x09\x36\x04\
	\x37\x09\x37\x04\x38\x09\x38\x04\x39\x09\x39\x04\x3a\x09\x3a\x04\x3b\x09\
	\x3b\x04\x3c\x09\x3c\x04\x3d\x09\x3d\x04\x3e\x09\x3e\x04\x3f\x09\x3f\x04\
	\x40\x09\x40\x04\x41\x09\x41\x04\x42\x09\x42\x04\x43\x09\x43\x04\x44\x09\
	\x44\x04\x45\x09\x45\x04\x46\x09\x46\x04\x47\x09\x47\x04\x48\x09\x48\x04\
	\x49\x09\x49\x04\x4a\x09\x4a\x04\x4b\x09\x4b\x04\x4c\x09\x4c\x04\x4d\x09\
	\x4d\x04\x4e\x09\x4e\x04\x4f\x09\x4f\x04\x50\x09\x50\x04\x51\x09\x51\x04\
	\x52\x09\x52\x04\x53\x09\x53\x04\x54\x09\x54\x04\x55\x09\x55\x04\x56\x09\
	\x56\x04\x57\x09\x57\x04\x58\x09\x58\x04\x59\x09\x59\x04\x5a\x09\x5a\x04\
	\x5b\x09\x5b\x04\x5c\x09\x5c\x04\x5d\x09\x5d\x04\x5e\x09\x5e\x04\x5f\x09\
	\x5f\x04\x60\x09\x60\x04\x61\x09\x61\x04\x62\x09\x62\x04\x63\x09\x63\x04\
	\x64\x09\x64\x04\x65\x09\x65\x04\x66\x09\x66\x04\x67\x09\x67\x04\x68\x09\
	\x68\x04\x69\x09\x69\x04\x6a\x09\x6a\x04\x6b\x09\x6b\x04\x6c\x09\x6c\x04\
	\x6d\x09\x6d\x04\x6e\x09\x6e\x04\x6f\x09\x6f\x04\x70\x09\x70\x04\x71\x09\
	\x71\x04\x72\x09\x72\x04\x73\x09\x73\x04\x74\x09\x74\x04\x75\x09\x75\x04\
	\x76\x09\x76\x04\x77\x09\x77\x04\x78\x09\x78\x04\x79\x09\x79\x04\x7a\x09\
	\x7a\x04\x7b\x09\x7b\x04\x7c\x09\x7c\x04\x7d\x09\x7d\x04\x7e\x09\x7e\x04\
	\x7f\x09\x7f\x04\u{80}\x09\u{80}\x04\u{81}\x09\u{81}\x04\u{82}\x09\u{82}\
	\x04\u{83}\x09\u{83}\x04\u{84}\x09\u{84}\x04\u{85}\x09\u{85}\x04\u{86}\x09\
	\u{86}\x04\u{87}\x09\u{87}\x04\u{88}\x09\u{88}\x04\u{89}\x09\u{89}\x04\u{8a}\
	\x09\u{8a}\x04\u{8b}\x09\u{8b}\x04\u{8c}\x09\u{8c}\x04\u{8d}\x09\u{8d}\x04\
	\u{8e}\x09\u{8e}\x04\u{8f}\x09\u{8f}\x04\u{90}\x09\u{90}\x04\u{91}\x09\u{91}\
	\x04\u{92}\x09\u{92}\x04\u{93}\x09\u{93}\x04\u{94}\x09\u{94}\x04\u{95}\x09\
	\u{95}\x04\u{96}\x09\u{96}\x04\u{97}\x09\u{97}\x04\u{98}\x09\u{98}\x04\u{99}\
	\x09\u{99}\x04\u{9a}\x09\u{9a}\x04\u{9b}\x09\u{9b}\x04\u{9c}\x09\u{9c}\x04\
	\u{9d}\x09\u{9d}\x04\u{9e}\x09\u{9e}\x04\u{9f}\x09\u{9f}\x04\u{a0}\x09\u{a0}\
	\x04\u{a1}\x09\u{a1}\x04\u{a2}\x09\u{a2}\x04\u{a3}\x09\u{a3}\x04\u{a4}\x09\
	\u{a4}\x04\u{a5}\x09\u{a5}\x04\u{a6}\x09\u{a6}\x04\u{a7}\x09\u{a7}\x04\u{a8}\
	\x09\u{a8}\x04\u{a9}\x09\u{a9}\x03\x02\x05\x02\u{154}\x0a\x02\x03\x02\x03\
	\x02\x05\x02\u{158}\x0a\x02\x07\x02\u{15a}\x0a\x02\x0c\x02\x0e\x02\u{15d}\
	\x0b\x02\x03\x02\x03\x02\x03\x03\x05\x03\u{162}\x0a\x03\x03\x03\x05\x03\
	\u{165}\x0a\x03\x03\x03\x03\x03\x03\x04\x03\x04\x03\x04\x03\x05\x03\x05\
	\x03\x05\x03\x06\x03\x06\x03\x06\x03\x07\x03\x07\x03\x07\x07\x07\u{175}\
	\x0a\x07\x0c\x07\x0e\x07\u{178}\x0b\x07\x03\x07\x03\x07\x03\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x05\x08\u{188}\x0a\x08\x03\x08\x03\x08\x07\x08\u{18c}\x0a\x08\x0c\
	\x08\x0e\x08\u{18f}\x0b\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\
	\x08\u{1a8}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{1af}\
	\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{1b5}\x0a\x08\x03\x08\
	\x03\x08\x05\x08\u{1b9}\x0a\x08\x03\x08\x05\x08\u{1bc}\x0a\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x05\x08\u{1c2}\x0a\x08\x05\x08\u{1c4}\x0a\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{1cc}\x0a\x08\x03\x08\
	\x05\x08\u{1cf}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{1d5}\x0a\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x05\x08\u{1e1}\x0a\x08\x05\x08\u{1e3}\x0a\x08\x03\x08\x03\x08\
	\x03\x08\x05\x08\u{1e8}\x0a\x08\x03\x08\x03\x08\x05\x08\u{1ec}\x0a\x08\x03\
	\x08\x03\x08\x03\x08\x05\x08\u{1f1}\x0a\x08\x03\x08\x03\x08\x03\x08\x05\
	\x08\u{1f6}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x07\x08\u{1fd}\
	\x0a\x08\x0c\x08\x0e\x08\u{200}\x0b\x08\x05\x08\u{202}\x0a\x08\x03\x08\x03\
	\x08\x05\x08\u{206}\x0a\x08\x03\x08\x03\x08\x05\x08\u{20a}\x0a\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{212}\x0a\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{21c}\
	\x0a\x08\x03\x08\x03\x08\x05\x08\u{220}\x0a\x08\x03\x08\x03\x08\x05\x08\
	\u{224}\x0a\x08\x03\x08\x03\x08\x05\x08\u{228}\x0a\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x05\x08\u{22f}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x05\x08\u{236}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\
	\x08\u{23c}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x07\x08\u{243}\
	\x0a\x08\x0c\x08\x0e\x08\u{246}\x0b\x08\x05\x08\u{248}\x0a\x08\x03\x08\x03\
	\x08\x05\x08\u{24c}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x05\x08\u{254}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{25a}\
	\x0a\x08\x03\x08\x03\x08\x05\x08\u{25e}\x0a\x08\x03\x08\x03\x08\x05\x08\
	\u{262}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{26f}\x0a\x08\x03\x08\x03\x08\
	\x05\x08\u{273}\x0a\x08\x03\x08\x05\x08\u{276}\x0a\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x06\x08\u{27d}\x0a\x08\x0d\x08\x0e\x08\u{27e}\x03\x08\
	\x03\x08\x03\x08\x05\x08\u{284}\x0a\x08\x03\x08\x05\x08\u{287}\x0a\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{28d}\x0a\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x07\x08\u{294}\x0a\x08\x0c\x08\x0e\x08\u{297}\x0b\x08\
	\x03\x08\x05\x08\u{29a}\x0a\x08\x05\x08\u{29c}\x0a\x08\x03\x08\x03\x08\x03\
	\x08\x05\x08\u{2a1}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x05\x08\u{2aa}\x0a\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{2af}\
	\x0a\x08\x03\x08\x05\x08\u{2b2}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x05\x08\u{2b8}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x07\x08\
	\u{2bf}\x0a\x08\x0c\x08\x0e\x08\u{2c2}\x0b\x08\x03\x08\x05\x08\u{2c5}\x0a\
	\x08\x05\x08\u{2c7}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x05\x08\u{2cf}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x05\x08\u{2d8}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{2e3}\x0a\x08\x05\x08\u{2e5}\
	\x0a\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{2ea}\x0a\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x05\x08\u{2f0}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x07\x08\u{2f7}\x0a\x08\x0c\x08\x0e\x08\u{2fa}\x0b\x08\x03\x08\x05\
	\x08\u{2fd}\x0a\x08\x05\x08\u{2ff}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{30b}\x0a\x08\
	\x03\x08\x03\x08\x03\x08\x05\x08\u{310}\x0a\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x05\x08\u{316}\x0a\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{31b}\x0a\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{324}\
	\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\
	\u{32d}\x0a\x08\x03\x08\x03\x08\x05\x08\u{331}\x0a\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x05\x08\u{341}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x07\x08\u{347}\x0a\x08\x0c\x08\x0e\x08\u{34a}\x0b\x08\x03\x08\x05\x08\
	\u{34d}\x0a\x08\x03\x08\x03\x08\x05\x08\u{351}\x0a\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x07\x08\u{35a}\x0a\x08\x0c\x08\x0e\
	\x08\u{35d}\x0b\x08\x05\x08\u{35f}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x07\x08\u{365}\x0a\x08\x0c\x08\x0e\x08\u{368}\x0b\x08\x05\x08\u{36a}\x0a\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{37b}\x0a\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x06\x08\u{382}\x0a\x08\x0d\
	\x08\x0e\x08\u{383}\x03\x08\x03\x08\x05\x08\u{388}\x0a\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x07\x08\u{396}\x0a\x08\x0c\x08\x0e\x08\u{399}\x0b\x08\x03\x08\x03\
	\x08\x05\x08\u{39d}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x05\x08\u{3c9}\x0a\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{3ce}\x0a\x08\
	\x03\x08\x03\x08\x05\x08\u{3d2}\x0a\x08\x03\x08\x03\x08\x05\x08\u{3d6}\x0a\
	\x08\x03\x08\x03\x08\x07\x08\u{3da}\x0a\x08\x0c\x08\x0e\x08\u{3dd}\x0b\x08\
	\x03\x08\x03\x08\x03\x08\x05\x08\u{3e2}\x0a\x08\x03\x08\x03\x08\x07\x08\
	\u{3e6}\x0a\x08\x0c\x08\x0e\x08\u{3e9}\x0b\x08\x03\x08\x03\x08\x07\x08\u{3ed}\
	\x0a\x08\x0c\x08\x0e\x08\u{3f0}\x0b\x08\x03\x08\x03\x08\x07\x08\u{3f4}\x0a\
	\x08\x0c\x08\x0e\x08\u{3f7}\x0b\x08\x03\x08\x03\x08\x07\x08\u{3fb}\x0a\x08\
	\x0c\x08\x0e\x08\u{3fe}\x0b\x08\x03\x08\x03\x08\x07\x08\u{402}\x0a\x08\x0c\
	\x08\x0e\x08\u{405}\x0b\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{40b}\
	\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x05\x08\u{416}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x05\x08\u{41e}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x05\x08\u{426}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x05\x08\u{42d}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x05\x08\u{437}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x05\x08\u{43e}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x05\x08\u{446}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x07\x08\u{468}\x0a\x08\x0c\x08\x0e\x08\u{46b}\x0b\x08\x05\x08\u{46d}\x0a\
	\x08\x03\x08\x05\x08\u{470}\x0a\x08\x03\x08\x05\x08\u{473}\x0a\x08\x03\x08\
	\x03\x08\x05\x08\u{477}\x0a\x08\x03\x08\x03\x08\x07\x08\u{47b}\x0a\x08\x0c\
	\x08\x0e\x08\u{47e}\x0b\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{489}\x0a\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x07\
	\x08\u{4a8}\x0a\x08\x0c\x08\x0e\x08\u{4ab}\x0b\x08\x03\x08\x03\x08\x03\x08\
	\x07\x08\u{4b0}\x0a\x08\x0c\x08\x0e\x08\u{4b3}\x0b\x08\x03\x08\x03\x08\x07\
	\x08\u{4b7}\x0a\x08\x0c\x08\x0e\x08\u{4ba}\x0b\x08\x03\x08\x03\x08\x07\x08\
	\u{4be}\x0a\x08\x0c\x08\x0e\x08\u{4c1}\x0b\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x07\x08\u{4c7}\x0a\x08\x0c\x08\x0e\x08\u{4ca}\x0b\x08\x03\x08\x05\x08\
	\u{4cd}\x0a\x08\x03\x08\x03\x08\x05\x08\u{4d1}\x0a\x08\x03\x08\x03\x08\x05\
	\x08\u{4d5}\x0a\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x07\
	\x08\u{4dd}\x0a\x08\x0c\x08\x0e\x08\u{4e0}\x0b\x08\x03\x08\x03\x08\x07\x08\
	\u{4e4}\x0a\x08\x0c\x08\x0e\x08\u{4e7}\x0b\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x07\x08\u{4ee}\x0a\x08\x0c\x08\x0e\x08\u{4f1}\x0b\x08\x03\x08\
	\x05\x08\u{4f4}\x0a\x08\x05\x08\u{4f6}\x0a\x08\x03\x08\x03\x08\x07\x08\u{4fa}\
	\x0a\x08\x0c\x08\x0e\x08\u{4fd}\x0b\x08\x03\x08\x03\x08\x07\x08\u{501}\x0a\
	\x08\x0c\x08\x0e\x08\u{504}\x0b\x08\x03\x08\x03\x08\x07\x08\u{508}\x0a\x08\
	\x0c\x08\x0e\x08\u{50b}\x0b\x08\x03\x08\x03\x08\x07\x08\u{50f}\x0a\x08\x0c\
	\x08\x0e\x08\u{512}\x0b\x08\x03\x08\x03\x08\x07\x08\u{516}\x0a\x08\x0c\x08\
	\x0e\x08\u{519}\x0b\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\
	\x03\x08\x03\x08\x07\x08\u{523}\x0a\x08\x0c\x08\x0e\x08\u{526}\x0b\x08\x05\
	\x08\u{528}\x0a\x08\x03\x09\x03\x09\x03\x09\x07\x09\u{52d}\x0a\x09\x0c\x09\
	\x0e\x09\u{530}\x0b\x09\x03\x0a\x03\x0a\x03\x0a\x07\x0a\u{535}\x0a\x0a\x0c\
	\x0a\x0e\x0a\u{538}\x0b\x0a\x03\x0b\x03\x0b\x05\x0b\u{53c}\x0a\x0b\x03\x0b\
	\x03\x0b\x05\x0b\u{540}\x0a\x0b\x05\x0b\u{542}\x0a\x0b\x03\x0c\x03\x0c\x03\
	\x0c\x03\x0d\x03\x0d\x03\x0d\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0f\x05\
	\x0f\u{54f}\x0a\x0f\x03\x0f\x03\x0f\x03\x10\x03\x10\x05\x10\u{555}\x0a\x10\
	\x03\x10\x03\x10\x03\x10\x07\x10\u{55a}\x0a\x10\x0c\x10\x0e\x10\u{55d}\x0b\
	\x10\x03\x11\x03\x11\x03\x12\x03\x12\x03\x12\x05\x12\u{564}\x0a\x12\x03\
	\x13\x03\x13\x03\x13\x03\x14\x03\x14\x03\x15\x03\x15\x03\x16\x03\x16\x05\
	\x16\u{56f}\x0a\x16\x03\x16\x05\x16\u{572}\x0a\x16\x03\x16\x03\x16\x03\x16\
	\x05\x16\u{577}\x0a\x16\x03\x16\x05\x16\u{57a}\x0a\x16\x03\x17\x03\x17\x03\
	\x17\x07\x17\u{57f}\x0a\x17\x0c\x17\x0e\x17\u{582}\x0b\x17\x03\x17\x05\x17\
	\u{585}\x0a\x17\x03\x18\x03\x18\x03\x18\x03\x18\x03\x19\x03\x19\x03\x19\
	\x03\x19\x03\x19\x03\x19\x03\x19\x05\x19\u{592}\x0a\x19\x03\x1a\x03\x1a\
	\x03\x1a\x07\x1a\u{597}\x0a\x1a\x0c\x1a\x0e\x1a\u{59a}\x0b\x1a\x03\x1a\x05\
	\x1a\u{59d}\x0a\x1a\x03\x1b\x03\x1b\x03\x1b\x03\x1b\x05\x1b\u{5a3}\x0a\x1b\
	\x05\x1b\u{5a5}\x0a\x1b\x03\x1c\x03\x1c\x03\x1c\x03\x1c\x03\x1c\x03\x1d\
	\x03\x1d\x05\x1d\u{5ae}\x0a\x1d\x03\x1d\x03\x1d\x03\x1e\x03\x1e\x03\x1e\
	\x07\x1e\u{5b5}\x0a\x1e\x0c\x1e\x0e\x1e\u{5b8}\x0b\x1e\x03\x1e\x05\x1e\u{5bb}\
	\x0a\x1e\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x07\x1f\u{5c1}\x0a\x1f\x0c\x1f\
	\x0e\x1f\u{5c4}\x0b\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{5cc}\x0a\x1f\x03\x20\x03\x20\x03\x21\x03\x21\x03\x21\x05\x21\
	\u{5d3}\x0a\x21\x03\x22\x03\x22\x03\x23\x03\x23\x03\x23\x03\x23\x03\x23\
	\x05\x23\u{5dc}\x0a\x23\x05\x23\u{5de}\x0a\x23\x03\x24\x03\x24\x05\x24\u{5e2}\
	\x0a\x24\x03\x25\x03\x25\x03\x26\x03\x26\x03\x27\x03\x27\x03\x28\x03\x28\
	\x03\x28\x03\x28\x07\x28\u{5ee}\x0a\x28\x0c\x28\x0e\x28\u{5f1}\x0b\x28\x03\
	\x29\x03\x29\x05\x29\u{5f5}\x0a\x29\x03\x29\x05\x29\u{5f8}\x0a\x29\x05\x29\
	\u{5fa}\x0a\x29\x03\x29\x03\x29\x03\x29\x03\x29\x05\x29\u{600}\x0a\x29\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x07\x2a\u{606}\x0a\x2a\x0c\x2a\x0e\x2a\u{609}\
	\x0b\x2a\x03\x2b\x03\x2b\x05\x2b\u{60d}\x0a\x2b\x03\x2c\x03\x2c\x03\x2d\
	\x03\x2d\x03\x2d\x03\x2d\x07\x2d\u{615}\x0a\x2d\x0c\x2d\x0e\x2d\u{618}\x0b\
	\x2d\x03\x2d\x05\x2d\u{61b}\x0a\x2d\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\
	\x2e\x03\x2e\x03\x2e\x03\x2e\x05\x2e\u{625}\x0a\x2e\x03\x2f\x03\x2f\x05\
	\x2f\u{629}\x0a\x2f\x03\x2f\x03\x2f\x05\x2f\u{62d}\x0a\x2f\x03\x30\x03\x30\
	\x05\x30\u{631}\x0a\x30\x03\x30\x03\x30\x05\x30\u{635}\x0a\x30\x03\x30\x03\
	\x30\x03\x30\x05\x30\u{63a}\x0a\x30\x03\x30\x03\x30\x05\x30\u{63e}\x0a\x30\
	\x03\x30\x05\x30\u{641}\x0a\x30\x03\x30\x03\x30\x05\x30\u{645}\x0a\x30\x03\
	\x30\x03\x30\x05\x30\u{649}\x0a\x30\x03\x30\x03\x30\x03\x30\x03\x30\x07\
	\x30\u{64f}\x0a\x30\x0c\x30\x0e\x30\u{652}\x0b\x30\x03\x30\x05\x30\u{655}\
	\x0a\x30\x05\x30\u{657}\x0a\x30\x03\x31\x03\x31\x05\x31\u{65b}\x0a\x31\x03\
	\x31\x03\x31\x03\x32\x03\x32\x03\x32\x07\x32\u{662}\x0a\x32\x0c\x32\x0e\
	\x32\u{665}\x0b\x32\x03\x32\x05\x32\u{668}\x0a\x32\x03\x33\x03\x33\x03\x33\
	\x03\x33\x03\x34\x03\x34\x05\x34\u{670}\x0a\x34\x03\x34\x03\x34\x03\x34\
	\x07\x34\u{675}\x0a\x34\x0c\x34\x0e\x34\u{678}\x0b\x34\x03\x34\x05\x34\u{67b}\
	\x0a\x34\x05\x34\u{67d}\x0a\x34\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\
	\x07\x35\u{684}\x0a\x35\x0c\x35\x0e\x35\u{687}\x0b\x35\x03\x35\x05\x35\u{68a}\
	\x0a\x35\x05\x35\u{68c}\x0a\x35\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\
	\x03\x35\x07\x35\u{694}\x0a\x35\x0c\x35\x0e\x35\u{697}\x0b\x35\x03\x35\x05\
	\x35\u{69a}\x0a\x35\x05\x35\u{69c}\x0a\x35\x03\x35\x03\x35\x03\x35\x03\x35\
	\x03\x35\x03\x35\x03\x35\x07\x35\u{6a5}\x0a\x35\x0c\x35\x0e\x35\u{6a8}\x0b\
	\x35\x03\x35\x05\x35\u{6ab}\x0a\x35\x03\x35\x03\x35\x03\x35\x05\x35\u{6b0}\
	\x0a\x35\x03\x36\x03\x36\x03\x36\x03\x36\x07\x36\u{6b6}\x0a\x36\x0c\x36\
	\x0e\x36\u{6b9}\x0b\x36\x05\x36\u{6bb}\x0a\x36\x03\x36\x05\x36\u{6be}\x0a\
	\x36\x03\x36\x03\x36\x05\x36\u{6c2}\x0a\x36\x03\x37\x03\x37\x03\x37\x03\
	\x37\x03\x37\x03\x37\x03\x38\x05\x38\u{6cb}\x0a\x38\x03\x38\x05\x38\u{6ce}\
	\x0a\x38\x03\x38\x05\x38\u{6d1}\x0a\x38\x03\x38\x05\x38\u{6d4}\x0a\x38\x03\
	\x39\x03\x39\x03\x39\x03\x39\x03\x39\x07\x39\u{6db}\x0a\x39\x0c\x39\x0e\
	\x39\u{6de}\x0b\x39\x03\x39\x05\x39\u{6e1}\x0a\x39\x03\x3a\x03\x3a\x03\x3a\
	\x03\x3a\x03\x3a\x07\x3a\u{6e8}\x0a\x3a\x0c\x3a\x0e\x3a\u{6eb}\x0b\x3a\x03\
	\x3a\x05\x3a\u{6ee}\x0a\x3a\x03\x3b\x03\x3b\x03\x3b\x03\x3b\x03\x3b\x03\
	\x3b\x03\x3c\x03\x3c\x03\x3d\x03\x3d\x05\x3d\u{6fa}\x0a\x3d\x03\x3d\x05\
	\x3d\u{6fd}\x0a\x3d\x03\x3d\x05\x3d\u{700}\x0a\x3d\x03\x3e\x03\x3e\x03\x3e\
	\x05\x3e\u{705}\x0a\x3e\x03\x3e\x03\x3e\x03\x3e\x03\x3e\x03\x3e\x07\x3e\
	\u{70c}\x0a\x3e\x0c\x3e\x0e\x3e\u{70f}\x0b\x3e\x03\x3e\x03\x3e\x05\x3e\u{713}\
	\x0a\x3e\x03\x3f\x03\x3f\x03\x3f\x03\x3f\x03\x3f\x05\x3f\u{71a}\x0a\x3f\
	\x03\x40\x03\x40\x03\x41\x03\x41\x03\x41\x03\x41\x03\x41\x03\x41\x03\x41\
	\x03\x41\x05\x41\u{726}\x0a\x41\x03\x41\x03\x41\x03\x41\x03\x41\x03\x41\
	\x03\x41\x05\x41\u{72e}\x0a\x41\x03\x41\x03\x41\x03\x41\x03\x41\x03\x41\
	\x05\x41\u{735}\x0a\x41\x07\x41\u{737}\x0a\x41\x0c\x41\x0e\x41\u{73a}\x0b\
	\x41\x03\x42\x03\x42\x03\x42\x03\x42\x03\x42\x05\x42\u{741}\x0a\x42\x03\
	\x43\x05\x43\u{744}\x0a\x43\x03\x43\x03\x43\x05\x43\u{748}\x0a\x43\x03\x43\
	\x03\x43\x05\x43\u{74c}\x0a\x43\x03\x43\x03\x43\x05\x43\u{750}\x0a\x43\x05\
	\x43\u{752}\x0a\x43\x03\x44\x03\x44\x03\x44\x03\x44\x03\x44\x03\x44\x03\
	\x44\x07\x44\u{75b}\x0a\x44\x0c\x44\x0e\x44\u{75e}\x0b\x44\x03\x44\x05\x44\
	\u{761}\x0a\x44\x03\x44\x03\x44\x05\x44\u{765}\x0a\x44\x03\x45\x03\x45\x03\
	\x46\x03\x46\x05\x46\u{76b}\x0a\x46\x03\x47\x03\x47\x03\x47\x03\x47\x03\
	\x47\x03\x47\x03\x47\x03\x48\x03\x48\x03\x49\x03\x49\x03\x4a\x03\x4a\x03\
	\x4a\x05\x4a\u{77b}\x0a\x4a\x03\x4a\x05\x4a\u{77e}\x0a\x4a\x03\x4b\x03\x4b\
	\x03\x4b\x03\x4b\x05\x4b\u{784}\x0a\x4b\x03\x4c\x03\x4c\x03\x4c\x03\x4c\
	\x03\x4d\x03\x4d\x03\x4e\x03\x4e\x07\x4e\u{78e}\x0a\x4e\x0c\x4e\x0e\x4e\
	\u{791}\x0b\x4e\x03\x4f\x03\x4f\x03\x50\x03\x50\x03\x51\x03\x51\x03\x52\
	\x05\x52\u{79a}\x0a\x52\x03\x52\x05\x52\u{79d}\x0a\x52\x03\x53\x03\x53\x03\
	\x53\x03\x53\x03\x53\x03\x53\x03\x53\x03\x53\x03\x54\x03\x54\x05\x54\u{7a9}\
	\x0a\x54\x03\x54\x05\x54\u{7ac}\x0a\x54\x03\x54\x03\x54\x03\x54\x05\x54\
	\u{7b1}\x0a\x54\x03\x54\x05\x54\u{7b4}\x0a\x54\x07\x54\u{7b6}\x0a\x54\x0c\
	\x54\x0e\x54\u{7b9}\x0b\x54\x03\x54\x05\x54\u{7bc}\x0a\x54\x03\x55\x03\x55\
	\x05\x55\u{7c0}\x0a\x55\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\
	\x03\x56\x03\x56\x03\x57\x03\x57\x03\x57\x03\x57\x07\x57\u{7ce}\x0a\x57\
	\x0c\x57\x0e\x57\u{7d1}\x0b\x57\x03\x57\x05\x57\u{7d4}\x0a\x57\x03\x57\x03\
	\x57\x03\x58\x03\x58\x03\x58\x03\x58\x07\x58\u{7dc}\x0a\x58\x0c\x58\x0e\
	\x58\u{7df}\x0b\x58\x03\x58\x03\x58\x05\x58\u{7e3}\x0a\x58\x03\x58\x05\x58\
	\u{7e6}\x0a\x58\x03\x59\x03\x59\x03\x59\x07\x59\u{7eb}\x0a\x59\x0c\x59\x0e\
	\x59\u{7ee}\x0b\x59\x03\x59\x05\x59\u{7f1}\x0a\x59\x03\x5a\x03\x5a\x05\x5a\
	\u{7f5}\x0a\x5a\x03\x5b\x03\x5b\x03\x5b\x07\x5b\u{7fa}\x0a\x5b\x0c\x5b\x0e\
	\x5b\u{7fd}\x0b\x5b\x03\x5b\x05\x5b\u{800}\x0a\x5b\x03\x5c\x03\x5c\x03\x5c\
	\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\
	\x03\x5c\x03\x5c\x05\x5c\u{810}\x0a\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\
	\x03\x5c\x05\x5c\u{817}\x0a\x5c\x03\x5d\x03\x5d\x03\x5d\x03\x5d\x03\x5d\
	\x05\x5d\u{81e}\x0a\x5d\x03\x5e\x03\x5e\x05\x5e\u{822}\x0a\x5e\x03\x5e\x05\
	\x5e\u{825}\x0a\x5e\x03\x5f\x03\x5f\x03\x5f\x05\x5f\u{82a}\x0a\x5f\x03\x5f\
	\x03\x5f\x03\x5f\x03\x5f\x05\x5f\u{830}\x0a\x5f\x03\x5f\x03\x5f\x03\x5f\
	\x03\x5f\x05\x5f\u{836}\x0a\x5f\x07\x5f\u{838}\x0a\x5f\x0c\x5f\x0e\x5f\u{83b}\
	\x0b\x5f\x03\x5f\x05\x5f\u{83e}\x0a\x5f\x03\x5f\x03\x5f\x05\x5f\u{842}\x0a\
	\x5f\x03\x60\x03\x60\x03\x60\x03\x61\x03\x61\x03\x61\x03\x61\x07\x61\u{84b}\
	\x0a\x61\x0c\x61\x0e\x61\u{84e}\x0b\x61\x03\x61\x05\x61\u{851}\x0a\x61\x03\
	\x61\x03\x61\x03\x62\x03\x62\x03\x62\x03\x62\x03\x62\x03\x62\x07\x62\u{85b}\
	\x0a\x62\x0c\x62\x0e\x62\u{85e}\x0b\x62\x03\x62\x05\x62\u{861}\x0a\x62\x03\
	\x62\x03\x62\x05\x62\u{865}\x0a\x62\x03\x62\x05\x62\u{868}\x0a\x62\x03\x62\
	\x03\x62\x03\x62\x05\x62\u{86d}\x0a\x62\x03\x62\x05\x62\u{870}\x0a\x62\x05\
	\x62\u{872}\x0a\x62\x03\x62\x05\x62\u{875}\x0a\x62\x03\x63\x03\x63\x03\x63\
	\x03\x63\x03\x63\x07\x63\u{87c}\x0a\x63\x0c\x63\x0e\x63\u{87f}\x0b\x63\x03\
	\x63\x05\x63\u{882}\x0a\x63\x05\x63\u{884}\x0a\x63\x03\x63\x05\x63\u{887}\
	\x0a\x63\x03\x63\x03\x63\x05\x63\u{88b}\x0a\x63\x03\x64\x03\x64\x03\x64\
	\x03\x64\x07\x64\u{891}\x0a\x64\x0c\x64\x0e\x64\u{894}\x0b\x64\x03\x64\x05\
	\x64\u{897}\x0a\x64\x03\x65\x03\x65\x03\x66\x03\x66\x03\x66\x05\x66\u{89e}\
	\x0a\x66\x03\x66\x03\x66\x03\x66\x05\x66\u{8a3}\x0a\x66\x03\x67\x03\x67\
	\x03\x67\x03\x67\x03\x67\x03\x67\x03\x67\x07\x67\u{8ac}\x0a\x67\x0c\x67\
	\x0e\x67\u{8af}\x0b\x67\x03\x67\x05\x67\u{8b2}\x0a\x67\x05\x67\u{8b4}\x0a\
	\x67\x03\x67\x03\x67\x05\x67\u{8b8}\x0a\x67\x05\x67\u{8ba}\x0a\x67\x03\x67\
	\x03\x67\x03\x67\x03\x67\x03\x67\x03\x67\x05\x67\u{8c2}\x0a\x67\x03\x67\
	\x03\x67\x03\x67\x03\x67\x03\x67\x03\x67\x07\x67\u{8ca}\x0a\x67\x0c\x67\
	\x0e\x67\u{8cd}\x0b\x67\x03\x67\x05\x67\u{8d0}\x0a\x67\x03\x67\x03\x67\x03\
	\x67\x05\x67\u{8d5}\x0a\x67\x05\x67\u{8d7}\x0a\x67\x03\x68\x03\x68\x03\x68\
	\x03\x68\x03\x68\x03\x68\x03\x68\x05\x68\u{8e0}\x0a\x68\x03\x68\x03\x68\
	\x05\x68\u{8e4}\x0a\x68\x05\x68\u{8e6}\x0a\x68\x05\x68\u{8e8}\x0a\x68\x03\
	\x69\x03\x69\x03\x69\x03\x69\x03\x69\x07\x69\u{8ef}\x0a\x69\x0c\x69\x0e\
	\x69\u{8f2}\x0b\x69\x03\x69\x05\x69\u{8f5}\x0a\x69\x03\x69\x03\x69\x03\x69\
	\x03\x69\x03\x69\x03\x69\x03\x69\x03\x69\x05\x69\u{8ff}\x0a\x69\x03\x6a\
	\x03\x6a\x05\x6a\u{903}\x0a\x6a\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6b\
	\x03\x6b\x07\x6b\u{90b}\x0a\x6b\x0c\x6b\x0e\x6b\u{90e}\x0b\x6b\x03\x6b\x05\
	\x6b\u{911}\x0a\x6b\x03\x6b\x03\x6b\x03\x6c\x03\x6c\x03\x6d\x03\x6d\x03\
	\x6d\x05\x6d\u{91a}\x0a\x6d\x03\x6d\x03\x6d\x05\x6d\u{91e}\x0a\x6d\x03\x6d\
	\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x07\x6d\u{926}\x0a\x6d\x0c\x6d\
	\x0e\x6d\u{929}\x0b\x6d\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{935}\x0a\x6e\x03\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{93d}\x0a\x6e\x03\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x03\x6e\x07\x6e\u{944}\x0a\x6e\x0c\x6e\x0e\x6e\u{947}\x0b\
	\x6e\x03\x6e\x05\x6e\u{94a}\x0a\x6e\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{94f}\
	\x0a\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{955}\x0a\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{95d}\x0a\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x07\x6e\u{965}\x0a\x6e\x0c\x6e\
	\x0e\x6e\u{968}\x0b\x6e\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{96d}\x0a\x6e\x03\
	\x6e\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{973}\x0a\x6e\x03\x6e\x03\x6e\x03\
	\x6e\x05\x6e\u{978}\x0a\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x05\
	\x6e\u{97f}\x0a\x6e\x03\x6e\x03\x6e\x03\x6e\x05\x6e\u{984}\x0a\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x05\x6e\u{989}\x0a\x6e\x03\x6e\x05\x6e\u{98c}\x0a\x6e\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{992}\x0a\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x6f\x03\x6f\x03\x6f\x07\x6f\u{9a3}\x0a\x6f\x0c\x6f\x0e\x6f\u{9a6}\
	\x0b\x6f\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x06\x70\u{9b9}\x0a\x70\x0d\x70\x0e\x70\u{9ba}\x03\x70\x05\x70\u{9be}\x0a\
	\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x07\x70\u{9c7}\
	\x0a\x70\x0c\x70\x0e\x70\u{9ca}\x0b\x70\x03\x70\x03\x70\x05\x70\u{9ce}\x0a\
	\x70\x03\x70\x03\x70\x03\x70\x03\x70\x07\x70\u{9d4}\x0a\x70\x0c\x70\x0e\
	\x70\u{9d7}\x0b\x70\x05\x70\u{9d9}\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x06\x70\u{9e4}\x0a\x70\x0d\x70\
	\x0e\x70\u{9e5}\x03\x70\x03\x70\x05\x70\u{9ea}\x0a\x70\x03\x70\x03\x70\x03\
	\x70\x03\x70\x06\x70\u{9f0}\x0a\x70\x0d\x70\x0e\x70\u{9f1}\x03\x70\x03\x70\
	\x05\x70\u{9f6}\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x05\x70\u{a01}\x0a\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x05\x70\u{a0c}\x0a\x70\
	\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x05\x70\u{a13}\x0a\x70\x03\x70\
	\x05\x70\u{a16}\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x05\x70\u{a21}\x0a\x70\x03\x70\x05\x70\u{a24}\x0a\
	\x70\x05\x70\u{a26}\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\
	\x70\x03\x70\x03\x70\x03\x70\x05\x70\u{a31}\x0a\x70\x03\x70\x03\x70\x03\
	\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x05\x70\u{a3c}\x0a\
	\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x05\x70\u{a45}\
	\x0a\x70\x03\x70\x05\x70\u{a48}\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x05\x70\u{a55}\
	\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x07\x70\
	\u{a5e}\x0a\x70\x0c\x70\x0e\x70\u{a61}\x0b\x70\x03\x70\x05\x70\u{a64}\x0a\
	\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\
	\x70\x03\x70\x03\x70\x03\x70\x05\x70\u{a72}\x0a\x70\x03\x70\x03\x70\x03\
	\x70\x07\x70\u{a77}\x0a\x70\x0c\x70\x0e\x70\u{a7a}\x0b\x70\x05\x70\u{a7c}\
	\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x07\x70\
	\u{a8e}\x0a\x70\x0c\x70\x0e\x70\u{a91}\x0b\x70\x05\x70\u{a93}\x0a\x70\x03\
	\x70\x05\x70\u{a96}\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\
	\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x05\x70\u{aa4}\x0a\
	\x70\x03\x70\x03\x70\x03\x70\x03\x70\x07\x70\u{aaa}\x0a\x70\x0c\x70\x0e\
	\x70\u{aad}\x0b\x70\x05\x70\u{aaf}\x0a\x70\x03\x70\x05\x70\u{ab2}\x0a\x70\
	\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x07\x70\u{abe}\x0a\x70\x0c\x70\x0e\x70\u{ac1}\x0b\x70\x03\x70\x05\
	\x70\u{ac4}\x0a\x70\x05\x70\u{ac6}\x0a\x70\x03\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x05\x70\u{acf}\x0a\x70\x03\x70\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x07\x70\u{ad9}\x0a\x70\x0c\x70\
	\x0e\x70\u{adc}\x0b\x70\x03\x71\x03\x71\x05\x71\u{ae0}\x0a\x71\x03\x72\x05\
	\x72\u{ae3}\x0a\x72\x03\x73\x03\x73\x03\x73\x03\x73\x03\x73\x05\x73\u{aea}\
	\x0a\x73\x03\x74\x05\x74\u{aed}\x0a\x74\x03\x74\x05\x74\u{af0}\x0a\x74\x03\
	\x74\x03\x74\x03\x74\x03\x74\x03\x74\x07\x74\u{af7}\x0a\x74\x0c\x74\x0e\
	\x74\u{afa}\x0b\x74\x05\x74\u{afc}\x0a\x74\x03\x74\x05\x74\u{aff}\x0a\x74\
	\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\
	\x03\x76\x03\x76\x03\x76\x03\x76\x03\x76\x03\x76\x03\x76\x03\x76\x03\x76\
	\x03\x76\x03\x76\x03\x76\x05\x76\u{b16}\x0a\x76\x03\x76\x03\x76\x03\x76\
	\x03\x76\x03\x76\x03\x76\x03\x76\x03\x76\x05\x76\u{b20}\x0a\x76\x03\x77\
	\x03\x77\x03\x77\x03\x77\x03\x77\x03\x77\x05\x77\u{b28}\x0a\x77\x03\x78\
	\x03\x78\x03\x78\x03\x78\x03\x79\x03\x79\x03\x79\x03\x7a\x03\x7a\x03\x7a\
	\x03\x7a\x05\x7a\u{b35}\x0a\x7a\x03\x7b\x03\x7b\x03\x7b\x05\x7b\u{b3a}\x0a\
	\x7b\x03\x7c\x03\x7c\x03\x7d\x03\x7d\x03\x7d\x03\x7d\x05\x7d\u{b42}\x0a\
	\x7d\x03\x7e\x03\x7e\x03\x7e\x03\x7e\x05\x7e\u{b48}\x0a\x7e\x03\x7f\x03\
	\x7f\x03\u{80}\x03\u{80}\x03\u{81}\x03\u{81}\x03\u{82}\x03\u{82}\x03\u{82}\
	\x03\u{82}\x03\u{82}\x05\u{82}\u{b55}\x0a\u{82}\x03\u{83}\x03\u{83}\x03\
	\u{84}\x03\u{84}\x03\u{85}\x03\u{85}\x03\u{86}\x03\u{86}\x03\u{86}\x05\u{86}\
	\u{b60}\x0a\u{86}\x03\u{86}\x05\u{86}\u{b63}\x0a\u{86}\x03\u{87}\x03\u{87}\
	\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\
	\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x07\u{87}\u{b72}\x0a\u{87}\x0c\u{87}\
	\x0e\u{87}\u{b75}\x0b\u{87}\x03\u{87}\x05\u{87}\u{b78}\x0a\u{87}\x03\u{87}\
	\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x07\
	\u{87}\u{b82}\x0a\u{87}\x0c\u{87}\x0e\u{87}\u{b85}\x0b\u{87}\x03\u{87}\x05\
	\u{87}\u{b88}\x0a\u{87}\x03\u{87}\x03\u{87}\x05\u{87}\u{b8c}\x0a\u{87}\x05\
	\u{87}\u{b8e}\x0a\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x07\u{87}\u{b93}\x0a\
	\u{87}\x0c\u{87}\x0e\u{87}\u{b96}\x0b\u{87}\x03\u{88}\x03\u{88}\x03\u{88}\
	\x03\u{88}\x05\u{88}\u{b9c}\x0a\u{88}\x03\u{89}\x03\u{89}\x05\u{89}\u{ba0}\
	\x0a\u{89}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8b}\x03\
	\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8c}\x03\u{8c}\x03\u{8c}\
	\x03\u{8c}\x05\u{8c}\u{bb1}\x0a\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x05\
	\u{8c}\u{bb6}\x0a\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\
	\x05\u{8c}\u{bbd}\x0a\u{8c}\x03\u{8c}\x03\u{8c}\x05\u{8c}\u{bc1}\x0a\u{8c}\
	\x03\u{8c}\x03\u{8c}\x03\u{8c}\x05\u{8c}\u{bc6}\x0a\u{8c}\x03\u{8c}\x03\
	\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x05\u{8c}\u{bcf}\
	\x0a\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x05\u{8c}\u{bd4}\x0a\u{8c}\x05\
	\u{8c}\u{bd6}\x0a\u{8c}\x03\u{8d}\x03\u{8d}\x03\u{8d}\x03\u{8d}\x03\u{8d}\
	\x03\u{8d}\x03\u{8d}\x03\u{8d}\x03\u{8d}\x03\u{8d}\x07\u{8d}\u{be2}\x0a\
	\u{8d}\x0c\u{8d}\x0e\u{8d}\u{be5}\x0b\u{8d}\x03\u{8e}\x03\u{8e}\x03\u{8e}\
	\x03\u{8e}\x03\u{8e}\x07\u{8e}\u{bec}\x0a\u{8e}\x0c\u{8e}\x0e\u{8e}\u{bef}\
	\x0b\u{8e}\x03\u{8e}\x05\u{8e}\u{bf2}\x0a\u{8e}\x03\u{8e}\x03\u{8e}\x05\
	\u{8e}\u{bf6}\x0a\u{8e}\x03\u{8e}\x03\u{8e}\x03\u{8e}\x03\u{8e}\x03\u{8e}\
	\x07\u{8e}\u{bfd}\x0a\u{8e}\x0c\u{8e}\x0e\u{8e}\u{c00}\x0b\u{8e}\x03\u{8e}\
	\x05\u{8e}\u{c03}\x0a\u{8e}\x03\u{8e}\x03\u{8e}\x03\u{8f}\x03\u{8f}\x03\
	\u{8f}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x05\u{8f}\u{c0d}\x0a\u{8f}\x03\u{90}\
	\x03\u{90}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\
	\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\
	\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\
	\u{91}\x03\u{91}\x03\u{91}\x05\u{91}\u{c29}\x0a\u{91}\x03\u{92}\x03\u{92}\
	\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x05\
	\u{92}\u{c34}\x0a\u{92}\x03\u{93}\x03\u{93}\x03\u{93}\x05\u{93}\u{c39}\x0a\
	\u{93}\x03\u{93}\x03\u{93}\x03\u{93}\x03\u{93}\x03\u{93}\x07\u{93}\u{c40}\
	\x0a\u{93}\x0c\u{93}\x0e\u{93}\u{c43}\x0b\u{93}\x03\u{94}\x03\u{94}\x03\
	\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x07\u{94}\u{c4d}\
	\x0a\u{94}\x0c\u{94}\x0e\u{94}\u{c50}\x0b\u{94}\x03\u{94}\x05\u{94}\u{c53}\
	\x0a\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\
	\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x05\u{94}\u{c61}\
	\x0a\u{94}\x03\u{95}\x03\u{95}\x05\u{95}\u{c65}\x0a\u{95}\x03\u{95}\x03\
	\u{95}\x05\u{95}\u{c69}\x0a\u{95}\x03\u{95}\x03\u{95}\x05\u{95}\u{c6d}\x0a\
	\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x05\u{95}\u{c73}\x0a\u{95}\
	\x03\u{95}\x03\u{95}\x05\u{95}\u{c77}\x0a\u{95}\x03\u{95}\x03\u{95}\x05\
	\u{95}\u{c7b}\x0a\u{95}\x03\u{95}\x05\u{95}\u{c7e}\x0a\u{95}\x03\u{95}\x03\
	\u{95}\x05\u{95}\u{c82}\x0a\u{95}\x05\u{95}\u{c84}\x0a\u{95}\x03\u{96}\x03\
	\u{96}\x03\u{96}\x03\u{96}\x03\u{96}\x05\u{96}\u{c8b}\x0a\u{96}\x03\u{97}\
	\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x05\u{97}\u{c94}\
	\x0a\u{97}\x03\u{98}\x03\u{98}\x03\u{99}\x03\u{99}\x03\u{99}\x07\u{99}\u{c9b}\
	\x0a\u{99}\x0c\u{99}\x0e\u{99}\u{c9e}\x0b\u{99}\x03\u{9a}\x03\u{9a}\x03\
	\u{9b}\x03\u{9b}\x05\u{9b}\u{ca4}\x0a\u{9b}\x03\u{9c}\x03\u{9c}\x03\u{9c}\
	\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\
	\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x05\u{9c}\u{cb4}\x0a\u{9c}\x03\u{9c}\
	\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\
	\u{9c}\x03\u{9c}\x07\u{9c}\u{cc0}\x0a\u{9c}\x0c\u{9c}\x0e\u{9c}\u{cc3}\x0b\
	\u{9c}\x03\u{9d}\x03\u{9d}\x05\u{9d}\u{cc7}\x0a\u{9d}\x03\u{9e}\x03\u{9e}\
	\x03\u{9e}\x07\u{9e}\u{ccc}\x0a\u{9e}\x0c\u{9e}\x0e\u{9e}\u{ccf}\x0b\u{9e}\
	\x03\u{9f}\x03\u{9f}\x05\u{9f}\u{cd3}\x0a\u{9f}\x03\u{a0}\x03\u{a0}\x03\
	\u{a0}\x03\u{a0}\x03\u{a0}\x03\u{a0}\x03\u{a1}\x03\u{a1}\x03\u{a2}\x03\u{a2}\
	\x03\u{a2}\x03\u{a2}\x03\u{a2}\x05\u{a2}\u{ce2}\x0a\u{a2}\x03\u{a3}\x03\
	\u{a3}\x03\u{a3}\x05\u{a3}\u{ce7}\x0a\u{a3}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x05\u{a4}\u{d43}\x0a\u{a4}\
	\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a7}\x03\u{a7}\x03\u{a7}\x07\u{a7}\u{d4f}\x0a\u{a7}\x0c\u{a7}\x0e\u{a7}\
	\u{d52}\x0b\u{a7}\x03\u{a8}\x05\u{a8}\u{d55}\x0a\u{a8}\x03\u{a8}\x03\u{a8}\
	\x05\u{a8}\u{d59}\x0a\u{a8}\x03\u{a8}\x03\u{a8}\x05\u{a8}\u{d5d}\x0a\u{a8}\
	\x03\u{a8}\x03\u{a8}\x05\u{a8}\u{d61}\x0a\u{a8}\x03\u{a8}\x05\u{a8}\u{d64}\
	\x0a\u{a8}\x03\u{a9}\x03\u{a9}\x03\u{a9}\x02\x09\u{80}\u{d8}\u{dc}\u{de}\
	\u{10c}\u{124}\u{136}\u{aa}\x02\x04\x06\x08\x0a\x0c\x0e\x10\x12\x14\x16\
	\x18\x1a\x1c\x1e\x20\x22\x24\x26\x28\x2a\x2c\x2e\x30\x32\x34\x36\x38\x3a\
	\x3c\x3e\x40\x42\x44\x46\x48\x4a\x4c\x4e\x50\x52\x54\x56\x58\x5a\x5c\x5e\
	\x60\x62\x64\x66\x68\x6a\x6c\x6e\x70\x72\x74\x76\x78\x7a\x7c\x7e\u{80}\u{82}\
	\u{84}\u{86}\u{88}\u{8a}\u{8c}\u{8e}\u{90}\u{92}\u{94}\u{96}\u{98}\u{9a}\
	\u{9c}\u{9e}\u{a0}\u{a2}\u{a4}\u{a6}\u{a8}\u{aa}\u{ac}\u{ae}\u{b0}\u{b2}\
	\u{b4}\u{b6}\u{b8}\u{ba}\u{bc}\u{be}\u{c0}\u{c2}\u{c4}\u{c6}\u{c8}\u{ca}\
	\u{cc}\u{ce}\u{d0}\u{d2}\u{d4}\u{d6}\u{d8}\u{da}\u{dc}\u{de}\u{e0}\u{e2}\
	\u{e4}\u{e6}\u{e8}\u{ea}\u{ec}\u{ee}\u{f0}\u{f2}\u{f4}\u{f6}\u{f8}\u{fa}\
	\u{fc}\u{fe}\u{100}\u{102}\u{104}\u{106}\u{108}\u{10a}\u{10c}\u{10e}\u{110}\
	\u{112}\u{114}\u{116}\u{118}\u{11a}\u{11c}\u{11e}\u{120}\u{122}\u{124}\u{126}\
	\u{128}\u{12a}\u{12c}\u{12e}\u{130}\u{132}\u{134}\u{136}\u{138}\u{13a}\u{13c}\
	\u{13e}\u{140}\u{142}\u{144}\u{146}\u{148}\u{14a}\u{14c}\u{14e}\u{150}\x02\
	\x22\x03\x02\u{19f}\u{19f}\x03\x02\u{148}\u{149}\x04\x02\x40\x40\u{bb}\u{bb}\
	\x03\x02\x5c\x5d\x04\x02\u{12b}\u{12b}\u{145}\u{145}\x04\x02\x73\x73\u{9a}\
	\u{9a}\x04\x02\u{85}\u{85}\u{b8}\u{b8}\x05\x02\x71\x71\u{a2}\u{a2}\u{166}\
	\u{166}\x04\x02\x0f\x0f\x60\x60\x04\x02\x17\x17\x5c\x5c\x04\x02\x7f\x7f\
	\u{b5}\u{b5}\x04\x02\u{13f}\u{13f}\u{177}\u{177}\x04\x02\x1e\x1e\u{143}\
	\u{143}\x05\x02\x20\x20\u{b7}\u{b7}\u{155}\u{155}\x05\x02\x0f\x0f\x14\x14\
	\u{13a}\u{13a}\x04\x02\u{198}\u{199}\u{1a6}\u{1a6}\x03\x02\u{19a}\u{19b}\
	\x03\x02\u{198}\u{199}\x03\x02\u{1a2}\u{1a4}\x04\x02\x50\x51\u{152}\u{152}\
	\x09\x02\u{83}\u{83}\u{d5}\u{d5}\u{128}\u{128}\u{142}\u{142}\u{14e}\u{14e}\
	\u{160}\u{160}\u{17d}\u{17d}\x04\x02\u{cb}\u{cb}\u{d1}\u{d1}\x04\x02\x7e\
	\x7e\u{125}\u{125}\x03\x02\u{192}\u{197}\x04\x02\x7a\x7a\u{15c}\u{15c}\x0b\
	\x02\x4d\x4d\u{94}\u{94}\u{cf}\u{d0}\u{d3}\u{d3}\u{d6}\u{d6}\u{10a}\u{10a}\
	\u{12a}\u{12a}\u{17e}\u{17e}\u{189}\u{189}\x03\x02\u{da}\u{dd}\x04\x02\u{80}\
	\u{80}\u{101}\u{101}\x04\x02\u{ea}\u{ea}\u{187}\u{187}\x07\x02\x42\x42\x58\
	\x58\u{a1}\u{a1}\u{12f}\u{12f}\u{16e}\u{16e}\x04\x02\u{151}\u{151}\u{17b}\
	\u{17b}\x45\x02\x0a\x0e\x10\x11\x13\x13\x19\x1e\x20\x21\x23\x26\x28\x29\
	\x2b\x30\x32\x33\x35\x41\x46\x53\x55\x55\x57\x5b\x5d\x5f\x61\x67\x69\x6c\
	\x6e\x6e\x70\x70\x72\x72\x74\x75\x77\x78\x7c\x7f\u{82}\u{83}\u{86}\u{8d}\
	\u{91}\u{91}\u{93}\u{95}\u{98}\u{98}\u{9a}\u{9c}\u{9e}\u{a1}\u{a5}\u{a6}\
	\u{a8}\u{ac}\u{ae}\u{b5}\u{b7}\u{b7}\u{b9}\u{ba}\u{bd}\u{c8}\u{ca}\u{cc}\
	\u{ce}\u{d7}\u{d9}\u{dd}\u{df}\u{e0}\u{e4}\u{e4}\u{e6}\u{e7}\u{e9}\u{ec}\
	\u{f0}\u{f1}\u{f3}\u{f3}\u{f5}\u{100}\u{102}\u{108}\u{10a}\u{10c}\u{10e}\
	\u{10e}\u{110}\u{114}\u{116}\u{11c}\u{11e}\u{121}\u{123}\u{123}\u{125}\u{12e}\
	\u{130}\u{134}\u{136}\u{139}\u{13b}\u{13e}\u{140}\u{146}\u{148}\u{14c}\u{14e}\
	\u{152}\u{154}\u{15b}\u{15d}\u{162}\u{164}\u{165}\u{167}\u{169}\u{16b}\u{170}\
	\u{172}\u{17e}\u{181}\u{181}\u{184}\u{18c}\x02\u{f90}\x02\u{153}\x03\x02\
	\x02\x02\x04\u{161}\x03\x02\x02\x02\x06\u{168}\x03\x02\x02\x02\x08\u{16b}\
	\x03\x02\x02\x02\x0a\u{16e}\x03\x02\x02\x02\x0c\u{171}\x03\x02\x02\x02\x0e\
	\u{527}\x03\x02\x02\x02\x10\u{529}\x03\x02\x02\x02\x12\u{531}\x03\x02\x02\
	\x02\x14\u{539}\x03\x02\x02\x02\x16\u{543}\x03\x02\x02\x02\x18\u{546}\x03\
	\x02\x02\x02\x1a\u{549}\x03\x02\x02\x02\x1c\u{54e}\x03\x02\x02\x02\x1e\u{552}\
	\x03\x02\x02\x02\x20\u{55e}\x03\x02\x02\x02\x22\u{560}\x03\x02\x02\x02\x24\
	\u{565}\x03\x02\x02\x02\x26\u{568}\x03\x02\x02\x02\x28\u{56a}\x03\x02\x02\
	\x02\x2a\u{56c}\x03\x02\x02\x02\x2c\u{57b}\x03\x02\x02\x02\x2e\u{586}\x03\
	\x02\x02\x02\x30\u{591}\x03\x02\x02\x02\x32\u{593}\x03\x02\x02\x02\x34\u{5a4}\
	\x03\x02\x02\x02\x36\u{5a6}\x03\x02\x02\x02\x38\u{5ab}\x03\x02\x02\x02\x3a\
	\u{5b1}\x03\x02\x02\x02\x3c\u{5cb}\x03\x02\x02\x02\x3e\u{5cd}\x03\x02\x02\
	\x02\x40\u{5d2}\x03\x02\x02\x02\x42\u{5d4}\x03\x02\x02\x02\x44\u{5d6}\x03\
	\x02\x02\x02\x46\u{5df}\x03\x02\x02\x02\x48\u{5e3}\x03\x02\x02\x02\x4a\u{5e5}\
	\x03\x02\x02\x02\x4c\u{5e7}\x03\x02\x02\x02\x4e\u{5e9}\x03\x02\x02\x02\x50\
	\u{5f9}\x03\x02\x02\x02\x52\u{601}\x03\x02\x02\x02\x54\u{60a}\x03\x02\x02\
	\x02\x56\u{60e}\x03\x02\x02\x02\x58\u{610}\x03\x02\x02\x02\x5a\u{624}\x03\
	\x02\x02\x02\x5c\u{626}\x03\x02\x02\x02\x5e\u{62e}\x03\x02\x02\x02\x60\u{658}\
	\x03\x02\x02\x02\x62\u{65e}\x03\x02\x02\x02\x64\u{669}\x03\x02\x02\x02\x66\
	\u{67c}\x03\x02\x02\x02\x68\u{6af}\x03\x02\x02\x02\x6a\u{6c1}\x03\x02\x02\
	\x02\x6c\u{6c3}\x03\x02\x02\x02\x6e\u{6ca}\x03\x02\x02\x02\x70\u{6d5}\x03\
	\x02\x02\x02\x72\u{6e2}\x03\x02\x02\x02\x74\u{6ef}\x03\x02\x02\x02\x76\u{6f5}\
	\x03\x02\x02\x02\x78\u{6ff}\x03\x02\x02\x02\x7a\u{701}\x03\x02\x02\x02\x7c\
	\u{719}\x03\x02\x02\x02\x7e\u{71b}\x03\x02\x02\x02\u{80}\u{71d}\x03\x02\
	\x02\x02\u{82}\u{740}\x03\x02\x02\x02\u{84}\u{751}\x03\x02\x02\x02\u{86}\
	\u{764}\x03\x02\x02\x02\u{88}\u{766}\x03\x02\x02\x02\u{8a}\u{768}\x03\x02\
	\x02\x02\u{8c}\u{76c}\x03\x02\x02\x02\u{8e}\u{773}\x03\x02\x02\x02\u{90}\
	\u{775}\x03\x02\x02\x02\u{92}\u{77d}\x03\x02\x02\x02\u{94}\u{783}\x03\x02\
	\x02\x02\u{96}\u{785}\x03\x02\x02\x02\u{98}\u{789}\x03\x02\x02\x02\u{9a}\
	\u{78b}\x03\x02\x02\x02\u{9c}\u{792}\x03\x02\x02\x02\u{9e}\u{794}\x03\x02\
	\x02\x02\u{a0}\u{796}\x03\x02\x02\x02\u{a2}\u{79c}\x03\x02\x02\x02\u{a4}\
	\u{79e}\x03\x02\x02\x02\u{a6}\u{7a6}\x03\x02\x02\x02\u{a8}\u{7bf}\x03\x02\
	\x02\x02\u{aa}\u{7c1}\x03\x02\x02\x02\u{ac}\u{7c9}\x03\x02\x02\x02\u{ae}\
	\u{7d7}\x03\x02\x02\x02\u{b0}\u{7e7}\x03\x02\x02\x02\u{b2}\u{7f4}\x03\x02\
	\x02\x02\u{b4}\u{7f6}\x03\x02\x02\x02\u{b6}\u{816}\x03\x02\x02\x02\u{b8}\
	\u{81d}\x03\x02\x02\x02\u{ba}\u{81f}\x03\x02\x02\x02\u{bc}\u{841}\x03\x02\
	\x02\x02\u{be}\u{843}\x03\x02\x02\x02\u{c0}\u{846}\x03\x02\x02\x02\u{c2}\
	\u{874}\x03\x02\x02\x02\u{c4}\u{876}\x03\x02\x02\x02\u{c6}\u{88c}\x03\x02\
	\x02\x02\u{c8}\u{898}\x03\x02\x02\x02\u{ca}\u{89d}\x03\x02\x02\x02\u{cc}\
	\u{8a4}\x03\x02\x02\x02\u{ce}\u{8e7}\x03\x02\x02\x02\u{d0}\u{8fe}\x03\x02\
	\x02\x02\u{d2}\u{900}\x03\x02\x02\x02\u{d4}\u{904}\x03\x02\x02\x02\u{d6}\
	\u{914}\x03\x02\x02\x02\u{d8}\u{91d}\x03\x02\x02\x02\u{da}\u{98b}\x03\x02\
	\x02\x02\u{dc}\u{991}\x03\x02\x02\x02\u{de}\u{ace}\x03\x02\x02\x02\u{e0}\
	\u{adf}\x03\x02\x02\x02\u{e2}\u{ae2}\x03\x02\x02\x02\u{e4}\u{ae9}\x03\x02\
	\x02\x02\u{e6}\u{aec}\x03\x02\x02\x02\u{e8}\u{b00}\x03\x02\x02\x02\u{ea}\
	\u{b1f}\x03\x02\x02\x02\u{ec}\u{b27}\x03\x02\x02\x02\u{ee}\u{b29}\x03\x02\
	\x02\x02\u{f0}\u{b2d}\x03\x02\x02\x02\u{f2}\u{b30}\x03\x02\x02\x02\u{f4}\
	\u{b36}\x03\x02\x02\x02\u{f6}\u{b3b}\x03\x02\x02\x02\u{f8}\u{b41}\x03\x02\
	\x02\x02\u{fa}\u{b47}\x03\x02\x02\x02\u{fc}\u{b49}\x03\x02\x02\x02\u{fe}\
	\u{b4b}\x03\x02\x02\x02\u{100}\u{b4d}\x03\x02\x02\x02\u{102}\u{b4f}\x03\
	\x02\x02\x02\u{104}\u{b56}\x03\x02\x02\x02\u{106}\u{b58}\x03\x02\x02\x02\
	\u{108}\u{b5a}\x03\x02\x02\x02\u{10a}\u{b62}\x03\x02\x02\x02\u{10c}\u{b8d}\
	\x03\x02\x02\x02\u{10e}\u{b9b}\x03\x02\x02\x02\u{110}\u{b9f}\x03\x02\x02\
	\x02\u{112}\u{ba1}\x03\x02\x02\x02\u{114}\u{ba6}\x03\x02\x02\x02\u{116}\
	\u{bd5}\x03\x02\x02\x02\u{118}\u{bd7}\x03\x02\x02\x02\u{11a}\u{be6}\x03\
	\x02\x02\x02\u{11c}\u{c06}\x03\x02\x02\x02\u{11e}\u{c0e}\x03\x02\x02\x02\
	\u{120}\u{c28}\x03\x02\x02\x02\u{122}\u{c33}\x03\x02\x02\x02\u{124}\u{c35}\
	\x03\x02\x02\x02\u{126}\u{c60}\x03\x02\x02\x02\u{128}\u{c83}\x03\x02\x02\
	\x02\u{12a}\u{c8a}\x03\x02\x02\x02\u{12c}\u{c93}\x03\x02\x02\x02\u{12e}\
	\u{c95}\x03\x02\x02\x02\u{130}\u{c97}\x03\x02\x02\x02\u{132}\u{c9f}\x03\
	\x02\x02\x02\u{134}\u{ca3}\x03\x02\x02\x02\u{136}\u{cb3}\x03\x02\x02\x02\
	\u{138}\u{cc6}\x03\x02\x02\x02\u{13a}\u{cc8}\x03\x02\x02\x02\u{13c}\u{cd2}\
	\x03\x02\x02\x02\u{13e}\u{cd4}\x03\x02\x02\x02\u{140}\u{cda}\x03\x02\x02\
	\x02\u{142}\u{ce1}\x03\x02\x02\x02\u{144}\u{ce6}\x03\x02\x02\x02\u{146}\
	\u{d42}\x03\x02\x02\x02\u{148}\u{d44}\x03\x02\x02\x02\u{14a}\u{d47}\x03\
	\x02\x02\x02\u{14c}\u{d4b}\x03\x02\x02\x02\u{14e}\u{d63}\x03\x02\x02\x02\
	\u{150}\u{d65}\x03\x02\x02\x02\u{152}\u{154}\x05\x0e\x08\x02\u{153}\u{152}\
	\x03\x02\x02\x02\u{153}\u{154}\x03\x02\x02\x02\u{154}\u{15b}\x03\x02\x02\
	\x02\u{155}\u{157}\x07\u{19f}\x02\x02\u{156}\u{158}\x05\x0e\x08\x02\u{157}\
	\u{156}\x03\x02\x02\x02\u{157}\u{158}\x03\x02\x02\x02\u{158}\u{15a}\x03\
	\x02\x02\x02\u{159}\u{155}\x03\x02\x02\x02\u{15a}\u{15d}\x03\x02\x02\x02\
	\u{15b}\u{159}\x03\x02\x02\x02\u{15b}\u{15c}\x03\x02\x02\x02\u{15c}\u{15e}\
	\x03\x02\x02\x02\u{15d}\u{15b}\x03\x02\x02\x02\u{15e}\u{15f}\x07\x02\x02\
	\x03\u{15f}\x03\x03\x02\x02\x02\u{160}\u{162}\x05\x0e\x08\x02\u{161}\u{160}\
	\x03\x02\x02\x02\u{161}\u{162}\x03\x02\x02\x02\u{162}\u{164}\x03\x02\x02\
	\x02\u{163}\u{165}\x07\u{19f}\x02\x02\u{164}\u{163}\x03\x02\x02\x02\u{164}\
	\u{165}\x03\x02\x02\x02\u{165}\u{166}\x03\x02\x02\x02\u{166}\u{167}\x07\
	\x02\x02\x03\u{167}\x05\x03\x02\x02\x02\u{168}\u{169}\x05\u{d6}\x6c\x02\
	\u{169}\u{16a}\x07\x02\x02\x03\u{16a}\x07\x03\x02\x02\x02\u{16b}\u{16c}\
	\x05\u{130}\u{99}\x02\u{16c}\u{16d}\x07\x02\x02\x03\u{16d}\x09\x03\x02\x02\
	\x02\u{16e}\u{16f}\x05\u{10a}\u{86}\x02\u{16f}\u{170}\x07\x02\x02\x03\u{170}\
	\x0b\x03\x02\x02\x02\u{171}\u{176}\x05\x0e\x08\x02\u{172}\u{173}\x07\u{19f}\
	\x02\x02\u{173}\u{175}\x05\x0e\x08\x02\u{174}\u{172}\x03\x02\x02\x02\u{175}\
	\u{178}\x03\x02\x02\x02\u{176}\u{174}\x03\x02\x02\x02\u{176}\u{177}\x03\
	\x02\x02\x02\u{177}\u{179}\x03\x02\x02\x02\u{178}\u{176}\x03\x02\x02\x02\
	\u{179}\u{17a}\x07\u{19f}\x02\x02\u{17a}\x0d\x03\x02\x02\x02\u{17b}\u{528}\
	\x05\x1c\x0f\x02\u{17c}\u{17d}\x07\u{16f}\x02\x02\u{17d}\u{528}\x05\u{144}\
	\u{a3}\x02\u{17e}\u{17f}\x07\u{16f}\x02\x02\u{17f}\u{180}\x05\u{144}\u{a3}\
	\x02\u{180}\u{181}\x07\u{191}\x02\x02\u{181}\u{182}\x05\u{144}\u{a3}\x02\
	\u{182}\u{528}\x03\x02\x02\x02\u{183}\u{184}\x07\x67\x02\x02\u{184}\u{187}\
	\x07\u{12b}\x02\x02\u{185}\u{186}\x07\u{96}\x02\x02\u{186}\u{188}\x07\x76\
	\x02\x02\u{187}\u{185}\x03\x02\x02\x02\u{187}\u{188}\x03\x02\x02\x02\u{188}\
	\u{189}\x03\x02\x02\x02\u{189}\u{18d}\x05\u{130}\u{99}\x02\u{18a}\u{18c}\
	\x0a\x02\x02\x02\u{18b}\u{18a}\x03\x02\x02\x02\u{18c}\u{18f}\x03\x02\x02\
	\x02\u{18d}\u{18b}\x03\x02\x02\x02\u{18d}\u{18e}\x03\x02\x02\x02\u{18e}\
	\u{528}\x03\x02\x02\x02\u{18f}\u{18d}\x03\x02\x02\x02\u{190}\u{191}\x07\
	\x10\x02\x02\u{191}\u{192}\x07\u{12b}\x02\x02\u{192}\u{193}\x05\u{130}\u{99}\
	\x02\u{193}\u{194}\x07\u{111}\x02\x02\u{194}\u{195}\x07\u{153}\x02\x02\u{195}\
	\u{196}\x05\u{144}\u{a3}\x02\u{196}\u{528}\x03\x02\x02\x02\u{197}\u{198}\
	\x07\x10\x02\x02\u{198}\u{199}\x07\u{12b}\x02\x02\u{199}\u{19a}\x05\u{130}\
	\u{99}\x02\u{19a}\u{19b}\x07\u{135}\x02\x02\u{19b}\u{19c}\x07\x1a\x02\x02\
	\u{19c}\u{19d}\x05\u{142}\u{a2}\x02\u{19d}\u{528}\x03\x02\x02\x02\u{19e}\
	\u{19f}\x07\x67\x02\x02\u{19f}\u{1a0}\x07\u{145}\x02\x02\u{1a0}\u{528}\x05\
	\u{130}\u{99}\x02\u{1a1}\u{1a2}\x07\x67\x02\x02\u{1a2}\u{1a3}\x07\u{17c}\
	\x02\x02\u{1a3}\u{528}\x05\u{130}\u{99}\x02\u{1a4}\u{1a7}\x07\x42\x02\x02\
	\u{1a5}\u{1a6}\x07\u{ed}\x02\x02\u{1a6}\u{1a8}\x07\u{113}\x02\x02\u{1a7}\
	\u{1a5}\x03\x02\x02\x02\u{1a7}\u{1a8}\x03\x02\x02\x02\u{1a8}\u{1a9}\x03\
	\x02\x02\x02\u{1a9}\u{1aa}\x07\x78\x02\x02\u{1aa}\u{1ae}\x07\u{145}\x02\
	\x02\u{1ab}\u{1ac}\x07\u{96}\x02\x02\u{1ac}\u{1ad}\x07\u{e1}\x02\x02\u{1ad}\
	\u{1af}\x07\x76\x02\x02\u{1ae}\u{1ab}\x03\x02\x02\x02\u{1ae}\u{1af}\x03\
	\x02\x02\x02\u{1af}\u{1b0}\x03\x02\x02\x02\u{1b0}\u{1b8}\x05\u{13c}\u{9f}\
	\x02\u{1b1}\u{1b2}\x07\u{18d}\x02\x02\u{1b2}\u{1b4}\x05\x10\x09\x02\u{1b3}\
	\u{1b5}\x07\x34\x02\x02\u{1b4}\u{1b3}\x03\x02\x02\x02\u{1b4}\u{1b5}\x03\
	\x02\x02\x02\u{1b5}\u{1b6}\x03\x02\x02\x02\u{1b6}\u{1b7}\x07\u{18e}\x02\
	\x02\u{1b7}\u{1b9}\x03\x02\x02\x02\u{1b8}\u{1b1}\x03\x02\x02\x02\u{1b8}\
	\u{1b9}\x03\x02\x02\x02\u{1b9}\u{1bb}\x03\x02\x02\x02\u{1ba}\u{1bc}\x05\
	\x1a\x0e\x02\u{1bb}\u{1ba}\x03\x02\x02\x02\u{1bb}\u{1bc}\x03\x02\x02\x02\
	\u{1bc}\u{1c3}\x03\x02\x02\x02\u{1bd}\u{1be}\x07\u{183}\x02\x02\u{1be}\u{1bf}\
	\x07\u{f4}\x02\x02\u{1bf}\u{1c1}\x07\x33\x02\x02\u{1c0}\u{1c2}\x05\u{c0}\
	\x61\x02\u{1c1}\u{1c0}\x03\x02\x02\x02\u{1c1}\u{1c2}\x03\x02\x02\x02\u{1c2}\
	\u{1c4}\x03\x02\x02\x02\u{1c3}\u{1bd}\x03\x02\x02\x02\u{1c3}\u{1c4}\x03\
	\x02\x02\x02\u{1c4}\u{1c5}\x03\x02\x02\x02\u{1c5}\u{1c6}\x07\u{ec}\x02\x02\
	\u{1c6}\u{1c7}\x05\x38\x1d\x02\u{1c7}\u{528}\x03\x02\x02\x02\u{1c8}\u{1cb}\
	\x07\x42\x02\x02\u{1c9}\u{1ca}\x07\u{ed}\x02\x02\u{1ca}\u{1cc}\x07\u{113}\
	\x02\x02\u{1cb}\u{1c9}\x03\x02\x02\x02\u{1cb}\u{1cc}\x03\x02\x02\x02\u{1cc}\
	\u{1ce}\x03\x02\x02\x02\u{1cd}\u{1cf}\x09\x03\x02\x02\u{1ce}\u{1cd}\x03\
	\x02\x02\x02\u{1ce}\u{1cf}\x03\x02\x02\x02\u{1cf}\u{1d0}\x03\x02\x02\x02\
	\u{1d0}\u{1d4}\x07\u{145}\x02\x02\u{1d1}\u{1d2}\x07\u{96}\x02\x02\u{1d2}\
	\u{1d3}\x07\u{e1}\x02\x02\u{1d3}\u{1d5}\x07\x76\x02\x02\u{1d4}\u{1d1}\x03\
	\x02\x02\x02\u{1d4}\u{1d5}\x03\x02\x02\x02\u{1d5}\u{1d6}\x03\x02\x02\x02\
	\u{1d6}\u{1e2}\x05\u{13c}\u{9f}\x02\u{1d7}\u{1d8}\x09\x04\x02\x02\u{1d8}\
	\u{1e3}\x05\u{13c}\u{9f}\x02\u{1d9}\u{1da}\x07\x2d\x02\x02\u{1da}\u{1e0}\
	\x05\u{13c}\u{9f}\x02\u{1db}\u{1dc}\x07\u{81}\x02\x02\u{1dc}\u{1dd}\x07\
	\u{144}\x02\x02\u{1dd}\u{1de}\x07\x16\x02\x02\u{1de}\u{1df}\x07\u{e5}\x02\
	\x02\u{1df}\u{1e1}\x05\u{d6}\x6c\x02\u{1e0}\u{1db}\x03\x02\x02\x02\u{1e0}\
	\u{1e1}\x03\x02\x02\x02\u{1e1}\u{1e3}\x03\x02\x02\x02\u{1e2}\u{1d7}\x03\
	\x02\x02\x02\u{1e2}\u{1d9}\x03\x02\x02\x02\u{1e2}\u{1e3}\x03\x02\x02\x02\
	\u{1e3}\u{1eb}\x03\x02\x02\x02\u{1e4}\u{1e5}\x07\u{18d}\x02\x02\u{1e5}\u{1e7}\
	\x05\x10\x09\x02\u{1e6}\u{1e8}\x07\x34\x02\x02\u{1e7}\u{1e6}\x03\x02\x02\
	\x02\u{1e7}\u{1e8}\x03\x02\x02\x02\u{1e8}\u{1e9}\x03\x02\x02\x02\u{1e9}\
	\u{1ea}\x07\u{18e}\x02\x02\u{1ea}\u{1ec}\x03\x02\x02\x02\u{1eb}\u{1e4}\x03\
	\x02\x02\x02\u{1eb}\u{1ec}\x03\x02\x02\x02\u{1ec}\u{1f0}\x03\x02\x02\x02\
	\u{1ed}\u{1ee}\x07\x54\x02\x02\u{1ee}\u{1ef}\x07\x31\x02\x02\u{1ef}\u{1f1}\
	\x05\u{fa}\x7e\x02\u{1f0}\u{1ed}\x03\x02\x02\x02\u{1f0}\u{1f1}\x03\x02\x02\
	\x02\u{1f1}\u{1f5}\x03\x02\x02\x02\u{1f2}\u{1f3}\x07\u{f4}\x02\x02\u{1f3}\
	\u{1f4}\x07\x22\x02\x02\u{1f4}\u{1f6}\x05\u{d6}\x6c\x02\u{1f5}\u{1f2}\x03\
	\x02\x02\x02\u{1f5}\u{1f6}\x03\x02\x02\x02\u{1f6}\u{201}\x03\x02\x02\x02\
	\u{1f7}\u{1f8}\x07\x2f\x02\x02\u{1f8}\u{1f9}\x07\x22\x02\x02\u{1f9}\u{1fe}\
	\x05\u{144}\u{a3}\x02\u{1fa}\u{1fb}\x07\x34\x02\x02\u{1fb}\u{1fd}\x05\u{144}\
	\u{a3}\x02\u{1fc}\u{1fa}\x03\x02\x02\x02\u{1fd}\u{200}\x03\x02\x02\x02\u{1fe}\
	\u{1fc}\x03\x02\x02\x02\u{1fe}\u{1ff}\x03\x02\x02\x02\u{1ff}\u{202}\x03\
	\x02\x02\x02\u{200}\u{1fe}\x03\x02\x02\x02\u{201}\u{1f7}\x03\x02\x02\x02\
	\u{201}\u{202}\x03\x02\x02\x02\u{202}\u{205}\x03\x02\x02\x02\u{203}\u{204}\
	\x07\u{ec}\x02\x02\u{204}\u{206}\x05\x38\x1d\x02\u{205}\u{203}\x03\x02\x02\
	\x02\u{205}\u{206}\x03\x02\x02\x02\u{206}\u{209}\x03\x02\x02\x02\u{207}\
	\u{208}\x07\x16\x02\x02\u{208}\u{20a}\x05\x1c\x0f\x02\u{209}\u{207}\x03\
	\x02\x02\x02\u{209}\u{20a}\x03\x02\x02\x02\u{20a}\u{528}\x03\x02\x02\x02\
	\u{20b}\u{20c}\x07\x42\x02\x02\u{20c}\u{20d}\x07\u{139}\x02\x02\u{20d}\u{211}\
	\x07\u{145}\x02\x02\u{20e}\u{20f}\x07\u{96}\x02\x02\u{20f}\u{210}\x07\u{e1}\
	\x02\x02\u{210}\u{212}\x07\x76\x02\x02\u{211}\u{20e}\x03\x02\x02\x02\u{211}\
	\u{212}\x03\x02\x02\x02\u{212}\u{213}\x03\x02\x02\x02\u{213}\u{214}\x05\
	\u{13c}\u{9f}\x02\u{214}\u{215}\x07\x2d\x02\x02\u{215}\u{21b}\x05\u{13c}\
	\u{9f}\x02\u{216}\u{217}\x07\u{81}\x02\x02\u{217}\u{218}\x07\u{144}\x02\
	\x02\u{218}\u{219}\x07\x16\x02\x02\u{219}\u{21a}\x07\u{e5}\x02\x02\u{21a}\
	\u{21c}\x05\u{d6}\x6c\x02\u{21b}\u{216}\x03\x02\x02\x02\u{21b}\u{21c}\x03\
	\x02\x02\x02\u{21c}\u{21f}\x03\x02\x02\x02\u{21d}\u{21e}\x07\u{ec}\x02\x02\
	\u{21e}\u{220}\x05\x38\x1d\x02\u{21f}\u{21d}\x03\x02\x02\x02\u{21f}\u{220}\
	\x03\x02\x02\x02\u{220}\u{528}\x03\x02\x02\x02\u{221}\u{223}\x07\u{a1}\x02\
	\x02\u{222}\u{224}\x07\u{a4}\x02\x02\u{223}\u{222}\x03\x02\x02\x02\u{223}\
	\u{224}\x03\x02\x02\x02\u{224}\u{225}\x03\x02\x02\x02\u{225}\u{227}\x05\
	\u{13c}\u{9f}\x02\u{226}\u{228}\x05\u{bc}\x5f\x02\u{227}\u{226}\x03\x02\
	\x02\x02\u{227}\u{228}\x03\x02\x02\x02\u{228}\u{229}\x03\x02\x02\x02\u{229}\
	\u{22a}\x05\x1c\x0f\x02\u{22a}\u{528}\x03\x02\x02\x02\u{22b}\u{22e}\x07\
	\x42\x02\x02\u{22c}\u{22d}\x07\u{ed}\x02\x02\u{22d}\u{22f}\x07\u{113}\x02\
	\x02\u{22e}\u{22c}\x03\x02\x02\x02\u{22e}\u{22f}\x03\x02\x02\x02\u{22f}\
	\u{230}\x03\x02\x02\x02\u{230}\u{231}\x07\u{ca}\x02\x02\u{231}\u{235}\x07\
	\u{17c}\x02\x02\u{232}\u{233}\x07\u{96}\x02\x02\u{233}\u{234}\x07\u{e1}\
	\x02\x02\u{234}\u{236}\x07\x76\x02\x02\u{235}\u{232}\x03\x02\x02\x02\u{235}\
	\u{236}\x03\x02\x02\x02\u{236}\u{237}\x03\x02\x02\x02\u{237}\u{23b}\x05\
	\u{13c}\u{9f}\x02\u{238}\u{239}\x07\u{f4}\x02\x02\u{239}\u{23a}\x07\x22\
	\x02\x02\u{23a}\u{23c}\x05\u{d6}\x6c\x02\u{23b}\u{238}\x03\x02\x02\x02\u{23b}\
	\u{23c}\x03\x02\x02\x02\u{23c}\u{247}\x03\x02\x02\x02\u{23d}\u{23e}\x07\
	\x2f\x02\x02\u{23e}\u{23f}\x07\x22\x02\x02\u{23f}\u{244}\x05\u{144}\u{a3}\
	\x02\u{240}\u{241}\x07\x34\x02\x02\u{241}\u{243}\x05\u{144}\u{a3}\x02\u{242}\
	\u{240}\x03\x02\x02\x02\u{243}\u{246}\x03\x02\x02\x02\u{244}\u{242}\x03\
	\x02\x02\x02\u{244}\u{245}\x03\x02\x02\x02\u{245}\u{248}\x03\x02\x02\x02\
	\u{246}\u{244}\x03\x02\x02\x02\u{247}\u{23d}\x03\x02\x02\x02\u{247}\u{248}\
	\x03\x02\x02\x02\u{248}\u{24b}\x03\x02\x02\x02\u{249}\u{24a}\x07\u{ec}\x02\
	\x02\u{24a}\u{24c}\x05\x38\x1d\x02\u{24b}\u{249}\x03\x02\x02\x02\u{24b}\
	\u{24c}\x03\x02\x02\x02\u{24c}\u{24d}\x03\x02\x02\x02\u{24d}\u{24e}\x07\
	\x16\x02\x02\u{24e}\u{24f}\x05\x1c\x0f\x02\u{24f}\u{528}\x03\x02\x02\x02\
	\u{250}\u{253}\x07\x42\x02\x02\u{251}\u{252}\x07\u{ed}\x02\x02\u{252}\u{254}\
	\x07\u{113}\x02\x02\u{253}\u{251}\x03\x02\x02\x02\u{253}\u{254}\x03\x02\
	\x02\x02\u{254}\u{255}\x03\x02\x02\x02\u{255}\u{259}\x07\u{17c}\x02\x02\
	\u{256}\u{257}\x07\u{96}\x02\x02\u{257}\u{258}\x07\u{e1}\x02\x02\u{258}\
	\u{25a}\x07\x76\x02\x02\u{259}\u{256}\x03\x02\x02\x02\u{259}\u{25a}\x03\
	\x02\x02\x02\u{25a}\u{25b}\x03\x02\x02\x02\u{25b}\u{25d}\x05\u{13c}\u{9f}\
	\x02\u{25c}\u{25e}\x05\u{bc}\x5f\x02\u{25d}\u{25c}\x03\x02\x02\x02\u{25d}\
	\u{25e}\x03\x02\x02\x02\u{25e}\u{261}\x03\x02\x02\x02\u{25f}\u{260}\x07\
	\u{ec}\x02\x02\u{260}\u{262}\x05\x38\x1d\x02\u{261}\u{25f}\x03\x02\x02\x02\
	\u{261}\u{262}\x03\x02\x02\x02\u{262}\u{263}\x03\x02\x02\x02\u{263}\u{264}\
	\x07\x16\x02\x02\u{264}\u{265}\x05\x1c\x0f\x02\u{265}\u{528}\x03\x02\x02\
	\x02\u{266}\u{267}\x09\x05\x02\x02\u{267}\u{528}\x05\u{130}\u{99}\x02\u{268}\
	\u{269}\x07\u{137}\x02\x02\u{269}\u{26a}\x07\x33\x02\x02\u{26a}\u{26b}\x07\
	\u{84}\x02\x02\u{26b}\u{528}\x05\u{130}\u{99}\x02\u{26c}\u{26e}\x07\u{cd}\
	\x02\x02\u{26d}\u{26f}\x07\u{a4}\x02\x02\u{26e}\u{26d}\x03\x02\x02\x02\u{26e}\
	\u{26f}\x03\x02\x02\x02\u{26f}\u{270}\x03\x02\x02\x02\u{270}\u{275}\x05\
	\u{130}\u{99}\x02\u{271}\u{273}\x07\x16\x02\x02\u{272}\u{271}\x03\x02\x02\
	\x02\u{272}\u{273}\x03\x02\x02\x02\u{273}\u{274}\x03\x02\x02\x02\u{274}\
	\u{276}\x05\u{144}\u{a3}\x02\u{275}\u{272}\x03\x02\x02\x02\u{275}\u{276}\
	\x03\x02\x02\x02\u{276}\u{277}\x03\x02\x02\x02\u{277}\u{278}\x07\u{171}\
	\x02\x02\u{278}\u{279}\x05\u{ba}\x5e\x02\u{279}\u{27a}\x07\u{e8}\x02\x02\
	\u{27a}\u{27c}\x05\u{d8}\x6d\x02\u{27b}\u{27d}\x05\u{116}\u{8c}\x02\u{27c}\
	\u{27b}\x03\x02\x02\x02\u{27d}\u{27e}\x03\x02\x02\x02\u{27e}\u{27c}\x03\
	\x02\x02\x02\u{27e}\u{27f}\x03\x02\x02\x02\u{27f}\u{528}\x03\x02\x02\x02\
	\u{280}\u{283}\x07\x42\x02\x02\u{281}\u{282}\x07\u{ed}\x02\x02\u{282}\u{284}\
	\x07\u{113}\x02\x02\u{283}\u{281}\x03\x02\x02\x02\u{283}\u{284}\x03\x02\
	\x02\x02\u{284}\u{286}\x03\x02\x02\x02\u{285}\u{287}\x09\x03\x02\x02\u{286}\
	\u{285}\x03\x02\x02\x02\u{286}\u{287}\x03\x02\x02\x02\u{287}\u{288}\x03\
	\x02\x02\x02\u{288}\u{28c}\x07\u{86}\x02\x02\u{289}\u{28a}\x07\u{96}\x02\
	\x02\u{28a}\u{28b}\x07\u{e1}\x02\x02\u{28b}\u{28d}\x07\x76\x02\x02\u{28c}\
	\u{289}\x03\x02\x02\x02\u{28c}\u{28d}\x03\x02\x02\x02\u{28d}\u{28e}\x03\
	\x02\x02\x02\u{28e}\u{28f}\x05\u{130}\u{99}\x02\u{28f}\u{29b}\x07\u{18d}\
	\x02\x02\u{290}\u{295}\x05\u{f2}\x7a\x02\u{291}\u{292}\x07\x34\x02\x02\u{292}\
	\u{294}\x05\u{f2}\x7a\x02\u{293}\u{291}\x03\x02\x02\x02\u{294}\u{297}\x03\
	\x02\x02\x02\u{295}\u{293}\x03\x02\x02\x02\u{295}\u{296}\x03\x02\x02\x02\
	\u{296}\u{299}\x03\x02\x02\x02\u{297}\u{295}\x03\x02\x02\x02\u{298}\u{29a}\
	\x07\x34\x02\x02\u{299}\u{298}\x03\x02\x02\x02\u{299}\u{29a}\x03\x02\x02\
	\x02\u{29a}\u{29c}\x03\x02\x02\x02\u{29b}\u{290}\x03\x02\x02\x02\u{29b}\
	\u{29c}\x03\x02\x02\x02\u{29c}\u{29d}\x03\x02\x02\x02\u{29d}\u{2a0}\x07\
	\u{18e}\x02\x02\u{29e}\u{29f}\x07\u{11b}\x02\x02\u{29f}\u{2a1}\x05\u{10a}\
	\u{86}\x02\u{2a0}\u{29e}\x03\x02\x02\x02\u{2a0}\u{2a1}\x03\x02\x02\x02\u{2a1}\
	\u{2a2}\x03\x02\x02\x02\u{2a2}\u{2a3}\x07\x16\x02\x02\u{2a3}\u{2a9}\x05\
	\u{d6}\x6c\x02\u{2a4}\u{2a5}\x07\u{ec}\x02\x02\u{2a5}\u{2a6}\x07\u{18d}\
	\x02\x02\u{2a6}\u{2a7}\x05\x2c\x17\x02\u{2a7}\u{2a8}\x07\u{18e}\x02\x02\
	\u{2a8}\u{2aa}\x03\x02\x02\x02\u{2a9}\u{2a4}\x03\x02\x02\x02\u{2a9}\u{2aa}\
	\x03\x02\x02\x02\u{2aa}\u{528}\x03\x02\x02\x02\u{2ab}\u{2ae}\x07\x42\x02\
	\x02\u{2ac}\u{2ad}\x07\u{ed}\x02\x02\u{2ad}\u{2af}\x07\u{113}\x02\x02\u{2ae}\
	\u{2ac}\x03\x02\x02\x02\u{2ae}\u{2af}\x03\x02\x02\x02\u{2af}\u{2b1}\x03\
	\x02\x02\x02\u{2b0}\u{2b2}\x09\x03\x02\x02\u{2b1}\u{2b0}\x03\x02\x02\x02\
	\u{2b1}\u{2b2}\x03\x02\x02\x02\u{2b2}\u{2b3}\x03\x02\x02\x02\u{2b3}\u{2b7}\
	\x07\u{86}\x02\x02\u{2b4}\u{2b5}\x07\u{96}\x02\x02\u{2b5}\u{2b6}\x07\u{e1}\
	\x02\x02\u{2b6}\u{2b8}\x07\x76\x02\x02\u{2b7}\u{2b4}\x03\x02\x02\x02\u{2b7}\
	\u{2b8}\x03\x02\x02\x02\u{2b8}\u{2b9}\x03\x02\x02\x02\u{2b9}\u{2ba}\x05\
	\u{130}\u{99}\x02\u{2ba}\u{2c6}\x07\u{18d}\x02\x02\u{2bb}\u{2c0}\x05\u{f2}\
	\x7a\x02\u{2bc}\u{2bd}\x07\x34\x02\x02\u{2bd}\u{2bf}\x05\u{f2}\x7a\x02\u{2be}\
	\u{2bc}\x03\x02\x02\x02\u{2bf}\u{2c2}\x03\x02\x02\x02\u{2c0}\u{2be}\x03\
	\x02\x02\x02\u{2c0}\u{2c1}\x03\x02\x02\x02\u{2c1}\u{2c4}\x03\x02\x02\x02\
	\u{2c2}\u{2c0}\x03\x02\x02\x02\u{2c3}\u{2c5}\x07\x34\x02\x02\u{2c4}\u{2c3}\
	\x03\x02\x02\x02\u{2c4}\u{2c5}\x03\x02\x02\x02\u{2c5}\u{2c7}\x03\x02\x02\
	\x02\u{2c6}\u{2bb}\x03\x02\x02\x02\u{2c6}\u{2c7}\x03\x02\x02\x02\u{2c7}\
	\u{2c8}\x03\x02\x02\x02\u{2c8}\u{2c9}\x07\u{18e}\x02\x02\u{2c9}\u{2ca}\x07\
	\u{11b}\x02\x02\u{2ca}\u{2ce}\x05\u{10a}\u{86}\x02\u{2cb}\u{2cf}\x07\x5f\
	\x02\x02\u{2cc}\u{2cd}\x07\u{e1}\x02\x02\u{2cd}\u{2cf}\x07\x5f\x02\x02\u{2ce}\
	\u{2cb}\x03\x02\x02\x02\u{2ce}\u{2cc}\x03\x02\x02\x02\u{2ce}\u{2cf}\x03\
	\x02\x02\x02\u{2cf}\u{2d0}\x03\x02\x02\x02\u{2d0}\u{2d1}\x07\u{b3}\x02\x02\
	\u{2d1}\u{2e4}\x05\u{144}\u{a3}\x02\u{2d2}\u{2d3}\x07\u{ec}\x02\x02\u{2d3}\
	\u{2d4}\x07\u{18d}\x02\x02\u{2d4}\u{2d5}\x05\x2c\x17\x02\u{2d5}\u{2d6}\x07\
	\u{18e}\x02\x02\u{2d6}\u{2d8}\x03\x02\x02\x02\u{2d7}\u{2d2}\x03\x02\x02\
	\x02\u{2d7}\u{2d8}\x03\x02\x02\x02\u{2d8}\u{2d9}\x03\x02\x02\x02\u{2d9}\
	\u{2da}\x07\x16\x02\x02\u{2da}\u{2e5}\x05\u{fa}\x7e\x02\u{2db}\u{2dc}\x07\
	\x16\x02\x02\u{2dc}\u{2e2}\x05\u{fa}\x7e\x02\u{2dd}\u{2de}\x07\u{ec}\x02\
	\x02\u{2de}\u{2df}\x07\u{18d}\x02\x02\u{2df}\u{2e0}\x05\x2c\x17\x02\u{2e0}\
	\u{2e1}\x07\u{18e}\x02\x02\u{2e1}\u{2e3}\x03\x02\x02\x02\u{2e2}\u{2dd}\x03\
	\x02\x02\x02\u{2e2}\u{2e3}\x03\x02\x02\x02\u{2e3}\u{2e5}\x03\x02\x02\x02\
	\u{2e4}\u{2d7}\x03\x02\x02\x02\u{2e4}\u{2db}\x03\x02\x02\x02\u{2e5}\u{528}\
	\x03\x02\x02\x02\u{2e6}\u{2e9}\x07\x42\x02\x02\u{2e7}\u{2e8}\x07\u{ed}\x02\
	\x02\u{2e8}\u{2ea}\x07\u{113}\x02\x02\u{2e9}\u{2e7}\x03\x02\x02\x02\u{2e9}\
	\u{2ea}\x03\x02\x02\x02\u{2ea}\u{2eb}\x03\x02\x02\x02\u{2eb}\u{2ef}\x07\
	\u{86}\x02\x02\u{2ec}\u{2ed}\x07\u{96}\x02\x02\u{2ed}\u{2ee}\x07\u{e1}\x02\
	\x02\u{2ee}\u{2f0}\x07\x76\x02\x02\u{2ef}\u{2ec}\x03\x02\x02\x02\u{2ef}\
	\u{2f0}\x03\x02\x02\x02\u{2f0}\u{2f1}\x03\x02\x02\x02\u{2f1}\u{2f2}\x05\
	\u{130}\u{99}\x02\u{2f2}\u{2fe}\x07\u{18d}\x02\x02\u{2f3}\u{2f8}\x05\u{f2}\
	\x7a\x02\u{2f4}\u{2f5}\x07\x34\x02\x02\u{2f5}\u{2f7}\x05\u{f2}\x7a\x02\u{2f6}\
	\u{2f4}\x03\x02\x02\x02\u{2f7}\u{2fa}\x03\x02\x02\x02\u{2f8}\u{2f6}\x03\
	\x02\x02\x02\u{2f8}\u{2f9}\x03\x02\x02\x02\u{2f9}\u{2fc}\x03\x02\x02\x02\
	\u{2fa}\u{2f8}\x03\x02\x02\x02\u{2fb}\u{2fd}\x07\x34\x02\x02\u{2fc}\u{2fb}\
	\x03\x02\x02\x02\u{2fc}\u{2fd}\x03\x02\x02\x02\u{2fd}\u{2ff}\x03\x02\x02\
	\x02\u{2fe}\u{2f3}\x03\x02\x02\x02\u{2fe}\u{2ff}\x03\x02\x02\x02\u{2ff}\
	\u{300}\x03\x02\x02\x02\u{300}\u{301}\x07\u{18e}\x02\x02\u{301}\u{302}\x07\
	\u{11b}\x02\x02\u{302}\u{303}\x05\u{10a}\u{86}\x02\u{303}\u{304}\x07\u{119}\
	\x02\x02\u{304}\u{30a}\x05\x1a\x0e\x02\u{305}\u{306}\x07\u{ec}\x02\x02\u{306}\
	\u{307}\x07\u{18d}\x02\x02\u{307}\u{308}\x05\x2c\x17\x02\u{308}\u{309}\x07\
	\u{18e}\x02\x02\u{309}\u{30b}\x03\x02\x02\x02\u{30a}\u{305}\x03\x02\x02\
	\x02\u{30a}\u{30b}\x03\x02\x02\x02\u{30b}\u{528}\x03\x02\x02\x02\u{30c}\
	\u{30f}\x07\x42\x02\x02\u{30d}\u{30e}\x07\u{ed}\x02\x02\u{30e}\u{310}\x07\
	\u{113}\x02\x02\u{30f}\u{30d}\x03\x02\x02\x02\u{30f}\u{310}\x03\x02\x02\
	\x02\u{310}\u{311}\x03\x02\x02\x02\u{311}\u{315}\x07\u{d4}\x02\x02\u{312}\
	\u{313}\x07\u{96}\x02\x02\u{313}\u{314}\x07\u{e1}\x02\x02\u{314}\u{316}\
	\x07\x76\x02\x02\u{315}\u{312}\x03\x02\x02\x02\u{315}\u{316}\x03\x02\x02\
	\x02\u{316}\u{317}\x03\x02\x02\x02\u{317}\u{31a}\x05\u{13c}\u{9f}\x02\u{318}\
	\u{319}\x07\u{15a}\x02\x02\u{319}\u{31b}\x05\x62\x32\x02\u{31a}\u{318}\x03\
	\x02\x02\x02\u{31a}\u{31b}\x03\x02\x02\x02\u{31b}\u{323}\x03\x02\x02\x02\
	\u{31c}\u{31d}\x07\u{9e}\x02\x02\u{31d}\u{31e}\x05\u{144}\u{a3}\x02\u{31e}\
	\u{31f}\x05\u{10a}\u{86}\x02\u{31f}\u{320}\x07\u{f0}\x02\x02\u{320}\u{321}\
	\x05\u{144}\u{a3}\x02\u{321}\u{322}\x05\u{10a}\u{86}\x02\u{322}\u{324}\x03\
	\x02\x02\x02\u{323}\u{31c}\x03\x02\x02\x02\u{323}\u{324}\x03\x02\x02\x02\
	\u{324}\u{32c}\x03\x02\x02\x02\u{325}\u{326}\x07\u{119}\x02\x02\u{326}\u{327}\
	\x07\u{183}\x02\x02\u{327}\u{328}\x07\x3c\x02\x02\u{328}\u{329}\x07\x03\
	\x02\x02\u{329}\u{32a}\x05\u{144}\u{a3}\x02\u{32a}\u{32b}\x07\x03\x02\x02\
	\u{32b}\u{32d}\x03\x02\x02\x02\u{32c}\u{325}\x03\x02\x02\x02\u{32c}\u{32d}\
	\x03\x02\x02\x02\u{32d}\u{330}\x03\x02\x02\x02\u{32e}\u{32f}\x07\u{ec}\x02\
	\x02\u{32f}\u{331}\x05\x38\x1d\x02\u{330}\u{32e}\x03\x02\x02\x02\u{330}\
	\u{331}\x03\x02\x02\x02\u{331}\u{332}\x03\x02\x02\x02\u{332}\u{340}\x07\
	\x16\x02\x02\u{333}\u{341}\x05\x1c\x0f\x02\u{334}\u{335}\x07\u{158}\x02\
	\x02\u{335}\u{336}\x07\x16\x02\x02\u{336}\u{337}\x07\u{18d}\x02\x02\u{337}\
	\u{338}\x05\x1c\x0f\x02\u{338}\u{339}\x07\u{18e}\x02\x02\u{339}\u{341}\x03\
	\x02\x02\x02\u{33a}\u{33b}\x07\x47\x02\x02\u{33b}\u{33c}\x07\x16\x02\x02\
	\u{33c}\u{33d}\x07\u{18d}\x02\x02\u{33d}\u{33e}\x05\x1c\x0f\x02\u{33e}\u{33f}\
	\x07\u{18e}\x02\x02\u{33f}\u{341}\x03\x02\x02\x02\u{340}\u{333}\x03\x02\
	\x02\x02\u{340}\u{334}\x03\x02\x02\x02\u{340}\u{33a}\x03\x02\x02\x02\u{341}\
	\u{528}\x03\x02\x02\x02\u{342}\u{343}\x07\x53\x02\x02\u{343}\u{348}\x05\
	\u{144}\u{a3}\x02\u{344}\u{345}\x07\x34\x02\x02\u{345}\u{347}\x05\u{144}\
	\u{a3}\x02\u{346}\u{344}\x03\x02\x02\x02\u{347}\u{34a}\x03\x02\x02\x02\u{348}\
	\u{346}\x03\x02\x02\x02\u{348}\u{349}\x03\x02\x02\x02\u{349}\u{34c}\x03\
	\x02\x02\x02\u{34a}\u{348}\x03\x02\x02\x02\u{34b}\u{34d}\x05\u{10a}\u{86}\
	\x02\u{34c}\u{34b}\x03\x02\x02\x02\u{34c}\u{34d}\x03\x02\x02\x02\u{34d}\
	\u{350}\x03\x02\x02\x02\u{34e}\u{34f}\x07\x54\x02\x02\u{34f}\u{351}\x05\
	\u{d6}\x6c\x02\u{350}\u{34e}\x03\x02\x02\x02\u{350}\u{351}\x03\x02\x02\x02\
	\u{351}\u{528}\x03\x02\x02\x02\u{352}\u{353}\x07\x75\x02\x02\u{353}\u{354}\
	\x07\u{98}\x02\x02\u{354}\u{35e}\x05\u{d6}\x6c\x02\u{355}\u{356}\x07\u{a4}\
	\x02\x02\u{356}\u{35b}\x05\u{144}\u{a3}\x02\u{357}\u{358}\x07\x34\x02\x02\
	\u{358}\u{35a}\x05\u{144}\u{a3}\x02\u{359}\u{357}\x03\x02\x02\x02\u{35a}\
	\u{35d}\x03\x02\x02\x02\u{35b}\u{359}\x03\x02\x02\x02\u{35b}\u{35c}\x03\
	\x02\x02\x02\u{35c}\u{35f}\x03\x02\x02\x02\u{35d}\u{35b}\x03\x02\x02\x02\
	\u{35e}\u{355}\x03\x02\x02\x02\u{35e}\u{35f}\x03\x02\x02\x02\u{35f}\u{369}\
	\x03\x02\x02\x02\u{360}\u{361}\x07\u{171}\x02\x02\u{361}\u{366}\x05\u{144}\
	\u{a3}\x02\u{362}\u{363}\x07\x34\x02\x02\u{363}\u{365}\x05\u{144}\u{a3}\
	\x02\u{364}\u{362}\x03\x02\x02\x02\u{365}\u{368}\x03\x02\x02\x02\u{366}\
	\u{364}\x03\x02\x02\x02\u{366}\u{367}\x03\x02\x02\x02\u{367}\u{36a}\x03\
	\x02\x02\x02\u{368}\u{366}\x03\x02\x02\x02\u{369}\u{360}\x03\x02\x02\x02\
	\u{369}\u{36a}\x03\x02\x02\x02\u{36a}\u{528}\x03\x02\x02\x02\u{36b}\u{36c}\
	\x07\x1d\x02\x02\u{36c}\u{36d}\x05\x0c\x07\x02\u{36d}\u{36e}\x07\x6d\x02\
	\x02\u{36e}\u{528}\x03\x02\x02\x02\u{36f}\u{370}\x07\x1d\x02\x02\u{370}\
	\u{371}\x05\x0c\x07\x02\u{371}\u{372}\x07\x72\x02\x02\u{372}\u{373}\x07\
	\u{17f}\x02\x02\u{373}\u{374}\x07\x6e\x02\x02\u{374}\u{375}\x07\u{14d}\x02\
	\x02\u{375}\u{376}\x05\x0c\x07\x02\u{376}\u{377}\x07\x6d\x02\x02\u{377}\
	\u{528}\x03\x02\x02\x02\u{378}\u{37a}\x07\x27\x02\x02\u{379}\u{37b}\x05\
	\u{d6}\x6c\x02\u{37a}\u{379}\x03\x02\x02\x02\u{37a}\u{37b}\x03\x02\x02\x02\
	\u{37b}\u{381}\x03\x02\x02\x02\u{37c}\u{37d}\x07\u{17f}\x02\x02\u{37d}\u{37e}\
	\x05\u{d8}\x6d\x02\u{37e}\u{37f}\x07\u{14d}\x02\x02\u{37f}\u{380}\x05\x0c\
	\x07\x02\u{380}\u{382}\x03\x02\x02\x02\u{381}\u{37c}\x03\x02\x02\x02\u{382}\
	\u{383}\x03\x02\x02\x02\u{383}\u{381}\x03\x02\x02\x02\u{383}\u{384}\x03\
	\x02\x02\x02\u{384}\u{387}\x03\x02\x02\x02\u{385}\u{386}\x07\x68\x02\x02\
	\u{386}\u{388}\x05\x0c\x07\x02\u{387}\u{385}\x03\x02\x02\x02\u{387}\u{388}\
	\x03\x02\x02\x02\u{388}\u{389}\x03\x02\x02\x02\u{389}\u{38a}\x07\x6d\x02\
	\x02\u{38a}\u{38b}\x07\x27\x02\x02\u{38b}\u{528}\x03\x02\x02\x02\u{38c}\
	\u{38d}\x07\u{96}\x02\x02\u{38d}\u{38e}\x05\u{d8}\x6d\x02\u{38e}\u{38f}\
	\x07\u{14d}\x02\x02\u{38f}\u{397}\x05\x0c\x07\x02\u{390}\u{391}\x07\x69\
	\x02\x02\u{391}\u{392}\x05\u{d8}\x6d\x02\u{392}\u{393}\x07\u{14d}\x02\x02\
	\u{393}\u{394}\x05\x0c\x07\x02\u{394}\u{396}\x03\x02\x02\x02\u{395}\u{390}\
	\x03\x02\x02\x02\u{396}\u{399}\x03\x02\x02\x02\u{397}\u{395}\x03\x02\x02\
	\x02\u{397}\u{398}\x03\x02\x02\x02\u{398}\u{39c}\x03\x02\x02\x02\u{399}\
	\u{397}\x03\x02\x02\x02\u{39a}\u{39b}\x07\x68\x02\x02\u{39b}\u{39d}\x05\
	\x0c\x07\x02\u{39c}\u{39a}\x03\x02\x02\x02\u{39c}\u{39d}\x03\x02\x02\x02\
	\u{39d}\u{39e}\x03\x02\x02\x02\u{39e}\u{39f}\x07\x6d\x02\x02\u{39f}\u{3a0}\
	\x07\u{96}\x02\x02\u{3a0}\u{528}\x03\x02\x02\x02\u{3a1}\u{3a2}\x07\u{c3}\
	\x02\x02\u{3a2}\u{3a3}\x05\x0c\x07\x02\u{3a3}\u{3a4}\x07\x6d\x02\x02\u{3a4}\
	\u{3a5}\x07\u{c3}\x02\x02\u{3a5}\u{528}\x03\x02\x02\x02\u{3a6}\u{3a7}\x07\
	\u{11a}\x02\x02\u{3a7}\u{3a8}\x05\x0c\x07\x02\u{3a8}\u{3a9}\x07\u{16d}\x02\
	\x02\u{3a9}\u{3aa}\x05\u{d8}\x6d\x02\u{3aa}\u{3ab}\x07\x6d\x02\x02\u{3ab}\
	\u{3ac}\x07\u{11a}\x02\x02\u{3ac}\u{528}\x03\x02\x02\x02\u{3ad}\u{3ae}\x07\
	\u{181}\x02\x02\u{3ae}\u{3af}\x05\u{d8}\x6d\x02\u{3af}\u{3b0}\x07\x65\x02\
	\x02\u{3b0}\u{3b1}\x05\x0c\x07\x02\u{3b1}\u{3b2}\x07\x6d\x02\x02\u{3b2}\
	\u{3b3}\x07\u{181}\x02\x02\u{3b3}\u{528}\x03\x02\x02\x02\u{3b4}\u{528}\x07\
	\x21\x02\x02\u{3b5}\u{528}\x07\u{b4}\x02\x02\u{3b6}\u{528}\x07\x3e\x02\x02\
	\u{3b7}\u{528}\x07\u{ab}\x02\x02\u{3b8}\u{3b9}\x07\u{81}\x02\x02\u{3b9}\
	\u{3ba}\x05\u{144}\u{a3}\x02\u{3ba}\u{3bb}\x07\u{99}\x02\x02\u{3bb}\u{3bc}\
	\x07\u{18d}\x02\x02\u{3bc}\u{3bd}\x05\x1c\x0f\x02\u{3bd}\u{3be}\x07\u{18e}\
	\x02\x02\u{3be}\u{3bf}\x07\x65\x02\x02\u{3bf}\u{3c0}\x05\x0c\x07\x02\u{3c0}\
	\u{3c1}\x07\x6d\x02\x02\u{3c1}\u{3c2}\x07\u{81}\x02\x02\u{3c2}\u{528}\x03\
	\x02\x02\x02\u{3c3}\u{3c8}\x07\u{10c}\x02\x02\u{3c4}\u{3c5}\x07\u{171}\x02\
	\x02\u{3c5}\u{3c6}\x07\u{ce}\x02\x02\u{3c6}\u{3c7}\x07\u{192}\x02\x02\u{3c7}\
	\u{3c9}\x05\u{fa}\x7e\x02\u{3c8}\u{3c4}\x03\x02\x02\x02\u{3c8}\u{3c9}\x03\
	\x02\x02\x02\u{3c9}\u{528}\x03\x02\x02\x02\u{3ca}\u{528}\x07\u{117}\x02\
	\x02\u{3cb}\u{3cd}\x07\x1d\x02\x02\u{3cc}\u{3ce}\x07\u{159}\x02\x02\u{3cd}\
	\u{3cc}\x03\x02\x02\x02\u{3cd}\u{3ce}\x03\x02\x02\x02\u{3ce}\u{528}\x03\
	\x02\x02\x02\u{3cf}\u{3d1}\x07\x36\x02\x02\u{3d0}\u{3d2}\x07\u{159}\x02\
	\x02\u{3d1}\u{3d0}\x03\x02\x02\x02\u{3d1}\u{3d2}\x03\x02\x02\x02\u{3d2}\
	\u{528}\x03\x02\x02\x02\u{3d3}\u{3d5}\x07\u{121}\x02\x02\u{3d4}\u{3d6}\x07\
	\u{159}\x02\x02\u{3d5}\u{3d4}\x03\x02\x02\x02\u{3d5}\u{3d6}\x03\x02\x02\
	\x02\u{3d6}\u{528}\x03\x02\x02\x02\u{3d7}\u{3db}\x07\u{135}\x02\x02\u{3d8}\
	\u{3da}\x0a\x02\x02\x02\u{3d9}\u{3d8}\x03\x02\x02\x02\u{3da}\u{3dd}\x03\
	\x02\x02\x02\u{3db}\u{3d9}\x03\x02\x02\x02\u{3db}\u{3dc}\x03\x02\x02\x02\
	\u{3dc}\u{528}\x03\x02\x02\x02\u{3dd}\u{3db}\x03\x02\x02\x02\u{3de}\u{3e1}\
	\x07\x42\x02\x02\u{3df}\u{3e0}\x07\u{ed}\x02\x02\u{3e0}\u{3e2}\x07\u{113}\
	\x02\x02\u{3e1}\u{3df}\x03\x02\x02\x02\u{3e1}\u{3e2}\x03\x02\x02\x02\u{3e2}\
	\u{3e3}\x03\x02\x02\x02\u{3e3}\u{3e7}\x07\u{12b}\x02\x02\u{3e4}\u{3e6}\x0a\
	\x02\x02\x02\u{3e5}\u{3e4}\x03\x02\x02\x02\u{3e6}\u{3e9}\x03\x02\x02\x02\
	\u{3e7}\u{3e5}\x03\x02\x02\x02\u{3e7}\u{3e8}\x03\x02\x02\x02\u{3e8}\u{528}\
	\x03\x02\x02\x02\u{3e9}\u{3e7}\x03\x02\x02\x02\u{3ea}\u{3ee}\x07\x67\x02\
	\x02\u{3eb}\u{3ed}\x0a\x02\x02\x02\u{3ec}\u{3eb}\x03\x02\x02\x02\u{3ed}\
	\u{3f0}\x03\x02\x02\x02\u{3ee}\u{3ec}\x03\x02\x02\x02\u{3ee}\u{3ef}\x03\
	\x02\x02\x02\u{3ef}\u{528}\x03\x02\x02\x02\u{3f0}\u{3ee}\x03\x02\x02\x02\
	\u{3f1}\u{3f5}\x07\x58\x02\x02\u{3f2}\u{3f4}\x0a\x02\x02\x02\u{3f3}\u{3f2}\
	\x03\x02\x02\x02\u{3f4}\u{3f7}\x03\x02\x02\x02\u{3f5}\u{3f3}\x03\x02\x02\
	\x02\u{3f5}\u{3f6}\x03\x02\x02\x02\u{3f6}\u{528}\x03\x02\x02\x02\u{3f7}\
	\u{3f5}\x03\x02\x02\x02\u{3f8}\u{3fc}\x07\u{15d}\x02\x02\u{3f9}\u{3fb}\x0a\
	\x02\x02\x02\u{3fa}\u{3f9}\x03\x02\x02\x02\u{3fb}\u{3fe}\x03\x02\x02\x02\
	\u{3fc}\u{3fa}\x03\x02\x02\x02\u{3fc}\u{3fd}\x03\x02\x02\x02\u{3fd}\u{528}\
	\x03\x02\x02\x02\u{3fe}\u{3fc}\x03\x02\x02\x02\u{3ff}\u{403}\x07\x35\x02\
	\x02\u{400}\u{402}\x0a\x02\x02\x02\u{401}\u{400}\x03\x02\x02\x02\u{402}\
	\u{405}\x03\x02\x02\x02\u{403}\u{401}\x03\x02\x02\x02\u{403}\u{404}\x03\
	\x02\x02\x02\u{404}\u{528}\x03\x02\x02\x02\u{405}\u{403}\x03\x02\x02\x02\
	\u{406}\u{407}\x07\x10\x02\x02\u{407}\u{40a}\x07\u{145}\x02\x02\u{408}\u{409}\
	\x07\u{96}\x02\x02\u{409}\u{40b}\x07\x76\x02\x02\u{40a}\u{408}\x03\x02\x02\
	\x02\u{40a}\u{40b}\x03\x02\x02\x02\u{40b}\u{40c}\x03\x02\x02\x02\u{40c}\
	\u{40d}\x05\u{130}\u{99}\x02\u{40d}\u{40e}\x07\u{111}\x02\x02\u{40e}\u{40f}\
	\x07\u{153}\x02\x02\u{40f}\u{410}\x05\u{130}\u{99}\x02\u{410}\u{528}\x03\
	\x02\x02\x02\u{411}\u{412}\x07\x10\x02\x02\u{412}\u{415}\x07\u{145}\x02\
	\x02\u{413}\u{414}\x07\u{96}\x02\x02\u{414}\u{416}\x07\x76\x02\x02\u{415}\
	\u{413}\x03\x02\x02\x02\u{415}\u{416}\x03\x02\x02\x02\u{416}\u{417}\x03\
	\x02\x02\x02\u{417}\u{418}\x05\u{130}\u{99}\x02\u{418}\u{419}\x07\x0c\x02\
	\x02\u{419}\u{41d}\x07\x32\x02\x02\u{41a}\u{41b}\x07\u{96}\x02\x02\u{41b}\
	\u{41c}\x07\u{e1}\x02\x02\u{41c}\u{41e}\x07\x76\x02\x02\u{41d}\u{41a}\x03\
	\x02\x02\x02\u{41d}\u{41e}\x03\x02\x02\x02\u{41e}\u{41f}\x03\x02\x02\x02\
	\u{41f}\u{420}\x05\x22\x12\x02\u{420}\u{528}\x03\x02\x02\x02\u{421}\u{422}\
	\x07\x10\x02\x02\u{422}\u{425}\x07\u{145}\x02\x02\u{423}\u{424}\x07\u{96}\
	\x02\x02\u{424}\u{426}\x07\x76\x02\x02\u{425}\u{423}\x03\x02\x02\x02\u{425}\
	\u{426}\x03\x02\x02\x02\u{426}\u{427}\x03\x02\x02\x02\u{427}\u{428}\x05\
	\u{130}\u{99}\x02\u{428}\u{429}\x07\u{111}\x02\x02\u{429}\u{42c}\x07\x32\
	\x02\x02\u{42a}\u{42b}\x07\u{96}\x02\x02\u{42b}\u{42d}\x07\x76\x02\x02\u{42c}\
	\u{42a}\x03\x02\x02\x02\u{42c}\u{42d}\x03\x02\x02\x02\u{42d}\u{42e}\x03\
	\x02\x02\x02\u{42e}\u{42f}\x05\u{144}\u{a3}\x02\u{42f}\u{430}\x07\u{153}\
	\x02\x02\u{430}\u{431}\x05\u{144}\u{a3}\x02\u{431}\u{528}\x03\x02\x02\x02\
	\u{432}\u{433}\x07\x10\x02\x02\u{433}\u{436}\x07\u{145}\x02\x02\u{434}\u{435}\
	\x07\u{96}\x02\x02\u{435}\u{437}\x07\x76\x02\x02\u{436}\u{434}\x03\x02\x02\
	\x02\u{436}\u{437}\x03\x02\x02\x02\u{437}\u{438}\x03\x02\x02\x02\u{438}\
	\u{439}\x05\u{130}\u{99}\x02\u{439}\u{43a}\x07\x67\x02\x02\u{43a}\u{43d}\
	\x07\x32\x02\x02\u{43b}\u{43c}\x07\u{96}\x02\x02\u{43c}\u{43e}\x07\x76\x02\
	\x02\u{43d}\u{43b}\x03\x02\x02\x02\u{43d}\u{43e}\x03\x02\x02\x02\u{43e}\
	\u{43f}\x03\x02\x02\x02\u{43f}\u{440}\x05\u{130}\u{99}\x02\u{440}\u{528}\
	\x03\x02\x02\x02\u{441}\u{442}\x07\x10\x02\x02\u{442}\u{445}\x07\u{145}\
	\x02\x02\u{443}\u{444}\x07\u{96}\x02\x02\u{444}\u{446}\x07\x76\x02\x02\u{445}\
	\u{443}\x03\x02\x02\x02\u{445}\u{446}\x03\x02\x02\x02\u{446}\u{447}\x03\
	\x02\x02\x02\u{447}\u{448}\x05\u{130}\u{99}\x02\u{448}\u{449}\x07\x10\x02\
	\x02\u{449}\u{44a}\x07\x32\x02\x02\u{44a}\u{44b}\x05\u{144}\u{a3}\x02\u{44b}\
	\u{44c}\x07\u{135}\x02\x02\u{44c}\u{44d}\x07\x48\x02\x02\u{44d}\u{44e}\x07\
	\u{161}\x02\x02\u{44e}\u{44f}\x05\u{10a}\u{86}\x02\u{44f}\u{528}\x03\x02\
	\x02\x02\u{450}\u{451}\x07\x10\x02\x02\u{451}\u{452}\x07\u{145}\x02\x02\
	\u{452}\u{453}\x05\u{130}\u{99}\x02\u{453}\u{454}\x07\u{135}\x02\x02\u{454}\
	\u{455}\x07\x1a\x02\x02\u{455}\u{456}\x05\u{142}\u{a2}\x02\u{456}\u{528}\
	\x03\x02\x02\x02\u{457}\u{458}\x07\x10\x02\x02\u{458}\u{459}\x07\u{145}\
	\x02\x02\u{459}\u{45a}\x05\u{130}\u{99}\x02\u{45a}\u{45b}\x07\u{135}\x02\
	\x02\u{45b}\u{45c}\x07\u{107}\x02\x02\u{45c}\u{45d}\x05\x3a\x1e\x02\u{45d}\
	\u{528}\x03\x02\x02\x02\u{45e}\u{45f}\x07\x10\x02\x02\u{45f}\u{460}\x07\
	\u{145}\x02\x02\u{460}\u{461}\x05\u{130}\u{99}\x02\u{461}\u{462}\x07\x75\
	\x02\x02\u{462}\u{472}\x05\u{144}\u{a3}\x02\u{463}\u{46c}\x07\u{18d}\x02\
	\x02\u{464}\u{469}\x05\u{e4}\x73\x02\u{465}\u{466}\x07\x34\x02\x02\u{466}\
	\u{468}\x05\u{e4}\x73\x02\u{467}\u{465}\x03\x02\x02\x02\u{468}\u{46b}\x03\
	\x02\x02\x02\u{469}\u{467}\x03\x02\x02\x02\u{469}\u{46a}\x03\x02\x02\x02\
	\u{46a}\u{46d}\x03\x02\x02\x02\u{46b}\u{469}\x03\x02\x02\x02\u{46c}\u{464}\
	\x03\x02\x02\x02\u{46c}\u{46d}\x03\x02\x02\x02\u{46d}\u{46f}\x03\x02\x02\
	\x02\u{46e}\u{470}\x07\x34\x02\x02\u{46f}\u{46e}\x03\x02\x02\x02\u{46f}\
	\u{470}\x03\x02\x02\x02\u{470}\u{471}\x03\x02\x02\x02\u{471}\u{473}\x07\
	\u{18e}\x02\x02\u{472}\u{463}\x03\x02\x02\x02\u{472}\u{473}\x03\x02\x02\
	\x02\u{473}\u{476}\x03\x02\x02\x02\u{474}\u{475}\x07\u{180}\x02\x02\u{475}\
	\u{477}\x05\u{d8}\x6d\x02\u{476}\u{474}\x03\x02\x02\x02\u{476}\u{477}\x03\
	\x02\x02\x02\u{477}\u{528}\x03\x02\x02\x02\u{478}\u{47c}\x07\x11\x02\x02\
	\u{479}\u{47b}\x0a\x02\x02\x02\u{47a}\u{479}\x03\x02\x02\x02\u{47b}\u{47e}\
	\x03\x02\x02\x02\u{47c}\u{47a}\x03\x02\x02\x02\u{47c}\u{47d}\x03\x02\x02\
	\x02\u{47d}\u{528}\x03\x02\x02\x02\u{47e}\u{47c}\x03\x02\x02\x02\u{47f}\
	\u{480}\x07\u{110}\x02\x02\u{480}\u{481}\x07\u{ca}\x02\x02\u{481}\u{482}\
	\x07\u{17c}\x02\x02\u{482}\u{528}\x05\u{130}\u{99}\x02\u{483}\u{484}\x07\
	\x10\x02\x02\u{484}\u{485}\x07\u{ca}\x02\x02\u{485}\u{488}\x07\u{17c}\x02\
	\x02\u{486}\u{487}\x07\u{96}\x02\x02\u{487}\u{489}\x07\x76\x02\x02\u{488}\
	\u{486}\x03\x02\x02\x02\u{488}\u{489}\x03\x02\x02\x02\u{489}\u{48a}\x03\
	\x02\x02\x02\u{48a}\u{48b}\x05\u{130}\u{99}\x02\u{48b}\u{48c}\x07\u{111}\
	\x02\x02\u{48c}\u{48d}\x07\u{153}\x02\x02\u{48d}\u{48e}\x05\u{130}\u{99}\
	\x02\u{48e}\u{528}\x03\x02\x02\x02\u{48f}\u{490}\x07\x10\x02\x02\u{490}\
	\u{491}\x07\u{ca}\x02\x02\u{491}\u{492}\x07\u{17c}\x02\x02\u{492}\u{493}\
	\x05\u{130}\u{99}\x02\u{493}\u{494}\x07\u{135}\x02\x02\u{494}\u{495}\x07\
	\u{107}\x02\x02\u{495}\u{496}\x05\x3a\x1e\x02\u{496}\u{528}\x03\x02\x02\
	\x02\u{497}\u{498}\x07\x10\x02\x02\u{498}\u{499}\x07\u{17c}\x02\x02\u{499}\
	\u{49a}\x05\u{130}\u{99}\x02\u{49a}\u{49b}\x07\u{111}\x02\x02\u{49b}\u{49c}\
	\x07\u{153}\x02\x02\u{49c}\u{49d}\x05\u{130}\u{99}\x02\u{49d}\u{528}\x03\
	\x02\x02\x02\u{49e}\u{49f}\x07\x10\x02\x02\u{49f}\u{4a0}\x07\u{17c}\x02\
	\x02\u{4a0}\u{4a1}\x05\u{130}\u{99}\x02\u{4a1}\u{4a2}\x07\u{135}\x02\x02\
	\u{4a2}\u{4a3}\x07\x1a\x02\x02\u{4a3}\u{4a4}\x05\u{142}\u{a2}\x02\u{4a4}\
	\u{528}\x03\x02\x02\x02\u{4a5}\u{4a9}\x07\x24\x02\x02\u{4a6}\u{4a8}\x0a\
	\x02\x02\x02\u{4a7}\u{4a6}\x03\x02\x02\x02\u{4a8}\u{4ab}\x03\x02\x02\x02\
	\u{4a9}\u{4a7}\x03\x02\x02\x02\u{4a9}\u{4aa}\x03\x02\x02\x02\u{4aa}\u{528}\
	\x03\x02\x02\x02\u{4ab}\u{4a9}\x03\x02\x02\x02\u{4ac}\u{4ad}\x07\x42\x02\
	\x02\u{4ad}\u{4b1}\x07\u{11f}\x02\x02\u{4ae}\u{4b0}\x0a\x02\x02\x02\u{4af}\
	\u{4ae}\x03\x02\x02\x02\u{4b0}\u{4b3}\x03\x02\x02\x02\u{4b1}\u{4af}\x03\
	\x02\x02\x02\u{4b1}\u{4b2}\x03\x02\x02\x02\u{4b2}\u{528}\x03\x02\x02\x02\
	\u{4b3}\u{4b1}\x03\x02\x02\x02\u{4b4}\u{4b8}\x07\u{8a}\x02\x02\u{4b5}\u{4b7}\
	\x0a\x02\x02\x02\u{4b6}\u{4b5}\x03\x02\x02\x02\u{4b7}\u{4ba}\x03\x02\x02\
	\x02\u{4b8}\u{4b6}\x03\x02\x02\x02\u{4b8}\u{4b9}\x03\x02\x02\x02\u{4b9}\
	\u{528}\x03\x02\x02\x02\u{4ba}\u{4b8}\x03\x02\x02\x02\u{4bb}\u{4bf}\x07\
	\u{11c}\x02\x02\u{4bc}\u{4be}\x0a\x02\x02\x02\u{4bd}\u{4bc}\x03\x02\x02\
	\x02\u{4be}\u{4c1}\x03\x02\x02\x02\u{4bf}\u{4bd}\x03\x02\x02\x02\u{4bf}\
	\u{4c0}\x03\x02\x02\x02\u{4c0}\u{528}\x03\x02\x02\x02\u{4c1}\u{4bf}\x03\
	\x02\x02\x02\u{4c2}\u{4d0}\x07\x5b\x02\x02\u{4c3}\u{4c8}\x05\u{12e}\u{98}\
	\x02\u{4c4}\u{4c5}\x07\x34\x02\x02\u{4c5}\u{4c7}\x05\u{12e}\u{98}\x02\u{4c6}\
	\u{4c4}\x03\x02\x02\x02\u{4c7}\u{4ca}\x03\x02\x02\x02\u{4c8}\u{4c6}\x03\
	\x02\x02\x02\u{4c8}\u{4c9}\x03\x02\x02\x02\u{4c9}\u{4cc}\x03\x02\x02\x02\
	\u{4ca}\u{4c8}\x03\x02\x02\x02\u{4cb}\u{4cd}\x07\x34\x02\x02\u{4cc}\u{4cb}\
	\x03\x02\x02\x02\u{4cc}\u{4cd}\x03\x02\x02\x02\u{4cd}\u{4d1}\x03\x02\x02\
	\x02\u{4ce}\u{4cf}\x07\x0f\x02\x02\u{4cf}\u{4d1}\x07\u{106}\x02\x02\u{4d0}\
	\u{4c3}\x03\x02\x02\x02\u{4d0}\u{4ce}\x03\x02\x02\x02\u{4d1}\u{4d2}\x03\
	\x02\x02\x02\u{4d2}\u{4d4}\x07\u{e8}\x02\x02\u{4d3}\u{4d5}\x09\x06\x02\x02\
	\u{4d4}\u{4d3}\x03\x02\x02\x02\u{4d4}\u{4d5}\x03\x02\x02\x02\u{4d5}\u{4d6}\
	\x03\x02\x02\x02\u{4d6}\u{4d7}\x05\u{130}\u{99}\x02\u{4d7}\u{4d8}\x07\u{153}\
	\x02\x02\u{4d8}\u{4d9}\x05\u{142}\u{a2}\x02\u{4d9}\u{528}\x03\x02\x02\x02\
	\u{4da}\u{4de}\x07\u{137}\x02\x02\u{4db}\u{4dd}\x0a\x02\x02\x02\u{4dc}\u{4db}\
	\x03\x02\x02\x02\u{4dd}\u{4e0}\x03\x02\x02\x02\u{4de}\u{4dc}\x03\x02\x02\
	\x02\u{4de}\u{4df}\x03\x02\x02\x02\u{4df}\u{528}\x03\x02\x02\x02\u{4e0}\
	\u{4de}\x03\x02\x02\x02\u{4e1}\u{4e5}\x07\u{114}\x02\x02\u{4e2}\u{4e4}\x0a\
	\x02\x02\x02\u{4e3}\u{4e2}\x03\x02\x02\x02\u{4e4}\u{4e7}\x03\x02\x02\x02\
	\u{4e5}\u{4e3}\x03\x02\x02\x02\u{4e5}\u{4e6}\x03\x02\x02\x02\u{4e6}\u{528}\
	\x03\x02\x02\x02\u{4e7}\u{4e5}\x03\x02\x02\x02\u{4e8}\u{4e9}\x07\u{13c}\
	\x02\x02\u{4e9}\u{4f5}\x07\u{159}\x02\x02\u{4ea}\u{4ef}\x05\u{12a}\u{96}\
	\x02\u{4eb}\u{4ec}\x07\x34\x02\x02\u{4ec}\u{4ee}\x05\u{12a}\u{96}\x02\u{4ed}\
	\u{4eb}\x03\x02\x02\x02\u{4ee}\u{4f1}\x03\x02\x02\x02\u{4ef}\u{4ed}\x03\
	\x02\x02\x02\u{4ef}\u{4f0}\x03\x02\x02\x02\u{4f0}\u{4f3}\x03\x02\x02\x02\
	\u{4f1}\u{4ef}\x03\x02\x02\x02\u{4f2}\u{4f4}\x07\x34\x02\x02\u{4f3}\u{4f2}\
	\x03\x02\x02\x02\u{4f3}\u{4f4}\x03\x02\x02\x02\u{4f4}\u{4f6}\x03\x02\x02\
	\x02\u{4f5}\u{4ea}\x03\x02\x02\x02\u{4f5}\u{4f6}\x03\x02\x02\x02\u{4f6}\
	\u{528}\x03\x02\x02\x02\u{4f7}\u{4fb}\x07\x36\x02\x02\u{4f8}\u{4fa}\x0a\
	\x02\x02\x02\u{4f9}\u{4f8}\x03\x02\x02\x02\u{4fa}\u{4fd}\x03\x02\x02\x02\
	\u{4fb}\u{4f9}\x03\x02\x02\x02\u{4fb}\u{4fc}\x03\x02\x02\x02\u{4fc}\u{528}\
	\x03\x02\x02\x02\u{4fd}\u{4fb}\x03\x02\x02\x02\u{4fe}\u{502}\x07\u{121}\
	\x02\x02\u{4ff}\u{501}\x0a\x02\x02\x02\u{500}\u{4ff}\x03\x02\x02\x02\u{501}\
	\u{504}\x03\x02\x02\x02\u{502}\u{500}\x03\x02\x02\x02\u{502}\u{503}\x03\
	\x02\x02\x02\u{503}\u{528}\x03\x02\x02\x02\u{504}\u{502}\x03\x02\x02\x02\
	\u{505}\u{509}\x07\u{103}\x02\x02\u{506}\u{508}\x0a\x02\x02\x02\u{507}\u{506}\
	\x03\x02\x02\x02\u{508}\u{50b}\x03\x02\x02\x02\u{509}\u{507}\x03\x02\x02\
	\x02\u{509}\u{50a}\x03\x02\x02\x02\u{50a}\u{528}\x03\x02\x02\x02\u{50b}\
	\u{509}\x03\x02\x02\x02\u{50c}\u{510}\x07\x52\x02\x02\u{50d}\u{50f}\x0a\
	\x02\x02\x02\u{50e}\u{50d}\x03\x02\x02\x02\u{50f}\u{512}\x03\x02\x02\x02\
	\u{510}\u{50e}\x03\x02\x02\x02\u{510}\u{511}\x03\x02\x02\x02\u{511}\u{528}\
	\x03\x02\x02\x02\u{512}\u{510}\x03\x02\x02\x02\u{513}\u{517}\x07\x75\x02\
	\x02\u{514}\u{516}\x0a\x02\x02\x02\u{515}\u{514}\x03\x02\x02\x02\u{516}\
	\u{519}\x03\x02\x02\x02\u{517}\u{515}\x03\x02\x02\x02\u{517}\u{518}\x03\
	\x02\x02\x02\u{518}\u{528}\x03\x02\x02\x02\u{519}\u{517}\x03\x02\x02\x02\
	\u{51a}\u{51b}\x07\x5d\x02\x02\u{51b}\u{51c}\x07\u{9e}\x02\x02\u{51c}\u{528}\
	\x05\u{144}\u{a3}\x02\u{51d}\u{51e}\x07\x5d\x02\x02\u{51e}\u{51f}\x07\u{f0}\
	\x02\x02\u{51f}\u{528}\x05\u{144}\u{a3}\x02\u{520}\u{524}\x07\u{16e}\x02\
	\x02\u{521}\u{523}\x0a\x02\x02\x02\u{522}\u{521}\x03\x02\x02\x02\u{523}\
	\u{526}\x03\x02\x02\x02\u{524}\u{522}\x03\x02\x02\x02\u{524}\u{525}\x03\
	\x02\x02\x02\u{525}\u{528}\x03\x02\x02\x02\u{526}\u{524}\x03\x02\x02\x02\
	\u{527}\u{17b}\x03\x02\x02\x02\u{527}\u{17c}\x03\x02\x02\x02\u{527}\u{17e}\
	\x03\x02\x02\x02\u{527}\u{183}\x03\x02\x02\x02\u{527}\u{190}\x03\x02\x02\
	\x02\u{527}\u{197}\x03\x02\x02\x02\u{527}\u{19e}\x03\x02\x02\x02\u{527}\
	\u{1a1}\x03\x02\x02\x02\u{527}\u{1a4}\x03\x02\x02\x02\u{527}\u{1c8}\x03\
	\x02\x02\x02\u{527}\u{20b}\x03\x02\x02\x02\u{527}\u{221}\x03\x02\x02\x02\
	\u{527}\u{22b}\x03\x02\x02\x02\u{527}\u{250}\x03\x02\x02\x02\u{527}\u{266}\
	\x03\x02\x02\x02\u{527}\u{268}\x03\x02\x02\x02\u{527}\u{26c}\x03\x02\x02\
	\x02\u{527}\u{280}\x03\x02\x02\x02\u{527}\u{2ab}\x03\x02\x02\x02\u{527}\
	\u{2e6}\x03\x02\x02\x02\u{527}\u{30c}\x03\x02\x02\x02\u{527}\u{342}\x03\
	\x02\x02\x02\u{527}\u{352}\x03\x02\x02\x02\u{527}\u{36b}\x03\x02\x02\x02\
	\u{527}\u{36f}\x03\x02\x02\x02\u{527}\u{378}\x03\x02\x02\x02\u{527}\u{38c}\
	\x03\x02\x02\x02\u{527}\u{3a1}\x03\x02\x02\x02\u{527}\u{3a6}\x03\x02\x02\
	\x02\u{527}\u{3ad}\x03\x02\x02\x02\u{527}\u{3b4}\x03\x02\x02\x02\u{527}\
	\u{3b5}\x03\x02\x02\x02\u{527}\u{3b6}\x03\x02\x02\x02\u{527}\u{3b7}\x03\
	\x02\x02\x02\u{527}\u{3b8}\x03\x02\x02\x02\u{527}\u{3c3}\x03\x02\x02\x02\
	\u{527}\u{3ca}\x03\x02\x02\x02\u{527}\u{3cb}\x03\x02\x02\x02\u{527}\u{3cf}\
	\x03\x02\x02\x02\u{527}\u{3d3}\x03\x02\x02\x02\u{527}\u{3d7}\x03\x02\x02\
	\x02\u{527}\u{3de}\x03\x02\x02\x02\u{527}\u{3ea}\x03\x02\x02\x02\u{527}\
	\u{3f1}\x03\x02\x02\x02\u{527}\u{3f8}\x03\x02\x02\x02\u{527}\u{3ff}\x03\
	\x02\x02\x02\u{527}\u{406}\x03\x02\x02\x02\u{527}\u{411}\x03\x02\x02\x02\
	\u{527}\u{421}\x03\x02\x02\x02\u{527}\u{432}\x03\x02\x02\x02\u{527}\u{441}\
	\x03\x02\x02\x02\u{527}\u{450}\x03\x02\x02\x02\u{527}\u{457}\x03\x02\x02\
	\x02\u{527}\u{45e}\x03\x02\x02\x02\u{527}\u{478}\x03\x02\x02\x02\u{527}\
	\u{47f}\x03\x02\x02\x02\u{527}\u{483}\x03\x02\x02\x02\u{527}\u{48f}\x03\
	\x02\x02\x02\u{527}\u{497}\x03\x02\x02\x02\u{527}\u{49e}\x03\x02\x02\x02\
	\u{527}\u{4a5}\x03\x02\x02\x02\u{527}\u{4ac}\x03\x02\x02\x02\u{527}\u{4b4}\
	\x03\x02\x02\x02\u{527}\u{4bb}\x03\x02\x02\x02\u{527}\u{4c2}\x03\x02\x02\
	\x02\u{527}\u{4da}\x03\x02\x02\x02\u{527}\u{4e1}\x03\x02\x02\x02\u{527}\
	\u{4e8}\x03\x02\x02\x02\u{527}\u{4f7}\x03\x02\x02\x02\u{527}\u{4fe}\x03\
	\x02\x02\x02\u{527}\u{505}\x03\x02\x02\x02\u{527}\u{50c}\x03\x02\x02\x02\
	\u{527}\u{513}\x03\x02\x02\x02\u{527}\u{51a}\x03\x02\x02\x02\u{527}\u{51d}\
	\x03\x02\x02\x02\u{527}\u{520}\x03\x02\x02\x02\u{528}\x0f\x03\x02\x02\x02\
	\u{529}\u{52e}\x05\x20\x11\x02\u{52a}\u{52b}\x07\x34\x02\x02\u{52b}\u{52d}\
	\x05\x20\x11\x02\u{52c}\u{52a}\x03\x02\x02\x02\u{52d}\u{530}\x03\x02\x02\
	\x02\u{52e}\u{52c}\x03\x02\x02\x02\u{52e}\u{52f}\x03\x02\x02\x02\u{52f}\
	\x11\x03\x02\x02\x02\u{530}\u{52e}\x03\x02\x02\x02\u{531}\u{536}\x05\x14\
	\x0b\x02\u{532}\u{533}\x07\x34\x02\x02\u{533}\u{535}\x05\x14\x0b\x02\u{534}\
	\u{532}\x03\x02\x02\x02\u{535}\u{538}\x03\x02\x02\x02\u{536}\u{534}\x03\
	\x02\x02\x02\u{536}\u{537}\x03\x02\x02\x02\u{537}\x13\x03\x02\x02\x02\u{538}\
	\u{536}\x03\x02\x02\x02\u{539}\u{541}\x05\u{d6}\x6c\x02\u{53a}\u{53c}\x07\
	\x16\x02\x02\u{53b}\u{53a}\x03\x02\x02\x02\u{53b}\u{53c}\x03\x02\x02\x02\
	\u{53c}\u{53f}\x03\x02\x02\x02\u{53d}\u{540}\x05\u{144}\u{a3}\x02\u{53e}\
	\u{540}\x05\u{14a}\u{a6}\x02\u{53f}\u{53d}\x03\x02\x02\x02\u{53f}\u{53e}\
	\x03\x02\x02\x02\u{540}\u{542}\x03\x02\x02\x02\u{541}\u{53b}\x03\x02\x02\
	\x02\u{541}\u{542}\x03\x02\x02\x02\u{542}\x15\x03\x02\x02\x02\u{543}\u{544}\
	\x09\x07\x02\x02\u{544}\u{545}\x07\u{e3}\x02\x02\u{545}\x17\x03\x02\x02\
	\x02\u{546}\u{547}\x07\u{c0}\x02\x02\u{547}\u{548}\x05\u{fa}\x7e\x02\u{548}\
	\x19\x03\x02\x02\x02\u{549}\u{54a}\x07\u{183}\x02\x02\u{54a}\u{54b}\x07\
	\x3c\x02\x02\u{54b}\u{54c}\x05\u{130}\u{99}\x02\u{54c}\x1b\x03\x02\x02\x02\
	\u{54d}\u{54f}\x05\x1e\x10\x02\u{54e}\u{54d}\x03\x02\x02\x02\u{54e}\u{54f}\
	\x03\x02\x02\x02\u{54f}\u{550}\x03\x02\x02\x02\u{550}\u{551}\x05\x42\x22\
	\x02\u{551}\x1d\x03\x02\x02\x02\u{552}\u{554}\x07\u{183}\x02\x02\u{553}\
	\u{555}\x07\u{10f}\x02\x02\u{554}\u{553}\x03\x02\x02\x02\u{554}\u{555}\x03\
	\x02\x02\x02\u{555}\u{556}\x03\x02\x02\x02\u{556}\u{55b}\x05\x74\x3b\x02\
	\u{557}\u{558}\x07\x34\x02\x02\u{558}\u{55a}\x05\x74\x3b\x02\u{559}\u{557}\
	\x03\x02\x02\x02\u{55a}\u{55d}\x03\x02\x02\x02\u{55b}\u{559}\x03\x02\x02\
	\x02\u{55b}\u{55c}\x03\x02\x02\x02\u{55c}\x1f\x03\x02\x02\x02\u{55d}\u{55b}\
	\x03\x02\x02\x02\u{55e}\u{55f}\x05\x22\x12\x02\u{55f}\x21\x03\x02\x02\x02\
	\u{560}\u{563}\x05\x24\x13\x02\u{561}\u{562}\x07\u{183}\x02\x02\u{562}\u{564}\
	\x05\x38\x1d\x02\u{563}\u{561}\x03\x02\x02\x02\u{563}\u{564}\x03\x02\x02\
	\x02\u{564}\x23\x03\x02\x02\x02\u{565}\u{566}\x05\x26\x14\x02\u{566}\u{567}\
	\x05\x2a\x16\x02\u{567}\x25\x03\x02\x02\x02\u{568}\u{569}\x05\u{144}\u{a3}\
	\x02\u{569}\x27\x03\x02\x02\x02\u{56a}\u{56b}\x05\u{146}\u{a4}\x02\u{56b}\
	\x29\x03\x02\x02\x02\u{56c}\u{571}\x05\x30\x19\x02\u{56d}\u{56f}\x07\u{e1}\
	\x02\x02\u{56e}\u{56d}\x03\x02\x02\x02\u{56e}\u{56f}\x03\x02\x02\x02\u{56f}\
	\u{570}\x03\x02\x02\x02\u{570}\u{572}\x07\u{e2}\x02\x02\u{571}\u{56e}\x03\
	\x02\x02\x02\u{571}\u{572}\x03\x02\x02\x02\u{572}\u{579}\x03\x02\x02\x02\
	\u{573}\u{574}\x07\u{ec}\x02\x02\u{574}\u{576}\x07\u{18d}\x02\x02\u{575}\
	\u{577}\x05\x2c\x17\x02\u{576}\u{575}\x03\x02\x02\x02\u{576}\u{577}\x03\
	\x02\x02\x02\u{577}\u{578}\x03\x02\x02\x02\u{578}\u{57a}\x07\u{18e}\x02\
	\x02\u{579}\u{573}\x03\x02\x02\x02\u{579}\u{57a}\x03\x02\x02\x02\u{57a}\
	\x2b\x03\x02\x02\x02\u{57b}\u{580}\x05\x2e\x18\x02\u{57c}\u{57d}\x07\x34\
	\x02\x02\u{57d}\u{57f}\x05\x2e\x18\x02\u{57e}\u{57c}\x03\x02\x02\x02\u{57f}\
	\u{582}\x03\x02\x02\x02\u{580}\u{57e}\x03\x02\x02\x02\u{580}\u{581}\x03\
	\x02\x02\x02\u{581}\u{584}\x03\x02\x02\x02\u{582}\u{580}\x03\x02\x02\x02\
	\u{583}\u{585}\x07\x34\x02\x02\u{584}\u{583}\x03\x02\x02\x02\u{584}\u{585}\
	\x03\x02\x02\x02\u{585}\x2d\x03\x02\x02\x02\u{586}\u{587}\x05\u{144}\u{a3}\
	\x02\u{587}\u{588}\x07\u{192}\x02\x02\u{588}\u{589}\x05\u{d6}\x6c\x02\u{589}\
	\x2f\x03\x02\x02\x02\u{58a}\u{592}\x05\u{10a}\u{86}\x02\u{58b}\u{592}\x05\
	\x36\x1c\x02\u{58c}\u{58d}\x07\x15\x02\x02\u{58d}\u{58e}\x07\u{194}\x02\
	\x02\u{58e}\u{58f}\x05\x34\x1b\x02\u{58f}\u{590}\x07\u{196}\x02\x02\u{590}\
	\u{592}\x03\x02\x02\x02\u{591}\u{58a}\x03\x02\x02\x02\u{591}\u{58b}\x03\
	\x02\x02\x02\u{591}\u{58c}\x03\x02\x02\x02\u{592}\x31\x03\x02\x02\x02\u{593}\
	\u{598}\x05\x24\x13\x02\u{594}\u{595}\x07\x34\x02\x02\u{595}\u{597}\x05\
	\x24\x13\x02\u{596}\u{594}\x03\x02\x02\x02\u{597}\u{59a}\x03\x02\x02\x02\
	\u{598}\u{596}\x03\x02\x02\x02\u{598}\u{599}\x03\x02\x02\x02\u{599}\u{59c}\
	\x03\x02\x02\x02\u{59a}\u{598}\x03\x02\x02\x02\u{59b}\u{59d}\x07\x34\x02\
	\x02\u{59c}\u{59b}\x03\x02\x02\x02\u{59c}\u{59d}\x03\x02\x02\x02\u{59d}\
	\x33\x03\x02\x02\x02\u{59e}\u{5a5}\x05\u{10a}\u{86}\x02\u{59f}\u{5a2}\x05\
	\x36\x1c\x02\u{5a0}\u{5a1}\x07\u{e1}\x02\x02\u{5a1}\u{5a3}\x07\u{e2}\x02\
	\x02\u{5a2}\u{5a0}\x03\x02\x02\x02\u{5a2}\u{5a3}\x03\x02\x02\x02\u{5a3}\
	\u{5a5}\x03\x02\x02\x02\u{5a4}\u{59e}\x03\x02\x02\x02\u{5a4}\u{59f}\x03\
	\x02\x02\x02\u{5a5}\x35\x03\x02\x02\x02\u{5a6}\u{5a7}\x07\u{13f}\x02\x02\
	\u{5a7}\u{5a8}\x07\u{194}\x02\x02\u{5a8}\u{5a9}\x05\x32\x1a\x02\u{5a9}\u{5aa}\
	\x07\u{196}\x02\x02\u{5aa}\x37\x03\x02\x02\x02\u{5ab}\u{5ad}\x07\u{18d}\
	\x02\x02\u{5ac}\u{5ae}\x05\x3a\x1e\x02\u{5ad}\u{5ac}\x03\x02\x02\x02\u{5ad}\
	\u{5ae}\x03\x02\x02\x02\u{5ae}\u{5af}\x03\x02\x02\x02\u{5af}\u{5b0}\x07\
	\u{18e}\x02\x02\u{5b0}\x39\x03\x02\x02\x02\u{5b1}\u{5b6}\x05\x3c\x1f\x02\
	\u{5b2}\u{5b3}\x07\x34\x02\x02\u{5b3}\u{5b5}\x05\x3c\x1f\x02\u{5b4}\u{5b2}\
	\x03\x02\x02\x02\u{5b5}\u{5b8}\x03\x02\x02\x02\u{5b6}\u{5b4}\x03\x02\x02\
	\x02\u{5b6}\u{5b7}\x03\x02\x02\x02\u{5b7}\u{5ba}\x03\x02\x02\x02\u{5b8}\
	\u{5b6}\x03\x02\x02\x02\u{5b9}\u{5bb}\x07\x34\x02\x02\u{5ba}\u{5b9}\x03\
	\x02\x02\x02\u{5ba}\u{5bb}\x03\x02\x02\x02\u{5bb}\x3b\x03\x02\x02\x02\u{5bc}\
	\u{5bd}\x05\x3e\x20\x02\u{5bd}\u{5be}\x07\u{192}\x02\x02\u{5be}\u{5c2}\x07\
	\u{18d}\x02\x02\u{5bf}\u{5c1}\x05\x3c\x1f\x02\u{5c0}\u{5bf}\x03\x02\x02\
	\x02\u{5c1}\u{5c4}\x03\x02\x02\x02\u{5c2}\u{5c0}\x03\x02\x02\x02\u{5c2}\
	\u{5c3}\x03\x02\x02\x02\u{5c3}\u{5c5}\x03\x02\x02\x02\u{5c4}\u{5c2}\x03\
	\x02\x02\x02\u{5c5}\u{5c6}\x07\u{18e}\x02\x02\u{5c6}\u{5cc}\x03\x02\x02\
	\x02\u{5c7}\u{5c8}\x05\x3e\x20\x02\u{5c8}\u{5c9}\x07\u{192}\x02\x02\u{5c9}\
	\u{5ca}\x05\x40\x21\x02\u{5ca}\u{5cc}\x03\x02\x02\x02\u{5cb}\u{5bc}\x03\
	\x02\x02\x02\u{5cb}\u{5c7}\x03\x02\x02\x02\u{5cc}\x3d\x03\x02\x02\x02\u{5cd}\
	\u{5ce}\x05\u{144}\u{a3}\x02\u{5ce}\x3f\x03\x02\x02\x02\u{5cf}\u{5d3}\x07\
	\x54\x02\x02\u{5d0}\u{5d3}\x05\u{144}\u{a3}\x02\u{5d1}\u{5d3}\x05\u{d6}\
	\x6c\x02\u{5d2}\u{5cf}\x03\x02\x02\x02\u{5d2}\u{5d0}\x03\x02\x02\x02\u{5d2}\
	\u{5d1}\x03\x02\x02\x02\u{5d3}\x41\x03\x02\x02\x02\u{5d4}\u{5d5}\x05\x44\
	\x23\x02\u{5d5}\x43\x03\x02\x02\x02\u{5d6}\u{5dd}\x05\x46\x24\x02\u{5d7}\
	\u{5d8}\x07\u{bc}\x02\x02\u{5d8}\u{5db}\x05\x48\x25\x02\u{5d9}\u{5da}\x07\
	\u{e6}\x02\x02\u{5da}\u{5dc}\x05\x4a\x26\x02\u{5db}\u{5d9}\x03\x02\x02\x02\
	\u{5db}\u{5dc}\x03\x02\x02\x02\u{5dc}\u{5de}\x03\x02\x02\x02\u{5dd}\u{5d7}\
	\x03\x02\x02\x02\u{5dd}\u{5de}\x03\x02\x02\x02\u{5de}\x45\x03\x02\x02\x02\
	\u{5df}\u{5e1}\x05\x4c\x27\x02\u{5e0}\u{5e2}\x05\x72\x3a\x02\u{5e1}\u{5e0}\
	\x03\x02\x02\x02\u{5e1}\u{5e2}\x03\x02\x02\x02\u{5e2}\x47\x03\x02\x02\x02\
	\u{5e3}\u{5e4}\x05\x4a\x26\x02\u{5e4}\x49\x03\x02\x02\x02\u{5e5}\u{5e6}\
	\x07\u{1ad}\x02\x02\u{5e6}\x4b\x03\x02\x02\x02\u{5e7}\u{5e8}\x05\x4e\x28\
	\x02\u{5e8}\x4d\x03\x02\x02\x02\u{5e9}\u{5ef}\x05\x52\x2a\x02\u{5ea}\u{5eb}\
	\x05\x50\x29\x02\u{5eb}\u{5ec}\x05\x52\x2a\x02\u{5ec}\u{5ee}\x03\x02\x02\
	\x02\u{5ed}\u{5ea}\x03\x02\x02\x02\u{5ee}\u{5f1}\x03\x02\x02\x02\u{5ef}\
	\u{5ed}\x03\x02\x02\x02\u{5ef}\u{5f0}\x03\x02\x02\x02\u{5f0}\x4f\x03\x02\
	\x02\x02\u{5f1}\u{5ef}\x03\x02\x02\x02\u{5f2}\u{5fa}\x07\u{9d}\x02\x02\u{5f3}\
	\u{5f5}\x09\x08\x02\x02\u{5f4}\u{5f3}\x03\x02\x02\x02\u{5f4}\u{5f5}\x03\
	\x02\x02\x02\u{5f5}\u{5f7}\x03\x02\x02\x02\u{5f6}\u{5f8}\x07\u{ef}\x02\x02\
	\u{5f7}\u{5f6}\x03\x02\x02\x02\u{5f7}\u{5f8}\x03\x02\x02\x02\u{5f8}\u{5fa}\
	\x03\x02\x02\x02\u{5f9}\u{5f2}\x03\x02\x02\x02\u{5f9}\u{5f4}\x03\x02\x02\
	\x02\u{5fa}\u{5fb}\x03\x02\x02\x02\u{5fb}\u{5fc}\x09\x09\x02\x02\u{5fc}\
	\u{5ff}\x05\x56\x2c\x02\u{5fd}\u{5fe}\x07\x22\x02\x02\u{5fe}\u{600}\x07\
	\u{d7}\x02\x02\u{5ff}\u{5fd}\x03\x02\x02\x02\u{5ff}\u{600}\x03\x02\x02\x02\
	\u{600}\x51\x03\x02\x02\x02\u{601}\u{607}\x05\x5a\x2e\x02\u{602}\u{603}\
	\x05\x54\x2b\x02\u{603}\u{604}\x05\x5a\x2e\x02\u{604}\u{606}\x03\x02\x02\
	\x02\u{605}\u{602}\x03\x02\x02\x02\u{606}\u{609}\x03\x02\x02\x02\u{607}\
	\u{605}\x03\x02\x02\x02\u{607}\u{608}\x03\x02\x02\x02\u{608}\x53\x03\x02\
	\x02\x02\u{609}\u{607}\x03\x02\x02\x02\u{60a}\u{60c}\x07\u{a2}\x02\x02\u{60b}\
	\u{60d}\x05\x56\x2c\x02\u{60c}\u{60b}\x03\x02\x02\x02\u{60c}\u{60d}\x03\
	\x02\x02\x02\u{60d}\x55\x03\x02\x02\x02\u{60e}\u{60f}\x09\x0a\x02\x02\u{60f}\
	\x57\x03\x02\x02\x02\u{610}\u{611}\x07\u{178}\x02\x02\u{611}\u{616}\x05\
	\u{d6}\x6c\x02\u{612}\u{613}\x07\x34\x02\x02\u{613}\u{615}\x05\u{d6}\x6c\
	\x02\u{614}\u{612}\x03\x02\x02\x02\u{615}\u{618}\x03\x02\x02\x02\u{616}\
	\u{614}\x03\x02\x02\x02\u{616}\u{617}\x03\x02\x02\x02\u{617}\u{61a}\x03\
	\x02\x02\x02\u{618}\u{616}\x03\x02\x02\x02\u{619}\u{61b}\x07\x34\x02\x02\
	\u{61a}\u{619}\x03\x02\x02\x02\u{61a}\u{61b}\x03\x02\x02\x02\u{61b}\x59\
	\x03\x02\x02\x02\u{61c}\u{625}\x05\x5e\x30\x02\u{61d}\u{61e}\x07\u{145}\
	\x02\x02\u{61e}\u{625}\x05\u{132}\u{9a}\x02\u{61f}\u{625}\x05\x58\x2d\x02\
	\u{620}\u{621}\x07\u{18d}\x02\x02\u{621}\u{622}\x05\x1c\x0f\x02\u{622}\u{623}\
	\x07\u{18e}\x02\x02\u{623}\u{625}\x03\x02\x02\x02\u{624}\u{61c}\x03\x02\
	\x02\x02\u{624}\u{61d}\x03\x02\x02\x02\u{624}\u{61f}\x03\x02\x02\x02\u{624}\
	\u{620}\x03\x02\x02\x02\u{625}\x5b\x03\x02\x02\x02\u{626}\u{628}\x05\u{d6}\
	\x6c\x02\u{627}\u{629}\x09\x0b\x02\x02\u{628}\u{627}\x03\x02\x02\x02\u{628}\
	\u{629}\x03\x02\x02\x02\u{629}\u{62c}\x03\x02\x02\x02\u{62a}\u{62b}\x07\
	\u{e3}\x02\x02\u{62b}\u{62d}\x09\x0c\x02\x02\u{62c}\u{62a}\x03\x02\x02\x02\
	\u{62c}\u{62d}\x03\x02\x02\x02\u{62d}\x5d\x03\x02\x02\x02\u{62e}\u{630}\
	\x07\u{12f}\x02\x02\u{62f}\u{631}\x05\x56\x2c\x02\u{630}\u{62f}\x03\x02\
	\x02\x02\u{630}\u{631}\x03\x02\x02\x02\u{631}\u{634}\x03\x02\x02\x02\u{632}\
	\u{633}\x07\x16\x02\x02\u{633}\u{635}\x09\x0d\x02\x02\u{634}\u{632}\x03\
	\x02\x02\x02\u{634}\u{635}\x03\x02\x02\x02\u{635}\u{636}\x03\x02\x02\x02\
	\u{636}\u{639}\x05\x62\x32\x02\u{637}\u{638}\x07\u{84}\x02\x02\u{638}\u{63a}\
	\x05\x7e\x40\x02\u{639}\u{637}\x03\x02\x02\x02\u{639}\u{63a}\x03\x02\x02\
	\x02\u{63a}\u{63d}\x03\x02\x02\x02\u{63b}\u{63c}\x07\u{180}\x02\x02\u{63c}\
	\u{63e}\x05\u{d8}\x6d\x02\u{63d}\u{63b}\x03\x02\x02\x02\u{63d}\u{63e}\x03\
	\x02\x02\x02\u{63e}\u{640}\x03\x02\x02\x02\u{63f}\u{641}\x05\x64\x33\x02\
	\u{640}\u{63f}\x03\x02\x02\x02\u{640}\u{641}\x03\x02\x02\x02\u{641}\u{644}\
	\x03\x02\x02\x02\u{642}\u{643}\x07\u{92}\x02\x02\u{643}\u{645}\x05\u{d8}\
	\x6d\x02\u{644}\u{642}\x03\x02\x02\x02\u{644}\u{645}\x03\x02\x02\x02\u{645}\
	\u{648}\x03\x02\x02\x02\u{646}\u{647}\x07\u{109}\x02\x02\u{647}\u{649}\x05\
	\u{d8}\x6d\x02\u{648}\u{646}\x03\x02\x02\x02\u{648}\u{649}\x03\x02\x02\x02\
	\u{649}\u{656}\x03\x02\x02\x02\u{64a}\u{64b}\x07\u{182}\x02\x02\u{64b}\u{650}\
	\x05\x6c\x37\x02\u{64c}\u{64d}\x07\x34\x02\x02\u{64d}\u{64f}\x05\x6c\x37\
	\x02\u{64e}\u{64c}\x03\x02\x02\x02\u{64f}\u{652}\x03\x02\x02\x02\u{650}\
	\u{64e}\x03\x02\x02\x02\u{650}\u{651}\x03\x02\x02\x02\u{651}\u{654}\x03\
	\x02\x02\x02\u{652}\u{650}\x03\x02\x02\x02\u{653}\u{655}\x07\x34\x02\x02\
	\u{654}\u{653}\x03\x02\x02\x02\u{654}\u{655}\x03\x02\x02\x02\u{655}\u{657}\
	\x03\x02\x02\x02\u{656}\u{64a}\x03\x02\x02\x02\u{656}\u{657}\x03\x02\x02\
	\x02\u{657}\x5f\x03\x02\x02\x02\u{658}\u{65a}\x05\u{d6}\x6c\x02\u{659}\u{65b}\
	\x07\x16\x02\x02\u{65a}\u{659}\x03\x02\x02\x02\u{65a}\u{65b}\x03\x02\x02\
	\x02\u{65b}\u{65c}\x03\x02\x02\x02\u{65c}\u{65d}\x05\u{144}\u{a3}\x02\u{65d}\
	\x61\x03\x02\x02\x02\u{65e}\u{663}\x05\x78\x3d\x02\u{65f}\u{660}\x07\x34\
	\x02\x02\u{660}\u{662}\x05\x78\x3d\x02\u{661}\u{65f}\x03\x02\x02\x02\u{662}\
	\u{665}\x03\x02\x02\x02\u{663}\u{661}\x03\x02\x02\x02\u{663}\u{664}\x03\
	\x02\x02\x02\u{664}\u{667}\x03\x02\x02\x02\u{665}\u{663}\x03\x02\x02\x02\
	\u{666}\u{668}\x07\x34\x02\x02\u{667}\u{666}\x03\x02\x02\x02\u{667}\u{668}\
	\x03\x02\x02\x02\u{668}\x63\x03\x02\x02\x02\u{669}\u{66a}\x07\u{8e}\x02\
	\x02\u{66a}\u{66b}\x07\x22\x02\x02\u{66b}\u{66c}\x05\x66\x34\x02\u{66c}\
	\x65\x03\x02\x02\x02\u{66d}\u{67d}\x07\x0f\x02\x02\u{66e}\u{670}\x05\x56\
	\x2c\x02\u{66f}\u{66e}\x03\x02\x02\x02\u{66f}\u{670}\x03\x02\x02\x02\u{670}\
	\u{671}\x03\x02\x02\x02\u{671}\u{676}\x05\x68\x35\x02\u{672}\u{673}\x07\
	\x34\x02\x02\u{673}\u{675}\x05\x68\x35\x02\u{674}\u{672}\x03\x02\x02\x02\
	\u{675}\u{678}\x03\x02\x02\x02\u{676}\u{674}\x03\x02\x02\x02\u{676}\u{677}\
	\x03\x02\x02\x02\u{677}\u{67a}\x03\x02\x02\x02\u{678}\u{676}\x03\x02\x02\
	\x02\u{679}\u{67b}\x07\x34\x02\x02\u{67a}\u{679}\x03\x02\x02\x02\u{67a}\
	\u{67b}\x03\x02\x02\x02\u{67b}\u{67d}\x03\x02\x02\x02\u{67c}\u{66d}\x03\
	\x02\x02\x02\u{67c}\u{66f}\x03\x02\x02\x02\u{67d}\x67\x03\x02\x02\x02\u{67e}\
	\u{67f}\x07\u{122}\x02\x02\u{67f}\u{68b}\x07\u{18d}\x02\x02\u{680}\u{685}\
	\x05\u{d6}\x6c\x02\u{681}\u{682}\x07\x34\x02\x02\u{682}\u{684}\x05\u{d6}\
	\x6c\x02\u{683}\u{681}\x03\x02\x02\x02\u{684}\u{687}\x03\x02\x02\x02\u{685}\
	\u{683}\x03\x02\x02\x02\u{685}\u{686}\x03\x02\x02\x02\u{686}\u{689}\x03\
	\x02\x02\x02\u{687}\u{685}\x03\x02\x02\x02\u{688}\u{68a}\x07\x34\x02\x02\
	\u{689}\u{688}\x03\x02\x02\x02\u{689}\u{68a}\x03\x02\x02\x02\u{68a}\u{68c}\
	\x03\x02\x02\x02\u{68b}\u{680}\x03\x02\x02\x02\u{68b}\u{68c}\x03\x02\x02\
	\x02\u{68c}\u{68d}\x03\x02\x02\x02\u{68d}\u{6b0}\x07\u{18e}\x02\x02\u{68e}\
	\u{68f}\x07\x44\x02\x02\u{68f}\u{69b}\x07\u{18d}\x02\x02\u{690}\u{695}\x05\
	\u{d6}\x6c\x02\u{691}\u{692}\x07\x34\x02\x02\u{692}\u{694}\x05\u{d6}\x6c\
	\x02\u{693}\u{691}\x03\x02\x02\x02\u{694}\u{697}\x03\x02\x02\x02\u{695}\
	\u{693}\x03\x02\x02\x02\u{695}\u{696}\x03\x02\x02\x02\u{696}\u{699}\x03\
	\x02\x02\x02\u{697}\u{695}\x03\x02\x02\x02\u{698}\u{69a}\x07\x34\x02\x02\
	\u{699}\u{698}\x03\x02\x02\x02\u{699}\u{69a}\x03\x02\x02\x02\u{69a}\u{69c}\
	\x03\x02\x02\x02\u{69b}\u{690}\x03\x02\x02\x02\u{69b}\u{69c}\x03\x02\x02\
	\x02\u{69c}\u{69d}\x03\x02\x02\x02\u{69d}\u{6b0}\x07\u{18e}\x02\x02\u{69e}\
	\u{69f}\x07\u{8f}\x02\x02\u{69f}\u{6a0}\x07\u{136}\x02\x02\u{6a0}\u{6a1}\
	\x07\u{18d}\x02\x02\u{6a1}\u{6a6}\x05\x6a\x36\x02\u{6a2}\u{6a3}\x07\x34\
	\x02\x02\u{6a3}\u{6a5}\x05\x6a\x36\x02\u{6a4}\u{6a2}\x03\x02\x02\x02\u{6a5}\
	\u{6a8}\x03\x02\x02\x02\u{6a6}\u{6a4}\x03\x02\x02\x02\u{6a6}\u{6a7}\x03\
	\x02\x02\x02\u{6a7}\u{6aa}\x03\x02\x02\x02\u{6a8}\u{6a6}\x03\x02\x02\x02\
	\u{6a9}\u{6ab}\x07\x34\x02\x02\u{6aa}\u{6a9}\x03\x02\x02\x02\u{6aa}\u{6ab}\
	\x03\x02\x02\x02\u{6ab}\u{6ac}\x03\x02\x02\x02\u{6ac}\u{6ad}\x07\u{18e}\
	\x02\x02\u{6ad}\u{6b0}\x03\x02\x02\x02\u{6ae}\u{6b0}\x05\x6a\x36\x02\u{6af}\
	\u{67e}\x03\x02\x02\x02\u{6af}\u{68e}\x03\x02\x02\x02\u{6af}\u{69e}\x03\
	\x02\x02\x02\u{6af}\u{6ae}\x03\x02\x02\x02\u{6b0}\x69\x03\x02\x02\x02\u{6b1}\
	\u{6ba}\x07\u{18d}\x02\x02\u{6b2}\u{6b7}\x05\u{d6}\x6c\x02\u{6b3}\u{6b4}\
	\x07\x34\x02\x02\u{6b4}\u{6b6}\x05\u{d6}\x6c\x02\u{6b5}\u{6b3}\x03\x02\x02\
	\x02\u{6b6}\u{6b9}\x03\x02\x02\x02\u{6b7}\u{6b5}\x03\x02\x02\x02\u{6b7}\
	\u{6b8}\x03\x02\x02\x02\u{6b8}\u{6bb}\x03\x02\x02\x02\u{6b9}\u{6b7}\x03\
	\x02\x02\x02\u{6ba}\u{6b2}\x03\x02\x02\x02\u{6ba}\u{6bb}\x03\x02\x02\x02\
	\u{6bb}\u{6bd}\x03\x02\x02\x02\u{6bc}\u{6be}\x07\x34\x02\x02\u{6bd}\u{6bc}\
	\x03\x02\x02\x02\u{6bd}\u{6be}\x03\x02\x02\x02\u{6be}\u{6bf}\x03\x02\x02\
	\x02\u{6bf}\u{6c2}\x07\u{18e}\x02\x02\u{6c0}\u{6c2}\x05\u{d6}\x6c\x02\u{6c1}\
	\u{6b1}\x03\x02\x02\x02\u{6c1}\u{6c0}\x03\x02\x02\x02\u{6c2}\x6b\x03\x02\
	\x02\x02\u{6c3}\u{6c4}\x05\u{144}\u{a3}\x02\u{6c4}\u{6c5}\x07\x16\x02\x02\
	\u{6c5}\u{6c6}\x07\u{18d}\x02\x02\u{6c6}\u{6c7}\x05\x6e\x38\x02\u{6c7}\u{6c8}\
	\x07\u{18e}\x02\x02\u{6c8}\x6d\x03\x02\x02\x02\u{6c9}\u{6cb}\x05\u{144}\
	\u{a3}\x02\u{6ca}\u{6c9}\x03\x02\x02\x02\u{6ca}\u{6cb}\x03\x02\x02\x02\u{6cb}\
	\u{6cd}\x03\x02\x02\x02\u{6cc}\u{6ce}\x05\x70\x39\x02\u{6cd}\u{6cc}\x03\
	\x02\x02\x02\u{6cd}\u{6ce}\x03\x02\x02\x02\u{6ce}\u{6d0}\x03\x02\x02\x02\
	\u{6cf}\u{6d1}\x05\x72\x3a\x02\u{6d0}\u{6cf}\x03\x02\x02\x02\u{6d0}\u{6d1}\
	\x03\x02\x02\x02\u{6d1}\u{6d3}\x03\x02\x02\x02\u{6d2}\u{6d4}\x05\u{11e}\
	\u{90}\x02\u{6d3}\u{6d2}\x03\x02\x02\x02\u{6d3}\u{6d4}\x03\x02\x02\x02\u{6d4}\
	\x6f\x03\x02\x02\x02\u{6d5}\u{6d6}\x07\u{f4}\x02\x02\u{6d6}\u{6d7}\x07\x22\
	\x02\x02\u{6d7}\u{6dc}\x05\u{d6}\x6c\x02\u{6d8}\u{6d9}\x07\x34\x02\x02\u{6d9}\
	\u{6db}\x05\u{d6}\x6c\x02\u{6da}\u{6d8}\x03\x02\x02\x02\u{6db}\u{6de}\x03\
	\x02\x02\x02\u{6dc}\u{6da}\x03\x02\x02\x02\u{6dc}\u{6dd}\x03\x02\x02\x02\
	\u{6dd}\u{6e0}\x03\x02\x02\x02\u{6de}\u{6dc}\x03\x02\x02\x02\u{6df}\u{6e1}\
	\x07\x34\x02\x02\u{6e0}\u{6df}\x03\x02\x02\x02\u{6e0}\u{6e1}\x03\x02\x02\
	\x02\u{6e1}\x71\x03\x02\x02\x02\u{6e2}\u{6e3}\x07\u{ee}\x02\x02\u{6e3}\u{6e4}\
	\x07\x22\x02\x02\u{6e4}\u{6e9}\x05\x5c\x2f\x02\u{6e5}\u{6e6}\x07\x34\x02\
	\x02\u{6e6}\u{6e8}\x05\x5c\x2f\x02\u{6e7}\u{6e5}\x03\x02\x02\x02\u{6e8}\
	\u{6eb}\x03\x02\x02\x02\u{6e9}\u{6e7}\x03\x02\x02\x02\u{6e9}\u{6ea}\x03\
	\x02\x02\x02\u{6ea}\u{6ed}\x03\x02\x02\x02\u{6eb}\u{6e9}\x03\x02\x02\x02\
	\u{6ec}\u{6ee}\x07\x34\x02\x02\u{6ed}\u{6ec}\x03\x02\x02\x02\u{6ed}\u{6ee}\
	\x03\x02\x02\x02\u{6ee}\x73\x03\x02\x02\x02\u{6ef}\u{6f0}\x05\u{144}\u{a3}\
	\x02\u{6f0}\u{6f1}\x07\x16\x02\x02\u{6f1}\u{6f2}\x07\u{18d}\x02\x02\u{6f2}\
	\u{6f3}\x05\x1c\x0f\x02\u{6f3}\u{6f4}\x07\u{18e}\x02\x02\u{6f4}\x75\x03\
	\x02\x02\x02\u{6f5}\u{6f6}\x05\x26\x14\x02\u{6f6}\x77\x03\x02\x02\x02\u{6f7}\
	\u{6fc}\x05\u{d6}\x6c\x02\u{6f8}\u{6fa}\x07\x16\x02\x02\u{6f9}\u{6f8}\x03\
	\x02\x02\x02\u{6f9}\u{6fa}\x03\x02\x02\x02\u{6fa}\u{6fb}\x03\x02\x02\x02\
	\u{6fb}\u{6fd}\x05\x76\x3c\x02\u{6fc}\u{6f9}\x03\x02\x02\x02\u{6fc}\u{6fd}\
	\x03\x02\x02\x02\u{6fd}\u{700}\x03\x02\x02\x02\u{6fe}\u{700}\x05\x7a\x3e\
	\x02\u{6ff}\u{6f7}\x03\x02\x02\x02\u{6ff}\u{6fe}\x03\x02\x02\x02\u{700}\
	\x79\x03\x02\x02\x02\u{701}\u{704}\x05\x7c\x3f\x02\u{702}\u{703}\x07\x71\
	\x02\x02\u{703}\u{705}\x05\u{14a}\u{a6}\x02\u{704}\u{702}\x03\x02\x02\x02\
	\u{704}\u{705}\x03\x02\x02\x02\u{705}\u{712}\x03\x02\x02\x02\u{706}\u{707}\
	\x07\u{113}\x02\x02\u{707}\u{708}\x07\u{18d}\x02\x02\u{708}\u{70d}\x05\x60\
	\x31\x02\u{709}\u{70a}\x07\x34\x02\x02\u{70a}\u{70c}\x05\x60\x31\x02\u{70b}\
	\u{709}\x03\x02\x02\x02\u{70c}\u{70f}\x03\x02\x02\x02\u{70d}\u{70b}\x03\
	\x02\x02\x02\u{70d}\u{70e}\x03\x02\x02\x02\u{70e}\u{710}\x03\x02\x02\x02\
	\u{70f}\u{70d}\x03\x02\x02\x02\u{710}\u{711}\x07\u{18e}\x02\x02\u{711}\u{713}\
	\x03\x02\x02\x02\u{712}\u{706}\x03\x02\x02\x02\u{712}\u{713}\x03\x02\x02\
	\x02\u{713}\x7b\x03\x02\x02\x02\u{714}\u{715}\x05\u{de}\x70\x02\u{715}\u{716}\
	\x07\u{191}\x02\x02\u{716}\u{717}\x07\u{19a}\x02\x02\u{717}\u{71a}\x03\x02\
	\x02\x02\u{718}\u{71a}\x07\u{19a}\x02\x02\u{719}\u{714}\x03\x02\x02\x02\
	\u{719}\u{718}\x03\x02\x02\x02\u{71a}\x7d\x03\x02\x02\x02\u{71b}\u{71c}\
	\x05\u{80}\x41\x02\u{71c}\x7f\x03\x02\x02\x02\u{71d}\u{71e}\x08\x41\x01\
	\x02\u{71e}\u{71f}\x05\u{82}\x42\x02\u{71f}\u{738}\x03\x02\x02\x02\u{720}\
	\u{734}\x0c\x04\x02\x02\u{721}\u{722}\x07\x43\x02\x02\u{722}\u{723}\x07\
	\u{ad}\x02\x02\u{723}\u{725}\x05\u{82}\x42\x02\u{724}\u{726}\x05\u{86}\x44\
	\x02\u{725}\u{724}\x03\x02\x02\x02\u{725}\u{726}\x03\x02\x02\x02\u{726}\
	\u{735}\x03\x02\x02\x02\u{727}\u{728}\x07\x34\x02\x02\u{728}\u{735}\x05\
	\u{82}\x42\x02\u{729}\u{72a}\x05\u{84}\x43\x02\u{72a}\u{72b}\x07\u{ad}\x02\
	\x02\u{72b}\u{72d}\x05\u{82}\x42\x02\u{72c}\u{72e}\x05\u{86}\x44\x02\u{72d}\
	\u{72c}\x03\x02\x02\x02\u{72d}\u{72e}\x03\x02\x02\x02\u{72e}\u{735}\x03\
	\x02\x02\x02\u{72f}\u{730}\x07\u{d8}\x02\x02\u{730}\u{731}\x05\u{84}\x43\
	\x02\u{731}\u{732}\x07\u{ad}\x02\x02\u{732}\u{733}\x05\u{82}\x42\x02\u{733}\
	\u{735}\x03\x02\x02\x02\u{734}\u{721}\x03\x02\x02\x02\u{734}\u{727}\x03\
	\x02\x02\x02\u{734}\u{729}\x03\x02\x02\x02\u{734}\u{72f}\x03\x02\x02\x02\
	\u{735}\u{737}\x03\x02\x02\x02\u{736}\u{720}\x03\x02\x02\x02\u{737}\u{73a}\
	\x03\x02\x02\x02\u{738}\u{736}\x03\x02\x02\x02\u{738}\u{739}\x03\x02\x02\
	\x02\u{739}\u{81}\x03\x02\x02\x02\u{73a}\u{738}\x03\x02\x02\x02\u{73b}\u{741}\
	\x05\u{8a}\x46\x02\u{73c}\u{73d}\x07\u{18d}\x02\x02\u{73d}\u{73e}\x05\u{80}\
	\x41\x02\u{73e}\u{73f}\x07\u{18e}\x02\x02\u{73f}\u{741}\x03\x02\x02\x02\
	\u{740}\u{73b}\x03\x02\x02\x02\u{740}\u{73c}\x03\x02\x02\x02\u{741}\u{83}\
	\x03\x02\x02\x02\u{742}\u{744}\x07\u{9d}\x02\x02\u{743}\u{742}\x03\x02\x02\
	\x02\u{743}\u{744}\x03\x02\x02\x02\u{744}\u{752}\x03\x02\x02\x02\u{745}\
	\u{747}\x07\u{b8}\x02\x02\u{746}\u{748}\x07\u{ef}\x02\x02\u{747}\u{746}\
	\x03\x02\x02\x02\u{747}\u{748}\x03\x02\x02\x02\u{748}\u{752}\x03\x02\x02\
	\x02\u{749}\u{74b}\x07\u{11d}\x02\x02\u{74a}\u{74c}\x07\u{ef}\x02\x02\u{74b}\
	\u{74a}\x03\x02\x02\x02\u{74b}\u{74c}\x03\x02\x02\x02\u{74c}\u{752}\x03\
	\x02\x02\x02\u{74d}\u{74f}\x07\u{85}\x02\x02\u{74e}\u{750}\x07\u{ef}\x02\
	\x02\u{74f}\u{74e}\x03\x02\x02\x02\u{74f}\u{750}\x03\x02\x02\x02\u{750}\
	\u{752}\x03\x02\x02\x02\u{751}\u{743}\x03\x02\x02\x02\u{751}\u{745}\x03\
	\x02\x02\x02\u{751}\u{749}\x03\x02\x02\x02\u{751}\u{74d}\x03\x02\x02\x02\
	\u{752}\u{85}\x03\x02\x02\x02\u{753}\u{754}\x07\u{e8}\x02\x02\u{754}\u{765}\
	\x05\u{d8}\x6d\x02\u{755}\u{756}\x07\u{171}\x02\x02\u{756}\u{757}\x07\u{18d}\
	\x02\x02\u{757}\u{75c}\x05\u{144}\u{a3}\x02\u{758}\u{759}\x07\x34\x02\x02\
	\u{759}\u{75b}\x05\u{144}\u{a3}\x02\u{75a}\u{758}\x03\x02\x02\x02\u{75b}\
	\u{75e}\x03\x02\x02\x02\u{75c}\u{75a}\x03\x02\x02\x02\u{75c}\u{75d}\x03\
	\x02\x02\x02\u{75d}\u{760}\x03\x02\x02\x02\u{75e}\u{75c}\x03\x02\x02\x02\
	\u{75f}\u{761}\x07\x34\x02\x02\u{760}\u{75f}\x03\x02\x02\x02\u{760}\u{761}\
	\x03\x02\x02\x02\u{761}\u{762}\x03\x02\x02\x02\u{762}\u{763}\x07\u{18e}\
	\x02\x02\u{763}\u{765}\x03\x02\x02\x02\u{764}\u{753}\x03\x02\x02\x02\u{764}\
	\u{755}\x03\x02\x02\x02\u{765}\u{87}\x03\x02\x02\x02\u{766}\u{767}\x05\u{9a}\
	\x4e\x02\u{767}\u{89}\x03\x02\x02\x02\u{768}\u{76a}\x05\u{88}\x45\x02\u{769}\
	\u{76b}\x05\u{8c}\x47\x02\u{76a}\u{769}\x03\x02\x02\x02\u{76a}\u{76b}\x03\
	\x02\x02\x02\u{76b}\u{8b}\x03\x02\x02\x02\u{76c}\u{76d}\x07\u{147}\x02\x02\
	\u{76d}\u{76e}\x05\u{8e}\x48\x02\u{76e}\u{76f}\x07\u{18d}\x02\x02\u{76f}\
	\u{770}\x05\u{d6}\x6c\x02\u{770}\u{771}\x07\u{fc}\x02\x02\u{771}\u{772}\
	\x07\u{18e}\x02\x02\u{772}\u{8d}\x03\x02\x02\x02\u{773}\u{774}\x09\x0e\x02\
	\x02\u{774}\u{8f}\x03\x02\x02\x02\u{775}\u{776}\x09\x0f\x02\x02\u{776}\u{91}\
	\x03\x02\x02\x02\u{777}\u{77e}\x07\x6e\x02\x02\u{778}\u{77a}\x07\u{15d}\
	\x02\x02\u{779}\u{77b}\x05\u{fa}\x7e\x02\u{77a}\u{779}\x03\x02\x02\x02\u{77a}\
	\u{77b}\x03\x02\x02\x02\u{77b}\u{77c}\x03\x02\x02\x02\u{77c}\u{77e}\x05\
	\u{94}\x4b\x02\u{77d}\u{777}\x03\x02\x02\x02\u{77d}\u{778}\x03\x02\x02\x02\
	\u{77e}\u{93}\x03\x02\x02\x02\u{77f}\u{780}\x07\u{183}\x02\x02\u{780}\u{784}\
	\x07\x41\x02\x02\u{781}\u{782}\x07\u{184}\x02\x02\u{782}\u{784}\x07\x41\
	\x02\x02\u{783}\u{77f}\x03\x02\x02\x02\u{783}\u{781}\x03\x02\x02\x02\u{784}\
	\u{95}\x03\x02\x02\x02\u{785}\u{786}\x05\u{144}\u{a3}\x02\u{786}\u{787}\
	\x07\x16\x02\x02\u{787}\u{788}\x05\u{d6}\x6c\x02\u{788}\u{97}\x03\x02\x02\
	\x02\u{789}\u{78a}\x05\u{c2}\x62\x02\u{78a}\u{99}\x03\x02\x02\x02\u{78b}\
	\u{78f}\x05\u{98}\x4d\x02\u{78c}\u{78e}\x05\u{b6}\x5c\x02\u{78d}\u{78c}\
	\x03\x02\x02\x02\u{78e}\u{791}\x03\x02\x02\x02\u{78f}\u{78d}\x03\x02\x02\
	\x02\u{78f}\u{790}\x03\x02\x02\x02\u{790}\u{9b}\x03\x02\x02\x02\u{791}\u{78f}\
	\x03\x02\x02\x02\u{792}\u{793}\x05\x12\x0a\x02\u{793}\u{9d}\x03\x02\x02\
	\x02\u{794}\u{795}\x05\u{d6}\x6c\x02\u{795}\u{9f}\x03\x02\x02\x02\u{796}\
	\u{797}\x05\x14\x0b\x02\u{797}\u{a1}\x03\x02\x02\x02\u{798}\u{79a}\x07\x16\
	\x02\x02\u{799}\u{798}\x03\x02\x02\x02\u{799}\u{79a}\x03\x02\x02\x02\u{79a}\
	\u{79b}\x03\x02\x02\x02\u{79b}\u{79d}\x05\u{144}\u{a3}\x02\u{79c}\u{799}\
	\x03\x02\x02\x02\u{79c}\u{79d}\x03\x02\x02\x02\u{79d}\u{a3}\x03\x02\x02\
	\x02\u{79e}\u{79f}\x05\u{144}\u{a3}\x02\u{79f}\u{7a0}\x07\u{81}\x02\x02\
	\u{7a0}\u{7a1}\x05\u{144}\u{a3}\x02\u{7a1}\u{7a2}\x07\u{99}\x02\x02\u{7a2}\
	\u{7a3}\x07\u{18d}\x02\x02\u{7a3}\u{7a4}\x05\u{a6}\x54\x02\u{7a4}\u{7a5}\
	\x07\u{18e}\x02\x02\u{7a5}\u{a5}\x03\x02\x02\x02\u{7a6}\u{7ab}\x05\u{144}\
	\u{a3}\x02\u{7a7}\u{7a9}\x07\x16\x02\x02\u{7a8}\u{7a7}\x03\x02\x02\x02\u{7a8}\
	\u{7a9}\x03\x02\x02\x02\u{7a9}\u{7aa}\x03\x02\x02\x02\u{7aa}\u{7ac}\x05\
	\u{a8}\x55\x02\u{7ab}\u{7a8}\x03\x02\x02\x02\u{7ab}\u{7ac}\x03\x02\x02\x02\
	\u{7ac}\u{7b7}\x03\x02\x02\x02\u{7ad}\u{7ae}\x07\x34\x02\x02\u{7ae}\u{7b3}\
	\x05\u{144}\u{a3}\x02\u{7af}\u{7b1}\x07\x16\x02\x02\u{7b0}\u{7af}\x03\x02\
	\x02\x02\u{7b0}\u{7b1}\x03\x02\x02\x02\u{7b1}\u{7b2}\x03\x02\x02\x02\u{7b2}\
	\u{7b4}\x05\u{a8}\x55\x02\u{7b3}\u{7b0}\x03\x02\x02\x02\u{7b3}\u{7b4}\x03\
	\x02\x02\x02\u{7b4}\u{7b6}\x03\x02\x02\x02\u{7b5}\u{7ad}\x03\x02\x02\x02\
	\u{7b6}\u{7b9}\x03\x02\x02\x02\u{7b7}\u{7b5}\x03\x02\x02\x02\u{7b7}\u{7b8}\
	\x03\x02\x02\x02\u{7b8}\u{7bb}\x03\x02\x02\x02\u{7b9}\u{7b7}\x03\x02\x02\
	\x02\u{7ba}\u{7bc}\x07\x34\x02\x02\u{7bb}\u{7ba}\x03\x02\x02\x02\u{7bb}\
	\u{7bc}\x03\x02\x02\x02\u{7bc}\u{a7}\x03\x02\x02\x02\u{7bd}\u{7c0}\x05\u{14e}\
	\u{a8}\x02\u{7be}\u{7c0}\x05\u{fa}\x7e\x02\u{7bf}\u{7bd}\x03\x02\x02\x02\
	\u{7bf}\u{7be}\x03\x02\x02\x02\u{7c0}\u{a9}\x03\x02\x02\x02\u{7c1}\u{7c2}\
	\x05\u{ac}\x57\x02\u{7c2}\u{7c3}\x07\u{81}\x02\x02\u{7c3}\u{7c4}\x05\u{144}\
	\u{a3}\x02\u{7c4}\u{7c5}\x07\u{99}\x02\x02\u{7c5}\u{7c6}\x07\u{18d}\x02\
	\x02\u{7c6}\u{7c7}\x05\u{b0}\x59\x02\u{7c7}\u{7c8}\x07\u{18e}\x02\x02\u{7c8}\
	\u{ab}\x03\x02\x02\x02\u{7c9}\u{7ca}\x07\u{18d}\x02\x02\u{7ca}\u{7cf}\x05\
	\u{144}\u{a3}\x02\u{7cb}\u{7cc}\x07\x34\x02\x02\u{7cc}\u{7ce}\x05\u{144}\
	\u{a3}\x02\u{7cd}\u{7cb}\x03\x02\x02\x02\u{7ce}\u{7d1}\x03\x02\x02\x02\u{7cf}\
	\u{7cd}\x03\x02\x02\x02\u{7cf}\u{7d0}\x03\x02\x02\x02\u{7d0}\u{7d3}\x03\
	\x02\x02\x02\u{7d1}\u{7cf}\x03\x02\x02\x02\u{7d2}\u{7d4}\x07\x34\x02\x02\
	\u{7d3}\u{7d2}\x03\x02\x02\x02\u{7d3}\u{7d4}\x03\x02\x02\x02\u{7d4}\u{7d5}\
	\x03\x02\x02\x02\u{7d5}\u{7d6}\x07\u{18e}\x02\x02\u{7d6}\u{ad}\x03\x02\x02\
	\x02\u{7d7}\u{7d8}\x07\u{18d}\x02\x02\u{7d8}\u{7dd}\x05\u{144}\u{a3}\x02\
	\u{7d9}\u{7da}\x07\x34\x02\x02\u{7da}\u{7dc}\x05\u{144}\u{a3}\x02\u{7db}\
	\u{7d9}\x03\x02\x02\x02\u{7dc}\u{7df}\x03\x02\x02\x02\u{7dd}\u{7db}\x03\
	\x02\x02\x02\u{7dd}\u{7de}\x03\x02\x02\x02\u{7de}\u{7e0}\x03\x02\x02\x02\
	\u{7df}\u{7dd}\x03\x02\x02\x02\u{7e0}\u{7e5}\x07\u{18e}\x02\x02\u{7e1}\u{7e3}\
	\x07\x16\x02\x02\u{7e2}\u{7e1}\x03\x02\x02\x02\u{7e2}\u{7e3}\x03\x02\x02\
	\x02\u{7e3}\u{7e4}\x03\x02\x02\x02\u{7e4}\u{7e6}\x05\u{a8}\x55\x02\u{7e5}\
	\u{7e2}\x03\x02\x02\x02\u{7e5}\u{7e6}\x03\x02\x02\x02\u{7e6}\u{af}\x03\x02\
	\x02\x02\u{7e7}\u{7ec}\x05\u{ae}\x58\x02\u{7e8}\u{7e9}\x07\x34\x02\x02\u{7e9}\
	\u{7eb}\x05\u{ae}\x58\x02\u{7ea}\u{7e8}\x03\x02\x02\x02\u{7eb}\u{7ee}\x03\
	\x02\x02\x02\u{7ec}\u{7ea}\x03\x02\x02\x02\u{7ec}\u{7ed}\x03\x02\x02\x02\
	\u{7ed}\u{7f0}\x03\x02\x02\x02\u{7ee}\u{7ec}\x03\x02\x02\x02\u{7ef}\u{7f1}\
	\x07\x34\x02\x02\u{7f0}\u{7ef}\x03\x02\x02\x02\u{7f0}\u{7f1}\x03\x02\x02\
	\x02\u{7f1}\u{b1}\x03\x02\x02\x02\u{7f2}\u{7f5}\x05\u{a4}\x53\x02\u{7f3}\
	\u{7f5}\x05\u{aa}\x56\x02\u{7f4}\u{7f2}\x03\x02\x02\x02\u{7f4}\u{7f3}\x03\
	\x02\x02\x02\u{7f5}\u{b3}\x03\x02\x02\x02\u{7f6}\u{7fb}\x05\u{a0}\x51\x02\
	\u{7f7}\u{7f8}\x07\x34\x02\x02\u{7f8}\u{7fa}\x05\u{a0}\x51\x02\u{7f9}\u{7f7}\
	\x03\x02\x02\x02\u{7fa}\u{7fd}\x03\x02\x02\x02\u{7fb}\u{7f9}\x03\x02\x02\
	\x02\u{7fb}\u{7fc}\x03\x02\x02\x02\u{7fc}\u{7ff}\x03\x02\x02\x02\u{7fd}\
	\u{7fb}\x03\x02\x02\x02\u{7fe}\u{800}\x07\x34\x02\x02\u{7ff}\u{7fe}\x03\
	\x02\x02\x02\u{7ff}\u{800}\x03\x02\x02\x02\u{800}\u{b5}\x03\x02\x02\x02\
	\u{801}\u{802}\x07\u{ff}\x02\x02\u{802}\u{803}\x07\u{18d}\x02\x02\u{803}\
	\u{804}\x05\u{9c}\x4f\x02\u{804}\u{805}\x07\u{81}\x02\x02\u{805}\u{806}\
	\x05\u{9e}\x50\x02\u{806}\u{807}\x07\u{99}\x02\x02\u{807}\u{808}\x07\u{18d}\
	\x02\x02\u{808}\u{809}\x05\u{b4}\x5b\x02\u{809}\u{80a}\x07\u{18e}\x02\x02\
	\u{80a}\u{80b}\x07\u{18e}\x02\x02\u{80b}\u{80c}\x05\u{a2}\x52\x02\u{80c}\
	\u{817}\x03\x02\x02\x02\u{80d}\u{80f}\x07\u{16b}\x02\x02\u{80e}\u{810}\x05\
	\x16\x0c\x02\u{80f}\u{80e}\x03\x02\x02\x02\u{80f}\u{810}\x03\x02\x02\x02\
	\u{810}\u{811}\x03\x02\x02\x02\u{811}\u{812}\x07\u{18d}\x02\x02\u{812}\u{813}\
	\x05\u{b2}\x5a\x02\u{813}\u{814}\x07\u{18e}\x02\x02\u{814}\u{815}\x05\u{a2}\
	\x52\x02\u{815}\u{817}\x03\x02\x02\x02\u{816}\u{801}\x03\x02\x02\x02\u{816}\
	\u{80d}\x03\x02\x02\x02\u{817}\u{b7}\x03\x02\x02\x02\u{818}\u{81e}\x05\u{13c}\
	\u{9f}\x02\u{819}\u{81a}\x07\u{18d}\x02\x02\u{81a}\u{81b}\x05\x1c\x0f\x02\
	\u{81b}\u{81c}\x07\u{18e}\x02\x02\u{81c}\u{81e}\x03\x02\x02\x02\u{81d}\u{818}\
	\x03\x02\x02\x02\u{81d}\u{819}\x03\x02\x02\x02\u{81e}\u{b9}\x03\x02\x02\
	\x02\u{81f}\u{824}\x05\u{b8}\x5d\x02\u{820}\u{822}\x07\x16\x02\x02\u{821}\
	\u{820}\x03\x02\x02\x02\u{821}\u{822}\x03\x02\x02\x02\u{822}\u{823}\x03\
	\x02\x02\x02\u{823}\u{825}\x05\u{144}\u{a3}\x02\u{824}\u{821}\x03\x02\x02\
	\x02\u{824}\u{825}\x03\x02\x02\x02\u{825}\u{bb}\x03\x02\x02\x02\u{826}\u{829}\
	\x05\u{144}\u{a3}\x02\u{827}\u{828}\x07\u{ec}\x02\x02\u{828}\u{82a}\x05\
	\x38\x1d\x02\u{829}\u{827}\x03\x02\x02\x02\u{829}\u{82a}\x03\x02\x02\x02\
	\u{82a}\u{842}\x03\x02\x02\x02\u{82b}\u{82c}\x07\u{18d}\x02\x02\u{82c}\u{82f}\
	\x05\u{144}\u{a3}\x02\u{82d}\u{82e}\x07\u{ec}\x02\x02\u{82e}\u{830}\x05\
	\x38\x1d\x02\u{82f}\u{82d}\x03\x02\x02\x02\u{82f}\u{830}\x03\x02\x02\x02\
	\u{830}\u{839}\x03\x02\x02\x02\u{831}\u{832}\x07\x34\x02\x02\u{832}\u{835}\
	\x05\u{144}\u{a3}\x02\u{833}\u{834}\x07\u{ec}\x02\x02\u{834}\u{836}\x05\
	\x38\x1d\x02\u{835}\u{833}\x03\x02\x02\x02\u{835}\u{836}\x03\x02\x02\x02\
	\u{836}\u{838}\x03\x02\x02\x02\u{837}\u{831}\x03\x02\x02\x02\u{838}\u{83b}\
	\x03\x02\x02\x02\u{839}\u{837}\x03\x02\x02\x02\u{839}\u{83a}\x03\x02\x02\
	\x02\u{83a}\u{83d}\x03\x02\x02\x02\u{83b}\u{839}\x03\x02\x02\x02\u{83c}\
	\u{83e}\x07\x34\x02\x02\u{83d}\u{83c}\x03\x02\x02\x02\u{83d}\u{83e}\x03\
	\x02\x02\x02\u{83e}\u{83f}\x03\x02\x02\x02\u{83f}\u{840}\x07\u{18e}\x02\
	\x02\u{840}\u{842}\x03\x02\x02\x02\u{841}\u{826}\x03\x02\x02\x02\u{841}\
	\u{82b}\x03\x02\x02\x02\u{842}\u{bd}\x03\x02\x02\x02\u{843}\u{844}\x05\u{144}\
	\u{a3}\x02\u{844}\u{845}\x05\u{10a}\u{86}\x02\u{845}\u{bf}\x03\x02\x02\x02\
	\u{846}\u{847}\x07\u{18d}\x02\x02\u{847}\u{84c}\x05\u{be}\x60\x02\u{848}\
	\u{849}\x07\x34\x02\x02\u{849}\u{84b}\x05\u{be}\x60\x02\u{84a}\u{848}\x03\
	\x02\x02\x02\u{84b}\u{84e}\x03\x02\x02\x02\u{84c}\u{84a}\x03\x02\x02\x02\
	\u{84c}\u{84d}\x03\x02\x02\x02\u{84d}\u{850}\x03\x02\x02\x02\u{84e}\u{84c}\
	\x03\x02\x02\x02\u{84f}\u{851}\x07\x34\x02\x02\u{850}\u{84f}\x03\x02\x02\
	\x02\u{850}\u{851}\x03\x02\x02\x02\u{851}\u{852}\x03\x02\x02\x02\u{852}\
	\u{853}\x07\u{18e}\x02\x02\u{853}\u{c1}\x03\x02\x02\x02\u{854}\u{875}\x05\
	\u{ba}\x5e\x02\u{855}\u{856}\x07\u{16a}\x02\x02\u{856}\u{857}\x07\u{18d}\
	\x02\x02\u{857}\u{85c}\x05\u{d6}\x6c\x02\u{858}\u{859}\x07\x34\x02\x02\u{859}\
	\u{85b}\x05\u{d6}\x6c\x02\u{85a}\u{858}\x03\x02\x02\x02\u{85b}\u{85e}\x03\
	\x02\x02\x02\u{85c}\u{85a}\x03\x02\x02\x02\u{85c}\u{85d}\x03\x02\x02\x02\
	\u{85d}\u{860}\x03\x02\x02\x02\u{85e}\u{85c}\x03\x02\x02\x02\u{85f}\u{861}\
	\x07\x34\x02\x02\u{860}\u{85f}\x03\x02\x02\x02\u{860}\u{861}\x03\x02\x02\
	\x02\u{861}\u{862}\x03\x02\x02\x02\u{862}\u{867}\x07\u{18e}\x02\x02\u{863}\
	\u{865}\x07\x16\x02\x02\u{864}\u{863}\x03\x02\x02\x02\u{864}\u{865}\x03\
	\x02\x02\x02\u{865}\u{866}\x03\x02\x02\x02\u{866}\u{868}\x05\u{144}\u{a3}\
	\x02\u{867}\u{864}\x03\x02\x02\x02\u{867}\u{868}\x03\x02\x02\x02\u{868}\
	\u{871}\x03\x02\x02\x02\u{869}\u{86a}\x07\u{183}\x02\x02\u{86a}\u{86f}\x07\
	\u{e6}\x02\x02\u{86b}\u{86d}\x07\x16\x02\x02\u{86c}\u{86b}\x03\x02\x02\x02\
	\u{86c}\u{86d}\x03\x02\x02\x02\u{86d}\u{86e}\x03\x02\x02\x02\u{86e}\u{870}\
	\x05\u{144}\u{a3}\x02\u{86f}\u{86c}\x03\x02\x02\x02\u{86f}\u{870}\x03\x02\
	\x02\x02\u{870}\u{872}\x03\x02\x02\x02\u{871}\u{869}\x03\x02\x02\x02\u{871}\
	\u{872}\x03\x02\x02\x02\u{872}\u{875}\x03\x02\x02\x02\u{873}\u{875}\x05\
	\u{c4}\x63\x02\u{874}\u{854}\x03\x02\x02\x02\u{874}\u{855}\x03\x02\x02\x02\
	\u{874}\u{873}\x03\x02\x02\x02\u{875}\u{c3}\x03\x02\x02\x02\u{876}\u{877}\
	\x05\u{ec}\x77\x02\u{877}\u{883}\x07\u{18d}\x02\x02\u{878}\u{87d}\x05\u{ca}\
	\x66\x02\u{879}\u{87a}\x07\x34\x02\x02\u{87a}\u{87c}\x05\u{ca}\x66\x02\u{87b}\
	\u{879}\x03\x02\x02\x02\u{87c}\u{87f}\x03\x02\x02\x02\u{87d}\u{87b}\x03\
	\x02\x02\x02\u{87d}\u{87e}\x03\x02\x02\x02\u{87e}\u{881}\x03\x02\x02\x02\
	\u{87f}\u{87d}\x03\x02\x02\x02\u{880}\u{882}\x07\x34\x02\x02\u{881}\u{880}\
	\x03\x02\x02\x02\u{881}\u{882}\x03\x02\x02\x02\u{882}\u{884}\x03\x02\x02\
	\x02\u{883}\u{878}\x03\x02\x02\x02\u{883}\u{884}\x03\x02\x02\x02\u{884}\
	\u{886}\x03\x02\x02\x02\u{885}\u{887}\x05\u{c6}\x64\x02\u{886}\u{885}\x03\
	\x02\x02\x02\u{886}\u{887}\x03\x02\x02\x02\u{887}\u{888}\x03\x02\x02\x02\
	\u{888}\u{88a}\x07\u{18e}\x02\x02\u{889}\u{88b}\x05\u{11c}\u{8f}\x02\u{88a}\
	\u{889}\x03\x02\x02\x02\u{88a}\u{88b}\x03\x02\x02\x02\u{88b}\u{c5}\x03\x02\
	\x02\x02\u{88c}\u{88d}\x07\x3f\x02\x02\u{88d}\u{892}\x05\u{d4}\x6b\x02\u{88e}\
	\u{88f}\x07\x34\x02\x02\u{88f}\u{891}\x05\u{d4}\x6b\x02\u{890}\u{88e}\x03\
	\x02\x02\x02\u{891}\u{894}\x03\x02\x02\x02\u{892}\u{890}\x03\x02\x02\x02\
	\u{892}\u{893}\x03\x02\x02\x02\u{893}\u{896}\x03\x02\x02\x02\u{894}\u{892}\
	\x03\x02\x02\x02\u{895}\u{897}\x07\x34\x02\x02\u{896}\u{895}\x03\x02\x02\
	\x02\u{896}\u{897}\x03\x02\x02\x02\u{897}\u{c7}\x03\x02\x02\x02\u{898}\u{899}\
	\x05\u{144}\u{a3}\x02\u{899}\u{c9}\x03\x02\x02\x02\u{89a}\u{89b}\x05\u{c8}\
	\x65\x02\u{89b}\u{89c}\x07\x04\x02\x02\u{89c}\u{89e}\x03\x02\x02\x02\u{89d}\
	\u{89a}\x03\x02\x02\x02\u{89d}\u{89e}\x03\x02\x02\x02\u{89e}\u{8a2}\x03\
	\x02\x02\x02\u{89f}\u{8a3}\x05\u{cc}\x67\x02\u{8a0}\u{8a3}\x05\u{d0}\x69\
	\x02\u{8a1}\u{8a3}\x05\u{d6}\x6c\x02\u{8a2}\u{89f}\x03\x02\x02\x02\u{8a2}\
	\u{8a0}\x03\x02\x02\x02\u{8a2}\u{8a1}\x03\x02\x02\x02\u{8a3}\u{cb}\x03\x02\
	\x02\x02\u{8a4}\u{8b9}\x05\u{ce}\x68\x02\u{8a5}\u{8a6}\x07\u{f4}\x02\x02\
	\u{8a6}\u{8b7}\x07\x22\x02\x02\u{8a7}\u{8b3}\x07\u{18d}\x02\x02\u{8a8}\u{8ad}\
	\x05\u{d6}\x6c\x02\u{8a9}\u{8aa}\x07\x34\x02\x02\u{8aa}\u{8ac}\x05\u{d6}\
	\x6c\x02\u{8ab}\u{8a9}\x03\x02\x02\x02\u{8ac}\u{8af}\x03\x02\x02\x02\u{8ad}\
	\u{8ab}\x03\x02\x02\x02\u{8ad}\u{8ae}\x03\x02\x02\x02\u{8ae}\u{8b1}\x03\
	\x02\x02\x02\u{8af}\u{8ad}\x03\x02\x02\x02\u{8b0}\u{8b2}\x07\x34\x02\x02\
	\u{8b1}\u{8b0}\x03\x02\x02\x02\u{8b1}\u{8b2}\x03\x02\x02\x02\u{8b2}\u{8b4}\
	\x03\x02\x02\x02\u{8b3}\u{8a8}\x03\x02\x02\x02\u{8b3}\u{8b4}\x03\x02\x02\
	\x02\u{8b4}\u{8b5}\x03\x02\x02\x02\u{8b5}\u{8b8}\x07\u{18e}\x02\x02\u{8b6}\
	\u{8b8}\x05\u{d6}\x6c\x02\u{8b7}\u{8a7}\x03\x02\x02\x02\u{8b7}\u{8b6}\x03\
	\x02\x02\x02\u{8b8}\u{8ba}\x03\x02\x02\x02\u{8b9}\u{8a5}\x03\x02\x02\x02\
	\u{8b9}\u{8ba}\x03\x02\x02\x02\u{8ba}\u{8c1}\x03\x02\x02\x02\u{8bb}\u{8bc}\
	\x07\u{108}\x02\x02\u{8bc}\u{8bd}\x07\u{17f}\x02\x02\u{8bd}\u{8c2}\x07\x6a\
	\x02\x02\u{8be}\u{8bf}\x07\u{af}\x02\x02\u{8bf}\u{8c0}\x07\u{17f}\x02\x02\
	\u{8c0}\u{8c2}\x07\x6a\x02\x02\u{8c1}\u{8bb}\x03\x02\x02\x02\u{8c1}\u{8be}\
	\x03\x02\x02\x02\u{8c1}\u{8c2}\x03\x02\x02\x02\u{8c2}\u{8d6}\x03\x02\x02\
	\x02\u{8c3}\u{8c4}\x07\u{ee}\x02\x02\u{8c4}\u{8d4}\x07\x22\x02\x02\u{8c5}\
	\u{8c6}\x07\u{18d}\x02\x02\u{8c6}\u{8cb}\x05\x5c\x2f\x02\u{8c7}\u{8c8}\x07\
	\x34\x02\x02\u{8c8}\u{8ca}\x05\x5c\x2f\x02\u{8c9}\u{8c7}\x03\x02\x02\x02\
	\u{8ca}\u{8cd}\x03\x02\x02\x02\u{8cb}\u{8c9}\x03\x02\x02\x02\u{8cb}\u{8cc}\
	\x03\x02\x02\x02\u{8cc}\u{8cf}\x03\x02\x02\x02\u{8cd}\u{8cb}\x03\x02\x02\
	\x02\u{8ce}\u{8d0}\x07\x34\x02\x02\u{8cf}\u{8ce}\x03\x02\x02\x02\u{8cf}\
	\u{8d0}\x03\x02\x02\x02\u{8d0}\u{8d1}\x03\x02\x02\x02\u{8d1}\u{8d2}\x07\
	\u{18e}\x02\x02\u{8d2}\u{8d5}\x03\x02\x02\x02\u{8d3}\u{8d5}\x05\x5c\x2f\
	\x02\u{8d4}\u{8c5}\x03\x02\x02\x02\u{8d4}\u{8d3}\x03\x02\x02\x02\u{8d5}\
	\u{8d7}\x03\x02\x02\x02\u{8d6}\u{8c3}\x03\x02\x02\x02\u{8d6}\u{8d7}\x03\
	\x02\x02\x02\u{8d7}\u{cd}\x03\x02\x02\x02\u{8d8}\u{8d9}\x07\u{145}\x02\x02\
	\u{8d9}\u{8e8}\x05\u{130}\u{99}\x02\u{8da}\u{8db}\x07\u{145}\x02\x02\u{8db}\
	\u{8dc}\x07\u{18d}\x02\x02\u{8dc}\u{8dd}\x05\x1c\x0f\x02\u{8dd}\u{8e5}\x07\
	\u{18e}\x02\x02\u{8de}\u{8e0}\x07\x16\x02\x02\u{8df}\u{8de}\x03\x02\x02\
	\x02\u{8df}\u{8e0}\x03\x02\x02\x02\u{8e0}\u{8e1}\x03\x02\x02\x02\u{8e1}\
	\u{8e3}\x05\u{144}\u{a3}\x02\u{8e2}\u{8e4}\x05\u{bc}\x5f\x02\u{8e3}\u{8e2}\
	\x03\x02\x02\x02\u{8e3}\u{8e4}\x03\x02\x02\x02\u{8e4}\u{8e6}\x03\x02\x02\
	\x02\u{8e5}\u{8df}\x03\x02\x02\x02\u{8e5}\u{8e6}\x03\x02\x02\x02\u{8e6}\
	\u{8e8}\x03\x02\x02\x02\u{8e7}\u{8d8}\x03\x02\x02\x02\u{8e7}\u{8da}\x03\
	\x02\x02\x02\u{8e8}\u{cf}\x03\x02\x02\x02\u{8e9}\u{8ea}\x07\x5e\x02\x02\
	\u{8ea}\u{8eb}\x07\u{18d}\x02\x02\u{8eb}\u{8f0}\x05\u{d2}\x6a\x02\u{8ec}\
	\u{8ed}\x07\x34\x02\x02\u{8ed}\u{8ef}\x05\u{d2}\x6a\x02\u{8ee}\u{8ec}\x03\
	\x02\x02\x02\u{8ef}\u{8f2}\x03\x02\x02\x02\u{8f0}\u{8ee}\x03\x02\x02\x02\
	\u{8f0}\u{8f1}\x03\x02\x02\x02\u{8f1}\u{8f4}\x03\x02\x02\x02\u{8f2}\u{8f0}\
	\x03\x02\x02\x02\u{8f3}\u{8f5}\x07\x34\x02\x02\u{8f4}\u{8f3}\x03\x02\x02\
	\x02\u{8f4}\u{8f5}\x03\x02\x02\x02\u{8f5}\u{8f6}\x03\x02\x02\x02\u{8f6}\
	\u{8f7}\x07\u{18e}\x02\x02\u{8f7}\u{8ff}\x03\x02\x02\x02\u{8f8}\u{8f9}\x07\
	\x2a\x02\x02\u{8f9}\u{8fa}\x07\u{18d}\x02\x02\u{8fa}\u{8fb}\x07\u{e2}\x02\
	\x02\u{8fb}\u{8fc}\x07\x16\x02\x02\u{8fc}\u{8fd}\x07\x5e\x02\x02\u{8fd}\
	\u{8ff}\x07\u{18e}\x02\x02\u{8fe}\u{8e9}\x03\x02\x02\x02\u{8fe}\u{8f8}\x03\
	\x02\x02\x02\u{8ff}\u{d1}\x03\x02\x02\x02\u{900}\u{902}\x05\u{144}\u{a3}\
	\x02\u{901}\u{903}\x05\u{10a}\u{86}\x02\u{902}\u{901}\x03\x02\x02\x02\u{902}\
	\u{903}\x03\x02\x02\x02\u{903}\u{d3}\x03\x02\x02\x02\u{904}\u{905}\x07\u{18d}\
	\x02\x02\u{905}\u{906}\x05\u{130}\u{99}\x02\u{906}\u{907}\x07\x34\x02\x02\
	\u{907}\u{90c}\x05\u{130}\u{99}\x02\u{908}\u{909}\x07\x34\x02\x02\u{909}\
	\u{90b}\x05\u{130}\u{99}\x02\u{90a}\u{908}\x03\x02\x02\x02\u{90b}\u{90e}\
	\x03\x02\x02\x02\u{90c}\u{90a}\x03\x02\x02\x02\u{90c}\u{90d}\x03\x02\x02\
	\x02\u{90d}\u{910}\x03\x02\x02\x02\u{90e}\u{90c}\x03\x02\x02\x02\u{90f}\
	\u{911}\x07\x34\x02\x02\u{910}\u{90f}\x03\x02\x02\x02\u{910}\u{911}\x03\
	\x02\x02\x02\u{911}\u{912}\x03\x02\x02\x02\u{912}\u{913}\x07\u{18e}\x02\
	\x02\u{913}\u{d5}\x03\x02\x02\x02\u{914}\u{915}\x05\u{d8}\x6d\x02\u{915}\
	\u{d7}\x03\x02\x02\x02\u{916}\u{917}\x08\x6d\x01\x02\u{917}\u{919}\x05\u{dc}\
	\x6f\x02\u{918}\u{91a}\x05\u{da}\x6e\x02\u{919}\u{918}\x03\x02\x02\x02\u{919}\
	\u{91a}\x03\x02\x02\x02\u{91a}\u{91e}\x03\x02\x02\x02\u{91b}\u{91c}\x07\
	\u{e1}\x02\x02\u{91c}\u{91e}\x05\u{d8}\x6d\x05\u{91d}\u{916}\x03\x02\x02\
	\x02\u{91d}\u{91b}\x03\x02\x02\x02\u{91e}\u{927}\x03\x02\x02\x02\u{91f}\
	\u{920}\x0c\x04\x02\x02\u{920}\u{921}\x07\x12\x02\x02\u{921}\u{926}\x05\
	\u{d8}\x6d\x05\u{922}\u{923}\x0c\x03\x02\x02\u{923}\u{924}\x07\u{ed}\x02\
	\x02\u{924}\u{926}\x05\u{d8}\x6d\x04\u{925}\u{91f}\x03\x02\x02\x02\u{925}\
	\u{922}\x03\x02\x02\x02\u{926}\u{929}\x03\x02\x02\x02\u{927}\u{925}\x03\
	\x02\x02\x02\u{927}\u{928}\x03\x02\x02\x02\u{928}\u{d9}\x03\x02\x02\x02\
	\u{929}\u{927}\x03\x02\x02\x02\u{92a}\u{92b}\x05\u{fc}\x7f\x02\u{92b}\u{92c}\
	\x05\u{dc}\x6f\x02\u{92c}\u{98c}\x03\x02\x02\x02\u{92d}\u{92e}\x05\u{fc}\
	\x7f\x02\u{92e}\u{92f}\x05\u{fe}\u{80}\x02\u{92f}\u{930}\x07\u{18d}\x02\
	\x02\u{930}\u{931}\x05\x1c\x0f\x02\u{931}\u{932}\x07\u{18e}\x02\x02\u{932}\
	\u{98c}\x03\x02\x02\x02\u{933}\u{935}\x07\u{e1}\x02\x02\u{934}\u{933}\x03\
	\x02\x02\x02\u{934}\u{935}\x03\x02\x02\x02\u{935}\u{936}\x03\x02\x02\x02\
	\u{936}\u{937}\x07\x1f\x02\x02\u{937}\u{938}\x05\u{dc}\x6f\x02\u{938}\u{939}\
	\x07\x12\x02\x02\u{939}\u{93a}\x05\u{dc}\x6f\x02\u{93a}\u{98c}\x03\x02\x02\
	\x02\u{93b}\u{93d}\x07\u{e1}\x02\x02\u{93c}\u{93b}\x03\x02\x02\x02\u{93c}\
	\u{93d}\x03\x02\x02\x02\u{93d}\u{93e}\x03\x02\x02\x02\u{93e}\u{93f}\x07\
	\u{99}\x02\x02\u{93f}\u{940}\x07\u{18d}\x02\x02\u{940}\u{945}\x05\u{d6}\
	\x6c\x02\u{941}\u{942}\x07\x34\x02\x02\u{942}\u{944}\x05\u{d6}\x6c\x02\u{943}\
	\u{941}\x03\x02\x02\x02\u{944}\u{947}\x03\x02\x02\x02\u{945}\u{943}\x03\
	\x02\x02\x02\u{945}\u{946}\x03\x02\x02\x02\u{946}\u{949}\x03\x02\x02\x02\
	\u{947}\u{945}\x03\x02\x02\x02\u{948}\u{94a}\x07\x34\x02\x02\u{949}\u{948}\
	\x03\x02\x02\x02\u{949}\u{94a}\x03\x02\x02\x02\u{94a}\u{94b}\x03\x02\x02\
	\x02\u{94b}\u{94c}\x07\u{18e}\x02\x02\u{94c}\u{98c}\x03\x02\x02\x02\u{94d}\
	\u{94f}\x07\u{e1}\x02\x02\u{94e}\u{94d}\x03\x02\x02\x02\u{94e}\u{94f}\x03\
	\x02\x02\x02\u{94f}\u{950}\x03\x02\x02\x02\u{950}\u{951}\x07\u{99}\x02\x02\
	\u{951}\u{952}\x07\u{16a}\x02\x02\u{952}\u{98c}\x05\u{dc}\x6f\x02\u{953}\
	\u{955}\x07\u{e1}\x02\x02\u{954}\u{953}\x03\x02\x02\x02\u{954}\u{955}\x03\
	\x02\x02\x02\u{955}\u{956}\x03\x02\x02\x02\u{956}\u{957}\x07\u{99}\x02\x02\
	\u{957}\u{958}\x07\u{18d}\x02\x02\u{958}\u{959}\x05\x1c\x0f\x02\u{959}\u{95a}\
	\x07\u{18e}\x02\x02\u{95a}\u{98c}\x03\x02\x02\x02\u{95b}\u{95d}\x07\u{e1}\
	\x02\x02\u{95c}\u{95b}\x03\x02\x02\x02\u{95c}\u{95d}\x03\x02\x02\x02\u{95d}\
	\u{95e}\x03\x02\x02\x02\u{95e}\u{95f}\x07\u{bb}\x02\x02\u{95f}\u{960}\x09\
	\x10\x02\x02\u{960}\u{961}\x07\u{18d}\x02\x02\u{961}\u{966}\x05\u{dc}\x6f\
	\x02\u{962}\u{963}\x07\x34\x02\x02\u{963}\u{965}\x05\u{dc}\x6f\x02\u{964}\
	\u{962}\x03\x02\x02\x02\u{965}\u{968}\x03\x02\x02\x02\u{966}\u{964}\x03\
	\x02\x02\x02\u{966}\u{967}\x03\x02\x02\x02\u{967}\u{969}\x03\x02\x02\x02\
	\u{968}\u{966}\x03\x02\x02\x02\u{969}\u{96a}\x07\u{18e}\x02\x02\u{96a}\u{98c}\
	\x03\x02\x02\x02\u{96b}\u{96d}\x07\u{e1}\x02\x02\u{96c}\u{96b}\x03\x02\x02\
	\x02\u{96c}\u{96d}\x03\x02\x02\x02\u{96d}\u{96e}\x03\x02\x02\x02\u{96e}\
	\u{96f}\x07\u{bb}\x02\x02\u{96f}\u{98c}\x05\u{dc}\x6f\x02\u{970}\u{972}\
	\x07\u{a7}\x02\x02\u{971}\u{973}\x07\u{e1}\x02\x02\u{972}\u{971}\x03\x02\
	\x02\x02\u{972}\u{973}\x03\x02\x02\x02\u{973}\u{974}\x03\x02\x02\x02\u{974}\
	\u{98c}\x07\u{e2}\x02\x02\u{975}\u{977}\x07\u{a7}\x02\x02\u{976}\u{978}\
	\x07\u{e1}\x02\x02\u{977}\u{976}\x03\x02\x02\x02\u{977}\u{978}\x03\x02\x02\
	\x02\u{978}\u{979}\x03\x02\x02\x02\u{979}\u{97a}\x07\x60\x02\x02\u{97a}\
	\u{97b}\x07\u{84}\x02\x02\u{97b}\u{98c}\x05\u{dc}\x6f\x02\u{97c}\u{97e}\
	\x07\u{a7}\x02\x02\u{97d}\u{97f}\x07\u{e1}\x02\x02\u{97e}\u{97d}\x03\x02\
	\x02\x02\u{97e}\u{97f}\x03\x02\x02\x02\u{97f}\u{980}\x03\x02\x02\x02\u{980}\
	\u{98c}\x07\u{15c}\x02\x02\u{981}\u{983}\x07\u{a7}\x02\x02\u{982}\u{984}\
	\x07\u{e1}\x02\x02\u{983}\u{982}\x03\x02\x02\x02\u{983}\u{984}\x03\x02\x02\
	\x02\u{984}\u{985}\x03\x02\x02\x02\u{985}\u{98c}\x07\x7a\x02\x02\u{986}\
	\u{988}\x07\u{a7}\x02\x02\u{987}\u{989}\x07\u{e1}\x02\x02\u{988}\u{987}\
	\x03\x02\x02\x02\u{988}\u{989}\x03\x02\x02\x02\u{989}\u{98a}\x03\x02\x02\
	\x02\u{98a}\u{98c}\x07\u{167}\x02\x02\u{98b}\u{92a}\x03\x02\x02\x02\u{98b}\
	\u{92d}\x03\x02\x02\x02\u{98b}\u{934}\x03\x02\x02\x02\u{98b}\u{93c}\x03\
	\x02\x02\x02\u{98b}\u{94e}\x03\x02\x02\x02\u{98b}\u{954}\x03\x02\x02\x02\
	\u{98b}\u{95c}\x03\x02\x02\x02\u{98b}\u{96c}\x03\x02\x02\x02\u{98b}\u{970}\
	\x03\x02\x02\x02\u{98b}\u{975}\x03\x02\x02\x02\u{98b}\u{97c}\x03\x02\x02\
	\x02\u{98b}\u{981}\x03\x02\x02\x02\u{98b}\u{986}\x03\x02\x02\x02\u{98c}\
	\u{db}\x03\x02\x02\x02\u{98d}\u{98e}\x08\x6f\x01\x02\u{98e}\u{992}\x05\u{de}\
	\x70\x02\u{98f}\u{990}\x09\x11\x02\x02\u{990}\u{992}\x05\u{dc}\x6f\x08\u{991}\
	\u{98d}\x03\x02\x02\x02\u{991}\u{98f}\x03\x02\x02\x02\u{992}\u{9a4}\x03\
	\x02\x02\x02\u{993}\u{994}\x0c\x07\x02\x02\u{994}\u{995}\x09\x12\x02\x02\
	\u{995}\u{9a3}\x05\u{dc}\x6f\x08\u{996}\u{997}\x0c\x06\x02\x02\u{997}\u{998}\
	\x09\x13\x02\x02\u{998}\u{9a3}\x05\u{dc}\x6f\x07\u{999}\u{99a}\x0c\x05\x02\
	\x02\u{99a}\u{99b}\x07\u{19d}\x02\x02\u{99b}\u{9a3}\x05\u{dc}\x6f\x06\u{99c}\
	\u{99d}\x0c\x04\x02\x02\u{99d}\u{99e}\x07\u{1a5}\x02\x02\u{99e}\u{9a3}\x05\
	\u{dc}\x6f\x05\u{99f}\u{9a0}\x0c\x03\x02\x02\u{9a0}\u{9a1}\x09\x14\x02\x02\
	\u{9a1}\u{9a3}\x05\u{dc}\x6f\x04\u{9a2}\u{993}\x03\x02\x02\x02\u{9a2}\u{996}\
	\x03\x02\x02\x02\u{9a2}\u{999}\x03\x02\x02\x02\u{9a2}\u{99c}\x03\x02\x02\
	\x02\u{9a2}\u{99f}\x03\x02\x02\x02\u{9a3}\u{9a6}\x03\x02\x02\x02\u{9a4}\
	\u{9a2}\x03\x02\x02\x02\u{9a4}\u{9a5}\x03\x02\x02\x02\u{9a5}\u{dd}\x03\x02\
	\x02\x02\u{9a6}\u{9a4}\x03\x02\x02\x02\u{9a7}\u{9a8}\x08\x70\x01\x02\u{9a8}\
	\u{acf}\x07\u{e2}\x02\x02\u{9a9}\u{acf}\x05\u{102}\u{82}\x02\u{9aa}\u{acf}\
	\x05\u{14e}\u{a8}\x02\u{9ab}\u{acf}\x05\u{100}\u{81}\x02\u{9ac}\u{acf}\x05\
	\u{fa}\x7e\x02\u{9ad}\u{acf}\x07\u{1ac}\x02\x02\u{9ae}\u{9af}\x05\u{144}\
	\u{a3}\x02\u{9af}\u{9b0}\x05\u{fa}\x7e\x02\u{9b0}\u{acf}\x03\x02\x02\x02\
	\u{9b1}\u{9b2}\x07\x66\x02\x02\u{9b2}\u{9b3}\x07\u{102}\x02\x02\u{9b3}\u{acf}\
	\x05\u{fa}\x7e\x02\u{9b4}\u{9b5}\x07\u{18d}\x02\x02\u{9b5}\u{9b8}\x05\u{d6}\
	\x6c\x02\u{9b6}\u{9b7}\x07\x34\x02\x02\u{9b7}\u{9b9}\x05\u{d6}\x6c\x02\u{9b8}\
	\u{9b6}\x03\x02\x02\x02\u{9b9}\u{9ba}\x03\x02\x02\x02\u{9ba}\u{9b8}\x03\
	\x02\x02\x02\u{9ba}\u{9bb}\x03\x02\x02\x02\u{9bb}\u{9bd}\x03\x02\x02\x02\
	\u{9bc}\u{9be}\x07\x34\x02\x02\u{9bd}\u{9bc}\x03\x02\x02\x02\u{9bd}\u{9be}\
	\x03\x02\x02\x02\u{9be}\u{9bf}\x03\x02\x02\x02\u{9bf}\u{9c0}\x07\u{18e}\
	\x02\x02\u{9c0}\u{acf}\x03\x02\x02\x02\u{9c1}\u{9cd}\x07\u{13f}\x02\x02\
	\u{9c2}\u{9c3}\x07\u{194}\x02\x02\u{9c3}\u{9c8}\x05\u{10e}\u{88}\x02\u{9c4}\
	\u{9c5}\x07\x34\x02\x02\u{9c5}\u{9c7}\x05\u{10e}\u{88}\x02\u{9c6}\u{9c4}\
	\x03\x02\x02\x02\u{9c7}\u{9ca}\x03\x02\x02\x02\u{9c8}\u{9c6}\x03\x02\x02\
	\x02\u{9c8}\u{9c9}\x03\x02\x02\x02\u{9c9}\u{9cb}\x03\x02\x02\x02\u{9ca}\
	\u{9c8}\x03\x02\x02\x02\u{9cb}\u{9cc}\x07\u{196}\x02\x02\u{9cc}\u{9ce}\x03\
	\x02\x02\x02\u{9cd}\u{9c2}\x03\x02\x02\x02\u{9cd}\u{9ce}\x03\x02\x02\x02\
	\u{9ce}\u{9cf}\x03\x02\x02\x02\u{9cf}\u{9d8}\x07\u{18d}\x02\x02\u{9d0}\u{9d5}\
	\x05\u{f4}\x7b\x02\u{9d1}\u{9d2}\x07\x34\x02\x02\u{9d2}\u{9d4}\x05\u{f4}\
	\x7b\x02\u{9d3}\u{9d1}\x03\x02\x02\x02\u{9d4}\u{9d7}\x03\x02\x02\x02\u{9d5}\
	\u{9d3}\x03\x02\x02\x02\u{9d5}\u{9d6}\x03\x02\x02\x02\u{9d6}\u{9d9}\x03\
	\x02\x02\x02\u{9d7}\u{9d5}\x03\x02\x02\x02\u{9d8}\u{9d0}\x03\x02\x02\x02\
	\u{9d8}\u{9d9}\x03\x02\x02\x02\u{9d9}\u{9da}\x03\x02\x02\x02\u{9da}\u{acf}\
	\x07\u{18e}\x02\x02\u{9db}\u{9dc}\x07\x76\x02\x02\u{9dc}\u{9dd}\x07\u{18d}\
	\x02\x02\u{9dd}\u{9de}\x05\x1c\x0f\x02\u{9de}\u{9df}\x07\u{18e}\x02\x02\
	\u{9df}\u{acf}\x03\x02\x02\x02\u{9e0}\u{9e1}\x07\x27\x02\x02\u{9e1}\u{9e3}\
	\x05\u{d6}\x6c\x02\u{9e2}\u{9e4}\x05\u{112}\u{8a}\x02\u{9e3}\u{9e2}\x03\
	\x02\x02\x02\u{9e4}\u{9e5}\x03\x02\x02\x02\u{9e5}\u{9e3}\x03\x02\x02\x02\
	\u{9e5}\u{9e6}\x03\x02\x02\x02\u{9e6}\u{9e9}\x03\x02\x02\x02\u{9e7}\u{9e8}\
	\x07\x68\x02\x02\u{9e8}\u{9ea}\x05\u{d6}\x6c\x02\u{9e9}\u{9e7}\x03\x02\x02\
	\x02\u{9e9}\u{9ea}\x03\x02\x02\x02\u{9ea}\u{9eb}\x03\x02\x02\x02\u{9eb}\
	\u{9ec}\x07\x6d\x02\x02\u{9ec}\u{acf}\x03\x02\x02\x02\u{9ed}\u{9ef}\x07\
	\x27\x02\x02\u{9ee}\u{9f0}\x05\u{112}\u{8a}\x02\u{9ef}\u{9ee}\x03\x02\x02\
	\x02\u{9f0}\u{9f1}\x03\x02\x02\x02\u{9f1}\u{9ef}\x03\x02\x02\x02\u{9f1}\
	\u{9f2}\x03\x02\x02\x02\u{9f2}\u{9f5}\x03\x02\x02\x02\u{9f3}\u{9f4}\x07\
	\x68\x02\x02\u{9f4}\u{9f6}\x05\u{d6}\x6c\x02\u{9f5}\u{9f3}\x03\x02\x02\x02\
	\u{9f5}\u{9f6}\x03\x02\x02\x02\u{9f6}\u{9f7}\x03\x02\x02\x02\u{9f7}\u{9f8}\
	\x07\x6d\x02\x02\u{9f8}\u{acf}\x03\x02\x02\x02\u{9f9}\u{9fa}\x07\x2a\x02\
	\x02\u{9fa}\u{9fb}\x07\u{18d}\x02\x02\u{9fb}\u{9fc}\x05\u{d6}\x6c\x02\u{9fc}\
	\u{9fd}\x07\x16\x02\x02\u{9fd}\u{a00}\x05\u{10a}\u{86}\x02\u{9fe}\u{9ff}\
	\x07\u{82}\x02\x02\u{9ff}\u{a01}\x05\u{fa}\x7e\x02\u{a00}\u{9fe}\x03\x02\
	\x02\x02\u{a00}\u{a01}\x03\x02\x02\x02\u{a01}\u{a02}\x03\x02\x02\x02\u{a02}\
	\u{a03}\x07\u{18e}\x02\x02\u{a03}\u{acf}\x03\x02\x02\x02\u{a04}\u{a05}\x07\
	\u{127}\x02\x02\u{a05}\u{a06}\x07\u{18d}\x02\x02\u{a06}\u{a07}\x05\u{d6}\
	\x6c\x02\u{a07}\u{a08}\x07\x16\x02\x02\u{a08}\u{a0b}\x05\u{10a}\u{86}\x02\
	\u{a09}\u{a0a}\x07\u{82}\x02\x02\u{a0a}\u{a0c}\x05\u{fa}\x7e\x02\u{a0b}\
	\u{a09}\x03\x02\x02\x02\u{a0b}\u{a0c}\x03\x02\x02\x02\u{a0c}\u{a0d}\x03\
	\x02\x02\x02\u{a0d}\u{a0e}\x07\u{18e}\x02\x02\u{a0e}\u{acf}\x03\x02\x02\
	\x02\u{a0f}\u{a10}\x07\u{15b}\x02\x02\u{a10}\u{a12}\x07\u{18d}\x02\x02\u{a11}\
	\u{a13}\x05\u{90}\x49\x02\u{a12}\u{a11}\x03\x02\x02\x02\u{a12}\u{a13}\x03\
	\x02\x02\x02\u{a13}\u{a15}\x03\x02\x02\x02\u{a14}\u{a16}\x05\u{dc}\x6f\x02\
	\u{a15}\u{a14}\x03\x02\x02\x02\u{a15}\u{a16}\x03\x02\x02\x02\u{a16}\u{a17}\
	\x03\x02\x02\x02\u{a17}\u{a18}\x07\u{84}\x02\x02\u{a18}\u{a19}\x03\x02\x02\
	\x02\u{a19}\u{a1a}\x05\u{dc}\x6f\x02\u{a1a}\u{a1b}\x07\u{18e}\x02\x02\u{a1b}\
	\u{acf}\x03\x02\x02\x02\u{a1c}\u{a1d}\x07\u{15b}\x02\x02\u{a1d}\u{a25}\x07\
	\u{18d}\x02\x02\u{a1e}\u{a20}\x05\u{90}\x49\x02\u{a1f}\u{a21}\x05\u{dc}\
	\x6f\x02\u{a20}\u{a1f}\x03\x02\x02\x02\u{a20}\u{a21}\x03\x02\x02\x02\u{a21}\
	\u{a23}\x03\x02\x02\x02\u{a22}\u{a24}\x07\u{84}\x02\x02\u{a23}\u{a22}\x03\
	\x02\x02\x02\u{a23}\u{a24}\x03\x02\x02\x02\u{a24}\u{a26}\x03\x02\x02\x02\
	\u{a25}\u{a1e}\x03\x02\x02\x02\u{a25}\u{a26}\x03\x02\x02\x02\u{a26}\u{a27}\
	\x03\x02\x02\x02\u{a27}\u{a28}\x05\u{dc}\x6f\x02\u{a28}\u{a29}\x07\u{18e}\
	\x02\x02\u{a29}\u{acf}\x03\x02\x02\x02\u{a2a}\u{a2b}\x07\u{15b}\x02\x02\
	\u{a2b}\u{a2c}\x07\u{18d}\x02\x02\u{a2c}\u{a2d}\x05\u{dc}\x6f\x02\u{a2d}\
	\u{a2e}\x07\x34\x02\x02\u{a2e}\u{a30}\x05\u{dc}\x6f\x02\u{a2f}\u{a31}\x07\
	\x34\x02\x02\u{a30}\u{a2f}\x03\x02\x02\x02\u{a30}\u{a31}\x03\x02\x02\x02\
	\u{a31}\u{a32}\x03\x02\x02\x02\u{a32}\u{a33}\x07\u{18e}\x02\x02\u{a33}\u{acf}\
	\x03\x02\x02\x02\u{a34}\u{a35}\x07\u{141}\x02\x02\u{a35}\u{a36}\x07\u{18d}\
	\x02\x02\u{a36}\u{a37}\x05\u{dc}\x6f\x02\u{a37}\u{a38}\x07\u{84}\x02\x02\
	\u{a38}\u{a3b}\x05\u{dc}\x6f\x02\u{a39}\u{a3a}\x07\u{81}\x02\x02\u{a3a}\
	\u{a3c}\x05\u{dc}\x6f\x02\u{a3b}\u{a39}\x03\x02\x02\x02\u{a3b}\u{a3c}\x03\
	\x02\x02\x02\u{a3c}\u{a3d}\x03\x02\x02\x02\u{a3d}\u{a3e}\x07\u{18e}\x02\
	\x02\u{a3e}\u{acf}\x03\x02\x02\x02\u{a3f}\u{a40}\x07\u{e0}\x02\x02\u{a40}\
	\u{a41}\x07\u{18d}\x02\x02\u{a41}\u{a44}\x05\u{dc}\x6f\x02\u{a42}\u{a43}\
	\x07\x34\x02\x02\u{a43}\u{a45}\x05\u{106}\u{84}\x02\u{a44}\u{a42}\x03\x02\
	\x02\x02\u{a44}\u{a45}\x03\x02\x02\x02\u{a45}\u{a47}\x03\x02\x02\x02\u{a46}\
	\u{a48}\x07\x34\x02\x02\u{a47}\u{a46}\x03\x02\x02\x02\u{a47}\u{a48}\x03\
	\x02\x02\x02\u{a48}\u{a49}\x03\x02\x02\x02\u{a49}\u{a4a}\x07\u{18e}\x02\
	\x02\u{a4a}\u{acf}\x03\x02\x02\x02\u{a4b}\u{a4c}\x07\x79\x02\x02\u{a4c}\
	\u{a4d}\x07\u{18d}\x02\x02\u{a4d}\u{a4e}\x05\u{ea}\x76\x02\u{a4e}\u{a4f}\
	\x07\u{84}\x02\x02\u{a4f}\u{a54}\x05\u{d6}\x6c\x02\u{a50}\u{a51}\x07\x18\
	\x02\x02\u{a51}\u{a52}\x07\u{150}\x02\x02\u{a52}\u{a53}\x07\u{18b}\x02\x02\
	\u{a53}\u{a55}\x05\u{fa}\x7e\x02\u{a54}\u{a50}\x03\x02\x02\x02\u{a54}\u{a55}\
	\x03\x02\x02\x02\u{a55}\u{a56}\x03\x02\x02\x02\u{a56}\u{a57}\x07\u{18e}\
	\x02\x02\u{a57}\u{acf}\x03\x02\x02\x02\u{a58}\u{a59}\x07\x30\x02\x02\u{a59}\
	\u{a5a}\x07\u{18d}\x02\x02\u{a5a}\u{a5f}\x05\u{e4}\x73\x02\u{a5b}\u{a5c}\
	\x07\x34\x02\x02\u{a5c}\u{a5e}\x05\u{e4}\x73\x02\u{a5d}\u{a5b}\x03\x02\x02\
	\x02\u{a5e}\u{a61}\x03\x02\x02\x02\u{a5f}\u{a5d}\x03\x02\x02\x02\u{a5f}\
	\u{a60}\x03\x02\x02\x02\u{a60}\u{a63}\x03\x02\x02\x02\u{a61}\u{a5f}\x03\
	\x02\x02\x02\u{a62}\u{a64}\x07\x34\x02\x02\u{a63}\u{a62}\x03\x02\x02\x02\
	\u{a63}\u{a64}\x03\x02\x02\x02\u{a64}\u{a65}\x03\x02\x02\x02\u{a65}\u{a66}\
	\x07\u{18e}\x02\x02\u{a66}\u{acf}\x03\x02\x02\x02\u{a67}\u{acf}\x05\u{e8}\
	\x75\x02\u{a68}\u{a69}\x07\x41\x02\x02\u{a69}\u{a6a}\x07\u{18d}\x02\x02\
	\u{a6a}\u{a6b}\x07\u{19a}\x02\x02\u{a6b}\u{a6c}\x07\u{18e}\x02\x02\u{a6c}\
	\u{acf}\x05\u{e2}\x72\x02\u{a6d}\u{a6e}\x05\u{e0}\x71\x02\u{a6e}\u{a6f}\
	\x05\u{ec}\x77\x02\u{a6f}\u{a7b}\x07\u{18d}\x02\x02\u{a70}\u{a72}\x05\x56\
	\x2c\x02\u{a71}\u{a70}\x03\x02\x02\x02\u{a71}\u{a72}\x03\x02\x02\x02\u{a72}\
	\u{a73}\x03\x02\x02\x02\u{a73}\u{a78}\x05\u{e4}\x73\x02\u{a74}\u{a75}\x07\
	\x34\x02\x02\u{a75}\u{a77}\x05\u{e4}\x73\x02\u{a76}\u{a74}\x03\x02\x02\x02\
	\u{a77}\u{a7a}\x03\x02\x02\x02\u{a78}\u{a76}\x03\x02\x02\x02\u{a78}\u{a79}\
	\x03\x02\x02\x02\u{a79}\u{a7c}\x03\x02\x02\x02\u{a7a}\u{a78}\x03\x02\x02\
	\x02\u{a7b}\u{a71}\x03\x02\x02\x02\u{a7b}\u{a7c}\x03\x02\x02\x02\u{a7c}\
	\u{a7d}\x03\x02\x02\x02\u{a7d}\u{a7e}\x05\u{e6}\x74\x02\u{a7e}\u{a7f}\x03\
	\x02\x02\x02\u{a7f}\u{a80}\x07\u{18e}\x02\x02\u{a80}\u{a81}\x05\u{e2}\x72\
	\x02\u{a81}\u{acf}\x03\x02\x02\x02\u{a82}\u{a83}\x05\u{144}\u{a3}\x02\u{a83}\
	\u{a84}\x05\u{11c}\u{8f}\x02\u{a84}\u{acf}\x03\x02\x02\x02\u{a85}\u{a86}\
	\x05\u{144}\u{a3}\x02\u{a86}\u{a87}\x07\x05\x02\x02\u{a87}\u{a88}\x05\u{d6}\
	\x6c\x02\u{a88}\u{acf}\x03\x02\x02\x02\u{a89}\u{a92}\x07\u{18d}\x02\x02\
	\u{a8a}\u{a8f}\x05\u{144}\u{a3}\x02\u{a8b}\u{a8c}\x07\x34\x02\x02\u{a8c}\
	\u{a8e}\x05\u{144}\u{a3}\x02\u{a8d}\u{a8b}\x03\x02\x02\x02\u{a8e}\u{a91}\
	\x03\x02\x02\x02\u{a8f}\u{a8d}\x03\x02\x02\x02\u{a8f}\u{a90}\x03\x02\x02\
	\x02\u{a90}\u{a93}\x03\x02\x02\x02\u{a91}\u{a8f}\x03\x02\x02\x02\u{a92}\
	\u{a8a}\x03\x02\x02\x02\u{a92}\u{a93}\x03\x02\x02\x02\u{a93}\u{a95}\x03\
	\x02\x02\x02\u{a94}\u{a96}\x07\x34\x02\x02\u{a95}\u{a94}\x03\x02\x02\x02\
	\u{a95}\u{a96}\x03\x02\x02\x02\u{a96}\u{a97}\x03\x02\x02\x02\u{a97}\u{a98}\
	\x07\u{18e}\x02\x02\u{a98}\u{a99}\x07\x05\x02\x02\u{a99}\u{acf}\x05\u{d6}\
	\x6c\x02\u{a9a}\u{a9b}\x07\u{18d}\x02\x02\u{a9b}\u{a9c}\x05\x1c\x0f\x02\
	\u{a9c}\u{a9d}\x07\u{18e}\x02\x02\u{a9d}\u{acf}\x03\x02\x02\x02\u{a9e}\u{aa3}\
	\x07\x15\x02\x02\u{a9f}\u{aa0}\x07\u{194}\x02\x02\u{aa0}\u{aa1}\x05\u{10a}\
	\u{86}\x02\u{aa1}\u{aa2}\x07\u{196}\x02\x02\u{aa2}\u{aa4}\x03\x02\x02\x02\
	\u{aa3}\u{a9f}\x03\x02\x02\x02\u{aa3}\u{aa4}\x03\x02\x02\x02\u{aa4}\u{aa5}\
	\x03\x02\x02\x02\u{aa5}\u{aae}\x07\u{18f}\x02\x02\u{aa6}\u{aab}\x05\u{d6}\
	\x6c\x02\u{aa7}\u{aa8}\x07\x34\x02\x02\u{aa8}\u{aaa}\x05\u{d6}\x6c\x02\u{aa9}\
	\u{aa7}\x03\x02\x02\x02\u{aaa}\u{aad}\x03\x02\x02\x02\u{aab}\u{aa9}\x03\
	\x02\x02\x02\u{aab}\u{aac}\x03\x02\x02\x02\u{aac}\u{aaf}\x03\x02\x02\x02\
	\u{aad}\u{aab}\x03\x02\x02\x02\u{aae}\u{aa6}\x03\x02\x02\x02\u{aae}\u{aaf}\
	\x03\x02\x02\x02\u{aaf}\u{ab1}\x03\x02\x02\x02\u{ab0}\u{ab2}\x07\x34\x02\
	\x02\u{ab1}\u{ab0}\x03\x02\x02\x02\u{ab1}\u{ab2}\x03\x02\x02\x02\u{ab2}\
	\u{ab3}\x03\x02\x02\x02\u{ab3}\u{acf}\x07\u{190}\x02\x02\u{ab4}\u{acf}\x05\
	\x26\x14\x02\u{ab5}\u{ab6}\x07\u{18d}\x02\x02\u{ab6}\u{ab7}\x05\u{d6}\x6c\
	\x02\u{ab7}\u{ab8}\x07\u{18e}\x02\x02\u{ab8}\u{acf}\x03\x02\x02\x02\u{ab9}\
	\u{ac5}\x07\u{18f}\x02\x02\u{aba}\u{abf}\x05\u{d6}\x6c\x02\u{abb}\u{abc}\
	\x07\x34\x02\x02\u{abc}\u{abe}\x05\u{d6}\x6c\x02\u{abd}\u{abb}\x03\x02\x02\
	\x02\u{abe}\u{ac1}\x03\x02\x02\x02\u{abf}\u{abd}\x03\x02\x02\x02\u{abf}\
	\u{ac0}\x03\x02\x02\x02\u{ac0}\u{ac3}\x03\x02\x02\x02\u{ac1}\u{abf}\x03\
	\x02\x02\x02\u{ac2}\u{ac4}\x07\x34\x02\x02\u{ac3}\u{ac2}\x03\x02\x02\x02\
	\u{ac3}\u{ac4}\x03\x02\x02\x02\u{ac4}\u{ac6}\x03\x02\x02\x02\u{ac5}\u{aba}\
	\x03\x02\x02\x02\u{ac5}\u{ac6}\x03\x02\x02\x02\u{ac6}\u{ac7}\x03\x02\x02\
	\x02\u{ac7}\u{acf}\x07\u{190}\x02\x02\u{ac8}\u{acf}\x07\u{1b3}\x02\x02\u{ac9}\
	\u{aca}\x07\x15\x02\x02\u{aca}\u{acb}\x07\u{18d}\x02\x02\u{acb}\u{acc}\x05\
	\x1c\x0f\x02\u{acc}\u{acd}\x07\u{18e}\x02\x02\u{acd}\u{acf}\x03\x02\x02\
	\x02\u{ace}\u{9a7}\x03\x02\x02\x02\u{ace}\u{9a9}\x03\x02\x02\x02\u{ace}\
	\u{9aa}\x03\x02\x02\x02\u{ace}\u{9ab}\x03\x02\x02\x02\u{ace}\u{9ac}\x03\
	\x02\x02\x02\u{ace}\u{9ad}\x03\x02\x02\x02\u{ace}\u{9ae}\x03\x02\x02\x02\
	\u{ace}\u{9b1}\x03\x02\x02\x02\u{ace}\u{9b4}\x03\x02\x02\x02\u{ace}\u{9c1}\
	\x03\x02\x02\x02\u{ace}\u{9db}\x03\x02\x02\x02\u{ace}\u{9e0}\x03\x02\x02\
	\x02\u{ace}\u{9ed}\x03\x02\x02\x02\u{ace}\u{9f9}\x03\x02\x02\x02\u{ace}\
	\u{a04}\x03\x02\x02\x02\u{ace}\u{a0f}\x03\x02\x02\x02\u{ace}\u{a1c}\x03\
	\x02\x02\x02\u{ace}\u{a2a}\x03\x02\x02\x02\u{ace}\u{a34}\x03\x02\x02\x02\
	\u{ace}\u{a3f}\x03\x02\x02\x02\u{ace}\u{a4b}\x03\x02\x02\x02\u{ace}\u{a58}\
	\x03\x02\x02\x02\u{ace}\u{a67}\x03\x02\x02\x02\u{ace}\u{a68}\x03\x02\x02\
	\x02\u{ace}\u{a6d}\x03\x02\x02\x02\u{ace}\u{a82}\x03\x02\x02\x02\u{ace}\
	\u{a85}\x03\x02\x02\x02\u{ace}\u{a89}\x03\x02\x02\x02\u{ace}\u{a9a}\x03\
	\x02\x02\x02\u{ace}\u{a9e}\x03\x02\x02\x02\u{ace}\u{ab4}\x03\x02\x02\x02\
	\u{ace}\u{ab5}\x03\x02\x02\x02\u{ace}\u{ab9}\x03\x02\x02\x02\u{ace}\u{ac8}\
	\x03\x02\x02\x02\u{ace}\u{ac9}\x03\x02\x02\x02\u{acf}\u{ada}\x03\x02\x02\
	\x02\u{ad0}\u{ad1}\x0c\x09\x02\x02\u{ad1}\u{ad2}\x07\u{18f}\x02\x02\u{ad2}\
	\u{ad3}\x05\u{dc}\x6f\x02\u{ad3}\u{ad4}\x07\u{190}\x02\x02\u{ad4}\u{ad9}\
	\x03\x02\x02\x02\u{ad5}\u{ad6}\x0c\x08\x02\x02\u{ad6}\u{ad7}\x07\u{191}\
	\x02\x02\u{ad7}\u{ad9}\x05\x28\x15\x02\u{ad8}\u{ad0}\x03\x02\x02\x02\u{ad8}\
	\u{ad5}\x03\x02\x02\x02\u{ad9}\u{adc}\x03\x02\x02\x02\u{ada}\u{ad8}\x03\
	\x02\x02\x02\u{ada}\u{adb}\x03\x02\x02\x02\u{adb}\u{df}\x03\x02\x02\x02\
	\u{adc}\u{ada}\x03\x02\x02\x02\u{add}\u{ade}\x07\u{126}\x02\x02\u{ade}\u{ae0}\
	\x07\u{191}\x02\x02\u{adf}\u{add}\x03\x02\x02\x02\u{adf}\u{ae0}\x03\x02\
	\x02\x02\u{ae0}\u{e1}\x03\x02\x02\x02\u{ae1}\u{ae3}\x05\u{11c}\u{8f}\x02\
	\u{ae2}\u{ae1}\x03\x02\x02\x02\u{ae2}\u{ae3}\x03\x02\x02\x02\u{ae3}\u{e3}\
	\x03\x02\x02\x02\u{ae4}\u{aea}\x05\u{d6}\x6c\x02\u{ae5}\u{ae6}\x05\u{144}\
	\u{a3}\x02\u{ae6}\u{ae7}\x07\x04\x02\x02\u{ae7}\u{ae8}\x05\u{d6}\x6c\x02\
	\u{ae8}\u{aea}\x03\x02\x02\x02\u{ae9}\u{ae4}\x03\x02\x02\x02\u{ae9}\u{ae5}\
	\x03\x02\x02\x02\u{aea}\u{e5}\x03\x02\x02\x02\u{aeb}\u{aed}\x05\u{f8}\x7d\
	\x02\u{aec}\u{aeb}\x03\x02\x02\x02\u{aec}\u{aed}\x03\x02\x02\x02\u{aed}\
	\u{aef}\x03\x02\x02\x02\u{aee}\u{af0}\x05\u{ee}\x78\x02\u{aef}\u{aee}\x03\
	\x02\x02\x02\u{aef}\u{af0}\x03\x02\x02\x02\u{af0}\u{afb}\x03\x02\x02\x02\
	\u{af1}\u{af2}\x07\u{ee}\x02\x02\u{af2}\u{af3}\x07\x22\x02\x02\u{af3}\u{af8}\
	\x05\x5c\x2f\x02\u{af4}\u{af5}\x07\x34\x02\x02\u{af5}\u{af7}\x05\x5c\x2f\
	\x02\u{af6}\u{af4}\x03\x02\x02\x02\u{af7}\u{afa}\x03\x02\x02\x02\u{af8}\
	\u{af6}\x03\x02\x02\x02\u{af8}\u{af9}\x03\x02\x02\x02\u{af9}\u{afc}\x03\
	\x02\x02\x02\u{afa}\u{af8}\x03\x02\x02\x02\u{afb}\u{af1}\x03\x02\x02\x02\
	\u{afb}\u{afc}\x03\x02\x02\x02\u{afc}\u{afe}\x03\x02\x02\x02\u{afd}\u{aff}\
	\x05\u{f0}\x79\x02\u{afe}\u{afd}\x03\x02\x02\x02\u{afe}\u{aff}\x03\x02\x02\
	\x02\u{aff}\u{e7}\x03\x02\x02\x02\u{b00}\u{b01}\x09\x15\x02\x02\u{b01}\u{b02}\
	\x07\u{18d}\x02\x02\u{b02}\u{b03}\x05\u{d6}\x6c\x02\u{b03}\u{b04}\x07\x34\
	\x02\x02\u{b04}\u{b05}\x05\u{d6}\x6c\x02\u{b05}\u{b06}\x07\x34\x02\x02\u{b06}\
	\u{b07}\x05\u{ea}\x76\x02\u{b07}\u{b08}\x07\u{18e}\x02\x02\u{b08}\u{e9}\
	\x03\x02\x02\x02\u{b09}\u{b20}\x07\u{cf}\x02\x02\u{b0a}\u{b20}\x07\u{d0}\
	\x02\x02\u{b0b}\u{b20}\x07\u{12a}\x02\x02\u{b0c}\u{b20}\x07\u{d3}\x02\x02\
	\u{b0d}\u{b20}\x07\u{94}\x02\x02\u{b0e}\u{b20}\x07\x4d\x02\x02\u{b0f}\u{b20}\
	\x07\x4e\x02\x02\u{b10}\u{b20}\x07\x4f\x02\x02\u{b11}\u{b15}\x07\u{17e}\
	\x02\x02\u{b12}\u{b13}\x07\u{18d}\x02\x02\u{b13}\u{b14}\x09\x16\x02\x02\
	\u{b14}\u{b16}\x07\u{18e}\x02\x02\u{b15}\u{b12}\x03\x02\x02\x02\u{b15}\u{b16}\
	\x03\x02\x02\x02\u{b16}\u{b20}\x03\x02\x02\x02\u{b17}\u{b20}\x07\u{a9}\x02\
	\x02\u{b18}\u{b20}\x07\u{d6}\x02\x02\u{b19}\u{b20}\x07\u{10a}\x02\x02\u{b1a}\
	\u{b20}\x07\u{189}\x02\x02\u{b1b}\u{b20}\x07\u{aa}\x02\x02\u{b1c}\u{b20}\
	\x07\x4c\x02\x02\u{b1d}\u{b20}\x07\x4b\x02\x02\u{b1e}\u{b20}\x07\u{150}\
	\x02\x02\u{b1f}\u{b09}\x03\x02\x02\x02\u{b1f}\u{b0a}\x03\x02\x02\x02\u{b1f}\
	\u{b0b}\x03\x02\x02\x02\u{b1f}\u{b0c}\x03\x02\x02\x02\u{b1f}\u{b0d}\x03\
	\x02\x02\x02\u{b1f}\u{b0e}\x03\x02\x02\x02\u{b1f}\u{b0f}\x03\x02\x02\x02\
	\u{b1f}\u{b10}\x03\x02\x02\x02\u{b1f}\u{b11}\x03\x02\x02\x02\u{b1f}\u{b17}\
	\x03\x02\x02\x02\u{b1f}\u{b18}\x03\x02\x02\x02\u{b1f}\u{b19}\x03\x02\x02\
	\x02\u{b1f}\u{b1a}\x03\x02\x02\x02\u{b1f}\u{b1b}\x03\x02\x02\x02\u{b1f}\
	\u{b1c}\x03\x02\x02\x02\u{b1f}\u{b1d}\x03\x02\x02\x02\u{b1f}\u{b1e}\x03\
	\x02\x02\x02\u{b20}\u{eb}\x03\x02\x02\x02\u{b21}\u{b28}\x05\u{130}\u{99}\
	\x02\u{b22}\u{b28}\x07\u{b8}\x02\x02\u{b23}\u{b28}\x07\u{11d}\x02\x02\u{b24}\
	\u{b28}\x07\u{96}\x02\x02\u{b25}\u{b28}\x07\u{113}\x02\x02\u{b26}\u{b28}\
	\x07\u{8f}\x02\x02\u{b27}\u{b21}\x03\x02\x02\x02\u{b27}\u{b22}\x03\x02\x02\
	\x02\u{b27}\u{b23}\x03\x02\x02\x02\u{b27}\u{b24}\x03\x02\x02\x02\u{b27}\
	\u{b25}\x03\x02\x02\x02\u{b27}\u{b26}\x03\x02\x02\x02\u{b28}\u{ed}\x03\x02\
	\x02\x02\u{b29}\u{b2a}\x07\u{92}\x02\x02\u{b2a}\u{b2b}\x09\x17\x02\x02\u{b2b}\
	\u{b2c}\x05\u{d6}\x6c\x02\u{b2c}\u{ef}\x03\x02\x02\x02\u{b2d}\u{b2e}\x07\
	\u{bc}\x02\x02\u{b2e}\u{b2f}\x05\x48\x25\x02\u{b2f}\u{f1}\x03\x02\x02\x02\
	\u{b30}\u{b34}\x05\u{144}\u{a3}\x02\u{b31}\u{b35}\x05\u{10a}\u{86}\x02\u{b32}\
	\u{b33}\x07\x14\x02\x02\u{b33}\u{b35}\x07\u{161}\x02\x02\u{b34}\u{b31}\x03\
	\x02\x02\x02\u{b34}\u{b32}\x03\x02\x02\x02\u{b35}\u{f3}\x03\x02\x02\x02\
	\u{b36}\u{b39}\x05\u{d6}\x6c\x02\u{b37}\u{b38}\x07\x16\x02\x02\u{b38}\u{b3a}\
	\x05\u{144}\u{a3}\x02\u{b39}\u{b37}\x03\x02\x02\x02\u{b39}\u{b3a}\x03\x02\
	\x02\x02\u{b3a}\u{f5}\x03\x02\x02\x02\u{b3b}\u{b3c}\x09\x18\x02\x02\u{b3c}\
	\u{f7}\x03\x02\x02\x02\u{b3d}\u{b3e}\x07\u{97}\x02\x02\u{b3e}\u{b42}\x07\
	\u{e3}\x02\x02\u{b3f}\u{b40}\x07\u{115}\x02\x02\u{b40}\u{b42}\x07\u{e3}\
	\x02\x02\u{b41}\u{b3d}\x03\x02\x02\x02\u{b41}\u{b3f}\x03\x02\x02\x02\u{b42}\
	\u{f9}\x03\x02\x02\x02\u{b43}\u{b48}\x07\u{1a8}\x02\x02\u{b44}\u{b48}\x07\
	\u{1a9}\x02\x02\u{b45}\u{b48}\x07\u{1aa}\x02\x02\u{b46}\u{b48}\x07\u{1ab}\
	\x02\x02\u{b47}\u{b43}\x03\x02\x02\x02\u{b47}\u{b44}\x03\x02\x02\x02\u{b47}\
	\u{b45}\x03\x02\x02\x02\u{b47}\u{b46}\x03\x02\x02\x02\u{b48}\u{fb}\x03\x02\
	\x02\x02\u{b49}\u{b4a}\x09\x19\x02\x02\u{b4a}\u{fd}\x03\x02\x02\x02\u{b4b}\
	\u{b4c}\x09\x10\x02\x02\u{b4c}\u{ff}\x03\x02\x02\x02\u{b4d}\u{b4e}\x09\x1a\
	\x02\x02\u{b4e}\u{101}\x03\x02\x02\x02\u{b4f}\u{b50}\x07\u{a3}\x02\x02\u{b50}\
	\u{b51}\x05\u{d6}\x6c\x02\u{b51}\u{b54}\x05\u{104}\u{83}\x02\u{b52}\u{b53}\
	\x07\u{153}\x02\x02\u{b53}\u{b55}\x05\u{104}\u{83}\x02\u{b54}\u{b52}\x03\
	\x02\x02\x02\u{b54}\u{b55}\x03\x02\x02\x02\u{b55}\u{103}\x03\x02\x02\x02\
	\u{b56}\u{b57}\x09\x1b\x02\x02\u{b57}\u{105}\x03\x02\x02\x02\u{b58}\u{b59}\
	\x09\x1c\x02\x02\u{b59}\u{107}\x03\x02\x02\x02\u{b5a}\u{b5b}\x05\u{144}\
	\u{a3}\x02\u{b5b}\u{109}\x03\x02\x02\x02\u{b5c}\u{b5f}\x05\u{10c}\u{87}\
	\x02\u{b5d}\u{b5e}\x07\u{e1}\x02\x02\u{b5e}\u{b60}\x07\u{e2}\x02\x02\u{b5f}\
	\u{b5d}\x03\x02\x02\x02\u{b5f}\u{b60}\x03\x02\x02\x02\u{b60}\u{b63}\x03\
	\x02\x02\x02\u{b61}\u{b63}\x07\u{e2}\x02\x02\u{b62}\u{b5c}\x03\x02\x02\x02\
	\u{b62}\u{b61}\x03\x02\x02\x02\u{b63}\u{10b}\x03\x02\x02\x02\u{b64}\u{b65}\
	\x08\u{87}\x01\x02\u{b65}\u{b66}\x07\u{1a1}\x02\x02\u{b66}\u{b8e}\x07\u{1ad}\
	\x02\x02\u{b67}\u{b68}\x07\x15\x02\x02\u{b68}\u{b69}\x07\u{194}\x02\x02\
	\u{b69}\u{b6a}\x05\u{10a}\u{86}\x02\u{b6a}\u{b6b}\x07\u{196}\x02\x02\u{b6b}\
	\u{b8e}\x03\x02\x02\x02\u{b6c}\u{b6d}\x07\u{13f}\x02\x02\u{b6d}\u{b6e}\x07\
	\u{194}\x02\x02\u{b6e}\u{b73}\x05\u{10e}\u{88}\x02\u{b6f}\u{b70}\x07\x34\
	\x02\x02\u{b70}\u{b72}\x05\u{10e}\u{88}\x02\u{b71}\u{b6f}\x03\x02\x02\x02\
	\u{b72}\u{b75}\x03\x02\x02\x02\u{b73}\u{b71}\x03\x02\x02\x02\u{b73}\u{b74}\
	\x03\x02\x02\x02\u{b74}\u{b77}\x03\x02\x02\x02\u{b75}\u{b73}\x03\x02\x02\
	\x02\u{b76}\u{b78}\x07\x34\x02\x02\u{b77}\u{b76}\x03\x02\x02\x02\u{b77}\
	\u{b78}\x03\x02\x02\x02\u{b78}\u{b79}\x03\x02\x02\x02\u{b79}\u{b7a}\x07\
	\u{196}\x02\x02\u{b7a}\u{b8e}\x03\x02\x02\x02\u{b7b}\u{b8e}\x07\u{a3}\x02\
	\x02\u{b7c}\u{b8b}\x05\u{108}\u{85}\x02\u{b7d}\u{b7e}\x07\u{18d}\x02\x02\
	\u{b7e}\u{b83}\x05\u{110}\u{89}\x02\u{b7f}\u{b80}\x07\x34\x02\x02\u{b80}\
	\u{b82}\x05\u{110}\u{89}\x02\u{b81}\u{b7f}\x03\x02\x02\x02\u{b82}\u{b85}\
	\x03\x02\x02\x02\u{b83}\u{b81}\x03\x02\x02\x02\u{b83}\u{b84}\x03\x02\x02\
	\x02\u{b84}\u{b87}\x03\x02\x02\x02\u{b85}\u{b83}\x03\x02\x02\x02\u{b86}\
	\u{b88}\x07\x34\x02\x02\u{b87}\u{b86}\x03\x02\x02\x02\u{b87}\u{b88}\x03\
	\x02\x02\x02\u{b88}\u{b89}\x03\x02\x02\x02\u{b89}\u{b8a}\x07\u{18e}\x02\
	\x02\u{b8a}\u{b8c}\x03\x02\x02\x02\u{b8b}\u{b7d}\x03\x02\x02\x02\u{b8b}\
	\u{b8c}\x03\x02\x02\x02\u{b8c}\u{b8e}\x03\x02\x02\x02\u{b8d}\u{b64}\x03\
	\x02\x02\x02\u{b8d}\u{b67}\x03\x02\x02\x02\u{b8d}\u{b6c}\x03\x02\x02\x02\
	\u{b8d}\u{b7b}\x03\x02\x02\x02\u{b8d}\u{b7c}\x03\x02\x02\x02\u{b8e}\u{b94}\
	\x03\x02\x02\x02\u{b8f}\u{b90}\x0c\x04\x02\x02\u{b90}\u{b91}\x07\x31\x02\
	\x02\u{b91}\u{b93}\x05\u{fa}\x7e\x02\u{b92}\u{b8f}\x03\x02\x02\x02\u{b93}\
	\u{b96}\x03\x02\x02\x02\u{b94}\u{b92}\x03\x02\x02\x02\u{b94}\u{b95}\x03\
	\x02\x02\x02\u{b95}\u{10d}\x03\x02\x02\x02\u{b96}\u{b94}\x03\x02\x02\x02\
	\u{b97}\u{b9c}\x05\u{10a}\u{86}\x02\u{b98}\u{b99}\x05\u{144}\u{a3}\x02\u{b99}\
	\u{b9a}\x05\u{10a}\u{86}\x02\u{b9a}\u{b9c}\x03\x02\x02\x02\u{b9b}\u{b97}\
	\x03\x02\x02\x02\u{b9b}\u{b98}\x03\x02\x02\x02\u{b9c}\u{10f}\x03\x02\x02\
	\x02\u{b9d}\u{ba0}\x07\u{1ad}\x02\x02\u{b9e}\u{ba0}\x05\u{10a}\u{86}\x02\
	\u{b9f}\u{b9d}\x03\x02\x02\x02\u{b9f}\u{b9e}\x03\x02\x02\x02\u{ba0}\u{111}\
	\x03\x02\x02\x02\u{ba1}\u{ba2}\x07\u{17f}\x02\x02\u{ba2}\u{ba3}\x05\u{d6}\
	\x6c\x02\u{ba3}\u{ba4}\x07\u{14d}\x02\x02\u{ba4}\u{ba5}\x05\u{d6}\x6c\x02\
	\u{ba5}\u{113}\x03\x02\x02\x02\u{ba6}\u{ba7}\x07\x7d\x02\x02\u{ba7}\u{ba8}\
	\x07\u{18d}\x02\x02\u{ba8}\u{ba9}\x07\u{180}\x02\x02\u{ba9}\u{baa}\x05\u{d8}\
	\x6d\x02\u{baa}\u{bab}\x07\u{18e}\x02\x02\u{bab}\u{115}\x03\x02\x02\x02\
	\u{bac}\u{bad}\x07\u{17f}\x02\x02\u{bad}\u{bb0}\x07\u{c7}\x02\x02\u{bae}\
	\u{baf}\x07\x12\x02\x02\u{baf}\u{bb1}\x05\u{d8}\x6d\x02\u{bb0}\u{bae}\x03\
	\x02\x02\x02\u{bb0}\u{bb1}\x03\x02\x02\x02\u{bb1}\u{bb2}\x03\x02\x02\x02\
	\u{bb2}\u{bb5}\x07\u{14d}\x02\x02\u{bb3}\u{bb6}\x05\u{118}\u{8d}\x02\u{bb4}\
	\u{bb6}\x07\x58\x02\x02\u{bb5}\u{bb3}\x03\x02\x02\x02\u{bb5}\u{bb4}\x03\
	\x02\x02\x02\u{bb6}\u{bd6}\x03\x02\x02\x02\u{bb7}\u{bb8}\x07\u{17f}\x02\
	\x02\u{bb8}\u{bb9}\x07\u{e1}\x02\x02\u{bb9}\u{bbc}\x07\u{c7}\x02\x02\u{bba}\
	\u{bbb}\x07\x22\x02\x02\u{bbb}\u{bbd}\x07\u{156}\x02\x02\u{bbc}\u{bba}\x03\
	\x02\x02\x02\u{bbc}\u{bbd}\x03\x02\x02\x02\u{bbd}\u{bc0}\x03\x02\x02\x02\
	\u{bbe}\u{bbf}\x07\x12\x02\x02\u{bbf}\u{bc1}\x05\u{d8}\x6d\x02\u{bc0}\u{bbe}\
	\x03\x02\x02\x02\u{bc0}\u{bc1}\x03\x02\x02\x02\u{bc1}\u{bc2}\x03\x02\x02\
	\x02\u{bc2}\u{bc5}\x07\u{14d}\x02\x02\u{bc3}\u{bc6}\x05\u{11a}\u{8e}\x02\
	\u{bc4}\u{bc6}\x07\x58\x02\x02\u{bc5}\u{bc3}\x03\x02\x02\x02\u{bc5}\u{bc4}\
	\x03\x02\x02\x02\u{bc6}\u{bd6}\x03\x02\x02\x02\u{bc7}\u{bc8}\x07\u{17f}\
	\x02\x02\u{bc8}\u{bc9}\x07\u{e1}\x02\x02\u{bc9}\u{bca}\x07\u{c7}\x02\x02\
	\u{bca}\u{bcb}\x07\x22\x02\x02\u{bcb}\u{bce}\x07\u{157}\x02\x02\u{bcc}\u{bcd}\
	\x07\x12\x02\x02\u{bcd}\u{bcf}\x05\u{d8}\x6d\x02\u{bce}\u{bcc}\x03\x02\x02\
	\x02\u{bce}\u{bcf}\x03\x02\x02\x02\u{bcf}\u{bd0}\x03\x02\x02\x02\u{bd0}\
	\u{bd3}\x07\u{14d}\x02\x02\u{bd1}\u{bd4}\x05\u{118}\u{8d}\x02\u{bd2}\u{bd4}\
	\x07\x58\x02\x02\u{bd3}\u{bd1}\x03\x02\x02\x02\u{bd3}\u{bd2}\x03\x02\x02\
	\x02\u{bd4}\u{bd6}\x03\x02\x02\x02\u{bd5}\u{bac}\x03\x02\x02\x02\u{bd5}\
	\u{bb7}\x03\x02\x02\x02\u{bd5}\u{bc7}\x03\x02\x02\x02\u{bd6}\u{117}\x03\
	\x02\x02\x02\u{bd7}\u{bd8}\x07\u{16e}\x02\x02\u{bd8}\u{bd9}\x07\u{135}\x02\
	\x02\u{bd9}\u{bda}\x05\u{d6}\x6c\x02\u{bda}\u{bdb}\x07\u{192}\x02\x02\u{bdb}\
	\u{be3}\x05\u{d6}\x6c\x02\u{bdc}\u{bdd}\x07\x34\x02\x02\u{bdd}\u{bde}\x05\
	\u{d6}\x6c\x02\u{bde}\u{bdf}\x07\u{192}\x02\x02\u{bdf}\u{be0}\x05\u{d6}\
	\x6c\x02\u{be0}\u{be2}\x03\x02\x02\x02\u{be1}\u{bdc}\x03\x02\x02\x02\u{be2}\
	\u{be5}\x03\x02\x02\x02\u{be3}\u{be1}\x03\x02\x02\x02\u{be3}\u{be4}\x03\
	\x02\x02\x02\u{be4}\u{119}\x03\x02\x02\x02\u{be5}\u{be3}\x03\x02\x02\x02\
	\u{be6}\u{bf5}\x07\u{a1}\x02\x02\u{be7}\u{be8}\x07\u{18d}\x02\x02\u{be8}\
	\u{bed}\x05\u{d6}\x6c\x02\u{be9}\u{bea}\x07\x34\x02\x02\u{bea}\u{bec}\x05\
	\u{d6}\x6c\x02\u{beb}\u{be9}\x03\x02\x02\x02\u{bec}\u{bef}\x03\x02\x02\x02\
	\u{bed}\u{beb}\x03\x02\x02\x02\u{bed}\u{bee}\x03\x02\x02\x02\u{bee}\u{bf1}\
	\x03\x02\x02\x02\u{bef}\u{bed}\x03\x02\x02\x02\u{bf0}\u{bf2}\x07\x34\x02\
	\x02\u{bf1}\u{bf0}\x03\x02\x02\x02\u{bf1}\u{bf2}\x03\x02\x02\x02\u{bf2}\
	\u{bf3}\x03\x02\x02\x02\u{bf3}\u{bf4}\x07\u{18e}\x02\x02\u{bf4}\u{bf6}\x03\
	\x02\x02\x02\u{bf5}\u{be7}\x03\x02\x02\x02\u{bf5}\u{bf6}\x03\x02\x02\x02\
	\u{bf6}\u{bf7}\x03\x02\x02\x02\u{bf7}\u{bf8}\x07\u{178}\x02\x02\u{bf8}\u{bf9}\
	\x07\u{18d}\x02\x02\u{bf9}\u{bfe}\x05\u{d6}\x6c\x02\u{bfa}\u{bfb}\x07\x34\
	\x02\x02\u{bfb}\u{bfd}\x05\u{d6}\x6c\x02\u{bfc}\u{bfa}\x03\x02\x02\x02\u{bfd}\
	\u{c00}\x03\x02\x02\x02\u{bfe}\u{bfc}\x03\x02\x02\x02\u{bfe}\u{bff}\x03\
	\x02\x02\x02\u{bff}\u{c02}\x03\x02\x02\x02\u{c00}\u{bfe}\x03\x02\x02\x02\
	\u{c01}\u{c03}\x07\x34\x02\x02\u{c02}\u{c01}\x03\x02\x02\x02\u{c02}\u{c03}\
	\x03\x02\x02\x02\u{c03}\u{c04}\x03\x02\x02\x02\u{c04}\u{c05}\x07\u{18e}\
	\x02\x02\u{c05}\u{11b}\x03\x02\x02\x02\u{c06}\u{c0c}\x07\u{f2}\x02\x02\u{c07}\
	\u{c0d}\x05\u{144}\u{a3}\x02\u{c08}\u{c09}\x07\u{18d}\x02\x02\u{c09}\u{c0a}\
	\x05\x6e\x38\x02\u{c0a}\u{c0b}\x07\u{18e}\x02\x02\u{c0b}\u{c0d}\x03\x02\
	\x02\x02\u{c0c}\u{c07}\x03\x02\x02\x02\u{c0c}\u{c08}\x03\x02\x02\x02\u{c0d}\
	\u{11d}\x03\x02\x02\x02\u{c0e}\u{c0f}\x05\u{120}\u{91}\x02\u{c0f}\u{11f}\
	\x03\x02\x02\x02\u{c10}\u{c11}\x07\u{10d}\x02\x02\u{c11}\u{c29}\x05\u{122}\
	\u{92}\x02\u{c12}\u{c13}\x07\u{124}\x02\x02\u{c13}\u{c29}\x05\u{122}\u{92}\
	\x02\u{c14}\u{c15}\x07\u{90}\x02\x02\u{c15}\u{c29}\x05\u{122}\u{92}\x02\
	\u{c16}\u{c17}\x07\u{10d}\x02\x02\u{c17}\u{c18}\x07\x1f\x02\x02\u{c18}\u{c19}\
	\x05\u{122}\u{92}\x02\u{c19}\u{c1a}\x07\x12\x02\x02\u{c1a}\u{c1b}\x05\u{122}\
	\u{92}\x02\u{c1b}\u{c29}\x03\x02\x02\x02\u{c1c}\u{c1d}\x07\u{124}\x02\x02\
	\u{c1d}\u{c1e}\x07\x1f\x02\x02\u{c1e}\u{c1f}\x05\u{122}\u{92}\x02\u{c1f}\
	\u{c20}\x07\x12\x02\x02\u{c20}\u{c21}\x05\u{122}\u{92}\x02\u{c21}\u{c29}\
	\x03\x02\x02\x02\u{c22}\u{c23}\x07\u{90}\x02\x02\u{c23}\u{c24}\x07\x1f\x02\
	\x02\u{c24}\u{c25}\x05\u{122}\u{92}\x02\u{c25}\u{c26}\x07\x12\x02\x02\u{c26}\
	\u{c27}\x05\u{122}\u{92}\x02\u{c27}\u{c29}\x03\x02\x02\x02\u{c28}\u{c10}\
	\x03\x02\x02\x02\u{c28}\u{c12}\x03\x02\x02\x02\u{c28}\u{c14}\x03\x02\x02\
	\x02\u{c28}\u{c16}\x03\x02\x02\x02\u{c28}\u{c1c}\x03\x02\x02\x02\u{c28}\
	\u{c22}\x03\x02\x02\x02\u{c29}\u{121}\x03\x02\x02\x02\u{c2a}\u{c2b}\x07\
	\u{163}\x02\x02\u{c2b}\u{c34}\x07\u{101}\x02\x02\u{c2c}\u{c2d}\x07\u{163}\
	\x02\x02\u{c2d}\u{c34}\x07\u{80}\x02\x02\u{c2e}\u{c2f}\x07\x45\x02\x02\u{c2f}\
	\u{c34}\x07\u{123}\x02\x02\u{c30}\u{c31}\x05\u{d6}\x6c\x02\u{c31}\u{c32}\
	\x09\x1d\x02\x02\u{c32}\u{c34}\x03\x02\x02\x02\u{c33}\u{c2a}\x03\x02\x02\
	\x02\u{c33}\u{c2c}\x03\x02\x02\x02\u{c33}\u{c2e}\x03\x02\x02\x02\u{c33}\
	\u{c30}\x03\x02\x02\x02\u{c34}\u{123}\x03\x02\x02\x02\u{c35}\u{c36}\x08\
	\u{93}\x01\x02\u{c36}\u{c38}\x05\u{126}\u{94}\x02\u{c37}\u{c39}\x05\u{128}\
	\u{95}\x02\u{c38}\u{c37}\x03\x02\x02\x02\u{c38}\u{c39}\x03\x02\x02\x02\u{c39}\
	\u{c41}\x03\x02\x02\x02\u{c3a}\u{c3b}\x0c\x04\x02\x02\u{c3b}\u{c40}\x05\
	\u{124}\u{93}\x05\u{c3c}\u{c3d}\x0c\x03\x02\x02\u{c3d}\u{c3e}\x07\u{1a3}\
	\x02\x02\u{c3e}\u{c40}\x05\u{124}\u{93}\x04\u{c3f}\u{c3a}\x03\x02\x02\x02\
	\u{c3f}\u{c3c}\x03\x02\x02\x02\u{c40}\u{c43}\x03\x02\x02\x02\u{c41}\u{c3f}\
	\x03\x02\x02\x02\u{c41}\u{c42}\x03\x02\x02\x02\u{c42}\u{125}\x03\x02\x02\
	\x02\u{c43}\u{c41}\x03\x02\x02\x02\u{c44}\u{c61}\x05\u{144}\u{a3}\x02\u{c45}\
	\u{c46}\x07\u{18d}\x02\x02\u{c46}\u{c61}\x07\u{18e}\x02\x02\u{c47}\u{c48}\
	\x07\u{fe}\x02\x02\u{c48}\u{c49}\x07\u{18d}\x02\x02\u{c49}\u{c4e}\x05\u{124}\
	\u{93}\x02\u{c4a}\u{c4b}\x07\x34\x02\x02\u{c4b}\u{c4d}\x05\u{124}\u{93}\
	\x02\u{c4c}\u{c4a}\x03\x02\x02\x02\u{c4d}\u{c50}\x03\x02\x02\x02\u{c4e}\
	\u{c4c}\x03\x02\x02\x02\u{c4e}\u{c4f}\x03\x02\x02\x02\u{c4f}\u{c52}\x03\
	\x02\x02\x02\u{c50}\u{c4e}\x03\x02\x02\x02\u{c51}\u{c53}\x07\x34\x02\x02\
	\u{c52}\u{c51}\x03\x02\x02\x02\u{c52}\u{c53}\x03\x02\x02\x02\u{c53}\u{c54}\
	\x03\x02\x02\x02\u{c54}\u{c55}\x07\u{18e}\x02\x02\u{c55}\u{c61}\x03\x02\
	\x02\x02\u{c56}\u{c57}\x07\u{18d}\x02\x02\u{c57}\u{c58}\x05\u{124}\u{93}\
	\x02\u{c58}\u{c59}\x07\u{18e}\x02\x02\u{c59}\u{c61}\x03\x02\x02\x02\u{c5a}\
	\u{c61}\x07\u{1a4}\x02\x02\u{c5b}\u{c61}\x07\u{1a1}\x02\x02\u{c5c}\u{c5d}\
	\x07\x06\x02\x02\u{c5d}\u{c5e}\x05\u{124}\u{93}\x02\u{c5e}\u{c5f}\x07\x07\
	\x02\x02\u{c5f}\u{c61}\x03\x02\x02\x02\u{c60}\u{c44}\x03\x02\x02\x02\u{c60}\
	\u{c45}\x03\x02\x02\x02\u{c60}\u{c47}\x03\x02\x02\x02\u{c60}\u{c56}\x03\
	\x02\x02\x02\u{c60}\u{c5a}\x03\x02\x02\x02\u{c60}\u{c5b}\x03\x02\x02\x02\
	\u{c60}\u{c5c}\x03\x02\x02\x02\u{c61}\u{127}\x03\x02\x02\x02\u{c62}\u{c64}\
	\x07\u{19a}\x02\x02\u{c63}\u{c65}\x07\u{19e}\x02\x02\u{c64}\u{c63}\x03\x02\
	\x02\x02\u{c64}\u{c65}\x03\x02\x02\x02\u{c65}\u{c84}\x03\x02\x02\x02\u{c66}\
	\u{c68}\x07\u{198}\x02\x02\u{c67}\u{c69}\x07\u{19e}\x02\x02\u{c68}\u{c67}\
	\x03\x02\x02\x02\u{c68}\u{c69}\x03\x02\x02\x02\u{c69}\u{c84}\x03\x02\x02\
	\x02\u{c6a}\u{c6c}\x07\u{19e}\x02\x02\u{c6b}\u{c6d}\x07\u{19e}\x02\x02\u{c6c}\
	\u{c6b}\x03\x02\x02\x02\u{c6c}\u{c6d}\x03\x02\x02\x02\u{c6d}\u{c84}\x03\
	\x02\x02\x02\u{c6e}\u{c6f}\x07\x08\x02\x02\u{c6f}\u{c70}\x07\u{1ad}\x02\
	\x02\u{c70}\u{c72}\x07\x09\x02\x02\u{c71}\u{c73}\x07\u{19e}\x02\x02\u{c72}\
	\u{c71}\x03\x02\x02\x02\u{c72}\u{c73}\x03\x02\x02\x02\u{c73}\u{c84}\x03\
	\x02\x02\x02\u{c74}\u{c76}\x07\x08\x02\x02\u{c75}\u{c77}\x07\u{1ad}\x02\
	\x02\u{c76}\u{c75}\x03\x02\x02\x02\u{c76}\u{c77}\x03\x02\x02\x02\u{c77}\
	\u{c78}\x03\x02\x02\x02\u{c78}\u{c7a}\x07\x34\x02\x02\u{c79}\u{c7b}\x07\
	\u{1ad}\x02\x02\u{c7a}\u{c79}\x03\x02\x02\x02\u{c7a}\u{c7b}\x03\x02\x02\
	\x02\u{c7b}\u{c7d}\x03\x02\x02\x02\u{c7c}\u{c7e}\x07\x34\x02\x02\u{c7d}\
	\u{c7c}\x03\x02\x02\x02\u{c7d}\u{c7e}\x03\x02\x02\x02\u{c7e}\u{c7f}\x03\
	\x02\x02\x02\u{c7f}\u{c81}\x07\x09\x02\x02\u{c80}\u{c82}\x07\u{19e}\x02\
	\x02\u{c81}\u{c80}\x03\x02\x02\x02\u{c81}\u{c82}\x03\x02\x02\x02\u{c82}\
	\u{c84}\x03\x02\x02\x02\u{c83}\u{c62}\x03\x02\x02\x02\u{c83}\u{c66}\x03\
	\x02\x02\x02\u{c83}\u{c6a}\x03\x02\x02\x02\u{c83}\u{c6e}\x03\x02\x02\x02\
	\u{c83}\u{c74}\x03\x02\x02\x02\u{c84}\u{129}\x03\x02\x02\x02\u{c85}\u{c86}\
	\x07\u{a8}\x02\x02\u{c86}\u{c87}\x07\u{b9}\x02\x02\u{c87}\u{c8b}\x05\u{12c}\
	\u{97}\x02\u{c88}\u{c89}\x07\u{10e}\x02\x02\u{c89}\u{c8b}\x09\x1e\x02\x02\
	\u{c8a}\u{c85}\x03\x02\x02\x02\u{c8a}\u{c88}\x03\x02\x02\x02\u{c8b}\u{12b}\
	\x03\x02\x02\x02\u{c8c}\u{c8d}\x07\u{10e}\x02\x02\u{c8d}\u{c94}\x07\u{164}\
	\x02\x02\u{c8e}\u{c8f}\x07\u{10e}\x02\x02\u{c8f}\u{c94}\x07\x37\x02\x02\
	\u{c90}\u{c91}\x07\u{112}\x02\x02\u{c91}\u{c94}\x07\u{10e}\x02\x02\u{c92}\
	\u{c94}\x07\u{133}\x02\x02\u{c93}\u{c8c}\x03\x02\x02\x02\u{c93}\u{c8e}\x03\
	\x02\x02\x02\u{c93}\u{c90}\x03\x02\x02\x02\u{c93}\u{c92}\x03\x02\x02\x02\
	\u{c94}\u{12d}\x03\x02\x02\x02\u{c95}\u{c96}\x09\x1f\x02\x02\u{c96}\u{12f}\
	\x03\x02\x02\x02\u{c97}\u{c9c}\x05\u{144}\u{a3}\x02\u{c98}\u{c99}\x07\u{191}\
	\x02\x02\u{c99}\u{c9b}\x05\u{146}\u{a4}\x02\u{c9a}\u{c98}\x03\x02\x02\x02\
	\u{c9b}\u{c9e}\x03\x02\x02\x02\u{c9c}\u{c9a}\x03\x02\x02\x02\u{c9c}\u{c9d}\
	\x03\x02\x02\x02\u{c9d}\u{131}\x03\x02\x02\x02\u{c9e}\u{c9c}\x03\x02\x02\
	\x02\u{c9f}\u{ca0}\x05\u{130}\u{99}\x02\u{ca0}\u{133}\x03\x02\x02\x02\u{ca1}\
	\u{ca4}\x07\u{1b1}\x02\x02\u{ca2}\u{ca4}\x05\u{150}\u{a9}\x02\u{ca3}\u{ca1}\
	\x03\x02\x02\x02\u{ca3}\u{ca2}\x03\x02\x02\x02\u{ca4}\u{135}\x03\x02\x02\
	\x02\u{ca5}\u{ca6}\x08\u{9c}\x01\x02\u{ca6}\u{ca7}\x05\u{134}\u{9b}\x02\
	\u{ca7}\u{ca8}\x07\u{199}\x02\x02\u{ca8}\u{ca9}\x05\u{134}\u{9b}\x02\u{ca9}\
	\u{cb4}\x03\x02\x02\x02\u{caa}\u{cab}\x05\u{134}\u{9b}\x02\u{cab}\u{cac}\
	\x07\u{199}\x02\x02\u{cac}\u{cad}\x07\u{1ad}\x02\x02\u{cad}\u{cb4}\x03\x02\
	\x02\x02\u{cae}\u{caf}\x05\u{134}\u{9b}\x02\u{caf}\u{cb0}\x07\u{199}\x02\
	\x02\u{cb0}\u{cb1}\x07\u{1af}\x02\x02\u{cb1}\u{cb2}\x05\u{134}\u{9b}\x02\
	\u{cb2}\u{cb4}\x03\x02\x02\x02\u{cb3}\u{ca5}\x03\x02\x02\x02\u{cb3}\u{caa}\
	\x03\x02\x02\x02\u{cb3}\u{cae}\x03\x02\x02\x02\u{cb4}\u{cc1}\x03\x02\x02\
	\x02\u{cb5}\u{cb6}\x0c\x07\x02\x02\u{cb6}\u{cb7}\x07\u{199}\x02\x02\u{cb7}\
	\u{cc0}\x05\u{134}\u{9b}\x02\u{cb8}\u{cb9}\x0c\x05\x02\x02\u{cb9}\u{cba}\
	\x07\u{199}\x02\x02\u{cba}\u{cc0}\x07\u{1ad}\x02\x02\u{cbb}\u{cbc}\x0c\x03\
	\x02\x02\u{cbc}\u{cbd}\x07\u{199}\x02\x02\u{cbd}\u{cbe}\x07\u{1af}\x02\x02\
	\u{cbe}\u{cc0}\x05\u{134}\u{9b}\x02\u{cbf}\u{cb5}\x03\x02\x02\x02\u{cbf}\
	\u{cb8}\x03\x02\x02\x02\u{cbf}\u{cbb}\x03\x02\x02\x02\u{cc0}\u{cc3}\x03\
	\x02\x02\x02\u{cc1}\u{cbf}\x03\x02\x02\x02\u{cc1}\u{cc2}\x03\x02\x02\x02\
	\u{cc2}\u{137}\x03\x02\x02\x02\u{cc3}\u{cc1}\x03\x02\x02\x02\u{cc4}\u{cc7}\
	\x05\u{144}\u{a3}\x02\u{cc5}\u{cc7}\x05\u{136}\u{9c}\x02\u{cc6}\u{cc4}\x03\
	\x02\x02\x02\u{cc6}\u{cc5}\x03\x02\x02\x02\u{cc7}\u{139}\x03\x02\x02\x02\
	\u{cc8}\u{ccd}\x05\u{136}\u{9c}\x02\u{cc9}\u{cca}\x07\u{191}\x02\x02\u{cca}\
	\u{ccc}\x05\u{146}\u{a4}\x02\u{ccb}\u{cc9}\x03\x02\x02\x02\u{ccc}\u{ccf}\
	\x03\x02\x02\x02\u{ccd}\u{ccb}\x03\x02\x02\x02\u{ccd}\u{cce}\x03\x02\x02\
	\x02\u{cce}\u{13b}\x03\x02\x02\x02\u{ccf}\u{ccd}\x03\x02\x02\x02\u{cd0}\
	\u{cd3}\x05\u{132}\u{9a}\x02\u{cd1}\u{cd3}\x05\u{13a}\u{9e}\x02\u{cd2}\u{cd0}\
	\x03\x02\x02\x02\u{cd2}\u{cd1}\x03\x02\x02\x02\u{cd3}\u{13d}\x03\x02\x02\
	\x02\u{cd4}\u{cd5}\x07\u{81}\x02\x02\u{cd5}\u{cd6}\x05\u{140}\u{a1}\x02\
	\u{cd6}\u{cd7}\x07\x16\x02\x02\u{cd7}\u{cd8}\x07\u{e5}\x02\x02\u{cd8}\u{cd9}\
	\x05\u{dc}\x6f\x02\u{cd9}\u{13f}\x03\x02\x02\x02\u{cda}\u{cdb}\x09\x20\x02\
	\x02\u{cdb}\u{141}\x03\x02\x02\x02\u{cdc}\u{ce2}\x05\u{144}\u{a3}\x02\u{cdd}\
	\u{cde}\x07\u{170}\x02\x02\u{cde}\u{ce2}\x05\u{144}\u{a3}\x02\u{cdf}\u{ce0}\
	\x07\u{11f}\x02\x02\u{ce0}\u{ce2}\x05\u{144}\u{a3}\x02\u{ce1}\u{cdc}\x03\
	\x02\x02\x02\u{ce1}\u{cdd}\x03\x02\x02\x02\u{ce1}\u{cdf}\x03\x02\x02\x02\
	\u{ce2}\u{143}\x03\x02\x02\x02\u{ce3}\u{ce7}\x07\u{1b1}\x02\x02\u{ce4}\u{ce7}\
	\x05\u{150}\u{a9}\x02\u{ce5}\u{ce7}\x07\u{1b2}\x02\x02\u{ce6}\u{ce3}\x03\
	\x02\x02\x02\u{ce6}\u{ce4}\x03\x02\x02\x02\u{ce6}\u{ce5}\x03\x02\x02\x02\
	\u{ce7}\u{145}\x03\x02\x02\x02\u{ce8}\u{d43}\x05\u{144}\u{a3}\x02\u{ce9}\
	\u{d43}\x07\x0f\x02\x02\u{cea}\u{d43}\x07\x12\x02\x02\u{ceb}\u{d43}\x07\
	\x14\x02\x02\u{cec}\u{d43}\x07\x15\x02\x02\u{ced}\u{d43}\x07\x16\x02\x02\
	\u{cee}\u{d43}\x07\x17\x02\x02\u{cef}\u{d43}\x07\x18\x02\x02\u{cf0}\u{d43}\
	\x07\x1f\x02\x02\u{cf1}\u{d43}\x07\x22\x02\x02\u{cf2}\u{d43}\x07\x27\x02\
	\x02\u{cf3}\u{d43}\x07\x2a\x02\x02\u{cf4}\u{d43}\x07\x31\x02\x02\u{cf5}\
	\u{d43}\x07\x42\x02\x02\u{cf6}\u{d43}\x07\x43\x02\x02\u{cf7}\u{d43}\x07\
	\x44\x02\x02\u{cf8}\u{d43}\x07\x45\x02\x02\u{cf9}\u{d43}\x07\x54\x02\x02\
	\u{cfa}\u{d43}\x07\x56\x02\x02\u{cfb}\u{d43}\x07\x5c\x02\x02\u{cfc}\u{d43}\
	\x07\x60\x02\x02\u{cfd}\u{d43}\x07\x68\x02\x02\u{cfe}\u{d43}\x07\x6d\x02\
	\x02\u{cff}\u{d43}\x07\x6f\x02\x02\u{d00}\u{d43}\x07\x71\x02\x02\u{d01}\
	\u{d43}\x07\x73\x02\x02\u{d02}\u{d43}\x07\x76\x02\x02\u{d03}\u{d43}\x07\
	\x79\x02\x02\u{d04}\u{d43}\x07\x7a\x02\x02\u{d05}\u{d43}\x07\x7b\x02\x02\
	\u{d06}\u{d43}\x07\u{80}\x02\x02\u{d07}\u{d43}\x07\u{81}\x02\x02\u{d08}\
	\u{d43}\x07\u{84}\x02\x02\u{d09}\u{d43}\x07\u{85}\x02\x02\u{d0a}\u{d43}\
	\x07\u{8e}\x02\x02\u{d0b}\u{d43}\x07\u{8f}\x02\x02\u{d0c}\u{d43}\x07\u{90}\
	\x02\x02\u{d0d}\u{d43}\x07\u{92}\x02\x02\u{d0e}\u{d43}\x07\u{96}\x02\x02\
	\u{d0f}\u{d43}\x07\u{97}\x02\x02\u{d10}\u{d43}\x07\u{99}\x02\x02\u{d11}\
	\u{d43}\x07\u{9d}\x02\x02\u{d12}\u{d43}\x07\u{a2}\x02\x02\u{d13}\u{d43}\
	\x07\u{a3}\x02\x02\u{d14}\u{d43}\x07\u{a4}\x02\x02\u{d15}\u{d43}\x07\u{a7}\
	\x02\x02\u{d16}\u{d43}\x07\u{ad}\x02\x02\u{d17}\u{d43}\x07\u{b6}\x02\x02\
	\u{d18}\u{d43}\x07\u{b8}\x02\x02\u{d19}\u{d43}\x07\u{bb}\x02\x02\u{d1a}\
	\u{d43}\x07\u{bc}\x02\x02\u{d1b}\u{d43}\x07\u{c9}\x02\x02\u{d1c}\u{d43}\
	\x07\u{cd}\x02\x02\u{d1d}\u{d43}\x07\u{d2}\x02\x02\u{d1e}\u{d43}\x07\u{d8}\
	\x02\x02\u{d1f}\u{d43}\x07\u{de}\x02\x02\u{d20}\u{d43}\x07\u{e1}\x02\x02\
	\u{d21}\u{d43}\x07\u{e2}\x02\x02\u{d22}\u{d43}\x07\u{e3}\x02\x02\u{d23}\
	\u{d43}\x07\u{e5}\x02\x02\u{d24}\u{d43}\x07\u{e8}\x02\x02\u{d25}\u{d43}\
	\x07\u{ed}\x02\x02\u{d26}\u{d43}\x07\u{ee}\x02\x02\u{d27}\u{d43}\x07\u{ef}\
	\x02\x02\u{d28}\u{d43}\x07\u{f2}\x02\x02\u{d29}\u{d43}\x07\u{f4}\x02\x02\
	\u{d2a}\u{d43}\x07\u{101}\x02\x02\u{d2b}\u{d43}\x07\u{109}\x02\x02\u{d2c}\
	\u{d43}\x07\u{10d}\x02\x02\u{d2d}\u{d43}\x07\u{10f}\x02\x02\u{d2e}\u{d43}\
	\x07\u{115}\x02\x02\u{d2f}\u{d43}\x07\u{11d}\x02\x02\u{d30}\u{d43}\x07\u{122}\
	\x02\x02\u{d31}\u{d43}\x07\u{124}\x02\x02\u{d32}\u{d43}\x07\u{12f}\x02\x02\
	\u{d33}\u{d43}\x07\u{135}\x02\x02\u{d34}\u{d43}\x07\u{13a}\x02\x02\u{d35}\
	\u{d43}\x07\u{13f}\x02\x02\u{d36}\u{d43}\x07\u{147}\x02\x02\u{d37}\u{d43}\
	\x07\u{14d}\x02\x02\u{d38}\u{d43}\x07\u{153}\x02\x02\u{d39}\u{d43}\x07\u{15c}\
	\x02\x02\u{d3a}\u{d43}\x07\u{163}\x02\x02\u{d3b}\u{d43}\x07\u{166}\x02\x02\
	\u{d3c}\u{d43}\x07\u{16a}\x02\x02\u{d3d}\u{d43}\x07\u{171}\x02\x02\u{d3e}\
	\u{d43}\x07\u{17f}\x02\x02\u{d3f}\u{d43}\x07\u{180}\x02\x02\u{d40}\u{d43}\
	\x07\u{182}\x02\x02\u{d41}\u{d43}\x07\u{183}\x02\x02\u{d42}\u{ce8}\x03\x02\
	\x02\x02\u{d42}\u{ce9}\x03\x02\x02\x02\u{d42}\u{cea}\x03\x02\x02\x02\u{d42}\
	\u{ceb}\x03\x02\x02\x02\u{d42}\u{cec}\x03\x02\x02\x02\u{d42}\u{ced}\x03\
	\x02\x02\x02\u{d42}\u{cee}\x03\x02\x02\x02\u{d42}\u{cef}\x03\x02\x02\x02\
	\u{d42}\u{cf0}\x03\x02\x02\x02\u{d42}\u{cf1}\x03\x02\x02\x02\u{d42}\u{cf2}\
	\x03\x02\x02\x02\u{d42}\u{cf3}\x03\x02\x02\x02\u{d42}\u{cf4}\x03\x02\x02\
	\x02\u{d42}\u{cf5}\x03\x02\x02\x02\u{d42}\u{cf6}\x03\x02\x02\x02\u{d42}\
	\u{cf7}\x03\x02\x02\x02\u{d42}\u{cf8}\x03\x02\x02\x02\u{d42}\u{cf9}\x03\
	\x02\x02\x02\u{d42}\u{cfa}\x03\x02\x02\x02\u{d42}\u{cfb}\x03\x02\x02\x02\
	\u{d42}\u{cfc}\x03\x02\x02\x02\u{d42}\u{cfd}\x03\x02\x02\x02\u{d42}\u{cfe}\
	\x03\x02\x02\x02\u{d42}\u{cff}\x03\x02\x02\x02\u{d42}\u{d00}\x03\x02\x02\
	\x02\u{d42}\u{d01}\x03\x02\x02\x02\u{d42}\u{d02}\x03\x02\x02\x02\u{d42}\
	\u{d03}\x03\x02\x02\x02\u{d42}\u{d04}\x03\x02\x02\x02\u{d42}\u{d05}\x03\
	\x02\x02\x02\u{d42}\u{d06}\x03\x02\x02\x02\u{d42}\u{d07}\x03\x02\x02\x02\
	\u{d42}\u{d08}\x03\x02\x02\x02\u{d42}\u{d09}\x03\x02\x02\x02\u{d42}\u{d0a}\
	\x03\x02\x02\x02\u{d42}\u{d0b}\x03\x02\x02\x02\u{d42}\u{d0c}\x03\x02\x02\
	\x02\u{d42}\u{d0d}\x03\x02\x02\x02\u{d42}\u{d0e}\x03\x02\x02\x02\u{d42}\
	\u{d0f}\x03\x02\x02\x02\u{d42}\u{d10}\x03\x02\x02\x02\u{d42}\u{d11}\x03\
	\x02\x02\x02\u{d42}\u{d12}\x03\x02\x02\x02\u{d42}\u{d13}\x03\x02\x02\x02\
	\u{d42}\u{d14}\x03\x02\x02\x02\u{d42}\u{d15}\x03\x02\x02\x02\u{d42}\u{d16}\
	\x03\x02\x02\x02\u{d42}\u{d17}\x03\x02\x02\x02\u{d42}\u{d18}\x03\x02\x02\
	\x02\u{d42}\u{d19}\x03\x02\x02\x02\u{d42}\u{d1a}\x03\x02\x02\x02\u{d42}\
	\u{d1b}\x03\x02\x02\x02\u{d42}\u{d1c}\x03\x02\x02\x02\u{d42}\u{d1d}\x03\
	\x02\x02\x02\u{d42}\u{d1e}\x03\x02\x02\x02\u{d42}\u{d1f}\x03\x02\x02\x02\
	\u{d42}\u{d20}\x03\x02\x02\x02\u{d42}\u{d21}\x03\x02\x02\x02\u{d42}\u{d22}\
	\x03\x02\x02\x02\u{d42}\u{d23}\x03\x02\x02\x02\u{d42}\u{d24}\x03\x02\x02\
	\x02\u{d42}\u{d25}\x03\x02\x02\x02\u{d42}\u{d26}\x03\x02\x02\x02\u{d42}\
	\u{d27}\x03\x02\x02\x02\u{d42}\u{d28}\x03\x02\x02\x02\u{d42}\u{d29}\x03\
	\x02\x02\x02\u{d42}\u{d2a}\x03\x02\x02\x02\u{d42}\u{d2b}\x03\x02\x02\x02\
	\u{d42}\u{d2c}\x03\x02\x02\x02\u{d42}\u{d2d}\x03\x02\x02\x02\u{d42}\u{d2e}\
	\x03\x02\x02\x02\u{d42}\u{d2f}\x03\x02\x02\x02\u{d42}\u{d30}\x03\x02\x02\
	\x02\u{d42}\u{d31}\x03\x02\x02\x02\u{d42}\u{d32}\x03\x02\x02\x02\u{d42}\
	\u{d33}\x03\x02\x02\x02\u{d42}\u{d34}\x03\x02\x02\x02\u{d42}\u{d35}\x03\
	\x02\x02\x02\u{d42}\u{d36}\x03\x02\x02\x02\u{d42}\u{d37}\x03\x02\x02\x02\
	\u{d42}\u{d38}\x03\x02\x02\x02\u{d42}\u{d39}\x03\x02\x02\x02\u{d42}\u{d3a}\
	\x03\x02\x02\x02\u{d42}\u{d3b}\x03\x02\x02\x02\u{d42}\u{d3c}\x03\x02\x02\
	\x02\u{d42}\u{d3d}\x03\x02\x02\x02\u{d42}\u{d3e}\x03\x02\x02\x02\u{d42}\
	\u{d3f}\x03\x02\x02\x02\u{d42}\u{d40}\x03\x02\x02\x02\u{d42}\u{d41}\x03\
	\x02\x02\x02\u{d43}\u{147}\x03\x02\x02\x02\u{d44}\u{d45}\x05\u{144}\u{a3}\
	\x02\u{d45}\u{d46}\x07\x02\x02\x03\u{d46}\u{149}\x03\x02\x02\x02\u{d47}\
	\u{d48}\x07\u{18d}\x02\x02\u{d48}\u{d49}\x05\u{14c}\u{a7}\x02\u{d49}\u{d4a}\
	\x07\u{18e}\x02\x02\u{d4a}\u{14b}\x03\x02\x02\x02\u{d4b}\u{d50}\x05\u{144}\
	\u{a3}\x02\u{d4c}\u{d4d}\x07\x34\x02\x02\u{d4d}\u{d4f}\x05\u{144}\u{a3}\
	\x02\u{d4e}\u{d4c}\x03\x02\x02\x02\u{d4f}\u{d52}\x03\x02\x02\x02\u{d50}\
	\u{d4e}\x03\x02\x02\x02\u{d50}\u{d51}\x03\x02\x02\x02\u{d51}\u{14d}\x03\
	\x02\x02\x02\u{d52}\u{d50}\x03\x02\x02\x02\u{d53}\u{d55}\x07\u{199}\x02\
	\x02\u{d54}\u{d53}\x03\x02\x02\x02\u{d54}\u{d55}\x03\x02\x02\x02\u{d55}\
	\u{d56}\x03\x02\x02\x02\u{d56}\u{d64}\x07\u{1af}\x02\x02\u{d57}\u{d59}\x07\
	\u{199}\x02\x02\u{d58}\u{d57}\x03\x02\x02\x02\u{d58}\u{d59}\x03\x02\x02\
	\x02\u{d59}\u{d5a}\x03\x02\x02\x02\u{d5a}\u{d64}\x07\u{1b0}\x02\x02\u{d5b}\
	\u{d5d}\x07\u{199}\x02\x02\u{d5c}\u{d5b}\x03\x02\x02\x02\u{d5c}\u{d5d}\x03\
	\x02\x02\x02\u{d5d}\u{d5e}\x03\x02\x02\x02\u{d5e}\u{d64}\x07\u{1ad}\x02\
	\x02\u{d5f}\u{d61}\x07\u{199}\x02\x02\u{d60}\u{d5f}\x03\x02\x02\x02\u{d60}\
	\u{d61}\x03\x02\x02\x02\u{d61}\u{d62}\x03\x02\x02\x02\u{d62}\u{d64}\x07\
	\u{1ae}\x02\x02\u{d63}\u{d54}\x03\x02\x02\x02\u{d63}\u{d58}\x03\x02\x02\
	\x02\u{d63}\u{d5c}\x03\x02\x02\x02\u{d63}\u{d60}\x03\x02\x02\x02\u{d64}\
	\u{14f}\x03\x02\x02\x02\u{d65}\u{d66}\x09\x21\x02\x02\u{d66}\u{151}\x03\
	\x02\x02\x02\u{1c3}\u{153}\u{157}\u{15b}\u{161}\u{164}\u{176}\u{187}\u{18d}\
	\u{1a7}\u{1ae}\u{1b4}\u{1b8}\u{1bb}\u{1c1}\u{1c3}\u{1cb}\u{1ce}\u{1d4}\u{1e0}\
	\u{1e2}\u{1e7}\u{1eb}\u{1f0}\u{1f5}\u{1fe}\u{201}\u{205}\u{209}\u{211}\u{21b}\
	\u{21f}\u{223}\u{227}\u{22e}\u{235}\u{23b}\u{244}\u{247}\u{24b}\u{253}\u{259}\
	\u{25d}\u{261}\u{26e}\u{272}\u{275}\u{27e}\u{283}\u{286}\u{28c}\u{295}\u{299}\
	\u{29b}\u{2a0}\u{2a9}\u{2ae}\u{2b1}\u{2b7}\u{2c0}\u{2c4}\u{2c6}\u{2ce}\u{2d7}\
	\u{2e2}\u{2e4}\u{2e9}\u{2ef}\u{2f8}\u{2fc}\u{2fe}\u{30a}\u{30f}\u{315}\u{31a}\
	\u{323}\u{32c}\u{330}\u{340}\u{348}\u{34c}\u{350}\u{35b}\u{35e}\u{366}\u{369}\
	\u{37a}\u{383}\u{387}\u{397}\u{39c}\u{3c8}\u{3cd}\u{3d1}\u{3d5}\u{3db}\u{3e1}\
	\u{3e7}\u{3ee}\u{3f5}\u{3fc}\u{403}\u{40a}\u{415}\u{41d}\u{425}\u{42c}\u{436}\
	\u{43d}\u{445}\u{469}\u{46c}\u{46f}\u{472}\u{476}\u{47c}\u{488}\u{4a9}\u{4b1}\
	\u{4b8}\u{4bf}\u{4c8}\u{4cc}\u{4d0}\u{4d4}\u{4de}\u{4e5}\u{4ef}\u{4f3}\u{4f5}\
	\u{4fb}\u{502}\u{509}\u{510}\u{517}\u{524}\u{527}\u{52e}\u{536}\u{53b}\u{53f}\
	\u{541}\u{54e}\u{554}\u{55b}\u{563}\u{56e}\u{571}\u{576}\u{579}\u{580}\u{584}\
	\u{591}\u{598}\u{59c}\u{5a2}\u{5a4}\u{5ad}\u{5b6}\u{5ba}\u{5c2}\u{5cb}\u{5d2}\
	\u{5db}\u{5dd}\u{5e1}\u{5ef}\u{5f4}\u{5f7}\u{5f9}\u{5ff}\u{607}\u{60c}\u{616}\
	\u{61a}\u{624}\u{628}\u{62c}\u{630}\u{634}\u{639}\u{63d}\u{640}\u{644}\u{648}\
	\u{650}\u{654}\u{656}\u{65a}\u{663}\u{667}\u{66f}\u{676}\u{67a}\u{67c}\u{685}\
	\u{689}\u{68b}\u{695}\u{699}\u{69b}\u{6a6}\u{6aa}\u{6af}\u{6b7}\u{6ba}\u{6bd}\
	\u{6c1}\u{6ca}\u{6cd}\u{6d0}\u{6d3}\u{6dc}\u{6e0}\u{6e9}\u{6ed}\u{6f9}\u{6fc}\
	\u{6ff}\u{704}\u{70d}\u{712}\u{719}\u{725}\u{72d}\u{734}\u{738}\u{740}\u{743}\
	\u{747}\u{74b}\u{74f}\u{751}\u{75c}\u{760}\u{764}\u{76a}\u{77a}\u{77d}\u{783}\
	\u{78f}\u{799}\u{79c}\u{7a8}\u{7ab}\u{7b0}\u{7b3}\u{7b7}\u{7bb}\u{7bf}\u{7cf}\
	\u{7d3}\u{7dd}\u{7e2}\u{7e5}\u{7ec}\u{7f0}\u{7f4}\u{7fb}\u{7ff}\u{80f}\u{816}\
	\u{81d}\u{821}\u{824}\u{829}\u{82f}\u{835}\u{839}\u{83d}\u{841}\u{84c}\u{850}\
	\u{85c}\u{860}\u{864}\u{867}\u{86c}\u{86f}\u{871}\u{874}\u{87d}\u{881}\u{883}\
	\u{886}\u{88a}\u{892}\u{896}\u{89d}\u{8a2}\u{8ad}\u{8b1}\u{8b3}\u{8b7}\u{8b9}\
	\u{8c1}\u{8cb}\u{8cf}\u{8d4}\u{8d6}\u{8df}\u{8e3}\u{8e5}\u{8e7}\u{8f0}\u{8f4}\
	\u{8fe}\u{902}\u{90c}\u{910}\u{919}\u{91d}\u{925}\u{927}\u{934}\u{93c}\u{945}\
	\u{949}\u{94e}\u{954}\u{95c}\u{966}\u{96c}\u{972}\u{977}\u{97e}\u{983}\u{988}\
	\u{98b}\u{991}\u{9a2}\u{9a4}\u{9ba}\u{9bd}\u{9c8}\u{9cd}\u{9d5}\u{9d8}\u{9e5}\
	\u{9e9}\u{9f1}\u{9f5}\u{a00}\u{a0b}\u{a12}\u{a15}\u{a20}\u{a23}\u{a25}\u{a30}\
	\u{a3b}\u{a44}\u{a47}\u{a54}\u{a5f}\u{a63}\u{a71}\u{a78}\u{a7b}\u{a8f}\u{a92}\
	\u{a95}\u{aa3}\u{aab}\u{aae}\u{ab1}\u{abf}\u{ac3}\u{ac5}\u{ace}\u{ad8}\u{ada}\
	\u{adf}\u{ae2}\u{ae9}\u{aec}\u{aef}\u{af8}\u{afb}\u{afe}\u{b15}\u{b1f}\u{b27}\
	\u{b34}\u{b39}\u{b41}\u{b47}\u{b54}\u{b5f}\u{b62}\u{b73}\u{b77}\u{b83}\u{b87}\
	\u{b8b}\u{b8d}\u{b94}\u{b9b}\u{b9f}\u{bb0}\u{bb5}\u{bbc}\u{bc0}\u{bc5}\u{bce}\
	\u{bd3}\u{bd5}\u{be3}\u{bed}\u{bf1}\u{bf5}\u{bfe}\u{c02}\u{c0c}\u{c28}\u{c33}\
	\u{c38}\u{c3f}\u{c41}\u{c4e}\u{c52}\u{c60}\u{c64}\u{c68}\u{c6c}\u{c72}\u{c76}\
	\u{c7a}\u{c7d}\u{c81}\u{c83}\u{c8a}\u{c93}\u{c9c}\u{ca3}\u{cb3}\u{cbf}\u{cc1}\
	\u{cc6}\u{ccd}\u{cd2}\u{ce1}\u{ce6}\u{d42}\u{d50}\u{d54}\u{d58}\u{d5c}\u{d60}\
	\u{d63}";

