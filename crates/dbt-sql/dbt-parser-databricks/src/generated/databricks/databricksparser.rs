// Generated from Databricks.g4 by ANTLR 4.8
#![allow(dead_code)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(nonstandard_style)]
#![allow(unused_imports)]
#![allow(unused_mut)]
#![allow(unused_braces)]
use antlr_rust::PredictionContextCache;
use antlr_rust::error_listener::ErrorListener;
use antlr_rust::parser::{Parser, BaseParser, ParserRecog, ParserNodeType};
use antlr_rust::token_stream::TokenStream;
use antlr_rust::TokenSource;
use antlr_rust::parser_atn_simulator::ParserATNSimulator;
use antlr_rust::errors::*;
use antlr_rust::rule_context::{BaseRuleContext, CustomRuleContext, RuleContext};
use antlr_rust::recognizer::{Recognizer,Actions};
use antlr_rust::atn_deserializer::ATNDeserializer;
use antlr_rust::dfa::DFA;
use antlr_rust::atn::{ATN, INVALID_ALT};
use antlr_rust::error_strategy::{ErrorStrategy, DefaultErrorStrategy};
use antlr_rust::parser_rule_context::{BaseParserRuleContext, ParserRuleContext,cast,cast_mut};
use antlr_rust::tree::*;
use antlr_rust::token::{TOKEN_EOF,OwningToken,Token};
use antlr_rust::int_stream::EOF;
use antlr_rust::vocabulary::{Vocabulary,VocabularyImpl};
use antlr_rust::token_factory::{CommonTokenFactory,TokenFactory, TokenAware};
use super::databrickslistener::*;
use super::databricksvisitor::*;

use antlr_rust::{TidAble,TidExt};

use std::marker::PhantomData;
use std::rc::Rc;
use std::convert::TryFrom;
use std::cell::RefCell;
use std::ops::{DerefMut, Deref};
use std::borrow::{Borrow,BorrowMut};
use std::any::{Any,TypeId};

		pub const T__0:isize=1; 
		pub const T__1:isize=2; 
		pub const T__2:isize=3; 
		pub const T__3:isize=4; 
		pub const ADD:isize=5; 
		pub const AFTER:isize=6; 
		pub const ALL:isize=7; 
		pub const ALTER:isize=8; 
		pub const ALWAYS:isize=9; 
		pub const ANALYZE:isize=10; 
		pub const AND:isize=11; 
		pub const ANTI:isize=12; 
		pub const ANY:isize=13; 
		pub const ANY_VALUE:isize=14; 
		pub const ARCHIVE:isize=15; 
		pub const ARRAY:isize=16; 
		pub const ARRAYS_ZIP:isize=17; 
		pub const AS:isize=18; 
		pub const ASC:isize=19; 
		pub const AT:isize=20; 
		pub const AUTHORIZATION:isize=21; 
		pub const BEGIN:isize=22; 
		pub const BETWEEN:isize=23; 
		pub const BIGINT:isize=24; 
		pub const BINARY:isize=25; 
		pub const X_KW:isize=26; 
		pub const BINDING:isize=27; 
		pub const BOOLEAN:isize=28; 
		pub const BOTH:isize=29; 
		pub const BUCKET:isize=30; 
		pub const BUCKETS:isize=31; 
		pub const BY:isize=32; 
		pub const BYTE:isize=33; 
		pub const CACHE:isize=34; 
		pub const CALLED:isize=35; 
		pub const CASCADE:isize=36; 
		pub const CASE:isize=37; 
		pub const CAST:isize=38; 
		pub const CATALOG:isize=39; 
		pub const CATALOGS:isize=40; 
		pub const CHANGE:isize=41; 
		pub const CHAR:isize=42; 
		pub const CHARACTER:isize=43; 
		pub const CHECK:isize=44; 
		pub const CLEAR:isize=45; 
		pub const CLUSTER:isize=46; 
		pub const CLUSTERED:isize=47; 
		pub const CODEGEN:isize=48; 
		pub const COLLATE:isize=49; 
		pub const COLLATION:isize=50; 
		pub const COLLECTION:isize=51; 
		pub const COLUMN:isize=52; 
		pub const COLUMNS:isize=53; 
		pub const COMMA:isize=54; 
		pub const COMMENT:isize=55; 
		pub const COMMIT:isize=56; 
		pub const COMPACT:isize=57; 
		pub const COMPACTIONS:isize=58; 
		pub const COMPENSATION:isize=59; 
		pub const COMPUTE:isize=60; 
		pub const CONCATENATE:isize=61; 
		pub const CONSTRAINT:isize=62; 
		pub const CONTAINS:isize=63; 
		pub const COST:isize=64; 
		pub const COUNT:isize=65; 
		pub const CREATE:isize=66; 
		pub const CROSS:isize=67; 
		pub const CUBE:isize=68; 
		pub const CURRENT:isize=69; 
		pub const CURRENT_DATE:isize=70; 
		pub const CURRENT_TIME:isize=71; 
		pub const CURRENT_TIMESTAMP:isize=72; 
		pub const CURRENT_USER:isize=73; 
		pub const DAY:isize=74; 
		pub const DAYS:isize=75; 
		pub const DAYOFYEAR:isize=76; 
		pub const DATA:isize=77; 
		pub const DATE:isize=78; 
		pub const DATABASE:isize=79; 
		pub const DATABASES:isize=80; 
		pub const DATEADD:isize=81; 
		pub const DATE_ADD:isize=82; 
		pub const DATEDIFF:isize=83; 
		pub const DATE_DIFF:isize=84; 
		pub const DBPROPERTIES:isize=85; 
		pub const DEC:isize=86; 
		pub const DECIMAL:isize=87; 
		pub const DECLARE:isize=88; 
		pub const DECODE:isize=89; 
		pub const DEFAULT:isize=90; 
		pub const DEFINED:isize=91; 
		pub const DEFINER:isize=92; 
		pub const DELETE:isize=93; 
		pub const DELIMITED:isize=94; 
		pub const DESC:isize=95; 
		pub const DESCRIBE:isize=96; 
		pub const DETERMINISTIC:isize=97; 
		pub const DFS:isize=98; 
		pub const DIRECTORIES:isize=99; 
		pub const DIRECTORY:isize=100; 
		pub const DISTINCT:isize=101; 
		pub const DISTRIBUTE:isize=102; 
		pub const DIV:isize=103; 
		pub const DO:isize=104; 
		pub const DOUBLE:isize=105; 
		pub const DROP:isize=106; 
		pub const ELSE:isize=107; 
		pub const END:isize=108; 
		pub const ESCAPE:isize=109; 
		pub const ESCAPED:isize=110; 
		pub const EVOLUTION:isize=111; 
		pub const EXCEPT:isize=112; 
		pub const EXCHANGE:isize=113; 
		pub const EXCLUDE:isize=114; 
		pub const EXECUTE:isize=115; 
		pub const EXISTS:isize=116; 
		pub const EXPLAIN:isize=117; 
		pub const EXPORT:isize=118; 
		pub const EXTENDED:isize=119; 
		pub const EXTERNAL:isize=120; 
		pub const EXTRACT:isize=121; 
		pub const FALSE:isize=122; 
		pub const FETCH:isize=123; 
		pub const FIELDS:isize=124; 
		pub const FILTER:isize=125; 
		pub const FILEFORMAT:isize=126; 
		pub const FIRST:isize=127; 
		pub const FLOAT:isize=128; 
		pub const FOLLOWING:isize=129; 
		pub const FOR:isize=130; 
		pub const FOREIGN:isize=131; 
		pub const FORMAT:isize=132; 
		pub const FORMATTED:isize=133; 
		pub const FROM:isize=134; 
		pub const FROM_JSON:isize=135; 
		pub const FULL:isize=136; 
		pub const FUNCTION:isize=137; 
		pub const FUNCTIONS:isize=138; 
		pub const GENERATED:isize=139; 
		pub const GLOBAL:isize=140; 
		pub const GRANT:isize=141; 
		pub const GROUP:isize=142; 
		pub const GROUPING:isize=143; 
		pub const HAVING:isize=144; 
		pub const HOUR:isize=145; 
		pub const HOURS:isize=146; 
		pub const IDENTIFIER_KW:isize=147; 
		pub const IDENTITY:isize=148; 
		pub const IF:isize=149; 
		pub const IGNORE:isize=150; 
		pub const IMMEDIATE:isize=151; 
		pub const IMPORT:isize=152; 
		pub const IN:isize=153; 
		pub const INCLUDE:isize=154; 
		pub const INDEX:isize=155; 
		pub const INDEXES:isize=156; 
		pub const INNER:isize=157; 
		pub const INPATH:isize=158; 
		pub const INPUT:isize=159; 
		pub const INPUTFORMAT:isize=160; 
		pub const INSERT:isize=161; 
		pub const INTERSECT:isize=162; 
		pub const INTERVAL:isize=163; 
		pub const INT:isize=164; 
		pub const INTEGER:isize=165; 
		pub const INTO:isize=166; 
		pub const INVOKER:isize=167; 
		pub const IS:isize=168; 
		pub const ITEMS:isize=169; 
		pub const ILIKE:isize=170; 
		pub const JOIN:isize=171; 
		pub const KEY:isize=172; 
		pub const KEYS:isize=173; 
		pub const LANGUAGE:isize=174; 
		pub const LAST:isize=175; 
		pub const LATERAL:isize=176; 
		pub const LAZY:isize=177; 
		pub const LEADING:isize=178; 
		pub const LEFT:isize=179; 
		pub const LIKE:isize=180; 
		pub const LIMIT:isize=181; 
		pub const LINES:isize=182; 
		pub const LIST:isize=183; 
		pub const LISTAGG:isize=184; 
		pub const LIVE:isize=185; 
		pub const LOAD:isize=186; 
		pub const LOCAL:isize=187; 
		pub const LOCATION:isize=188; 
		pub const LOCK:isize=189; 
		pub const LOCKS:isize=190; 
		pub const LOGICAL:isize=191; 
		pub const LONG:isize=192; 
		pub const MACRO:isize=193; 
		pub const MAP:isize=194; 
		pub const MAP_FROM_ENTRIES:isize=195; 
		pub const MATCHED:isize=196; 
		pub const MATERIALIZED:isize=197; 
		pub const MERGE:isize=198; 
		pub const MICROSECOND:isize=199; 
		pub const MICROSECONDS:isize=200; 
		pub const MILLISECOND:isize=201; 
		pub const MILLISECONDS:isize=202; 
		pub const MINUS_KW:isize=203; 
		pub const MINUTE:isize=204; 
		pub const MINUTES:isize=205; 
		pub const MODE:isize=206; 
		pub const MODIFIES:isize=207; 
		pub const MONTH:isize=208; 
		pub const MONTHS:isize=209; 
		pub const MSCK:isize=210; 
		pub const NAME:isize=211; 
		pub const NAMESPACE:isize=212; 
		pub const NAMESPACES:isize=213; 
		pub const NAMED_STRUCT:isize=214; 
		pub const NANOSECOND:isize=215; 
		pub const NANOSECONDS:isize=216; 
		pub const NATURAL:isize=217; 
		pub const NO:isize=218; 
		pub const NONE:isize=219; 
		pub const NOT:isize=220; 
		pub const NULL:isize=221; 
		pub const NULLS:isize=222; 
		pub const NUMERIC:isize=223; 
		pub const OF:isize=224; 
		pub const OFFSET:isize=225; 
		pub const ON:isize=226; 
		pub const ONLY:isize=227; 
		pub const OPTIMIZE:isize=228; 
		pub const OPTION:isize=229; 
		pub const OPTIONS:isize=230; 
		pub const OR:isize=231; 
		pub const ORDER:isize=232; 
		pub const OUT:isize=233; 
		pub const OUTER:isize=234; 
		pub const OUTPUTFORMAT:isize=235; 
		pub const OVER:isize=236; 
		pub const OVERLAPS:isize=237; 
		pub const OVERLAY:isize=238; 
		pub const OVERWRITE:isize=239; 
		pub const PARTITION:isize=240; 
		pub const PARTITIONED:isize=241; 
		pub const PARTITIONS:isize=242; 
		pub const PERCENT_KW:isize=243; 
		pub const PERCENTILE_CONT:isize=244; 
		pub const PERCENTILE_DISC:isize=245; 
		pub const PIVOT:isize=246; 
		pub const PLACING:isize=247; 
		pub const POSITION:isize=248; 
		pub const PRECEDING:isize=249; 
		pub const PRIMARY:isize=250; 
		pub const PRINCIPALS:isize=251; 
		pub const PROPERTIES:isize=252; 
		pub const PRUNE:isize=253; 
		pub const PURGE:isize=254; 
		pub const QUALIFY:isize=255; 
		pub const QUARTER:isize=256; 
		pub const QUERY:isize=257; 
		pub const RANGE:isize=258; 
		pub const READS:isize=259; 
		pub const REAL:isize=260; 
		pub const RECORDREADER:isize=261; 
		pub const RECORDWRITER:isize=262; 
		pub const RECOVER:isize=263; 
		pub const RECURSIVE:isize=264; 
		pub const REDUCE:isize=265; 
		pub const REGEXP:isize=266; 
		pub const REFERENCE:isize=267; 
		pub const REFERENCES:isize=268; 
		pub const REFRESH:isize=269; 
		pub const RENAME:isize=270; 
		pub const REPAIR:isize=271; 
		pub const REPEATABLE:isize=272; 
		pub const REPLACE:isize=273; 
		pub const RESET:isize=274; 
		pub const RESPECT:isize=275; 
		pub const RESTRICT:isize=276; 
		pub const RETURN:isize=277; 
		pub const RETURNS:isize=278; 
		pub const REVOKE:isize=279; 
		pub const RIGHT:isize=280; 
		pub const RLIKE:isize=281; 
		pub const ROLE:isize=282; 
		pub const ROLES:isize=283; 
		pub const ROLLBACK:isize=284; 
		pub const ROLLUP:isize=285; 
		pub const ROW:isize=286; 
		pub const ROWS:isize=287; 
		pub const SECOND:isize=288; 
		pub const SECONDS:isize=289; 
		pub const SCHEMA:isize=290; 
		pub const SCHEMAS:isize=291; 
		pub const SECURITY:isize=292; 
		pub const SELECT:isize=293; 
		pub const SEMI:isize=294; 
		pub const SEPARATED:isize=295; 
		pub const SERDE:isize=296; 
		pub const SERDEPROPERTIES:isize=297; 
		pub const SESSION_USER:isize=298; 
		pub const SET:isize=299; 
		pub const SETS:isize=300; 
		pub const SHORT:isize=301; 
		pub const SHOW:isize=302; 
		pub const SINGLE:isize=303; 
		pub const SKEWED:isize=304; 
		pub const SMALLINT:isize=305; 
		pub const SOME:isize=306; 
		pub const SORT:isize=307; 
		pub const SORTED:isize=308; 
		pub const SOURCE:isize=309; 
		pub const SPECIFIC:isize=310; 
		pub const SQL:isize=311; 
		pub const START:isize=312; 
		pub const STATISTICS:isize=313; 
		pub const STORED:isize=314; 
		pub const STRATIFY:isize=315; 
		pub const STREAM:isize=316; 
		pub const STREAMING:isize=317; 
		pub const STRUCT:isize=318; 
		pub const SUBSTR:isize=319; 
		pub const SUBSTRING:isize=320; 
		pub const SYNC:isize=321; 
		pub const SYSTEM_TIME:isize=322; 
		pub const SYSTEM_VERSION:isize=323; 
		pub const TABLE:isize=324; 
		pub const TABLES:isize=325; 
		pub const TABLESAMPLE:isize=326; 
		pub const TARGET:isize=327; 
		pub const TBLPROPERTIES:isize=328; 
		pub const TEMP:isize=329; 
		pub const TEMPORARY:isize=330; 
		pub const TERMINATED:isize=331; 
		pub const STRING_KW:isize=332; 
		pub const THEN:isize=333; 
		pub const TIME:isize=334; 
		pub const TIMEDIFF:isize=335; 
		pub const TIMESTAMP:isize=336; 
		pub const TIMESTAMPADD:isize=337; 
		pub const TIMESTAMPDIFF:isize=338; 
		pub const TIMESTAMP_LTZ:isize=339; 
		pub const TIMESTAMP_NTZ:isize=340; 
		pub const TINYINT:isize=341; 
		pub const TO:isize=342; 
		pub const TOUCH:isize=343; 
		pub const TRAILING:isize=344; 
		pub const TRANSACTION:isize=345; 
		pub const TRANSACTIONS:isize=346; 
		pub const TRANSFORM:isize=347; 
		pub const TRIM:isize=348; 
		pub const TRUE:isize=349; 
		pub const TRUNCATE:isize=350; 
		pub const TRY_CAST:isize=351; 
		pub const TYPE:isize=352; 
		pub const UNARCHIVE:isize=353; 
		pub const UNBOUNDED:isize=354; 
		pub const UNCACHE:isize=355; 
		pub const UNION:isize=356; 
		pub const UNIQUE:isize=357; 
		pub const UNKNOWN:isize=358; 
		pub const UNLOCK:isize=359; 
		pub const UNPIVOT:isize=360; 
		pub const UNSET:isize=361; 
		pub const UPDATE:isize=362; 
		pub const USE:isize=363; 
		pub const USER:isize=364; 
		pub const USING:isize=365; 
		pub const VALUES:isize=366; 
		pub const VAR:isize=367; 
		pub const VARCHAR:isize=368; 
		pub const VARIANT:isize=369; 
		pub const VERSION:isize=370; 
		pub const VIEW:isize=371; 
		pub const VIEWS:isize=372; 
		pub const VOID:isize=373; 
		pub const WEEK:isize=374; 
		pub const WEEKS:isize=375; 
		pub const WHEN:isize=376; 
		pub const WHERE:isize=377; 
		pub const WHILE:isize=378; 
		pub const WINDOW:isize=379; 
		pub const WITH:isize=380; 
		pub const WITHIN:isize=381; 
		pub const YEAR:isize=382; 
		pub const YEARS:isize=383; 
		pub const ZONE:isize=384; 
		pub const LPAREN:isize=385; 
		pub const RPAREN:isize=386; 
		pub const LBRACKET:isize=387; 
		pub const RBRACKET:isize=388; 
		pub const DOT:isize=389; 
		pub const EQ:isize=390; 
		pub const DOUBLE_EQ:isize=391; 
		pub const BANG:isize=392; 
		pub const NSEQ:isize=393; 
		pub const HENT_START:isize=394; 
		pub const HENT_END:isize=395; 
		pub const NEQ:isize=396; 
		pub const LT:isize=397; 
		pub const LTE:isize=398; 
		pub const GT:isize=399; 
		pub const GTE:isize=400; 
		pub const PLUS:isize=401; 
		pub const MINUS:isize=402; 
		pub const ASTERISK:isize=403; 
		pub const SLASH:isize=404; 
		pub const PERCENT:isize=405; 
		pub const CONCAT:isize=406; 
		pub const QUESTION_MARK:isize=407; 
		pub const SEMI_COLON:isize=408; 
		pub const COLON:isize=409; 
		pub const DOLLAR:isize=410; 
		pub const BITWISE_AND:isize=411; 
		pub const BITWISE_OR:isize=412; 
		pub const BITWISE_XOR:isize=413; 
		pub const BITWISE_SHIFT_LEFT:isize=414; 
		pub const POSIX:isize=415; 
		pub const ESCAPE_SEQUENCE:isize=416; 
		pub const STRING:isize=417; 
		pub const DOUBLEQUOTED_STRING:isize=418; 
		pub const UNICODE_STRING:isize=419; 
		pub const INTEGER_VALUE:isize=420; 
		pub const BIGINT_VALUE:isize=421; 
		pub const SMALLINT_VALUE:isize=422; 
		pub const TINYINT_VALUE:isize=423; 
		pub const EXPONENT_VALUE:isize=424; 
		pub const DECIMAL_VALUE:isize=425; 
		pub const FLOAT_VALUE:isize=426; 
		pub const DOUBLE_VALUE:isize=427; 
		pub const BIGDECIMAL_VALUE:isize=428; 
		pub const IDENTIFIER:isize=429; 
		pub const BACKQUOTED_IDENTIFIER:isize=430; 
		pub const VARIABLE:isize=431; 
		pub const SIMPLE_COMMENT:isize=432; 
		pub const BRACKETED_COMMENT:isize=433; 
		pub const WS:isize=434; 
		pub const UNPAIRED_TOKEN:isize=435; 
		pub const UNRECOGNIZED:isize=436;
	pub const RULE_multipleStatement:usize = 0; 
	pub const RULE_singleStatement:usize = 1; 
	pub const RULE_standaloneExpression:usize = 2; 
	pub const RULE_standaloneQualifiedName:usize = 3; 
	pub const RULE_standaloneType:usize = 4; 
	pub const RULE_statement:usize = 5; 
	pub const RULE_tableElements:usize = 6; 
	pub const RULE_identifierReference:usize = 7; 
	pub const RULE_identifierCommentList:usize = 8; 
	pub const RULE_identifierComment:usize = 9; 
	pub const RULE_schemaBinding:usize = 10; 
	pub const RULE_createTableClauses:usize = 11; 
	pub const RULE_tableProvider:usize = 12; 
	pub const RULE_partitionField:usize = 13; 
	pub const RULE_transform:usize = 14; 
	pub const RULE_transformArgument:usize = 15; 
	pub const RULE_colType:usize = 16; 
	pub const RULE_skewSpec:usize = 17; 
	pub const RULE_clusterBySpec:usize = 18; 
	pub const RULE_bucketSpec:usize = 19; 
	pub const RULE_constantList:usize = 20; 
	pub const RULE_nestedConstantList:usize = 21; 
	pub const RULE_rowFormat:usize = 22; 
	pub const RULE_createFileFormat:usize = 23; 
	pub const RULE_fileFormat:usize = 24; 
	pub const RULE_storageHandler:usize = 25; 
	pub const RULE_locationSpec:usize = 26; 
	pub const RULE_literalType:usize = 27; 
	pub const RULE_dmlStatementNoWith:usize = 28; 
	pub const RULE_ctes:usize = 29; 
	pub const RULE_insertInto:usize = 30; 
	pub const RULE_multiInsertQueryBody:usize = 31; 
	pub const RULE_tableAlias:usize = 32; 
	pub const RULE_whereClause:usize = 33; 
	pub const RULE_setClause:usize = 34; 
	pub const RULE_matchedClause:usize = 35; 
	pub const RULE_notMatchedClause:usize = 36; 
	pub const RULE_notMatchedBySourceClause:usize = 37; 
	pub const RULE_optionsClause:usize = 38; 
	pub const RULE_partitionSpec:usize = 39; 
	pub const RULE_lateralView:usize = 40; 
	pub const RULE_fromStatementBody:usize = 41; 
	pub const RULE_queryOrganization:usize = 42; 
	pub const RULE_assignmentList:usize = 43; 
	pub const RULE_assignment:usize = 44; 
	pub const RULE_matchedAction:usize = 45; 
	pub const RULE_notMatchedAction:usize = 46; 
	pub const RULE_notMatchedBySourceAction:usize = 47; 
	pub const RULE_partitionVal:usize = 48; 
	pub const RULE_namedExpressionSeq:usize = 49; 
	pub const RULE_namedExpression:usize = 50; 
	pub const RULE_unpivotNullClause:usize = 51; 
	pub const RULE_transformClause:usize = 52; 
	pub const RULE_selectClause:usize = 53; 
	pub const RULE_havingClause:usize = 54; 
	pub const RULE_multipartIdentifierList:usize = 55; 
	pub const RULE_expressionSeq:usize = 56; 
	pub const RULE_colTypeList:usize = 57; 
	pub const RULE_hint:usize = 58; 
	pub const RULE_hintStatement:usize = 59; 
	pub const RULE_query:usize = 60; 
	pub const RULE_with:usize = 61; 
	pub const RULE_tableElement:usize = 62; 
	pub const RULE_tableConstraint:usize = 63; 
	pub const RULE_columnDefinition:usize = 64; 
	pub const RULE_columnDefinitionForView:usize = 65; 
	pub const RULE_fieldDefinitions:usize = 66; 
	pub const RULE_fieldDefinition:usize = 67; 
	pub const RULE_columnName:usize = 68; 
	pub const RULE_columnNameComponent:usize = 69; 
	pub const RULE_columnSchemaWithMetadata:usize = 70; 
	pub const RULE_colDefinitionOption:usize = 71; 
	pub const RULE_generationExpression:usize = 72; 
	pub const RULE_defaultExpression:usize = 73; 
	pub const RULE_columnOptionList:usize = 74; 
	pub const RULE_columnOption:usize = 75; 
	pub const RULE_columnSchema:usize = 76; 
	pub const RULE_properties:usize = 77; 
	pub const RULE_propertyAssignments:usize = 78; 
	pub const RULE_property:usize = 79; 
	pub const RULE_propertyKey:usize = 80; 
	pub const RULE_propertyValue:usize = 81; 
	pub const RULE_queryNoWith:usize = 82; 
	pub const RULE_queryLimit:usize = 83; 
	pub const RULE_queryLimitTarget:usize = 84; 
	pub const RULE_windowClause:usize = 85; 
	pub const RULE_limitRowCount:usize = 86; 
	pub const RULE_rowCount:usize = 87; 
	pub const RULE_queryTerm:usize = 88; 
	pub const RULE_setOperation:usize = 89; 
	pub const RULE_setOperator:usize = 90; 
	pub const RULE_setOperationIntersect:usize = 91; 
	pub const RULE_setIntersectOperator:usize = 92; 
	pub const RULE_setQuantifier:usize = 93; 
	pub const RULE_inlineTable:usize = 94; 
	pub const RULE_queryPrimary:usize = 95; 
	pub const RULE_sortItem:usize = 96; 
	pub const RULE_querySpecification:usize = 97; 
	pub const RULE_querySelectItems:usize = 98; 
	pub const RULE_aggregationClause:usize = 99; 
	pub const RULE_groupBy:usize = 100; 
	pub const RULE_groupingElement:usize = 101; 
	pub const RULE_groupingAnalytics:usize = 102; 
	pub const RULE_grpSetsElement:usize = 103; 
	pub const RULE_groupingSet:usize = 104; 
	pub const RULE_windowDefinition:usize = 105; 
	pub const RULE_windowSpecification:usize = 106; 
	pub const RULE_windowSpecificationPartitionBy:usize = 107; 
	pub const RULE_orderBy:usize = 108; 
	pub const RULE_namedQuery:usize = 109; 
	pub const RULE_selectItemAlias:usize = 110; 
	pub const RULE_selectItem:usize = 111; 
	pub const RULE_structItem:usize = 112; 
	pub const RULE_multiSelect:usize = 113; 
	pub const RULE_selectStar:usize = 114; 
	pub const RULE_relation:usize = 115; 
	pub const RULE_joinType:usize = 116; 
	pub const RULE_joinCriteria:usize = 117; 
	pub const RULE_sampledRelationTarget:usize = 118; 
	pub const RULE_sampledRelation:usize = 119; 
	pub const RULE_sample:usize = 120; 
	pub const RULE_sampleOperator:usize = 121; 
	pub const RULE_sampleMethod:usize = 122; 
	pub const RULE_trimsSpecification:usize = 123; 
	pub const RULE_variableDefinition:usize = 124; 
	pub const RULE_pivotedRelationTarget:usize = 125; 
	pub const RULE_lateralViewRelation:usize = 126; 
	pub const RULE_lateralViewRelationTarget:usize = 127; 
	pub const RULE_extensibleRelation:usize = 128; 
	pub const RULE_extensibleRelationTarget:usize = 129; 
	pub const RULE_relationExtension:usize = 130; 
	pub const RULE_joinRelation:usize = 131; 
	pub const RULE_pivotedRelation:usize = 132; 
	pub const RULE_pivotAggregates:usize = 133; 
	pub const RULE_pivotFrom:usize = 134; 
	pub const RULE_pivotInto:usize = 135; 
	pub const RULE_pivotAsAlias:usize = 136; 
	pub const RULE_singleColumnUnpivot:usize = 137; 
	pub const RULE_columnsToUnpivot:usize = 138; 
	pub const RULE_unpivotAlias:usize = 139; 
	pub const RULE_multiColumnUnpivot:usize = 140; 
	pub const RULE_valueColumnSet:usize = 141; 
	pub const RULE_unpivotColumnSet:usize = 142; 
	pub const RULE_columnSetsToUnpivot:usize = 143; 
	pub const RULE_columnUnpivot:usize = 144; 
	pub const RULE_pivotIntos:usize = 145; 
	pub const RULE_pivotOperator:usize = 146; 
	pub const RULE_aliasedRelationTarget:usize = 147; 
	pub const RULE_temporalClause:usize = 148; 
	pub const RULE_version:usize = 149; 
	pub const RULE_aliasedRelation:usize = 150; 
	pub const RULE_columnAliases:usize = 151; 
	pub const RULE_relationPrimary:usize = 152; 
	pub const RULE_tableFunctionCall:usize = 153; 
	pub const RULE_tableFunctionArgumentName:usize = 154; 
	pub const RULE_tableFunctionArgument:usize = 155; 
	pub const RULE_tableArgument:usize = 156; 
	pub const RULE_tableArgumentRelation:usize = 157; 
	pub const RULE_expression:usize = 158; 
	pub const RULE_booleanExpression:usize = 159; 
	pub const RULE_comparisonPredicate:usize = 160; 
	pub const RULE_nonComparisonExpression:usize = 161; 
	pub const RULE_predicate:usize = 162; 
	pub const RULE_valueExpression:usize = 163; 
	pub const RULE_primaryExpression:usize = 164; 
	pub const RULE_functionCallHead:usize = 165; 
	pub const RULE_functionCallTail:usize = 166; 
	pub const RULE_callArgument:usize = 167; 
	pub const RULE_functionExtraArguments:usize = 168; 
	pub const RULE_constant:usize = 169; 
	pub const RULE_jsonPath:usize = 170; 
	pub const RULE_jsonPathElement1:usize = 171; 
	pub const RULE_jsonPathElement2:usize = 172; 
	pub const RULE_functionName:usize = 173; 
	pub const RULE_field:usize = 174; 
	pub const RULE_nullTreatment:usize = 175; 
	pub const RULE_string:usize = 176; 
	pub const RULE_timeZoneSpecifier:usize = 177; 
	pub const RULE_comparisonOperator:usize = 178; 
	pub const RULE_comparisonQuantifier:usize = 179; 
	pub const RULE_booleanValue:usize = 180; 
	pub const RULE_standaloneInterval:usize = 181; 
	pub const RULE_interval:usize = 182; 
	pub const RULE_intervalValue:usize = 183; 
	pub const RULE_intervalValueField:usize = 184; 
	pub const RULE_intervalTypeField:usize = 185; 
	pub const RULE_typeIdentifier:usize = 186; 
	pub const RULE_collateClause:usize = 187; 
	pub const RULE_type_:usize = 188; 
	pub const RULE_nonnullableType:usize = 189; 
	pub const RULE_rowField:usize = 190; 
	pub const RULE_commentSpec:usize = 191; 
	pub const RULE_typeParameter:usize = 192; 
	pub const RULE_whenClause:usize = 193; 
	pub const RULE_filter:usize = 194; 
	pub const RULE_over:usize = 195; 
	pub const RULE_windowFrame:usize = 196; 
	pub const RULE_frameExtent:usize = 197; 
	pub const RULE_frameBound:usize = 198; 
	pub const RULE_privilege:usize = 199; 
	pub const RULE_qualifiedName:usize = 200; 
	pub const RULE_pathExpression:usize = 201; 
	pub const RULE_queryPeriod:usize = 202; 
	pub const RULE_rangeType:usize = 203; 
	pub const RULE_principal:usize = 204; 
	pub const RULE_identifier:usize = 205; 
	pub const RULE_strictIdentifier:usize = 206; 
	pub const RULE_quotedIdentifier:usize = 207; 
	pub const RULE_pathComponent:usize = 208; 
	pub const RULE_standaloneIdentifier:usize = 209; 
	pub const RULE_identifierList:usize = 210; 
	pub const RULE_identifierSeq:usize = 211; 
	pub const RULE_number:usize = 212; 
	pub const RULE_prestoShowFunctionType:usize = 213; 
	pub const RULE_prestoShowFunctionRowField:usize = 214; 
	pub const RULE_prestoShowFunctionTypes:usize = 215; 
	pub const RULE_strictNonReserved:usize = 216; 
	pub const RULE_nonReserved:usize = 217;
	pub const ruleNames: [&'static str; 218] =  [
		"multipleStatement", "singleStatement", "standaloneExpression", "standaloneQualifiedName", 
		"standaloneType", "statement", "tableElements", "identifierReference", 
		"identifierCommentList", "identifierComment", "schemaBinding", "createTableClauses", 
		"tableProvider", "partitionField", "transform", "transformArgument", "colType", 
		"skewSpec", "clusterBySpec", "bucketSpec", "constantList", "nestedConstantList", 
		"rowFormat", "createFileFormat", "fileFormat", "storageHandler", "locationSpec", 
		"literalType", "dmlStatementNoWith", "ctes", "insertInto", "multiInsertQueryBody", 
		"tableAlias", "whereClause", "setClause", "matchedClause", "notMatchedClause", 
		"notMatchedBySourceClause", "optionsClause", "partitionSpec", "lateralView", 
		"fromStatementBody", "queryOrganization", "assignmentList", "assignment", 
		"matchedAction", "notMatchedAction", "notMatchedBySourceAction", "partitionVal", 
		"namedExpressionSeq", "namedExpression", "unpivotNullClause", "transformClause", 
		"selectClause", "havingClause", "multipartIdentifierList", "expressionSeq", 
		"colTypeList", "hint", "hintStatement", "query", "with", "tableElement", 
		"tableConstraint", "columnDefinition", "columnDefinitionForView", "fieldDefinitions", 
		"fieldDefinition", "columnName", "columnNameComponent", "columnSchemaWithMetadata", 
		"colDefinitionOption", "generationExpression", "defaultExpression", "columnOptionList", 
		"columnOption", "columnSchema", "properties", "propertyAssignments", "property", 
		"propertyKey", "propertyValue", "queryNoWith", "queryLimit", "queryLimitTarget", 
		"windowClause", "limitRowCount", "rowCount", "queryTerm", "setOperation", 
		"setOperator", "setOperationIntersect", "setIntersectOperator", "setQuantifier", 
		"inlineTable", "queryPrimary", "sortItem", "querySpecification", "querySelectItems", 
		"aggregationClause", "groupBy", "groupingElement", "groupingAnalytics", 
		"grpSetsElement", "groupingSet", "windowDefinition", "windowSpecification", 
		"windowSpecificationPartitionBy", "orderBy", "namedQuery", "selectItemAlias", 
		"selectItem", "structItem", "multiSelect", "selectStar", "relation", "joinType", 
		"joinCriteria", "sampledRelationTarget", "sampledRelation", "sample", 
		"sampleOperator", "sampleMethod", "trimsSpecification", "variableDefinition", 
		"pivotedRelationTarget", "lateralViewRelation", "lateralViewRelationTarget", 
		"extensibleRelation", "extensibleRelationTarget", "relationExtension", 
		"joinRelation", "pivotedRelation", "pivotAggregates", "pivotFrom", "pivotInto", 
		"pivotAsAlias", "singleColumnUnpivot", "columnsToUnpivot", "unpivotAlias", 
		"multiColumnUnpivot", "valueColumnSet", "unpivotColumnSet", "columnSetsToUnpivot", 
		"columnUnpivot", "pivotIntos", "pivotOperator", "aliasedRelationTarget", 
		"temporalClause", "version", "aliasedRelation", "columnAliases", "relationPrimary", 
		"tableFunctionCall", "tableFunctionArgumentName", "tableFunctionArgument", 
		"tableArgument", "tableArgumentRelation", "expression", "booleanExpression", 
		"comparisonPredicate", "nonComparisonExpression", "predicate", "valueExpression", 
		"primaryExpression", "functionCallHead", "functionCallTail", "callArgument", 
		"functionExtraArguments", "constant", "jsonPath", "jsonPathElement1", 
		"jsonPathElement2", "functionName", "field", "nullTreatment", "string", 
		"timeZoneSpecifier", "comparisonOperator", "comparisonQuantifier", "booleanValue", 
		"standaloneInterval", "interval", "intervalValue", "intervalValueField", 
		"intervalTypeField", "typeIdentifier", "collateClause", "type_", "nonnullableType", 
		"rowField", "commentSpec", "typeParameter", "whenClause", "filter", "over", 
		"windowFrame", "frameExtent", "frameBound", "privilege", "qualifiedName", 
		"pathExpression", "queryPeriod", "rangeType", "principal", "identifier", 
		"strictIdentifier", "quotedIdentifier", "pathComponent", "standaloneIdentifier", 
		"identifierList", "identifierSeq", "number", "prestoShowFunctionType", 
		"prestoShowFunctionRowField", "prestoShowFunctionTypes", "strictNonReserved", 
		"nonReserved"
	];


	pub const _LITERAL_NAMES: [Option<&'static str>;416] = [
		None, Some("'=>'"), Some("'->'"), Some("'?::'"), Some("'::'"), Some("'ADD'"), 
		Some("'AFTER'"), Some("'ALL'"), Some("'ALTER'"), Some("'ALWAYS'"), Some("'ANALYZE'"), 
		Some("'AND'"), Some("'ANTI'"), Some("'ANY'"), Some("'ANY_VALUE'"), Some("'ARCHIVE'"), 
		Some("'ARRAY'"), Some("'ARRAYS_ZIP'"), Some("'AS'"), Some("'ASC'"), Some("'AT'"), 
		Some("'AUTHORIZATION'"), Some("'BEGIN'"), Some("'BETWEEN'"), Some("'BIGINT'"), 
		Some("'BINARY'"), Some("'X'"), Some("'BINDING'"), Some("'BOOLEAN'"), Some("'BOTH'"), 
		Some("'BUCKET'"), Some("'BUCKETS'"), Some("'BY'"), Some("'BYTE'"), Some("'CACHE'"), 
		Some("'CALLED'"), Some("'CASCADE'"), Some("'CASE'"), Some("'CAST'"), Some("'CATALOG'"), 
		Some("'CATALOGS'"), Some("'CHANGE'"), Some("'CHAR'"), Some("'CHARACTER'"), 
		Some("'CHECK'"), Some("'CLEAR'"), Some("'CLUSTER'"), Some("'CLUSTERED'"), 
		Some("'CODEGEN'"), Some("'COLLATE'"), Some("'COLLATION'"), Some("'COLLECTION'"), 
		Some("'COLUMN'"), Some("'COLUMNS'"), Some("','"), Some("'COMMENT'"), Some("'COMMIT'"), 
		Some("'COMPACT'"), Some("'COMPACTIONS'"), Some("'COMPENSATION'"), Some("'COMPUTE'"), 
		Some("'CONCATENATE'"), Some("'CONSTRAINT'"), Some("'CONTAINS'"), Some("'COST'"), 
		Some("'COUNT'"), Some("'CREATE'"), Some("'CROSS'"), Some("'CUBE'"), Some("'CURRENT'"), 
		Some("'CURRENT_DATE'"), Some("'CURRENT_TIME'"), Some("'CURRENT_TIMESTAMP'"), 
		Some("'CURRENT_USER'"), Some("'DAY'"), Some("'DAYS'"), Some("'DAYOFYEAR'"), 
		Some("'DATA'"), Some("'DATE'"), Some("'DATABASE'"), Some("'DATABASES'"), 
		Some("'DATEADD'"), Some("'DATE_ADD'"), Some("'DATEDIFF'"), Some("'DATE_DIFF'"), 
		Some("'DBPROPERTIES'"), Some("'DEC'"), Some("'DECIMAL'"), Some("'DECLARE'"), 
		Some("'DECODE'"), Some("'DEFAULT'"), Some("'DEFINED'"), Some("'DEFINER'"), 
		Some("'DELETE'"), Some("'DELIMITED'"), Some("'DESC'"), Some("'DESCRIBE'"), 
		Some("'DETERMINISTIC'"), Some("'DFS'"), Some("'DIRECTORIES'"), Some("'DIRECTORY'"), 
		Some("'DISTINCT'"), Some("'DISTRIBUTE'"), Some("'DIV'"), Some("'DO'"), 
		Some("'DOUBLE'"), Some("'DROP'"), Some("'ELSE'"), Some("'END'"), Some("'ESCAPE'"), 
		Some("'ESCAPED'"), Some("'EVOLUTION'"), Some("'EXCEPT'"), Some("'EXCHANGE'"), 
		Some("'EXCLUDE'"), Some("'EXECUTE'"), Some("'EXISTS'"), Some("'EXPLAIN'"), 
		Some("'EXPORT'"), Some("'EXTENDED'"), Some("'EXTERNAL'"), Some("'EXTRACT'"), 
		Some("'FALSE'"), Some("'FETCH'"), Some("'FIELDS'"), Some("'FILTER'"), 
		Some("'FILEFORMAT'"), Some("'FIRST'"), Some("'FLOAT'"), Some("'FOLLOWING'"), 
		Some("'FOR'"), Some("'FOREIGN'"), Some("'FORMAT'"), Some("'FORMATTED'"), 
		Some("'FROM'"), Some("'FROM_JSON'"), Some("'FULL'"), Some("'FUNCTION'"), 
		Some("'FUNCTIONS'"), Some("'GENERATED'"), Some("'GLOBAL'"), Some("'GRANT'"), 
		Some("'GROUP'"), Some("'GROUPING'"), Some("'HAVING'"), Some("'HOUR'"), 
		Some("'HOURS'"), Some("'IDENTIFIER'"), Some("'IDENTITY'"), Some("'IF'"), 
		Some("'IGNORE'"), Some("'IMMEDIATE'"), Some("'IMPORT'"), Some("'IN'"), 
		Some("'INCLUDE'"), Some("'INDEX'"), Some("'INDEXES'"), Some("'INNER'"), 
		Some("'INPATH'"), Some("'INPUT'"), Some("'INPUTFORMAT'"), Some("'INSERT'"), 
		Some("'INTERSECT'"), Some("'INTERVAL'"), Some("'INT'"), Some("'INTEGER'"), 
		Some("'INTO'"), Some("'INVOKER'"), Some("'IS'"), Some("'ITEMS'"), Some("'ILIKE'"), 
		Some("'JOIN'"), Some("'KEY'"), Some("'KEYS'"), Some("'LANGUAGE'"), Some("'LAST'"), 
		Some("'LATERAL'"), Some("'LAZY'"), Some("'LEADING'"), Some("'LEFT'"), 
		Some("'LIKE'"), Some("'LIMIT'"), Some("'LINES'"), Some("'LIST'"), Some("'LISTAGG'"), 
		Some("'LIVE'"), Some("'LOAD'"), Some("'LOCAL'"), Some("'LOCATION'"), Some("'LOCK'"), 
		Some("'LOCKS'"), Some("'LOGICAL'"), Some("'LONG'"), Some("'MACRO'"), Some("'MAP'"), 
		Some("'MAP_FROM_ENTRIES'"), Some("'MATCHED'"), Some("'MATERIALIZED'"), 
		Some("'MERGE'"), Some("'MICROSECOND'"), Some("'MICROSECONDS'"), Some("'MILLISECOND'"), 
		Some("'MILLISECONDS'"), Some("'MINUS'"), Some("'MINUTE'"), Some("'MINUTES'"), 
		Some("'MODE'"), Some("'MODIFIES'"), Some("'MONTH'"), Some("'MONTHS'"), 
		Some("'MSCK'"), Some("'NAME'"), Some("'NAMESPACE'"), Some("'NAMESPACES'"), 
		Some("'NAMED_STRUCT'"), Some("'NANOSECOND'"), Some("'NANOSECONDS'"), Some("'NATURAL'"), 
		Some("'NO'"), Some("'NONE'"), Some("'NOT'"), Some("'NULL'"), Some("'NULLS'"), 
		Some("'NUMERIC'"), Some("'OF'"), Some("'OFFSET'"), Some("'ON'"), Some("'ONLY'"), 
		Some("'OPTIMIZE'"), Some("'OPTION'"), Some("'OPTIONS'"), Some("'OR'"), 
		Some("'ORDER'"), Some("'OUT'"), Some("'OUTER'"), Some("'OUTPUTFORMAT'"), 
		Some("'OVER'"), Some("'OVERLAPS'"), Some("'OVERLAY'"), Some("'OVERWRITE'"), 
		Some("'PARTITION'"), Some("'PARTITIONED'"), Some("'PARTITIONS'"), Some("'PERCENT'"), 
		Some("'PERCENTILE_CONT'"), Some("'PERCENTILE_DISC'"), Some("'PIVOT'"), 
		Some("'PLACING'"), Some("'POSITION'"), Some("'PRECEDING'"), Some("'PRIMARY'"), 
		Some("'PRINCIPALS'"), Some("'PROPERTIES'"), Some("'PRUNE'"), Some("'PURGE'"), 
		Some("'QUALIFY'"), Some("'QUARTER'"), Some("'QUERY'"), Some("'RANGE'"), 
		Some("'READS'"), Some("'REAL'"), Some("'RECORDREADER'"), Some("'RECORDWRITER'"), 
		Some("'RECOVER'"), Some("'RECURSIVE'"), Some("'REDUCE'"), Some("'REGEXP'"), 
		Some("'REFERENCE'"), Some("'REFERENCES'"), Some("'REFRESH'"), Some("'RENAME'"), 
		Some("'REPAIR'"), Some("'REPEATABLE'"), Some("'REPLACE'"), Some("'RESET'"), 
		Some("'RESPECT'"), Some("'RESTRICT'"), Some("'RETURN'"), Some("'RETURNS'"), 
		Some("'REVOKE'"), Some("'RIGHT'"), Some("'RLIKE'"), Some("'ROLE'"), Some("'ROLES'"), 
		Some("'ROLLBACK'"), Some("'ROLLUP'"), Some("'ROW'"), Some("'ROWS'"), Some("'SECOND'"), 
		Some("'SECONDS'"), Some("'SCHEMA'"), Some("'SCHEMAS'"), Some("'SECURITY'"), 
		Some("'SELECT'"), Some("'SEMI'"), Some("'SEPARATED'"), Some("'SERDE'"), 
		Some("'SERDEPROPERTIES'"), Some("'SESSION_USER'"), Some("'SET'"), Some("'SETS'"), 
		Some("'SHORT'"), Some("'SHOW'"), Some("'SINGLE'"), Some("'SKEWED'"), Some("'SMALLINT'"), 
		Some("'SOME'"), Some("'SORT'"), Some("'SORTED'"), Some("'SOURCE'"), Some("'SPECIFIC'"), 
		Some("'SQL'"), Some("'START'"), Some("'STATISTICS'"), Some("'STORED'"), 
		Some("'STRATIFY'"), Some("'STREAM'"), Some("'STREAMING'"), Some("'STRUCT'"), 
		Some("'SUBSTR'"), Some("'SUBSTRING'"), Some("'SYNC'"), Some("'SYSTEM_TIME'"), 
		Some("'SYSTEM_VERSION'"), Some("'TABLE'"), Some("'TABLES'"), Some("'TABLESAMPLE'"), 
		Some("'TARGET'"), Some("'TBLPROPERTIES'"), Some("'TEMP'"), Some("'TEMPORARY'"), 
		Some("'TERMINATED'"), Some("'STRING'"), Some("'THEN'"), Some("'TIME'"), 
		Some("'TIMEDIFF'"), Some("'TIMESTAMP'"), Some("'TIMESTAMPADD'"), Some("'TIMESTAMPDIFF'"), 
		Some("'TIMESTAMP_LTZ'"), Some("'TIMESTAMP_NTZ'"), Some("'TINYINT'"), Some("'TO'"), 
		Some("'TOUCH'"), Some("'TRAILING'"), Some("'TRANSACTION'"), Some("'TRANSACTIONS'"), 
		Some("'TRANSFORM'"), Some("'TRIM'"), Some("'TRUE'"), Some("'TRUNCATE'"), 
		Some("'TRY_CAST'"), Some("'TYPE'"), Some("'UNARCHIVE'"), Some("'UNBOUNDED'"), 
		Some("'UNCACHE'"), Some("'UNION'"), Some("'UNIQUE'"), Some("'UNKNOWN'"), 
		Some("'UNLOCK'"), Some("'UNPIVOT'"), Some("'UNSET'"), Some("'UPDATE'"), 
		Some("'USE'"), Some("'USER'"), Some("'USING'"), Some("'VALUES'"), Some("'VAR'"), 
		Some("'VARCHAR'"), Some("'VARIANT'"), Some("'VERSION'"), Some("'VIEW'"), 
		Some("'VIEWS'"), Some("'VOID'"), Some("'WEEK'"), Some("'WEEKS'"), Some("'WHEN'"), 
		Some("'WHERE'"), Some("'WHILE'"), Some("'WINDOW'"), Some("'WITH'"), Some("'WITHIN'"), 
		Some("'YEAR'"), Some("'YEARS'"), Some("'ZONE'"), Some("'('"), Some("')'"), 
		Some("'['"), Some("']'"), Some("'.'"), Some("'='"), Some("'=='"), Some("'!'"), 
		Some("'<=>'"), Some("'/*+'"), Some("'*/'"), None, Some("'<'"), Some("'<='"), 
		Some("'>'"), Some("'>='"), Some("'+'"), Some("'-'"), Some("'*'"), Some("'/'"), 
		Some("'%'"), Some("'||'"), Some("'?'"), Some("';'"), Some("':'"), Some("'$'"), 
		Some("'&'"), Some("'|'"), Some("'^'"), Some("'<<'"), Some("'~'")
	];
	pub const _SYMBOLIC_NAMES: [Option<&'static str>;437]  = [
		None, None, None, None, None, Some("ADD"), Some("AFTER"), Some("ALL"), 
		Some("ALTER"), Some("ALWAYS"), Some("ANALYZE"), Some("AND"), Some("ANTI"), 
		Some("ANY"), Some("ANY_VALUE"), Some("ARCHIVE"), Some("ARRAY"), Some("ARRAYS_ZIP"), 
		Some("AS"), Some("ASC"), Some("AT"), Some("AUTHORIZATION"), Some("BEGIN"), 
		Some("BETWEEN"), Some("BIGINT"), Some("BINARY"), Some("X_KW"), Some("BINDING"), 
		Some("BOOLEAN"), Some("BOTH"), Some("BUCKET"), Some("BUCKETS"), Some("BY"), 
		Some("BYTE"), Some("CACHE"), Some("CALLED"), Some("CASCADE"), Some("CASE"), 
		Some("CAST"), Some("CATALOG"), Some("CATALOGS"), Some("CHANGE"), Some("CHAR"), 
		Some("CHARACTER"), Some("CHECK"), Some("CLEAR"), Some("CLUSTER"), Some("CLUSTERED"), 
		Some("CODEGEN"), Some("COLLATE"), Some("COLLATION"), Some("COLLECTION"), 
		Some("COLUMN"), Some("COLUMNS"), Some("COMMA"), Some("COMMENT"), Some("COMMIT"), 
		Some("COMPACT"), Some("COMPACTIONS"), Some("COMPENSATION"), Some("COMPUTE"), 
		Some("CONCATENATE"), Some("CONSTRAINT"), Some("CONTAINS"), Some("COST"), 
		Some("COUNT"), Some("CREATE"), Some("CROSS"), Some("CUBE"), Some("CURRENT"), 
		Some("CURRENT_DATE"), Some("CURRENT_TIME"), Some("CURRENT_TIMESTAMP"), 
		Some("CURRENT_USER"), Some("DAY"), Some("DAYS"), Some("DAYOFYEAR"), Some("DATA"), 
		Some("DATE"), Some("DATABASE"), Some("DATABASES"), Some("DATEADD"), Some("DATE_ADD"), 
		Some("DATEDIFF"), Some("DATE_DIFF"), Some("DBPROPERTIES"), Some("DEC"), 
		Some("DECIMAL"), Some("DECLARE"), Some("DECODE"), Some("DEFAULT"), Some("DEFINED"), 
		Some("DEFINER"), Some("DELETE"), Some("DELIMITED"), Some("DESC"), Some("DESCRIBE"), 
		Some("DETERMINISTIC"), Some("DFS"), Some("DIRECTORIES"), Some("DIRECTORY"), 
		Some("DISTINCT"), Some("DISTRIBUTE"), Some("DIV"), Some("DO"), Some("DOUBLE"), 
		Some("DROP"), Some("ELSE"), Some("END"), Some("ESCAPE"), Some("ESCAPED"), 
		Some("EVOLUTION"), Some("EXCEPT"), Some("EXCHANGE"), Some("EXCLUDE"), 
		Some("EXECUTE"), Some("EXISTS"), Some("EXPLAIN"), Some("EXPORT"), Some("EXTENDED"), 
		Some("EXTERNAL"), Some("EXTRACT"), Some("FALSE"), Some("FETCH"), Some("FIELDS"), 
		Some("FILTER"), Some("FILEFORMAT"), Some("FIRST"), Some("FLOAT"), Some("FOLLOWING"), 
		Some("FOR"), Some("FOREIGN"), Some("FORMAT"), Some("FORMATTED"), Some("FROM"), 
		Some("FROM_JSON"), Some("FULL"), Some("FUNCTION"), Some("FUNCTIONS"), 
		Some("GENERATED"), Some("GLOBAL"), Some("GRANT"), Some("GROUP"), Some("GROUPING"), 
		Some("HAVING"), Some("HOUR"), Some("HOURS"), Some("IDENTIFIER_KW"), Some("IDENTITY"), 
		Some("IF"), Some("IGNORE"), Some("IMMEDIATE"), Some("IMPORT"), Some("IN"), 
		Some("INCLUDE"), Some("INDEX"), Some("INDEXES"), Some("INNER"), Some("INPATH"), 
		Some("INPUT"), Some("INPUTFORMAT"), Some("INSERT"), Some("INTERSECT"), 
		Some("INTERVAL"), Some("INT"), Some("INTEGER"), Some("INTO"), Some("INVOKER"), 
		Some("IS"), Some("ITEMS"), Some("ILIKE"), Some("JOIN"), Some("KEY"), Some("KEYS"), 
		Some("LANGUAGE"), Some("LAST"), Some("LATERAL"), Some("LAZY"), Some("LEADING"), 
		Some("LEFT"), Some("LIKE"), Some("LIMIT"), Some("LINES"), Some("LIST"), 
		Some("LISTAGG"), Some("LIVE"), Some("LOAD"), Some("LOCAL"), Some("LOCATION"), 
		Some("LOCK"), Some("LOCKS"), Some("LOGICAL"), Some("LONG"), Some("MACRO"), 
		Some("MAP"), Some("MAP_FROM_ENTRIES"), Some("MATCHED"), Some("MATERIALIZED"), 
		Some("MERGE"), Some("MICROSECOND"), Some("MICROSECONDS"), Some("MILLISECOND"), 
		Some("MILLISECONDS"), Some("MINUS_KW"), Some("MINUTE"), Some("MINUTES"), 
		Some("MODE"), Some("MODIFIES"), Some("MONTH"), Some("MONTHS"), Some("MSCK"), 
		Some("NAME"), Some("NAMESPACE"), Some("NAMESPACES"), Some("NAMED_STRUCT"), 
		Some("NANOSECOND"), Some("NANOSECONDS"), Some("NATURAL"), Some("NO"), 
		Some("NONE"), Some("NOT"), Some("NULL"), Some("NULLS"), Some("NUMERIC"), 
		Some("OF"), Some("OFFSET"), Some("ON"), Some("ONLY"), Some("OPTIMIZE"), 
		Some("OPTION"), Some("OPTIONS"), Some("OR"), Some("ORDER"), Some("OUT"), 
		Some("OUTER"), Some("OUTPUTFORMAT"), Some("OVER"), Some("OVERLAPS"), Some("OVERLAY"), 
		Some("OVERWRITE"), Some("PARTITION"), Some("PARTITIONED"), Some("PARTITIONS"), 
		Some("PERCENT_KW"), Some("PERCENTILE_CONT"), Some("PERCENTILE_DISC"), 
		Some("PIVOT"), Some("PLACING"), Some("POSITION"), Some("PRECEDING"), Some("PRIMARY"), 
		Some("PRINCIPALS"), Some("PROPERTIES"), Some("PRUNE"), Some("PURGE"), 
		Some("QUALIFY"), Some("QUARTER"), Some("QUERY"), Some("RANGE"), Some("READS"), 
		Some("REAL"), Some("RECORDREADER"), Some("RECORDWRITER"), Some("RECOVER"), 
		Some("RECURSIVE"), Some("REDUCE"), Some("REGEXP"), Some("REFERENCE"), 
		Some("REFERENCES"), Some("REFRESH"), Some("RENAME"), Some("REPAIR"), Some("REPEATABLE"), 
		Some("REPLACE"), Some("RESET"), Some("RESPECT"), Some("RESTRICT"), Some("RETURN"), 
		Some("RETURNS"), Some("REVOKE"), Some("RIGHT"), Some("RLIKE"), Some("ROLE"), 
		Some("ROLES"), Some("ROLLBACK"), Some("ROLLUP"), Some("ROW"), Some("ROWS"), 
		Some("SECOND"), Some("SECONDS"), Some("SCHEMA"), Some("SCHEMAS"), Some("SECURITY"), 
		Some("SELECT"), Some("SEMI"), Some("SEPARATED"), Some("SERDE"), Some("SERDEPROPERTIES"), 
		Some("SESSION_USER"), Some("SET"), Some("SETS"), Some("SHORT"), Some("SHOW"), 
		Some("SINGLE"), Some("SKEWED"), Some("SMALLINT"), Some("SOME"), Some("SORT"), 
		Some("SORTED"), Some("SOURCE"), Some("SPECIFIC"), Some("SQL"), Some("START"), 
		Some("STATISTICS"), Some("STORED"), Some("STRATIFY"), Some("STREAM"), 
		Some("STREAMING"), Some("STRUCT"), Some("SUBSTR"), Some("SUBSTRING"), 
		Some("SYNC"), Some("SYSTEM_TIME"), Some("SYSTEM_VERSION"), Some("TABLE"), 
		Some("TABLES"), Some("TABLESAMPLE"), Some("TARGET"), Some("TBLPROPERTIES"), 
		Some("TEMP"), Some("TEMPORARY"), Some("TERMINATED"), Some("STRING_KW"), 
		Some("THEN"), Some("TIME"), Some("TIMEDIFF"), Some("TIMESTAMP"), Some("TIMESTAMPADD"), 
		Some("TIMESTAMPDIFF"), Some("TIMESTAMP_LTZ"), Some("TIMESTAMP_NTZ"), Some("TINYINT"), 
		Some("TO"), Some("TOUCH"), Some("TRAILING"), Some("TRANSACTION"), Some("TRANSACTIONS"), 
		Some("TRANSFORM"), Some("TRIM"), Some("TRUE"), Some("TRUNCATE"), Some("TRY_CAST"), 
		Some("TYPE"), Some("UNARCHIVE"), Some("UNBOUNDED"), Some("UNCACHE"), Some("UNION"), 
		Some("UNIQUE"), Some("UNKNOWN"), Some("UNLOCK"), Some("UNPIVOT"), Some("UNSET"), 
		Some("UPDATE"), Some("USE"), Some("USER"), Some("USING"), Some("VALUES"), 
		Some("VAR"), Some("VARCHAR"), Some("VARIANT"), Some("VERSION"), Some("VIEW"), 
		Some("VIEWS"), Some("VOID"), Some("WEEK"), Some("WEEKS"), Some("WHEN"), 
		Some("WHERE"), Some("WHILE"), Some("WINDOW"), Some("WITH"), Some("WITHIN"), 
		Some("YEAR"), Some("YEARS"), Some("ZONE"), Some("LPAREN"), Some("RPAREN"), 
		Some("LBRACKET"), Some("RBRACKET"), Some("DOT"), Some("EQ"), Some("DOUBLE_EQ"), 
		Some("BANG"), Some("NSEQ"), Some("HENT_START"), Some("HENT_END"), Some("NEQ"), 
		Some("LT"), Some("LTE"), Some("GT"), Some("GTE"), Some("PLUS"), Some("MINUS"), 
		Some("ASTERISK"), Some("SLASH"), Some("PERCENT"), Some("CONCAT"), Some("QUESTION_MARK"), 
		Some("SEMI_COLON"), Some("COLON"), Some("DOLLAR"), Some("BITWISE_AND"), 
		Some("BITWISE_OR"), Some("BITWISE_XOR"), Some("BITWISE_SHIFT_LEFT"), Some("POSIX"), 
		Some("ESCAPE_SEQUENCE"), Some("STRING"), Some("DOUBLEQUOTED_STRING"), 
		Some("UNICODE_STRING"), Some("INTEGER_VALUE"), Some("BIGINT_VALUE"), Some("SMALLINT_VALUE"), 
		Some("TINYINT_VALUE"), Some("EXPONENT_VALUE"), Some("DECIMAL_VALUE"), 
		Some("FLOAT_VALUE"), Some("DOUBLE_VALUE"), Some("BIGDECIMAL_VALUE"), Some("IDENTIFIER"), 
		Some("BACKQUOTED_IDENTIFIER"), Some("VARIABLE"), Some("SIMPLE_COMMENT"), 
		Some("BRACKETED_COMMENT"), Some("WS"), Some("UNPAIRED_TOKEN"), Some("UNRECOGNIZED")
	];
	thread_local!{
	    static _shared_context_cache: Rc<PredictionContextCache> = Rc::new(PredictionContextCache::new());
		static VOCABULARY: Box<dyn Vocabulary> = Box::new(VocabularyImpl::new(_LITERAL_NAMES.iter(), _SYMBOLIC_NAMES.iter(), None));
	}


type BaseParserType<'input, I> =
	BaseParser<'input,DatabricksParserExt<'input>, I, DatabricksParserContextType , dyn DatabricksListener<'input> + 'input >;

type TokenType<'input> = <LocalTokenFactory<'input> as TokenFactory<'input>>::Tok;

pub type LocalTokenFactory<'input> = antlr_rust::token_factory::ArenaCommonFactory<'input>;

pub type DatabricksTreeWalker<'input,'a> =
	ParseTreeWalker<'input, 'a, DatabricksParserContextType , dyn DatabricksListener<'input> + 'a>;

/// Parser for Databricks grammar
pub struct DatabricksParser<'input,I,H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	base:BaseParserType<'input,I>,
	interpreter:Rc<ParserATNSimulator>,
	_shared_context_cache: Box<PredictionContextCache>,
    pub err_handler: H,
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn get_serialized_atn() -> &'static str { _serializedATN }

    pub fn set_error_strategy(&mut self, strategy: H) {
        self.err_handler = strategy
    }

    pub fn with_strategy(input: I, strategy: H) -> Self {
		antlr_rust::recognizer::check_version("0","3");
        let interpreter = Rc::new(ParserATNSimulator::new(
            _ATN.with(|atn| atn.clone()),
            _decision_to_DFA.with(|decision| decision.clone()),
            _shared_context_cache.with(|ctx| ctx.clone()),
        ));
		Self {
			base: BaseParser::new_base_parser(
				input,
				Rc::clone(&interpreter),
				DatabricksParserExt{
					_pd: Default::default(),
				}
			),
			interpreter,
            _shared_context_cache: Box::new(PredictionContextCache::new()),
            err_handler: strategy,
        }
    }

    pub fn add_error_listener(&mut self, listener: Box<(dyn ErrorListener<'input, BaseParser<'input, DatabricksParserExt<'input>, I, DatabricksParserContextType, (dyn DatabricksListener<'input> + 'input)>> + 'static)>) {
        self.base.add_error_listener(listener)
    }

	pub fn remove_error_listeners(&mut self) {
        self.base.remove_error_listeners()
    }
}

type DynStrategy<'input,I> = Box<dyn ErrorStrategy<'input,BaseParserType<'input,I>> + 'input>;

impl<'input, I> DatabricksParser<'input, I, DynStrategy<'input,I>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn with_dyn_strategy(input: I) -> Self{
    	Self::with_strategy(input,Box::new(DefaultErrorStrategy::new()))
    }
}

impl<'input, I> DatabricksParser<'input, I, DefaultErrorStrategy<'input,DatabricksParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn new(input: I) -> Self{
    	Self::with_strategy(input,DefaultErrorStrategy::new())
    }
}

/// Trait for monomorphized trait object that corresponds to the nodes of parse tree generated for DatabricksParser
pub trait DatabricksParserContext<'input>:
	for<'x> Listenable<dyn DatabricksListener<'input> + 'x > + 
	for<'x> Visitable<dyn DatabricksVisitor<'input> + 'x > + 
	ParserRuleContext<'input, TF=LocalTokenFactory<'input>, Ctx=DatabricksParserContextType>
{}

antlr_rust::coerce_from!{ 'input : DatabricksParserContext<'input> }

impl<'input, 'x, T> VisitableDyn<T> for dyn DatabricksParserContext<'input> + 'input
where
    T: DatabricksVisitor<'input> + 'x,
{
    fn accept_dyn(&self, visitor: &mut T) {
        self.accept(visitor as &mut (dyn DatabricksVisitor<'input> + 'x))
    }
}

impl<'input> DatabricksParserContext<'input> for TerminalNode<'input,DatabricksParserContextType> {}
impl<'input> DatabricksParserContext<'input> for ErrorNode<'input,DatabricksParserContextType> {}

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn DatabricksParserContext<'input> + 'input }

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn DatabricksListener<'input> + 'input }

pub struct DatabricksParserContextType;
antlr_rust::tid!{DatabricksParserContextType}

impl<'input> ParserNodeType<'input> for DatabricksParserContextType{
	type TF = LocalTokenFactory<'input>;
	type Type = dyn DatabricksParserContext<'input> + 'input;
}

impl<'input, I, H> Deref for DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    type Target = BaseParserType<'input,I>;

    fn deref(&self) -> &Self::Target {
        &self.base
    }
}

impl<'input, I, H> DerefMut for DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.base
    }
}

pub struct DatabricksParserExt<'input>{
	_pd: PhantomData<&'input str>,
}

impl<'input> DatabricksParserExt<'input>{
}
antlr_rust::tid! { DatabricksParserExt<'a> }

impl<'input> TokenAware<'input> for DatabricksParserExt<'input>{
	type TF = LocalTokenFactory<'input>;
}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> ParserRecog<'input, BaseParserType<'input,I>> for DatabricksParserExt<'input>{}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> Actions<'input, BaseParserType<'input,I>> for DatabricksParserExt<'input>{
	fn get_grammar_file_name(&self) -> & str{ "Databricks.g4"}

   	fn get_rule_names(&self) -> &[& str] {&ruleNames}

   	fn get_vocabulary(&self) -> &dyn Vocabulary { VOCABULARY.with(|v| unsafe { std::mem::transmute(&**v) }) }
	fn sempred(_localctx: Option<&(dyn DatabricksParserContext<'input> + 'input)>, rule_index: isize, pred_index: isize,
			   recog:&mut BaseParserType<'input,I>
	)->bool{
		match rule_index {
					127 => DatabricksParser::<'input,I,_>::lateralViewRelationTarget_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					129 => DatabricksParser::<'input,I,_>::extensibleRelationTarget_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					159 => DatabricksParser::<'input,I,_>::booleanExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					163 => DatabricksParser::<'input,I,_>::valueExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					164 => DatabricksParser::<'input,I,_>::primaryExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
			_ => true
		}
	}
}

impl<'input, I> DatabricksParser<'input, I, DefaultErrorStrategy<'input,DatabricksParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
	fn lateralViewRelationTarget_sempred(_localctx: Option<&LateralViewRelationTargetContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				0=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
	fn extensibleRelationTarget_sempred(_localctx: Option<&ExtensibleRelationTargetContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				1=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
	fn booleanExpression_sempred(_localctx: Option<&BooleanExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				2=>{
					recog.precpred(None, 2)
				}
				3=>{
					recog.precpred(None, 1)
				}
				4=>{
					recog.precpred(None, 5)
				}
			_ => true
		}
	}
	fn valueExpression_sempred(_localctx: Option<&ValueExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				5=>{
					recog.precpred(None, 5)
				}
				6=>{
					recog.precpred(None, 4)
				}
				7=>{
					recog.precpred(None, 3)
				}
				8=>{
					recog.precpred(None, 2)
				}
				9=>{
					recog.precpred(None, 1)
				}
				10=>{
					recog.precpred(None, 7)
				}
			_ => true
		}
	}
	fn primaryExpression_sempred(_localctx: Option<&PrimaryExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				11=>{
					recog.precpred(None, 35)
				}
				12=>{
					recog.precpred(None, 34)
				}
				13=>{
					recog.precpred(None, 12)
				}
				14=>{
					recog.precpred(None, 11)
				}
				15=>{
					recog.precpred(None, 10)
				}
				16=>{
					recog.precpred(None, 9)
				}
			_ => true
		}
	}
}
//------------------- multipleStatement ----------------
pub type MultipleStatementContextAll<'input> = MultipleStatementContext<'input>;


pub type MultipleStatementContext<'input> = BaseParserRuleContext<'input,MultipleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct MultipleStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for MultipleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MultipleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multipleStatement(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_multipleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MultipleStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_multipleStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multipleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multipleStatement }
}
antlr_rust::tid!{MultipleStatementContextExt<'a>}

impl<'input> MultipleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultipleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultipleStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultipleStatementContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<MultipleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement_all(&self) ->  Vec<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn statement(&self, i: usize) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SEMI_COLON, i)
}

}

impl<'input> MultipleStatementContextAttrs<'input> for MultipleStatementContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multipleStatement(&mut self,)
	-> Result<Rc<MultipleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultipleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 0, RULE_multipleStatement);
        let mut _localctx: Rc<MultipleStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(437);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ALTER || _la==ANALYZE || ((((_la - 55)) & !0x3f) == 0 && ((1usize << (_la - 55)) & ((1usize << (COMMENT - 55)) | (1usize << (COMMIT - 55)) | (1usize << (CREATE - 55)))) != 0) || ((((_la - 93)) & !0x3f) == 0 && ((1usize << (_la - 93)) & ((1usize << (DELETE - 93)) | (1usize << (DESCRIBE - 93)) | (1usize << (DROP - 93)) | (1usize << (EXECUTE - 93)) | (1usize << (EXPLAIN - 93)))) != 0) || ((((_la - 134)) & !0x3f) == 0 && ((1usize << (_la - 134)) & ((1usize << (FROM - 134)) | (1usize << (GRANT - 134)) | (1usize << (INSERT - 134)))) != 0) || _la==MERGE || _la==OPTIMIZE || ((((_la - 273)) & !0x3f) == 0 && ((1usize << (_la - 273)) & ((1usize << (REPLACE - 273)) | (1usize << (RESET - 273)) | (1usize << (REVOKE - 273)) | (1usize << (ROLLBACK - 273)) | (1usize << (SELECT - 273)) | (1usize << (SET - 273)) | (1usize << (SHOW - 273)))) != 0) || _la==TABLE || _la==TRUNCATE || ((((_la - 362)) & !0x3f) == 0 && ((1usize << (_la - 362)) & ((1usize << (UPDATE - 362)) | (1usize << (USE - 362)) | (1usize << (VALUES - 362)) | (1usize << (WITH - 362)) | (1usize << (LPAREN - 362)))) != 0) {
				{
				/*InvokeRule statement*/
				recog.base.set_state(436);
				recog.statement()?;

				}
			}

			recog.base.set_state(445);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==SEMI_COLON {
				{
				{
				recog.base.set_state(439);
				recog.base.match_token(SEMI_COLON,&mut recog.err_handler)?;

				recog.base.set_state(441);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==ALTER || _la==ANALYZE || ((((_la - 55)) & !0x3f) == 0 && ((1usize << (_la - 55)) & ((1usize << (COMMENT - 55)) | (1usize << (COMMIT - 55)) | (1usize << (CREATE - 55)))) != 0) || ((((_la - 93)) & !0x3f) == 0 && ((1usize << (_la - 93)) & ((1usize << (DELETE - 93)) | (1usize << (DESCRIBE - 93)) | (1usize << (DROP - 93)) | (1usize << (EXECUTE - 93)) | (1usize << (EXPLAIN - 93)))) != 0) || ((((_la - 134)) & !0x3f) == 0 && ((1usize << (_la - 134)) & ((1usize << (FROM - 134)) | (1usize << (GRANT - 134)) | (1usize << (INSERT - 134)))) != 0) || _la==MERGE || _la==OPTIMIZE || ((((_la - 273)) & !0x3f) == 0 && ((1usize << (_la - 273)) & ((1usize << (REPLACE - 273)) | (1usize << (RESET - 273)) | (1usize << (REVOKE - 273)) | (1usize << (ROLLBACK - 273)) | (1usize << (SELECT - 273)) | (1usize << (SET - 273)) | (1usize << (SHOW - 273)))) != 0) || _la==TABLE || _la==TRUNCATE || ((((_la - 362)) & !0x3f) == 0 && ((1usize << (_la - 362)) & ((1usize << (UPDATE - 362)) | (1usize << (USE - 362)) | (1usize << (VALUES - 362)) | (1usize << (WITH - 362)) | (1usize << (LPAREN - 362)))) != 0) {
					{
					/*InvokeRule statement*/
					recog.base.set_state(440);
					recog.statement()?;

					}
				}

				}
				}
				recog.base.set_state(447);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(448);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleStatement ----------------
pub type SingleStatementContextAll<'input> = SingleStatementContext<'input>;


pub type SingleStatementContext<'input> = BaseParserRuleContext<'input,SingleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SingleStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SingleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SingleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleStatement(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_singleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SingleStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_singleStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleStatement }
}
antlr_rust::tid!{SingleStatementContextExt<'a>}

impl<'input> SingleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleStatementContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SingleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SEMI_COLON
/// Returns `None` if there is no child corresponding to token SEMI_COLON
fn SEMI_COLON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SEMI_COLON, 0)
}

}

impl<'input> SingleStatementContextAttrs<'input> for SingleStatementContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleStatement(&mut self,)
	-> Result<Rc<SingleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 2, RULE_singleStatement);
        let mut _localctx: Rc<SingleStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(451);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ALTER || _la==ANALYZE || ((((_la - 55)) & !0x3f) == 0 && ((1usize << (_la - 55)) & ((1usize << (COMMENT - 55)) | (1usize << (COMMIT - 55)) | (1usize << (CREATE - 55)))) != 0) || ((((_la - 93)) & !0x3f) == 0 && ((1usize << (_la - 93)) & ((1usize << (DELETE - 93)) | (1usize << (DESCRIBE - 93)) | (1usize << (DROP - 93)) | (1usize << (EXECUTE - 93)) | (1usize << (EXPLAIN - 93)))) != 0) || ((((_la - 134)) & !0x3f) == 0 && ((1usize << (_la - 134)) & ((1usize << (FROM - 134)) | (1usize << (GRANT - 134)) | (1usize << (INSERT - 134)))) != 0) || _la==MERGE || _la==OPTIMIZE || ((((_la - 273)) & !0x3f) == 0 && ((1usize << (_la - 273)) & ((1usize << (REPLACE - 273)) | (1usize << (RESET - 273)) | (1usize << (REVOKE - 273)) | (1usize << (ROLLBACK - 273)) | (1usize << (SELECT - 273)) | (1usize << (SET - 273)) | (1usize << (SHOW - 273)))) != 0) || _la==TABLE || _la==TRUNCATE || ((((_la - 362)) & !0x3f) == 0 && ((1usize << (_la - 362)) & ((1usize << (UPDATE - 362)) | (1usize << (USE - 362)) | (1usize << (VALUES - 362)) | (1usize << (WITH - 362)) | (1usize << (LPAREN - 362)))) != 0) {
				{
				/*InvokeRule statement*/
				recog.base.set_state(450);
				recog.statement()?;

				}
			}

			recog.base.set_state(454);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SEMI_COLON {
				{
				recog.base.set_state(453);
				recog.base.match_token(SEMI_COLON,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(456);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneExpression ----------------
pub type StandaloneExpressionContextAll<'input> = StandaloneExpressionContext<'input>;


pub type StandaloneExpressionContext<'input> = BaseParserRuleContext<'input,StandaloneExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StandaloneExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StandaloneExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneExpression(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_standaloneExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StandaloneExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_standaloneExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneExpression }
}
antlr_rust::tid!{StandaloneExpressionContextExt<'a>}

impl<'input> StandaloneExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StandaloneExpressionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneExpressionContextAttrs<'input> for StandaloneExpressionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneExpression(&mut self,)
	-> Result<Rc<StandaloneExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 4, RULE_standaloneExpression);
        let mut _localctx: Rc<StandaloneExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(458);
			recog.expression()?;

			recog.base.set_state(459);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneQualifiedName ----------------
pub type StandaloneQualifiedNameContextAll<'input> = StandaloneQualifiedNameContext<'input>;


pub type StandaloneQualifiedNameContext<'input> = BaseParserRuleContext<'input,StandaloneQualifiedNameContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneQualifiedNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StandaloneQualifiedNameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StandaloneQualifiedNameContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneQualifiedName(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_standaloneQualifiedName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StandaloneQualifiedNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_standaloneQualifiedName(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneQualifiedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneQualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneQualifiedName }
}
antlr_rust::tid!{StandaloneQualifiedNameContextExt<'a>}

impl<'input> StandaloneQualifiedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneQualifiedNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneQualifiedNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneQualifiedNameContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StandaloneQualifiedNameContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneQualifiedNameContextAttrs<'input> for StandaloneQualifiedNameContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneQualifiedName(&mut self,)
	-> Result<Rc<StandaloneQualifiedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneQualifiedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 6, RULE_standaloneQualifiedName);
        let mut _localctx: Rc<StandaloneQualifiedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(461);
			recog.qualifiedName()?;

			recog.base.set_state(462);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneType ----------------
pub type StandaloneTypeContextAll<'input> = StandaloneTypeContext<'input>;


pub type StandaloneTypeContext<'input> = BaseParserRuleContext<'input,StandaloneTypeContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StandaloneTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StandaloneTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneType(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_standaloneType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StandaloneTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_standaloneType(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneType }
}
antlr_rust::tid!{StandaloneTypeContextExt<'a>}

impl<'input> StandaloneTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneTypeContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StandaloneTypeContextExt<'input>>{

fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneTypeContextAttrs<'input> for StandaloneTypeContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneType(&mut self,)
	-> Result<Rc<StandaloneTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 8, RULE_standaloneType);
        let mut _localctx: Rc<StandaloneTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule type_*/
			recog.base.set_state(464);
			recog.type_()?;

			recog.base.set_state(465);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- statement ----------------
#[derive(Debug)]
pub enum StatementContextAll<'input>{
	DropContext(DropContext<'input>),
	ExplainContext(ExplainContext<'input>),
	CreateFooContext(CreateFooContext<'input>),
	CreateTableContext(CreateTableContext<'input>),
	CreateTableAsSelectContext(CreateTableAsSelectContext<'input>),
	DmlStatementContext(DmlStatementContext<'input>),
	UseContext(UseContext<'input>),
	CreateTableLikeContext(CreateTableLikeContext<'input>),
	RenameTableContext(RenameTableContext<'input>),
	ShowContext(ShowContext<'input>),
	CommitContext(CommitContext<'input>),
	CreateRoleContext(CreateRoleContext<'input>),
	RevokeContext(RevokeContext<'input>),
	UpdateContext(UpdateContext<'input>),
	DropViewContext(DropViewContext<'input>),
	DropColumnContext(DropColumnContext<'input>),
	TableExecuteContext(TableExecuteContext<'input>),
	DeleteContext(DeleteContext<'input>),
	SetViewAuthorizationContext(SetViewAuthorizationContext<'input>),
	SetColumnTypeContext(SetColumnTypeContext<'input>),
	OptimizeContext(OptimizeContext<'input>),
	StatementDefaultContext(StatementDefaultContext<'input>),
	MergeContext(MergeContext<'input>),
	RenameColumnContext(RenameColumnContext<'input>),
	TruncateTableContext(TruncateTableContext<'input>),
	CreateViewContext(CreateViewContext<'input>),
	DropTableContext(DropTableContext<'input>),
	ShowColumnsContext(ShowColumnsContext<'input>),
	AlterContext(AlterContext<'input>),
	SetSchemaAuthorizationContext(SetSchemaAuthorizationContext<'input>),
	RollbackContext(RollbackContext<'input>),
	AddColumnContext(AddColumnContext<'input>),
	SetContext(SetContext<'input>),
	RenameViewContext(RenameViewContext<'input>),
	CreateSchemaContext(CreateSchemaContext<'input>),
	ExecuteContext(ExecuteContext<'input>),
	RenameSchemaContext(RenameSchemaContext<'input>),
	AnalyzeContext(AnalyzeContext<'input>),
	CreateFunctionContext(CreateFunctionContext<'input>),
	ResetContext(ResetContext<'input>),
	CommentContext(CommentContext<'input>),
	DropSchemaContext(DropSchemaContext<'input>),
	GrantContext(GrantContext<'input>),
	SetTableAuthorizationContext(SetTableAuthorizationContext<'input>),
	SetTablePropertiesContext(SetTablePropertiesContext<'input>),
Error(StatementContext<'input>)
}
antlr_rust::tid!{StatementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StatementContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for StatementContextAll<'input>{}

impl<'input> Deref for StatementContextAll<'input>{
	type Target = dyn StatementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StatementContextAll::*;
		match self{
			DropContext(inner) => inner,
			ExplainContext(inner) => inner,
			CreateFooContext(inner) => inner,
			CreateTableContext(inner) => inner,
			CreateTableAsSelectContext(inner) => inner,
			DmlStatementContext(inner) => inner,
			UseContext(inner) => inner,
			CreateTableLikeContext(inner) => inner,
			RenameTableContext(inner) => inner,
			ShowContext(inner) => inner,
			CommitContext(inner) => inner,
			CreateRoleContext(inner) => inner,
			RevokeContext(inner) => inner,
			UpdateContext(inner) => inner,
			DropViewContext(inner) => inner,
			DropColumnContext(inner) => inner,
			TableExecuteContext(inner) => inner,
			DeleteContext(inner) => inner,
			SetViewAuthorizationContext(inner) => inner,
			SetColumnTypeContext(inner) => inner,
			OptimizeContext(inner) => inner,
			StatementDefaultContext(inner) => inner,
			MergeContext(inner) => inner,
			RenameColumnContext(inner) => inner,
			TruncateTableContext(inner) => inner,
			CreateViewContext(inner) => inner,
			DropTableContext(inner) => inner,
			ShowColumnsContext(inner) => inner,
			AlterContext(inner) => inner,
			SetSchemaAuthorizationContext(inner) => inner,
			RollbackContext(inner) => inner,
			AddColumnContext(inner) => inner,
			SetContext(inner) => inner,
			RenameViewContext(inner) => inner,
			CreateSchemaContext(inner) => inner,
			ExecuteContext(inner) => inner,
			RenameSchemaContext(inner) => inner,
			AnalyzeContext(inner) => inner,
			CreateFunctionContext(inner) => inner,
			ResetContext(inner) => inner,
			CommentContext(inner) => inner,
			DropSchemaContext(inner) => inner,
			GrantContext(inner) => inner,
			SetTableAuthorizationContext(inner) => inner,
			SetTablePropertiesContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StatementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StatementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StatementContext<'input> = BaseParserRuleContext<'input,StatementContextExt<'input>>;

#[derive(Clone)]
pub struct StatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StatementContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StatementContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StatementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}
antlr_rust::tid!{StatementContextExt<'a>}

impl<'input> StatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StatementContextAll<'input>> {
		Rc::new(
		StatementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StatementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StatementContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StatementContextExt<'input>>{


}

impl<'input> StatementContextAttrs<'input> for StatementContext<'input>{}

pub type DropContext<'input> = BaseParserRuleContext<'input,DropContextExt<'input>>;

pub trait DropContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DropContextAttrs<'input> for DropContext<'input>{}

pub struct DropContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DropContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DropContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_drop(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_drop(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DropContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_drop(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropContext<'input> {}

impl<'input> DropContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropContext(
				BaseParserRuleContext::copy_from(ctx,DropContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExplainContext<'input> = BaseParserRuleContext<'input,ExplainContextExt<'input>>;

pub trait ExplainContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXPLAIN
	/// Returns `None` if there is no child corresponding to token EXPLAIN
	fn EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXPLAIN, 0)
	}
	fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTENDED
	/// Returns `None` if there is no child corresponding to token EXTENDED
	fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXTENDED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CODEGEN
	/// Returns `None` if there is no child corresponding to token CODEGEN
	fn CODEGEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CODEGEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COST
	/// Returns `None` if there is no child corresponding to token COST
	fn COST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMATTED
	/// Returns `None` if there is no child corresponding to token FORMATTED
	fn FORMATTED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FORMATTED, 0)
	}
}

impl<'input> ExplainContextAttrs<'input> for ExplainContext<'input>{}

pub struct ExplainContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExplainContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ExplainContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExplainContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_explain(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_explain(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExplainContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_explain(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExplainContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ExplainContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ExplainContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ExplainContext<'input> {}

impl<'input> ExplainContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ExplainContext(
				BaseParserRuleContext::copy_from(ctx,ExplainContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateFooContext<'input> = BaseParserRuleContext<'input,CreateFooContextExt<'input>>;

pub trait CreateFooContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATABASE
	/// Returns `None` if there is no child corresponding to token DATABASE
	fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DATABASE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
	/// Retrieves first TerminalNode corresponding to token CATALOG
	/// Returns `None` if there is no child corresponding to token CATALOG
	fn CATALOG(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CATALOG, 0)
	}
}

impl<'input> CreateFooContextAttrs<'input> for CreateFooContext<'input>{}

pub struct CreateFooContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateFooContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CreateFooContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateFooContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createFoo(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_createFoo(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateFooContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createFoo(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateFooContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateFooContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateFooContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateFooContext<'input> {}

impl<'input> CreateFooContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateFooContext(
				BaseParserRuleContext::copy_from(ctx,CreateFooContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateTableContext<'input> = BaseParserRuleContext<'input,CreateTableContextExt<'input>>;

pub trait CreateTableContextAttrs<'input>: DatabricksParserContext<'input>{
	fn createTableClauses(&self) -> Option<Rc<CreateTableClausesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn tableElements(&self) -> Option<Rc<TableElementsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTERNAL
	/// Returns `None` if there is no child corresponding to token EXTERNAL
	fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXTERNAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMP
	/// Returns `None` if there is no child corresponding to token TEMP
	fn TEMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TEMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
}

impl<'input> CreateTableContextAttrs<'input> for CreateTableContext<'input>{}

pub struct CreateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CreateTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_createTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateTableContext<'input> {}

impl<'input> CreateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateTableContext(
				BaseParserRuleContext::copy_from(ctx,CreateTableContextExt{
					tail:None, 
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateTableAsSelectContext<'input> = BaseParserRuleContext<'input,CreateTableAsSelectContextExt<'input>>;

pub trait CreateTableAsSelectContextAttrs<'input>: DatabricksParserContext<'input>{
	fn createTableClauses(&self) -> Option<Rc<CreateTableClausesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn tableElements(&self) -> Option<Rc<TableElementsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REFRESH
	/// Returns `None` if there is no child corresponding to token REFRESH
	fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REFRESH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTERNAL
	/// Returns `None` if there is no child corresponding to token EXTERNAL
	fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXTERNAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LIVE
	/// Returns `None` if there is no child corresponding to token LIVE
	fn LIVE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LIVE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token STREAMING
	/// Returns `None` if there is no child corresponding to token STREAMING
	fn STREAMING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(STREAMING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMP
	/// Returns `None` if there is no child corresponding to token TEMP
	fn TEMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TEMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
}

impl<'input> CreateTableAsSelectContextAttrs<'input> for CreateTableAsSelectContext<'input>{}

pub struct CreateTableAsSelectContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateTableAsSelectContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CreateTableAsSelectContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateTableAsSelectContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createTableAsSelect(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_createTableAsSelect(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateTableAsSelectContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createTableAsSelect(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTableAsSelectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateTableAsSelectContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateTableAsSelectContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateTableAsSelectContext<'input> {}

impl<'input> CreateTableAsSelectContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateTableAsSelectContext(
				BaseParserRuleContext::copy_from(ctx,CreateTableAsSelectContextExt{
					tail:None, 
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DmlStatementContext<'input> = BaseParserRuleContext<'input,DmlStatementContextExt<'input>>;

pub trait DmlStatementContextAttrs<'input>: DatabricksParserContext<'input>{
	fn dmlStatementNoWith(&self) -> Option<Rc<DmlStatementNoWithContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn ctes(&self) -> Option<Rc<CtesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DmlStatementContextAttrs<'input> for DmlStatementContext<'input>{}

pub struct DmlStatementContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DmlStatementContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DmlStatementContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DmlStatementContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dmlStatement(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_dmlStatement(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DmlStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_dmlStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for DmlStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DmlStatementContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DmlStatementContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DmlStatementContext<'input> {}

impl<'input> DmlStatementContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DmlStatementContext(
				BaseParserRuleContext::copy_from(ctx,DmlStatementContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UseContext<'input> = BaseParserRuleContext<'input,UseContextExt<'input>>;

pub trait UseContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token USE
	/// Returns `None` if there is no child corresponding to token USE
	fn USE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(USE, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> UseContextAttrs<'input> for UseContext<'input>{}

pub struct UseContextExt<'input>{
	base:StatementContextExt<'input>,
	pub schema: Option<Rc<IdentifierContextAll<'input>>>,
	pub catalog: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UseContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UseContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_use(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_use(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_use(self);
	}
}

impl<'input> CustomRuleContext<'input> for UseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UseContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UseContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UseContext<'input> {}

impl<'input> UseContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UseContext(
				BaseParserRuleContext::copy_from(ctx,UseContextExt{
        			schema:None, catalog:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateTableLikeContext<'input> = BaseParserRuleContext<'input,CreateTableLikeContextExt<'input>>;

pub trait CreateTableLikeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn tableProvider_all(&self) ->  Vec<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn tableProvider(&self, i: usize) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn rowFormat_all(&self) ->  Vec<Rc<RowFormatContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowFormat(&self, i: usize) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn createFileFormat_all(&self) ->  Vec<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn createFileFormat(&self, i: usize) -> Option<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn locationSpec_all(&self) ->  Vec<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn locationSpec(&self, i: usize) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TBLPROPERTIES in current rule
	fn TBLPROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TBLPROPERTIES, starting from 0.
	/// Returns `None` if number of children corresponding to token TBLPROPERTIES is less or equal than `i`.
	fn TBLPROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TBLPROPERTIES, i)
	}
	fn properties_all(&self) ->  Vec<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn properties(&self, i: usize) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> CreateTableLikeContextAttrs<'input> for CreateTableLikeContext<'input>{}

pub struct CreateTableLikeContextExt<'input>{
	base:StatementContextExt<'input>,
	pub target: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub source: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub tableProps: Option<Rc<PropertiesContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateTableLikeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CreateTableLikeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateTableLikeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createTableLike(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_createTableLike(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateTableLikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createTableLike(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTableLikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateTableLikeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateTableLikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateTableLikeContext<'input> {}

impl<'input> CreateTableLikeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateTableLikeContext(
				BaseParserRuleContext::copy_from(ctx,CreateTableLikeContextExt{
        			target:None, source:None, tableProps:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameTableContext<'input> = BaseParserRuleContext<'input,RenameTableContextExt<'input>>;

pub trait RenameTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> RenameTableContextAttrs<'input> for RenameTableContext<'input>{}

pub struct RenameTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub to: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RenameTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RenameTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_renameTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RenameTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_renameTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameTableContext<'input> {}

impl<'input> RenameTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameTableContext(
				BaseParserRuleContext::copy_from(ctx,RenameTableContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowContext<'input> = BaseParserRuleContext<'input,ShowContextExt<'input>>;

pub trait ShowContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ShowContextAttrs<'input> for ShowContext<'input>{}

pub struct ShowContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ShowContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ShowContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_show(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_show(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ShowContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_show(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowContext<'input> {}

impl<'input> ShowContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowContext(
				BaseParserRuleContext::copy_from(ctx,ShowContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommitContext<'input> = BaseParserRuleContext<'input,CommitContextExt<'input>>;

pub trait CommitContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMIT
	/// Returns `None` if there is no child corresponding to token COMMIT
	fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMIT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CommitContextAttrs<'input> for CommitContext<'input>{}

pub struct CommitContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommitContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CommitContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CommitContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_commit(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_commit(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CommitContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_commit(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommitContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommitContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommitContext<'input> {}

impl<'input> CommitContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommitContext(
				BaseParserRuleContext::copy_from(ctx,CommitContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateRoleContext<'input> = BaseParserRuleContext<'input,CreateRoleContextExt<'input>>;

pub trait CreateRoleContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROLE
	/// Returns `None` if there is no child corresponding to token ROLE
	fn ROLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROLE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateRoleContextAttrs<'input> for CreateRoleContext<'input>{}

pub struct CreateRoleContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateRoleContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CreateRoleContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateRoleContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createRole(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_createRole(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateRoleContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createRole(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateRoleContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateRoleContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateRoleContext<'input> {}

impl<'input> CreateRoleContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateRoleContext(
				BaseParserRuleContext::copy_from(ctx,CreateRoleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RevokeContext<'input> = BaseParserRuleContext<'input,RevokeContextExt<'input>>;

pub trait RevokeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REVOKE
	/// Returns `None` if there is no child corresponding to token REVOKE
	fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REVOKE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> RevokeContextAttrs<'input> for RevokeContext<'input>{}

pub struct RevokeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RevokeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RevokeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RevokeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_revoke(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_revoke(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RevokeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_revoke(self);
	}
}

impl<'input> CustomRuleContext<'input> for RevokeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RevokeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RevokeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RevokeContext<'input> {}

impl<'input> RevokeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RevokeContext(
				BaseParserRuleContext::copy_from(ctx,RevokeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UpdateContext<'input> = BaseParserRuleContext<'input,UpdateContextExt<'input>>;

pub trait UpdateContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UPDATE
	/// Returns `None` if there is no child corresponding to token UPDATE
	fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(UPDATE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> UpdateContextAttrs<'input> for UpdateContext<'input>{}

pub struct UpdateContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UpdateContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UpdateContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UpdateContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_update(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_update(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UpdateContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_update(self);
	}
}

impl<'input> CustomRuleContext<'input> for UpdateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UpdateContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UpdateContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UpdateContext<'input> {}

impl<'input> UpdateContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UpdateContext(
				BaseParserRuleContext::copy_from(ctx,UpdateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropViewContext<'input> = BaseParserRuleContext<'input,DropViewContextExt<'input>>;

pub trait DropViewContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DropViewContextAttrs<'input> for DropViewContext<'input>{}

pub struct DropViewContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropViewContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DropViewContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DropViewContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropView(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_dropView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DropViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_dropView(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropViewContext<'input> {}

impl<'input> DropViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropViewContext(
				BaseParserRuleContext::copy_from(ctx,DropViewContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropColumnContext<'input> = BaseParserRuleContext<'input,DropColumnContextExt<'input>>;

pub trait DropColumnContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
}

impl<'input> DropColumnContextAttrs<'input> for DropColumnContext<'input>{}

pub struct DropColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub column: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropColumnContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DropColumnContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DropColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropColumn(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_dropColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DropColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_dropColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropColumnContext<'input> {}

impl<'input> DropColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropColumnContext(
				BaseParserRuleContext::copy_from(ctx,DropColumnContextExt{
        			tableName:None, column:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableExecuteContext<'input> = BaseParserRuleContext<'input,TableExecuteContextExt<'input>>;

pub trait TableExecuteContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXECUTE
	/// Returns `None` if there is no child corresponding to token EXECUTE
	fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXECUTE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WHERE
	/// Returns `None` if there is no child corresponding to token WHERE
	fn WHERE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(WHERE, 0)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> TableExecuteContextAttrs<'input> for TableExecuteContext<'input>{}

pub struct TableExecuteContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub procedureName: Option<Rc<IdentifierContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	pub where_: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableExecuteContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TableExecuteContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableExecuteContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableExecute(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_tableExecute(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableExecuteContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableExecute(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableExecuteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for TableExecuteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for TableExecuteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for TableExecuteContext<'input> {}

impl<'input> TableExecuteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::TableExecuteContext(
				BaseParserRuleContext::copy_from(ctx,TableExecuteContextExt{
					tail:None, 
        			tableName:None, procedureName:None, where_:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DeleteContext<'input> = BaseParserRuleContext<'input,DeleteContextExt<'input>>;

pub trait DeleteContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DELETE
	/// Returns `None` if there is no child corresponding to token DELETE
	fn DELETE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DELETE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DeleteContextAttrs<'input> for DeleteContext<'input>{}

pub struct DeleteContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeleteContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DeleteContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DeleteContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_delete(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_delete(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DeleteContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_delete(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeleteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DeleteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DeleteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DeleteContext<'input> {}

impl<'input> DeleteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DeleteContext(
				BaseParserRuleContext::copy_from(ctx,DeleteContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetViewAuthorizationContext<'input> = BaseParserRuleContext<'input,SetViewAuthorizationContextExt<'input>>;

pub trait SetViewAuthorizationContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetViewAuthorizationContextAttrs<'input> for SetViewAuthorizationContext<'input>{}

pub struct SetViewAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetViewAuthorizationContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SetViewAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetViewAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setViewAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_setViewAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetViewAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setViewAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetViewAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetViewAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetViewAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetViewAuthorizationContext<'input> {}

impl<'input> SetViewAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetViewAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetViewAuthorizationContextExt{
        			from:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetColumnTypeContext<'input> = BaseParserRuleContext<'input,SetColumnTypeContextExt<'input>>;

pub trait SetColumnTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token ALTER in current rule
	fn ALTER_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ALTER, starting from 0.
	/// Returns `None` if number of children corresponding to token ALTER is less or equal than `i`.
	fn ALTER(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, i)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATA
	/// Returns `None` if there is no child corresponding to token DATA
	fn DATA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DATA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TYPE
	/// Returns `None` if there is no child corresponding to token TYPE
	fn TYPE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TYPE, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> SetColumnTypeContextAttrs<'input> for SetColumnTypeContext<'input>{}

pub struct SetColumnTypeContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub setColumnName: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetColumnTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SetColumnTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetColumnTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setColumnType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_setColumnType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetColumnTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setColumnType(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetColumnTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetColumnTypeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetColumnTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetColumnTypeContext<'input> {}

impl<'input> SetColumnTypeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetColumnTypeContext(
				BaseParserRuleContext::copy_from(ctx,SetColumnTypeContextExt{
        			tableName:None, setColumnName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type OptimizeContext<'input> = BaseParserRuleContext<'input,OptimizeContextExt<'input>>;

pub trait OptimizeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token OPTIMIZE
	/// Returns `None` if there is no child corresponding to token OPTIMIZE
	fn OPTIMIZE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OPTIMIZE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> OptimizeContextAttrs<'input> for OptimizeContext<'input>{}

pub struct OptimizeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OptimizeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for OptimizeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for OptimizeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_optimize(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_optimize(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for OptimizeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_optimize(self);
	}
}

impl<'input> CustomRuleContext<'input> for OptimizeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for OptimizeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for OptimizeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for OptimizeContext<'input> {}

impl<'input> OptimizeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::OptimizeContext(
				BaseParserRuleContext::copy_from(ctx,OptimizeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StatementDefaultContext<'input> = BaseParserRuleContext<'input,StatementDefaultContextExt<'input>>;

pub trait StatementDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StatementDefaultContextAttrs<'input> for StatementDefaultContext<'input>{}

pub struct StatementDefaultContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StatementDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StatementDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StatementDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_statementDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_statementDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StatementDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_statementDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for StatementDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for StatementDefaultContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for StatementDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for StatementDefaultContext<'input> {}

impl<'input> StatementDefaultContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::StatementDefaultContext(
				BaseParserRuleContext::copy_from(ctx,StatementDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MergeContext<'input> = BaseParserRuleContext<'input,MergeContextExt<'input>>;

pub trait MergeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MERGE
	/// Returns `None` if there is no child corresponding to token MERGE
	fn MERGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MERGE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> MergeContextAttrs<'input> for MergeContext<'input>{}

pub struct MergeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MergeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for MergeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MergeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_merge(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_merge(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MergeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_merge(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for MergeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for MergeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for MergeContext<'input> {}

impl<'input> MergeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::MergeContext(
				BaseParserRuleContext::copy_from(ctx,MergeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameColumnContext<'input> = BaseParserRuleContext<'input,RenameColumnContextExt<'input>>;

pub trait RenameColumnContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
}

impl<'input> RenameColumnContextAttrs<'input> for RenameColumnContext<'input>{}

pub struct RenameColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub from: Option<Rc<IdentifierContextAll<'input>>>,
	pub to: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameColumnContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RenameColumnContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RenameColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameColumn(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_renameColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RenameColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_renameColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameColumnContext<'input> {}

impl<'input> RenameColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameColumnContext(
				BaseParserRuleContext::copy_from(ctx,RenameColumnContextExt{
        			tableName:None, from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TruncateTableContext<'input> = BaseParserRuleContext<'input,TruncateTableContextExt<'input>>;

pub trait TruncateTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRUNCATE
	/// Returns `None` if there is no child corresponding to token TRUNCATE
	fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TRUNCATE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> TruncateTableContextAttrs<'input> for TruncateTableContext<'input>{}

pub struct TruncateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TruncateTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TruncateTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TruncateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_truncateTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_truncateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TruncateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_truncateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for TruncateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for TruncateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for TruncateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for TruncateTableContext<'input> {}

impl<'input> TruncateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::TruncateTableContext(
				BaseParserRuleContext::copy_from(ctx,TruncateTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateViewContext<'input> = BaseParserRuleContext<'input,CreateViewContextExt<'input>>;

pub trait CreateViewContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MATERIALIZED
	/// Returns `None` if there is no child corresponding to token MATERIALIZED
	fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MATERIALIZED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn columnDefinitionForView_all(&self) ->  Vec<Rc<ColumnDefinitionForViewContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn columnDefinitionForView(&self, i: usize) -> Option<Rc<ColumnDefinitionForViewContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMP
	/// Returns `None` if there is no child corresponding to token TEMP
	fn TEMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TEMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	fn commentSpec_all(&self) ->  Vec<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn commentSpec(&self, i: usize) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn schemaBinding_all(&self) ->  Vec<Rc<SchemaBindingContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn schemaBinding(&self, i: usize) -> Option<Rc<SchemaBindingContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token GLOBAL
	/// Returns `None` if there is no child corresponding to token GLOBAL
	fn GLOBAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GLOBAL, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token PARTITIONED in current rule
	fn PARTITIONED_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token PARTITIONED, starting from 0.
	/// Returns `None` if number of children corresponding to token PARTITIONED is less or equal than `i`.
	fn PARTITIONED(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PARTITIONED, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token ON in current rule
	fn ON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ON, starting from 0.
	/// Returns `None` if number of children corresponding to token ON is less or equal than `i`.
	fn ON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ON, i)
	}
	fn identifierList_all(&self) ->  Vec<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifierList(&self, i: usize) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TBLPROPERTIES in current rule
	fn TBLPROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TBLPROPERTIES, starting from 0.
	/// Returns `None` if number of children corresponding to token TBLPROPERTIES is less or equal than `i`.
	fn TBLPROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TBLPROPERTIES, i)
	}
	fn properties_all(&self) ->  Vec<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn properties(&self, i: usize) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> CreateViewContextAttrs<'input> for CreateViewContext<'input>{}

pub struct CreateViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub dest: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateViewContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CreateViewContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateViewContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createView(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_createView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createView(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateViewContext<'input> {}

impl<'input> CreateViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateViewContext(
				BaseParserRuleContext::copy_from(ctx,CreateViewContextExt{
					tail:None, 
        			dest:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropTableContext<'input> = BaseParserRuleContext<'input,DropTableContextExt<'input>>;

pub trait DropTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DropTableContextAttrs<'input> for DropTableContext<'input>{}

pub struct DropTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DropTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DropTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_dropTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DropTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_dropTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropTableContext<'input> {}

impl<'input> DropTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropTableContext(
				BaseParserRuleContext::copy_from(ctx,DropTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowColumnsContext<'input> = BaseParserRuleContext<'input,ShowColumnsContextExt<'input>>;

pub trait ShowColumnsContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
}

impl<'input> ShowColumnsContextAttrs<'input> for ShowColumnsContext<'input>{}

pub struct ShowColumnsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowColumnsContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ShowColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ShowColumnsContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showColumns(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_showColumns(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ShowColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_showColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowColumnsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowColumnsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowColumnsContext<'input> {}

impl<'input> ShowColumnsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowColumnsContext(
				BaseParserRuleContext::copy_from(ctx,ShowColumnsContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AlterContext<'input> = BaseParserRuleContext<'input,AlterContextExt<'input>>;

pub trait AlterContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> AlterContextAttrs<'input> for AlterContext<'input>{}

pub struct AlterContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AlterContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for AlterContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AlterContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_alter(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_alter(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AlterContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_alter(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AlterContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AlterContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AlterContext<'input> {}

impl<'input> AlterContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AlterContext(
				BaseParserRuleContext::copy_from(ctx,AlterContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetSchemaAuthorizationContext<'input> = BaseParserRuleContext<'input,SetSchemaAuthorizationContextExt<'input>>;

pub trait SetSchemaAuthorizationContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetSchemaAuthorizationContextAttrs<'input> for SetSchemaAuthorizationContext<'input>{}

pub struct SetSchemaAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetSchemaAuthorizationContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SetSchemaAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetSchemaAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setSchemaAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_setSchemaAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetSchemaAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setSchemaAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetSchemaAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetSchemaAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetSchemaAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetSchemaAuthorizationContext<'input> {}

impl<'input> SetSchemaAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetSchemaAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetSchemaAuthorizationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RollbackContext<'input> = BaseParserRuleContext<'input,RollbackContextExt<'input>>;

pub trait RollbackContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLLBACK
	/// Returns `None` if there is no child corresponding to token ROLLBACK
	fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROLLBACK, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> RollbackContextAttrs<'input> for RollbackContext<'input>{}

pub struct RollbackContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RollbackContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RollbackContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RollbackContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rollback(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_rollback(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RollbackContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rollback(self);
	}
}

impl<'input> CustomRuleContext<'input> for RollbackContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RollbackContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RollbackContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RollbackContext<'input> {}

impl<'input> RollbackContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RollbackContext(
				BaseParserRuleContext::copy_from(ctx,RollbackContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AddColumnContext<'input> = BaseParserRuleContext<'input,AddColumnContextExt<'input>>;

pub trait AddColumnContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ADD
	/// Returns `None` if there is no child corresponding to token ADD
	fn ADD(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn columnDefinition(&self) -> Option<Rc<ColumnDefinitionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
	fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
	/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
	fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token EXISTS in current rule
	fn EXISTS_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token EXISTS, starting from 0.
	/// Returns `None` if number of children corresponding to token EXISTS is less or equal than `i`.
	fn EXISTS(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> AddColumnContextAttrs<'input> for AddColumnContext<'input>{}

pub struct AddColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub column: Option<Rc<ColumnDefinitionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AddColumnContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for AddColumnContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AddColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_addColumn(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_addColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AddColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_addColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for AddColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AddColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AddColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AddColumnContext<'input> {}

impl<'input> AddColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AddColumnContext(
				BaseParserRuleContext::copy_from(ctx,AddColumnContextExt{
        			tableName:None, column:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetContext<'input> = BaseParserRuleContext<'input,SetContextExt<'input>>;

pub trait SetContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> SetContextAttrs<'input> for SetContext<'input>{}

pub struct SetContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_set(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_set(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_set(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetContext<'input> {}

impl<'input> SetContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetContext(
				BaseParserRuleContext::copy_from(ctx,SetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameViewContext<'input> = BaseParserRuleContext<'input,RenameViewContextExt<'input>>;

pub trait RenameViewContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> RenameViewContextAttrs<'input> for RenameViewContext<'input>{}

pub struct RenameViewContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub to: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameViewContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RenameViewContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RenameViewContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameView(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_renameView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RenameViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_renameView(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameViewContext<'input> {}

impl<'input> RenameViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameViewContext(
				BaseParserRuleContext::copy_from(ctx,RenameViewContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateSchemaContext<'input> = BaseParserRuleContext<'input,CreateSchemaContextExt<'input>>;

pub trait CreateSchemaContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateSchemaContextAttrs<'input> for CreateSchemaContext<'input>{}

pub struct CreateSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateSchemaContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CreateSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createSchema(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_createSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateSchemaContext<'input> {}

impl<'input> CreateSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateSchemaContext(
				BaseParserRuleContext::copy_from(ctx,CreateSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExecuteContext<'input> = BaseParserRuleContext<'input,ExecuteContextExt<'input>>;

pub trait ExecuteContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXECUTE
	/// Returns `None` if there is no child corresponding to token EXECUTE
	fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXECUTE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ExecuteContextAttrs<'input> for ExecuteContext<'input>{}

pub struct ExecuteContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExecuteContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ExecuteContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExecuteContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_execute(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_execute(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExecuteContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_execute(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExecuteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ExecuteContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ExecuteContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ExecuteContext<'input> {}

impl<'input> ExecuteContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ExecuteContext(
				BaseParserRuleContext::copy_from(ctx,ExecuteContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameSchemaContext<'input> = BaseParserRuleContext<'input,RenameSchemaContextExt<'input>>;

pub trait RenameSchemaContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RenameSchemaContextAttrs<'input> for RenameSchemaContext<'input>{}

pub struct RenameSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameSchemaContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RenameSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RenameSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameSchema(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_renameSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RenameSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_renameSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameSchemaContext<'input> {}

impl<'input> RenameSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameSchemaContext(
				BaseParserRuleContext::copy_from(ctx,RenameSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AnalyzeContext<'input> = BaseParserRuleContext<'input,AnalyzeContextExt<'input>>;

pub trait AnalyzeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ANALYZE
	/// Returns `None` if there is no child corresponding to token ANALYZE
	fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ANALYZE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> AnalyzeContextAttrs<'input> for AnalyzeContext<'input>{}

pub struct AnalyzeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AnalyzeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for AnalyzeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AnalyzeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_analyze(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_analyze(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AnalyzeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_analyze(self);
	}
}

impl<'input> CustomRuleContext<'input> for AnalyzeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AnalyzeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AnalyzeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AnalyzeContext<'input> {}

impl<'input> AnalyzeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AnalyzeContext(
				BaseParserRuleContext::copy_from(ctx,AnalyzeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateFunctionContext<'input> = BaseParserRuleContext<'input,CreateFunctionContextExt<'input>>;

pub trait CreateFunctionContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTERNAL
	/// Returns `None` if there is no child corresponding to token EXTERNAL
	fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXTERNAL, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CreateFunctionContextAttrs<'input> for CreateFunctionContext<'input>{}

pub struct CreateFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateFunctionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CreateFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createFunction(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_createFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateFunctionContext<'input> {}

impl<'input> CreateFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateFunctionContext(
				BaseParserRuleContext::copy_from(ctx,CreateFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ResetContext<'input> = BaseParserRuleContext<'input,ResetContextExt<'input>>;

pub trait ResetContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RESET
	/// Returns `None` if there is no child corresponding to token RESET
	fn RESET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RESET, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> ResetContextAttrs<'input> for ResetContext<'input>{}

pub struct ResetContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ResetContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ResetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ResetContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_reset(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_reset(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ResetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_reset(self);
	}
}

impl<'input> CustomRuleContext<'input> for ResetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ResetContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ResetContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ResetContext<'input> {}

impl<'input> ResetContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ResetContext(
				BaseParserRuleContext::copy_from(ctx,ResetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommentContext<'input> = BaseParserRuleContext<'input,CommentContextExt<'input>>;

pub trait CommentContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMENT
	/// Returns `None` if there is no child corresponding to token COMMENT
	fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMENT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> CommentContextAttrs<'input> for CommentContext<'input>{}

pub struct CommentContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommentContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CommentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CommentContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_comment(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_comment(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CommentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_comment(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommentContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommentContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommentContext<'input> {}

impl<'input> CommentContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommentContext(
				BaseParserRuleContext::copy_from(ctx,CommentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropSchemaContext<'input> = BaseParserRuleContext<'input,DropSchemaContextExt<'input>>;

pub trait DropSchemaContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> DropSchemaContextAttrs<'input> for DropSchemaContext<'input>{}

pub struct DropSchemaContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropSchemaContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DropSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DropSchemaContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropSchema(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_dropSchema(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DropSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_dropSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropSchemaContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropSchemaContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropSchemaContext<'input> {}

impl<'input> DropSchemaContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropSchemaContext(
				BaseParserRuleContext::copy_from(ctx,DropSchemaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GrantContext<'input> = BaseParserRuleContext<'input,GrantContextExt<'input>>;

pub trait GrantContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token GRANT
	/// Returns `None` if there is no child corresponding to token GRANT
	fn GRANT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GRANT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token SEMI_COLON in current rule
	fn SEMI_COLON_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token SEMI_COLON, starting from 0.
	/// Returns `None` if number of children corresponding to token SEMI_COLON is less or equal than `i`.
	fn SEMI_COLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SEMI_COLON, i)
	}
}

impl<'input> GrantContextAttrs<'input> for GrantContext<'input>{}

pub struct GrantContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrantContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GrantContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrantContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grant(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_grant(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrantContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_grant(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrantContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for GrantContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for GrantContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for GrantContext<'input> {}

impl<'input> GrantContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::GrantContext(
				BaseParserRuleContext::copy_from(ctx,GrantContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTableAuthorizationContext<'input> = BaseParserRuleContext<'input,SetTableAuthorizationContextExt<'input>>;

pub trait SetTableAuthorizationContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
	/// Returns `None` if there is no child corresponding to token AUTHORIZATION
	fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AUTHORIZATION, 0)
	}
	fn principal(&self) -> Option<Rc<PrincipalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTableAuthorizationContextAttrs<'input> for SetTableAuthorizationContext<'input>{}

pub struct SetTableAuthorizationContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTableAuthorizationContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SetTableAuthorizationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetTableAuthorizationContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableAuthorization(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_setTableAuthorization(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetTableAuthorizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setTableAuthorization(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTableAuthorizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTableAuthorizationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTableAuthorizationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTableAuthorizationContext<'input> {}

impl<'input> SetTableAuthorizationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTableAuthorizationContext(
				BaseParserRuleContext::copy_from(ctx,SetTableAuthorizationContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTablePropertiesContext<'input> = BaseParserRuleContext<'input,SetTablePropertiesContextExt<'input>>;

pub trait SetTablePropertiesContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROPERTIES
	/// Returns `None` if there is no child corresponding to token PROPERTIES
	fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PROPERTIES, 0)
	}
	fn propertyAssignments(&self) -> Option<Rc<PropertyAssignmentsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTablePropertiesContextAttrs<'input> for SetTablePropertiesContext<'input>{}

pub struct SetTablePropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	pub tableName: Option<Rc<QualifiedNameContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTablePropertiesContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SetTablePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetTablePropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableProperties(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_setTableProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetTablePropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setTableProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTablePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTablePropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTablePropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTablePropertiesContext<'input> {}

impl<'input> SetTablePropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTablePropertiesContext(
				BaseParserRuleContext::copy_from(ctx,SetTablePropertiesContextExt{
        			tableName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn statement(&mut self,)
	-> Result<Rc<StatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 10, RULE_statement);
        let mut _localctx: Rc<StatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(989);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(82,&mut recog.base)? {
				1 =>{
					let tmp = StatementDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule query*/
					recog.base.set_state(467);
					recog.query()?;

					}
				}
			,
				2 =>{
					let tmp = UseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(468);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(469);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.schema = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				3 =>{
					let tmp = UseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(470);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(471);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.catalog = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(472);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(473);
					let tmp = recog.identifier()?;
					if let StatementContextAll::UseContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.schema = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				4 =>{
					let tmp = DropSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(475);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(476);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					recog.base.set_state(479);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(5,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(477);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(478);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(481);
					recog.qualifiedName()?;

					recog.base.set_state(485);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(482);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(487);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				5 =>{
					let tmp = RenameSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(488);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(489);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(490);
					recog.qualifiedName()?;

					recog.base.set_state(491);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(492);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(493);
					recog.identifier()?;

					}
				}
			,
				6 =>{
					let tmp = SetSchemaAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(495);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(496);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(497);
					recog.qualifiedName()?;

					recog.base.set_state(498);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(499);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(500);
					recog.principal()?;

					}
				}
			,
				7 =>{
					let tmp = DropTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(502);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(503);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(504);
					recog.qualifiedName()?;

					}
				}
			,
				8 =>{
					let tmp = DropViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(505);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(506);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(507);
					recog.qualifiedName()?;

					}
				}
			,
				9 =>{
					let tmp = CreateTableAsSelectContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(537);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(14,&mut recog.base)? {
						1 =>{
							{
							recog.base.set_state(508);
							recog.base.match_token(CREATE,&mut recog.err_handler)?;

							recog.base.set_state(511);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==OR {
								{
								recog.base.set_state(509);
								recog.base.match_token(OR,&mut recog.err_handler)?;

								recog.base.set_state(510);
								recog.base.match_token(REFRESH,&mut recog.err_handler)?;

								}
							}

							recog.base.set_state(514);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==TEMP || _la==TEMPORARY {
								{
								recog.base.set_state(513);
								_la = recog.base.input.la(1);
								if { !(_la==TEMP || _la==TEMPORARY) } {
									recog.err_handler.recover_inline(&mut recog.base)?;

								}
								else {
									if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
									recog.err_handler.report_match(&mut recog.base);
									recog.base.consume(&mut recog.err_handler);
								}
								}
							}

							recog.base.set_state(517);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==EXTERNAL {
								{
								recog.base.set_state(516);
								recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

								}
							}

							recog.base.set_state(520);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==LIVE {
								{
								recog.base.set_state(519);
								recog.base.match_token(LIVE,&mut recog.err_handler)?;

								}
							}

							recog.base.set_state(523);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==STREAMING {
								{
								recog.base.set_state(522);
								recog.base.match_token(STREAMING,&mut recog.err_handler)?;

								}
							}

							recog.base.set_state(525);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							recog.base.set_state(529);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(12,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(526);
									recog.base.match_token(IF,&mut recog.err_handler)?;

									recog.base.set_state(527);
									recog.base.match_token(NOT,&mut recog.err_handler)?;

									recog.base.set_state(528);
									recog.base.match_token(EXISTS,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							}
						}
					,
						2 =>{
							{
							recog.base.set_state(533);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==CREATE {
								{
								recog.base.set_state(531);
								recog.base.match_token(CREATE,&mut recog.err_handler)?;

								recog.base.set_state(532);
								recog.base.match_token(OR,&mut recog.err_handler)?;

								}
							}

							recog.base.set_state(535);
							recog.base.match_token(REPLACE,&mut recog.err_handler)?;

							recog.base.set_state(536);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(539);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::CreateTableAsSelectContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(547);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(16,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(540);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule tableElements*/
							recog.base.set_state(541);
							recog.tableElements()?;

							recog.base.set_state(543);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(542);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let StatementContextAll::CreateTableAsSelectContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							recog.base.set_state(545);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(550);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						/*InvokeRule tableProvider*/
						recog.base.set_state(549);
						recog.tableProvider()?;

						}
					}

					/*InvokeRule createTableClauses*/
					recog.base.set_state(552);
					recog.createTableClauses()?;

					recog.base.set_state(554);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(553);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule query*/
					recog.base.set_state(556);
					recog.query()?;

					}
				}
			,
				10 =>{
					let tmp = CreateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(577);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(23,&mut recog.base)? {
						1 =>{
							{
							recog.base.set_state(558);
							recog.base.match_token(CREATE,&mut recog.err_handler)?;

							recog.base.set_state(560);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==TEMP || _la==TEMPORARY {
								{
								recog.base.set_state(559);
								_la = recog.base.input.la(1);
								if { !(_la==TEMP || _la==TEMPORARY) } {
									recog.err_handler.recover_inline(&mut recog.base)?;

								}
								else {
									if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
									recog.err_handler.report_match(&mut recog.base);
									recog.base.consume(&mut recog.err_handler);
								}
								}
							}

							recog.base.set_state(563);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==EXTERNAL {
								{
								recog.base.set_state(562);
								recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

								}
							}

							recog.base.set_state(565);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							recog.base.set_state(569);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(21,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(566);
									recog.base.match_token(IF,&mut recog.err_handler)?;

									recog.base.set_state(567);
									recog.base.match_token(NOT,&mut recog.err_handler)?;

									recog.base.set_state(568);
									recog.base.match_token(EXISTS,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							}
						}
					,
						2 =>{
							{
							recog.base.set_state(573);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==CREATE {
								{
								recog.base.set_state(571);
								recog.base.match_token(CREATE,&mut recog.err_handler)?;

								recog.base.set_state(572);
								recog.base.match_token(OR,&mut recog.err_handler)?;

								}
							}

							recog.base.set_state(575);
							recog.base.match_token(REPLACE,&mut recog.err_handler)?;

							recog.base.set_state(576);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(579);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::CreateTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(587);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(580);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule tableElements*/
						recog.base.set_state(581);
						recog.tableElements()?;

						recog.base.set_state(583);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(582);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::CreateTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						recog.base.set_state(585);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(590);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						/*InvokeRule tableProvider*/
						recog.base.set_state(589);
						recog.tableProvider()?;

						}
					}

					/*InvokeRule createTableClauses*/
					recog.base.set_state(592);
					recog.createTableClauses()?;

					}
				}
			,
				11 =>{
					let tmp = CreateTableLikeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(594);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(595);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(599);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(27,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(596);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(597);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(598);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(601);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::CreateTableLikeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.target = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(602);
					recog.base.match_token(LIKE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(603);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::CreateTableLikeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.source = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(612);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==LOCATION || _la==ROW || _la==STORED || _la==TBLPROPERTIES || _la==USING {
						{
						recog.base.set_state(610);
						recog.err_handler.sync(&mut recog.base)?;
						match recog.base.input.la(1) {
						 USING 
							=> {
								{
								/*InvokeRule tableProvider*/
								recog.base.set_state(604);
								recog.tableProvider()?;

								}
							}

						 ROW 
							=> {
								{
								/*InvokeRule rowFormat*/
								recog.base.set_state(605);
								recog.rowFormat()?;

								}
							}

						 STORED 
							=> {
								{
								/*InvokeRule createFileFormat*/
								recog.base.set_state(606);
								recog.createFileFormat()?;

								}
							}

						 LOCATION 
							=> {
								{
								/*InvokeRule locationSpec*/
								recog.base.set_state(607);
								recog.locationSpec()?;

								}
							}

						 TBLPROPERTIES 
							=> {
								{
								{
								recog.base.set_state(608);
								recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

								/*InvokeRule properties*/
								recog.base.set_state(609);
								let tmp = recog.properties()?;
								if let StatementContextAll::CreateTableLikeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
								ctx.tableProps = Some(tmp.clone()); } else {unreachable!("cant cast");}  

								}
								}
							}

							_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						}
						recog.base.set_state(614);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				12 =>{
					let tmp = DmlStatementContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 12);
					_localctx = tmp;
					{
					recog.base.set_state(616);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						/*InvokeRule ctes*/
						recog.base.set_state(615);
						recog.ctes()?;

						}
					}

					/*InvokeRule dmlStatementNoWith*/
					recog.base.set_state(618);
					recog.dmlStatementNoWith()?;

					}
				}
			,
				13 =>{
					let tmp = CreateViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 13);
					_localctx = tmp;
					{
					recog.base.set_state(619);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(622);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(620);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(621);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(628);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==GLOBAL || _la==TEMP || _la==TEMPORARY {
						{
						recog.base.set_state(625);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==GLOBAL {
							{
							recog.base.set_state(624);
							recog.base.match_token(GLOBAL,&mut recog.err_handler)?;

							}
						}

						recog.base.set_state(627);
						_la = recog.base.input.la(1);
						if { !(_la==TEMP || _la==TEMPORARY) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(631);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MATERIALIZED {
						{
						recog.base.set_state(630);
						recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(633);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(637);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(35,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(634);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(635);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(636);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(639);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::CreateViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.dest = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(654);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(640);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule columnDefinitionForView*/
						recog.base.set_state(641);
						recog.columnDefinitionForView()?;

						recog.base.set_state(646);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(36,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(642);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule columnDefinitionForView*/
								recog.base.set_state(643);
								recog.columnDefinitionForView()?;

								}
								} 
							}
							recog.base.set_state(648);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(36,&mut recog.base)?;
						}
						recog.base.set_state(650);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(649);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::CreateViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						recog.base.set_state(652);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(671);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 USING 
						=> {
							{
							/*InvokeRule tableProvider*/
							recog.base.set_state(656);
							recog.tableProvider()?;

							}
						}

					 AS | COMMENT | PARTITIONED | TBLPROPERTIES | WITH 
						=> {
							{
							recog.base.set_state(666);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMENT || _la==PARTITIONED || _la==TBLPROPERTIES || _la==WITH {
								{
								recog.base.set_state(664);
								recog.err_handler.sync(&mut recog.base)?;
								match recog.base.input.la(1) {
								 COMMENT 
									=> {
										{
										/*InvokeRule commentSpec*/
										recog.base.set_state(657);
										recog.commentSpec()?;

										}
									}

								 WITH 
									=> {
										{
										/*InvokeRule schemaBinding*/
										recog.base.set_state(658);
										recog.schemaBinding()?;

										}
									}

								 PARTITIONED 
									=> {
										{
										{
										recog.base.set_state(659);
										recog.base.match_token(PARTITIONED,&mut recog.err_handler)?;

										recog.base.set_state(660);
										recog.base.match_token(ON,&mut recog.err_handler)?;

										/*InvokeRule identifierList*/
										recog.base.set_state(661);
										recog.identifierList()?;

										}
										}
									}

								 TBLPROPERTIES 
									=> {
										{
										{
										recog.base.set_state(662);
										recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

										/*InvokeRule properties*/
										recog.base.set_state(663);
										recog.properties()?;

										}
										}
									}

									_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
								}
								}
								recog.base.set_state(668);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							recog.base.set_state(669);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(670);
							recog.query()?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}
			,
				14 =>{
					let tmp = ShowColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 14);
					_localctx = tmp;
					{
					recog.base.set_state(673);
					recog.base.match_token(DESCRIBE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(674);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::ShowColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				15 =>{
					let tmp = ShowColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 15);
					_localctx = tmp;
					{
					recog.base.set_state(675);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(676);
					recog.base.match_token(COLUMNS,&mut recog.err_handler)?;

					recog.base.set_state(677);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(678);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::ShowColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				16 =>{
					let tmp = CreateFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 16);
					_localctx = tmp;
					{
					recog.base.set_state(679);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(682);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(680);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(681);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(685);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EXTERNAL {
						{
						recog.base.set_state(684);
						recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(687);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(691);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(688);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(693);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				17 =>{
					let tmp = MergeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 17);
					_localctx = tmp;
					{
					recog.base.set_state(694);
					recog.base.match_token(MERGE,&mut recog.err_handler)?;

					recog.base.set_state(698);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(695);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(700);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				18 =>{
					let tmp = SetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 18);
					_localctx = tmp;
					{
					recog.base.set_state(701);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(705);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(702);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(707);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				19 =>{
					let tmp = CreateSchemaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 19);
					_localctx = tmp;
					{
					recog.base.set_state(708);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(711);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(709);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(710);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(713);
					recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

					recog.base.set_state(717);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(714);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(719);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				20 =>{
					let tmp = DropContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 20);
					_localctx = tmp;
					{
					recog.base.set_state(720);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(724);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(721);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(726);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				21 =>{
					let tmp = DeleteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 21);
					_localctx = tmp;
					{
					recog.base.set_state(727);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					recog.base.set_state(731);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(728);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(733);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				22 =>{
					let tmp = TruncateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 22);
					_localctx = tmp;
					{
					recog.base.set_state(734);
					recog.base.match_token(TRUNCATE,&mut recog.err_handler)?;

					recog.base.set_state(738);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(735);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(740);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				23 =>{
					let tmp = CommentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 23);
					_localctx = tmp;
					{
					recog.base.set_state(741);
					recog.base.match_token(COMMENT,&mut recog.err_handler)?;

					recog.base.set_state(745);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(742);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(747);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				24 =>{
					let tmp = RenameTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 24);
					_localctx = tmp;
					{
					recog.base.set_state(748);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(749);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(752);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(53,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(750);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(751);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(754);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(755);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(756);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(757);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				25 =>{
					let tmp = AddColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 25);
					_localctx = tmp;
					{
					recog.base.set_state(759);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(760);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(763);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(54,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(761);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(762);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(765);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::AddColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(766);
					recog.base.match_token(ADD,&mut recog.err_handler)?;

					recog.base.set_state(767);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(771);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(55,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(768);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(769);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(770);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule columnDefinition*/
					recog.base.set_state(773);
					let tmp = recog.columnDefinition()?;
					if let StatementContextAll::AddColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.column = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				26 =>{
					let tmp = RenameColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 26);
					_localctx = tmp;
					{
					recog.base.set_state(775);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(776);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(779);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(56,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(777);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(778);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(781);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(782);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(783);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(786);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(57,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(784);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(785);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifier*/
					recog.base.set_state(788);
					let tmp = recog.identifier()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(789);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(790);
					let tmp = recog.identifier()?;
					if let StatementContextAll::RenameColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				27 =>{
					let tmp = DropColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 27);
					_localctx = tmp;
					{
					recog.base.set_state(792);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(793);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(796);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(58,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(794);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(795);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(798);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::DropColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(799);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(800);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					recog.base.set_state(803);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(59,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(801);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(802);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(805);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::DropColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.column = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				28 =>{
					let tmp = SetColumnTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 28);
					_localctx = tmp;
					{
					recog.base.set_state(807);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(808);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(811);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(60,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(809);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(810);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule qualifiedName*/
					recog.base.set_state(813);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetColumnTypeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(814);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(815);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(816);
					let tmp = recog.identifier()?;
					if let StatementContextAll::SetColumnTypeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.setColumnName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(817);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(818);
					recog.base.match_token(DATA,&mut recog.err_handler)?;

					recog.base.set_state(819);
					recog.base.match_token(TYPE,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(820);
					recog.type_()?;

					}
				}
			,
				29 =>{
					let tmp = SetTableAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 29);
					_localctx = tmp;
					{
					recog.base.set_state(822);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(823);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(824);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetTableAuthorizationContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(825);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(826);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(827);
					recog.principal()?;

					}
				}
			,
				30 =>{
					let tmp = SetTablePropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 30);
					_localctx = tmp;
					{
					recog.base.set_state(829);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(830);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(831);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetTablePropertiesContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(832);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(833);
					recog.base.match_token(PROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule propertyAssignments*/
					recog.base.set_state(834);
					recog.propertyAssignments()?;

					}
				}
			,
				31 =>{
					let tmp = TableExecuteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 31);
					_localctx = tmp;
					{
					recog.base.set_state(836);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(837);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(838);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.tableName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(839);
					recog.base.match_token(EXECUTE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(840);
					let tmp = recog.identifier()?;
					if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.procedureName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(856);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						recog.base.set_state(841);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(850);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
							{
							/*InvokeRule callArgument*/
							recog.base.set_state(842);
							recog.callArgument()?;

							recog.base.set_state(847);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(61,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(843);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule callArgument*/
									recog.base.set_state(844);
									recog.callArgument()?;

									}
									} 
								}
								recog.base.set_state(849);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(61,&mut recog.base)?;
							}
							}
						}

						recog.base.set_state(853);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(852);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						recog.base.set_state(855);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(860);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						recog.base.set_state(858);
						recog.base.match_token(WHERE,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(859);
						let tmp = recog.booleanExpression_rec(0)?;
						if let StatementContextAll::TableExecuteContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.where_ = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					}
				}
			,
				32 =>{
					let tmp = AnalyzeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 32);
					_localctx = tmp;
					{
					recog.base.set_state(862);
					recog.base.match_token(ANALYZE,&mut recog.err_handler)?;

					recog.base.set_state(866);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(863);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(868);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				33 =>{
					let tmp = RenameViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 33);
					_localctx = tmp;
					{
					recog.base.set_state(869);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(870);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(871);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(872);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(873);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(874);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::RenameViewContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				34 =>{
					let tmp = SetViewAuthorizationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 34);
					_localctx = tmp;
					{
					recog.base.set_state(876);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(877);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(878);
					let tmp = recog.qualifiedName()?;
					if let StatementContextAll::SetViewAuthorizationContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(879);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(880);
					recog.base.match_token(AUTHORIZATION,&mut recog.err_handler)?;

					/*InvokeRule principal*/
					recog.base.set_state(881);
					recog.principal()?;

					}
				}
			,
				35 =>{
					let tmp = CreateRoleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 35);
					_localctx = tmp;
					{
					recog.base.set_state(883);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(884);
					recog.base.match_token(ROLE,&mut recog.err_handler)?;

					recog.base.set_state(888);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(885);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(890);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				36 =>{
					let tmp = GrantContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 36);
					_localctx = tmp;
					{
					recog.base.set_state(891);
					recog.base.match_token(GRANT,&mut recog.err_handler)?;

					recog.base.set_state(895);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(892);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(897);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				37 =>{
					let tmp = RevokeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 37);
					_localctx = tmp;
					{
					recog.base.set_state(898);
					recog.base.match_token(REVOKE,&mut recog.err_handler)?;

					recog.base.set_state(902);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(899);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(904);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				38 =>{
					let tmp = ExplainContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 38);
					_localctx = tmp;
					{
					recog.base.set_state(905);
					recog.base.match_token(EXPLAIN,&mut recog.err_handler)?;

					recog.base.set_state(907);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==CODEGEN || _la==COST || _la==EXTENDED || _la==FORMATTED {
						{
						recog.base.set_state(906);
						_la = recog.base.input.la(1);
						if { !(_la==CODEGEN || _la==COST || _la==EXTENDED || _la==FORMATTED) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					/*InvokeRule statement*/
					recog.base.set_state(909);
					recog.statement()?;

					}
				}
			,
				39 =>{
					let tmp = ShowContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 39);
					_localctx = tmp;
					{
					recog.base.set_state(910);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(914);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(911);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(916);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				40 =>{
					let tmp = ResetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 40);
					_localctx = tmp;
					{
					recog.base.set_state(917);
					recog.base.match_token(RESET,&mut recog.err_handler)?;

					recog.base.set_state(921);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(918);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(923);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				41 =>{
					let tmp = CommitContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 41);
					_localctx = tmp;
					{
					recog.base.set_state(924);
					recog.base.match_token(COMMIT,&mut recog.err_handler)?;

					recog.base.set_state(928);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(925);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(930);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				42 =>{
					let tmp = RollbackContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 42);
					_localctx = tmp;
					{
					recog.base.set_state(931);
					recog.base.match_token(ROLLBACK,&mut recog.err_handler)?;

					recog.base.set_state(935);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(932);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(937);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				43 =>{
					let tmp = ExecuteContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 43);
					_localctx = tmp;
					{
					recog.base.set_state(938);
					recog.base.match_token(EXECUTE,&mut recog.err_handler)?;

					recog.base.set_state(942);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(939);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(944);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				44 =>{
					let tmp = UpdateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 44);
					_localctx = tmp;
					{
					recog.base.set_state(945);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(949);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(946);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(951);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				45 =>{
					let tmp = CreateFooContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 45);
					_localctx = tmp;
					{
					recog.base.set_state(952);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(953);
					recog.base.match_token(DATABASE,&mut recog.err_handler)?;

					recog.base.set_state(957);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(954);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(959);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				46 =>{
					let tmp = CreateFooContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 46);
					_localctx = tmp;
					{
					recog.base.set_state(960);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(961);
					recog.base.match_token(CATALOG,&mut recog.err_handler)?;

					recog.base.set_state(965);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(962);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(967);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				47 =>{
					let tmp = AlterContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 47);
					_localctx = tmp;
					{
					recog.base.set_state(968);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(972);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(969);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(974);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				48 =>{
					let tmp = UseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 48);
					_localctx = tmp;
					{
					recog.base.set_state(975);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					recog.base.set_state(979);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(976);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(981);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				49 =>{
					let tmp = OptimizeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 49);
					_localctx = tmp;
					{
					recog.base.set_state(982);
					recog.base.match_token(OPTIMIZE,&mut recog.err_handler)?;

					recog.base.set_state(986);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << T__0) | (1usize << T__1) | (1usize << T__2) | (1usize << T__3) | (1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMA - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (RPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (RBRACKET - 384)) | (1usize << (DOT - 384)) | (1usize << (EQ - 384)) | (1usize << (DOUBLE_EQ - 384)) | (1usize << (BANG - 384)) | (1usize << (NSEQ - 384)) | (1usize << (HENT_START - 384)) | (1usize << (HENT_END - 384)) | (1usize << (NEQ - 384)) | (1usize << (LT - 384)) | (1usize << (LTE - 384)) | (1usize << (GT - 384)) | (1usize << (GTE - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (SLASH - 384)) | (1usize << (PERCENT - 384)) | (1usize << (CONCAT - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (DOLLAR - 384)) | (1usize << (BITWISE_AND - 384)) | (1usize << (BITWISE_OR - 384)) | (1usize << (BITWISE_XOR - 384)) | (1usize << (BITWISE_SHIFT_LEFT - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (ESCAPE_SEQUENCE - 416)) | (1usize << (STRING - 416)) | (1usize << (DOUBLEQUOTED_STRING - 416)) | (1usize << (UNICODE_STRING - 416)) | (1usize << (INTEGER_VALUE - 416)) | (1usize << (BIGINT_VALUE - 416)) | (1usize << (SMALLINT_VALUE - 416)) | (1usize << (TINYINT_VALUE - 416)) | (1usize << (EXPONENT_VALUE - 416)) | (1usize << (DECIMAL_VALUE - 416)) | (1usize << (FLOAT_VALUE - 416)) | (1usize << (DOUBLE_VALUE - 416)) | (1usize << (BIGDECIMAL_VALUE - 416)) | (1usize << (IDENTIFIER - 416)) | (1usize << (BACKQUOTED_IDENTIFIER - 416)) | (1usize << (VARIABLE - 416)) | (1usize << (SIMPLE_COMMENT - 416)) | (1usize << (BRACKETED_COMMENT - 416)) | (1usize << (WS - 416)) | (1usize << (UNPAIRED_TOKEN - 416)) | (1usize << (UNRECOGNIZED - 416)))) != 0) {
						{
						{
						recog.base.set_state(983);
						_la = recog.base.input.la(1);
						if { _la <= 0 || (_la==SEMI_COLON) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
						}
						recog.base.set_state(988);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableElements ----------------
pub type TableElementsContextAll<'input> = TableElementsContext<'input>;


pub type TableElementsContext<'input> = BaseParserRuleContext<'input,TableElementsContextExt<'input>>;

#[derive(Clone)]
pub struct TableElementsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableElementsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableElementsContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableElements(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_tableElements(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableElementsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableElements(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableElementsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableElements }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableElements }
}
antlr_rust::tid!{TableElementsContextExt<'a>}

impl<'input> TableElementsContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableElementsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableElementsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableElementsContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableElementsContextExt<'input>>{

fn tableElement_all(&self) ->  Vec<Rc<TableElementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tableElement(&self, i: usize) -> Option<Rc<TableElementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableElementsContextAttrs<'input> for TableElementsContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableElements(&mut self,)
	-> Result<Rc<TableElementsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableElementsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 12, RULE_tableElements);
        let mut _localctx: Rc<TableElementsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableElement*/
			recog.base.set_state(991);
			recog.tableElement()?;

			recog.base.set_state(996);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(83,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(992);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule tableElement*/
					recog.base.set_state(993);
					recog.tableElement()?;

					}
					} 
				}
				recog.base.set_state(998);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(83,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierReference ----------------
pub type IdentifierReferenceContextAll<'input> = IdentifierReferenceContext<'input>;


pub type IdentifierReferenceContext<'input> = BaseParserRuleContext<'input,IdentifierReferenceContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierReferenceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IdentifierReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentifierReferenceContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierReference(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_identifierReference(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentifierReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_identifierReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierReference }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierReference }
}
antlr_rust::tid!{IdentifierReferenceContextExt<'a>}

impl<'input> IdentifierReferenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierReferenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierReferenceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierReferenceContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IdentifierReferenceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierReferenceContextAttrs<'input> for IdentifierReferenceContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierReference(&mut self,)
	-> Result<Rc<IdentifierReferenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierReferenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 14, RULE_identifierReference);
        let mut _localctx: Rc<IdentifierReferenceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1005);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(84,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(999);
					recog.base.match_token(IDENTIFIER_KW,&mut recog.err_handler)?;

					recog.base.set_state(1000);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1001);
					recog.expression()?;

					recog.base.set_state(1002);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(1004);
					recog.qualifiedName()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierCommentList ----------------
pub type IdentifierCommentListContextAll<'input> = IdentifierCommentListContext<'input>;


pub type IdentifierCommentListContext<'input> = BaseParserRuleContext<'input,IdentifierCommentListContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierCommentListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IdentifierCommentListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentifierCommentListContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierCommentList(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_identifierCommentList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentifierCommentListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_identifierCommentList(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierCommentListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierCommentList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierCommentList }
}
antlr_rust::tid!{IdentifierCommentListContextExt<'a>}

impl<'input> IdentifierCommentListContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierCommentListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierCommentListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierCommentListContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IdentifierCommentListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn identifierComment_all(&self) ->  Vec<Rc<IdentifierCommentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifierComment(&self, i: usize) -> Option<Rc<IdentifierCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> IdentifierCommentListContextAttrs<'input> for IdentifierCommentListContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierCommentList(&mut self,)
	-> Result<Rc<IdentifierCommentListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierCommentListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 16, RULE_identifierCommentList);
        let mut _localctx: Rc<IdentifierCommentListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1007);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifierComment*/
			recog.base.set_state(1008);
			recog.identifierComment()?;

			recog.base.set_state(1013);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1009);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule identifierComment*/
				recog.base.set_state(1010);
				recog.identifierComment()?;

				}
				}
				recog.base.set_state(1015);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1016);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierComment ----------------
pub type IdentifierCommentContextAll<'input> = IdentifierCommentContext<'input>;


pub type IdentifierCommentContext<'input> = BaseParserRuleContext<'input,IdentifierCommentContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierCommentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IdentifierCommentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentifierCommentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierComment(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_identifierComment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentifierCommentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_identifierComment(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierCommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierComment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierComment }
}
antlr_rust::tid!{IdentifierCommentContextExt<'a>}

impl<'input> IdentifierCommentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierCommentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierCommentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierCommentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IdentifierCommentContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierCommentContextAttrs<'input> for IdentifierCommentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierComment(&mut self,)
	-> Result<Rc<IdentifierCommentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierCommentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 18, RULE_identifierComment);
        let mut _localctx: Rc<IdentifierCommentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1018);
			recog.identifier()?;

			recog.base.set_state(1020);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMENT {
				{
				/*InvokeRule commentSpec*/
				recog.base.set_state(1019);
				recog.commentSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- schemaBinding ----------------
pub type SchemaBindingContextAll<'input> = SchemaBindingContext<'input>;


pub type SchemaBindingContext<'input> = BaseParserRuleContext<'input,SchemaBindingContextExt<'input>>;

#[derive(Clone)]
pub struct SchemaBindingContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SchemaBindingContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SchemaBindingContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_schemaBinding(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_schemaBinding(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SchemaBindingContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_schemaBinding(self);
	}
}

impl<'input> CustomRuleContext<'input> for SchemaBindingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_schemaBinding }
	//fn type_rule_index() -> usize where Self: Sized { RULE_schemaBinding }
}
antlr_rust::tid!{SchemaBindingContextExt<'a>}

impl<'input> SchemaBindingContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SchemaBindingContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SchemaBindingContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SchemaBindingContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SchemaBindingContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMA
/// Returns `None` if there is no child corresponding to token SCHEMA
fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SCHEMA, 0)
}
/// Retrieves first TerminalNode corresponding to token BINDING
/// Returns `None` if there is no child corresponding to token BINDING
fn BINDING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BINDING, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPENSATION
/// Returns `None` if there is no child corresponding to token COMPENSATION
fn COMPENSATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMPENSATION, 0)
}
/// Retrieves first TerminalNode corresponding to token EVOLUTION
/// Returns `None` if there is no child corresponding to token EVOLUTION
fn EVOLUTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EVOLUTION, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}

}

impl<'input> SchemaBindingContextAttrs<'input> for SchemaBindingContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn schemaBinding(&mut self,)
	-> Result<Rc<SchemaBindingContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SchemaBindingContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 20, RULE_schemaBinding);
        let mut _localctx: Rc<SchemaBindingContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1022);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(1023);
			recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

			recog.base.set_state(1029);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 BINDING 
				=> {
					{
					recog.base.set_state(1024);
					recog.base.match_token(BINDING,&mut recog.err_handler)?;

					}
				}

			 COMPENSATION 
				=> {
					{
					recog.base.set_state(1025);
					recog.base.match_token(COMPENSATION,&mut recog.err_handler)?;

					}
				}

			 EVOLUTION 
				=> {
					{
					recog.base.set_state(1026);
					recog.base.match_token(EVOLUTION,&mut recog.err_handler)?;

					}
				}

			 TYPE 
				=> {
					{
					recog.base.set_state(1027);
					recog.base.match_token(TYPE,&mut recog.err_handler)?;

					recog.base.set_state(1028);
					recog.base.match_token(EVOLUTION,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createTableClauses ----------------
pub type CreateTableClausesContextAll<'input> = CreateTableClausesContext<'input>;


pub type CreateTableClausesContext<'input> = BaseParserRuleContext<'input,CreateTableClausesContextExt<'input>>;

#[derive(Clone)]
pub struct CreateTableClausesContextExt<'input>{
	pub options: Option<Rc<PropertiesContextAll<'input>>>,
	pub partitionField: Option<Rc<PartitionFieldContextAll<'input>>>,
	pub fields:Vec<Rc<PartitionFieldContextAll<'input>>>,
	pub tableProps: Option<Rc<PropertiesContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for CreateTableClausesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateTableClausesContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createTableClauses(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_createTableClauses(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateTableClausesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createTableClauses(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTableClausesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createTableClauses }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createTableClauses }
}
antlr_rust::tid!{CreateTableClausesContextExt<'a>}

impl<'input> CreateTableClausesContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateTableClausesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateTableClausesContextExt{
				options: None, partitionField: None, tableProps: None, 
				fields: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateTableClausesContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<CreateTableClausesContextExt<'input>>{

fn skewSpec_all(&self) ->  Vec<Rc<SkewSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn skewSpec(&self, i: usize) -> Option<Rc<SkewSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn clusterBySpec_all(&self) ->  Vec<Rc<ClusterBySpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn clusterBySpec(&self, i: usize) -> Option<Rc<ClusterBySpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn bucketSpec_all(&self) ->  Vec<Rc<BucketSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn bucketSpec(&self, i: usize) -> Option<Rc<BucketSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn rowFormat_all(&self) ->  Vec<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowFormat(&self, i: usize) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn createFileFormat_all(&self) ->  Vec<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn createFileFormat(&self, i: usize) -> Option<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn locationSpec_all(&self) ->  Vec<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn locationSpec(&self, i: usize) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn commentSpec_all(&self) ->  Vec<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn commentSpec(&self, i: usize) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token OPTIONS in current rule
fn OPTIONS_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token OPTIONS, starting from 0.
/// Returns `None` if number of children corresponding to token OPTIONS is less or equal than `i`.
fn OPTIONS(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, i)
}
/// Retrieves all `TerminalNode`s corresponding to token PARTITIONED in current rule
fn PARTITIONED_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token PARTITIONED, starting from 0.
/// Returns `None` if number of children corresponding to token PARTITIONED is less or equal than `i`.
fn PARTITIONED(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, i)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token TBLPROPERTIES in current rule
fn TBLPROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token TBLPROPERTIES, starting from 0.
/// Returns `None` if number of children corresponding to token TBLPROPERTIES is less or equal than `i`.
fn TBLPROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TBLPROPERTIES, i)
}
fn properties_all(&self) ->  Vec<Rc<PropertiesContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn properties(&self, i: usize) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn partitionField_all(&self) ->  Vec<Rc<PartitionFieldContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionField(&self, i: usize) -> Option<Rc<PartitionFieldContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> CreateTableClausesContextAttrs<'input> for CreateTableClausesContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createTableClauses(&mut self,)
	-> Result<Rc<CreateTableClausesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateTableClausesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 22, RULE_createTableClauses);
        let mut _localctx: Rc<CreateTableClausesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1057);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 46)) & !0x3f) == 0 && ((1usize << (_la - 46)) & ((1usize << (CLUSTER - 46)) | (1usize << (CLUSTERED - 46)) | (1usize << (COMMENT - 46)))) != 0) || _la==LOCATION || _la==OPTIONS || _la==PARTITIONED || ((((_la - 286)) & !0x3f) == 0 && ((1usize << (_la - 286)) & ((1usize << (ROW - 286)) | (1usize << (SKEWED - 286)) | (1usize << (STORED - 286)))) != 0) || _la==TBLPROPERTIES {
				{
				recog.base.set_state(1055);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 OPTIONS 
					=> {
						{
						{
						recog.base.set_state(1031);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(1032);
						let tmp = recog.properties()?;
						 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).options = Some(tmp.clone());
						  

						}
						}
					}

				 PARTITIONED 
					=> {
						{
						{
						recog.base.set_state(1033);
						recog.base.match_token(PARTITIONED,&mut recog.err_handler)?;

						recog.base.set_state(1034);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						recog.base.set_state(1035);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						/*InvokeRule partitionField*/
						recog.base.set_state(1036);
						let tmp = recog.partitionField()?;
						 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).partitionField = Some(tmp.clone());
						  

						let temp =  cast_mut::<_,CreateTableClausesContext >(&mut _localctx).partitionField.clone().unwrap()
						 ;
						 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).fields.push(temp);
						  
						recog.base.set_state(1041);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(1037);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule partitionField*/
							recog.base.set_state(1038);
							let tmp = recog.partitionField()?;
							 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).partitionField = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,CreateTableClausesContext >(&mut _localctx).partitionField.clone().unwrap()
							 ;
							 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).fields.push(temp);
							  
							}
							}
							recog.base.set_state(1043);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						recog.base.set_state(1044);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
						}
					}

				 SKEWED 
					=> {
						{
						/*InvokeRule skewSpec*/
						recog.base.set_state(1046);
						recog.skewSpec()?;

						}
					}

				 CLUSTER 
					=> {
						{
						/*InvokeRule clusterBySpec*/
						recog.base.set_state(1047);
						recog.clusterBySpec()?;

						}
					}

				 CLUSTERED 
					=> {
						{
						/*InvokeRule bucketSpec*/
						recog.base.set_state(1048);
						recog.bucketSpec()?;

						}
					}

				 ROW 
					=> {
						{
						/*InvokeRule rowFormat*/
						recog.base.set_state(1049);
						recog.rowFormat()?;

						}
					}

				 STORED 
					=> {
						{
						/*InvokeRule createFileFormat*/
						recog.base.set_state(1050);
						recog.createFileFormat()?;

						}
					}

				 LOCATION 
					=> {
						{
						/*InvokeRule locationSpec*/
						recog.base.set_state(1051);
						recog.locationSpec()?;

						}
					}

				 COMMENT 
					=> {
						{
						/*InvokeRule commentSpec*/
						recog.base.set_state(1052);
						recog.commentSpec()?;

						}
					}

				 TBLPROPERTIES 
					=> {
						{
						{
						recog.base.set_state(1053);
						recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(1054);
						let tmp = recog.properties()?;
						 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).tableProps = Some(tmp.clone());
						  

						}
						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
				recog.base.set_state(1059);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableProvider ----------------
pub type TableProviderContextAll<'input> = TableProviderContext<'input>;


pub type TableProviderContext<'input> = BaseParserRuleContext<'input,TableProviderContextExt<'input>>;

#[derive(Clone)]
pub struct TableProviderContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableProviderContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableProviderContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableProvider(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_tableProvider(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableProviderContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableProvider(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableProviderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableProvider }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableProvider }
}
antlr_rust::tid!{TableProviderContextExt<'a>}

impl<'input> TableProviderContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableProviderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableProviderContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableProviderContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableProviderContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONS
/// Returns `None` if there is no child corresponding to token OPTIONS
fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOUBLEQUOTED_STRING in current rule
fn DOUBLEQUOTED_STRING_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOUBLEQUOTED_STRING, starting from 0.
/// Returns `None` if number of children corresponding to token DOUBLEQUOTED_STRING is less or equal than `i`.
fn DOUBLEQUOTED_STRING(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DOUBLEQUOTED_STRING, i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableProviderContextAttrs<'input> for TableProviderContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableProvider(&mut self,)
	-> Result<Rc<TableProviderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableProviderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 24, RULE_tableProvider);
        let mut _localctx: Rc<TableProviderContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1060);
			recog.base.match_token(USING,&mut recog.err_handler)?;

			/*InvokeRule qualifiedName*/
			recog.base.set_state(1061);
			recog.qualifiedName()?;

			recog.base.set_state(1077);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(92,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1062);
					recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

					recog.base.set_state(1063);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(1064);
					recog.identifier()?;

					recog.base.set_state(1065);
					recog.base.match_token(DOUBLEQUOTED_STRING,&mut recog.err_handler)?;

					recog.base.set_state(1072);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(1066);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(1067);
						recog.identifier()?;

						recog.base.set_state(1068);
						recog.base.match_token(DOUBLEQUOTED_STRING,&mut recog.err_handler)?;

						}
						}
						recog.base.set_state(1074);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1075);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionField ----------------
#[derive(Debug)]
pub enum PartitionFieldContextAll<'input>{
	PartitionColumnContext(PartitionColumnContext<'input>),
	PartitionTransformContext(PartitionTransformContext<'input>),
Error(PartitionFieldContext<'input>)
}
antlr_rust::tid!{PartitionFieldContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PartitionFieldContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PartitionFieldContextAll<'input>{}

impl<'input> Deref for PartitionFieldContextAll<'input>{
	type Target = dyn PartitionFieldContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PartitionFieldContextAll::*;
		match self{
			PartitionColumnContext(inner) => inner,
			PartitionTransformContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PartitionFieldContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PartitionFieldContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PartitionFieldContext<'input> = BaseParserRuleContext<'input,PartitionFieldContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PartitionFieldContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PartitionFieldContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PartitionFieldContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PartitionFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionField }
}
antlr_rust::tid!{PartitionFieldContextExt<'a>}

impl<'input> PartitionFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionFieldContextAll<'input>> {
		Rc::new(
		PartitionFieldContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionFieldContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PartitionFieldContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PartitionFieldContextExt<'input>>{


}

impl<'input> PartitionFieldContextAttrs<'input> for PartitionFieldContext<'input>{}

pub type PartitionColumnContext<'input> = BaseParserRuleContext<'input,PartitionColumnContextExt<'input>>;

pub trait PartitionColumnContextAttrs<'input>: DatabricksParserContext<'input>{
	fn colType(&self) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PartitionColumnContextAttrs<'input> for PartitionColumnContext<'input>{}

pub struct PartitionColumnContextExt<'input>{
	base:PartitionFieldContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PartitionColumnContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PartitionColumnContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PartitionColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_partitionColumn(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_partitionColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PartitionColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_partitionColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionField }
}

impl<'input> Borrow<PartitionFieldContextExt<'input>> for PartitionColumnContext<'input>{
	fn borrow(&self) -> &PartitionFieldContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PartitionFieldContextExt<'input>> for PartitionColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut PartitionFieldContextExt<'input> { &mut self.base }
}

impl<'input> PartitionFieldContextAttrs<'input> for PartitionColumnContext<'input> {}

impl<'input> PartitionColumnContextExt<'input>{
	fn new(ctx: &dyn PartitionFieldContextAttrs<'input>) -> Rc<PartitionFieldContextAll<'input>>  {
		Rc::new(
			PartitionFieldContextAll::PartitionColumnContext(
				BaseParserRuleContext::copy_from(ctx,PartitionColumnContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PartitionTransformContext<'input> = BaseParserRuleContext<'input,PartitionTransformContextExt<'input>>;

pub trait PartitionTransformContextAttrs<'input>: DatabricksParserContext<'input>{
	fn transform(&self) -> Option<Rc<TransformContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PartitionTransformContextAttrs<'input> for PartitionTransformContext<'input>{}

pub struct PartitionTransformContextExt<'input>{
	base:PartitionFieldContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PartitionTransformContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PartitionTransformContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PartitionTransformContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_partitionTransform(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_partitionTransform(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PartitionTransformContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_partitionTransform(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionTransformContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionField }
}

impl<'input> Borrow<PartitionFieldContextExt<'input>> for PartitionTransformContext<'input>{
	fn borrow(&self) -> &PartitionFieldContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PartitionFieldContextExt<'input>> for PartitionTransformContext<'input>{
	fn borrow_mut(&mut self) -> &mut PartitionFieldContextExt<'input> { &mut self.base }
}

impl<'input> PartitionFieldContextAttrs<'input> for PartitionTransformContext<'input> {}

impl<'input> PartitionTransformContextExt<'input>{
	fn new(ctx: &dyn PartitionFieldContextAttrs<'input>) -> Rc<PartitionFieldContextAll<'input>>  {
		Rc::new(
			PartitionFieldContextAll::PartitionTransformContext(
				BaseParserRuleContext::copy_from(ctx,PartitionTransformContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionField(&mut self,)
	-> Result<Rc<PartitionFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 26, RULE_partitionField);
        let mut _localctx: Rc<PartitionFieldContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1081);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(93,&mut recog.base)? {
				1 =>{
					let tmp = PartitionTransformContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule transform*/
					recog.base.set_state(1079);
					recog.transform()?;

					}
				}
			,
				2 =>{
					let tmp = PartitionColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule colType*/
					recog.base.set_state(1080);
					recog.colType()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transform ----------------
#[derive(Debug)]
pub enum TransformContextAll<'input>{
	IdentityTransformContext(IdentityTransformContext<'input>),
	ApplyTransformContext(ApplyTransformContext<'input>),
Error(TransformContext<'input>)
}
antlr_rust::tid!{TransformContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TransformContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for TransformContextAll<'input>{}

impl<'input> Deref for TransformContextAll<'input>{
	type Target = dyn TransformContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TransformContextAll::*;
		match self{
			IdentityTransformContext(inner) => inner,
			ApplyTransformContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TransformContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TransformContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TransformContext<'input> = BaseParserRuleContext<'input,TransformContextExt<'input>>;

#[derive(Clone)]
pub struct TransformContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TransformContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TransformContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TransformContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TransformContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transform }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transform }
}
antlr_rust::tid!{TransformContextExt<'a>}

impl<'input> TransformContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransformContextAll<'input>> {
		Rc::new(
		TransformContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransformContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TransformContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TransformContextExt<'input>>{


}

impl<'input> TransformContextAttrs<'input> for TransformContext<'input>{}

pub type IdentityTransformContext<'input> = BaseParserRuleContext<'input,IdentityTransformContextExt<'input>>;

pub trait IdentityTransformContextAttrs<'input>: DatabricksParserContext<'input>{
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IdentityTransformContextAttrs<'input> for IdentityTransformContext<'input>{}

pub struct IdentityTransformContextExt<'input>{
	base:TransformContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IdentityTransformContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for IdentityTransformContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentityTransformContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_identityTransform(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_identityTransform(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentityTransformContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_identityTransform(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentityTransformContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transform }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transform }
}

impl<'input> Borrow<TransformContextExt<'input>> for IdentityTransformContext<'input>{
	fn borrow(&self) -> &TransformContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TransformContextExt<'input>> for IdentityTransformContext<'input>{
	fn borrow_mut(&mut self) -> &mut TransformContextExt<'input> { &mut self.base }
}

impl<'input> TransformContextAttrs<'input> for IdentityTransformContext<'input> {}

impl<'input> IdentityTransformContextExt<'input>{
	fn new(ctx: &dyn TransformContextAttrs<'input>) -> Rc<TransformContextAll<'input>>  {
		Rc::new(
			TransformContextAll::IdentityTransformContext(
				BaseParserRuleContext::copy_from(ctx,IdentityTransformContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ApplyTransformContext<'input> = BaseParserRuleContext<'input,ApplyTransformContextExt<'input>>;

pub trait ApplyTransformContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn transformArgument_all(&self) ->  Vec<Rc<TransformArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn transformArgument(&self, i: usize) -> Option<Rc<TransformArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ApplyTransformContextAttrs<'input> for ApplyTransformContext<'input>{}

pub struct ApplyTransformContextExt<'input>{
	base:TransformContextExt<'input>,
	pub transformName: Option<Rc<IdentifierContextAll<'input>>>,
	pub transformArgument: Option<Rc<TransformArgumentContextAll<'input>>>,
	pub argument:Vec<Rc<TransformArgumentContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ApplyTransformContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ApplyTransformContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ApplyTransformContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_applyTransform(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_applyTransform(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ApplyTransformContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_applyTransform(self);
	}
}

impl<'input> CustomRuleContext<'input> for ApplyTransformContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transform }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transform }
}

impl<'input> Borrow<TransformContextExt<'input>> for ApplyTransformContext<'input>{
	fn borrow(&self) -> &TransformContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TransformContextExt<'input>> for ApplyTransformContext<'input>{
	fn borrow_mut(&mut self) -> &mut TransformContextExt<'input> { &mut self.base }
}

impl<'input> TransformContextAttrs<'input> for ApplyTransformContext<'input> {}

impl<'input> ApplyTransformContextExt<'input>{
	fn new(ctx: &dyn TransformContextAttrs<'input>) -> Rc<TransformContextAll<'input>>  {
		Rc::new(
			TransformContextAll::ApplyTransformContext(
				BaseParserRuleContext::copy_from(ctx,ApplyTransformContextExt{
        			transformName:None, transformArgument:None, 
        			argument:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transform(&mut self,)
	-> Result<Rc<TransformContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransformContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 28, RULE_transform);
        let mut _localctx: Rc<TransformContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1096);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(95,&mut recog.base)? {
				1 =>{
					let tmp = IdentityTransformContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(1083);
					recog.qualifiedName()?;

					}
				}
			,
				2 =>{
					let tmp = ApplyTransformContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1084);
					let tmp = recog.identifier()?;
					if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
					ctx.transformName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1085);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule transformArgument*/
					recog.base.set_state(1086);
					let tmp = recog.transformArgument()?;
					if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
					ctx.transformArgument = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
					ctx.transformArgument.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
					ctx.argument.push(temp); } else {unreachable!("cant cast");}  
					recog.base.set_state(1091);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(1087);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule transformArgument*/
						recog.base.set_state(1088);
						let tmp = recog.transformArgument()?;
						if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
						ctx.transformArgument = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
						ctx.transformArgument.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
						ctx.argument.push(temp); } else {unreachable!("cant cast");}  
						}
						}
						recog.base.set_state(1093);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1094);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transformArgument ----------------
pub type TransformArgumentContextAll<'input> = TransformArgumentContext<'input>;


pub type TransformArgumentContext<'input> = BaseParserRuleContext<'input,TransformArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct TransformArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TransformArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TransformArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_transformArgument(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_transformArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TransformArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_transformArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for TransformArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transformArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transformArgument }
}
antlr_rust::tid!{TransformArgumentContextExt<'a>}

impl<'input> TransformArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransformArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransformArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TransformArgumentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TransformArgumentContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TransformArgumentContextAttrs<'input> for TransformArgumentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transformArgument(&mut self,)
	-> Result<Rc<TransformArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransformArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 30, RULE_transformArgument);
        let mut _localctx: Rc<TransformArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1100);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(96,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(1098);
					recog.qualifiedName()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule constant*/
					recog.base.set_state(1099);
					recog.constant()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colType ----------------
pub type ColTypeContextAll<'input> = ColTypeContext<'input>;


pub type ColTypeContext<'input> = BaseParserRuleContext<'input,ColTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ColTypeContextExt<'input>{
	pub colName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colType(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_colType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_colType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colType }
}
antlr_rust::tid!{ColTypeContextExt<'a>}

impl<'input> ColTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColTypeContextExt{
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColTypeContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColTypeContextExt<'input>>{

fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColTypeContextAttrs<'input> for ColTypeContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colType(&mut self,)
	-> Result<Rc<ColTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 32, RULE_colType);
        let mut _localctx: Rc<ColTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1102);
			let tmp = recog.identifier()?;
			 cast_mut::<_,ColTypeContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			/*InvokeRule type_*/
			recog.base.set_state(1103);
			recog.type_()?;

			recog.base.set_state(1106);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==NOT {
				{
				recog.base.set_state(1104);
				recog.base.match_token(NOT,&mut recog.err_handler)?;

				recog.base.set_state(1105);
				recog.base.match_token(NULL,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1109);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMENT {
				{
				/*InvokeRule commentSpec*/
				recog.base.set_state(1108);
				recog.commentSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewSpec ----------------
pub type SkewSpecContextAll<'input> = SkewSpecContext<'input>;


pub type SkewSpecContext<'input> = BaseParserRuleContext<'input,SkewSpecContextExt<'input>>;

#[derive(Clone)]
pub struct SkewSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SkewSpecContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SkewSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewSpec(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_skewSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SkewSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_skewSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for SkewSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewSpec }
}
antlr_rust::tid!{SkewSpecContextExt<'a>}

impl<'input> SkewSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewSpecContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SkewSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SKEWED
/// Returns `None` if there is no child corresponding to token SKEWED
fn SKEWED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn constantList(&self) -> Option<Rc<ConstantListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn nestedConstantList(&self) -> Option<Rc<NestedConstantListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORIES
/// Returns `None` if there is no child corresponding to token DIRECTORIES
fn DIRECTORIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORIES, 0)
}

}

impl<'input> SkewSpecContextAttrs<'input> for SkewSpecContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewSpec(&mut self,)
	-> Result<Rc<SkewSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 34, RULE_skewSpec);
        let mut _localctx: Rc<SkewSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1111);
			recog.base.match_token(SKEWED,&mut recog.err_handler)?;

			recog.base.set_state(1112);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule identifierList*/
			recog.base.set_state(1113);
			recog.identifierList()?;

			recog.base.set_state(1114);
			recog.base.match_token(ON,&mut recog.err_handler)?;

			recog.base.set_state(1117);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(99,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule constantList*/
					recog.base.set_state(1115);
					recog.constantList()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule nestedConstantList*/
					recog.base.set_state(1116);
					recog.nestedConstantList()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(1122);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(100,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1119);
					recog.base.match_token(STORED,&mut recog.err_handler)?;

					recog.base.set_state(1120);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(1121);
					recog.base.match_token(DIRECTORIES,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- clusterBySpec ----------------
pub type ClusterBySpecContextAll<'input> = ClusterBySpecContext<'input>;


pub type ClusterBySpecContext<'input> = BaseParserRuleContext<'input,ClusterBySpecContextExt<'input>>;

#[derive(Clone)]
pub struct ClusterBySpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ClusterBySpecContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ClusterBySpecContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_clusterBySpec(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_clusterBySpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ClusterBySpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_clusterBySpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for ClusterBySpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_clusterBySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_clusterBySpec }
}
antlr_rust::tid!{ClusterBySpecContextExt<'a>}

impl<'input> ClusterBySpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ClusterBySpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ClusterBySpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ClusterBySpecContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ClusterBySpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ClusterBySpecContextAttrs<'input> for ClusterBySpecContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn clusterBySpec(&mut self,)
	-> Result<Rc<ClusterBySpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ClusterBySpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 36, RULE_clusterBySpec);
        let mut _localctx: Rc<ClusterBySpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1124);
			recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

			recog.base.set_state(1125);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			recog.base.set_state(1126);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule qualifiedName*/
			recog.base.set_state(1127);
			recog.qualifiedName()?;

			recog.base.set_state(1132);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1128);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule qualifiedName*/
				recog.base.set_state(1129);
				recog.qualifiedName()?;

				}
				}
				recog.base.set_state(1134);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1135);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- bucketSpec ----------------
pub type BucketSpecContextAll<'input> = BucketSpecContext<'input>;


pub type BucketSpecContext<'input> = BaseParserRuleContext<'input,BucketSpecContextExt<'input>>;

#[derive(Clone)]
pub struct BucketSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for BucketSpecContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BucketSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_bucketSpec(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_bucketSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BucketSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_bucketSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for BucketSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_bucketSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_bucketSpec }
}
antlr_rust::tid!{BucketSpecContextExt<'a>}

impl<'input> BucketSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BucketSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BucketSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BucketSpecContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<BucketSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CLUSTERED
/// Returns `None` if there is no child corresponding to token CLUSTERED
fn CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CLUSTERED, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token INTO
/// Returns `None` if there is no child corresponding to token INTO
fn INTO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token BUCKETS
/// Returns `None` if there is no child corresponding to token BUCKETS
fn BUCKETS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BUCKETS, 0)
}
/// Retrieves first TerminalNode corresponding to token SORTED
/// Returns `None` if there is no child corresponding to token SORTED
fn SORTED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SORTED, 0)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> BucketSpecContextAttrs<'input> for BucketSpecContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn bucketSpec(&mut self,)
	-> Result<Rc<BucketSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BucketSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 38, RULE_bucketSpec);
        let mut _localctx: Rc<BucketSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1137);
			recog.base.match_token(CLUSTERED,&mut recog.err_handler)?;

			recog.base.set_state(1138);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule identifierList*/
			recog.base.set_state(1139);
			recog.identifierList()?;

			recog.base.set_state(1150);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SORTED {
				{
				recog.base.set_state(1140);
				recog.base.match_token(SORTED,&mut recog.err_handler)?;

				recog.base.set_state(1141);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule sortItem*/
				recog.base.set_state(1142);
				recog.sortItem()?;

				recog.base.set_state(1147);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1143);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(1144);
					recog.sortItem()?;

					}
					}
					recog.base.set_state(1149);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(1152);
			recog.base.match_token(INTO,&mut recog.err_handler)?;

			recog.base.set_state(1153);
			recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

			recog.base.set_state(1154);
			recog.base.match_token(BUCKETS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- constantList ----------------
pub type ConstantListContextAll<'input> = ConstantListContext<'input>;


pub type ConstantListContext<'input> = BaseParserRuleContext<'input,ConstantListContextExt<'input>>;

#[derive(Clone)]
pub struct ConstantListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ConstantListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ConstantListContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_constantList(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_constantList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ConstantListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_constantList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConstantListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constantList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constantList }
}
antlr_rust::tid!{ConstantListContextExt<'a>}

impl<'input> ConstantListContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConstantListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConstantListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConstantListContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ConstantListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn constant_all(&self) ->  Vec<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn constant(&self, i: usize) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ConstantListContextAttrs<'input> for ConstantListContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn constantList(&mut self,)
	-> Result<Rc<ConstantListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConstantListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 40, RULE_constantList);
        let mut _localctx: Rc<ConstantListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1156);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule constant*/
			recog.base.set_state(1157);
			recog.constant()?;

			recog.base.set_state(1162);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1158);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule constant*/
				recog.base.set_state(1159);
				recog.constant()?;

				}
				}
				recog.base.set_state(1164);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1165);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nestedConstantList ----------------
pub type NestedConstantListContextAll<'input> = NestedConstantListContext<'input>;


pub type NestedConstantListContext<'input> = BaseParserRuleContext<'input,NestedConstantListContextExt<'input>>;

#[derive(Clone)]
pub struct NestedConstantListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NestedConstantListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NestedConstantListContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nestedConstantList(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_nestedConstantList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NestedConstantListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_nestedConstantList(self);
	}
}

impl<'input> CustomRuleContext<'input> for NestedConstantListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nestedConstantList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nestedConstantList }
}
antlr_rust::tid!{NestedConstantListContextExt<'a>}

impl<'input> NestedConstantListContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NestedConstantListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NestedConstantListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NestedConstantListContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NestedConstantListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn constantList_all(&self) ->  Vec<Rc<ConstantListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn constantList(&self, i: usize) -> Option<Rc<ConstantListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NestedConstantListContextAttrs<'input> for NestedConstantListContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nestedConstantList(&mut self,)
	-> Result<Rc<NestedConstantListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NestedConstantListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 42, RULE_nestedConstantList);
        let mut _localctx: Rc<NestedConstantListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1167);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule constantList*/
			recog.base.set_state(1168);
			recog.constantList()?;

			recog.base.set_state(1173);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1169);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule constantList*/
				recog.base.set_state(1170);
				recog.constantList()?;

				}
				}
				recog.base.set_state(1175);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1176);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowFormat ----------------
#[derive(Debug)]
pub enum RowFormatContextAll<'input>{
	RowFormatSerdeContext(RowFormatSerdeContext<'input>),
	RowFormatDelimitedContext(RowFormatDelimitedContext<'input>),
Error(RowFormatContext<'input>)
}
antlr_rust::tid!{RowFormatContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RowFormatContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for RowFormatContextAll<'input>{}

impl<'input> Deref for RowFormatContextAll<'input>{
	type Target = dyn RowFormatContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RowFormatContextAll::*;
		match self{
			RowFormatSerdeContext(inner) => inner,
			RowFormatDelimitedContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RowFormatContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RowFormatContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RowFormatContext<'input> = BaseParserRuleContext<'input,RowFormatContextExt<'input>>;

#[derive(Clone)]
pub struct RowFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for RowFormatContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RowFormatContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RowFormatContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RowFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormat }
}
antlr_rust::tid!{RowFormatContextExt<'a>}

impl<'input> RowFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFormatContextAll<'input>> {
		Rc::new(
		RowFormatContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFormatContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RowFormatContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<RowFormatContextExt<'input>>{


}

impl<'input> RowFormatContextAttrs<'input> for RowFormatContext<'input>{}

pub type RowFormatSerdeContext<'input> = BaseParserRuleContext<'input,RowFormatSerdeContextExt<'input>>;

pub trait RowFormatSerdeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMAT
	/// Returns `None` if there is no child corresponding to token FORMAT
	fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FORMAT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SERDE
	/// Returns `None` if there is no child corresponding to token SERDE
	fn SERDE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SERDE, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
	/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
	fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SERDEPROPERTIES, 0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RowFormatSerdeContextAttrs<'input> for RowFormatSerdeContext<'input>{}

pub struct RowFormatSerdeContextExt<'input>{
	base:RowFormatContextExt<'input>,
	pub name: Option<Rc<StringContextAll<'input>>>,
	pub props: Option<Rc<PropertiesContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowFormatSerdeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RowFormatSerdeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RowFormatSerdeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowFormatSerde(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_rowFormatSerde(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RowFormatSerdeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rowFormatSerde(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFormatSerdeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormat }
}

impl<'input> Borrow<RowFormatContextExt<'input>> for RowFormatSerdeContext<'input>{
	fn borrow(&self) -> &RowFormatContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowFormatContextExt<'input>> for RowFormatSerdeContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowFormatContextExt<'input> { &mut self.base }
}

impl<'input> RowFormatContextAttrs<'input> for RowFormatSerdeContext<'input> {}

impl<'input> RowFormatSerdeContextExt<'input>{
	fn new(ctx: &dyn RowFormatContextAttrs<'input>) -> Rc<RowFormatContextAll<'input>>  {
		Rc::new(
			RowFormatContextAll::RowFormatSerdeContext(
				BaseParserRuleContext::copy_from(ctx,RowFormatSerdeContextExt{
        			name:None, props:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RowFormatDelimitedContext<'input> = BaseParserRuleContext<'input,RowFormatDelimitedContextExt<'input>>;

pub trait RowFormatDelimitedContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMAT
	/// Returns `None` if there is no child corresponding to token FORMAT
	fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FORMAT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DELIMITED
	/// Returns `None` if there is no child corresponding to token DELIMITED
	fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DELIMITED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FIELDS
	/// Returns `None` if there is no child corresponding to token FIELDS
	fn FIELDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FIELDS, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TERMINATED in current rule
	fn TERMINATED_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TERMINATED, starting from 0.
	/// Returns `None` if number of children corresponding to token TERMINATED is less or equal than `i`.
	fn TERMINATED(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TERMINATED, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	/// Retrieves first TerminalNode corresponding to token COLLECTION
	/// Returns `None` if there is no child corresponding to token COLLECTION
	fn COLLECTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COLLECTION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ITEMS
	/// Returns `None` if there is no child corresponding to token ITEMS
	fn ITEMS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ITEMS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MAP
	/// Returns `None` if there is no child corresponding to token MAP
	fn MAP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MAP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token KEYS
	/// Returns `None` if there is no child corresponding to token KEYS
	fn KEYS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(KEYS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LINES
	/// Returns `None` if there is no child corresponding to token LINES
	fn LINES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LINES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DEFINED
	/// Returns `None` if there is no child corresponding to token DEFINED
	fn DEFINED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DEFINED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn string_all(&self) ->  Vec<Rc<StringContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn string(&self, i: usize) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ESCAPED
	/// Returns `None` if there is no child corresponding to token ESCAPED
	fn ESCAPED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ESCAPED, 0)
	}
}

impl<'input> RowFormatDelimitedContextAttrs<'input> for RowFormatDelimitedContext<'input>{}

pub struct RowFormatDelimitedContextExt<'input>{
	base:RowFormatContextExt<'input>,
	pub fieldsTerminatedBy: Option<Rc<StringContextAll<'input>>>,
	pub escapedBy: Option<Rc<StringContextAll<'input>>>,
	pub collectionItemsTerminatedBy: Option<Rc<StringContextAll<'input>>>,
	pub keysTerminatedBy: Option<Rc<StringContextAll<'input>>>,
	pub linesSeparatedBy: Option<Rc<StringContextAll<'input>>>,
	pub nullDefinedAs: Option<Rc<StringContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowFormatDelimitedContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RowFormatDelimitedContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RowFormatDelimitedContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowFormatDelimited(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_rowFormatDelimited(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RowFormatDelimitedContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rowFormatDelimited(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFormatDelimitedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormat }
}

impl<'input> Borrow<RowFormatContextExt<'input>> for RowFormatDelimitedContext<'input>{
	fn borrow(&self) -> &RowFormatContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowFormatContextExt<'input>> for RowFormatDelimitedContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowFormatContextExt<'input> { &mut self.base }
}

impl<'input> RowFormatContextAttrs<'input> for RowFormatDelimitedContext<'input> {}

impl<'input> RowFormatDelimitedContextExt<'input>{
	fn new(ctx: &dyn RowFormatContextAttrs<'input>) -> Rc<RowFormatContextAll<'input>>  {
		Rc::new(
			RowFormatContextAll::RowFormatDelimitedContext(
				BaseParserRuleContext::copy_from(ctx,RowFormatDelimitedContextExt{
        			fieldsTerminatedBy:None, escapedBy:None, collectionItemsTerminatedBy:None, keysTerminatedBy:None, linesSeparatedBy:None, nullDefinedAs:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowFormat(&mut self,)
	-> Result<Rc<RowFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 44, RULE_rowFormat);
        let mut _localctx: Rc<RowFormatContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1227);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(113,&mut recog.base)? {
				1 =>{
					let tmp = RowFormatSerdeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1178);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					recog.base.set_state(1179);
					recog.base.match_token(FORMAT,&mut recog.err_handler)?;

					recog.base.set_state(1180);
					recog.base.match_token(SERDE,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1181);
					let tmp = recog.string()?;
					if let RowFormatContextAll::RowFormatSerdeContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1185);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(106,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1182);
							recog.base.match_token(WITH,&mut recog.err_handler)?;

							recog.base.set_state(1183);
							recog.base.match_token(SERDEPROPERTIES,&mut recog.err_handler)?;

							/*InvokeRule properties*/
							recog.base.set_state(1184);
							let tmp = recog.properties()?;
							if let RowFormatContextAll::RowFormatSerdeContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.props = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = RowFormatDelimitedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1187);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					recog.base.set_state(1188);
					recog.base.match_token(FORMAT,&mut recog.err_handler)?;

					recog.base.set_state(1189);
					recog.base.match_token(DELIMITED,&mut recog.err_handler)?;

					recog.base.set_state(1199);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FIELDS {
						{
						recog.base.set_state(1190);
						recog.base.match_token(FIELDS,&mut recog.err_handler)?;

						recog.base.set_state(1191);
						recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

						recog.base.set_state(1192);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(1193);
						let tmp = recog.string()?;
						if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
						ctx.fieldsTerminatedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						recog.base.set_state(1197);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==ESCAPED {
							{
							recog.base.set_state(1194);
							recog.base.match_token(ESCAPED,&mut recog.err_handler)?;

							recog.base.set_state(1195);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule string*/
							recog.base.set_state(1196);
							let tmp = recog.string()?;
							if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.escapedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(1206);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COLLECTION {
						{
						recog.base.set_state(1201);
						recog.base.match_token(COLLECTION,&mut recog.err_handler)?;

						recog.base.set_state(1202);
						recog.base.match_token(ITEMS,&mut recog.err_handler)?;

						recog.base.set_state(1203);
						recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

						recog.base.set_state(1204);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(1205);
						let tmp = recog.string()?;
						if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
						ctx.collectionItemsTerminatedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(1213);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(110,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1208);
							recog.base.match_token(MAP,&mut recog.err_handler)?;

							recog.base.set_state(1209);
							recog.base.match_token(KEYS,&mut recog.err_handler)?;

							recog.base.set_state(1210);
							recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

							recog.base.set_state(1211);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule string*/
							recog.base.set_state(1212);
							let tmp = recog.string()?;
							if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.keysTerminatedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(1219);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LINES {
						{
						recog.base.set_state(1215);
						recog.base.match_token(LINES,&mut recog.err_handler)?;

						recog.base.set_state(1216);
						recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

						recog.base.set_state(1217);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(1218);
						let tmp = recog.string()?;
						if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
						ctx.linesSeparatedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(1225);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NULL {
						{
						recog.base.set_state(1221);
						recog.base.match_token(NULL,&mut recog.err_handler)?;

						recog.base.set_state(1222);
						recog.base.match_token(DEFINED,&mut recog.err_handler)?;

						recog.base.set_state(1223);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						/*InvokeRule string*/
						recog.base.set_state(1224);
						let tmp = recog.string()?;
						if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
						ctx.nullDefinedAs = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createFileFormat ----------------
pub type CreateFileFormatContextAll<'input> = CreateFileFormatContext<'input>;


pub type CreateFileFormatContext<'input> = BaseParserRuleContext<'input,CreateFileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct CreateFileFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for CreateFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CreateFileFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createFileFormat(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_createFileFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CreateFileFormatContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_createFileFormat(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createFileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createFileFormat }
}
antlr_rust::tid!{CreateFileFormatContextExt<'a>}

impl<'input> CreateFileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateFileFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateFileFormatContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateFileFormatContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<CreateFileFormatContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn fileFormat(&self) -> Option<Rc<FileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn storageHandler(&self) -> Option<Rc<StorageHandlerContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateFileFormatContextAttrs<'input> for CreateFileFormatContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createFileFormat(&mut self,)
	-> Result<Rc<CreateFileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateFileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 46, RULE_createFileFormat);
        let mut _localctx: Rc<CreateFileFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1235);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(114,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1229);
					recog.base.match_token(STORED,&mut recog.err_handler)?;

					recog.base.set_state(1230);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule fileFormat*/
					recog.base.set_state(1231);
					recog.fileFormat()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1232);
					recog.base.match_token(STORED,&mut recog.err_handler)?;

					recog.base.set_state(1233);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule storageHandler*/
					recog.base.set_state(1234);
					recog.storageHandler()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fileFormat ----------------
#[derive(Debug)]
pub enum FileFormatContextAll<'input>{
	TableFileFormatContext(TableFileFormatContext<'input>),
	GenericFileFormatContext(GenericFileFormatContext<'input>),
Error(FileFormatContext<'input>)
}
antlr_rust::tid!{FileFormatContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for FileFormatContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for FileFormatContextAll<'input>{}

impl<'input> Deref for FileFormatContextAll<'input>{
	type Target = dyn FileFormatContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use FileFormatContextAll::*;
		match self{
			TableFileFormatContext(inner) => inner,
			GenericFileFormatContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FileFormatContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FileFormatContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type FileFormatContext<'input> = BaseParserRuleContext<'input,FileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct FileFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FileFormatContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FileFormatContext<'input>{
}

impl<'input> CustomRuleContext<'input> for FileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fileFormat }
}
antlr_rust::tid!{FileFormatContextExt<'a>}

impl<'input> FileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FileFormatContextAll<'input>> {
		Rc::new(
		FileFormatContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FileFormatContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait FileFormatContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FileFormatContextExt<'input>>{


}

impl<'input> FileFormatContextAttrs<'input> for FileFormatContext<'input>{}

pub type TableFileFormatContext<'input> = BaseParserRuleContext<'input,TableFileFormatContextExt<'input>>;

pub trait TableFileFormatContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INPUTFORMAT
	/// Returns `None` if there is no child corresponding to token INPUTFORMAT
	fn INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INPUTFORMAT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OUTPUTFORMAT
	/// Returns `None` if there is no child corresponding to token OUTPUTFORMAT
	fn OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OUTPUTFORMAT, 0)
	}
	fn string_all(&self) ->  Vec<Rc<StringContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn string(&self, i: usize) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> TableFileFormatContextAttrs<'input> for TableFileFormatContext<'input>{}

pub struct TableFileFormatContextExt<'input>{
	base:FileFormatContextExt<'input>,
	pub inFmt: Option<Rc<StringContextAll<'input>>>,
	pub outFmt: Option<Rc<StringContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableFileFormatContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TableFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableFileFormatContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableFileFormat(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_tableFileFormat(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableFileFormatContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableFileFormat(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fileFormat }
}

impl<'input> Borrow<FileFormatContextExt<'input>> for TableFileFormatContext<'input>{
	fn borrow(&self) -> &FileFormatContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FileFormatContextExt<'input>> for TableFileFormatContext<'input>{
	fn borrow_mut(&mut self) -> &mut FileFormatContextExt<'input> { &mut self.base }
}

impl<'input> FileFormatContextAttrs<'input> for TableFileFormatContext<'input> {}

impl<'input> TableFileFormatContextExt<'input>{
	fn new(ctx: &dyn FileFormatContextAttrs<'input>) -> Rc<FileFormatContextAll<'input>>  {
		Rc::new(
			FileFormatContextAll::TableFileFormatContext(
				BaseParserRuleContext::copy_from(ctx,TableFileFormatContextExt{
        			inFmt:None, outFmt:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GenericFileFormatContext<'input> = BaseParserRuleContext<'input,GenericFileFormatContextExt<'input>>;

pub trait GenericFileFormatContextAttrs<'input>: DatabricksParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> GenericFileFormatContextAttrs<'input> for GenericFileFormatContext<'input>{}

pub struct GenericFileFormatContextExt<'input>{
	base:FileFormatContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GenericFileFormatContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GenericFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GenericFileFormatContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_genericFileFormat(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_genericFileFormat(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GenericFileFormatContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_genericFileFormat(self);
	}
}

impl<'input> CustomRuleContext<'input> for GenericFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fileFormat }
}

impl<'input> Borrow<FileFormatContextExt<'input>> for GenericFileFormatContext<'input>{
	fn borrow(&self) -> &FileFormatContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FileFormatContextExt<'input>> for GenericFileFormatContext<'input>{
	fn borrow_mut(&mut self) -> &mut FileFormatContextExt<'input> { &mut self.base }
}

impl<'input> FileFormatContextAttrs<'input> for GenericFileFormatContext<'input> {}

impl<'input> GenericFileFormatContextExt<'input>{
	fn new(ctx: &dyn FileFormatContextAttrs<'input>) -> Rc<FileFormatContextAll<'input>>  {
		Rc::new(
			FileFormatContextAll::GenericFileFormatContext(
				BaseParserRuleContext::copy_from(ctx,GenericFileFormatContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fileFormat(&mut self,)
	-> Result<Rc<FileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 48, RULE_fileFormat);
        let mut _localctx: Rc<FileFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1243);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(115,&mut recog.base)? {
				1 =>{
					let tmp = TableFileFormatContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1237);
					recog.base.match_token(INPUTFORMAT,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1238);
					let tmp = recog.string()?;
					if let FileFormatContextAll::TableFileFormatContext(ctx) = cast_mut::<_,FileFormatContextAll >(&mut _localctx){
					ctx.inFmt = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1239);
					recog.base.match_token(OUTPUTFORMAT,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1240);
					let tmp = recog.string()?;
					if let FileFormatContextAll::TableFileFormatContext(ctx) = cast_mut::<_,FileFormatContextAll >(&mut _localctx){
					ctx.outFmt = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = GenericFileFormatContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1242);
					recog.identifier()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- storageHandler ----------------
pub type StorageHandlerContextAll<'input> = StorageHandlerContext<'input>;


pub type StorageHandlerContext<'input> = BaseParserRuleContext<'input,StorageHandlerContextExt<'input>>;

#[derive(Clone)]
pub struct StorageHandlerContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StorageHandlerContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StorageHandlerContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_storageHandler(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_storageHandler(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StorageHandlerContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_storageHandler(self);
	}
}

impl<'input> CustomRuleContext<'input> for StorageHandlerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_storageHandler }
	//fn type_rule_index() -> usize where Self: Sized { RULE_storageHandler }
}
antlr_rust::tid!{StorageHandlerContextExt<'a>}

impl<'input> StorageHandlerContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StorageHandlerContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StorageHandlerContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StorageHandlerContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StorageHandlerContextExt<'input>>{

fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SERDEPROPERTIES, 0)
}
fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> StorageHandlerContextAttrs<'input> for StorageHandlerContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn storageHandler(&mut self,)
	-> Result<Rc<StorageHandlerContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StorageHandlerContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 50, RULE_storageHandler);
        let mut _localctx: Rc<StorageHandlerContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule string*/
			recog.base.set_state(1245);
			recog.string()?;

			recog.base.set_state(1249);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(116,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1246);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(1247);
					recog.base.match_token(SERDEPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule properties*/
					recog.base.set_state(1248);
					recog.properties()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- locationSpec ----------------
pub type LocationSpecContextAll<'input> = LocationSpecContext<'input>;


pub type LocationSpecContext<'input> = BaseParserRuleContext<'input,LocationSpecContextExt<'input>>;

#[derive(Clone)]
pub struct LocationSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for LocationSpecContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LocationSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_locationSpec(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_locationSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LocationSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_locationSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for LocationSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_locationSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_locationSpec }
}
antlr_rust::tid!{LocationSpecContextExt<'a>}

impl<'input> LocationSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LocationSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LocationSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LocationSpecContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<LocationSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LocationSpecContextAttrs<'input> for LocationSpecContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn locationSpec(&mut self,)
	-> Result<Rc<LocationSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LocationSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 52, RULE_locationSpec);
        let mut _localctx: Rc<LocationSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1251);
			recog.base.match_token(LOCATION,&mut recog.err_handler)?;

			/*InvokeRule string*/
			recog.base.set_state(1252);
			recog.string()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- literalType ----------------
pub type LiteralTypeContextAll<'input> = LiteralTypeContext<'input>;


pub type LiteralTypeContext<'input> = BaseParserRuleContext<'input,LiteralTypeContextExt<'input>>;

#[derive(Clone)]
pub struct LiteralTypeContextExt<'input>{
	pub unsupportedType: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for LiteralTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LiteralTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_literalType(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_literalType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LiteralTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_literalType(self);
	}
}

impl<'input> CustomRuleContext<'input> for LiteralTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_literalType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_literalType }
}
antlr_rust::tid!{LiteralTypeContextExt<'a>}

impl<'input> LiteralTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LiteralTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LiteralTypeContextExt{
				unsupportedType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LiteralTypeContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<LiteralTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_LTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_LTZ
fn TIMESTAMP_LTZ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_LTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_NTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_NTZ
fn TIMESTAMP_NTZ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_NTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token X_KW
/// Returns `None` if there is no child corresponding to token X_KW
fn X_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(X_KW, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LiteralTypeContextAttrs<'input> for LiteralTypeContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn literalType(&mut self,)
	-> Result<Rc<LiteralTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LiteralTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 54, RULE_literalType);
        let mut _localctx: Rc<LiteralTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1261);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(117,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1254);
					recog.base.match_token(DATE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1255);
					recog.base.match_token(TIMESTAMP,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1256);
					recog.base.match_token(TIMESTAMP_LTZ,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(1257);
					recog.base.match_token(TIMESTAMP_NTZ,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(1258);
					recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(1259);
					recog.base.match_token(X_KW,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1260);
					let tmp = recog.identifier()?;
					 cast_mut::<_,LiteralTypeContext >(&mut _localctx).unsupportedType = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dmlStatementNoWith ----------------
#[derive(Debug)]
pub enum DmlStatementNoWithContextAll<'input>{
	DeleteFromTableContext(DeleteFromTableContext<'input>),
	SingleInsertQueryContext(SingleInsertQueryContext<'input>),
	MultiInsertQueryContext(MultiInsertQueryContext<'input>),
	UpdateTableContext(UpdateTableContext<'input>),
	MergeIntoTableContext(MergeIntoTableContext<'input>),
Error(DmlStatementNoWithContext<'input>)
}
antlr_rust::tid!{DmlStatementNoWithContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for DmlStatementNoWithContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for DmlStatementNoWithContextAll<'input>{}

impl<'input> Deref for DmlStatementNoWithContextAll<'input>{
	type Target = dyn DmlStatementNoWithContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use DmlStatementNoWithContextAll::*;
		match self{
			DeleteFromTableContext(inner) => inner,
			SingleInsertQueryContext(inner) => inner,
			MultiInsertQueryContext(inner) => inner,
			UpdateTableContext(inner) => inner,
			MergeIntoTableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DmlStatementNoWithContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DmlStatementNoWithContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type DmlStatementNoWithContext<'input> = BaseParserRuleContext<'input,DmlStatementNoWithContextExt<'input>>;

#[derive(Clone)]
pub struct DmlStatementNoWithContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for DmlStatementNoWithContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DmlStatementNoWithContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DmlStatementNoWithContext<'input>{
}

impl<'input> CustomRuleContext<'input> for DmlStatementNoWithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}
antlr_rust::tid!{DmlStatementNoWithContextExt<'a>}

impl<'input> DmlStatementNoWithContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DmlStatementNoWithContextAll<'input>> {
		Rc::new(
		DmlStatementNoWithContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DmlStatementNoWithContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait DmlStatementNoWithContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<DmlStatementNoWithContextExt<'input>>{


}

impl<'input> DmlStatementNoWithContextAttrs<'input> for DmlStatementNoWithContext<'input>{}

pub type DeleteFromTableContext<'input> = BaseParserRuleContext<'input,DeleteFromTableContextExt<'input>>;

pub trait DeleteFromTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DELETE
	/// Returns `None` if there is no child corresponding to token DELETE
	fn DELETE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DELETE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DeleteFromTableContextAttrs<'input> for DeleteFromTableContext<'input>{}

pub struct DeleteFromTableContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeleteFromTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DeleteFromTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DeleteFromTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_deleteFromTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_deleteFromTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DeleteFromTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_deleteFromTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeleteFromTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for DeleteFromTableContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for DeleteFromTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for DeleteFromTableContext<'input> {}

impl<'input> DeleteFromTableContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::DeleteFromTableContext(
				BaseParserRuleContext::copy_from(ctx,DeleteFromTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SingleInsertQueryContext<'input> = BaseParserRuleContext<'input,SingleInsertQueryContextExt<'input>>;

pub trait SingleInsertQueryContextAttrs<'input>: DatabricksParserContext<'input>{
	fn insertInto(&self) -> Option<Rc<InsertIntoContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SingleInsertQueryContextAttrs<'input> for SingleInsertQueryContext<'input>{}

pub struct SingleInsertQueryContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleInsertQueryContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SingleInsertQueryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SingleInsertQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleInsertQuery(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_singleInsertQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SingleInsertQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_singleInsertQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleInsertQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for SingleInsertQueryContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for SingleInsertQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for SingleInsertQueryContext<'input> {}

impl<'input> SingleInsertQueryContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::SingleInsertQueryContext(
				BaseParserRuleContext::copy_from(ctx,SingleInsertQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MultiInsertQueryContext<'input> = BaseParserRuleContext<'input,MultiInsertQueryContextExt<'input>>;

pub trait MultiInsertQueryContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn relation(&self) -> Option<Rc<RelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn multiInsertQueryBody_all(&self) ->  Vec<Rc<MultiInsertQueryBodyContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn multiInsertQueryBody(&self, i: usize) -> Option<Rc<MultiInsertQueryBodyContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> MultiInsertQueryContextAttrs<'input> for MultiInsertQueryContext<'input>{}

pub struct MultiInsertQueryContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MultiInsertQueryContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for MultiInsertQueryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MultiInsertQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_multiInsertQuery(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_multiInsertQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MultiInsertQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_multiInsertQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiInsertQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for MultiInsertQueryContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for MultiInsertQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for MultiInsertQueryContext<'input> {}

impl<'input> MultiInsertQueryContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::MultiInsertQueryContext(
				BaseParserRuleContext::copy_from(ctx,MultiInsertQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UpdateTableContext<'input> = BaseParserRuleContext<'input,UpdateTableContextExt<'input>>;

pub trait UpdateTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UPDATE
	/// Returns `None` if there is no child corresponding to token UPDATE
	fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(UPDATE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn setClause(&self) -> Option<Rc<SetClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UpdateTableContextAttrs<'input> for UpdateTableContext<'input>{}

pub struct UpdateTableContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UpdateTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UpdateTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UpdateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_updateTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_updateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UpdateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_updateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for UpdateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for UpdateTableContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for UpdateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for UpdateTableContext<'input> {}

impl<'input> UpdateTableContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::UpdateTableContext(
				BaseParserRuleContext::copy_from(ctx,UpdateTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MergeIntoTableContext<'input> = BaseParserRuleContext<'input,MergeIntoTableContextExt<'input>>;

pub trait MergeIntoTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MERGE
	/// Returns `None` if there is no child corresponding to token MERGE
	fn MERGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MERGE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USING
	/// Returns `None` if there is no child corresponding to token USING
	fn USING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(USING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn identifierReference_all(&self) ->  Vec<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifierReference(&self, i: usize) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn tableAlias_all(&self) ->  Vec<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn tableAlias(&self, i: usize) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EVOLUTION
	/// Returns `None` if there is no child corresponding to token EVOLUTION
	fn EVOLUTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EVOLUTION, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn matchedClause_all(&self) ->  Vec<Rc<MatchedClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn matchedClause(&self, i: usize) -> Option<Rc<MatchedClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn notMatchedClause_all(&self) ->  Vec<Rc<NotMatchedClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn notMatchedClause(&self, i: usize) -> Option<Rc<NotMatchedClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn notMatchedBySourceClause_all(&self) ->  Vec<Rc<NotMatchedBySourceClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn notMatchedBySourceClause(&self, i: usize) -> Option<Rc<NotMatchedBySourceClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> MergeIntoTableContextAttrs<'input> for MergeIntoTableContext<'input>{}

pub struct MergeIntoTableContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	pub target: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub targetAlias: Option<Rc<TableAliasContextAll<'input>>>,
	pub source: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub sourceQuery: Option<Rc<QueryContextAll<'input>>>,
	pub sourceAlias: Option<Rc<TableAliasContextAll<'input>>>,
	pub mergeCondition: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MergeIntoTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for MergeIntoTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MergeIntoTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_mergeIntoTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_mergeIntoTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MergeIntoTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_mergeIntoTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeIntoTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for MergeIntoTableContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for MergeIntoTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for MergeIntoTableContext<'input> {}

impl<'input> MergeIntoTableContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::MergeIntoTableContext(
				BaseParserRuleContext::copy_from(ctx,MergeIntoTableContextExt{
        			target:None, targetAlias:None, source:None, sourceQuery:None, sourceAlias:None, mergeCondition:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dmlStatementNoWith(&mut self,)
	-> Result<Rc<DmlStatementNoWithContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DmlStatementNoWithContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 56, RULE_dmlStatementNoWith);
        let mut _localctx: Rc<DmlStatementNoWithContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1325);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INSERT 
				=> {
					let tmp = SingleInsertQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule insertInto*/
					recog.base.set_state(1263);
					recog.insertInto()?;

					/*InvokeRule query*/
					recog.base.set_state(1264);
					recog.query()?;

					}
				}

			 FROM 
				=> {
					let tmp = MultiInsertQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1266);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule relation*/
					recog.base.set_state(1267);
					recog.relation()?;

					recog.base.set_state(1269); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule multiInsertQueryBody*/
						recog.base.set_state(1268);
						recog.multiInsertQueryBody()?;

						}
						}
						recog.base.set_state(1271); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==INSERT) {break}
					}
					}
				}

			 DELETE 
				=> {
					let tmp = DeleteFromTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(1273);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					recog.base.set_state(1274);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1275);
					recog.identifierReference()?;

					/*InvokeRule tableAlias*/
					recog.base.set_state(1276);
					recog.tableAlias()?;

					recog.base.set_state(1278);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(1277);
						recog.whereClause()?;

						}
					}

					}
				}

			 UPDATE 
				=> {
					let tmp = UpdateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(1280);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1281);
					recog.identifierReference()?;

					/*InvokeRule tableAlias*/
					recog.base.set_state(1282);
					recog.tableAlias()?;

					/*InvokeRule setClause*/
					recog.base.set_state(1283);
					recog.setClause()?;

					recog.base.set_state(1285);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(1284);
						recog.whereClause()?;

						}
					}

					}
				}

			 MERGE 
				=> {
					let tmp = MergeIntoTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(1287);
					recog.base.match_token(MERGE,&mut recog.err_handler)?;

					recog.base.set_state(1291);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						recog.base.set_state(1288);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						recog.base.set_state(1289);
						recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

						recog.base.set_state(1290);
						recog.base.match_token(EVOLUTION,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1293);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1294);
					let tmp = recog.identifierReference()?;
					if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
					ctx.target = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					/*InvokeRule tableAlias*/
					recog.base.set_state(1295);
					let tmp = recog.tableAlias()?;
					if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
					ctx.targetAlias = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1296);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					recog.base.set_state(1302);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
					 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
					 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
					 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
					 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
					 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
					 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
					 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
					 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
					 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
					 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
					 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
					 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
					 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
					 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT |
					 EXTENDED | EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT |
					 FIRST | FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM |
					 FROM_JSON | FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT |
					 GROUP | GROUPING | HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY |
					 IF | IGNORE | IMMEDIATE | IMPORT | IN | INCLUDE | INDEX | INDEXES |
					 INNER | INPATH | INPUT | INPUTFORMAT | INSERT | INTERSECT | INTERVAL |
					 INT | INTEGER | INTO | INVOKER | IS | ITEMS | ILIKE | JOIN | KEY |
					 KEYS | LANGUAGE | LAST | LATERAL | LAZY | LEADING | LEFT | LIKE | LIMIT |
					 LINES | LIST | LISTAGG | LIVE | LOAD | LOCAL | LOCATION | LOCK | LOCKS |
					 LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES | MATCHED | MATERIALIZED |
					 MERGE | MICROSECOND | MICROSECONDS | MILLISECOND | MILLISECONDS | MINUS_KW |
					 MINUTE | MINUTES | MODE | MODIFIES | MONTH | MONTHS | MSCK | NAME |
					 NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND | NANOSECONDS |
					 NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF | OFFSET |
					 ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT | OUTER |
					 OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
					 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
					 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
					 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL |
					 RECORDREADER | RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP |
					 REFERENCE | REFERENCES | REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE |
					 RESET | RESPECT | RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE |
					 ROLE | ROLES | ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS |
					 SCHEMA | SCHEMAS | SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES |
					 SESSION_USER | SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT |
					 SOME | SORT | SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS |
					 STORED | STRATIFY | STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING |
					 SYNC | SYSTEM_TIME | SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE |
					 TARGET | TBLPROPERTIES | TEMP | TEMPORARY | TERMINATED | STRING_KW |
					 THEN | TIME | TIMEDIFF | TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF |
					 TIMESTAMP_LTZ | TIMESTAMP_NTZ | TINYINT | TO | TOUCH | TRAILING | TRANSACTION |
					 TRANSACTIONS | TRANSFORM | TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE |
					 UNARCHIVE | UNBOUNDED | UNCACHE | UNION | UNIQUE | UNKNOWN | UNLOCK |
					 UNPIVOT | UNSET | UPDATE | USE | USER | USING | VALUES | VAR | VARCHAR |
					 VARIANT | VERSION | VIEW | VIEWS | VOID | WEEK | WEEKS | WHEN | WHERE |
					 WHILE | WINDOW | WITH | WITHIN | YEAR | YEARS | ZONE | IDENTIFIER |
					 BACKQUOTED_IDENTIFIER 
						=> {
							{
							/*InvokeRule identifierReference*/
							recog.base.set_state(1297);
							let tmp = recog.identifierReference()?;
							if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
							ctx.source = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

					 LPAREN 
						=> {
							{
							recog.base.set_state(1298);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(1299);
							let tmp = recog.query()?;
							if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
							ctx.sourceQuery = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(1300);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					/*InvokeRule tableAlias*/
					recog.base.set_state(1304);
					let tmp = recog.tableAlias()?;
					if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
					ctx.sourceAlias = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1305);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(1306);
					let tmp = recog.booleanExpression_rec(0)?;
					if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
					ctx.mergeCondition = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1310);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(123,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule matchedClause*/
							recog.base.set_state(1307);
							recog.matchedClause()?;

							}
							} 
						}
						recog.base.set_state(1312);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(123,&mut recog.base)?;
					}
					recog.base.set_state(1316);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(124,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule notMatchedClause*/
							recog.base.set_state(1313);
							recog.notMatchedClause()?;

							}
							} 
						}
						recog.base.set_state(1318);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(124,&mut recog.base)?;
					}
					recog.base.set_state(1322);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==WHEN {
						{
						{
						/*InvokeRule notMatchedBySourceClause*/
						recog.base.set_state(1319);
						recog.notMatchedBySourceClause()?;

						}
						}
						recog.base.set_state(1324);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- ctes ----------------
pub type CtesContextAll<'input> = CtesContext<'input>;


pub type CtesContext<'input> = BaseParserRuleContext<'input,CtesContextExt<'input>>;

#[derive(Clone)]
pub struct CtesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for CtesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CtesContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_ctes(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_ctes(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CtesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_ctes(self);
	}
}

impl<'input> CustomRuleContext<'input> for CtesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_ctes }
	//fn type_rule_index() -> usize where Self: Sized { RULE_ctes }
}
antlr_rust::tid!{CtesContextExt<'a>}

impl<'input> CtesContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CtesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CtesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CtesContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<CtesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn namedQuery_all(&self) ->  Vec<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedQuery(&self, i: usize) -> Option<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> CtesContextAttrs<'input> for CtesContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn ctes(&mut self,)
	-> Result<Rc<CtesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CtesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 58, RULE_ctes);
        let mut _localctx: Rc<CtesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1327);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule namedQuery*/
			recog.base.set_state(1328);
			recog.namedQuery()?;

			recog.base.set_state(1333);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1329);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedQuery*/
				recog.base.set_state(1330);
				recog.namedQuery()?;

				}
				}
				recog.base.set_state(1335);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- insertInto ----------------
#[derive(Debug)]
pub enum InsertIntoContextAll<'input>{
	InsertIntoReplaceWhereContext(InsertIntoReplaceWhereContext<'input>),
	InsertOverwriteHiveDirContext(InsertOverwriteHiveDirContext<'input>),
	InsertOverwriteDirContext(InsertOverwriteDirContext<'input>),
	InsertOverwriteTableContext(InsertOverwriteTableContext<'input>),
	InsertIntoTableContext(InsertIntoTableContext<'input>),
Error(InsertIntoContext<'input>)
}
antlr_rust::tid!{InsertIntoContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for InsertIntoContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for InsertIntoContextAll<'input>{}

impl<'input> Deref for InsertIntoContextAll<'input>{
	type Target = dyn InsertIntoContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use InsertIntoContextAll::*;
		match self{
			InsertIntoReplaceWhereContext(inner) => inner,
			InsertOverwriteHiveDirContext(inner) => inner,
			InsertOverwriteDirContext(inner) => inner,
			InsertOverwriteTableContext(inner) => inner,
			InsertIntoTableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InsertIntoContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InsertIntoContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type InsertIntoContext<'input> = BaseParserRuleContext<'input,InsertIntoContextExt<'input>>;

#[derive(Clone)]
pub struct InsertIntoContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for InsertIntoContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InsertIntoContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InsertIntoContext<'input>{
}

impl<'input> CustomRuleContext<'input> for InsertIntoContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}
antlr_rust::tid!{InsertIntoContextExt<'a>}

impl<'input> InsertIntoContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InsertIntoContextAll<'input>> {
		Rc::new(
		InsertIntoContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InsertIntoContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait InsertIntoContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<InsertIntoContextExt<'input>>{


}

impl<'input> InsertIntoContextAttrs<'input> for InsertIntoContext<'input>{}

pub type InsertIntoReplaceWhereContext<'input> = BaseParserRuleContext<'input,InsertIntoReplaceWhereContextExt<'input>>;

pub trait InsertIntoReplaceWhereContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InsertIntoReplaceWhereContextAttrs<'input> for InsertIntoReplaceWhereContext<'input>{}

pub struct InsertIntoReplaceWhereContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertIntoReplaceWhereContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InsertIntoReplaceWhereContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InsertIntoReplaceWhereContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertIntoReplaceWhere(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_insertIntoReplaceWhere(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InsertIntoReplaceWhereContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_insertIntoReplaceWhere(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertIntoReplaceWhereContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertIntoReplaceWhereContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertIntoReplaceWhereContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertIntoReplaceWhereContext<'input> {}

impl<'input> InsertIntoReplaceWhereContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertIntoReplaceWhereContext(
				BaseParserRuleContext::copy_from(ctx,InsertIntoReplaceWhereContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertOverwriteHiveDirContext<'input> = BaseParserRuleContext<'input,InsertOverwriteHiveDirContextExt<'input>>;

pub trait InsertOverwriteHiveDirContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OVERWRITE
	/// Returns `None` if there is no child corresponding to token OVERWRITE
	fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OVERWRITE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DIRECTORY
	/// Returns `None` if there is no child corresponding to token DIRECTORY
	fn DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DIRECTORY, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LOCAL
	/// Returns `None` if there is no child corresponding to token LOCAL
	fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LOCAL, 0)
	}
	fn rowFormat(&self) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn createFileFormat(&self) -> Option<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InsertOverwriteHiveDirContextAttrs<'input> for InsertOverwriteHiveDirContext<'input>{}

pub struct InsertOverwriteHiveDirContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	pub path: Option<Rc<StringContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertOverwriteHiveDirContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InsertOverwriteHiveDirContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InsertOverwriteHiveDirContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertOverwriteHiveDir(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_insertOverwriteHiveDir(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InsertOverwriteHiveDirContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_insertOverwriteHiveDir(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertOverwriteHiveDirContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertOverwriteHiveDirContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertOverwriteHiveDirContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertOverwriteHiveDirContext<'input> {}

impl<'input> InsertOverwriteHiveDirContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertOverwriteHiveDirContext(
				BaseParserRuleContext::copy_from(ctx,InsertOverwriteHiveDirContextExt{
        			path:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertOverwriteDirContext<'input> = BaseParserRuleContext<'input,InsertOverwriteDirContextExt<'input>>;

pub trait InsertOverwriteDirContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OVERWRITE
	/// Returns `None` if there is no child corresponding to token OVERWRITE
	fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OVERWRITE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DIRECTORY
	/// Returns `None` if there is no child corresponding to token DIRECTORY
	fn DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DIRECTORY, 0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LOCAL
	/// Returns `None` if there is no child corresponding to token LOCAL
	fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LOCAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InsertOverwriteDirContextAttrs<'input> for InsertOverwriteDirContext<'input>{}

pub struct InsertOverwriteDirContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	pub path: Option<Rc<StringContextAll<'input>>>,
	pub options: Option<Rc<PropertiesContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertOverwriteDirContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InsertOverwriteDirContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InsertOverwriteDirContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertOverwriteDir(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_insertOverwriteDir(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InsertOverwriteDirContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_insertOverwriteDir(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertOverwriteDirContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertOverwriteDirContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertOverwriteDirContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertOverwriteDirContext<'input> {}

impl<'input> InsertOverwriteDirContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertOverwriteDirContext(
				BaseParserRuleContext::copy_from(ctx,InsertOverwriteDirContextExt{
        			path:None, options:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertOverwriteTableContext<'input> = BaseParserRuleContext<'input,InsertOverwriteTableContextExt<'input>>;

pub trait InsertOverwriteTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OVERWRITE
	/// Returns `None` if there is no child corresponding to token OVERWRITE
	fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OVERWRITE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NAME
	/// Returns `None` if there is no child corresponding to token NAME
	fn NAME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> InsertOverwriteTableContextAttrs<'input> for InsertOverwriteTableContext<'input>{}

pub struct InsertOverwriteTableContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertOverwriteTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InsertOverwriteTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InsertOverwriteTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertOverwriteTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_insertOverwriteTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InsertOverwriteTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_insertOverwriteTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertOverwriteTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertOverwriteTableContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertOverwriteTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertOverwriteTableContext<'input> {}

impl<'input> InsertOverwriteTableContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertOverwriteTableContext(
				BaseParserRuleContext::copy_from(ctx,InsertOverwriteTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertIntoTableContext<'input> = BaseParserRuleContext<'input,InsertIntoTableContextExt<'input>>;

pub trait InsertIntoTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NAME
	/// Returns `None` if there is no child corresponding to token NAME
	fn NAME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NAME, 0)
	}
}

impl<'input> InsertIntoTableContextAttrs<'input> for InsertIntoTableContext<'input>{}

pub struct InsertIntoTableContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertIntoTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InsertIntoTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InsertIntoTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertIntoTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_insertIntoTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InsertIntoTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_insertIntoTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertIntoTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertIntoTableContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertIntoTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertIntoTableContext<'input> {}

impl<'input> InsertIntoTableContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertIntoTableContext(
				BaseParserRuleContext::copy_from(ctx,InsertIntoTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn insertInto(&mut self,)
	-> Result<Rc<InsertIntoContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InsertIntoContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 60, RULE_insertInto);
        let mut _localctx: Rc<InsertIntoContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1419);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(146,&mut recog.base)? {
				1 =>{
					let tmp = InsertOverwriteTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1336);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(1337);
					recog.base.match_token(OVERWRITE,&mut recog.err_handler)?;

					recog.base.set_state(1339);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(128,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1338);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1341);
					recog.identifierReference()?;

					recog.base.set_state(1343);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(129,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule optionsClause*/
							recog.base.set_state(1342);
							recog.optionsClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1351);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1345);
						recog.partitionSpec()?;

						recog.base.set_state(1349);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==IF {
							{
							recog.base.set_state(1346);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1347);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(1348);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						}
					}

					recog.base.set_state(1356);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(132,&mut recog.base)? {
						x if x == 1=>{
							{
							{
							recog.base.set_state(1353);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							recog.base.set_state(1354);
							recog.base.match_token(NAME,&mut recog.err_handler)?;

							}
							}
						}

						x if x == 2=>{
							{
							/*InvokeRule identifierList*/
							recog.base.set_state(1355);
							recog.identifierList()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = InsertIntoTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1358);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(1359);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					recog.base.set_state(1361);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(133,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1360);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1363);
					recog.identifierReference()?;

					recog.base.set_state(1365);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(134,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule optionsClause*/
							recog.base.set_state(1364);
							recog.optionsClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1368);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1367);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(1373);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1370);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1371);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						recog.base.set_state(1372);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1378);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(137,&mut recog.base)? {
						x if x == 1=>{
							{
							{
							recog.base.set_state(1375);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							recog.base.set_state(1376);
							recog.base.match_token(NAME,&mut recog.err_handler)?;

							}
							}
						}

						x if x == 2=>{
							{
							/*InvokeRule identifierList*/
							recog.base.set_state(1377);
							recog.identifierList()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				3 =>{
					let tmp = InsertIntoReplaceWhereContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(1380);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(1381);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					recog.base.set_state(1383);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(138,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1382);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1385);
					recog.identifierReference()?;

					recog.base.set_state(1387);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						/*InvokeRule optionsClause*/
						recog.base.set_state(1386);
						recog.optionsClause()?;

						}
					}

					recog.base.set_state(1389);
					recog.base.match_token(REPLACE,&mut recog.err_handler)?;

					/*InvokeRule whereClause*/
					recog.base.set_state(1390);
					recog.whereClause()?;

					}
				}
			,
				4 =>{
					let tmp = InsertOverwriteHiveDirContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(1392);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(1393);
					recog.base.match_token(OVERWRITE,&mut recog.err_handler)?;

					recog.base.set_state(1395);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LOCAL {
						{
						recog.base.set_state(1394);
						recog.base.match_token(LOCAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1397);
					recog.base.match_token(DIRECTORY,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(1398);
					let tmp = recog.string()?;
					if let InsertIntoContextAll::InsertOverwriteHiveDirContext(ctx) = cast_mut::<_,InsertIntoContextAll >(&mut _localctx){
					ctx.path = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1400);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ROW {
						{
						/*InvokeRule rowFormat*/
						recog.base.set_state(1399);
						recog.rowFormat()?;

						}
					}

					recog.base.set_state(1403);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==STORED {
						{
						/*InvokeRule createFileFormat*/
						recog.base.set_state(1402);
						recog.createFileFormat()?;

						}
					}

					}
				}
			,
				5 =>{
					let tmp = InsertOverwriteDirContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(1405);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(1406);
					recog.base.match_token(OVERWRITE,&mut recog.err_handler)?;

					recog.base.set_state(1408);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LOCAL {
						{
						recog.base.set_state(1407);
						recog.base.match_token(LOCAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1410);
					recog.base.match_token(DIRECTORY,&mut recog.err_handler)?;

					recog.base.set_state(1412);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==STRING || _la==DOUBLEQUOTED_STRING {
						{
						/*InvokeRule string*/
						recog.base.set_state(1411);
						let tmp = recog.string()?;
						if let InsertIntoContextAll::InsertOverwriteDirContext(ctx) = cast_mut::<_,InsertIntoContextAll >(&mut _localctx){
						ctx.path = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					/*InvokeRule tableProvider*/
					recog.base.set_state(1414);
					recog.tableProvider()?;

					recog.base.set_state(1417);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(1415);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule properties*/
						recog.base.set_state(1416);
						let tmp = recog.properties()?;
						if let InsertIntoContextAll::InsertOverwriteDirContext(ctx) = cast_mut::<_,InsertIntoContextAll >(&mut _localctx){
						ctx.options = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiInsertQueryBody ----------------
pub type MultiInsertQueryBodyContextAll<'input> = MultiInsertQueryBodyContext<'input>;


pub type MultiInsertQueryBodyContext<'input> = BaseParserRuleContext<'input,MultiInsertQueryBodyContextExt<'input>>;

#[derive(Clone)]
pub struct MultiInsertQueryBodyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for MultiInsertQueryBodyContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MultiInsertQueryBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiInsertQueryBody(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_multiInsertQueryBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MultiInsertQueryBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_multiInsertQueryBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiInsertQueryBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiInsertQueryBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiInsertQueryBody }
}
antlr_rust::tid!{MultiInsertQueryBodyContextExt<'a>}

impl<'input> MultiInsertQueryBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiInsertQueryBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiInsertQueryBodyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiInsertQueryBodyContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<MultiInsertQueryBodyContextExt<'input>>{

fn insertInto(&self) -> Option<Rc<InsertIntoContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn fromStatementBody(&self) -> Option<Rc<FromStatementBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MultiInsertQueryBodyContextAttrs<'input> for MultiInsertQueryBodyContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiInsertQueryBody(&mut self,)
	-> Result<Rc<MultiInsertQueryBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiInsertQueryBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 62, RULE_multiInsertQueryBody);
        let mut _localctx: Rc<MultiInsertQueryBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule insertInto*/
			recog.base.set_state(1421);
			recog.insertInto()?;

			/*InvokeRule fromStatementBody*/
			recog.base.set_state(1422);
			recog.fromStatementBody()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableAlias ----------------
pub type TableAliasContextAll<'input> = TableAliasContext<'input>;


pub type TableAliasContext<'input> = BaseParserRuleContext<'input,TableAliasContextExt<'input>>;

#[derive(Clone)]
pub struct TableAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableAliasContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableAlias(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_tableAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableAlias }
}
antlr_rust::tid!{TableAliasContextExt<'a>}

impl<'input> TableAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableAliasContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableAliasContextExt<'input>>{

fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableAliasContextAttrs<'input> for TableAliasContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableAlias(&mut self,)
	-> Result<Rc<TableAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 64, RULE_tableAlias);
        let mut _localctx: Rc<TableAliasContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1431);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(149,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1425);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(147,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1424);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule strictIdentifier*/
					recog.base.set_state(1427);
					recog.strictIdentifier()?;

					recog.base.set_state(1429);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						/*InvokeRule identifierList*/
						recog.base.set_state(1428);
						recog.identifierList()?;

						}
					}

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whereClause ----------------
pub type WhereClauseContextAll<'input> = WhereClauseContext<'input>;


pub type WhereClauseContext<'input> = BaseParserRuleContext<'input,WhereClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhereClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for WhereClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for WhereClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whereClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_whereClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for WhereClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_whereClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhereClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whereClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whereClause }
}
antlr_rust::tid!{WhereClauseContextExt<'a>}

impl<'input> WhereClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhereClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhereClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WhereClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<WhereClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WhereClauseContextAttrs<'input> for WhereClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whereClause(&mut self,)
	-> Result<Rc<WhereClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhereClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 66, RULE_whereClause);
        let mut _localctx: Rc<WhereClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1433);
			recog.base.match_token(WHERE,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(1434);
			recog.booleanExpression_rec(0)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setClause ----------------
pub type SetClauseContextAll<'input> = SetClauseContext<'input>;


pub type SetClauseContext<'input> = BaseParserRuleContext<'input,SetClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SetClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SetClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_setClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setClause }
}
antlr_rust::tid!{SetClauseContextExt<'a>}

impl<'input> SetClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SetClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
fn assignmentList(&self) -> Option<Rc<AssignmentListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetClauseContextAttrs<'input> for SetClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setClause(&mut self,)
	-> Result<Rc<SetClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 68, RULE_setClause);
        let mut _localctx: Rc<SetClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1436);
			recog.base.match_token(SET,&mut recog.err_handler)?;

			/*InvokeRule assignmentList*/
			recog.base.set_state(1437);
			recog.assignmentList()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- matchedClause ----------------
pub type MatchedClauseContextAll<'input> = MatchedClauseContext<'input>;


pub type MatchedClauseContext<'input> = BaseParserRuleContext<'input,MatchedClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MatchedClauseContextExt<'input>{
	pub matchedCond: Option<Rc<BooleanExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for MatchedClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MatchedClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_matchedClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_matchedClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MatchedClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_matchedClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MatchedClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_matchedClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_matchedClause }
}
antlr_rust::tid!{MatchedClauseContextExt<'a>}

impl<'input> MatchedClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MatchedClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MatchedClauseContextExt{
				matchedCond: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MatchedClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<MatchedClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn matchedAction(&self) -> Option<Rc<MatchedActionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MatchedClauseContextAttrs<'input> for MatchedClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn matchedClause(&mut self,)
	-> Result<Rc<MatchedClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MatchedClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 70, RULE_matchedClause);
        let mut _localctx: Rc<MatchedClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1439);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			recog.base.set_state(1440);
			recog.base.match_token(MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(1443);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AND {
				{
				recog.base.set_state(1441);
				recog.base.match_token(AND,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1442);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,MatchedClauseContext >(&mut _localctx).matchedCond = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1445);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule matchedAction*/
			recog.base.set_state(1446);
			recog.matchedAction()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- notMatchedClause ----------------
pub type NotMatchedClauseContextAll<'input> = NotMatchedClauseContext<'input>;


pub type NotMatchedClauseContext<'input> = BaseParserRuleContext<'input,NotMatchedClauseContextExt<'input>>;

#[derive(Clone)]
pub struct NotMatchedClauseContextExt<'input>{
	pub notMatchedCond: Option<Rc<BooleanExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NotMatchedClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NotMatchedClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_notMatchedClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_notMatchedClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NotMatchedClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_notMatchedClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for NotMatchedClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_notMatchedClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_notMatchedClause }
}
antlr_rust::tid!{NotMatchedClauseContextExt<'a>}

impl<'input> NotMatchedClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NotMatchedClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NotMatchedClauseContextExt{
				notMatchedCond: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NotMatchedClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NotMatchedClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn notMatchedAction(&self) -> Option<Rc<NotMatchedActionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token TARGET
/// Returns `None` if there is no child corresponding to token TARGET
fn TARGET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TARGET, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NotMatchedClauseContextAttrs<'input> for NotMatchedClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn notMatchedClause(&mut self,)
	-> Result<Rc<NotMatchedClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NotMatchedClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 72, RULE_notMatchedClause);
        let mut _localctx: Rc<NotMatchedClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1448);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			recog.base.set_state(1449);
			recog.base.match_token(NOT,&mut recog.err_handler)?;

			recog.base.set_state(1450);
			recog.base.match_token(MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(1453);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==BY {
				{
				recog.base.set_state(1451);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(1452);
				recog.base.match_token(TARGET,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1457);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AND {
				{
				recog.base.set_state(1455);
				recog.base.match_token(AND,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1456);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,NotMatchedClauseContext >(&mut _localctx).notMatchedCond = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1459);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule notMatchedAction*/
			recog.base.set_state(1460);
			recog.notMatchedAction()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- notMatchedBySourceClause ----------------
pub type NotMatchedBySourceClauseContextAll<'input> = NotMatchedBySourceClauseContext<'input>;


pub type NotMatchedBySourceClauseContext<'input> = BaseParserRuleContext<'input,NotMatchedBySourceClauseContextExt<'input>>;

#[derive(Clone)]
pub struct NotMatchedBySourceClauseContextExt<'input>{
	pub notMatchedBySourceCond: Option<Rc<BooleanExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NotMatchedBySourceClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NotMatchedBySourceClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_notMatchedBySourceClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_notMatchedBySourceClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NotMatchedBySourceClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_notMatchedBySourceClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for NotMatchedBySourceClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_notMatchedBySourceClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_notMatchedBySourceClause }
}
antlr_rust::tid!{NotMatchedBySourceClauseContextExt<'a>}

impl<'input> NotMatchedBySourceClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NotMatchedBySourceClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NotMatchedBySourceClauseContextExt{
				notMatchedBySourceCond: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NotMatchedBySourceClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NotMatchedBySourceClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token SOURCE
/// Returns `None` if there is no child corresponding to token SOURCE
fn SOURCE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn notMatchedBySourceAction(&self) -> Option<Rc<NotMatchedBySourceActionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NotMatchedBySourceClauseContextAttrs<'input> for NotMatchedBySourceClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn notMatchedBySourceClause(&mut self,)
	-> Result<Rc<NotMatchedBySourceClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NotMatchedBySourceClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 74, RULE_notMatchedBySourceClause);
        let mut _localctx: Rc<NotMatchedBySourceClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1462);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			recog.base.set_state(1463);
			recog.base.match_token(NOT,&mut recog.err_handler)?;

			recog.base.set_state(1464);
			recog.base.match_token(MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(1465);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			recog.base.set_state(1466);
			recog.base.match_token(SOURCE,&mut recog.err_handler)?;

			recog.base.set_state(1469);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AND {
				{
				recog.base.set_state(1467);
				recog.base.match_token(AND,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(1468);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,NotMatchedBySourceClauseContext >(&mut _localctx).notMatchedBySourceCond = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1471);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule notMatchedBySourceAction*/
			recog.base.set_state(1472);
			recog.notMatchedBySourceAction()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- optionsClause ----------------
pub type OptionsClauseContextAll<'input> = OptionsClauseContext<'input>;


pub type OptionsClauseContext<'input> = BaseParserRuleContext<'input,OptionsClauseContextExt<'input>>;

#[derive(Clone)]
pub struct OptionsClauseContextExt<'input>{
	pub options: Option<Rc<PropertiesContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for OptionsClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for OptionsClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_optionsClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_optionsClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for OptionsClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_optionsClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for OptionsClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_optionsClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_optionsClause }
}
antlr_rust::tid!{OptionsClauseContextExt<'a>}

impl<'input> OptionsClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OptionsClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OptionsClauseContextExt{
				options: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait OptionsClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<OptionsClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn properties(&self) -> Option<Rc<PropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> OptionsClauseContextAttrs<'input> for OptionsClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn optionsClause(&mut self,)
	-> Result<Rc<OptionsClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OptionsClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 76, RULE_optionsClause);
        let mut _localctx: Rc<OptionsClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1474);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule properties*/
			recog.base.set_state(1475);
			let tmp = recog.properties()?;
			 cast_mut::<_,OptionsClauseContext >(&mut _localctx).options = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionSpec ----------------
pub type PartitionSpecContextAll<'input> = PartitionSpecContext<'input>;


pub type PartitionSpecContext<'input> = BaseParserRuleContext<'input,PartitionSpecContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PartitionSpecContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PartitionSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionSpec(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_partitionSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PartitionSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_partitionSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionSpec }
}
antlr_rust::tid!{PartitionSpecContextExt<'a>}

impl<'input> PartitionSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionSpecContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PartitionSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn partitionVal_all(&self) ->  Vec<Rc<PartitionValContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionVal(&self, i: usize) -> Option<Rc<PartitionValContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionSpecContextAttrs<'input> for PartitionSpecContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionSpec(&mut self,)
	-> Result<Rc<PartitionSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 78, RULE_partitionSpec);
        let mut _localctx: Rc<PartitionSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1477);
			recog.base.match_token(PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(1478);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule partitionVal*/
			recog.base.set_state(1479);
			recog.partitionVal()?;

			recog.base.set_state(1484);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1480);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule partitionVal*/
				recog.base.set_state(1481);
				recog.partitionVal()?;

				}
				}
				recog.base.set_state(1486);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1487);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lateralView ----------------
pub type LateralViewContextAll<'input> = LateralViewContext<'input>;


pub type LateralViewContext<'input> = BaseParserRuleContext<'input,LateralViewContextExt<'input>>;

#[derive(Clone)]
pub struct LateralViewContextExt<'input>{
	pub tblName: Option<Rc<IdentifierContextAll<'input>>>,
	pub colNames: Option<Rc<IdentifierSeqContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for LateralViewContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LateralViewContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_lateralView(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_lateralView(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LateralViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_lateralView(self);
	}
}

impl<'input> CustomRuleContext<'input> for LateralViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lateralView }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lateralView }
}
antlr_rust::tid!{LateralViewContextExt<'a>}

impl<'input> LateralViewContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LateralViewContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LateralViewContextExt{
				tblName: None, colNames: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LateralViewContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<LateralViewContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LATERAL
/// Returns `None` if there is no child corresponding to token LATERAL
fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LATERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
fn tableFunctionCall(&self) -> Option<Rc<TableFunctionCallContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LateralViewContextAttrs<'input> for LateralViewContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn lateralView(&mut self,)
	-> Result<Rc<LateralViewContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LateralViewContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 80, RULE_lateralView);
        let mut _localctx: Rc<LateralViewContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1489);
			recog.base.match_token(LATERAL,&mut recog.err_handler)?;

			recog.base.set_state(1490);
			recog.base.match_token(VIEW,&mut recog.err_handler)?;

			recog.base.set_state(1492);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(155,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1491);
					recog.base.match_token(OUTER,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule tableFunctionCall*/
			recog.base.set_state(1494);
			recog.tableFunctionCall()?;

			recog.base.set_state(1496);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(156,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1495);
					let tmp = recog.identifier()?;
					 cast_mut::<_,LateralViewContext >(&mut _localctx).tblName = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(1500);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(157,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1498);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule identifierSeq*/
					recog.base.set_state(1499);
					let tmp = recog.identifierSeq()?;
					 cast_mut::<_,LateralViewContext >(&mut _localctx).colNames = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fromStatementBody ----------------
pub type FromStatementBodyContextAll<'input> = FromStatementBodyContext<'input>;


pub type FromStatementBodyContext<'input> = BaseParserRuleContext<'input,FromStatementBodyContextExt<'input>>;

#[derive(Clone)]
pub struct FromStatementBodyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FromStatementBodyContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FromStatementBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fromStatementBody(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_fromStatementBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FromStatementBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_fromStatementBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for FromStatementBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fromStatementBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fromStatementBody }
}
antlr_rust::tid!{FromStatementBodyContextExt<'a>}

impl<'input> FromStatementBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FromStatementBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FromStatementBodyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FromStatementBodyContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FromStatementBodyContextExt<'input>>{

fn transformClause(&self) -> Option<Rc<TransformClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn queryOrganization(&self) -> Option<Rc<QueryOrganizationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn selectClause(&self) -> Option<Rc<SelectClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lateralView_all(&self) ->  Vec<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn lateralView(&self, i: usize) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn aggregationClause(&self) -> Option<Rc<AggregationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn havingClause(&self) -> Option<Rc<HavingClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn windowClause(&self) -> Option<Rc<WindowClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FromStatementBodyContextAttrs<'input> for FromStatementBodyContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fromStatementBody(&mut self,)
	-> Result<Rc<FromStatementBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FromStatementBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 82, RULE_fromStatementBody);
        let mut _localctx: Rc<FromStatementBodyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1529);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(164,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule transformClause*/
					recog.base.set_state(1502);
					recog.transformClause()?;

					recog.base.set_state(1504);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(1503);
						recog.whereClause()?;

						}
					}

					/*InvokeRule queryOrganization*/
					recog.base.set_state(1506);
					recog.queryOrganization()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule selectClause*/
					recog.base.set_state(1508);
					recog.selectClause()?;

					recog.base.set_state(1512);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==LATERAL {
						{
						{
						/*InvokeRule lateralView*/
						recog.base.set_state(1509);
						recog.lateralView()?;

						}
						}
						recog.base.set_state(1514);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1516);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(1515);
						recog.whereClause()?;

						}
					}

					recog.base.set_state(1519);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==GROUP {
						{
						/*InvokeRule aggregationClause*/
						recog.base.set_state(1518);
						recog.aggregationClause()?;

						}
					}

					recog.base.set_state(1522);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==HAVING {
						{
						/*InvokeRule havingClause*/
						recog.base.set_state(1521);
						recog.havingClause()?;

						}
					}

					recog.base.set_state(1525);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(163,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule windowClause*/
							recog.base.set_state(1524);
							recog.windowClause()?;

							}
						}

						_ => {}
					}
					/*InvokeRule queryOrganization*/
					recog.base.set_state(1527);
					recog.queryOrganization()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryOrganization ----------------
pub type QueryOrganizationContextAll<'input> = QueryOrganizationContext<'input>;


pub type QueryOrganizationContext<'input> = BaseParserRuleContext<'input,QueryOrganizationContextExt<'input>>;

#[derive(Clone)]
pub struct QueryOrganizationContextExt<'input>{
	pub sortItem: Option<Rc<SortItemContextAll<'input>>>,
	pub order:Vec<Rc<SortItemContextAll<'input>>>,
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub clusterBy:Vec<Rc<ExpressionContextAll<'input>>>,
	pub distributeBy:Vec<Rc<ExpressionContextAll<'input>>>,
	pub sort:Vec<Rc<SortItemContextAll<'input>>>,
	pub limit: Option<Rc<ExpressionContextAll<'input>>>,
	pub offset: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QueryOrganizationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryOrganizationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryOrganization(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_queryOrganization(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryOrganizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_queryOrganization(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryOrganizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryOrganization }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryOrganization }
}
antlr_rust::tid!{QueryOrganizationContextExt<'a>}

impl<'input> QueryOrganizationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryOrganizationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryOrganizationContextExt{
				sortItem: None, expression: None, limit: None, offset: None, 
				order: Vec::new(), clusterBy: Vec::new(), distributeBy: Vec::new(), sort: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryOrganizationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QueryOrganizationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTRIBUTE
/// Returns `None` if there is no child corresponding to token DISTRIBUTE
fn DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DISTRIBUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token SORT
/// Returns `None` if there is no child corresponding to token SORT
fn SORT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SORT, 0)
}
fn windowClause(&self) -> Option<Rc<WindowClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QueryOrganizationContextAttrs<'input> for QueryOrganizationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryOrganization(&mut self,)
	-> Result<Rc<QueryOrganizationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryOrganizationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 84, RULE_queryOrganization);
        let mut _localctx: Rc<QueryOrganizationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1541);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				recog.base.set_state(1531);
				recog.base.match_token(ORDER,&mut recog.err_handler)?;

				recog.base.set_state(1532);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule sortItem*/
				recog.base.set_state(1533);
				let tmp = recog.sortItem()?;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem.clone().unwrap()
				 ;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).order.push(temp);
				  
				recog.base.set_state(1538);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1534);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(1535);
					let tmp = recog.sortItem()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem.clone().unwrap()
					 ;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).order.push(temp);
					  
					}
					}
					recog.base.set_state(1540);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(1553);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==CLUSTER {
				{
				recog.base.set_state(1543);
				recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

				recog.base.set_state(1544);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(1545);
				let tmp = recog.expression()?;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression.clone().unwrap()
				 ;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).clusterBy.push(temp);
				  
				recog.base.set_state(1550);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1546);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1547);
					let tmp = recog.expression()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).clusterBy.push(temp);
					  
					}
					}
					recog.base.set_state(1552);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(1565);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DISTRIBUTE {
				{
				recog.base.set_state(1555);
				recog.base.match_token(DISTRIBUTE,&mut recog.err_handler)?;

				recog.base.set_state(1556);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(1557);
				let tmp = recog.expression()?;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression.clone().unwrap()
				 ;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).distributeBy.push(temp);
				  
				recog.base.set_state(1562);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1558);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1559);
					let tmp = recog.expression()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).distributeBy.push(temp);
					  
					}
					}
					recog.base.set_state(1564);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(1577);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SORT {
				{
				recog.base.set_state(1567);
				recog.base.match_token(SORT,&mut recog.err_handler)?;

				recog.base.set_state(1568);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule sortItem*/
				recog.base.set_state(1569);
				let tmp = recog.sortItem()?;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem.clone().unwrap()
				 ;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sort.push(temp);
				  
				recog.base.set_state(1574);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1570);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(1571);
					let tmp = recog.sortItem()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem.clone().unwrap()
					 ;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sort.push(temp);
					  
					}
					}
					recog.base.set_state(1576);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(1580);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WINDOW {
				{
				/*InvokeRule windowClause*/
				recog.base.set_state(1579);
				recog.windowClause()?;

				}
			}

			recog.base.set_state(1587);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LIMIT {
				{
				recog.base.set_state(1582);
				recog.base.match_token(LIMIT,&mut recog.err_handler)?;

				recog.base.set_state(1585);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(174,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(1583);
						recog.base.match_token(ALL,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule expression*/
						recog.base.set_state(1584);
						let tmp = recog.expression()?;
						 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).limit = Some(tmp.clone());
						  

						}
					}

					_ => {}
				}
				}
			}

			recog.base.set_state(1591);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==OFFSET {
				{
				recog.base.set_state(1589);
				recog.base.match_token(OFFSET,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(1590);
				let tmp = recog.expression()?;
				 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).offset = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- assignmentList ----------------
pub type AssignmentListContextAll<'input> = AssignmentListContext<'input>;


pub type AssignmentListContext<'input> = BaseParserRuleContext<'input,AssignmentListContextExt<'input>>;

#[derive(Clone)]
pub struct AssignmentListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for AssignmentListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AssignmentListContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_assignmentList(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_assignmentList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AssignmentListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_assignmentList(self);
	}
}

impl<'input> CustomRuleContext<'input> for AssignmentListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_assignmentList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_assignmentList }
}
antlr_rust::tid!{AssignmentListContextExt<'a>}

impl<'input> AssignmentListContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AssignmentListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AssignmentListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AssignmentListContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<AssignmentListContextExt<'input>>{

fn assignment_all(&self) ->  Vec<Rc<AssignmentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn assignment(&self, i: usize) -> Option<Rc<AssignmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> AssignmentListContextAttrs<'input> for AssignmentListContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn assignmentList(&mut self,)
	-> Result<Rc<AssignmentListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AssignmentListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 86, RULE_assignmentList);
        let mut _localctx: Rc<AssignmentListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule assignment*/
			recog.base.set_state(1593);
			recog.assignment()?;

			recog.base.set_state(1598);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1594);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule assignment*/
				recog.base.set_state(1595);
				recog.assignment()?;

				}
				}
				recog.base.set_state(1600);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- assignment ----------------
pub type AssignmentContextAll<'input> = AssignmentContext<'input>;


pub type AssignmentContext<'input> = BaseParserRuleContext<'input,AssignmentContextExt<'input>>;

#[derive(Clone)]
pub struct AssignmentContextExt<'input>{
	pub key: Option<Rc<QualifiedNameContextAll<'input>>>,
	pub value: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for AssignmentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AssignmentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_assignment(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_assignment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AssignmentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_assignment(self);
	}
}

impl<'input> CustomRuleContext<'input> for AssignmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_assignment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_assignment }
}
antlr_rust::tid!{AssignmentContextExt<'a>}

impl<'input> AssignmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AssignmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AssignmentContextExt{
				key: None, value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AssignmentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<AssignmentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AssignmentContextAttrs<'input> for AssignmentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn assignment(&mut self,)
	-> Result<Rc<AssignmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AssignmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 88, RULE_assignment);
        let mut _localctx: Rc<AssignmentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(1601);
			let tmp = recog.qualifiedName()?;
			 cast_mut::<_,AssignmentContext >(&mut _localctx).key = Some(tmp.clone());
			  

			recog.base.set_state(1602);
			recog.base.match_token(EQ,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1603);
			let tmp = recog.expression()?;
			 cast_mut::<_,AssignmentContext >(&mut _localctx).value = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- matchedAction ----------------
pub type MatchedActionContextAll<'input> = MatchedActionContext<'input>;


pub type MatchedActionContext<'input> = BaseParserRuleContext<'input,MatchedActionContextExt<'input>>;

#[derive(Clone)]
pub struct MatchedActionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for MatchedActionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MatchedActionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_matchedAction(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_matchedAction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MatchedActionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_matchedAction(self);
	}
}

impl<'input> CustomRuleContext<'input> for MatchedActionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_matchedAction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_matchedAction }
}
antlr_rust::tid!{MatchedActionContextExt<'a>}

impl<'input> MatchedActionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MatchedActionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MatchedActionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MatchedActionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<MatchedActionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
fn assignmentList(&self) -> Option<Rc<AssignmentListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MatchedActionContextAttrs<'input> for MatchedActionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn matchedAction(&mut self,)
	-> Result<Rc<MatchedActionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MatchedActionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 90, RULE_matchedAction);
        let mut _localctx: Rc<MatchedActionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1612);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(178,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1605);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1606);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(1607);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1608);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1609);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(1610);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule assignmentList*/
					recog.base.set_state(1611);
					recog.assignmentList()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- notMatchedAction ----------------
pub type NotMatchedActionContextAll<'input> = NotMatchedActionContext<'input>;


pub type NotMatchedActionContext<'input> = BaseParserRuleContext<'input,NotMatchedActionContextExt<'input>>;

#[derive(Clone)]
pub struct NotMatchedActionContextExt<'input>{
	pub columns: Option<Rc<MultipartIdentifierListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NotMatchedActionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NotMatchedActionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_notMatchedAction(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_notMatchedAction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NotMatchedActionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_notMatchedAction(self);
	}
}

impl<'input> CustomRuleContext<'input> for NotMatchedActionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_notMatchedAction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_notMatchedAction }
}
antlr_rust::tid!{NotMatchedActionContextExt<'a>}

impl<'input> NotMatchedActionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NotMatchedActionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NotMatchedActionContextExt{
				columns: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NotMatchedActionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NotMatchedActionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NotMatchedActionContextAttrs<'input> for NotMatchedActionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn notMatchedAction(&mut self,)
	-> Result<Rc<NotMatchedActionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NotMatchedActionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 92, RULE_notMatchedAction);
        let mut _localctx: Rc<NotMatchedActionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1632);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(180,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1614);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(1615);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1616);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(1617);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifierList*/
					recog.base.set_state(1618);
					let tmp = recog.multipartIdentifierList()?;
					 cast_mut::<_,NotMatchedActionContext >(&mut _localctx).columns = Some(tmp.clone());
					  

					recog.base.set_state(1619);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1620);
					recog.base.match_token(VALUES,&mut recog.err_handler)?;

					recog.base.set_state(1621);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1622);
					recog.expression()?;

					recog.base.set_state(1627);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(1623);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(1624);
						recog.expression()?;

						}
						}
						recog.base.set_state(1629);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1630);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- notMatchedBySourceAction ----------------
pub type NotMatchedBySourceActionContextAll<'input> = NotMatchedBySourceActionContext<'input>;


pub type NotMatchedBySourceActionContext<'input> = BaseParserRuleContext<'input,NotMatchedBySourceActionContextExt<'input>>;

#[derive(Clone)]
pub struct NotMatchedBySourceActionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NotMatchedBySourceActionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NotMatchedBySourceActionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_notMatchedBySourceAction(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_notMatchedBySourceAction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NotMatchedBySourceActionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_notMatchedBySourceAction(self);
	}
}

impl<'input> CustomRuleContext<'input> for NotMatchedBySourceActionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_notMatchedBySourceAction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_notMatchedBySourceAction }
}
antlr_rust::tid!{NotMatchedBySourceActionContextExt<'a>}

impl<'input> NotMatchedBySourceActionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NotMatchedBySourceActionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NotMatchedBySourceActionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NotMatchedBySourceActionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NotMatchedBySourceActionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
fn assignmentList(&self) -> Option<Rc<AssignmentListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NotMatchedBySourceActionContextAttrs<'input> for NotMatchedBySourceActionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn notMatchedBySourceAction(&mut self,)
	-> Result<Rc<NotMatchedBySourceActionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NotMatchedBySourceActionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 94, RULE_notMatchedBySourceAction);
        let mut _localctx: Rc<NotMatchedBySourceActionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1638);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DELETE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1634);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					}
				}

			 UPDATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1635);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(1636);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule assignmentList*/
					recog.base.set_state(1637);
					recog.assignmentList()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionVal ----------------
pub type PartitionValContextAll<'input> = PartitionValContext<'input>;


pub type PartitionValContext<'input> = BaseParserRuleContext<'input,PartitionValContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionValContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PartitionValContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PartitionValContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionVal(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_partitionVal(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PartitionValContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_partitionVal(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionValContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionVal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionVal }
}
antlr_rust::tid!{PartitionValContextExt<'a>}

impl<'input> PartitionValContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionValContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionValContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionValContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PartitionValContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}

}

impl<'input> PartitionValContextAttrs<'input> for PartitionValContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionVal(&mut self,)
	-> Result<Rc<PartitionValContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionValContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 96, RULE_partitionVal);
        let mut _localctx: Rc<PartitionValContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1649);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(183,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1640);
					recog.identifier()?;

					recog.base.set_state(1643);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EQ {
						{
						recog.base.set_state(1641);
						recog.base.match_token(EQ,&mut recog.err_handler)?;

						/*InvokeRule constant*/
						recog.base.set_state(1642);
						recog.constant()?;

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1645);
					recog.identifier()?;

					recog.base.set_state(1646);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					recog.base.set_state(1647);
					recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpressionSeq ----------------
pub type NamedExpressionSeqContextAll<'input> = NamedExpressionSeqContext<'input>;


pub type NamedExpressionSeqContext<'input> = BaseParserRuleContext<'input,NamedExpressionSeqContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionSeqContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NamedExpressionSeqContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NamedExpressionSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpressionSeq(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_namedExpressionSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NamedExpressionSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_namedExpressionSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpressionSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpressionSeq }
}
antlr_rust::tid!{NamedExpressionSeqContextExt<'a>}

impl<'input> NamedExpressionSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionSeqContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionSeqContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NamedExpressionSeqContextExt<'input>>{

fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NamedExpressionSeqContextAttrs<'input> for NamedExpressionSeqContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpressionSeq(&mut self,)
	-> Result<Rc<NamedExpressionSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 98, RULE_namedExpressionSeq);
        let mut _localctx: Rc<NamedExpressionSeqContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(1651);
			recog.namedExpression()?;

			recog.base.set_state(1656);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1652);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1653);
				recog.namedExpression()?;

				}
				}
				recog.base.set_state(1658);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpression ----------------
pub type NamedExpressionContextAll<'input> = NamedExpressionContext<'input>;


pub type NamedExpressionContext<'input> = BaseParserRuleContext<'input,NamedExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NamedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NamedExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpression(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_namedExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NamedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_namedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpression }
}
antlr_rust::tid!{NamedExpressionContextExt<'a>}

impl<'input> NamedExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NamedExpressionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedExpressionContextAttrs<'input> for NamedExpressionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpression(&mut self,)
	-> Result<Rc<NamedExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 100, RULE_namedExpression);
        let mut _localctx: Rc<NamedExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(1659);
			recog.expression()?;

			recog.base.set_state(1667);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(187,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1661);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(185,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1660);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1665);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
					 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
					 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
					 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
					 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
					 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
					 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
					 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
					 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
					 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
					 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
					 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
					 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
					 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
					 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT |
					 EXTENDED | EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT |
					 FIRST | FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM |
					 FROM_JSON | FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT |
					 GROUP | GROUPING | HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY |
					 IF | IGNORE | IMMEDIATE | IMPORT | IN | INCLUDE | INDEX | INDEXES |
					 INNER | INPATH | INPUT | INPUTFORMAT | INSERT | INTERSECT | INTERVAL |
					 INT | INTEGER | INTO | INVOKER | IS | ITEMS | ILIKE | JOIN | KEY |
					 KEYS | LANGUAGE | LAST | LATERAL | LAZY | LEADING | LEFT | LIKE | LIMIT |
					 LINES | LIST | LISTAGG | LIVE | LOAD | LOCAL | LOCATION | LOCK | LOCKS |
					 LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES | MATCHED | MATERIALIZED |
					 MERGE | MICROSECOND | MICROSECONDS | MILLISECOND | MILLISECONDS | MINUS_KW |
					 MINUTE | MINUTES | MODE | MODIFIES | MONTH | MONTHS | MSCK | NAME |
					 NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND | NANOSECONDS |
					 NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF | OFFSET |
					 ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT | OUTER |
					 OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
					 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
					 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
					 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL |
					 RECORDREADER | RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP |
					 REFERENCE | REFERENCES | REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE |
					 RESET | RESPECT | RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE |
					 ROLE | ROLES | ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS |
					 SCHEMA | SCHEMAS | SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES |
					 SESSION_USER | SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT |
					 SOME | SORT | SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS |
					 STORED | STRATIFY | STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING |
					 SYNC | SYSTEM_TIME | SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE |
					 TARGET | TBLPROPERTIES | TEMP | TEMPORARY | TERMINATED | STRING_KW |
					 THEN | TIME | TIMEDIFF | TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF |
					 TIMESTAMP_LTZ | TIMESTAMP_NTZ | TINYINT | TO | TOUCH | TRAILING | TRANSACTION |
					 TRANSACTIONS | TRANSFORM | TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE |
					 UNARCHIVE | UNBOUNDED | UNCACHE | UNION | UNIQUE | UNKNOWN | UNLOCK |
					 UNPIVOT | UNSET | UPDATE | USE | USER | USING | VALUES | VAR | VARCHAR |
					 VARIANT | VERSION | VIEW | VIEWS | VOID | WEEK | WEEKS | WHEN | WHERE |
					 WHILE | WINDOW | WITH | WITHIN | YEAR | YEARS | ZONE | IDENTIFIER |
					 BACKQUOTED_IDENTIFIER 
						=> {
							{
							/*InvokeRule identifier*/
							recog.base.set_state(1663);
							let tmp = recog.identifier()?;
							 cast_mut::<_,NamedExpressionContext >(&mut _localctx).name = Some(tmp.clone());
							  

							}
						}

					 LPAREN 
						=> {
							{
							/*InvokeRule identifierList*/
							recog.base.set_state(1664);
							recog.identifierList()?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotNullClause ----------------
pub type UnpivotNullClauseContextAll<'input> = UnpivotNullClauseContext<'input>;


pub type UnpivotNullClauseContext<'input> = BaseParserRuleContext<'input,UnpivotNullClauseContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotNullClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for UnpivotNullClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UnpivotNullClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotNullClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_unpivotNullClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UnpivotNullClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_unpivotNullClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotNullClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotNullClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotNullClause }
}
antlr_rust::tid!{UnpivotNullClauseContextExt<'a>}

impl<'input> UnpivotNullClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotNullClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotNullClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotNullClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<UnpivotNullClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}

}

impl<'input> UnpivotNullClauseContextAttrs<'input> for UnpivotNullClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotNullClause(&mut self,)
	-> Result<Rc<UnpivotNullClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotNullClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 102, RULE_unpivotNullClause);
        let mut _localctx: Rc<UnpivotNullClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1669);
			_la = recog.base.input.la(1);
			if { !(_la==EXCLUDE || _la==INCLUDE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1670);
			recog.base.match_token(NULLS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transformClause ----------------
pub type TransformClauseContextAll<'input> = TransformClauseContext<'input>;


pub type TransformClauseContext<'input> = BaseParserRuleContext<'input,TransformClauseContextExt<'input>>;

#[derive(Clone)]
pub struct TransformClauseContextExt<'input>{
	pub kind: Option<TokenType<'input>>,
	pub inRowFormat: Option<Rc<RowFormatContextAll<'input>>>,
	pub recordWriter: Option<Rc<StringContextAll<'input>>>,
	pub script: Option<Rc<StringContextAll<'input>>>,
	pub outRowFormat: Option<Rc<RowFormatContextAll<'input>>>,
	pub recordReader: Option<Rc<StringContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TransformClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TransformClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_transformClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_transformClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TransformClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_transformClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for TransformClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transformClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transformClause }
}
antlr_rust::tid!{TransformClauseContextExt<'a>}

impl<'input> TransformClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransformClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransformClauseContextExt{
				kind: None, 
				inRowFormat: None, recordWriter: None, script: None, outRowFormat: None, recordReader: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TransformClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TransformClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
fn string_all(&self) ->  Vec<Rc<StringContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn string(&self, i: usize) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
fn expressionSeq(&self) -> Option<Rc<ExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
/// Retrieves first TerminalNode corresponding to token TRANSFORM
/// Returns `None` if there is no child corresponding to token TRANSFORM
fn TRANSFORM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRANSFORM, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token REDUCE
/// Returns `None` if there is no child corresponding to token REDUCE
fn REDUCE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REDUCE, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDWRITER
/// Returns `None` if there is no child corresponding to token RECORDWRITER
fn RECORDWRITER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RECORDWRITER, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDREADER
/// Returns `None` if there is no child corresponding to token RECORDREADER
fn RECORDREADER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RECORDREADER, 0)
}
fn rowFormat_all(&self) ->  Vec<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowFormat(&self, i: usize) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colTypeList(&self) -> Option<Rc<ColTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TransformClauseContextAttrs<'input> for TransformClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transformClause(&mut self,)
	-> Result<Rc<TransformClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransformClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 104, RULE_transformClause);
        let mut _localctx: Rc<TransformClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1691);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 SELECT 
				=> {
					{
					recog.base.set_state(1672);
					recog.base.match_token(SELECT,&mut recog.err_handler)?;

					recog.base.set_state(1673);
					let tmp = recog.base.match_token(TRANSFORM,&mut recog.err_handler)?;
					 cast_mut::<_,TransformClauseContext >(&mut _localctx).kind = Some(tmp);
					  

					recog.base.set_state(1674);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1676);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(188,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(1675);
							recog.setQuantifier()?;

							}
						}

						_ => {}
					}
					/*InvokeRule expressionSeq*/
					recog.base.set_state(1678);
					recog.expressionSeq()?;

					recog.base.set_state(1679);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

			 MAP 
				=> {
					{
					recog.base.set_state(1681);
					let tmp = recog.base.match_token(MAP,&mut recog.err_handler)?;
					 cast_mut::<_,TransformClauseContext >(&mut _localctx).kind = Some(tmp);
					  

					recog.base.set_state(1683);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(189,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(1682);
							recog.setQuantifier()?;

							}
						}

						_ => {}
					}
					/*InvokeRule expressionSeq*/
					recog.base.set_state(1685);
					recog.expressionSeq()?;

					}
				}

			 REDUCE 
				=> {
					{
					recog.base.set_state(1686);
					let tmp = recog.base.match_token(REDUCE,&mut recog.err_handler)?;
					 cast_mut::<_,TransformClauseContext >(&mut _localctx).kind = Some(tmp);
					  

					recog.base.set_state(1688);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(190,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(1687);
							recog.setQuantifier()?;

							}
						}

						_ => {}
					}
					/*InvokeRule expressionSeq*/
					recog.base.set_state(1690);
					recog.expressionSeq()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(1694);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ROW {
				{
				/*InvokeRule rowFormat*/
				recog.base.set_state(1693);
				let tmp = recog.rowFormat()?;
				 cast_mut::<_,TransformClauseContext >(&mut _localctx).inRowFormat = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1698);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==RECORDWRITER {
				{
				recog.base.set_state(1696);
				recog.base.match_token(RECORDWRITER,&mut recog.err_handler)?;

				/*InvokeRule string*/
				recog.base.set_state(1697);
				let tmp = recog.string()?;
				 cast_mut::<_,TransformClauseContext >(&mut _localctx).recordWriter = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1700);
			recog.base.match_token(USING,&mut recog.err_handler)?;

			/*InvokeRule string*/
			recog.base.set_state(1701);
			let tmp = recog.string()?;
			 cast_mut::<_,TransformClauseContext >(&mut _localctx).script = Some(tmp.clone());
			  

			recog.base.set_state(1714);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(1702);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				recog.base.set_state(1712);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(195,&mut recog.base)? {
					1 =>{
						{
						/*InvokeRule identifierSeq*/
						recog.base.set_state(1703);
						recog.identifierSeq()?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule colTypeList*/
						recog.base.set_state(1704);
						recog.colTypeList()?;

						}
					}
				,
					3 =>{
						{
						{
						recog.base.set_state(1705);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(1708);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(194,&mut recog.base)? {
							1 =>{
								{
								/*InvokeRule identifierSeq*/
								recog.base.set_state(1706);
								recog.identifierSeq()?;

								}
							}
						,
							2 =>{
								{
								/*InvokeRule colTypeList*/
								recog.base.set_state(1707);
								recog.colTypeList()?;

								}
							}

							_ => {}
						}
						recog.base.set_state(1710);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
						}
					}

					_ => {}
				}
				}
			}

			recog.base.set_state(1717);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ROW {
				{
				/*InvokeRule rowFormat*/
				recog.base.set_state(1716);
				let tmp = recog.rowFormat()?;
				 cast_mut::<_,TransformClauseContext >(&mut _localctx).outRowFormat = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1721);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==RECORDREADER {
				{
				recog.base.set_state(1719);
				recog.base.match_token(RECORDREADER,&mut recog.err_handler)?;

				/*InvokeRule string*/
				recog.base.set_state(1720);
				let tmp = recog.string()?;
				 cast_mut::<_,TransformClauseContext >(&mut _localctx).recordReader = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectClause ----------------
pub type SelectClauseContextAll<'input> = SelectClauseContext<'input>;


pub type SelectClauseContext<'input> = BaseParserRuleContext<'input,SelectClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SelectClauseContextExt<'input>{
	pub hint: Option<Rc<HintContextAll<'input>>>,
	pub hints:Vec<Rc<HintContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SelectClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SelectClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_selectClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SelectClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_selectClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectClause }
}
antlr_rust::tid!{SelectClauseContextExt<'a>}

impl<'input> SelectClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectClauseContextExt{
				hint: None, 
				hints: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SelectClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
fn namedExpressionSeq(&self) -> Option<Rc<NamedExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn hint_all(&self) ->  Vec<Rc<HintContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn hint(&self, i: usize) -> Option<Rc<HintContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SelectClauseContextAttrs<'input> for SelectClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectClause(&mut self,)
	-> Result<Rc<SelectClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 106, RULE_selectClause);
        let mut _localctx: Rc<SelectClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1723);
			recog.base.match_token(SELECT,&mut recog.err_handler)?;

			recog.base.set_state(1727);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==HENT_START {
				{
				{
				/*InvokeRule hint*/
				recog.base.set_state(1724);
				let tmp = recog.hint()?;
				 cast_mut::<_,SelectClauseContext >(&mut _localctx).hint = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SelectClauseContext >(&mut _localctx).hint.clone().unwrap()
				 ;
				 cast_mut::<_,SelectClauseContext >(&mut _localctx).hints.push(temp);
				  
				}
				}
				recog.base.set_state(1729);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1731);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(200,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule setQuantifier*/
					recog.base.set_state(1730);
					recog.setQuantifier()?;

					}
				}

				_ => {}
			}
			/*InvokeRule namedExpressionSeq*/
			recog.base.set_state(1733);
			recog.namedExpressionSeq()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- havingClause ----------------
pub type HavingClauseContextAll<'input> = HavingClauseContext<'input>;


pub type HavingClauseContext<'input> = BaseParserRuleContext<'input,HavingClauseContextExt<'input>>;

#[derive(Clone)]
pub struct HavingClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for HavingClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for HavingClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_havingClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_havingClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for HavingClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_havingClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for HavingClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_havingClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_havingClause }
}
antlr_rust::tid!{HavingClauseContextExt<'a>}

impl<'input> HavingClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HavingClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HavingClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HavingClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<HavingClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> HavingClauseContextAttrs<'input> for HavingClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn havingClause(&mut self,)
	-> Result<Rc<HavingClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HavingClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 108, RULE_havingClause);
        let mut _localctx: Rc<HavingClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1735);
			recog.base.match_token(HAVING,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(1736);
			recog.booleanExpression_rec(0)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multipartIdentifierList ----------------
pub type MultipartIdentifierListContextAll<'input> = MultipartIdentifierListContext<'input>;


pub type MultipartIdentifierListContext<'input> = BaseParserRuleContext<'input,MultipartIdentifierListContextExt<'input>>;

#[derive(Clone)]
pub struct MultipartIdentifierListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for MultipartIdentifierListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MultipartIdentifierListContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multipartIdentifierList(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_multipartIdentifierList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MultipartIdentifierListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_multipartIdentifierList(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipartIdentifierListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multipartIdentifierList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multipartIdentifierList }
}
antlr_rust::tid!{MultipartIdentifierListContextExt<'a>}

impl<'input> MultipartIdentifierListContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultipartIdentifierListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultipartIdentifierListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultipartIdentifierListContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<MultipartIdentifierListContextExt<'input>>{

fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> MultipartIdentifierListContextAttrs<'input> for MultipartIdentifierListContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multipartIdentifierList(&mut self,)
	-> Result<Rc<MultipartIdentifierListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultipartIdentifierListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 110, RULE_multipartIdentifierList);
        let mut _localctx: Rc<MultipartIdentifierListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(1738);
			recog.qualifiedName()?;

			recog.base.set_state(1743);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1739);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule qualifiedName*/
				recog.base.set_state(1740);
				recog.qualifiedName()?;

				}
				}
				recog.base.set_state(1745);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionSeq ----------------
pub type ExpressionSeqContextAll<'input> = ExpressionSeqContext<'input>;


pub type ExpressionSeqContext<'input> = BaseParserRuleContext<'input,ExpressionSeqContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionSeqContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ExpressionSeqContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExpressionSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionSeq(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_expressionSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExpressionSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_expressionSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionSeq }
}
antlr_rust::tid!{ExpressionSeqContextExt<'a>}

impl<'input> ExpressionSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionSeqContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionSeqContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ExpressionSeqContextExt<'input>>{

fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ExpressionSeqContextAttrs<'input> for ExpressionSeqContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionSeq(&mut self,)
	-> Result<Rc<ExpressionSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 112, RULE_expressionSeq);
        let mut _localctx: Rc<ExpressionSeqContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(1746);
			recog.expression()?;

			recog.base.set_state(1751);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1747);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(1748);
				recog.expression()?;

				}
				}
				recog.base.set_state(1753);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colTypeList ----------------
pub type ColTypeListContextAll<'input> = ColTypeListContext<'input>;


pub type ColTypeListContext<'input> = BaseParserRuleContext<'input,ColTypeListContextExt<'input>>;

#[derive(Clone)]
pub struct ColTypeListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColTypeListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColTypeListContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colTypeList(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_colTypeList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColTypeListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_colTypeList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColTypeListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colTypeList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colTypeList }
}
antlr_rust::tid!{ColTypeListContextExt<'a>}

impl<'input> ColTypeListContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColTypeListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColTypeListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColTypeListContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColTypeListContextExt<'input>>{

fn colType_all(&self) ->  Vec<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn colType(&self, i: usize) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColTypeListContextAttrs<'input> for ColTypeListContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colTypeList(&mut self,)
	-> Result<Rc<ColTypeListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColTypeListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 114, RULE_colTypeList);
        let mut _localctx: Rc<ColTypeListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule colType*/
			recog.base.set_state(1754);
			recog.colType()?;

			recog.base.set_state(1759);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1755);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule colType*/
				recog.base.set_state(1756);
				recog.colType()?;

				}
				}
				recog.base.set_state(1761);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hint ----------------
pub type HintContextAll<'input> = HintContext<'input>;


pub type HintContext<'input> = BaseParserRuleContext<'input,HintContextExt<'input>>;

#[derive(Clone)]
pub struct HintContextExt<'input>{
	pub hintStatement: Option<Rc<HintStatementContextAll<'input>>>,
	pub hintStatements:Vec<Rc<HintStatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for HintContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for HintContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hint(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_hint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for HintContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_hint(self);
	}
}

impl<'input> CustomRuleContext<'input> for HintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hint }
}
antlr_rust::tid!{HintContextExt<'a>}

impl<'input> HintContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintContextExt{
				hintStatement: None, 
				hintStatements: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait HintContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<HintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token HENT_START
/// Returns `None` if there is no child corresponding to token HENT_START
fn HENT_START(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HENT_START, 0)
}
/// Retrieves first TerminalNode corresponding to token HENT_END
/// Returns `None` if there is no child corresponding to token HENT_END
fn HENT_END(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HENT_END, 0)
}
fn hintStatement_all(&self) ->  Vec<Rc<HintStatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn hintStatement(&self, i: usize) -> Option<Rc<HintStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> HintContextAttrs<'input> for HintContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hint(&mut self,)
	-> Result<Rc<HintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 116, RULE_hint);
        let mut _localctx: Rc<HintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1762);
			recog.base.match_token(HENT_START,&mut recog.err_handler)?;

			/*InvokeRule hintStatement*/
			recog.base.set_state(1763);
			let tmp = recog.hintStatement()?;
			 cast_mut::<_,HintContext >(&mut _localctx).hintStatement = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,HintContext >(&mut _localctx).hintStatement.clone().unwrap()
			 ;
			 cast_mut::<_,HintContext >(&mut _localctx).hintStatements.push(temp);
			  
			recog.base.set_state(1770);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMA - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
				{
				{
				recog.base.set_state(1765);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==COMMA {
					{
					recog.base.set_state(1764);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					}
				}

				/*InvokeRule hintStatement*/
				recog.base.set_state(1767);
				let tmp = recog.hintStatement()?;
				 cast_mut::<_,HintContext >(&mut _localctx).hintStatement = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,HintContext >(&mut _localctx).hintStatement.clone().unwrap()
				 ;
				 cast_mut::<_,HintContext >(&mut _localctx).hintStatements.push(temp);
				  
				}
				}
				recog.base.set_state(1772);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1773);
			recog.base.match_token(HENT_END,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hintStatement ----------------
pub type HintStatementContextAll<'input> = HintStatementContext<'input>;


pub type HintStatementContext<'input> = BaseParserRuleContext<'input,HintStatementContextExt<'input>>;

#[derive(Clone)]
pub struct HintStatementContextExt<'input>{
	pub hintName: Option<Rc<IdentifierContextAll<'input>>>,
	pub primaryExpression: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub parameters:Vec<Rc<PrimaryExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for HintStatementContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for HintStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hintStatement(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_hintStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for HintStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_hintStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for HintStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hintStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hintStatement }
}
antlr_rust::tid!{HintStatementContextExt<'a>}

impl<'input> HintStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintStatementContextExt{
				hintName: None, primaryExpression: None, 
				parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait HintStatementContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<HintStatementContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn primaryExpression_all(&self) ->  Vec<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn primaryExpression(&self, i: usize) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> HintStatementContextAttrs<'input> for HintStatementContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hintStatement(&mut self,)
	-> Result<Rc<HintStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 118, RULE_hintStatement);
        let mut _localctx: Rc<HintStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1788);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(207,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1775);
					let tmp = recog.identifier()?;
					 cast_mut::<_,HintStatementContext >(&mut _localctx).hintName = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1776);
					let tmp = recog.identifier()?;
					 cast_mut::<_,HintStatementContext >(&mut _localctx).hintName = Some(tmp.clone());
					  

					recog.base.set_state(1777);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule primaryExpression*/
					recog.base.set_state(1778);
					let tmp = recog.primaryExpression_rec(0)?;
					 cast_mut::<_,HintStatementContext >(&mut _localctx).primaryExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,HintStatementContext >(&mut _localctx).primaryExpression.clone().unwrap()
					 ;
					 cast_mut::<_,HintStatementContext >(&mut _localctx).parameters.push(temp);
					  
					recog.base.set_state(1783);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(1779);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule primaryExpression*/
						recog.base.set_state(1780);
						let tmp = recog.primaryExpression_rec(0)?;
						 cast_mut::<_,HintStatementContext >(&mut _localctx).primaryExpression = Some(tmp.clone());
						  

						let temp =  cast_mut::<_,HintStatementContext >(&mut _localctx).primaryExpression.clone().unwrap()
						 ;
						 cast_mut::<_,HintStatementContext >(&mut _localctx).parameters.push(temp);
						  
						}
						}
						recog.base.set_state(1785);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1786);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- query ----------------
pub type QueryContextAll<'input> = QueryContext<'input>;


pub type QueryContext<'input> = BaseParserRuleContext<'input,QueryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QueryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_query(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_query(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_query(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_query }
	//fn type_rule_index() -> usize where Self: Sized { RULE_query }
}
antlr_rust::tid!{QueryContextExt<'a>}

impl<'input> QueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QueryContextExt<'input>>{

fn queryNoWith(&self) -> Option<Rc<QueryNoWithContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn with(&self) -> Option<Rc<WithContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryContextAttrs<'input> for QueryContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn query(&mut self,)
	-> Result<Rc<QueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 120, RULE_query);
        let mut _localctx: Rc<QueryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1791);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WITH {
				{
				/*InvokeRule with*/
				recog.base.set_state(1790);
				recog.with()?;

				}
			}

			/*InvokeRule queryNoWith*/
			recog.base.set_state(1793);
			recog.queryNoWith()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- with ----------------
pub type WithContextAll<'input> = WithContext<'input>;


pub type WithContext<'input> = BaseParserRuleContext<'input,WithContextExt<'input>>;

#[derive(Clone)]
pub struct WithContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for WithContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for WithContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_with(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_with(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for WithContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_with(self);
	}
}

impl<'input> CustomRuleContext<'input> for WithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_with }
	//fn type_rule_index() -> usize where Self: Sized { RULE_with }
}
antlr_rust::tid!{WithContextExt<'a>}

impl<'input> WithContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WithContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WithContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WithContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<WithContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn namedQuery_all(&self) ->  Vec<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedQuery(&self, i: usize) -> Option<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WithContextAttrs<'input> for WithContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn with(&mut self,)
	-> Result<Rc<WithContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WithContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 122, RULE_with);
        let mut _localctx: Rc<WithContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1795);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule namedQuery*/
			recog.base.set_state(1796);
			recog.namedQuery()?;

			recog.base.set_state(1801);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1797);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedQuery*/
				recog.base.set_state(1798);
				recog.namedQuery()?;

				}
				}
				recog.base.set_state(1803);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableElement ----------------
pub type TableElementContextAll<'input> = TableElementContext<'input>;


pub type TableElementContext<'input> = BaseParserRuleContext<'input,TableElementContextExt<'input>>;

#[derive(Clone)]
pub struct TableElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableElementContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableElementContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableElement(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_tableElement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableElementContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableElement(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableElement }
}
antlr_rust::tid!{TableElementContextExt<'a>}

impl<'input> TableElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableElementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableElementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableElementContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableElementContextExt<'input>>{

fn columnDefinition(&self) -> Option<Rc<ColumnDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn tableConstraint(&self) -> Option<Rc<TableConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableElementContextAttrs<'input> for TableElementContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableElement(&mut self,)
	-> Result<Rc<TableElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 124, RULE_tableElement);
        let mut _localctx: Rc<TableElementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1811);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(211,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule columnDefinition*/
					recog.base.set_state(1804);
					recog.columnDefinition()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1806); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule qualifiedName*/
						recog.base.set_state(1805);
						recog.qualifiedName()?;

						}
						}
						recog.base.set_state(1808); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER) {break}
					}
					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule tableConstraint*/
					recog.base.set_state(1810);
					recog.tableConstraint()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableConstraint ----------------
pub type TableConstraintContextAll<'input> = TableConstraintContext<'input>;


pub type TableConstraintContext<'input> = BaseParserRuleContext<'input,TableConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct TableConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableConstraint(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_tableConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableConstraint }
}
antlr_rust::tid!{TableConstraintContextExt<'a>}

impl<'input> TableConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableConstraintContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PRIMARY
/// Returns `None` if there is no child corresponding to token PRIMARY
fn PRIMARY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PRIMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
fn identifierList_all(&self) ->  Vec<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifierList(&self, i: usize) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token FOREIGN
/// Returns `None` if there is no child corresponding to token FOREIGN
fn FOREIGN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FOREIGN, 0)
}
/// Retrieves first TerminalNode corresponding to token REFERENCES
/// Returns `None` if there is no child corresponding to token REFERENCES
fn REFERENCES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REFERENCES, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CONSTRAINT
/// Returns `None` if there is no child corresponding to token CONSTRAINT
fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableConstraintContextAttrs<'input> for TableConstraintContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableConstraint(&mut self,)
	-> Result<Rc<TableConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 126, RULE_tableConstraint);
        let mut _localctx: Rc<TableConstraintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1815);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==CONSTRAINT {
				{
				recog.base.set_state(1813);
				recog.base.match_token(CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule identifier*/
				recog.base.set_state(1814);
				recog.identifier()?;

				}
			}

			recog.base.set_state(1828);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 PRIMARY 
				=> {
					{
					recog.base.set_state(1817);
					recog.base.match_token(PRIMARY,&mut recog.err_handler)?;

					recog.base.set_state(1818);
					recog.base.match_token(KEY,&mut recog.err_handler)?;

					/*InvokeRule identifierList*/
					recog.base.set_state(1819);
					recog.identifierList()?;

					}
				}

			 FOREIGN 
				=> {
					{
					recog.base.set_state(1820);
					recog.base.match_token(FOREIGN,&mut recog.err_handler)?;

					recog.base.set_state(1821);
					recog.base.match_token(KEY,&mut recog.err_handler)?;

					/*InvokeRule identifierList*/
					recog.base.set_state(1822);
					recog.identifierList()?;

					recog.base.set_state(1823);
					recog.base.match_token(REFERENCES,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(1824);
					recog.qualifiedName()?;

					recog.base.set_state(1826);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LPAREN {
						{
						/*InvokeRule identifierList*/
						recog.base.set_state(1825);
						recog.identifierList()?;

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnDefinition ----------------
pub type ColumnDefinitionContextAll<'input> = ColumnDefinitionContext<'input>;


pub type ColumnDefinitionContext<'input> = BaseParserRuleContext<'input,ColumnDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnDefinition }
}
antlr_rust::tid!{ColumnDefinitionContextExt<'a>}

impl<'input> ColumnDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnDefinitionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnDefinitionContextExt<'input>>{

fn fieldDefinition(&self) -> Option<Rc<FieldDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnDefinitionContextAttrs<'input> for ColumnDefinitionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnDefinition(&mut self,)
	-> Result<Rc<ColumnDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 128, RULE_columnDefinition);
        let mut _localctx: Rc<ColumnDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule fieldDefinition*/
			recog.base.set_state(1830);
			recog.fieldDefinition()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnDefinitionForView ----------------
pub type ColumnDefinitionForViewContextAll<'input> = ColumnDefinitionForViewContext<'input>;


pub type ColumnDefinitionForViewContext<'input> = BaseParserRuleContext<'input,ColumnDefinitionForViewContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnDefinitionForViewContextExt<'input>{
	pub name: Option<Rc<ColumnNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnDefinitionForViewContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnDefinitionForViewContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnDefinitionForView(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnDefinitionForView(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnDefinitionForViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnDefinitionForView(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnDefinitionForViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnDefinitionForView }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnDefinitionForView }
}
antlr_rust::tid!{ColumnDefinitionForViewContextExt<'a>}

impl<'input> ColumnDefinitionForViewContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnDefinitionForViewContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnDefinitionForViewContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnDefinitionForViewContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnDefinitionForViewContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnDefinitionForViewContextAttrs<'input> for ColumnDefinitionForViewContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnDefinitionForView(&mut self,)
	-> Result<Rc<ColumnDefinitionForViewContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnDefinitionForViewContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 130, RULE_columnDefinitionForView);
        let mut _localctx: Rc<ColumnDefinitionForViewContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnName*/
			recog.base.set_state(1832);
			let tmp = recog.columnName()?;
			 cast_mut::<_,ColumnDefinitionForViewContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(1834);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(215,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule type_*/
					recog.base.set_state(1833);
					recog.type_()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(1838);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMENT {
				{
				recog.base.set_state(1836);
				recog.base.match_token(COMMENT,&mut recog.err_handler)?;

				/*InvokeRule string*/
				recog.base.set_state(1837);
				recog.string()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fieldDefinitions ----------------
pub type FieldDefinitionsContextAll<'input> = FieldDefinitionsContext<'input>;


pub type FieldDefinitionsContext<'input> = BaseParserRuleContext<'input,FieldDefinitionsContextExt<'input>>;

#[derive(Clone)]
pub struct FieldDefinitionsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FieldDefinitionsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FieldDefinitionsContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fieldDefinitions(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_fieldDefinitions(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FieldDefinitionsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_fieldDefinitions(self);
	}
}

impl<'input> CustomRuleContext<'input> for FieldDefinitionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fieldDefinitions }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fieldDefinitions }
}
antlr_rust::tid!{FieldDefinitionsContextExt<'a>}

impl<'input> FieldDefinitionsContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FieldDefinitionsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FieldDefinitionsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FieldDefinitionsContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FieldDefinitionsContextExt<'input>>{

fn fieldDefinition_all(&self) ->  Vec<Rc<FieldDefinitionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn fieldDefinition(&self, i: usize) -> Option<Rc<FieldDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> FieldDefinitionsContextAttrs<'input> for FieldDefinitionsContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fieldDefinitions(&mut self,)
	-> Result<Rc<FieldDefinitionsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FieldDefinitionsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 132, RULE_fieldDefinitions);
        let mut _localctx: Rc<FieldDefinitionsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule fieldDefinition*/
			recog.base.set_state(1840);
			recog.fieldDefinition()?;

			recog.base.set_state(1845);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(217,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1841);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule fieldDefinition*/
					recog.base.set_state(1842);
					recog.fieldDefinition()?;

					}
					} 
				}
				recog.base.set_state(1847);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(217,&mut recog.base)?;
			}
			recog.base.set_state(1849);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1848);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,FieldDefinitionsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fieldDefinition ----------------
pub type FieldDefinitionContextAll<'input> = FieldDefinitionContext<'input>;


pub type FieldDefinitionContext<'input> = BaseParserRuleContext<'input,FieldDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct FieldDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FieldDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FieldDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fieldDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_fieldDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FieldDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_fieldDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for FieldDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fieldDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fieldDefinition }
}
antlr_rust::tid!{FieldDefinitionContextExt<'a>}

impl<'input> FieldDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FieldDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FieldDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FieldDefinitionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FieldDefinitionContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnSchemaWithMetadata(&self) -> Option<Rc<ColumnSchemaWithMetadataContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FieldDefinitionContextAttrs<'input> for FieldDefinitionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fieldDefinition(&mut self,)
	-> Result<Rc<FieldDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FieldDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 134, RULE_fieldDefinition);
        let mut _localctx: Rc<FieldDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnName*/
			recog.base.set_state(1851);
			recog.columnName()?;

			/*InvokeRule columnSchemaWithMetadata*/
			recog.base.set_state(1852);
			recog.columnSchemaWithMetadata()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnName ----------------
pub type ColumnNameContextAll<'input> = ColumnNameContext<'input>;


pub type ColumnNameContext<'input> = BaseParserRuleContext<'input,ColumnNameContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnNameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnNameContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnName(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnName(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnName }
}
antlr_rust::tid!{ColumnNameContextExt<'a>}

impl<'input> ColumnNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnNameContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameContextAttrs<'input> for ColumnNameContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnName(&mut self,)
	-> Result<Rc<ColumnNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 136, RULE_columnName);
        let mut _localctx: Rc<ColumnNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1854);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameComponent ----------------
pub type ColumnNameComponentContextAll<'input> = ColumnNameComponentContext<'input>;


pub type ColumnNameComponentContext<'input> = BaseParserRuleContext<'input,ColumnNameComponentContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameComponentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnNameComponentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnNameComponentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameComponent(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnNameComponent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnNameComponentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnNameComponent(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnNameComponentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameComponent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameComponent }
}
antlr_rust::tid!{ColumnNameComponentContextExt<'a>}

impl<'input> ColumnNameComponentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameComponentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameComponentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameComponentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnNameComponentContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameComponentContextAttrs<'input> for ColumnNameComponentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameComponent(&mut self,)
	-> Result<Rc<ColumnNameComponentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameComponentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 138, RULE_columnNameComponent);
        let mut _localctx: Rc<ColumnNameComponentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnName*/
			recog.base.set_state(1856);
			recog.columnName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnSchemaWithMetadata ----------------
pub type ColumnSchemaWithMetadataContextAll<'input> = ColumnSchemaWithMetadataContext<'input>;


pub type ColumnSchemaWithMetadataContext<'input> = BaseParserRuleContext<'input,ColumnSchemaWithMetadataContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnSchemaWithMetadataContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnSchemaWithMetadataContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnSchemaWithMetadataContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnSchemaWithMetadata(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnSchemaWithMetadata(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnSchemaWithMetadataContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnSchemaWithMetadata(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaWithMetadataContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchemaWithMetadata }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchemaWithMetadata }
}
antlr_rust::tid!{ColumnSchemaWithMetadataContextExt<'a>}

impl<'input> ColumnSchemaWithMetadataContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnSchemaWithMetadataContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnSchemaWithMetadataContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnSchemaWithMetadataContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnSchemaWithMetadataContextExt<'input>>{

fn columnSchema(&self) -> Option<Rc<ColumnSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colDefinitionOption_all(&self) ->  Vec<Rc<ColDefinitionOptionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn colDefinitionOption(&self, i: usize) -> Option<Rc<ColDefinitionOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ColumnSchemaWithMetadataContextAttrs<'input> for ColumnSchemaWithMetadataContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnSchemaWithMetadata(&mut self,)
	-> Result<Rc<ColumnSchemaWithMetadataContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnSchemaWithMetadataContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 140, RULE_columnSchemaWithMetadata);
        let mut _localctx: Rc<ColumnSchemaWithMetadataContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnSchema*/
			recog.base.set_state(1858);
			recog.columnSchema()?;

			recog.base.set_state(1862);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMENT || _la==DEFAULT || _la==GENERATED || _la==NOT {
				{
				{
				/*InvokeRule colDefinitionOption*/
				recog.base.set_state(1859);
				recog.colDefinitionOption()?;

				}
				}
				recog.base.set_state(1864);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colDefinitionOption ----------------
pub type ColDefinitionOptionContextAll<'input> = ColDefinitionOptionContext<'input>;


pub type ColDefinitionOptionContext<'input> = BaseParserRuleContext<'input,ColDefinitionOptionContextExt<'input>>;

#[derive(Clone)]
pub struct ColDefinitionOptionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColDefinitionOptionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColDefinitionOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colDefinitionOption(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_colDefinitionOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColDefinitionOptionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_colDefinitionOption(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColDefinitionOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colDefinitionOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colDefinitionOption }
}
antlr_rust::tid!{ColDefinitionOptionContextExt<'a>}

impl<'input> ColDefinitionOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColDefinitionOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColDefinitionOptionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColDefinitionOptionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColDefinitionOptionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
fn defaultExpression(&self) -> Option<Rc<DefaultExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn generationExpression(&self) -> Option<Rc<GenerationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColDefinitionOptionContextAttrs<'input> for ColDefinitionOptionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colDefinitionOption(&mut self,)
	-> Result<Rc<ColDefinitionOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColDefinitionOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 142, RULE_colDefinitionOption);
        let mut _localctx: Rc<ColDefinitionOptionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1870);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1865);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					recog.base.set_state(1866);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

			 DEFAULT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule defaultExpression*/
					recog.base.set_state(1867);
					recog.defaultExpression()?;

					}
				}

			 GENERATED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule generationExpression*/
					recog.base.set_state(1868);
					recog.generationExpression()?;

					}
				}

			 COMMENT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule commentSpec*/
					recog.base.set_state(1869);
					recog.commentSpec()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- generationExpression ----------------
pub type GenerationExpressionContextAll<'input> = GenerationExpressionContext<'input>;


pub type GenerationExpressionContext<'input> = BaseParserRuleContext<'input,GenerationExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct GenerationExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for GenerationExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GenerationExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_generationExpression(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_generationExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GenerationExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_generationExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for GenerationExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_generationExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_generationExpression }
}
antlr_rust::tid!{GenerationExpressionContextExt<'a>}

impl<'input> GenerationExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GenerationExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GenerationExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GenerationExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<GenerationExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GENERATED
/// Returns `None` if there is no child corresponding to token GENERATED
fn GENERATED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GENERATED, 0)
}
/// Retrieves first TerminalNode corresponding to token ALWAYS
/// Returns `None` if there is no child corresponding to token ALWAYS
fn ALWAYS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALWAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTITY
/// Returns `None` if there is no child corresponding to token IDENTITY
fn IDENTITY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IDENTITY, 0)
}

}

impl<'input> GenerationExpressionContextAttrs<'input> for GenerationExpressionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn generationExpression(&mut self,)
	-> Result<Rc<GenerationExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GenerationExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 144, RULE_generationExpression);
        let mut _localctx: Rc<GenerationExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1872);
			recog.base.match_token(GENERATED,&mut recog.err_handler)?;

			recog.base.set_state(1873);
			recog.base.match_token(ALWAYS,&mut recog.err_handler)?;

			recog.base.set_state(1874);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(1880);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LPAREN 
				=> {
					{
					recog.base.set_state(1875);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1876);
					recog.expression()?;

					recog.base.set_state(1877);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

			 IDENTITY 
				=> {
					{
					recog.base.set_state(1879);
					recog.base.match_token(IDENTITY,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- defaultExpression ----------------
pub type DefaultExpressionContextAll<'input> = DefaultExpressionContext<'input>;


pub type DefaultExpressionContext<'input> = BaseParserRuleContext<'input,DefaultExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct DefaultExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for DefaultExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DefaultExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_defaultExpression(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_defaultExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DefaultExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_defaultExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_defaultExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_defaultExpression }
}
antlr_rust::tid!{DefaultExpressionContextExt<'a>}

impl<'input> DefaultExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DefaultExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DefaultExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DefaultExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<DefaultExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DefaultExpressionContextAttrs<'input> for DefaultExpressionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn defaultExpression(&mut self,)
	-> Result<Rc<DefaultExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DefaultExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 146, RULE_defaultExpression);
        let mut _localctx: Rc<DefaultExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1882);
			recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1883);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnOptionList ----------------
pub type ColumnOptionListContextAll<'input> = ColumnOptionListContext<'input>;


pub type ColumnOptionListContext<'input> = BaseParserRuleContext<'input,ColumnOptionListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnOptionListContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnOptionListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnOptionListContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnOptionList(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnOptionList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnOptionListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnOptionList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnOptionListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnOptionList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnOptionList }
}
antlr_rust::tid!{ColumnOptionListContextExt<'a>}

impl<'input> ColumnOptionListContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnOptionListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnOptionListContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnOptionListContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnOptionListContextExt<'input>>{

fn columnOption_all(&self) ->  Vec<Rc<ColumnOptionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnOption(&self, i: usize) -> Option<Rc<ColumnOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnOptionListContextAttrs<'input> for ColumnOptionListContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnOptionList(&mut self,)
	-> Result<Rc<ColumnOptionListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnOptionListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 148, RULE_columnOptionList);
        let mut _localctx: Rc<ColumnOptionListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnOption*/
			recog.base.set_state(1885);
			recog.columnOption()?;

			recog.base.set_state(1890);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(222,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1886);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule columnOption*/
					recog.base.set_state(1887);
					recog.columnOption()?;

					}
					} 
				}
				recog.base.set_state(1892);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(222,&mut recog.base)?;
			}
			recog.base.set_state(1894);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1893);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnOptionListContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnOption ----------------
pub type ColumnOptionContextAll<'input> = ColumnOptionContext<'input>;


pub type ColumnOptionContext<'input> = BaseParserRuleContext<'input,ColumnOptionContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnOptionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnOptionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnOption(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnOptionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnOption(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnOption }
}
antlr_rust::tid!{ColumnOptionContextExt<'a>}

impl<'input> ColumnOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnOptionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnOptionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnOptionContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnOptionContextAttrs<'input> for ColumnOptionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnOption(&mut self,)
	-> Result<Rc<ColumnOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 150, RULE_columnOption);
        let mut _localctx: Rc<ColumnOptionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(1896);
			recog.identifier()?;

			recog.base.set_state(1897);
			recog.base.match_token(EQ,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1898);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnSchema ----------------
#[derive(Debug)]
pub enum ColumnSchemaContextAll<'input>{
	ColumnSchemaSimpleTypeContext(ColumnSchemaSimpleTypeContext<'input>),
Error(ColumnSchemaContext<'input>)
}
antlr_rust::tid!{ColumnSchemaContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ColumnSchemaContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for ColumnSchemaContextAll<'input>{}

impl<'input> Deref for ColumnSchemaContextAll<'input>{
	type Target = dyn ColumnSchemaContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ColumnSchemaContextAll::*;
		match self{
			ColumnSchemaSimpleTypeContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnSchemaContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnSchemaContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ColumnSchemaContext<'input> = BaseParserRuleContext<'input,ColumnSchemaContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnSchemaContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnSchemaContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnSchemaContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchema }
}
antlr_rust::tid!{ColumnSchemaContextExt<'a>}

impl<'input> ColumnSchemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnSchemaContextAll<'input>> {
		Rc::new(
		ColumnSchemaContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnSchemaContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ColumnSchemaContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnSchemaContextExt<'input>>{


}

impl<'input> ColumnSchemaContextAttrs<'input> for ColumnSchemaContext<'input>{}

pub type ColumnSchemaSimpleTypeContext<'input> = BaseParserRuleContext<'input,ColumnSchemaSimpleTypeContextExt<'input>>;

pub trait ColumnSchemaSimpleTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ColumnSchemaSimpleTypeContextAttrs<'input> for ColumnSchemaSimpleTypeContext<'input>{}

pub struct ColumnSchemaSimpleTypeContextExt<'input>{
	base:ColumnSchemaContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnSchemaSimpleTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ColumnSchemaSimpleTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnSchemaSimpleTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnSchemaSimpleType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_columnSchemaSimpleType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnSchemaSimpleTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnSchemaSimpleType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSchemaSimpleTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSchema }
}

impl<'input> Borrow<ColumnSchemaContextExt<'input>> for ColumnSchemaSimpleTypeContext<'input>{
	fn borrow(&self) -> &ColumnSchemaContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnSchemaContextExt<'input>> for ColumnSchemaSimpleTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnSchemaContextExt<'input> { &mut self.base }
}

impl<'input> ColumnSchemaContextAttrs<'input> for ColumnSchemaSimpleTypeContext<'input> {}

impl<'input> ColumnSchemaSimpleTypeContextExt<'input>{
	fn new(ctx: &dyn ColumnSchemaContextAttrs<'input>) -> Rc<ColumnSchemaContextAll<'input>>  {
		Rc::new(
			ColumnSchemaContextAll::ColumnSchemaSimpleTypeContext(
				BaseParserRuleContext::copy_from(ctx,ColumnSchemaSimpleTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnSchema(&mut self,)
	-> Result<Rc<ColumnSchemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnSchemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 152, RULE_columnSchema);
        let mut _localctx: Rc<ColumnSchemaContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = ColumnSchemaSimpleTypeContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule type_*/
			recog.base.set_state(1900);
			recog.type_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- properties ----------------
pub type PropertiesContextAll<'input> = PropertiesContext<'input>;


pub type PropertiesContext<'input> = BaseParserRuleContext<'input,PropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct PropertiesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_properties(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_properties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_properties(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_properties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_properties }
}
antlr_rust::tid!{PropertiesContextExt<'a>}

impl<'input> PropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertiesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertiesContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn propertyAssignments(&self) -> Option<Rc<PropertyAssignmentsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertiesContextAttrs<'input> for PropertiesContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn properties(&mut self,)
	-> Result<Rc<PropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 154, RULE_properties);
        let mut _localctx: Rc<PropertiesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1902);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(1904);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)))) != 0) {
				{
				/*InvokeRule propertyAssignments*/
				recog.base.set_state(1903);
				recog.propertyAssignments()?;

				}
			}

			recog.base.set_state(1906);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyAssignments ----------------
pub type PropertyAssignmentsContextAll<'input> = PropertyAssignmentsContext<'input>;


pub type PropertyAssignmentsContext<'input> = BaseParserRuleContext<'input,PropertyAssignmentsContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyAssignmentsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PropertyAssignmentsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PropertyAssignmentsContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyAssignments(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_propertyAssignments(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PropertyAssignmentsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_propertyAssignments(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyAssignmentsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyAssignments }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyAssignments }
}
antlr_rust::tid!{PropertyAssignmentsContextExt<'a>}

impl<'input> PropertyAssignmentsContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyAssignmentsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyAssignmentsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyAssignmentsContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PropertyAssignmentsContextExt<'input>>{

fn property_all(&self) ->  Vec<Rc<PropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn property(&self, i: usize) -> Option<Rc<PropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PropertyAssignmentsContextAttrs<'input> for PropertyAssignmentsContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyAssignments(&mut self,)
	-> Result<Rc<PropertyAssignmentsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyAssignmentsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 156, RULE_propertyAssignments);
        let mut _localctx: Rc<PropertyAssignmentsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule property*/
			recog.base.set_state(1908);
			recog.property()?;

			recog.base.set_state(1913);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(225,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1909);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule property*/
					recog.base.set_state(1910);
					recog.property()?;

					}
					} 
				}
				recog.base.set_state(1915);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(225,&mut recog.base)?;
			}
			recog.base.set_state(1917);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(1916);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,PropertyAssignmentsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- property ----------------
#[derive(Debug)]
pub enum PropertyContextAll<'input>{
	DefaultPropertyContext(DefaultPropertyContext<'input>),
	NestedPropertyContext(NestedPropertyContext<'input>),
Error(PropertyContext<'input>)
}
antlr_rust::tid!{PropertyContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PropertyContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PropertyContextAll<'input>{}

impl<'input> Deref for PropertyContextAll<'input>{
	type Target = dyn PropertyContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PropertyContextAll::*;
		match self{
			DefaultPropertyContext(inner) => inner,
			NestedPropertyContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PropertyContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PropertyContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PropertyContext<'input> = BaseParserRuleContext<'input,PropertyContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PropertyContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PropertyContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PropertyContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}
antlr_rust::tid!{PropertyContextExt<'a>}

impl<'input> PropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyContextAll<'input>> {
		Rc::new(
		PropertyContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PropertyContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PropertyContextExt<'input>>{


}

impl<'input> PropertyContextAttrs<'input> for PropertyContext<'input>{}

pub type DefaultPropertyContext<'input> = BaseParserRuleContext<'input,DefaultPropertyContextExt<'input>>;

pub trait DefaultPropertyContextAttrs<'input>: DatabricksParserContext<'input>{
	fn propertyKey(&self) -> Option<Rc<PropertyKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn propertyValue(&self) -> Option<Rc<PropertyValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DefaultPropertyContextAttrs<'input> for DefaultPropertyContext<'input>{}

pub struct DefaultPropertyContextExt<'input>{
	base:PropertyContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultPropertyContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DefaultPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DefaultPropertyContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultProperty(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_defaultProperty(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DefaultPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_defaultProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}

impl<'input> Borrow<PropertyContextExt<'input>> for DefaultPropertyContext<'input>{
	fn borrow(&self) -> &PropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyContextExt<'input>> for DefaultPropertyContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyContextExt<'input> { &mut self.base }
}

impl<'input> PropertyContextAttrs<'input> for DefaultPropertyContext<'input> {}

impl<'input> DefaultPropertyContextExt<'input>{
	fn new(ctx: &dyn PropertyContextAttrs<'input>) -> Rc<PropertyContextAll<'input>>  {
		Rc::new(
			PropertyContextAll::DefaultPropertyContext(
				BaseParserRuleContext::copy_from(ctx,DefaultPropertyContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NestedPropertyContext<'input> = BaseParserRuleContext<'input,NestedPropertyContextExt<'input>>;

pub trait NestedPropertyContextAttrs<'input>: DatabricksParserContext<'input>{
	fn propertyKey(&self) -> Option<Rc<PropertyKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn property_all(&self) ->  Vec<Rc<PropertyContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn property(&self, i: usize) -> Option<Rc<PropertyContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> NestedPropertyContextAttrs<'input> for NestedPropertyContext<'input>{}

pub struct NestedPropertyContextExt<'input>{
	base:PropertyContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NestedPropertyContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for NestedPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NestedPropertyContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nestedProperty(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_nestedProperty(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NestedPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_nestedProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for NestedPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}

impl<'input> Borrow<PropertyContextExt<'input>> for NestedPropertyContext<'input>{
	fn borrow(&self) -> &PropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyContextExt<'input>> for NestedPropertyContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyContextExt<'input> { &mut self.base }
}

impl<'input> PropertyContextAttrs<'input> for NestedPropertyContext<'input> {}

impl<'input> NestedPropertyContextExt<'input>{
	fn new(ctx: &dyn PropertyContextAttrs<'input>) -> Rc<PropertyContextAll<'input>>  {
		Rc::new(
			PropertyContextAll::NestedPropertyContext(
				BaseParserRuleContext::copy_from(ctx,NestedPropertyContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn property(&mut self,)
	-> Result<Rc<PropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 158, RULE_property);
        let mut _localctx: Rc<PropertyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1934);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(228,&mut recog.base)? {
				1 =>{
					let tmp = NestedPropertyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule propertyKey*/
					recog.base.set_state(1919);
					recog.propertyKey()?;

					recog.base.set_state(1920);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					recog.base.set_state(1921);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(1925);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while ((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)))) != 0) {
						{
						{
						/*InvokeRule property*/
						recog.base.set_state(1922);
						recog.property()?;

						}
						}
						recog.base.set_state(1927);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1928);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = DefaultPropertyContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule propertyKey*/
					recog.base.set_state(1930);
					recog.propertyKey()?;

					recog.base.set_state(1931);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule propertyValue*/
					recog.base.set_state(1932);
					recog.propertyValue()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyKey ----------------
pub type PropertyKeyContextAll<'input> = PropertyKeyContext<'input>;


pub type PropertyKeyContext<'input> = BaseParserRuleContext<'input,PropertyKeyContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyKeyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PropertyKeyContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PropertyKeyContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyKey(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_propertyKey(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PropertyKeyContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_propertyKey(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyKeyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyKey }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyKey }
}
antlr_rust::tid!{PropertyKeyContextExt<'a>}

impl<'input> PropertyKeyContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyKeyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyKeyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyKeyContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PropertyKeyContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertyKeyContextAttrs<'input> for PropertyKeyContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyKey(&mut self,)
	-> Result<Rc<PropertyKeyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyKeyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 160, RULE_propertyKey);
        let mut _localctx: Rc<PropertyKeyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1938);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
			 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
			 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
			 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
			 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
			 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
			 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
			 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
			 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
			 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
			 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
			 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
			 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
			 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT | EXTENDED |
			 EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT | FIRST |
			 FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM | FROM_JSON |
			 FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT | GROUP | GROUPING |
			 HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY | IF | IGNORE | IMMEDIATE |
			 IMPORT | IN | INCLUDE | INDEX | INDEXES | INNER | INPATH | INPUT | INPUTFORMAT |
			 INSERT | INTERSECT | INTERVAL | INT | INTEGER | INTO | INVOKER | IS |
			 ITEMS | ILIKE | JOIN | KEY | KEYS | LANGUAGE | LAST | LATERAL | LAZY |
			 LEADING | LEFT | LIKE | LIMIT | LINES | LIST | LISTAGG | LIVE | LOAD |
			 LOCAL | LOCATION | LOCK | LOCKS | LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES |
			 MATCHED | MATERIALIZED | MERGE | MICROSECOND | MICROSECONDS | MILLISECOND |
			 MILLISECONDS | MINUS_KW | MINUTE | MINUTES | MODE | MODIFIES | MONTH |
			 MONTHS | MSCK | NAME | NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND |
			 NANOSECONDS | NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF |
			 OFFSET | ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT |
			 OUTER | OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
			 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
			 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
			 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL | RECORDREADER |
			 RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP | REFERENCE | REFERENCES |
			 REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE | RESET | RESPECT |
			 RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE | ROLE | ROLES |
			 ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES | SESSION_USER |
			 SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT | SOME | SORT |
			 SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS | STORED | STRATIFY |
			 STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING | SYNC | SYSTEM_TIME |
			 SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE | TARGET | TBLPROPERTIES |
			 TEMP | TEMPORARY | TERMINATED | STRING_KW | THEN | TIME | TIMEDIFF |
			 TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF | TIMESTAMP_LTZ | TIMESTAMP_NTZ |
			 TINYINT | TO | TOUCH | TRAILING | TRANSACTION | TRANSACTIONS | TRANSFORM |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE | UNARCHIVE | UNBOUNDED | UNCACHE |
			 UNION | UNIQUE | UNKNOWN | UNLOCK | UNPIVOT | UNSET | UPDATE | USE |
			 USER | USING | VALUES | VAR | VARCHAR | VARIANT | VERSION | VIEW | VIEWS |
			 VOID | WEEK | WEEKS | WHEN | WHERE | WHILE | WINDOW | WITH | WITHIN |
			 YEAR | YEARS | ZONE | IDENTIFIER | BACKQUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(1936);
					recog.qualifiedName()?;

					}
				}

			 STRING | DOUBLEQUOTED_STRING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule string*/
					recog.base.set_state(1937);
					recog.string()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyValue ----------------
#[derive(Debug)]
pub enum PropertyValueContextAll<'input>{
	ExpressionPropertyValueContext(ExpressionPropertyValueContext<'input>),
	DefaultPropertyValueContext(DefaultPropertyValueContext<'input>),
	IdentifierPropertyValueContext(IdentifierPropertyValueContext<'input>),
Error(PropertyValueContext<'input>)
}
antlr_rust::tid!{PropertyValueContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PropertyValueContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PropertyValueContextAll<'input>{}

impl<'input> Deref for PropertyValueContextAll<'input>{
	type Target = dyn PropertyValueContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PropertyValueContextAll::*;
		match self{
			ExpressionPropertyValueContext(inner) => inner,
			DefaultPropertyValueContext(inner) => inner,
			IdentifierPropertyValueContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PropertyValueContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PropertyValueContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PropertyValueContext<'input> = BaseParserRuleContext<'input,PropertyValueContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PropertyValueContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PropertyValueContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}
antlr_rust::tid!{PropertyValueContextExt<'a>}

impl<'input> PropertyValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyValueContextAll<'input>> {
		Rc::new(
		PropertyValueContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyValueContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PropertyValueContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PropertyValueContextExt<'input>>{


}

impl<'input> PropertyValueContextAttrs<'input> for PropertyValueContext<'input>{}

pub type ExpressionPropertyValueContext<'input> = BaseParserRuleContext<'input,ExpressionPropertyValueContextExt<'input>>;

pub trait ExpressionPropertyValueContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExpressionPropertyValueContextAttrs<'input> for ExpressionPropertyValueContext<'input>{}

pub struct ExpressionPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExpressionPropertyValueContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ExpressionPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExpressionPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_expressionPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_expressionPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExpressionPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_expressionPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for ExpressionPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for ExpressionPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for ExpressionPropertyValueContext<'input> {}

impl<'input> ExpressionPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::ExpressionPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,ExpressionPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DefaultPropertyValueContext<'input> = BaseParserRuleContext<'input,DefaultPropertyValueContextExt<'input>>;

pub trait DefaultPropertyValueContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DEFAULT
	/// Returns `None` if there is no child corresponding to token DEFAULT
	fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DEFAULT, 0)
	}
}

impl<'input> DefaultPropertyValueContextAttrs<'input> for DefaultPropertyValueContext<'input>{}

pub struct DefaultPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultPropertyValueContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DefaultPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DefaultPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_defaultPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DefaultPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_defaultPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for DefaultPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for DefaultPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for DefaultPropertyValueContext<'input> {}

impl<'input> DefaultPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::DefaultPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,DefaultPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IdentifierPropertyValueContext<'input> = BaseParserRuleContext<'input,IdentifierPropertyValueContextExt<'input>>;

pub trait IdentifierPropertyValueContextAttrs<'input>: DatabricksParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IdentifierPropertyValueContextAttrs<'input> for IdentifierPropertyValueContext<'input>{}

pub struct IdentifierPropertyValueContextExt<'input>{
	base:PropertyValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IdentifierPropertyValueContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for IdentifierPropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentifierPropertyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_identifierPropertyValue(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_identifierPropertyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentifierPropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_identifierPropertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierPropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}

impl<'input> Borrow<PropertyValueContextExt<'input>> for IdentifierPropertyValueContext<'input>{
	fn borrow(&self) -> &PropertyValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyValueContextExt<'input>> for IdentifierPropertyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyValueContextExt<'input> { &mut self.base }
}

impl<'input> PropertyValueContextAttrs<'input> for IdentifierPropertyValueContext<'input> {}

impl<'input> IdentifierPropertyValueContextExt<'input>{
	fn new(ctx: &dyn PropertyValueContextAttrs<'input>) -> Rc<PropertyValueContextAll<'input>>  {
		Rc::new(
			PropertyValueContextAll::IdentifierPropertyValueContext(
				BaseParserRuleContext::copy_from(ctx,IdentifierPropertyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyValue(&mut self,)
	-> Result<Rc<PropertyValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 162, RULE_propertyValue);
        let mut _localctx: Rc<PropertyValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1943);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(230,&mut recog.base)? {
				1 =>{
					let tmp = DefaultPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1940);
					recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = IdentifierPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(1941);
					recog.identifier()?;

					}
				}
			,
				3 =>{
					let tmp = ExpressionPropertyValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(1942);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryNoWith ----------------
pub type QueryNoWithContextAll<'input> = QueryNoWithContext<'input>;


pub type QueryNoWithContext<'input> = BaseParserRuleContext<'input,QueryNoWithContextExt<'input>>;

#[derive(Clone)]
pub struct QueryNoWithContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QueryNoWithContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryNoWithContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryNoWith(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_queryNoWith(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryNoWithContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_queryNoWith(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryNoWithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryNoWith }
}
antlr_rust::tid!{QueryNoWithContextExt<'a>}

impl<'input> QueryNoWithContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryNoWithContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryNoWithContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryNoWithContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QueryNoWithContextExt<'input>>{

fn queryLimit(&self) -> Option<Rc<QueryLimitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryNoWithContextAttrs<'input> for QueryNoWithContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryNoWith(&mut self,)
	-> Result<Rc<QueryNoWithContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryNoWithContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 164, RULE_queryNoWith);
        let mut _localctx: Rc<QueryNoWithContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryLimit*/
			recog.base.set_state(1945);
			recog.queryLimit()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryLimit ----------------
pub type QueryLimitContextAll<'input> = QueryLimitContext<'input>;


pub type QueryLimitContext<'input> = BaseParserRuleContext<'input,QueryLimitContextExt<'input>>;

#[derive(Clone)]
pub struct QueryLimitContextExt<'input>{
	pub limit: Option<Rc<LimitRowCountContextAll<'input>>>,
	pub offset: Option<Rc<RowCountContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QueryLimitContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryLimitContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryLimit(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_queryLimit(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryLimitContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_queryLimit(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryLimitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimit }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimit }
}
antlr_rust::tid!{QueryLimitContextExt<'a>}

impl<'input> QueryLimitContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryLimitContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryLimitContextExt{
				limit: None, offset: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryLimitContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QueryLimitContextExt<'input>>{

fn queryLimitTarget(&self) -> Option<Rc<QueryLimitTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
fn rowCount(&self) -> Option<Rc<RowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
fn limitRowCount(&self) -> Option<Rc<LimitRowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryLimitContextAttrs<'input> for QueryLimitContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryLimit(&mut self,)
	-> Result<Rc<QueryLimitContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryLimitContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 166, RULE_queryLimit);
        let mut _localctx: Rc<QueryLimitContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryLimitTarget*/
			recog.base.set_state(1947);
			recog.queryLimitTarget()?;

			recog.base.set_state(1953);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LIMIT {
				{
				recog.base.set_state(1948);
				recog.base.match_token(LIMIT,&mut recog.err_handler)?;

				recog.base.set_state(1951);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(231,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(1949);
						recog.base.match_token(ALL,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule limitRowCount*/
						recog.base.set_state(1950);
						let tmp = recog.limitRowCount()?;
						 cast_mut::<_,QueryLimitContext >(&mut _localctx).limit = Some(tmp.clone());
						  

						}
					}

					_ => {}
				}
				}
			}

			recog.base.set_state(1957);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==OFFSET {
				{
				recog.base.set_state(1955);
				recog.base.match_token(OFFSET,&mut recog.err_handler)?;

				/*InvokeRule rowCount*/
				recog.base.set_state(1956);
				let tmp = recog.rowCount()?;
				 cast_mut::<_,QueryLimitContext >(&mut _localctx).offset = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryLimitTarget ----------------
#[derive(Debug)]
pub enum QueryLimitTargetContextAll<'input>{
	QueryLimitTargetDatabricksContext(QueryLimitTargetDatabricksContext<'input>),
Error(QueryLimitTargetContext<'input>)
}
antlr_rust::tid!{QueryLimitTargetContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QueryLimitTargetContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for QueryLimitTargetContextAll<'input>{}

impl<'input> Deref for QueryLimitTargetContextAll<'input>{
	type Target = dyn QueryLimitTargetContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QueryLimitTargetContextAll::*;
		match self{
			QueryLimitTargetDatabricksContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryLimitTargetContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryLimitTargetContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QueryLimitTargetContext<'input> = BaseParserRuleContext<'input,QueryLimitTargetContextExt<'input>>;

#[derive(Clone)]
pub struct QueryLimitTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QueryLimitTargetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryLimitTargetContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryLimitTargetContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QueryLimitTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimitTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimitTarget }
}
antlr_rust::tid!{QueryLimitTargetContextExt<'a>}

impl<'input> QueryLimitTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryLimitTargetContextAll<'input>> {
		Rc::new(
		QueryLimitTargetContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryLimitTargetContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QueryLimitTargetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QueryLimitTargetContextExt<'input>>{


}

impl<'input> QueryLimitTargetContextAttrs<'input> for QueryLimitTargetContext<'input>{}

pub type QueryLimitTargetDatabricksContext<'input> = BaseParserRuleContext<'input,QueryLimitTargetDatabricksContextExt<'input>>;

pub trait QueryLimitTargetDatabricksContextAttrs<'input>: DatabricksParserContext<'input>{
	fn queryTerm(&self) -> Option<Rc<QueryTermContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn orderBy(&self) -> Option<Rc<OrderByContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token CLUSTER
	/// Returns `None` if there is no child corresponding to token CLUSTER
	fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CLUSTER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	/// Retrieves first TerminalNode corresponding to token DISTRIBUTE
	/// Returns `None` if there is no child corresponding to token DISTRIBUTE
	fn DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DISTRIBUTE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SORT
	/// Returns `None` if there is no child corresponding to token SORT
	fn SORT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SORT, 0)
	}
	fn windowClause(&self) -> Option<Rc<WindowClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> QueryLimitTargetDatabricksContextAttrs<'input> for QueryLimitTargetDatabricksContext<'input>{}

pub struct QueryLimitTargetDatabricksContextExt<'input>{
	base:QueryLimitTargetContextExt<'input>,
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub clusterBy:Vec<Rc<ExpressionContextAll<'input>>>,
	pub distributeBy:Vec<Rc<ExpressionContextAll<'input>>>,
	pub sortItem: Option<Rc<SortItemContextAll<'input>>>,
	pub sort:Vec<Rc<SortItemContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QueryLimitTargetDatabricksContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for QueryLimitTargetDatabricksContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryLimitTargetDatabricksContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_queryLimitTargetDatabricks(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_queryLimitTargetDatabricks(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryLimitTargetDatabricksContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_queryLimitTargetDatabricks(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryLimitTargetDatabricksContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryLimitTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryLimitTarget }
}

impl<'input> Borrow<QueryLimitTargetContextExt<'input>> for QueryLimitTargetDatabricksContext<'input>{
	fn borrow(&self) -> &QueryLimitTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryLimitTargetContextExt<'input>> for QueryLimitTargetDatabricksContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryLimitTargetContextExt<'input> { &mut self.base }
}

impl<'input> QueryLimitTargetContextAttrs<'input> for QueryLimitTargetDatabricksContext<'input> {}

impl<'input> QueryLimitTargetDatabricksContextExt<'input>{
	fn new(ctx: &dyn QueryLimitTargetContextAttrs<'input>) -> Rc<QueryLimitTargetContextAll<'input>>  {
		Rc::new(
			QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(
				BaseParserRuleContext::copy_from(ctx,QueryLimitTargetDatabricksContextExt{
        			expression:None, sortItem:None, 
        			clusterBy:Vec::new(), distributeBy:Vec::new(), sort:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryLimitTarget(&mut self,)
	-> Result<Rc<QueryLimitTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryLimitTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 168, RULE_queryLimitTarget);
        let mut _localctx: Rc<QueryLimitTargetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = QueryLimitTargetDatabricksContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule queryTerm*/
			recog.base.set_state(1959);
			recog.queryTerm()?;

			recog.base.set_state(1961);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				/*InvokeRule orderBy*/
				recog.base.set_state(1960);
				recog.orderBy()?;

				}
			}

			recog.base.set_state(1973);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==CLUSTER {
				{
				recog.base.set_state(1963);
				recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

				recog.base.set_state(1964);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(1965);
				let tmp = recog.expression()?;
				if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

				let temp = if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
				if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.clusterBy.push(temp); } else {unreachable!("cant cast");}  
				recog.base.set_state(1970);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1966);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1967);
					let tmp = recog.expression()?;
					if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.clusterBy.push(temp); } else {unreachable!("cant cast");}  
					}
					}
					recog.base.set_state(1972);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(1985);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DISTRIBUTE {
				{
				recog.base.set_state(1975);
				recog.base.match_token(DISTRIBUTE,&mut recog.err_handler)?;

				recog.base.set_state(1976);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(1977);
				let tmp = recog.expression()?;
				if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

				let temp = if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
				if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.distributeBy.push(temp); } else {unreachable!("cant cast");}  
				recog.base.set_state(1982);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1978);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(1979);
					let tmp = recog.expression()?;
					if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.distributeBy.push(temp); } else {unreachable!("cant cast");}  
					}
					}
					recog.base.set_state(1984);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(1997);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SORT {
				{
				recog.base.set_state(1987);
				recog.base.match_token(SORT,&mut recog.err_handler)?;

				recog.base.set_state(1988);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule sortItem*/
				recog.base.set_state(1989);
				let tmp = recog.sortItem()?;
				if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.sortItem = Some(tmp.clone()); } else {unreachable!("cant cast");}  

				let temp = if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.sortItem.clone().unwrap() } else {unreachable!("cant cast");} ;
				if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
				ctx.sort.push(temp); } else {unreachable!("cant cast");}  
				recog.base.set_state(1994);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1990);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(1991);
					let tmp = recog.sortItem()?;
					if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.sortItem = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.sortItem.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let QueryLimitTargetContextAll::QueryLimitTargetDatabricksContext(ctx) = cast_mut::<_,QueryLimitTargetContextAll >(&mut _localctx){
					ctx.sort.push(temp); } else {unreachable!("cant cast");}  
					}
					}
					recog.base.set_state(1996);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(2000);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WINDOW {
				{
				/*InvokeRule windowClause*/
				recog.base.set_state(1999);
				recog.windowClause()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowClause ----------------
pub type WindowClauseContextAll<'input> = WindowClauseContext<'input>;


pub type WindowClauseContext<'input> = BaseParserRuleContext<'input,WindowClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WindowClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for WindowClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for WindowClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_windowClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for WindowClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_windowClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowClause }
}
antlr_rust::tid!{WindowClauseContextExt<'a>}

impl<'input> WindowClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<WindowClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
fn windowDefinition_all(&self) ->  Vec<Rc<WindowDefinitionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn windowDefinition(&self, i: usize) -> Option<Rc<WindowDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WindowClauseContextAttrs<'input> for WindowClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowClause(&mut self,)
	-> Result<Rc<WindowClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 170, RULE_windowClause);
        let mut _localctx: Rc<WindowClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2002);
			recog.base.match_token(WINDOW,&mut recog.err_handler)?;

			/*InvokeRule windowDefinition*/
			recog.base.set_state(2003);
			recog.windowDefinition()?;

			recog.base.set_state(2008);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2004);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule windowDefinition*/
				recog.base.set_state(2005);
				recog.windowDefinition()?;

				}
				}
				recog.base.set_state(2010);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- limitRowCount ----------------
pub type LimitRowCountContextAll<'input> = LimitRowCountContext<'input>;


pub type LimitRowCountContext<'input> = BaseParserRuleContext<'input,LimitRowCountContextExt<'input>>;

#[derive(Clone)]
pub struct LimitRowCountContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for LimitRowCountContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LimitRowCountContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_limitRowCount(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_limitRowCount(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LimitRowCountContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_limitRowCount(self);
	}
}

impl<'input> CustomRuleContext<'input> for LimitRowCountContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_limitRowCount }
	//fn type_rule_index() -> usize where Self: Sized { RULE_limitRowCount }
}
antlr_rust::tid!{LimitRowCountContextExt<'a>}

impl<'input> LimitRowCountContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LimitRowCountContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LimitRowCountContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LimitRowCountContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<LimitRowCountContextExt<'input>>{

fn rowCount(&self) -> Option<Rc<RowCountContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LimitRowCountContextAttrs<'input> for LimitRowCountContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn limitRowCount(&mut self,)
	-> Result<Rc<LimitRowCountContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LimitRowCountContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 172, RULE_limitRowCount);
        let mut _localctx: Rc<LimitRowCountContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule rowCount*/
			recog.base.set_state(2011);
			recog.rowCount()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowCount ----------------
pub type RowCountContextAll<'input> = RowCountContext<'input>;


pub type RowCountContext<'input> = BaseParserRuleContext<'input,RowCountContextExt<'input>>;

#[derive(Clone)]
pub struct RowCountContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for RowCountContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RowCountContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowCount(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_rowCount(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RowCountContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rowCount(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowCountContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowCount }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowCount }
}
antlr_rust::tid!{RowCountContextExt<'a>}

impl<'input> RowCountContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowCountContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowCountContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowCountContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<RowCountContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RowCountContextAttrs<'input> for RowCountContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowCount(&mut self,)
	-> Result<Rc<RowCountContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowCountContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 174, RULE_rowCount);
        let mut _localctx: Rc<RowCountContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(2013);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryTerm ----------------
pub type QueryTermContextAll<'input> = QueryTermContext<'input>;


pub type QueryTermContext<'input> = BaseParserRuleContext<'input,QueryTermContextExt<'input>>;

#[derive(Clone)]
pub struct QueryTermContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QueryTermContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryTermContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryTerm(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_queryTerm(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryTermContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_queryTerm(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryTermContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryTerm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryTerm }
}
antlr_rust::tid!{QueryTermContextExt<'a>}

impl<'input> QueryTermContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryTermContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryTermContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryTermContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QueryTermContextExt<'input>>{

fn setOperation(&self) -> Option<Rc<SetOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryTermContextAttrs<'input> for QueryTermContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryTerm(&mut self,)
	-> Result<Rc<QueryTermContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryTermContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 176, RULE_queryTerm);
        let mut _localctx: Rc<QueryTermContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule setOperation*/
			recog.base.set_state(2015);
			recog.setOperation()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperation ----------------
pub type SetOperationContextAll<'input> = SetOperationContext<'input>;


pub type SetOperationContext<'input> = BaseParserRuleContext<'input,SetOperationContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperationContextExt<'input>{
	pub left: Option<Rc<SetOperationIntersectContextAll<'input>>>,
	pub setOperationIntersect: Option<Rc<SetOperationIntersectContextAll<'input>>>,
	pub right:Vec<Rc<SetOperationIntersectContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SetOperationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperation(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_setOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperation }
}
antlr_rust::tid!{SetOperationContextExt<'a>}

impl<'input> SetOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperationContextExt{
				left: None, setOperationIntersect: None, 
				right: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SetOperationContextExt<'input>>{

fn setOperationIntersect_all(&self) ->  Vec<Rc<SetOperationIntersectContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setOperationIntersect(&self, i: usize) -> Option<Rc<SetOperationIntersectContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setOperator_all(&self) ->  Vec<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setOperator(&self, i: usize) -> Option<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SetOperationContextAttrs<'input> for SetOperationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperation(&mut self,)
	-> Result<Rc<SetOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 178, RULE_setOperation);
        let mut _localctx: Rc<SetOperationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule setOperationIntersect*/
			recog.base.set_state(2017);
			let tmp = recog.setOperationIntersect()?;
			 cast_mut::<_,SetOperationContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(2023);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==EXCEPT || _la==MINUS_KW || _la==UNION {
				{
				{
				/*InvokeRule setOperator*/
				recog.base.set_state(2018);
				recog.setOperator()?;

				/*InvokeRule setOperationIntersect*/
				recog.base.set_state(2019);
				let tmp = recog.setOperationIntersect()?;
				 cast_mut::<_,SetOperationContext >(&mut _localctx).setOperationIntersect = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SetOperationContext >(&mut _localctx).setOperationIntersect.clone().unwrap()
				 ;
				 cast_mut::<_,SetOperationContext >(&mut _localctx).right.push(temp);
				  
				}
				}
				recog.base.set_state(2025);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperator ----------------
pub type SetOperatorContextAll<'input> = SetOperatorContext<'input>;


pub type SetOperatorContext<'input> = BaseParserRuleContext<'input,SetOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SetOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperator(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_setOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperator }
}
antlr_rust::tid!{SetOperatorContextExt<'a>}

impl<'input> SetOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperatorContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SetOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS_KW
/// Returns `None` if there is no child corresponding to token MINUS_KW
fn MINUS_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MINUS_KW, 0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetOperatorContextAttrs<'input> for SetOperatorContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperator(&mut self,)
	-> Result<Rc<SetOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 180, RULE_setOperator);
        let mut _localctx: Rc<SetOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2026);
			_la = recog.base.input.la(1);
			if { !(_la==EXCEPT || _la==MINUS_KW || _la==UNION) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2028);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ALL || _la==DISTINCT {
				{
				/*InvokeRule setQuantifier*/
				recog.base.set_state(2027);
				recog.setQuantifier()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperationIntersect ----------------
pub type SetOperationIntersectContextAll<'input> = SetOperationIntersectContext<'input>;


pub type SetOperationIntersectContext<'input> = BaseParserRuleContext<'input,SetOperationIntersectContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperationIntersectContextExt<'input>{
	pub left: Option<Rc<QueryPrimaryContextAll<'input>>>,
	pub queryPrimary: Option<Rc<QueryPrimaryContextAll<'input>>>,
	pub right:Vec<Rc<QueryPrimaryContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SetOperationIntersectContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetOperationIntersectContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperationIntersect(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_setOperationIntersect(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetOperationIntersectContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setOperationIntersect(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperationIntersectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperationIntersect }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperationIntersect }
}
antlr_rust::tid!{SetOperationIntersectContextExt<'a>}

impl<'input> SetOperationIntersectContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperationIntersectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperationIntersectContextExt{
				left: None, queryPrimary: None, 
				right: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperationIntersectContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SetOperationIntersectContextExt<'input>>{

fn queryPrimary_all(&self) ->  Vec<Rc<QueryPrimaryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn queryPrimary(&self, i: usize) -> Option<Rc<QueryPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setIntersectOperator_all(&self) ->  Vec<Rc<SetIntersectOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setIntersectOperator(&self, i: usize) -> Option<Rc<SetIntersectOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SetOperationIntersectContextAttrs<'input> for SetOperationIntersectContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperationIntersect(&mut self,)
	-> Result<Rc<SetOperationIntersectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperationIntersectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 182, RULE_setOperationIntersect);
        let mut _localctx: Rc<SetOperationIntersectContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule queryPrimary*/
			recog.base.set_state(2030);
			let tmp = recog.queryPrimary()?;
			 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(2036);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==INTERSECT {
				{
				{
				/*InvokeRule setIntersectOperator*/
				recog.base.set_state(2031);
				recog.setIntersectOperator()?;

				/*InvokeRule queryPrimary*/
				recog.base.set_state(2032);
				let tmp = recog.queryPrimary()?;
				 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).queryPrimary = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).queryPrimary.clone().unwrap()
				 ;
				 cast_mut::<_,SetOperationIntersectContext >(&mut _localctx).right.push(temp);
				  
				}
				}
				recog.base.set_state(2038);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setIntersectOperator ----------------
pub type SetIntersectOperatorContextAll<'input> = SetIntersectOperatorContext<'input>;


pub type SetIntersectOperatorContext<'input> = BaseParserRuleContext<'input,SetIntersectOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SetIntersectOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SetIntersectOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetIntersectOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setIntersectOperator(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_setIntersectOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetIntersectOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setIntersectOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetIntersectOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setIntersectOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setIntersectOperator }
}
antlr_rust::tid!{SetIntersectOperatorContextExt<'a>}

impl<'input> SetIntersectOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetIntersectOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetIntersectOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetIntersectOperatorContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SetIntersectOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetIntersectOperatorContextAttrs<'input> for SetIntersectOperatorContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setIntersectOperator(&mut self,)
	-> Result<Rc<SetIntersectOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetIntersectOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 184, RULE_setIntersectOperator);
        let mut _localctx: Rc<SetIntersectOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2039);
			recog.base.match_token(INTERSECT,&mut recog.err_handler)?;

			recog.base.set_state(2041);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ALL || _la==DISTINCT {
				{
				/*InvokeRule setQuantifier*/
				recog.base.set_state(2040);
				recog.setQuantifier()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setQuantifier ----------------
pub type SetQuantifierContextAll<'input> = SetQuantifierContext<'input>;


pub type SetQuantifierContext<'input> = BaseParserRuleContext<'input,SetQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct SetQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SetQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SetQuantifierContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setQuantifier(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_setQuantifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SetQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_setQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setQuantifier }
}
antlr_rust::tid!{SetQuantifierContextExt<'a>}

impl<'input> SetQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetQuantifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetQuantifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetQuantifierContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SetQuantifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}

}

impl<'input> SetQuantifierContextAttrs<'input> for SetQuantifierContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setQuantifier(&mut self,)
	-> Result<Rc<SetQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 186, RULE_setQuantifier);
        let mut _localctx: Rc<SetQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2043);
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==DISTINCT) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- inlineTable ----------------
pub type InlineTableContextAll<'input> = InlineTableContext<'input>;


pub type InlineTableContext<'input> = BaseParserRuleContext<'input,InlineTableContextExt<'input>>;

#[derive(Clone)]
pub struct InlineTableContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for InlineTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InlineTableContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_inlineTable(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_inlineTable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InlineTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_inlineTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_inlineTable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_inlineTable }
}
antlr_rust::tid!{InlineTableContextExt<'a>}

impl<'input> InlineTableContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InlineTableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InlineTableContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait InlineTableContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<InlineTableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> InlineTableContextAttrs<'input> for InlineTableContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn inlineTable(&mut self,)
	-> Result<Rc<InlineTableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InlineTableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 188, RULE_inlineTable);
        let mut _localctx: Rc<InlineTableContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2045);
			recog.base.match_token(VALUES,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2046);
			recog.expression()?;

			recog.base.set_state(2051);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(247,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2047);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2048);
					recog.expression()?;

					}
					} 
				}
				recog.base.set_state(2053);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(247,&mut recog.base)?;
			}
			recog.base.set_state(2055);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(248,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2054);
					let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
					 cast_mut::<_,InlineTableContext >(&mut _localctx).tail = Some(tmp);
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryPrimary ----------------
#[derive(Debug)]
pub enum QueryPrimaryContextAll<'input>{
	SubqueryContext(SubqueryContext<'input>),
	QueryPrimaryDefaultContext(QueryPrimaryDefaultContext<'input>),
	InlineTableDefault1Context(InlineTableDefault1Context<'input>),
	TableContext(TableContext<'input>),
Error(QueryPrimaryContext<'input>)
}
antlr_rust::tid!{QueryPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QueryPrimaryContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for QueryPrimaryContextAll<'input>{}

impl<'input> Deref for QueryPrimaryContextAll<'input>{
	type Target = dyn QueryPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QueryPrimaryContextAll::*;
		match self{
			SubqueryContext(inner) => inner,
			QueryPrimaryDefaultContext(inner) => inner,
			InlineTableDefault1Context(inner) => inner,
			TableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QueryPrimaryContext<'input> = BaseParserRuleContext<'input,QueryPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QueryPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QueryPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}
antlr_rust::tid!{QueryPrimaryContextExt<'a>}

impl<'input> QueryPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryPrimaryContextAll<'input>> {
		Rc::new(
		QueryPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QueryPrimaryContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QueryPrimaryContextExt<'input>>{


}

impl<'input> QueryPrimaryContextAttrs<'input> for QueryPrimaryContext<'input>{}

pub type SubqueryContext<'input> = BaseParserRuleContext<'input,SubqueryContextExt<'input>>;

pub trait SubqueryContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SubqueryContextAttrs<'input> for SubqueryContext<'input>{}

pub struct SubqueryContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	pub query_: Option<Rc<QueryContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SubqueryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SubqueryContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subquery(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_subquery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SubqueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_subquery(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for SubqueryContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for SubqueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for SubqueryContext<'input> {}

impl<'input> SubqueryContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::SubqueryContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryContextExt{
        			query_:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QueryPrimaryDefaultContext<'input> = BaseParserRuleContext<'input,QueryPrimaryDefaultContextExt<'input>>;

pub trait QueryPrimaryDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn querySpecification(&self) -> Option<Rc<QuerySpecificationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QueryPrimaryDefaultContextAttrs<'input> for QueryPrimaryDefaultContext<'input>{}

pub struct QueryPrimaryDefaultContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QueryPrimaryDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for QueryPrimaryDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryPrimaryDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_queryPrimaryDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_queryPrimaryDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryPrimaryDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_queryPrimaryDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryPrimaryDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for QueryPrimaryDefaultContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for QueryPrimaryDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for QueryPrimaryDefaultContext<'input> {}

impl<'input> QueryPrimaryDefaultContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::QueryPrimaryDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QueryPrimaryDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InlineTableDefault1Context<'input> = BaseParserRuleContext<'input,InlineTableDefault1ContextExt<'input>>;

pub trait InlineTableDefault1ContextAttrs<'input>: DatabricksParserContext<'input>{
	fn inlineTable(&self) -> Option<Rc<InlineTableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InlineTableDefault1ContextAttrs<'input> for InlineTableDefault1Context<'input>{}

pub struct InlineTableDefault1ContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InlineTableDefault1ContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InlineTableDefault1Context<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InlineTableDefault1Context<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inlineTableDefault1(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_inlineTableDefault1(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InlineTableDefault1Context<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_inlineTableDefault1(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableDefault1ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for InlineTableDefault1Context<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for InlineTableDefault1Context<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for InlineTableDefault1Context<'input> {}

impl<'input> InlineTableDefault1ContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::InlineTableDefault1Context(
				BaseParserRuleContext::copy_from(ctx,InlineTableDefault1ContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableContext<'input> = BaseParserRuleContext<'input,TableContextExt<'input>>;

pub trait TableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn pathExpression(&self) -> Option<Rc<PathExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableContextAttrs<'input> for TableContext<'input>{}

pub struct TableContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_table(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_table(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_table(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for TableContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for TableContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for TableContext<'input> {}

impl<'input> TableContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::TableContext(
				BaseParserRuleContext::copy_from(ctx,TableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryPrimary(&mut self,)
	-> Result<Rc<QueryPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 190, RULE_queryPrimary);
        let mut _localctx: Rc<QueryPrimaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2065);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 SELECT 
				=> {
					let tmp = QueryPrimaryDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule querySpecification*/
					recog.base.set_state(2057);
					recog.querySpecification()?;

					}
				}

			 TABLE 
				=> {
					let tmp = TableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2058);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule pathExpression*/
					recog.base.set_state(2059);
					recog.pathExpression()?;

					}
				}

			 VALUES 
				=> {
					let tmp = InlineTableDefault1ContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule inlineTable*/
					recog.base.set_state(2060);
					recog.inlineTable()?;

					}
				}

			 LPAREN 
				=> {
					let tmp = SubqueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(2061);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2062);
					let tmp = recog.query()?;
					if let QueryPrimaryContextAll::SubqueryContext(ctx) = cast_mut::<_,QueryPrimaryContextAll >(&mut _localctx){
					ctx.query_ = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2063);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sortItem ----------------
pub type SortItemContextAll<'input> = SortItemContext<'input>;


pub type SortItemContext<'input> = BaseParserRuleContext<'input,SortItemContextExt<'input>>;

#[derive(Clone)]
pub struct SortItemContextExt<'input>{
	pub ordering: Option<TokenType<'input>>,
	pub nullOrdering: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SortItemContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SortItemContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sortItem(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_sortItem(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SortItemContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sortItem(self);
	}
}

impl<'input> CustomRuleContext<'input> for SortItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sortItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sortItem }
}
antlr_rust::tid!{SortItemContextExt<'a>}

impl<'input> SortItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SortItemContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SortItemContextExt{
				ordering: None, nullOrdering: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SortItemContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SortItemContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}

}

impl<'input> SortItemContextAttrs<'input> for SortItemContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sortItem(&mut self,)
	-> Result<Rc<SortItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SortItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 192, RULE_sortItem);
        let mut _localctx: Rc<SortItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(2067);
			recog.expression()?;

			recog.base.set_state(2069);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASC || _la==DESC {
				{
				recog.base.set_state(2068);
				 cast_mut::<_,SortItemContext >(&mut _localctx).ordering = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==ASC || _la==DESC) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,SortItemContext >(&mut _localctx).ordering = Some(tmp);
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			recog.base.set_state(2073);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==NULLS {
				{
				recog.base.set_state(2071);
				recog.base.match_token(NULLS,&mut recog.err_handler)?;

				recog.base.set_state(2072);
				 cast_mut::<_,SortItemContext >(&mut _localctx).nullOrdering = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==FIRST || _la==LAST) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,SortItemContext >(&mut _localctx).nullOrdering = Some(tmp);
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- querySpecification ----------------
pub type QuerySpecificationContextAll<'input> = QuerySpecificationContext<'input>;


pub type QuerySpecificationContext<'input> = BaseParserRuleContext<'input,QuerySpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct QuerySpecificationContextExt<'input>{
	pub where_: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub having: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub qualify: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QuerySpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QuerySpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_querySpecification(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_querySpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QuerySpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_querySpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuerySpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySpecification }
}
antlr_rust::tid!{QuerySpecificationContextExt<'a>}

impl<'input> QuerySpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuerySpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuerySpecificationContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				where_: None, having: None, qualify: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QuerySpecificationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QuerySpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
fn querySelectItems(&self) -> Option<Rc<QuerySelectItemsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
fn relation(&self) -> Option<Rc<RelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn aggregationClause(&self) -> Option<Rc<AggregationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
/// Retrieves first TerminalNode corresponding to token QUALIFY
/// Returns `None` if there is no child corresponding to token QUALIFY
fn QUALIFY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(QUALIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
fn windowDefinition_all(&self) ->  Vec<Rc<WindowDefinitionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn windowDefinition(&self, i: usize) -> Option<Rc<WindowDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QuerySpecificationContextAttrs<'input> for QuerySpecificationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn querySpecification(&mut self,)
	-> Result<Rc<QuerySpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuerySpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 194, RULE_querySpecification);
        let mut _localctx: Rc<QuerySpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2075);
			recog.base.match_token(SELECT,&mut recog.err_handler)?;

			recog.base.set_state(2077);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(252,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule setQuantifier*/
					recog.base.set_state(2076);
					recog.setQuantifier()?;

					}
				}

				_ => {}
			}
			/*InvokeRule querySelectItems*/
			recog.base.set_state(2079);
			recog.querySelectItems()?;

			recog.base.set_state(2082);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==FROM {
				{
				recog.base.set_state(2080);
				recog.base.match_token(FROM,&mut recog.err_handler)?;

				/*InvokeRule relation*/
				recog.base.set_state(2081);
				recog.relation()?;

				}
			}

			recog.base.set_state(2086);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WHERE {
				{
				recog.base.set_state(2084);
				recog.base.match_token(WHERE,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(2085);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).where_ = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2089);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==GROUP {
				{
				/*InvokeRule aggregationClause*/
				recog.base.set_state(2088);
				recog.aggregationClause()?;

				}
			}

			recog.base.set_state(2093);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==HAVING {
				{
				recog.base.set_state(2091);
				recog.base.match_token(HAVING,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(2092);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).having = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2097);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==QUALIFY {
				{
				recog.base.set_state(2095);
				recog.base.match_token(QUALIFY,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(2096);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).qualify = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2111);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(260,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2099);
					recog.base.match_token(WINDOW,&mut recog.err_handler)?;

					/*InvokeRule windowDefinition*/
					recog.base.set_state(2100);
					recog.windowDefinition()?;

					recog.base.set_state(2105);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(258,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2101);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule windowDefinition*/
							recog.base.set_state(2102);
							recog.windowDefinition()?;

							}
							} 
						}
						recog.base.set_state(2107);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(258,&mut recog.base)?;
					}
					recog.base.set_state(2109);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2108);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).COMMA = Some(tmp);
						  

						let temp =  cast_mut::<_,QuerySpecificationContext >(&mut _localctx).COMMA.clone().unwrap()
						 ;
						 cast_mut::<_,QuerySpecificationContext >(&mut _localctx).tail.push(temp);
						  
						}
					}

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- querySelectItems ----------------
pub type QuerySelectItemsContextAll<'input> = QuerySelectItemsContext<'input>;


pub type QuerySelectItemsContext<'input> = BaseParserRuleContext<'input,QuerySelectItemsContextExt<'input>>;

#[derive(Clone)]
pub struct QuerySelectItemsContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QuerySelectItemsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QuerySelectItemsContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_querySelectItems(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_querySelectItems(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QuerySelectItemsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_querySelectItems(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuerySelectItemsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySelectItems }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySelectItems }
}
antlr_rust::tid!{QuerySelectItemsContextExt<'a>}

impl<'input> QuerySelectItemsContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuerySelectItemsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuerySelectItemsContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QuerySelectItemsContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QuerySelectItemsContextExt<'input>>{

fn selectItem_all(&self) ->  Vec<Rc<SelectItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn selectItem(&self, i: usize) -> Option<Rc<SelectItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QuerySelectItemsContextAttrs<'input> for QuerySelectItemsContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn querySelectItems(&mut self,)
	-> Result<Rc<QuerySelectItemsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuerySelectItemsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 196, RULE_querySelectItems);
        let mut _localctx: Rc<QuerySelectItemsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule selectItem*/
			recog.base.set_state(2113);
			recog.selectItem()?;

			recog.base.set_state(2118);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(261,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2114);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule selectItem*/
					recog.base.set_state(2115);
					recog.selectItem()?;

					}
					} 
				}
				recog.base.set_state(2120);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(261,&mut recog.base)?;
			}
			recog.base.set_state(2122);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2121);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,QuerySelectItemsContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aggregationClause ----------------
pub type AggregationClauseContextAll<'input> = AggregationClauseContext<'input>;


pub type AggregationClauseContext<'input> = BaseParserRuleContext<'input,AggregationClauseContextExt<'input>>;

#[derive(Clone)]
pub struct AggregationClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for AggregationClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AggregationClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aggregationClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_aggregationClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AggregationClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_aggregationClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for AggregationClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aggregationClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aggregationClause }
}
antlr_rust::tid!{AggregationClauseContextExt<'a>}

impl<'input> AggregationClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AggregationClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AggregationClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AggregationClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<AggregationClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GROUP
/// Returns `None` if there is no child corresponding to token GROUP
fn GROUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn groupBy(&self) -> Option<Rc<GroupByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AggregationClauseContextAttrs<'input> for AggregationClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aggregationClause(&mut self,)
	-> Result<Rc<AggregationClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AggregationClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 198, RULE_aggregationClause);
        let mut _localctx: Rc<AggregationClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2124);
			recog.base.match_token(GROUP,&mut recog.err_handler)?;

			recog.base.set_state(2125);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule groupBy*/
			recog.base.set_state(2126);
			recog.groupBy()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupBy ----------------
#[derive(Debug)]
pub enum GroupByContextAll<'input>{
	GroupByAllContext(GroupByAllContext<'input>),
	GroupByWithContext(GroupByWithContext<'input>),
	GroupByDefaultContext(GroupByDefaultContext<'input>),
Error(GroupByContext<'input>)
}
antlr_rust::tid!{GroupByContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GroupByContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for GroupByContextAll<'input>{}

impl<'input> Deref for GroupByContextAll<'input>{
	type Target = dyn GroupByContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GroupByContextAll::*;
		match self{
			GroupByAllContext(inner) => inner,
			GroupByWithContext(inner) => inner,
			GroupByDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupByContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupByContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GroupByContext<'input> = BaseParserRuleContext<'input,GroupByContextExt<'input>>;

#[derive(Clone)]
pub struct GroupByContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for GroupByContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupByContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupByContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GroupByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}
antlr_rust::tid!{GroupByContextExt<'a>}

impl<'input> GroupByContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupByContextAll<'input>> {
		Rc::new(
		GroupByContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupByContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GroupByContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<GroupByContextExt<'input>>{


}

impl<'input> GroupByContextAttrs<'input> for GroupByContext<'input>{}

pub type GroupByAllContext<'input> = BaseParserRuleContext<'input,GroupByAllContextExt<'input>>;

pub trait GroupByAllContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALL
	/// Returns `None` if there is no child corresponding to token ALL
	fn ALL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALL, 0)
	}
}

impl<'input> GroupByAllContextAttrs<'input> for GroupByAllContext<'input>{}

pub struct GroupByAllContextExt<'input>{
	base:GroupByContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GroupByAllContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GroupByAllContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupByAllContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_groupByAll(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_groupByAll(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupByAllContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_groupByAll(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupByAllContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}

impl<'input> Borrow<GroupByContextExt<'input>> for GroupByAllContext<'input>{
	fn borrow(&self) -> &GroupByContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupByContextExt<'input>> for GroupByAllContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupByContextExt<'input> { &mut self.base }
}

impl<'input> GroupByContextAttrs<'input> for GroupByAllContext<'input> {}

impl<'input> GroupByAllContextExt<'input>{
	fn new(ctx: &dyn GroupByContextAttrs<'input>) -> Rc<GroupByContextAll<'input>>  {
		Rc::new(
			GroupByContextAll::GroupByAllContext(
				BaseParserRuleContext::copy_from(ctx,GroupByAllContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GroupByWithContext<'input> = BaseParserRuleContext<'input,GroupByWithContextExt<'input>>;

pub trait GroupByWithContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROLLUP
	/// Returns `None` if there is no child corresponding to token ROLLUP
	fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROLLUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CUBE
	/// Returns `None` if there is no child corresponding to token CUBE
	fn CUBE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CUBE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> GroupByWithContextAttrs<'input> for GroupByWithContext<'input>{}

pub struct GroupByWithContextExt<'input>{
	base:GroupByContextExt<'input>,
	pub kind: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GroupByWithContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GroupByWithContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupByWithContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_groupByWith(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_groupByWith(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupByWithContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_groupByWith(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupByWithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}

impl<'input> Borrow<GroupByContextExt<'input>> for GroupByWithContext<'input>{
	fn borrow(&self) -> &GroupByContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupByContextExt<'input>> for GroupByWithContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupByContextExt<'input> { &mut self.base }
}

impl<'input> GroupByContextAttrs<'input> for GroupByWithContext<'input> {}

impl<'input> GroupByWithContextExt<'input>{
	fn new(ctx: &dyn GroupByContextAttrs<'input>) -> Rc<GroupByContextAll<'input>>  {
		Rc::new(
			GroupByContextAll::GroupByWithContext(
				BaseParserRuleContext::copy_from(ctx,GroupByWithContextExt{
					kind:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GroupByDefaultContext<'input> = BaseParserRuleContext<'input,GroupByDefaultContextExt<'input>>;

pub trait GroupByDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn groupingElement_all(&self) ->  Vec<Rc<GroupingElementContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn groupingElement(&self, i: usize) -> Option<Rc<GroupingElementContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> GroupByDefaultContextAttrs<'input> for GroupByDefaultContext<'input>{}

pub struct GroupByDefaultContextExt<'input>{
	base:GroupByContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GroupByDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GroupByDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupByDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_groupByDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_groupByDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupByDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_groupByDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupByDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupBy }
}

impl<'input> Borrow<GroupByContextExt<'input>> for GroupByDefaultContext<'input>{
	fn borrow(&self) -> &GroupByContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupByContextExt<'input>> for GroupByDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupByContextExt<'input> { &mut self.base }
}

impl<'input> GroupByContextAttrs<'input> for GroupByDefaultContext<'input> {}

impl<'input> GroupByDefaultContextExt<'input>{
	fn new(ctx: &dyn GroupByContextAttrs<'input>) -> Rc<GroupByContextAll<'input>>  {
		Rc::new(
			GroupByContextAll::GroupByDefaultContext(
				BaseParserRuleContext::copy_from(ctx,GroupByDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupBy(&mut self,)
	-> Result<Rc<GroupByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 200, RULE_groupBy);
        let mut _localctx: Rc<GroupByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2148);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(265,&mut recog.base)? {
				1 =>{
					let tmp = GroupByAllContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2128);
					recog.base.match_token(ALL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = GroupByDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule groupingElement*/
					recog.base.set_state(2129);
					recog.groupingElement()?;

					recog.base.set_state(2134);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2130);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule groupingElement*/
						recog.base.set_state(2131);
						recog.groupingElement()?;

						}
						}
						recog.base.set_state(2136);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				3 =>{
					let tmp = GroupByWithContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(2137);
					recog.expression()?;

					recog.base.set_state(2142);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2138);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(2139);
						recog.expression()?;

						}
						}
						recog.base.set_state(2144);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2145);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(2146);
					if let GroupByContextAll::GroupByWithContext(ctx) = cast_mut::<_,GroupByContextAll >(&mut _localctx){
					ctx.kind = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==CUBE || _la==ROLLUP) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let GroupByContextAll::GroupByWithContext(ctx) = cast_mut::<_,GroupByContextAll >(&mut _localctx){
						ctx.kind = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingElement ----------------
#[derive(Debug)]
pub enum GroupingElementContextAll<'input>{
	GrpElementAnalyticsContext(GrpElementAnalyticsContext<'input>),
	GrpElementExpressionContext(GrpElementExpressionContext<'input>),
Error(GroupingElementContext<'input>)
}
antlr_rust::tid!{GroupingElementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GroupingElementContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for GroupingElementContextAll<'input>{}

impl<'input> Deref for GroupingElementContextAll<'input>{
	type Target = dyn GroupingElementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GroupingElementContextAll::*;
		match self{
			GrpElementAnalyticsContext(inner) => inner,
			GrpElementExpressionContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupingElementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupingElementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GroupingElementContext<'input> = BaseParserRuleContext<'input,GroupingElementContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for GroupingElementContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupingElementContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupingElementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GroupingElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}
antlr_rust::tid!{GroupingElementContextExt<'a>}

impl<'input> GroupingElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingElementContextAll<'input>> {
		Rc::new(
		GroupingElementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingElementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GroupingElementContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<GroupingElementContextExt<'input>>{


}

impl<'input> GroupingElementContextAttrs<'input> for GroupingElementContext<'input>{}

pub type GrpElementAnalyticsContext<'input> = BaseParserRuleContext<'input,GrpElementAnalyticsContextExt<'input>>;

pub trait GrpElementAnalyticsContextAttrs<'input>: DatabricksParserContext<'input>{
	fn groupingAnalytics(&self) -> Option<Rc<GroupingAnalyticsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> GrpElementAnalyticsContextAttrs<'input> for GrpElementAnalyticsContext<'input>{}

pub struct GrpElementAnalyticsContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrpElementAnalyticsContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GrpElementAnalyticsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrpElementAnalyticsContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grpElementAnalytics(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_grpElementAnalytics(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrpElementAnalyticsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_grpElementAnalytics(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrpElementAnalyticsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for GrpElementAnalyticsContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for GrpElementAnalyticsContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for GrpElementAnalyticsContext<'input> {}

impl<'input> GrpElementAnalyticsContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::GrpElementAnalyticsContext(
				BaseParserRuleContext::copy_from(ctx,GrpElementAnalyticsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GrpElementExpressionContext<'input> = BaseParserRuleContext<'input,GrpElementExpressionContextExt<'input>>;

pub trait GrpElementExpressionContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> GrpElementExpressionContextAttrs<'input> for GrpElementExpressionContext<'input>{}

pub struct GrpElementExpressionContextExt<'input>{
	base:GroupingElementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrpElementExpressionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GrpElementExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrpElementExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grpElementExpression(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_grpElementExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrpElementExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_grpElementExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrpElementExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}

impl<'input> Borrow<GroupingElementContextExt<'input>> for GrpElementExpressionContext<'input>{
	fn borrow(&self) -> &GroupingElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingElementContextExt<'input>> for GrpElementExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingElementContextExt<'input> { &mut self.base }
}

impl<'input> GroupingElementContextAttrs<'input> for GrpElementExpressionContext<'input> {}

impl<'input> GrpElementExpressionContextExt<'input>{
	fn new(ctx: &dyn GroupingElementContextAttrs<'input>) -> Rc<GroupingElementContextAll<'input>>  {
		Rc::new(
			GroupingElementContextAll::GrpElementExpressionContext(
				BaseParserRuleContext::copy_from(ctx,GrpElementExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingElement(&mut self,)
	-> Result<Rc<GroupingElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 202, RULE_groupingElement);
        let mut _localctx: Rc<GroupingElementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2152);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(266,&mut recog.base)? {
				1 =>{
					let tmp = GrpElementAnalyticsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule groupingAnalytics*/
					recog.base.set_state(2150);
					recog.groupingAnalytics()?;

					}
				}
			,
				2 =>{
					let tmp = GrpElementExpressionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(2151);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingAnalytics ----------------
#[derive(Debug)]
pub enum GroupingAnalyticsContextAll<'input>{
	GrpAnalyticsSugarContext(GrpAnalyticsSugarContext<'input>),
	GrpAnalyticsSetsContext(GrpAnalyticsSetsContext<'input>),
Error(GroupingAnalyticsContext<'input>)
}
antlr_rust::tid!{GroupingAnalyticsContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GroupingAnalyticsContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for GroupingAnalyticsContextAll<'input>{}

impl<'input> Deref for GroupingAnalyticsContextAll<'input>{
	type Target = dyn GroupingAnalyticsContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GroupingAnalyticsContextAll::*;
		match self{
			GrpAnalyticsSugarContext(inner) => inner,
			GrpAnalyticsSetsContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupingAnalyticsContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupingAnalyticsContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GroupingAnalyticsContext<'input> = BaseParserRuleContext<'input,GroupingAnalyticsContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingAnalyticsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for GroupingAnalyticsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupingAnalyticsContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupingAnalyticsContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GroupingAnalyticsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingAnalytics }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingAnalytics }
}
antlr_rust::tid!{GroupingAnalyticsContextExt<'a>}

impl<'input> GroupingAnalyticsContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingAnalyticsContextAll<'input>> {
		Rc::new(
		GroupingAnalyticsContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingAnalyticsContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GroupingAnalyticsContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<GroupingAnalyticsContextExt<'input>>{


}

impl<'input> GroupingAnalyticsContextAttrs<'input> for GroupingAnalyticsContext<'input>{}

pub type GrpAnalyticsSugarContext<'input> = BaseParserRuleContext<'input,GrpAnalyticsSugarContextExt<'input>>;

pub trait GrpAnalyticsSugarContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn groupingSet_all(&self) ->  Vec<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn groupingSet(&self, i: usize) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROLLUP
	/// Returns `None` if there is no child corresponding to token ROLLUP
	fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROLLUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CUBE
	/// Returns `None` if there is no child corresponding to token CUBE
	fn CUBE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CUBE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> GrpAnalyticsSugarContextAttrs<'input> for GrpAnalyticsSugarContext<'input>{}

pub struct GrpAnalyticsSugarContextExt<'input>{
	base:GroupingAnalyticsContextExt<'input>,
	pub kind: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrpAnalyticsSugarContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GrpAnalyticsSugarContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrpAnalyticsSugarContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grpAnalyticsSugar(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_grpAnalyticsSugar(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrpAnalyticsSugarContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_grpAnalyticsSugar(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrpAnalyticsSugarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingAnalytics }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingAnalytics }
}

impl<'input> Borrow<GroupingAnalyticsContextExt<'input>> for GrpAnalyticsSugarContext<'input>{
	fn borrow(&self) -> &GroupingAnalyticsContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingAnalyticsContextExt<'input>> for GrpAnalyticsSugarContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingAnalyticsContextExt<'input> { &mut self.base }
}

impl<'input> GroupingAnalyticsContextAttrs<'input> for GrpAnalyticsSugarContext<'input> {}

impl<'input> GrpAnalyticsSugarContextExt<'input>{
	fn new(ctx: &dyn GroupingAnalyticsContextAttrs<'input>) -> Rc<GroupingAnalyticsContextAll<'input>>  {
		Rc::new(
			GroupingAnalyticsContextAll::GrpAnalyticsSugarContext(
				BaseParserRuleContext::copy_from(ctx,GrpAnalyticsSugarContextExt{
					kind:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GrpAnalyticsSetsContext<'input> = BaseParserRuleContext<'input,GrpAnalyticsSetsContextExt<'input>>;

pub trait GrpAnalyticsSetsContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token GROUPING
	/// Returns `None` if there is no child corresponding to token GROUPING
	fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GROUPING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SETS
	/// Returns `None` if there is no child corresponding to token SETS
	fn SETS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SETS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn grpSetsElement_all(&self) ->  Vec<Rc<GrpSetsElementContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn grpSetsElement(&self, i: usize) -> Option<Rc<GrpSetsElementContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> GrpAnalyticsSetsContextAttrs<'input> for GrpAnalyticsSetsContext<'input>{}

pub struct GrpAnalyticsSetsContextExt<'input>{
	base:GroupingAnalyticsContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrpAnalyticsSetsContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GrpAnalyticsSetsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrpAnalyticsSetsContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grpAnalyticsSets(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_grpAnalyticsSets(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrpAnalyticsSetsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_grpAnalyticsSets(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrpAnalyticsSetsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingAnalytics }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingAnalytics }
}

impl<'input> Borrow<GroupingAnalyticsContextExt<'input>> for GrpAnalyticsSetsContext<'input>{
	fn borrow(&self) -> &GroupingAnalyticsContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GroupingAnalyticsContextExt<'input>> for GrpAnalyticsSetsContext<'input>{
	fn borrow_mut(&mut self) -> &mut GroupingAnalyticsContextExt<'input> { &mut self.base }
}

impl<'input> GroupingAnalyticsContextAttrs<'input> for GrpAnalyticsSetsContext<'input> {}

impl<'input> GrpAnalyticsSetsContextExt<'input>{
	fn new(ctx: &dyn GroupingAnalyticsContextAttrs<'input>) -> Rc<GroupingAnalyticsContextAll<'input>>  {
		Rc::new(
			GroupingAnalyticsContextAll::GrpAnalyticsSetsContext(
				BaseParserRuleContext::copy_from(ctx,GrpAnalyticsSetsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingAnalytics(&mut self,)
	-> Result<Rc<GroupingAnalyticsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingAnalyticsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 204, RULE_groupingAnalytics);
        let mut _localctx: Rc<GroupingAnalyticsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2179);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 CUBE | ROLLUP 
				=> {
					let tmp = GrpAnalyticsSugarContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2154);
					if let GroupingAnalyticsContextAll::GrpAnalyticsSugarContext(ctx) = cast_mut::<_,GroupingAnalyticsContextAll >(&mut _localctx){
					ctx.kind = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==CUBE || _la==ROLLUP) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let GroupingAnalyticsContextAll::GrpAnalyticsSugarContext(ctx) = cast_mut::<_,GroupingAnalyticsContextAll >(&mut _localctx){
						ctx.kind = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2155);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule groupingSet*/
					recog.base.set_state(2156);
					recog.groupingSet()?;

					recog.base.set_state(2161);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2157);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule groupingSet*/
						recog.base.set_state(2158);
						recog.groupingSet()?;

						}
						}
						recog.base.set_state(2163);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2164);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

			 GROUPING 
				=> {
					let tmp = GrpAnalyticsSetsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2166);
					recog.base.match_token(GROUPING,&mut recog.err_handler)?;

					recog.base.set_state(2167);
					recog.base.match_token(SETS,&mut recog.err_handler)?;

					recog.base.set_state(2168);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule grpSetsElement*/
					recog.base.set_state(2169);
					recog.grpSetsElement()?;

					recog.base.set_state(2174);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2170);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule grpSetsElement*/
						recog.base.set_state(2171);
						recog.grpSetsElement()?;

						}
						}
						recog.base.set_state(2176);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2177);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- grpSetsElement ----------------
#[derive(Debug)]
pub enum GrpSetsElementContextAll<'input>{
	GrpSetsElementSetContext(GrpSetsElementSetContext<'input>),
	GrpSetsElementAnalyticsContext(GrpSetsElementAnalyticsContext<'input>),
Error(GrpSetsElementContext<'input>)
}
antlr_rust::tid!{GrpSetsElementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GrpSetsElementContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for GrpSetsElementContextAll<'input>{}

impl<'input> Deref for GrpSetsElementContextAll<'input>{
	type Target = dyn GrpSetsElementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GrpSetsElementContextAll::*;
		match self{
			GrpSetsElementSetContext(inner) => inner,
			GrpSetsElementAnalyticsContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrpSetsElementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrpSetsElementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GrpSetsElementContext<'input> = BaseParserRuleContext<'input,GrpSetsElementContextExt<'input>>;

#[derive(Clone)]
pub struct GrpSetsElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for GrpSetsElementContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrpSetsElementContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrpSetsElementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GrpSetsElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_grpSetsElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_grpSetsElement }
}
antlr_rust::tid!{GrpSetsElementContextExt<'a>}

impl<'input> GrpSetsElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GrpSetsElementContextAll<'input>> {
		Rc::new(
		GrpSetsElementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GrpSetsElementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GrpSetsElementContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<GrpSetsElementContextExt<'input>>{


}

impl<'input> GrpSetsElementContextAttrs<'input> for GrpSetsElementContext<'input>{}

pub type GrpSetsElementSetContext<'input> = BaseParserRuleContext<'input,GrpSetsElementSetContextExt<'input>>;

pub trait GrpSetsElementSetContextAttrs<'input>: DatabricksParserContext<'input>{
	fn groupingSet(&self) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> GrpSetsElementSetContextAttrs<'input> for GrpSetsElementSetContext<'input>{}

pub struct GrpSetsElementSetContextExt<'input>{
	base:GrpSetsElementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrpSetsElementSetContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GrpSetsElementSetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrpSetsElementSetContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grpSetsElementSet(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_grpSetsElementSet(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrpSetsElementSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_grpSetsElementSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrpSetsElementSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_grpSetsElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_grpSetsElement }
}

impl<'input> Borrow<GrpSetsElementContextExt<'input>> for GrpSetsElementSetContext<'input>{
	fn borrow(&self) -> &GrpSetsElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GrpSetsElementContextExt<'input>> for GrpSetsElementSetContext<'input>{
	fn borrow_mut(&mut self) -> &mut GrpSetsElementContextExt<'input> { &mut self.base }
}

impl<'input> GrpSetsElementContextAttrs<'input> for GrpSetsElementSetContext<'input> {}

impl<'input> GrpSetsElementSetContextExt<'input>{
	fn new(ctx: &dyn GrpSetsElementContextAttrs<'input>) -> Rc<GrpSetsElementContextAll<'input>>  {
		Rc::new(
			GrpSetsElementContextAll::GrpSetsElementSetContext(
				BaseParserRuleContext::copy_from(ctx,GrpSetsElementSetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GrpSetsElementAnalyticsContext<'input> = BaseParserRuleContext<'input,GrpSetsElementAnalyticsContextExt<'input>>;

pub trait GrpSetsElementAnalyticsContextAttrs<'input>: DatabricksParserContext<'input>{
	fn groupingAnalytics(&self) -> Option<Rc<GroupingAnalyticsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> GrpSetsElementAnalyticsContextAttrs<'input> for GrpSetsElementAnalyticsContext<'input>{}

pub struct GrpSetsElementAnalyticsContextExt<'input>{
	base:GrpSetsElementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GrpSetsElementAnalyticsContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for GrpSetsElementAnalyticsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GrpSetsElementAnalyticsContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_grpSetsElementAnalytics(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_grpSetsElementAnalytics(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GrpSetsElementAnalyticsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_grpSetsElementAnalytics(self);
	}
}

impl<'input> CustomRuleContext<'input> for GrpSetsElementAnalyticsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_grpSetsElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_grpSetsElement }
}

impl<'input> Borrow<GrpSetsElementContextExt<'input>> for GrpSetsElementAnalyticsContext<'input>{
	fn borrow(&self) -> &GrpSetsElementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GrpSetsElementContextExt<'input>> for GrpSetsElementAnalyticsContext<'input>{
	fn borrow_mut(&mut self) -> &mut GrpSetsElementContextExt<'input> { &mut self.base }
}

impl<'input> GrpSetsElementContextAttrs<'input> for GrpSetsElementAnalyticsContext<'input> {}

impl<'input> GrpSetsElementAnalyticsContextExt<'input>{
	fn new(ctx: &dyn GrpSetsElementContextAttrs<'input>) -> Rc<GrpSetsElementContextAll<'input>>  {
		Rc::new(
			GrpSetsElementContextAll::GrpSetsElementAnalyticsContext(
				BaseParserRuleContext::copy_from(ctx,GrpSetsElementAnalyticsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn grpSetsElement(&mut self,)
	-> Result<Rc<GrpSetsElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GrpSetsElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 206, RULE_grpSetsElement);
        let mut _localctx: Rc<GrpSetsElementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2183);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(270,&mut recog.base)? {
				1 =>{
					let tmp = GrpSetsElementAnalyticsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule groupingAnalytics*/
					recog.base.set_state(2181);
					recog.groupingAnalytics()?;

					}
				}
			,
				2 =>{
					let tmp = GrpSetsElementSetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule groupingSet*/
					recog.base.set_state(2182);
					recog.groupingSet()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingSet ----------------
pub type GroupingSetContextAll<'input> = GroupingSetContext<'input>;


pub type GroupingSetContext<'input> = BaseParserRuleContext<'input,GroupingSetContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingSetContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for GroupingSetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for GroupingSetContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingSet(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_groupingSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for GroupingSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_groupingSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupingSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingSet }
}
antlr_rust::tid!{GroupingSetContextExt<'a>}

impl<'input> GroupingSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingSetContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingSetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<GroupingSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> GroupingSetContextAttrs<'input> for GroupingSetContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingSet(&mut self,)
	-> Result<Rc<GroupingSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 208, RULE_groupingSet);
        let mut _localctx: Rc<GroupingSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2201);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(274,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2185);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2194);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(2186);
						recog.expression()?;

						recog.base.set_state(2191);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(271,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(2187);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(2188);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(2193);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(271,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(2197);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2196);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,GroupingSetContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(2199);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expression*/
					recog.base.set_state(2200);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowDefinition ----------------
pub type WindowDefinitionContextAll<'input> = WindowDefinitionContext<'input>;


pub type WindowDefinitionContext<'input> = BaseParserRuleContext<'input,WindowDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct WindowDefinitionContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for WindowDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for WindowDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_windowDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for WindowDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_windowDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowDefinition }
}
antlr_rust::tid!{WindowDefinitionContextExt<'a>}

impl<'input> WindowDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowDefinitionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowDefinitionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<WindowDefinitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn windowSpecification(&self) -> Option<Rc<WindowSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowDefinitionContextAttrs<'input> for WindowDefinitionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowDefinition(&mut self,)
	-> Result<Rc<WindowDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 210, RULE_windowDefinition);
        let mut _localctx: Rc<WindowDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2203);
			let tmp = recog.identifier()?;
			 cast_mut::<_,WindowDefinitionContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(2204);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(2205);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule windowSpecification*/
			recog.base.set_state(2206);
			recog.windowSpecification()?;

			recog.base.set_state(2207);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowSpecification ----------------
pub type WindowSpecificationContextAll<'input> = WindowSpecificationContext<'input>;


pub type WindowSpecificationContext<'input> = BaseParserRuleContext<'input,WindowSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct WindowSpecificationContextExt<'input>{
	pub existingWindowName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for WindowSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for WindowSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowSpecification(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_windowSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for WindowSpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_windowSpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpecification }
}
antlr_rust::tid!{WindowSpecificationContextExt<'a>}

impl<'input> WindowSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowSpecificationContextExt{
				existingWindowName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowSpecificationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<WindowSpecificationContextExt<'input>>{

fn windowSpecificationPartitionBy(&self) -> Option<Rc<WindowSpecificationPartitionByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderBy(&self) -> Option<Rc<OrderByContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn windowFrame(&self) -> Option<Rc<WindowFrameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowSpecificationContextAttrs<'input> for WindowSpecificationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowSpecification(&mut self,)
	-> Result<Rc<WindowSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 212, RULE_windowSpecification);
        let mut _localctx: Rc<WindowSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2210);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(275,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2209);
					let tmp = recog.identifier()?;
					 cast_mut::<_,WindowSpecificationContext >(&mut _localctx).existingWindowName = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(2213);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PARTITION {
				{
				/*InvokeRule windowSpecificationPartitionBy*/
				recog.base.set_state(2212);
				recog.windowSpecificationPartitionBy()?;

				}
			}

			recog.base.set_state(2216);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				/*InvokeRule orderBy*/
				recog.base.set_state(2215);
				recog.orderBy()?;

				}
			}

			recog.base.set_state(2219);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==RANGE || _la==ROWS {
				{
				/*InvokeRule windowFrame*/
				recog.base.set_state(2218);
				recog.windowFrame()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowSpecificationPartitionBy ----------------
pub type WindowSpecificationPartitionByContextAll<'input> = WindowSpecificationPartitionByContext<'input>;


pub type WindowSpecificationPartitionByContext<'input> = BaseParserRuleContext<'input,WindowSpecificationPartitionByContextExt<'input>>;

#[derive(Clone)]
pub struct WindowSpecificationPartitionByContextExt<'input>{
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub partition:Vec<Rc<ExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for WindowSpecificationPartitionByContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for WindowSpecificationPartitionByContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowSpecificationPartitionBy(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_windowSpecificationPartitionBy(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for WindowSpecificationPartitionByContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_windowSpecificationPartitionBy(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowSpecificationPartitionByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpecificationPartitionBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpecificationPartitionBy }
}
antlr_rust::tid!{WindowSpecificationPartitionByContextExt<'a>}

impl<'input> WindowSpecificationPartitionByContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowSpecificationPartitionByContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowSpecificationPartitionByContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				expression: None, 
				partition: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowSpecificationPartitionByContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<WindowSpecificationPartitionByContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WindowSpecificationPartitionByContextAttrs<'input> for WindowSpecificationPartitionByContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowSpecificationPartitionBy(&mut self,)
	-> Result<Rc<WindowSpecificationPartitionByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowSpecificationPartitionByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 214, RULE_windowSpecificationPartitionBy);
        let mut _localctx: Rc<WindowSpecificationPartitionByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2221);
			recog.base.match_token(PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(2222);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2223);
			let tmp = recog.expression()?;
			 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression.clone().unwrap()
			 ;
			 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).partition.push(temp);
			  
			recog.base.set_state(2228);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(279,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2224);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2225);
					let tmp = recog.expression()?;
					 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).partition.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2230);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(279,&mut recog.base)?;
			}
			recog.base.set_state(2232);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2231);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).COMMA = Some(tmp);
				  

				let temp =  cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).COMMA.clone().unwrap()
				 ;
				 cast_mut::<_,WindowSpecificationPartitionByContext >(&mut _localctx).tail.push(temp);
				  
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderBy ----------------
pub type OrderByContextAll<'input> = OrderByContext<'input>;


pub type OrderByContext<'input> = BaseParserRuleContext<'input,OrderByContextExt<'input>>;

#[derive(Clone)]
pub struct OrderByContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for OrderByContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for OrderByContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderBy(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_orderBy(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for OrderByContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_orderBy(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrderByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderBy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderBy }
}
antlr_rust::tid!{OrderByContextExt<'a>}

impl<'input> OrderByContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderByContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderByContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderByContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<OrderByContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> OrderByContextAttrs<'input> for OrderByContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderBy(&mut self,)
	-> Result<Rc<OrderByContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderByContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 216, RULE_orderBy);
        let mut _localctx: Rc<OrderByContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2234);
			recog.base.match_token(ORDER,&mut recog.err_handler)?;

			recog.base.set_state(2235);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			recog.base.set_state(2248);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(283,&mut recog.base)? {
				1 =>{
					{
					recog.base.set_state(2236);
					recog.base.match_token(ALL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule sortItem*/
					recog.base.set_state(2237);
					recog.sortItem()?;

					recog.base.set_state(2242);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(281,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2238);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule sortItem*/
							recog.base.set_state(2239);
							recog.sortItem()?;

							}
							} 
						}
						recog.base.set_state(2244);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(281,&mut recog.base)?;
					}
					recog.base.set_state(2246);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2245);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,OrderByContext >(&mut _localctx).COMMA = Some(tmp);
						  

						let temp =  cast_mut::<_,OrderByContext >(&mut _localctx).COMMA.clone().unwrap()
						 ;
						 cast_mut::<_,OrderByContext >(&mut _localctx).tail.push(temp);
						  
						}
					}

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedQuery ----------------
pub type NamedQueryContextAll<'input> = NamedQueryContext<'input>;


pub type NamedQueryContext<'input> = BaseParserRuleContext<'input,NamedQueryContextExt<'input>>;

#[derive(Clone)]
pub struct NamedQueryContextExt<'input>{
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NamedQueryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NamedQueryContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedQuery(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_namedQuery(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NamedQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_namedQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedQuery }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedQuery }
}
antlr_rust::tid!{NamedQueryContextExt<'a>}

impl<'input> NamedQueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedQueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedQueryContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedQueryContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NamedQueryContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> NamedQueryContextAttrs<'input> for NamedQueryContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedQuery(&mut self,)
	-> Result<Rc<NamedQueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedQueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 218, RULE_namedQuery);
        let mut _localctx: Rc<NamedQueryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2250);
			let tmp = recog.identifier()?;
			 cast_mut::<_,NamedQueryContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(2252);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(284,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule columnAliases*/
					recog.base.set_state(2251);
					recog.columnAliases()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(2255);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(2254);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2257);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule query*/
			recog.base.set_state(2258);
			recog.query()?;

			recog.base.set_state(2259);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectItemAlias ----------------
pub type SelectItemAliasContextAll<'input> = SelectItemAliasContext<'input>;


pub type SelectItemAliasContext<'input> = BaseParserRuleContext<'input,SelectItemAliasContextExt<'input>>;

#[derive(Clone)]
pub struct SelectItemAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SelectItemAliasContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SelectItemAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectItemAlias(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_selectItemAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SelectItemAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_selectItemAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectItemAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItemAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItemAlias }
}
antlr_rust::tid!{SelectItemAliasContextExt<'a>}

impl<'input> SelectItemAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectItemAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectItemAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectItemAliasContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SelectItemAliasContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SelectItemAliasContextAttrs<'input> for SelectItemAliasContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectItemAlias(&mut self,)
	-> Result<Rc<SelectItemAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectItemAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 220, RULE_selectItemAlias);
        let mut _localctx: Rc<SelectItemAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2263);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
			 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
			 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
			 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
			 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
			 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
			 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
			 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
			 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
			 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
			 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
			 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
			 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
			 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT | EXTENDED |
			 EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT | FIRST |
			 FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM | FROM_JSON |
			 FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT | GROUP | GROUPING |
			 HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY | IF | IGNORE | IMMEDIATE |
			 IMPORT | IN | INCLUDE | INDEX | INDEXES | INNER | INPATH | INPUT | INPUTFORMAT |
			 INSERT | INTERSECT | INTERVAL | INT | INTEGER | INTO | INVOKER | IS |
			 ITEMS | ILIKE | JOIN | KEY | KEYS | LANGUAGE | LAST | LATERAL | LAZY |
			 LEADING | LEFT | LIKE | LIMIT | LINES | LIST | LISTAGG | LIVE | LOAD |
			 LOCAL | LOCATION | LOCK | LOCKS | LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES |
			 MATCHED | MATERIALIZED | MERGE | MICROSECOND | MICROSECONDS | MILLISECOND |
			 MILLISECONDS | MINUS_KW | MINUTE | MINUTES | MODE | MODIFIES | MONTH |
			 MONTHS | MSCK | NAME | NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND |
			 NANOSECONDS | NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF |
			 OFFSET | ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT |
			 OUTER | OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
			 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
			 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
			 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL | RECORDREADER |
			 RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP | REFERENCE | REFERENCES |
			 REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE | RESET | RESPECT |
			 RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE | ROLE | ROLES |
			 ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES | SESSION_USER |
			 SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT | SOME | SORT |
			 SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS | STORED | STRATIFY |
			 STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING | SYNC | SYSTEM_TIME |
			 SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE | TARGET | TBLPROPERTIES |
			 TEMP | TEMPORARY | TERMINATED | STRING_KW | THEN | TIME | TIMEDIFF |
			 TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF | TIMESTAMP_LTZ | TIMESTAMP_NTZ |
			 TINYINT | TO | TOUCH | TRAILING | TRANSACTION | TRANSACTIONS | TRANSFORM |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE | UNARCHIVE | UNBOUNDED | UNCACHE |
			 UNION | UNIQUE | UNKNOWN | UNLOCK | UNPIVOT | UNSET | UPDATE | USE |
			 USER | USING | VALUES | VAR | VARCHAR | VARIANT | VERSION | VIEW | VIEWS |
			 VOID | WEEK | WEEKS | WHEN | WHERE | WHILE | WINDOW | WITH | WITHIN |
			 YEAR | YEARS | ZONE | IDENTIFIER | BACKQUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2261);
					recog.identifier()?;

					}
				}

			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule columnAliases*/
					recog.base.set_state(2262);
					recog.columnAliases()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectItem ----------------
#[derive(Debug)]
pub enum SelectItemContextAll<'input>{
	SelectSingleContext(SelectSingleContext<'input>),
	SelectMultiContext(SelectMultiContext<'input>),
Error(SelectItemContext<'input>)
}
antlr_rust::tid!{SelectItemContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SelectItemContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for SelectItemContextAll<'input>{}

impl<'input> Deref for SelectItemContextAll<'input>{
	type Target = dyn SelectItemContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SelectItemContextAll::*;
		match self{
			SelectSingleContext(inner) => inner,
			SelectMultiContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SelectItemContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SelectItemContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SelectItemContext<'input> = BaseParserRuleContext<'input,SelectItemContextExt<'input>>;

#[derive(Clone)]
pub struct SelectItemContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SelectItemContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SelectItemContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SelectItemContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SelectItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}
antlr_rust::tid!{SelectItemContextExt<'a>}

impl<'input> SelectItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectItemContextAll<'input>> {
		Rc::new(
		SelectItemContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectItemContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SelectItemContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SelectItemContextExt<'input>>{


}

impl<'input> SelectItemContextAttrs<'input> for SelectItemContext<'input>{}

pub type SelectSingleContext<'input> = BaseParserRuleContext<'input,SelectSingleContextExt<'input>>;

pub trait SelectSingleContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn selectItemAlias(&self) -> Option<Rc<SelectItemAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> SelectSingleContextAttrs<'input> for SelectSingleContext<'input>{}

pub struct SelectSingleContextExt<'input>{
	base:SelectItemContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SelectSingleContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SelectSingleContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SelectSingleContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_selectSingle(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_selectSingle(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SelectSingleContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_selectSingle(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectSingleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}

impl<'input> Borrow<SelectItemContextExt<'input>> for SelectSingleContext<'input>{
	fn borrow(&self) -> &SelectItemContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SelectItemContextExt<'input>> for SelectSingleContext<'input>{
	fn borrow_mut(&mut self) -> &mut SelectItemContextExt<'input> { &mut self.base }
}

impl<'input> SelectItemContextAttrs<'input> for SelectSingleContext<'input> {}

impl<'input> SelectSingleContextExt<'input>{
	fn new(ctx: &dyn SelectItemContextAttrs<'input>) -> Rc<SelectItemContextAll<'input>>  {
		Rc::new(
			SelectItemContextAll::SelectSingleContext(
				BaseParserRuleContext::copy_from(ctx,SelectSingleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SelectMultiContext<'input> = BaseParserRuleContext<'input,SelectMultiContextExt<'input>>;

pub trait SelectMultiContextAttrs<'input>: DatabricksParserContext<'input>{
	fn multiSelect(&self) -> Option<Rc<MultiSelectContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SelectMultiContextAttrs<'input> for SelectMultiContext<'input>{}

pub struct SelectMultiContextExt<'input>{
	base:SelectItemContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SelectMultiContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SelectMultiContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SelectMultiContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_selectMulti(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_selectMulti(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SelectMultiContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_selectMulti(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectMultiContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}

impl<'input> Borrow<SelectItemContextExt<'input>> for SelectMultiContext<'input>{
	fn borrow(&self) -> &SelectItemContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SelectItemContextExt<'input>> for SelectMultiContext<'input>{
	fn borrow_mut(&mut self) -> &mut SelectItemContextExt<'input> { &mut self.base }
}

impl<'input> SelectItemContextAttrs<'input> for SelectMultiContext<'input> {}

impl<'input> SelectMultiContextExt<'input>{
	fn new(ctx: &dyn SelectItemContextAttrs<'input>) -> Rc<SelectItemContextAll<'input>>  {
		Rc::new(
			SelectItemContextAll::SelectMultiContext(
				BaseParserRuleContext::copy_from(ctx,SelectMultiContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectItem(&mut self,)
	-> Result<Rc<SelectItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 222, RULE_selectItem);
        let mut _localctx: Rc<SelectItemContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2273);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(289,&mut recog.base)? {
				1 =>{
					let tmp = SelectSingleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(2265);
					recog.expression()?;

					recog.base.set_state(2270);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(288,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2267);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(287,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(2266);
									recog.base.match_token(AS,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							/*InvokeRule selectItemAlias*/
							recog.base.set_state(2269);
							recog.selectItemAlias()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = SelectMultiContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule multiSelect*/
					recog.base.set_state(2272);
					recog.multiSelect()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- structItem ----------------
#[derive(Debug)]
pub enum StructItemContextAll<'input>{
	StructItemMultiContext(StructItemMultiContext<'input>),
	StructItemSingleContext(StructItemSingleContext<'input>),
Error(StructItemContext<'input>)
}
antlr_rust::tid!{StructItemContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StructItemContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for StructItemContextAll<'input>{}

impl<'input> Deref for StructItemContextAll<'input>{
	type Target = dyn StructItemContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StructItemContextAll::*;
		match self{
			StructItemMultiContext(inner) => inner,
			StructItemSingleContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StructItemContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StructItemContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StructItemContext<'input> = BaseParserRuleContext<'input,StructItemContextExt<'input>>;

#[derive(Clone)]
pub struct StructItemContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StructItemContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StructItemContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StructItemContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StructItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_structItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_structItem }
}
antlr_rust::tid!{StructItemContextExt<'a>}

impl<'input> StructItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StructItemContextAll<'input>> {
		Rc::new(
		StructItemContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StructItemContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StructItemContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StructItemContextExt<'input>>{


}

impl<'input> StructItemContextAttrs<'input> for StructItemContext<'input>{}

pub type StructItemMultiContext<'input> = BaseParserRuleContext<'input,StructItemMultiContextExt<'input>>;

pub trait StructItemMultiContextAttrs<'input>: DatabricksParserContext<'input>{
	fn multiSelect(&self) -> Option<Rc<MultiSelectContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StructItemMultiContextAttrs<'input> for StructItemMultiContext<'input>{}

pub struct StructItemMultiContextExt<'input>{
	base:StructItemContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StructItemMultiContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StructItemMultiContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StructItemMultiContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_structItemMulti(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_structItemMulti(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StructItemMultiContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_structItemMulti(self);
	}
}

impl<'input> CustomRuleContext<'input> for StructItemMultiContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_structItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_structItem }
}

impl<'input> Borrow<StructItemContextExt<'input>> for StructItemMultiContext<'input>{
	fn borrow(&self) -> &StructItemContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StructItemContextExt<'input>> for StructItemMultiContext<'input>{
	fn borrow_mut(&mut self) -> &mut StructItemContextExt<'input> { &mut self.base }
}

impl<'input> StructItemContextAttrs<'input> for StructItemMultiContext<'input> {}

impl<'input> StructItemMultiContextExt<'input>{
	fn new(ctx: &dyn StructItemContextAttrs<'input>) -> Rc<StructItemContextAll<'input>>  {
		Rc::new(
			StructItemContextAll::StructItemMultiContext(
				BaseParserRuleContext::copy_from(ctx,StructItemMultiContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StructItemSingleContext<'input> = BaseParserRuleContext<'input,StructItemSingleContextExt<'input>>;

pub trait StructItemSingleContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> StructItemSingleContextAttrs<'input> for StructItemSingleContext<'input>{}

pub struct StructItemSingleContextExt<'input>{
	base:StructItemContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StructItemSingleContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StructItemSingleContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StructItemSingleContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_structItemSingle(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_structItemSingle(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StructItemSingleContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_structItemSingle(self);
	}
}

impl<'input> CustomRuleContext<'input> for StructItemSingleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_structItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_structItem }
}

impl<'input> Borrow<StructItemContextExt<'input>> for StructItemSingleContext<'input>{
	fn borrow(&self) -> &StructItemContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StructItemContextExt<'input>> for StructItemSingleContext<'input>{
	fn borrow_mut(&mut self) -> &mut StructItemContextExt<'input> { &mut self.base }
}

impl<'input> StructItemContextAttrs<'input> for StructItemSingleContext<'input> {}

impl<'input> StructItemSingleContextExt<'input>{
	fn new(ctx: &dyn StructItemContextAttrs<'input>) -> Rc<StructItemContextAll<'input>>  {
		Rc::new(
			StructItemContextAll::StructItemSingleContext(
				BaseParserRuleContext::copy_from(ctx,StructItemSingleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn structItem(&mut self,)
	-> Result<Rc<StructItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StructItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 224, RULE_structItem);
        let mut _localctx: Rc<StructItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2283);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(292,&mut recog.base)? {
				1 =>{
					let tmp = StructItemSingleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(2275);
					recog.expression()?;

					recog.base.set_state(2280);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if ((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						recog.base.set_state(2277);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(290,&mut recog.base)? {
							x if x == 1=>{
								{
								recog.base.set_state(2276);
								recog.base.match_token(AS,&mut recog.err_handler)?;

								}
							}

							_ => {}
						}
						/*InvokeRule identifier*/
						recog.base.set_state(2279);
						recog.identifier()?;

						}
					}

					}
				}
			,
				2 =>{
					let tmp = StructItemMultiContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule multiSelect*/
					recog.base.set_state(2282);
					recog.multiSelect()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiSelect ----------------
pub type MultiSelectContextAll<'input> = MultiSelectContext<'input>;


pub type MultiSelectContext<'input> = BaseParserRuleContext<'input,MultiSelectContextExt<'input>>;

#[derive(Clone)]
pub struct MultiSelectContextExt<'input>{
	pub exceptCols: Option<Rc<MultipartIdentifierListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for MultiSelectContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MultiSelectContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiSelect(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_multiSelect(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MultiSelectContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_multiSelect(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiSelectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiSelect }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiSelect }
}
antlr_rust::tid!{MultiSelectContextExt<'a>}

impl<'input> MultiSelectContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiSelectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiSelectContextExt{
				exceptCols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiSelectContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<MultiSelectContextExt<'input>>{

fn selectStar(&self) -> Option<Rc<SelectStarContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MultiSelectContextAttrs<'input> for MultiSelectContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiSelect(&mut self,)
	-> Result<Rc<MultiSelectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiSelectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 226, RULE_multiSelect);
        let mut _localctx: Rc<MultiSelectContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule selectStar*/
			recog.base.set_state(2285);
			recog.selectStar()?;

			recog.base.set_state(2291);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(293,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2286);
					recog.base.match_token(EXCEPT,&mut recog.err_handler)?;

					recog.base.set_state(2287);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifierList*/
					recog.base.set_state(2288);
					let tmp = recog.multipartIdentifierList()?;
					 cast_mut::<_,MultiSelectContext >(&mut _localctx).exceptCols = Some(tmp.clone());
					  

					recog.base.set_state(2289);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectStar ----------------
pub type SelectStarContextAll<'input> = SelectStarContext<'input>;


pub type SelectStarContext<'input> = BaseParserRuleContext<'input,SelectStarContextExt<'input>>;

#[derive(Clone)]
pub struct SelectStarContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SelectStarContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SelectStarContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectStar(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_selectStar(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SelectStarContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_selectStar(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectStarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectStar }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectStar }
}
antlr_rust::tid!{SelectStarContextExt<'a>}

impl<'input> SelectStarContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectStarContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectStarContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectStarContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SelectStarContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn selectStar(&self) -> Option<Rc<SelectStarContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}

}

impl<'input> SelectStarContextAttrs<'input> for SelectStarContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectStar(&mut self,)
	-> Result<Rc<SelectStarContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectStarContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 228, RULE_selectStar);
        let mut _localctx: Rc<SelectStarContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2302);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(294,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2293);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule selectStar*/
					recog.base.set_state(2294);
					recog.selectStar()?;

					recog.base.set_state(2295);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule primaryExpression*/
					recog.base.set_state(2297);
					recog.primaryExpression_rec(0)?;

					recog.base.set_state(2298);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					recog.base.set_state(2299);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(2301);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relation ----------------
pub type RelationContextAll<'input> = RelationContext<'input>;


pub type RelationContext<'input> = BaseParserRuleContext<'input,RelationContextExt<'input>>;

#[derive(Clone)]
pub struct RelationContextExt<'input>{
	pub target: Option<Rc<PivotedRelationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for RelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RelationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relation(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_relation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_relation(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relation }
}
antlr_rust::tid!{RelationContextExt<'a>}

impl<'input> RelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationContextExt{
				target: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RelationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<RelationContextExt<'input>>{

fn pivotedRelation(&self) -> Option<Rc<PivotedRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RelationContextAttrs<'input> for RelationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relation(&mut self,)
	-> Result<Rc<RelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 230, RULE_relation);
        let mut _localctx: Rc<RelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule pivotedRelation*/
			recog.base.set_state(2304);
			let tmp = recog.pivotedRelation()?;
			 cast_mut::<_,RelationContext >(&mut _localctx).target = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinType ----------------
pub type JoinTypeContextAll<'input> = JoinTypeContext<'input>;


pub type JoinTypeContext<'input> = BaseParserRuleContext<'input,JoinTypeContextExt<'input>>;

#[derive(Clone)]
pub struct JoinTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for JoinTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JoinTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinType(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_joinType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JoinTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_joinType(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinType }
}
antlr_rust::tid!{JoinTypeContextExt<'a>}

impl<'input> JoinTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinTypeContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<JoinTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSS
/// Returns `None` if there is no child corresponding to token CROSS
fn CROSS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CROSS, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token SEMI
/// Returns `None` if there is no child corresponding to token SEMI
fn SEMI(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}
/// Retrieves first TerminalNode corresponding to token ANTI
/// Returns `None` if there is no child corresponding to token ANTI
fn ANTI(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ANTI, 0)
}

}

impl<'input> JoinTypeContextAttrs<'input> for JoinTypeContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinType(&mut self,)
	-> Result<Rc<JoinTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 232, RULE_joinType);
        let mut _localctx: Rc<JoinTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2330);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(301,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2307);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INNER {
						{
						recog.base.set_state(2306);
						recog.base.match_token(INNER,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2309);
					recog.base.match_token(CROSS,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(2310);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					recog.base.set_state(2312);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(2311);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(2315);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT {
						{
						recog.base.set_state(2314);
						recog.base.match_token(LEFT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2317);
					recog.base.match_token(SEMI,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(2318);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					recog.base.set_state(2320);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(2319);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(2322);
					recog.base.match_token(FULL,&mut recog.err_handler)?;

					recog.base.set_state(2324);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(2323);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(2327);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT {
						{
						recog.base.set_state(2326);
						recog.base.match_token(LEFT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2329);
					recog.base.match_token(ANTI,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinCriteria ----------------
pub type JoinCriteriaContextAll<'input> = JoinCriteriaContext<'input>;


pub type JoinCriteriaContext<'input> = BaseParserRuleContext<'input,JoinCriteriaContextExt<'input>>;

#[derive(Clone)]
pub struct JoinCriteriaContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for JoinCriteriaContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JoinCriteriaContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinCriteria(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_joinCriteria(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JoinCriteriaContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_joinCriteria(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinCriteriaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinCriteria }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinCriteria }
}
antlr_rust::tid!{JoinCriteriaContextExt<'a>}

impl<'input> JoinCriteriaContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinCriteriaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinCriteriaContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinCriteriaContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<JoinCriteriaContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> JoinCriteriaContextAttrs<'input> for JoinCriteriaContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinCriteria(&mut self,)
	-> Result<Rc<JoinCriteriaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinCriteriaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 234, RULE_joinCriteria);
        let mut _localctx: Rc<JoinCriteriaContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2349);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ON 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2332);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(2333);
					recog.booleanExpression_rec(0)?;

					}
				}

			 USING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2334);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					recog.base.set_state(2335);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(2336);
					recog.identifier()?;

					recog.base.set_state(2341);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(302,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2337);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(2338);
							recog.identifier()?;

							}
							} 
						}
						recog.base.set_state(2343);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(302,&mut recog.base)?;
					}
					recog.base.set_state(2345);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2344);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						 cast_mut::<_,JoinCriteriaContext >(&mut _localctx).tail = Some(tmp);
						  

						}
					}

					recog.base.set_state(2347);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampledRelationTarget ----------------
pub type SampledRelationTargetContextAll<'input> = SampledRelationTargetContext<'input>;


pub type SampledRelationTargetContext<'input> = BaseParserRuleContext<'input,SampledRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct SampledRelationTargetContextExt<'input>{
	pub target: Option<Rc<RelationPrimaryContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SampledRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampledRelationTargetContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampledRelationTarget(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_sampledRelationTarget(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampledRelationTargetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sampledRelationTarget(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampledRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampledRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampledRelationTarget }
}
antlr_rust::tid!{SampledRelationTargetContextExt<'a>}

impl<'input> SampledRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampledRelationTargetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampledRelationTargetContextExt{
				target: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SampledRelationTargetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SampledRelationTargetContextExt<'input>>{

fn relationPrimary(&self) -> Option<Rc<RelationPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SampledRelationTargetContextAttrs<'input> for SampledRelationTargetContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampledRelationTarget(&mut self,)
	-> Result<Rc<SampledRelationTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampledRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 236, RULE_sampledRelationTarget);
        let mut _localctx: Rc<SampledRelationTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule relationPrimary*/
			recog.base.set_state(2351);
			let tmp = recog.relationPrimary()?;
			 cast_mut::<_,SampledRelationTargetContext >(&mut _localctx).target = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampledRelation ----------------
pub type SampledRelationContextAll<'input> = SampledRelationContext<'input>;


pub type SampledRelationContext<'input> = BaseParserRuleContext<'input,SampledRelationContextExt<'input>>;

#[derive(Clone)]
pub struct SampledRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SampledRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampledRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampledRelation(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_sampledRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampledRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sampledRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampledRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampledRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampledRelation }
}
antlr_rust::tid!{SampledRelationContextExt<'a>}

impl<'input> SampledRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampledRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampledRelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SampledRelationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SampledRelationContextExt<'input>>{

fn sampledRelationTarget(&self) -> Option<Rc<SampledRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sample(&self) -> Option<Rc<SampleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SampledRelationContextAttrs<'input> for SampledRelationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampledRelation(&mut self,)
	-> Result<Rc<SampledRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampledRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 238, RULE_sampledRelation);
        let mut _localctx: Rc<SampledRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule sampledRelationTarget*/
			recog.base.set_state(2353);
			recog.sampledRelationTarget()?;

			recog.base.set_state(2355);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(305,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule sample*/
					recog.base.set_state(2354);
					recog.sample()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sample ----------------
pub type SampleContextAll<'input> = SampleContext<'input>;


pub type SampleContext<'input> = BaseParserRuleContext<'input,SampleContextExt<'input>>;

#[derive(Clone)]
pub struct SampleContextExt<'input>{
	pub seed: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SampleContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampleContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sample(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_sample(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampleContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sample(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sample }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sample }
}
antlr_rust::tid!{SampleContextExt<'a>}

impl<'input> SampleContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleContextExt{
				seed: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SampleContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SampleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn sampleMethod(&self) -> Option<Rc<SampleMethodContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token REPEATABLE
/// Returns `None` if there is no child corresponding to token REPEATABLE
fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REPEATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}

}

impl<'input> SampleContextAttrs<'input> for SampleContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sample(&mut self,)
	-> Result<Rc<SampleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 240, RULE_sample);
        let mut _localctx: Rc<SampleContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2357);
			recog.base.match_token(TABLESAMPLE,&mut recog.err_handler)?;

			recog.base.set_state(2358);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2360);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
				{
				/*InvokeRule sampleMethod*/
				recog.base.set_state(2359);
				recog.sampleMethod()?;

				}
			}

			recog.base.set_state(2362);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2367);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(307,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2363);
					recog.base.match_token(REPEATABLE,&mut recog.err_handler)?;

					recog.base.set_state(2364);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2365);
					let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
					 cast_mut::<_,SampleContext >(&mut _localctx).seed = Some(tmp);
					  

					recog.base.set_state(2366);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampleOperator ----------------
pub type SampleOperatorContextAll<'input> = SampleOperatorContext<'input>;


pub type SampleOperatorContext<'input> = BaseParserRuleContext<'input,SampleOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SampleOperatorContextExt<'input>{
	pub seed: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SampleOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampleOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampleOperator(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_sampleOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampleOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sampleOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleOperator }
}
antlr_rust::tid!{SampleOperatorContextExt<'a>}

impl<'input> SampleOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleOperatorContextExt{
				seed: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SampleOperatorContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SampleOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn sampleMethod(&self) -> Option<Rc<SampleMethodContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token REPEATABLE
/// Returns `None` if there is no child corresponding to token REPEATABLE
fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REPEATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}

}

impl<'input> SampleOperatorContextAttrs<'input> for SampleOperatorContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampleOperator(&mut self,)
	-> Result<Rc<SampleOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 242, RULE_sampleOperator);
        let mut _localctx: Rc<SampleOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2369);
			recog.base.match_token(TABLESAMPLE,&mut recog.err_handler)?;

			recog.base.set_state(2370);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2372);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
				{
				/*InvokeRule sampleMethod*/
				recog.base.set_state(2371);
				recog.sampleMethod()?;

				}
			}

			recog.base.set_state(2374);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2379);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==REPEATABLE {
				{
				recog.base.set_state(2375);
				recog.base.match_token(REPEATABLE,&mut recog.err_handler)?;

				recog.base.set_state(2376);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				recog.base.set_state(2377);
				let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
				 cast_mut::<_,SampleOperatorContext >(&mut _localctx).seed = Some(tmp);
				  

				recog.base.set_state(2378);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampleMethod ----------------
#[derive(Debug)]
pub enum SampleMethodContextAll<'input>{
	SampleByRowsContext(SampleByRowsContext<'input>),
	SampleByPercentileContext(SampleByPercentileContext<'input>),
	SampleByBucketContext(SampleByBucketContext<'input>),
	SampleByBytesContext(SampleByBytesContext<'input>),
Error(SampleMethodContext<'input>)
}
antlr_rust::tid!{SampleMethodContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SampleMethodContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for SampleMethodContextAll<'input>{}

impl<'input> Deref for SampleMethodContextAll<'input>{
	type Target = dyn SampleMethodContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SampleMethodContextAll::*;
		match self{
			SampleByRowsContext(inner) => inner,
			SampleByPercentileContext(inner) => inner,
			SampleByBucketContext(inner) => inner,
			SampleByBytesContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampleMethodContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampleMethodContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SampleMethodContext<'input> = BaseParserRuleContext<'input,SampleMethodContextExt<'input>>;

#[derive(Clone)]
pub struct SampleMethodContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SampleMethodContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampleMethodContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampleMethodContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SampleMethodContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}
antlr_rust::tid!{SampleMethodContextExt<'a>}

impl<'input> SampleMethodContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleMethodContextAll<'input>> {
		Rc::new(
		SampleMethodContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleMethodContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SampleMethodContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SampleMethodContextExt<'input>>{


}

impl<'input> SampleMethodContextAttrs<'input> for SampleMethodContext<'input>{}

pub type SampleByRowsContext<'input> = BaseParserRuleContext<'input,SampleByRowsContextExt<'input>>;

pub trait SampleByRowsContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ROWS
	/// Returns `None` if there is no child corresponding to token ROWS
	fn ROWS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROWS, 0)
	}
}

impl<'input> SampleByRowsContextAttrs<'input> for SampleByRowsContext<'input>{}

pub struct SampleByRowsContextExt<'input>{
	base:SampleMethodContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampleByRowsContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SampleByRowsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampleByRowsContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampleByRows(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_sampleByRows(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampleByRowsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sampleByRows(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleByRowsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}

impl<'input> Borrow<SampleMethodContextExt<'input>> for SampleByRowsContext<'input>{
	fn borrow(&self) -> &SampleMethodContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SampleMethodContextExt<'input>> for SampleByRowsContext<'input>{
	fn borrow_mut(&mut self) -> &mut SampleMethodContextExt<'input> { &mut self.base }
}

impl<'input> SampleMethodContextAttrs<'input> for SampleByRowsContext<'input> {}

impl<'input> SampleByRowsContextExt<'input>{
	fn new(ctx: &dyn SampleMethodContextAttrs<'input>) -> Rc<SampleMethodContextAll<'input>>  {
		Rc::new(
			SampleMethodContextAll::SampleByRowsContext(
				BaseParserRuleContext::copy_from(ctx,SampleByRowsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SampleByPercentileContext<'input> = BaseParserRuleContext<'input,SampleByPercentileContextExt<'input>>;

pub trait SampleByPercentileContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PERCENT_KW
	/// Returns `None` if there is no child corresponding to token PERCENT_KW
	fn PERCENT_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PERCENT_KW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
	fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> SampleByPercentileContextAttrs<'input> for SampleByPercentileContext<'input>{}

pub struct SampleByPercentileContextExt<'input>{
	base:SampleMethodContextExt<'input>,
	pub negativeSign: Option<TokenType<'input>>,
	pub percentage: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampleByPercentileContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SampleByPercentileContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampleByPercentileContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampleByPercentile(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_sampleByPercentile(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampleByPercentileContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sampleByPercentile(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleByPercentileContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}

impl<'input> Borrow<SampleMethodContextExt<'input>> for SampleByPercentileContext<'input>{
	fn borrow(&self) -> &SampleMethodContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SampleMethodContextExt<'input>> for SampleByPercentileContext<'input>{
	fn borrow_mut(&mut self) -> &mut SampleMethodContextExt<'input> { &mut self.base }
}

impl<'input> SampleMethodContextAttrs<'input> for SampleByPercentileContext<'input> {}

impl<'input> SampleByPercentileContextExt<'input>{
	fn new(ctx: &dyn SampleMethodContextAttrs<'input>) -> Rc<SampleMethodContextAll<'input>>  {
		Rc::new(
			SampleMethodContextAll::SampleByPercentileContext(
				BaseParserRuleContext::copy_from(ctx,SampleByPercentileContextExt{
					negativeSign:None, percentage:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SampleByBucketContext<'input> = BaseParserRuleContext<'input,SampleByBucketContextExt<'input>>;

pub trait SampleByBucketContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token OUT
	/// Returns `None` if there is no child corresponding to token OUT
	fn OUT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OUT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OF
	/// Returns `None` if there is no child corresponding to token OF
	fn OF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BUCKET
	/// Returns `None` if there is no child corresponding to token BUCKET
	fn BUCKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BUCKET, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token INTEGER_VALUE in current rule
	fn INTEGER_VALUE_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token INTEGER_VALUE, starting from 0.
	/// Returns `None` if number of children corresponding to token INTEGER_VALUE is less or equal than `i`.
	fn INTEGER_VALUE(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, i)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> SampleByBucketContextAttrs<'input> for SampleByBucketContext<'input>{}

pub struct SampleByBucketContextExt<'input>{
	base:SampleMethodContextExt<'input>,
	pub sampleType: Option<TokenType<'input>>,
	pub numerator: Option<TokenType<'input>>,
	pub denominator: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampleByBucketContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SampleByBucketContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampleByBucketContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampleByBucket(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_sampleByBucket(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampleByBucketContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sampleByBucket(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleByBucketContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}

impl<'input> Borrow<SampleMethodContextExt<'input>> for SampleByBucketContext<'input>{
	fn borrow(&self) -> &SampleMethodContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SampleMethodContextExt<'input>> for SampleByBucketContext<'input>{
	fn borrow_mut(&mut self) -> &mut SampleMethodContextExt<'input> { &mut self.base }
}

impl<'input> SampleMethodContextAttrs<'input> for SampleByBucketContext<'input> {}

impl<'input> SampleByBucketContextExt<'input>{
	fn new(ctx: &dyn SampleMethodContextAttrs<'input>) -> Rc<SampleMethodContextAll<'input>>  {
		Rc::new(
			SampleMethodContextAll::SampleByBucketContext(
				BaseParserRuleContext::copy_from(ctx,SampleByBucketContextExt{
					sampleType:None, numerator:None, denominator:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SampleByBytesContext<'input> = BaseParserRuleContext<'input,SampleByBytesContextExt<'input>>;

pub trait SampleByBytesContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SampleByBytesContextAttrs<'input> for SampleByBytesContext<'input>{}

pub struct SampleByBytesContextExt<'input>{
	base:SampleMethodContextExt<'input>,
	pub bytes: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampleByBytesContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SampleByBytesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampleByBytesContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampleByBytes(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_sampleByBytes(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampleByBytesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sampleByBytes(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleByBytesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}

impl<'input> Borrow<SampleMethodContextExt<'input>> for SampleByBytesContext<'input>{
	fn borrow(&self) -> &SampleMethodContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SampleMethodContextExt<'input>> for SampleByBytesContext<'input>{
	fn borrow_mut(&mut self) -> &mut SampleMethodContextExt<'input> { &mut self.base }
}

impl<'input> SampleMethodContextAttrs<'input> for SampleByBytesContext<'input> {}

impl<'input> SampleByBytesContextExt<'input>{
	fn new(ctx: &dyn SampleMethodContextAttrs<'input>) -> Rc<SampleMethodContextAll<'input>>  {
		Rc::new(
			SampleMethodContextAll::SampleByBytesContext(
				BaseParserRuleContext::copy_from(ctx,SampleByBytesContextExt{
        			bytes:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampleMethod(&mut self,)
	-> Result<Rc<SampleMethodContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleMethodContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 244, RULE_sampleMethod);
        let mut _localctx: Rc<SampleMethodContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2405);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(313,&mut recog.base)? {
				1 =>{
					let tmp = SampleByPercentileContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2382);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(2381);
						let tmp = recog.base.match_token(MINUS,&mut recog.err_handler)?;
						if let SampleMethodContextAll::SampleByPercentileContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
						ctx.negativeSign = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2384);
					if let SampleMethodContextAll::SampleByPercentileContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.percentage = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==INTEGER_VALUE || _la==DECIMAL_VALUE) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let SampleMethodContextAll::SampleByPercentileContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
						ctx.percentage = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2385);
					recog.base.match_token(PERCENT_KW,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = SampleByRowsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(2386);
					recog.expression()?;

					recog.base.set_state(2387);
					recog.base.match_token(ROWS,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = SampleByBucketContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2389);
					let tmp = recog.base.match_token(BUCKET,&mut recog.err_handler)?;
					if let SampleMethodContextAll::SampleByBucketContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.sampleType = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(2390);
					let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
					if let SampleMethodContextAll::SampleByBucketContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.numerator = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(2391);
					recog.base.match_token(OUT,&mut recog.err_handler)?;

					recog.base.set_state(2392);
					recog.base.match_token(OF,&mut recog.err_handler)?;

					recog.base.set_state(2393);
					let tmp = recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;
					if let SampleMethodContextAll::SampleByBucketContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.denominator = Some(tmp); } else {unreachable!("cant cast");}  

					recog.base.set_state(2402);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ON {
						{
						recog.base.set_state(2394);
						recog.base.match_token(ON,&mut recog.err_handler)?;

						recog.base.set_state(2400);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(311,&mut recog.base)? {
							1 =>{
								{
								/*InvokeRule identifier*/
								recog.base.set_state(2395);
								recog.identifier()?;

								}
							}
						,
							2 =>{
								{
								/*InvokeRule qualifiedName*/
								recog.base.set_state(2396);
								recog.qualifiedName()?;

								recog.base.set_state(2397);
								recog.base.match_token(LPAREN,&mut recog.err_handler)?;

								recog.base.set_state(2398);
								recog.base.match_token(RPAREN,&mut recog.err_handler)?;

								}
							}

							_ => {}
						}
						}
					}

					}
				}
			,
				4 =>{
					let tmp = SampleByBytesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(2404);
					let tmp = recog.expression()?;
					if let SampleMethodContextAll::SampleByBytesContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.bytes = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- trimsSpecification ----------------
pub type TrimsSpecificationContextAll<'input> = TrimsSpecificationContext<'input>;


pub type TrimsSpecificationContext<'input> = BaseParserRuleContext<'input,TrimsSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct TrimsSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TrimsSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TrimsSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_trimsSpecification(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_trimsSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TrimsSpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_trimsSpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for TrimsSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_trimsSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_trimsSpecification }
}
antlr_rust::tid!{TrimsSpecificationContextExt<'a>}

impl<'input> TrimsSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TrimsSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TrimsSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TrimsSpecificationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TrimsSpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEADING
/// Returns `None` if there is no child corresponding to token LEADING
fn LEADING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LEADING, 0)
}
/// Retrieves first TerminalNode corresponding to token TRAILING
/// Returns `None` if there is no child corresponding to token TRAILING
fn TRAILING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRAILING, 0)
}
/// Retrieves first TerminalNode corresponding to token BOTH
/// Returns `None` if there is no child corresponding to token BOTH
fn BOTH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BOTH, 0)
}

}

impl<'input> TrimsSpecificationContextAttrs<'input> for TrimsSpecificationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn trimsSpecification(&mut self,)
	-> Result<Rc<TrimsSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TrimsSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 246, RULE_trimsSpecification);
        let mut _localctx: Rc<TrimsSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2407);
			_la = recog.base.input.la(1);
			if { !(_la==BOTH || _la==LEADING || _la==TRAILING) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- variableDefinition ----------------
pub type VariableDefinitionContextAll<'input> = VariableDefinitionContext<'input>;


pub type VariableDefinitionContext<'input> = BaseParserRuleContext<'input,VariableDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct VariableDefinitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for VariableDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for VariableDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_variableDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_variableDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for VariableDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_variableDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for VariableDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_variableDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_variableDefinition }
}
antlr_rust::tid!{VariableDefinitionContextExt<'a>}

impl<'input> VariableDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VariableDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VariableDefinitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VariableDefinitionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<VariableDefinitionContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> VariableDefinitionContextAttrs<'input> for VariableDefinitionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn variableDefinition(&mut self,)
	-> Result<Rc<VariableDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VariableDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 248, RULE_variableDefinition);
        let mut _localctx: Rc<VariableDefinitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2409);
			recog.identifier()?;

			recog.base.set_state(2410);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2411);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotedRelationTarget ----------------
pub type PivotedRelationTargetContextAll<'input> = PivotedRelationTargetContext<'input>;


pub type PivotedRelationTargetContext<'input> = BaseParserRuleContext<'input,PivotedRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct PivotedRelationTargetContextExt<'input>{
	pub target: Option<Rc<LateralViewRelationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PivotedRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotedRelationTargetContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotedRelationTarget(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_pivotedRelationTarget(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotedRelationTargetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pivotedRelationTarget(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotedRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotedRelationTarget }
}
antlr_rust::tid!{PivotedRelationTargetContextExt<'a>}

impl<'input> PivotedRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotedRelationTargetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotedRelationTargetContextExt{
				target: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotedRelationTargetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PivotedRelationTargetContextExt<'input>>{

fn lateralViewRelation(&self) -> Option<Rc<LateralViewRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PivotedRelationTargetContextAttrs<'input> for PivotedRelationTargetContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotedRelationTarget(&mut self,)
	-> Result<Rc<PivotedRelationTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotedRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 250, RULE_pivotedRelationTarget);
        let mut _localctx: Rc<PivotedRelationTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule lateralViewRelation*/
			recog.base.set_state(2413);
			let tmp = recog.lateralViewRelation()?;
			 cast_mut::<_,PivotedRelationTargetContext >(&mut _localctx).target = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lateralViewRelation ----------------
pub type LateralViewRelationContextAll<'input> = LateralViewRelationContext<'input>;


pub type LateralViewRelationContext<'input> = BaseParserRuleContext<'input,LateralViewRelationContextExt<'input>>;

#[derive(Clone)]
pub struct LateralViewRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for LateralViewRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LateralViewRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_lateralViewRelation(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_lateralViewRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LateralViewRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_lateralViewRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for LateralViewRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lateralViewRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lateralViewRelation }
}
antlr_rust::tid!{LateralViewRelationContextExt<'a>}

impl<'input> LateralViewRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LateralViewRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LateralViewRelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LateralViewRelationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<LateralViewRelationContextExt<'input>>{

fn lateralViewRelationTarget(&self) -> Option<Rc<LateralViewRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lateralView(&self) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LateralViewRelationContextAttrs<'input> for LateralViewRelationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn lateralViewRelation(&mut self,)
	-> Result<Rc<LateralViewRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LateralViewRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 252, RULE_lateralViewRelation);
        let mut _localctx: Rc<LateralViewRelationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule lateralViewRelationTarget*/
			recog.base.set_state(2415);
			recog.lateralViewRelationTarget_rec(0)?;

			recog.base.set_state(2417);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LATERAL {
				{
				/*InvokeRule lateralView*/
				recog.base.set_state(2416);
				recog.lateralView()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lateralViewRelationTarget ----------------
#[derive(Debug)]
pub enum LateralViewRelationTargetContextAll<'input>{
	LateralViewRelationTargetDefaultContext(LateralViewRelationTargetDefaultContext<'input>),
	LateralViewRelationTargetIncrementalContext(LateralViewRelationTargetIncrementalContext<'input>),
Error(LateralViewRelationTargetContext<'input>)
}
antlr_rust::tid!{LateralViewRelationTargetContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for LateralViewRelationTargetContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for LateralViewRelationTargetContextAll<'input>{}

impl<'input> Deref for LateralViewRelationTargetContextAll<'input>{
	type Target = dyn LateralViewRelationTargetContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use LateralViewRelationTargetContextAll::*;
		match self{
			LateralViewRelationTargetDefaultContext(inner) => inner,
			LateralViewRelationTargetIncrementalContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LateralViewRelationTargetContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LateralViewRelationTargetContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type LateralViewRelationTargetContext<'input> = BaseParserRuleContext<'input,LateralViewRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct LateralViewRelationTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for LateralViewRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LateralViewRelationTargetContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LateralViewRelationTargetContext<'input>{
}

impl<'input> CustomRuleContext<'input> for LateralViewRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lateralViewRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lateralViewRelationTarget }
}
antlr_rust::tid!{LateralViewRelationTargetContextExt<'a>}

impl<'input> LateralViewRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LateralViewRelationTargetContextAll<'input>> {
		Rc::new(
		LateralViewRelationTargetContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LateralViewRelationTargetContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait LateralViewRelationTargetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<LateralViewRelationTargetContextExt<'input>>{


}

impl<'input> LateralViewRelationTargetContextAttrs<'input> for LateralViewRelationTargetContext<'input>{}

pub type LateralViewRelationTargetDefaultContext<'input> = BaseParserRuleContext<'input,LateralViewRelationTargetDefaultContextExt<'input>>;

pub trait LateralViewRelationTargetDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn extensibleRelation_all(&self) ->  Vec<Rc<ExtensibleRelationContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn extensibleRelation(&self, i: usize) -> Option<Rc<ExtensibleRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> LateralViewRelationTargetDefaultContextAttrs<'input> for LateralViewRelationTargetDefaultContext<'input>{}

pub struct LateralViewRelationTargetDefaultContextExt<'input>{
	base:LateralViewRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LateralViewRelationTargetDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LateralViewRelationTargetDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LateralViewRelationTargetDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_lateralViewRelationTargetDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_lateralViewRelationTargetDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LateralViewRelationTargetDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_lateralViewRelationTargetDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for LateralViewRelationTargetDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lateralViewRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lateralViewRelationTarget }
}

impl<'input> Borrow<LateralViewRelationTargetContextExt<'input>> for LateralViewRelationTargetDefaultContext<'input>{
	fn borrow(&self) -> &LateralViewRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LateralViewRelationTargetContextExt<'input>> for LateralViewRelationTargetDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut LateralViewRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> LateralViewRelationTargetContextAttrs<'input> for LateralViewRelationTargetDefaultContext<'input> {}

impl<'input> LateralViewRelationTargetDefaultContextExt<'input>{
	fn new(ctx: &dyn LateralViewRelationTargetContextAttrs<'input>) -> Rc<LateralViewRelationTargetContextAll<'input>>  {
		Rc::new(
			LateralViewRelationTargetContextAll::LateralViewRelationTargetDefaultContext(
				BaseParserRuleContext::copy_from(ctx,LateralViewRelationTargetDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LateralViewRelationTargetIncrementalContext<'input> = BaseParserRuleContext<'input,LateralViewRelationTargetIncrementalContextExt<'input>>;

pub trait LateralViewRelationTargetIncrementalContextAttrs<'input>: DatabricksParserContext<'input>{
	fn lateralViewRelationTarget(&self) -> Option<Rc<LateralViewRelationTargetContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn lateralView(&self) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> LateralViewRelationTargetIncrementalContextAttrs<'input> for LateralViewRelationTargetIncrementalContext<'input>{}

pub struct LateralViewRelationTargetIncrementalContextExt<'input>{
	base:LateralViewRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LateralViewRelationTargetIncrementalContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LateralViewRelationTargetIncrementalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LateralViewRelationTargetIncrementalContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_lateralViewRelationTargetIncremental(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_lateralViewRelationTargetIncremental(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LateralViewRelationTargetIncrementalContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_lateralViewRelationTargetIncremental(self);
	}
}

impl<'input> CustomRuleContext<'input> for LateralViewRelationTargetIncrementalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lateralViewRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lateralViewRelationTarget }
}

impl<'input> Borrow<LateralViewRelationTargetContextExt<'input>> for LateralViewRelationTargetIncrementalContext<'input>{
	fn borrow(&self) -> &LateralViewRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<LateralViewRelationTargetContextExt<'input>> for LateralViewRelationTargetIncrementalContext<'input>{
	fn borrow_mut(&mut self) -> &mut LateralViewRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> LateralViewRelationTargetContextAttrs<'input> for LateralViewRelationTargetIncrementalContext<'input> {}

impl<'input> LateralViewRelationTargetIncrementalContextExt<'input>{
	fn new(ctx: &dyn LateralViewRelationTargetContextAttrs<'input>) -> Rc<LateralViewRelationTargetContextAll<'input>>  {
		Rc::new(
			LateralViewRelationTargetContextAll::LateralViewRelationTargetIncrementalContext(
				BaseParserRuleContext::copy_from(ctx,LateralViewRelationTargetIncrementalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  lateralViewRelationTarget(&mut self,)
	-> Result<Rc<LateralViewRelationTargetContextAll<'input>>,ANTLRError> {
		self.lateralViewRelationTarget_rec(0)
	}

	fn lateralViewRelationTarget_rec(&mut self, _p: isize)
	-> Result<Rc<LateralViewRelationTargetContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = LateralViewRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 254, RULE_lateralViewRelationTarget, _p);
	    let mut _localctx: Rc<LateralViewRelationTargetContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 254;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			{
			let mut tmp = LateralViewRelationTargetDefaultContextExt::new(&**_localctx);
			recog.ctx = Some(tmp.clone());
			_localctx = tmp;
			_prevctx = _localctx.clone();


			/*InvokeRule extensibleRelation*/
			recog.base.set_state(2420);
			recog.extensibleRelation()?;

			recog.base.set_state(2425);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(315,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2421);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule extensibleRelation*/
					recog.base.set_state(2422);
					recog.extensibleRelation()?;

					}
					} 
				}
				recog.base.set_state(2427);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(315,&mut recog.base)?;
			}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2432);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(316,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					{
					/*recRuleLabeledAltStartAction*/
					let mut tmp = LateralViewRelationTargetIncrementalContextExt::new(&**LateralViewRelationTargetContextExt::new(_parentctx.clone(), _parentState));
					recog.push_new_recursion_context(tmp.clone(), _startState, RULE_lateralViewRelationTarget);
					_localctx = tmp;
					recog.base.set_state(2428);
					if !({recog.precpred(None, 1)}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
					}
					/*InvokeRule lateralView*/
					recog.base.set_state(2429);
					recog.lateralView()?;

					}
					} 
				}
				recog.base.set_state(2434);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(316,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- extensibleRelation ----------------
pub type ExtensibleRelationContextAll<'input> = ExtensibleRelationContext<'input>;


pub type ExtensibleRelationContext<'input> = BaseParserRuleContext<'input,ExtensibleRelationContextExt<'input>>;

#[derive(Clone)]
pub struct ExtensibleRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ExtensibleRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExtensibleRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_extensibleRelation(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_extensibleRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExtensibleRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_extensibleRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtensibleRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extensibleRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extensibleRelation }
}
antlr_rust::tid!{ExtensibleRelationContextExt<'a>}

impl<'input> ExtensibleRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtensibleRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtensibleRelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExtensibleRelationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ExtensibleRelationContextExt<'input>>{

fn extensibleRelationTarget(&self) -> Option<Rc<ExtensibleRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relationExtension(&self) -> Option<Rc<RelationExtensionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExtensibleRelationContextAttrs<'input> for ExtensibleRelationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn extensibleRelation(&mut self,)
	-> Result<Rc<ExtensibleRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExtensibleRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 256, RULE_extensibleRelation);
        let mut _localctx: Rc<ExtensibleRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule extensibleRelationTarget*/
			recog.base.set_state(2435);
			recog.extensibleRelationTarget_rec(0)?;

			recog.base.set_state(2437);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(317,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule relationExtension*/
					recog.base.set_state(2436);
					recog.relationExtension()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- extensibleRelationTarget ----------------
#[derive(Debug)]
pub enum ExtensibleRelationTargetContextAll<'input>{
	ExtensibleRelationTargetIncrementalContext(ExtensibleRelationTargetIncrementalContext<'input>),
	ExtensibleRelationTargetDefaultContext(ExtensibleRelationTargetDefaultContext<'input>),
Error(ExtensibleRelationTargetContext<'input>)
}
antlr_rust::tid!{ExtensibleRelationTargetContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ExtensibleRelationTargetContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for ExtensibleRelationTargetContextAll<'input>{}

impl<'input> Deref for ExtensibleRelationTargetContextAll<'input>{
	type Target = dyn ExtensibleRelationTargetContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ExtensibleRelationTargetContextAll::*;
		match self{
			ExtensibleRelationTargetIncrementalContext(inner) => inner,
			ExtensibleRelationTargetDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExtensibleRelationTargetContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExtensibleRelationTargetContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ExtensibleRelationTargetContext<'input> = BaseParserRuleContext<'input,ExtensibleRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct ExtensibleRelationTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ExtensibleRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExtensibleRelationTargetContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExtensibleRelationTargetContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ExtensibleRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extensibleRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extensibleRelationTarget }
}
antlr_rust::tid!{ExtensibleRelationTargetContextExt<'a>}

impl<'input> ExtensibleRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtensibleRelationTargetContextAll<'input>> {
		Rc::new(
		ExtensibleRelationTargetContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtensibleRelationTargetContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ExtensibleRelationTargetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ExtensibleRelationTargetContextExt<'input>>{


}

impl<'input> ExtensibleRelationTargetContextAttrs<'input> for ExtensibleRelationTargetContext<'input>{}

pub type ExtensibleRelationTargetIncrementalContext<'input> = BaseParserRuleContext<'input,ExtensibleRelationTargetIncrementalContextExt<'input>>;

pub trait ExtensibleRelationTargetIncrementalContextAttrs<'input>: DatabricksParserContext<'input>{
	fn extensibleRelationTarget(&self) -> Option<Rc<ExtensibleRelationTargetContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn relationExtension(&self) -> Option<Rc<RelationExtensionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExtensibleRelationTargetIncrementalContextAttrs<'input> for ExtensibleRelationTargetIncrementalContext<'input>{}

pub struct ExtensibleRelationTargetIncrementalContextExt<'input>{
	base:ExtensibleRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExtensibleRelationTargetIncrementalContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ExtensibleRelationTargetIncrementalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExtensibleRelationTargetIncrementalContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_extensibleRelationTargetIncremental(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_extensibleRelationTargetIncremental(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExtensibleRelationTargetIncrementalContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_extensibleRelationTargetIncremental(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtensibleRelationTargetIncrementalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extensibleRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extensibleRelationTarget }
}

impl<'input> Borrow<ExtensibleRelationTargetContextExt<'input>> for ExtensibleRelationTargetIncrementalContext<'input>{
	fn borrow(&self) -> &ExtensibleRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ExtensibleRelationTargetContextExt<'input>> for ExtensibleRelationTargetIncrementalContext<'input>{
	fn borrow_mut(&mut self) -> &mut ExtensibleRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> ExtensibleRelationTargetContextAttrs<'input> for ExtensibleRelationTargetIncrementalContext<'input> {}

impl<'input> ExtensibleRelationTargetIncrementalContextExt<'input>{
	fn new(ctx: &dyn ExtensibleRelationTargetContextAttrs<'input>) -> Rc<ExtensibleRelationTargetContextAll<'input>>  {
		Rc::new(
			ExtensibleRelationTargetContextAll::ExtensibleRelationTargetIncrementalContext(
				BaseParserRuleContext::copy_from(ctx,ExtensibleRelationTargetIncrementalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExtensibleRelationTargetDefaultContext<'input> = BaseParserRuleContext<'input,ExtensibleRelationTargetDefaultContextExt<'input>>;

pub trait ExtensibleRelationTargetDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn aliasedRelation(&self) -> Option<Rc<AliasedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LATERAL
	/// Returns `None` if there is no child corresponding to token LATERAL
	fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LATERAL, 0)
	}
}

impl<'input> ExtensibleRelationTargetDefaultContextAttrs<'input> for ExtensibleRelationTargetDefaultContext<'input>{}

pub struct ExtensibleRelationTargetDefaultContextExt<'input>{
	base:ExtensibleRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExtensibleRelationTargetDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ExtensibleRelationTargetDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExtensibleRelationTargetDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_extensibleRelationTargetDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_extensibleRelationTargetDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExtensibleRelationTargetDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_extensibleRelationTargetDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtensibleRelationTargetDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extensibleRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extensibleRelationTarget }
}

impl<'input> Borrow<ExtensibleRelationTargetContextExt<'input>> for ExtensibleRelationTargetDefaultContext<'input>{
	fn borrow(&self) -> &ExtensibleRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ExtensibleRelationTargetContextExt<'input>> for ExtensibleRelationTargetDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ExtensibleRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> ExtensibleRelationTargetContextAttrs<'input> for ExtensibleRelationTargetDefaultContext<'input> {}

impl<'input> ExtensibleRelationTargetDefaultContextExt<'input>{
	fn new(ctx: &dyn ExtensibleRelationTargetContextAttrs<'input>) -> Rc<ExtensibleRelationTargetContextAll<'input>>  {
		Rc::new(
			ExtensibleRelationTargetContextAll::ExtensibleRelationTargetDefaultContext(
				BaseParserRuleContext::copy_from(ctx,ExtensibleRelationTargetDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  extensibleRelationTarget(&mut self,)
	-> Result<Rc<ExtensibleRelationTargetContextAll<'input>>,ANTLRError> {
		self.extensibleRelationTarget_rec(0)
	}

	fn extensibleRelationTarget_rec(&mut self, _p: isize)
	-> Result<Rc<ExtensibleRelationTargetContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = ExtensibleRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 258, RULE_extensibleRelationTarget, _p);
	    let mut _localctx: Rc<ExtensibleRelationTargetContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 258;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			{
			let mut tmp = ExtensibleRelationTargetDefaultContextExt::new(&**_localctx);
			recog.ctx = Some(tmp.clone());
			_localctx = tmp;
			_prevctx = _localctx.clone();


			recog.base.set_state(2441);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(318,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2440);
					recog.base.match_token(LATERAL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule aliasedRelation*/
			recog.base.set_state(2443);
			recog.aliasedRelation()?;

			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2449);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(319,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					{
					/*recRuleLabeledAltStartAction*/
					let mut tmp = ExtensibleRelationTargetIncrementalContextExt::new(&**ExtensibleRelationTargetContextExt::new(_parentctx.clone(), _parentState));
					recog.push_new_recursion_context(tmp.clone(), _startState, RULE_extensibleRelationTarget);
					_localctx = tmp;
					recog.base.set_state(2445);
					if !({recog.precpred(None, 1)}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
					}
					/*InvokeRule relationExtension*/
					recog.base.set_state(2446);
					recog.relationExtension()?;

					}
					} 
				}
				recog.base.set_state(2451);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(319,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- relationExtension ----------------
#[derive(Debug)]
pub enum RelationExtensionContextAll<'input>{
	RelationExtensionPivotContext(RelationExtensionPivotContext<'input>),
	RelationExtensionJoinContext(RelationExtensionJoinContext<'input>),
Error(RelationExtensionContext<'input>)
}
antlr_rust::tid!{RelationExtensionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RelationExtensionContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for RelationExtensionContextAll<'input>{}

impl<'input> Deref for RelationExtensionContextAll<'input>{
	type Target = dyn RelationExtensionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RelationExtensionContextAll::*;
		match self{
			RelationExtensionPivotContext(inner) => inner,
			RelationExtensionJoinContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RelationExtensionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RelationExtensionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RelationExtensionContext<'input> = BaseParserRuleContext<'input,RelationExtensionContextExt<'input>>;

#[derive(Clone)]
pub struct RelationExtensionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for RelationExtensionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RelationExtensionContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RelationExtensionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RelationExtensionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationExtension }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationExtension }
}
antlr_rust::tid!{RelationExtensionContextExt<'a>}

impl<'input> RelationExtensionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationExtensionContextAll<'input>> {
		Rc::new(
		RelationExtensionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationExtensionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RelationExtensionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<RelationExtensionContextExt<'input>>{


}

impl<'input> RelationExtensionContextAttrs<'input> for RelationExtensionContext<'input>{}

pub type RelationExtensionPivotContext<'input> = BaseParserRuleContext<'input,RelationExtensionPivotContextExt<'input>>;

pub trait RelationExtensionPivotContextAttrs<'input>: DatabricksParserContext<'input>{
	fn pivotOperator(&self) -> Option<Rc<PivotOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RelationExtensionPivotContextAttrs<'input> for RelationExtensionPivotContext<'input>{}

pub struct RelationExtensionPivotContextExt<'input>{
	base:RelationExtensionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RelationExtensionPivotContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RelationExtensionPivotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RelationExtensionPivotContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_relationExtensionPivot(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_relationExtensionPivot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RelationExtensionPivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_relationExtensionPivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationExtensionPivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationExtension }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationExtension }
}

impl<'input> Borrow<RelationExtensionContextExt<'input>> for RelationExtensionPivotContext<'input>{
	fn borrow(&self) -> &RelationExtensionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationExtensionContextExt<'input>> for RelationExtensionPivotContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationExtensionContextExt<'input> { &mut self.base }
}

impl<'input> RelationExtensionContextAttrs<'input> for RelationExtensionPivotContext<'input> {}

impl<'input> RelationExtensionPivotContextExt<'input>{
	fn new(ctx: &dyn RelationExtensionContextAttrs<'input>) -> Rc<RelationExtensionContextAll<'input>>  {
		Rc::new(
			RelationExtensionContextAll::RelationExtensionPivotContext(
				BaseParserRuleContext::copy_from(ctx,RelationExtensionPivotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RelationExtensionJoinContext<'input> = BaseParserRuleContext<'input,RelationExtensionJoinContextExt<'input>>;

pub trait RelationExtensionJoinContextAttrs<'input>: DatabricksParserContext<'input>{
	fn joinRelation(&self) -> Option<Rc<JoinRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RelationExtensionJoinContextAttrs<'input> for RelationExtensionJoinContext<'input>{}

pub struct RelationExtensionJoinContextExt<'input>{
	base:RelationExtensionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RelationExtensionJoinContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RelationExtensionJoinContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RelationExtensionJoinContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_relationExtensionJoin(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_relationExtensionJoin(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RelationExtensionJoinContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_relationExtensionJoin(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationExtensionJoinContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationExtension }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationExtension }
}

impl<'input> Borrow<RelationExtensionContextExt<'input>> for RelationExtensionJoinContext<'input>{
	fn borrow(&self) -> &RelationExtensionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationExtensionContextExt<'input>> for RelationExtensionJoinContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationExtensionContextExt<'input> { &mut self.base }
}

impl<'input> RelationExtensionContextAttrs<'input> for RelationExtensionJoinContext<'input> {}

impl<'input> RelationExtensionJoinContextExt<'input>{
	fn new(ctx: &dyn RelationExtensionContextAttrs<'input>) -> Rc<RelationExtensionContextAll<'input>>  {
		Rc::new(
			RelationExtensionContextAll::RelationExtensionJoinContext(
				BaseParserRuleContext::copy_from(ctx,RelationExtensionJoinContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relationExtension(&mut self,)
	-> Result<Rc<RelationExtensionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationExtensionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 260, RULE_relationExtension);
        let mut _localctx: Rc<RelationExtensionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2454);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ANTI | CROSS | FULL | INNER | JOIN | LEFT | NATURAL | RIGHT | SEMI 
				=> {
					let tmp = RelationExtensionJoinContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule joinRelation*/
					recog.base.set_state(2452);
					recog.joinRelation()?;

					}
				}

			 PIVOT | UNPIVOT 
				=> {
					let tmp = RelationExtensionPivotContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule pivotOperator*/
					recog.base.set_state(2453);
					recog.pivotOperator()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinRelation ----------------
#[derive(Debug)]
pub enum JoinRelationContextAll<'input>{
	JoinRelationNaturalContext(JoinRelationNaturalContext<'input>),
	JoinRelationDefaultContext(JoinRelationDefaultContext<'input>),
Error(JoinRelationContext<'input>)
}
antlr_rust::tid!{JoinRelationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for JoinRelationContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for JoinRelationContextAll<'input>{}

impl<'input> Deref for JoinRelationContextAll<'input>{
	type Target = dyn JoinRelationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use JoinRelationContextAll::*;
		match self{
			JoinRelationNaturalContext(inner) => inner,
			JoinRelationDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JoinRelationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JoinRelationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type JoinRelationContext<'input> = BaseParserRuleContext<'input,JoinRelationContextExt<'input>>;

#[derive(Clone)]
pub struct JoinRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for JoinRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JoinRelationContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JoinRelationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for JoinRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinRelation }
}
antlr_rust::tid!{JoinRelationContextExt<'a>}

impl<'input> JoinRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinRelationContextAll<'input>> {
		Rc::new(
		JoinRelationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinRelationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait JoinRelationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<JoinRelationContextExt<'input>>{


}

impl<'input> JoinRelationContextAttrs<'input> for JoinRelationContext<'input>{}

pub type JoinRelationNaturalContext<'input> = BaseParserRuleContext<'input,JoinRelationNaturalContextExt<'input>>;

pub trait JoinRelationNaturalContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NATURAL
	/// Returns `None` if there is no child corresponding to token NATURAL
	fn NATURAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NATURAL, 0)
	}
	fn joinType(&self) -> Option<Rc<JoinTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token JOIN
	/// Returns `None` if there is no child corresponding to token JOIN
	fn JOIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(JOIN, 0)
	}
	fn aliasedRelation(&self) -> Option<Rc<AliasedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LATERAL
	/// Returns `None` if there is no child corresponding to token LATERAL
	fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LATERAL, 0)
	}
}

impl<'input> JoinRelationNaturalContextAttrs<'input> for JoinRelationNaturalContext<'input>{}

pub struct JoinRelationNaturalContextExt<'input>{
	base:JoinRelationContextExt<'input>,
	pub right: Option<Rc<AliasedRelationContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JoinRelationNaturalContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for JoinRelationNaturalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JoinRelationNaturalContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_joinRelationNatural(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_joinRelationNatural(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JoinRelationNaturalContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_joinRelationNatural(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinRelationNaturalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinRelation }
}

impl<'input> Borrow<JoinRelationContextExt<'input>> for JoinRelationNaturalContext<'input>{
	fn borrow(&self) -> &JoinRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<JoinRelationContextExt<'input>> for JoinRelationNaturalContext<'input>{
	fn borrow_mut(&mut self) -> &mut JoinRelationContextExt<'input> { &mut self.base }
}

impl<'input> JoinRelationContextAttrs<'input> for JoinRelationNaturalContext<'input> {}

impl<'input> JoinRelationNaturalContextExt<'input>{
	fn new(ctx: &dyn JoinRelationContextAttrs<'input>) -> Rc<JoinRelationContextAll<'input>>  {
		Rc::new(
			JoinRelationContextAll::JoinRelationNaturalContext(
				BaseParserRuleContext::copy_from(ctx,JoinRelationNaturalContextExt{
        			right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JoinRelationDefaultContext<'input> = BaseParserRuleContext<'input,JoinRelationDefaultContextExt<'input>>;

pub trait JoinRelationDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token JOIN
	/// Returns `None` if there is no child corresponding to token JOIN
	fn JOIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(JOIN, 0)
	}
	fn aliasedRelation(&self) -> Option<Rc<AliasedRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn joinType(&self) -> Option<Rc<JoinTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LATERAL
	/// Returns `None` if there is no child corresponding to token LATERAL
	fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LATERAL, 0)
	}
	fn joinCriteria(&self) -> Option<Rc<JoinCriteriaContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> JoinRelationDefaultContextAttrs<'input> for JoinRelationDefaultContext<'input>{}

pub struct JoinRelationDefaultContextExt<'input>{
	base:JoinRelationContextExt<'input>,
	pub right: Option<Rc<AliasedRelationContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JoinRelationDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for JoinRelationDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JoinRelationDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_joinRelationDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_joinRelationDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JoinRelationDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_joinRelationDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinRelationDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinRelation }
}

impl<'input> Borrow<JoinRelationContextExt<'input>> for JoinRelationDefaultContext<'input>{
	fn borrow(&self) -> &JoinRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<JoinRelationContextExt<'input>> for JoinRelationDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut JoinRelationContextExt<'input> { &mut self.base }
}

impl<'input> JoinRelationContextAttrs<'input> for JoinRelationDefaultContext<'input> {}

impl<'input> JoinRelationDefaultContextExt<'input>{
	fn new(ctx: &dyn JoinRelationContextAttrs<'input>) -> Rc<JoinRelationContextAll<'input>>  {
		Rc::new(
			JoinRelationContextAll::JoinRelationDefaultContext(
				BaseParserRuleContext::copy_from(ctx,JoinRelationDefaultContextExt{
        			right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinRelation(&mut self,)
	-> Result<Rc<JoinRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 262, RULE_joinRelation);
        let mut _localctx: Rc<JoinRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2473);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ANTI | CROSS | FULL | INNER | JOIN | LEFT | RIGHT | SEMI 
				=> {
					let tmp = JoinRelationDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					{
					/*InvokeRule joinType*/
					recog.base.set_state(2456);
					recog.joinType()?;

					}
					recog.base.set_state(2457);
					recog.base.match_token(JOIN,&mut recog.err_handler)?;

					recog.base.set_state(2459);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(321,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2458);
							recog.base.match_token(LATERAL,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule aliasedRelation*/
					recog.base.set_state(2461);
					let tmp = recog.aliasedRelation()?;
					if let JoinRelationContextAll::JoinRelationDefaultContext(ctx) = cast_mut::<_,JoinRelationContextAll >(&mut _localctx){
					ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2463);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(322,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule joinCriteria*/
							recog.base.set_state(2462);
							recog.joinCriteria()?;

							}
						}

						_ => {}
					}
					}
				}

			 NATURAL 
				=> {
					let tmp = JoinRelationNaturalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2465);
					recog.base.match_token(NATURAL,&mut recog.err_handler)?;

					/*InvokeRule joinType*/
					recog.base.set_state(2466);
					recog.joinType()?;

					recog.base.set_state(2467);
					recog.base.match_token(JOIN,&mut recog.err_handler)?;

					recog.base.set_state(2469);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(323,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2468);
							recog.base.match_token(LATERAL,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule aliasedRelation*/
					recog.base.set_state(2471);
					let tmp = recog.aliasedRelation()?;
					if let JoinRelationContextAll::JoinRelationNaturalContext(ctx) = cast_mut::<_,JoinRelationContextAll >(&mut _localctx){
					ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotedRelation ----------------
pub type PivotedRelationContextAll<'input> = PivotedRelationContext<'input>;


pub type PivotedRelationContext<'input> = BaseParserRuleContext<'input,PivotedRelationContextExt<'input>>;

#[derive(Clone)]
pub struct PivotedRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PivotedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotedRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotedRelation(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_pivotedRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotedRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pivotedRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotedRelation }
}
antlr_rust::tid!{PivotedRelationContextExt<'a>}

impl<'input> PivotedRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotedRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotedRelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotedRelationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PivotedRelationContextExt<'input>>{

fn pivotedRelationTarget(&self) -> Option<Rc<PivotedRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn pivotOperator_all(&self) ->  Vec<Rc<PivotOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn pivotOperator(&self, i: usize) -> Option<Rc<PivotOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PivotedRelationContextAttrs<'input> for PivotedRelationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotedRelation(&mut self,)
	-> Result<Rc<PivotedRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotedRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 264, RULE_pivotedRelation);
        let mut _localctx: Rc<PivotedRelationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule pivotedRelationTarget*/
			recog.base.set_state(2475);
			recog.pivotedRelationTarget()?;

			recog.base.set_state(2479);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==PIVOT || _la==UNPIVOT {
				{
				{
				/*InvokeRule pivotOperator*/
				recog.base.set_state(2476);
				recog.pivotOperator()?;

				}
				}
				recog.base.set_state(2481);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotAggregates ----------------
pub type PivotAggregatesContextAll<'input> = PivotAggregatesContext<'input>;


pub type PivotAggregatesContext<'input> = BaseParserRuleContext<'input,PivotAggregatesContextExt<'input>>;

#[derive(Clone)]
pub struct PivotAggregatesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PivotAggregatesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotAggregatesContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotAggregates(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_pivotAggregates(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotAggregatesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pivotAggregates(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotAggregatesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotAggregates }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotAggregates }
}
antlr_rust::tid!{PivotAggregatesContextExt<'a>}

impl<'input> PivotAggregatesContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotAggregatesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotAggregatesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotAggregatesContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PivotAggregatesContextExt<'input>>{

fn namedExpressionSeq(&self) -> Option<Rc<NamedExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PivotAggregatesContextAttrs<'input> for PivotAggregatesContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotAggregates(&mut self,)
	-> Result<Rc<PivotAggregatesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotAggregatesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 266, RULE_pivotAggregates);
        let mut _localctx: Rc<PivotAggregatesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpressionSeq*/
			recog.base.set_state(2482);
			recog.namedExpressionSeq()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotFrom ----------------
pub type PivotFromContextAll<'input> = PivotFromContext<'input>;


pub type PivotFromContext<'input> = BaseParserRuleContext<'input,PivotFromContextExt<'input>>;

#[derive(Clone)]
pub struct PivotFromContextExt<'input>{
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub identifiers:Vec<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PivotFromContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotFromContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotFrom(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_pivotFrom(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotFromContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pivotFrom(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotFromContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotFrom }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotFrom }
}
antlr_rust::tid!{PivotFromContextExt<'a>}

impl<'input> PivotFromContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotFromContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotFromContextExt{
				identifier: None, 
				identifiers: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotFromContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PivotFromContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PivotFromContextAttrs<'input> for PivotFromContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotFrom(&mut self,)
	-> Result<Rc<PivotFromContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotFromContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 268, RULE_pivotFrom);
        let mut _localctx: Rc<PivotFromContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2496);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
			 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
			 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
			 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
			 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
			 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
			 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
			 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
			 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
			 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
			 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
			 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
			 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
			 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT | EXTENDED |
			 EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT | FIRST |
			 FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM | FROM_JSON |
			 FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT | GROUP | GROUPING |
			 HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY | IF | IGNORE | IMMEDIATE |
			 IMPORT | IN | INCLUDE | INDEX | INDEXES | INNER | INPATH | INPUT | INPUTFORMAT |
			 INSERT | INTERSECT | INTERVAL | INT | INTEGER | INTO | INVOKER | IS |
			 ITEMS | ILIKE | JOIN | KEY | KEYS | LANGUAGE | LAST | LATERAL | LAZY |
			 LEADING | LEFT | LIKE | LIMIT | LINES | LIST | LISTAGG | LIVE | LOAD |
			 LOCAL | LOCATION | LOCK | LOCKS | LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES |
			 MATCHED | MATERIALIZED | MERGE | MICROSECOND | MICROSECONDS | MILLISECOND |
			 MILLISECONDS | MINUS_KW | MINUTE | MINUTES | MODE | MODIFIES | MONTH |
			 MONTHS | MSCK | NAME | NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND |
			 NANOSECONDS | NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF |
			 OFFSET | ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT |
			 OUTER | OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
			 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
			 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
			 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL | RECORDREADER |
			 RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP | REFERENCE | REFERENCES |
			 REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE | RESET | RESPECT |
			 RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE | ROLE | ROLES |
			 ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES | SESSION_USER |
			 SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT | SOME | SORT |
			 SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS | STORED | STRATIFY |
			 STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING | SYNC | SYSTEM_TIME |
			 SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE | TARGET | TBLPROPERTIES |
			 TEMP | TEMPORARY | TERMINATED | STRING_KW | THEN | TIME | TIMEDIFF |
			 TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF | TIMESTAMP_LTZ | TIMESTAMP_NTZ |
			 TINYINT | TO | TOUCH | TRAILING | TRANSACTION | TRANSACTIONS | TRANSFORM |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE | UNARCHIVE | UNBOUNDED | UNCACHE |
			 UNION | UNIQUE | UNKNOWN | UNLOCK | UNPIVOT | UNSET | UPDATE | USE |
			 USER | USING | VALUES | VAR | VARCHAR | VARIANT | VERSION | VIEW | VIEWS |
			 VOID | WEEK | WEEKS | WHEN | WHERE | WHILE | WINDOW | WITH | WITHIN |
			 YEAR | YEARS | ZONE | IDENTIFIER | BACKQUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2484);
					let tmp = recog.identifier()?;
					 cast_mut::<_,PivotFromContext >(&mut _localctx).identifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,PivotFromContext >(&mut _localctx).identifier.clone().unwrap()
					 ;
					 cast_mut::<_,PivotFromContext >(&mut _localctx).identifiers.push(temp);
					  
					}
				}

			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2485);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(2486);
					let tmp = recog.identifier()?;
					 cast_mut::<_,PivotFromContext >(&mut _localctx).identifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,PivotFromContext >(&mut _localctx).identifier.clone().unwrap()
					 ;
					 cast_mut::<_,PivotFromContext >(&mut _localctx).identifiers.push(temp);
					  
					recog.base.set_state(2491);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2487);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(2488);
						let tmp = recog.identifier()?;
						 cast_mut::<_,PivotFromContext >(&mut _localctx).identifier = Some(tmp.clone());
						  

						let temp =  cast_mut::<_,PivotFromContext >(&mut _localctx).identifier.clone().unwrap()
						 ;
						 cast_mut::<_,PivotFromContext >(&mut _localctx).identifiers.push(temp);
						  
						}
						}
						recog.base.set_state(2493);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2494);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotInto ----------------
#[derive(Debug)]
pub enum PivotIntoContextAll<'input>{
	PivotIntoNamedExpressionContext(PivotIntoNamedExpressionContext<'input>),
Error(PivotIntoContext<'input>)
}
antlr_rust::tid!{PivotIntoContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotIntoContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PivotIntoContextAll<'input>{}

impl<'input> Deref for PivotIntoContextAll<'input>{
	type Target = dyn PivotIntoContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotIntoContextAll::*;
		match self{
			PivotIntoNamedExpressionContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotIntoContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotIntoContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotIntoContext<'input> = BaseParserRuleContext<'input,PivotIntoContextExt<'input>>;

#[derive(Clone)]
pub struct PivotIntoContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PivotIntoContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotIntoContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotIntoContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotIntoContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotInto }
}
antlr_rust::tid!{PivotIntoContextExt<'a>}

impl<'input> PivotIntoContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotIntoContextAll<'input>> {
		Rc::new(
		PivotIntoContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotIntoContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotIntoContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PivotIntoContextExt<'input>>{


}

impl<'input> PivotIntoContextAttrs<'input> for PivotIntoContext<'input>{}

pub type PivotIntoNamedExpressionContext<'input> = BaseParserRuleContext<'input,PivotIntoNamedExpressionContextExt<'input>>;

pub trait PivotIntoNamedExpressionContextAttrs<'input>: DatabricksParserContext<'input>{
	fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PivotIntoNamedExpressionContextAttrs<'input> for PivotIntoNamedExpressionContext<'input>{}

pub struct PivotIntoNamedExpressionContextExt<'input>{
	base:PivotIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotIntoNamedExpressionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PivotIntoNamedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotIntoNamedExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivotIntoNamedExpression(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_pivotIntoNamedExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotIntoNamedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pivotIntoNamedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotIntoNamedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotInto }
}

impl<'input> Borrow<PivotIntoContextExt<'input>> for PivotIntoNamedExpressionContext<'input>{
	fn borrow(&self) -> &PivotIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotIntoContextExt<'input>> for PivotIntoNamedExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotIntoContextExt<'input> { &mut self.base }
}

impl<'input> PivotIntoContextAttrs<'input> for PivotIntoNamedExpressionContext<'input> {}

impl<'input> PivotIntoNamedExpressionContextExt<'input>{
	fn new(ctx: &dyn PivotIntoContextAttrs<'input>) -> Rc<PivotIntoContextAll<'input>>  {
		Rc::new(
			PivotIntoContextAll::PivotIntoNamedExpressionContext(
				BaseParserRuleContext::copy_from(ctx,PivotIntoNamedExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotInto(&mut self,)
	-> Result<Rc<PivotIntoContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotIntoContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 270, RULE_pivotInto);
        let mut _localctx: Rc<PivotIntoContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let tmp = PivotIntoNamedExpressionContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(2498);
			recog.namedExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotAsAlias ----------------
pub type PivotAsAliasContextAll<'input> = PivotAsAliasContext<'input>;


pub type PivotAsAliasContext<'input> = BaseParserRuleContext<'input,PivotAsAliasContextExt<'input>>;

#[derive(Clone)]
pub struct PivotAsAliasContextExt<'input>{
	pub alias: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PivotAsAliasContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotAsAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotAsAlias(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_pivotAsAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotAsAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pivotAsAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotAsAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotAsAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotAsAlias }
}
antlr_rust::tid!{PivotAsAliasContextExt<'a>}

impl<'input> PivotAsAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotAsAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotAsAliasContextExt{
				alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotAsAliasContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PivotAsAliasContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> PivotAsAliasContextAttrs<'input> for PivotAsAliasContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotAsAlias(&mut self,)
	-> Result<Rc<PivotAsAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotAsAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 272, RULE_pivotAsAlias);
        let mut _localctx: Rc<PivotAsAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2504);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(329,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2501);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(328,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2500);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifier*/
					recog.base.set_state(2503);
					let tmp = recog.identifier()?;
					 cast_mut::<_,PivotAsAliasContext >(&mut _localctx).alias = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleColumnUnpivot ----------------
pub type SingleColumnUnpivotContextAll<'input> = SingleColumnUnpivotContext<'input>;


pub type SingleColumnUnpivotContext<'input> = BaseParserRuleContext<'input,SingleColumnUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct SingleColumnUnpivotContextExt<'input>{
	pub valuesColumn: Option<Rc<IdentifierContextAll<'input>>>,
	pub nameColumn: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for SingleColumnUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SingleColumnUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleColumnUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_singleColumnUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SingleColumnUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_singleColumnUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleColumnUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleColumnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleColumnUnpivot }
}
antlr_rust::tid!{SingleColumnUnpivotContextExt<'a>}

impl<'input> SingleColumnUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleColumnUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleColumnUnpivotContextExt{
				valuesColumn: None, nameColumn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleColumnUnpivotContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<SingleColumnUnpivotContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnsToUnpivot(&self) -> Option<Rc<ColumnsToUnpivotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SingleColumnUnpivotContextAttrs<'input> for SingleColumnUnpivotContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleColumnUnpivot(&mut self,)
	-> Result<Rc<SingleColumnUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleColumnUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 274, RULE_singleColumnUnpivot);
        let mut _localctx: Rc<SingleColumnUnpivotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2506);
			let tmp = recog.identifier()?;
			 cast_mut::<_,SingleColumnUnpivotContext >(&mut _localctx).valuesColumn = Some(tmp.clone());
			  

			recog.base.set_state(2507);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(2508);
			let tmp = recog.identifier()?;
			 cast_mut::<_,SingleColumnUnpivotContext >(&mut _localctx).nameColumn = Some(tmp.clone());
			  

			recog.base.set_state(2509);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(2510);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnsToUnpivot*/
			recog.base.set_state(2511);
			recog.columnsToUnpivot()?;

			recog.base.set_state(2512);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnsToUnpivot ----------------
pub type ColumnsToUnpivotContextAll<'input> = ColumnsToUnpivotContext<'input>;


pub type ColumnsToUnpivotContext<'input> = BaseParserRuleContext<'input,ColumnsToUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnsToUnpivotContextExt<'input>{
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub unpivotCol:Vec<Rc<IdentifierContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnsToUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnsToUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnsToUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnsToUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnsToUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnsToUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnsToUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnsToUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnsToUnpivot }
}
antlr_rust::tid!{ColumnsToUnpivotContextExt<'a>}

impl<'input> ColumnsToUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnsToUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnsToUnpivotContextExt{
				tail: None, 
				identifier: None, 
				unpivotCol: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnsToUnpivotContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnsToUnpivotContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn unpivotAlias_all(&self) ->  Vec<Rc<UnpivotAliasContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unpivotAlias(&self, i: usize) -> Option<Rc<UnpivotAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves all `TerminalNode`s corresponding to token AS in current rule
fn AS_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token AS, starting from 0.
/// Returns `None` if number of children corresponding to token AS is less or equal than `i`.
fn AS(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, i)
}

}

impl<'input> ColumnsToUnpivotContextAttrs<'input> for ColumnsToUnpivotContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnsToUnpivot(&mut self,)
	-> Result<Rc<ColumnsToUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnsToUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 276, RULE_columnsToUnpivot);
        let mut _localctx: Rc<ColumnsToUnpivotContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2514);
			let tmp = recog.identifier()?;
			 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier.clone().unwrap()
			 ;
			 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).unpivotCol.push(temp);
			  
			recog.base.set_state(2519);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
				{
				recog.base.set_state(2516);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(330,&mut recog.base)? {
					x if x == 1=>{
						{
						recog.base.set_state(2515);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					_ => {}
				}
				/*InvokeRule unpivotAlias*/
				recog.base.set_state(2518);
				recog.unpivotAlias()?;

				}
			}

			recog.base.set_state(2531);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(334,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2521);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(2522);
					let tmp = recog.identifier()?;
					 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).identifier.clone().unwrap()
					 ;
					 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).unpivotCol.push(temp);
					  
					recog.base.set_state(2527);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if ((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						recog.base.set_state(2524);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(332,&mut recog.base)? {
							x if x == 1=>{
								{
								recog.base.set_state(2523);
								recog.base.match_token(AS,&mut recog.err_handler)?;

								}
							}

							_ => {}
						}
						/*InvokeRule unpivotAlias*/
						recog.base.set_state(2526);
						recog.unpivotAlias()?;

						}
					}

					}
					} 
				}
				recog.base.set_state(2533);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(334,&mut recog.base)?;
			}
			recog.base.set_state(2535);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2534);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnsToUnpivotContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotAlias ----------------
pub type UnpivotAliasContextAll<'input> = UnpivotAliasContext<'input>;


pub type UnpivotAliasContext<'input> = BaseParserRuleContext<'input,UnpivotAliasContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for UnpivotAliasContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UnpivotAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotAlias(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_unpivotAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UnpivotAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_unpivotAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotAlias }
}
antlr_rust::tid!{UnpivotAliasContextExt<'a>}

impl<'input> UnpivotAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotAliasContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<UnpivotAliasContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnpivotAliasContextAttrs<'input> for UnpivotAliasContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotAlias(&mut self,)
	-> Result<Rc<UnpivotAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 278, RULE_unpivotAlias);
        let mut _localctx: Rc<UnpivotAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2537);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiColumnUnpivot ----------------
pub type MultiColumnUnpivotContextAll<'input> = MultiColumnUnpivotContext<'input>;


pub type MultiColumnUnpivotContext<'input> = BaseParserRuleContext<'input,MultiColumnUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct MultiColumnUnpivotContextExt<'input>{
	pub nameColumn: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for MultiColumnUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MultiColumnUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiColumnUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_multiColumnUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MultiColumnUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_multiColumnUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiColumnUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiColumnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiColumnUnpivot }
}
antlr_rust::tid!{MultiColumnUnpivotContextExt<'a>}

impl<'input> MultiColumnUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiColumnUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiColumnUnpivotContextExt{
				nameColumn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiColumnUnpivotContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<MultiColumnUnpivotContextExt<'input>>{

fn valueColumnSet(&self) -> Option<Rc<ValueColumnSetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnSetsToUnpivot(&self) -> Option<Rc<ColumnSetsToUnpivotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MultiColumnUnpivotContextAttrs<'input> for MultiColumnUnpivotContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiColumnUnpivot(&mut self,)
	-> Result<Rc<MultiColumnUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiColumnUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 280, RULE_multiColumnUnpivot);
        let mut _localctx: Rc<MultiColumnUnpivotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule valueColumnSet*/
			recog.base.set_state(2539);
			recog.valueColumnSet()?;

			recog.base.set_state(2540);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(2541);
			let tmp = recog.identifier()?;
			 cast_mut::<_,MultiColumnUnpivotContext >(&mut _localctx).nameColumn = Some(tmp.clone());
			  

			recog.base.set_state(2542);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(2543);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnSetsToUnpivot*/
			recog.base.set_state(2544);
			recog.columnSetsToUnpivot()?;

			recog.base.set_state(2545);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valueColumnSet ----------------
pub type ValueColumnSetContextAll<'input> = ValueColumnSetContext<'input>;


pub type ValueColumnSetContext<'input> = BaseParserRuleContext<'input,ValueColumnSetContextExt<'input>>;

#[derive(Clone)]
pub struct ValueColumnSetContextExt<'input>{
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub valueColumn:Vec<Rc<IdentifierContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ValueColumnSetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ValueColumnSetContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_valueColumnSet(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_valueColumnSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ValueColumnSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_valueColumnSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for ValueColumnSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueColumnSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueColumnSet }
}
antlr_rust::tid!{ValueColumnSetContextExt<'a>}

impl<'input> ValueColumnSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValueColumnSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValueColumnSetContextExt{
				tail: None, 
				identifier: None, 
				valueColumn: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ValueColumnSetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ValueColumnSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ValueColumnSetContextAttrs<'input> for ValueColumnSetContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn valueColumnSet(&mut self,)
	-> Result<Rc<ValueColumnSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ValueColumnSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 282, RULE_valueColumnSet);
        let mut _localctx: Rc<ValueColumnSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2547);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(2548);
			let tmp = recog.identifier()?;
			 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).identifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ValueColumnSetContext >(&mut _localctx).identifier.clone().unwrap()
			 ;
			 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).valueColumn.push(temp);
			  
			recog.base.set_state(2553);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(336,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2549);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(2550);
					let tmp = recog.identifier()?;
					 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).identifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ValueColumnSetContext >(&mut _localctx).identifier.clone().unwrap()
					 ;
					 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).valueColumn.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2555);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(336,&mut recog.base)?;
			}
			recog.base.set_state(2557);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2556);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ValueColumnSetContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			recog.base.set_state(2559);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotColumnSet ----------------
pub type UnpivotColumnSetContextAll<'input> = UnpivotColumnSetContext<'input>;


pub type UnpivotColumnSetContext<'input> = BaseParserRuleContext<'input,UnpivotColumnSetContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotColumnSetContextExt<'input>{
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub unpivotColumns:Vec<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for UnpivotColumnSetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UnpivotColumnSetContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotColumnSet(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_unpivotColumnSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UnpivotColumnSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_unpivotColumnSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotColumnSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotColumnSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotColumnSet }
}
antlr_rust::tid!{UnpivotColumnSetContextExt<'a>}

impl<'input> UnpivotColumnSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotColumnSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotColumnSetContextExt{
				identifier: None, 
				unpivotColumns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotColumnSetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<UnpivotColumnSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn unpivotAlias(&self) -> Option<Rc<UnpivotAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> UnpivotColumnSetContextAttrs<'input> for UnpivotColumnSetContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotColumnSet(&mut self,)
	-> Result<Rc<UnpivotColumnSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotColumnSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 284, RULE_unpivotColumnSet);
        let mut _localctx: Rc<UnpivotColumnSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2561);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(2562);
			let tmp = recog.identifier()?;
			 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).identifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).identifier.clone().unwrap()
			 ;
			 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumns.push(temp);
			  
			recog.base.set_state(2567);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2563);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule identifier*/
				recog.base.set_state(2564);
				let tmp = recog.identifier()?;
				 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).identifier = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).identifier.clone().unwrap()
				 ;
				 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumns.push(temp);
				  
				}
				}
				recog.base.set_state(2569);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2570);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2575);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
				{
				recog.base.set_state(2572);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(339,&mut recog.base)? {
					x if x == 1=>{
						{
						recog.base.set_state(2571);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					_ => {}
				}
				/*InvokeRule unpivotAlias*/
				recog.base.set_state(2574);
				recog.unpivotAlias()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnSetsToUnpivot ----------------
pub type ColumnSetsToUnpivotContextAll<'input> = ColumnSetsToUnpivotContext<'input>;


pub type ColumnSetsToUnpivotContext<'input> = BaseParserRuleContext<'input,ColumnSetsToUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnSetsToUnpivotContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnSetsToUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnSetsToUnpivotContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnSetsToUnpivot(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnSetsToUnpivot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnSetsToUnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnSetsToUnpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnSetsToUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnSetsToUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnSetsToUnpivot }
}
antlr_rust::tid!{ColumnSetsToUnpivotContextExt<'a>}

impl<'input> ColumnSetsToUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnSetsToUnpivotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnSetsToUnpivotContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnSetsToUnpivotContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnSetsToUnpivotContextExt<'input>>{

fn unpivotColumnSet_all(&self) ->  Vec<Rc<UnpivotColumnSetContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unpivotColumnSet(&self, i: usize) -> Option<Rc<UnpivotColumnSetContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnSetsToUnpivotContextAttrs<'input> for ColumnSetsToUnpivotContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnSetsToUnpivot(&mut self,)
	-> Result<Rc<ColumnSetsToUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnSetsToUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 286, RULE_columnSetsToUnpivot);
        let mut _localctx: Rc<ColumnSetsToUnpivotContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule unpivotColumnSet*/
			recog.base.set_state(2577);
			recog.unpivotColumnSet()?;

			recog.base.set_state(2582);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(341,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2578);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule unpivotColumnSet*/
					recog.base.set_state(2579);
					recog.unpivotColumnSet()?;

					}
					} 
				}
				recog.base.set_state(2584);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(341,&mut recog.base)?;
			}
			recog.base.set_state(2586);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2585);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnUnpivot ----------------
#[derive(Debug)]
pub enum ColumnUnpivotContextAll<'input>{
	MultiColumnUnpivotDefaultContext(MultiColumnUnpivotDefaultContext<'input>),
	SingleColumnUnpivotDefaultContext(SingleColumnUnpivotDefaultContext<'input>),
Error(ColumnUnpivotContext<'input>)
}
antlr_rust::tid!{ColumnUnpivotContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ColumnUnpivotContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for ColumnUnpivotContextAll<'input>{}

impl<'input> Deref for ColumnUnpivotContextAll<'input>{
	type Target = dyn ColumnUnpivotContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ColumnUnpivotContextAll::*;
		match self{
			MultiColumnUnpivotDefaultContext(inner) => inner,
			SingleColumnUnpivotDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnUnpivotContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnUnpivotContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ColumnUnpivotContext<'input> = BaseParserRuleContext<'input,ColumnUnpivotContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnUnpivotContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnUnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnUnpivotContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnUnpivotContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ColumnUnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnUnpivot }
}
antlr_rust::tid!{ColumnUnpivotContextExt<'a>}

impl<'input> ColumnUnpivotContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnUnpivotContextAll<'input>> {
		Rc::new(
		ColumnUnpivotContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnUnpivotContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ColumnUnpivotContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnUnpivotContextExt<'input>>{


}

impl<'input> ColumnUnpivotContextAttrs<'input> for ColumnUnpivotContext<'input>{}

pub type MultiColumnUnpivotDefaultContext<'input> = BaseParserRuleContext<'input,MultiColumnUnpivotDefaultContextExt<'input>>;

pub trait MultiColumnUnpivotDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn multiColumnUnpivot(&self) -> Option<Rc<MultiColumnUnpivotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MultiColumnUnpivotDefaultContextAttrs<'input> for MultiColumnUnpivotDefaultContext<'input>{}

pub struct MultiColumnUnpivotDefaultContextExt<'input>{
	base:ColumnUnpivotContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MultiColumnUnpivotDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for MultiColumnUnpivotDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MultiColumnUnpivotDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_multiColumnUnpivotDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_multiColumnUnpivotDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MultiColumnUnpivotDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_multiColumnUnpivotDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiColumnUnpivotDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnUnpivot }
}

impl<'input> Borrow<ColumnUnpivotContextExt<'input>> for MultiColumnUnpivotDefaultContext<'input>{
	fn borrow(&self) -> &ColumnUnpivotContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnUnpivotContextExt<'input>> for MultiColumnUnpivotDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnUnpivotContextExt<'input> { &mut self.base }
}

impl<'input> ColumnUnpivotContextAttrs<'input> for MultiColumnUnpivotDefaultContext<'input> {}

impl<'input> MultiColumnUnpivotDefaultContextExt<'input>{
	fn new(ctx: &dyn ColumnUnpivotContextAttrs<'input>) -> Rc<ColumnUnpivotContextAll<'input>>  {
		Rc::new(
			ColumnUnpivotContextAll::MultiColumnUnpivotDefaultContext(
				BaseParserRuleContext::copy_from(ctx,MultiColumnUnpivotDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SingleColumnUnpivotDefaultContext<'input> = BaseParserRuleContext<'input,SingleColumnUnpivotDefaultContextExt<'input>>;

pub trait SingleColumnUnpivotDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn singleColumnUnpivot(&self) -> Option<Rc<SingleColumnUnpivotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SingleColumnUnpivotDefaultContextAttrs<'input> for SingleColumnUnpivotDefaultContext<'input>{}

pub struct SingleColumnUnpivotDefaultContextExt<'input>{
	base:ColumnUnpivotContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleColumnUnpivotDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SingleColumnUnpivotDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SingleColumnUnpivotDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleColumnUnpivotDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_singleColumnUnpivotDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SingleColumnUnpivotDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_singleColumnUnpivotDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleColumnUnpivotDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnUnpivot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnUnpivot }
}

impl<'input> Borrow<ColumnUnpivotContextExt<'input>> for SingleColumnUnpivotDefaultContext<'input>{
	fn borrow(&self) -> &ColumnUnpivotContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ColumnUnpivotContextExt<'input>> for SingleColumnUnpivotDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ColumnUnpivotContextExt<'input> { &mut self.base }
}

impl<'input> ColumnUnpivotContextAttrs<'input> for SingleColumnUnpivotDefaultContext<'input> {}

impl<'input> SingleColumnUnpivotDefaultContextExt<'input>{
	fn new(ctx: &dyn ColumnUnpivotContextAttrs<'input>) -> Rc<ColumnUnpivotContextAll<'input>>  {
		Rc::new(
			ColumnUnpivotContextAll::SingleColumnUnpivotDefaultContext(
				BaseParserRuleContext::copy_from(ctx,SingleColumnUnpivotDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnUnpivot(&mut self,)
	-> Result<Rc<ColumnUnpivotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnUnpivotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 288, RULE_columnUnpivot);
        let mut _localctx: Rc<ColumnUnpivotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2590);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
			 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
			 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
			 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
			 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
			 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
			 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
			 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
			 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
			 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
			 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
			 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
			 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
			 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT | EXTENDED |
			 EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT | FIRST |
			 FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM | FROM_JSON |
			 FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT | GROUP | GROUPING |
			 HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY | IF | IGNORE | IMMEDIATE |
			 IMPORT | IN | INCLUDE | INDEX | INDEXES | INNER | INPATH | INPUT | INPUTFORMAT |
			 INSERT | INTERSECT | INTERVAL | INT | INTEGER | INTO | INVOKER | IS |
			 ITEMS | ILIKE | JOIN | KEY | KEYS | LANGUAGE | LAST | LATERAL | LAZY |
			 LEADING | LEFT | LIKE | LIMIT | LINES | LIST | LISTAGG | LIVE | LOAD |
			 LOCAL | LOCATION | LOCK | LOCKS | LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES |
			 MATCHED | MATERIALIZED | MERGE | MICROSECOND | MICROSECONDS | MILLISECOND |
			 MILLISECONDS | MINUS_KW | MINUTE | MINUTES | MODE | MODIFIES | MONTH |
			 MONTHS | MSCK | NAME | NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND |
			 NANOSECONDS | NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF |
			 OFFSET | ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT |
			 OUTER | OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
			 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
			 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
			 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL | RECORDREADER |
			 RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP | REFERENCE | REFERENCES |
			 REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE | RESET | RESPECT |
			 RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE | ROLE | ROLES |
			 ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES | SESSION_USER |
			 SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT | SOME | SORT |
			 SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS | STORED | STRATIFY |
			 STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING | SYNC | SYSTEM_TIME |
			 SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE | TARGET | TBLPROPERTIES |
			 TEMP | TEMPORARY | TERMINATED | STRING_KW | THEN | TIME | TIMEDIFF |
			 TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF | TIMESTAMP_LTZ | TIMESTAMP_NTZ |
			 TINYINT | TO | TOUCH | TRAILING | TRANSACTION | TRANSACTIONS | TRANSFORM |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE | UNARCHIVE | UNBOUNDED | UNCACHE |
			 UNION | UNIQUE | UNKNOWN | UNLOCK | UNPIVOT | UNSET | UPDATE | USE |
			 USER | USING | VALUES | VAR | VARCHAR | VARIANT | VERSION | VIEW | VIEWS |
			 VOID | WEEK | WEEKS | WHEN | WHERE | WHILE | WINDOW | WITH | WITHIN |
			 YEAR | YEARS | ZONE | IDENTIFIER | BACKQUOTED_IDENTIFIER 
				=> {
					let tmp = SingleColumnUnpivotDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule singleColumnUnpivot*/
					recog.base.set_state(2588);
					recog.singleColumnUnpivot()?;

					}
				}

			 LPAREN 
				=> {
					let tmp = MultiColumnUnpivotDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule multiColumnUnpivot*/
					recog.base.set_state(2589);
					recog.multiColumnUnpivot()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotIntos ----------------
#[derive(Debug)]
pub enum PivotIntosContextAll<'input>{
	PivotIntosDefaultContext(PivotIntosDefaultContext<'input>),
Error(PivotIntosContext<'input>)
}
antlr_rust::tid!{PivotIntosContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotIntosContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PivotIntosContextAll<'input>{}

impl<'input> Deref for PivotIntosContextAll<'input>{
	type Target = dyn PivotIntosContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotIntosContextAll::*;
		match self{
			PivotIntosDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotIntosContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotIntosContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotIntosContext<'input> = BaseParserRuleContext<'input,PivotIntosContextExt<'input>>;

#[derive(Clone)]
pub struct PivotIntosContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PivotIntosContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotIntosContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotIntosContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotIntosContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotIntos }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotIntos }
}
antlr_rust::tid!{PivotIntosContextExt<'a>}

impl<'input> PivotIntosContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotIntosContextAll<'input>> {
		Rc::new(
		PivotIntosContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotIntosContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotIntosContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PivotIntosContextExt<'input>>{


}

impl<'input> PivotIntosContextAttrs<'input> for PivotIntosContext<'input>{}

pub type PivotIntosDefaultContext<'input> = BaseParserRuleContext<'input,PivotIntosDefaultContextExt<'input>>;

pub trait PivotIntosDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn pivotInto_all(&self) ->  Vec<Rc<PivotIntoContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn pivotInto(&self, i: usize) -> Option<Rc<PivotIntoContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PivotIntosDefaultContextAttrs<'input> for PivotIntosDefaultContext<'input>{}

pub struct PivotIntosDefaultContextExt<'input>{
	base:PivotIntosContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotIntosDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PivotIntosDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotIntosDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivotIntosDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_pivotIntosDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotIntosDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pivotIntosDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotIntosDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotIntos }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotIntos }
}

impl<'input> Borrow<PivotIntosContextExt<'input>> for PivotIntosDefaultContext<'input>{
	fn borrow(&self) -> &PivotIntosContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotIntosContextExt<'input>> for PivotIntosDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotIntosContextExt<'input> { &mut self.base }
}

impl<'input> PivotIntosContextAttrs<'input> for PivotIntosDefaultContext<'input> {}

impl<'input> PivotIntosDefaultContextExt<'input>{
	fn new(ctx: &dyn PivotIntosContextAttrs<'input>) -> Rc<PivotIntosContextAll<'input>>  {
		Rc::new(
			PivotIntosContextAll::PivotIntosDefaultContext(
				BaseParserRuleContext::copy_from(ctx,PivotIntosDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotIntos(&mut self,)
	-> Result<Rc<PivotIntosContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotIntosContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 290, RULE_pivotIntos);
        let mut _localctx: Rc<PivotIntosContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = PivotIntosDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule pivotInto*/
			recog.base.set_state(2592);
			recog.pivotInto()?;

			recog.base.set_state(2597);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(344,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2593);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule pivotInto*/
					recog.base.set_state(2594);
					recog.pivotInto()?;

					}
					} 
				}
				recog.base.set_state(2599);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(344,&mut recog.base)?;
			}
			recog.base.set_state(2601);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2600);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotOperator ----------------
#[derive(Debug)]
pub enum PivotOperatorContextAll<'input>{
	UnpivotContext(UnpivotContext<'input>),
	PivotContext(PivotContext<'input>),
Error(PivotOperatorContext<'input>)
}
antlr_rust::tid!{PivotOperatorContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PivotOperatorContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PivotOperatorContextAll<'input>{}

impl<'input> Deref for PivotOperatorContextAll<'input>{
	type Target = dyn PivotOperatorContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PivotOperatorContextAll::*;
		match self{
			UnpivotContext(inner) => inner,
			PivotContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotOperatorContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotOperatorContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PivotOperatorContext<'input> = BaseParserRuleContext<'input,PivotOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PivotOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PivotOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotOperatorContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotOperatorContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PivotOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}
antlr_rust::tid!{PivotOperatorContextExt<'a>}

impl<'input> PivotOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotOperatorContextAll<'input>> {
		Rc::new(
		PivotOperatorContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotOperatorContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PivotOperatorContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PivotOperatorContextExt<'input>>{


}

impl<'input> PivotOperatorContextAttrs<'input> for PivotOperatorContext<'input>{}

pub type UnpivotContext<'input> = BaseParserRuleContext<'input,UnpivotContextExt<'input>>;

pub trait UnpivotContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNPIVOT
	/// Returns `None` if there is no child corresponding to token UNPIVOT
	fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(UNPIVOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn columnUnpivot(&self) -> Option<Rc<ColumnUnpivotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn pivotAsAlias(&self) -> Option<Rc<PivotAsAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn unpivotNullClause(&self) -> Option<Rc<UnpivotNullClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnpivotContextAttrs<'input> for UnpivotContext<'input>{}

pub struct UnpivotContextExt<'input>{
	base:PivotOperatorContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnpivotContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UnpivotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UnpivotContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unpivot(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_unpivot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UnpivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_unpivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}

impl<'input> Borrow<PivotOperatorContextExt<'input>> for UnpivotContext<'input>{
	fn borrow(&self) -> &PivotOperatorContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotOperatorContextExt<'input>> for UnpivotContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotOperatorContextExt<'input> { &mut self.base }
}

impl<'input> PivotOperatorContextAttrs<'input> for UnpivotContext<'input> {}

impl<'input> UnpivotContextExt<'input>{
	fn new(ctx: &dyn PivotOperatorContextAttrs<'input>) -> Rc<PivotOperatorContextAll<'input>>  {
		Rc::new(
			PivotOperatorContextAll::UnpivotContext(
				BaseParserRuleContext::copy_from(ctx,UnpivotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PivotContext<'input> = BaseParserRuleContext<'input,PivotContextExt<'input>>;

pub trait PivotContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PIVOT
	/// Returns `None` if there is no child corresponding to token PIVOT
	fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PIVOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	fn pivotAggregates(&self) -> Option<Rc<PivotAggregatesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
	fn pivotFrom(&self) -> Option<Rc<PivotFromContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	fn pivotIntos(&self) -> Option<Rc<PivotIntosContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
}

impl<'input> PivotContextAttrs<'input> for PivotContext<'input>{}

pub struct PivotContextExt<'input>{
	base:PivotOperatorContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PivotContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PivotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PivotContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_pivot(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_pivot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PivotContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pivot(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotOperator }
}

impl<'input> Borrow<PivotOperatorContextExt<'input>> for PivotContext<'input>{
	fn borrow(&self) -> &PivotOperatorContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PivotOperatorContextExt<'input>> for PivotContext<'input>{
	fn borrow_mut(&mut self) -> &mut PivotOperatorContextExt<'input> { &mut self.base }
}

impl<'input> PivotOperatorContextAttrs<'input> for PivotContext<'input> {}

impl<'input> PivotContextExt<'input>{
	fn new(ctx: &dyn PivotOperatorContextAttrs<'input>) -> Rc<PivotOperatorContextAll<'input>>  {
		Rc::new(
			PivotOperatorContextAll::PivotContext(
				BaseParserRuleContext::copy_from(ctx,PivotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotOperator(&mut self,)
	-> Result<Rc<PivotOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 292, RULE_pivotOperator);
        let mut _localctx: Rc<PivotOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2623);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 PIVOT 
				=> {
					let tmp = PivotContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2603);
					recog.base.match_token(PIVOT,&mut recog.err_handler)?;

					recog.base.set_state(2604);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotAggregates*/
					recog.base.set_state(2605);
					recog.pivotAggregates()?;

					recog.base.set_state(2606);
					recog.base.match_token(FOR,&mut recog.err_handler)?;

					/*InvokeRule pivotFrom*/
					recog.base.set_state(2607);
					recog.pivotFrom()?;

					recog.base.set_state(2608);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2609);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotIntos*/
					recog.base.set_state(2610);
					recog.pivotIntos()?;

					recog.base.set_state(2611);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2612);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

			 UNPIVOT 
				=> {
					let tmp = UnpivotContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2614);
					recog.base.match_token(UNPIVOT,&mut recog.err_handler)?;

					recog.base.set_state(2616);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EXCLUDE || _la==INCLUDE {
						{
						/*InvokeRule unpivotNullClause*/
						recog.base.set_state(2615);
						recog.unpivotNullClause()?;

						}
					}

					recog.base.set_state(2618);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule columnUnpivot*/
					recog.base.set_state(2619);
					recog.columnUnpivot()?;

					recog.base.set_state(2620);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule pivotAsAlias*/
					recog.base.set_state(2621);
					recog.pivotAsAlias()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aliasedRelationTarget ----------------
#[derive(Debug)]
pub enum AliasedRelationTargetContextAll<'input>{
	StreamTableTargetContext(StreamTableTargetContext<'input>),
	FunctionTableDefaultContext(FunctionTableDefaultContext<'input>),
	SampledRelationDefaultContext(SampledRelationDefaultContext<'input>),
	InlineTableDefaultContext(InlineTableDefaultContext<'input>),
Error(AliasedRelationTargetContext<'input>)
}
antlr_rust::tid!{AliasedRelationTargetContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for AliasedRelationTargetContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for AliasedRelationTargetContextAll<'input>{}

impl<'input> Deref for AliasedRelationTargetContextAll<'input>{
	type Target = dyn AliasedRelationTargetContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use AliasedRelationTargetContextAll::*;
		match self{
			StreamTableTargetContext(inner) => inner,
			FunctionTableDefaultContext(inner) => inner,
			SampledRelationDefaultContext(inner) => inner,
			InlineTableDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AliasedRelationTargetContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AliasedRelationTargetContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type AliasedRelationTargetContext<'input> = BaseParserRuleContext<'input,AliasedRelationTargetContextExt<'input>>;

#[derive(Clone)]
pub struct AliasedRelationTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for AliasedRelationTargetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AliasedRelationTargetContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AliasedRelationTargetContext<'input>{
}

impl<'input> CustomRuleContext<'input> for AliasedRelationTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}
antlr_rust::tid!{AliasedRelationTargetContextExt<'a>}

impl<'input> AliasedRelationTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AliasedRelationTargetContextAll<'input>> {
		Rc::new(
		AliasedRelationTargetContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AliasedRelationTargetContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait AliasedRelationTargetContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<AliasedRelationTargetContextExt<'input>>{


}

impl<'input> AliasedRelationTargetContextAttrs<'input> for AliasedRelationTargetContext<'input>{}

pub type StreamTableTargetContext<'input> = BaseParserRuleContext<'input,StreamTableTargetContextExt<'input>>;

pub trait StreamTableTargetContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STREAM
	/// Returns `None` if there is no child corresponding to token STREAM
	fn STREAM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(STREAM, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> StreamTableTargetContextAttrs<'input> for StreamTableTargetContext<'input>{}

pub struct StreamTableTargetContextExt<'input>{
	base:AliasedRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StreamTableTargetContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StreamTableTargetContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StreamTableTargetContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_streamTableTarget(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_streamTableTarget(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StreamTableTargetContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_streamTableTarget(self);
	}
}

impl<'input> CustomRuleContext<'input> for StreamTableTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}

impl<'input> Borrow<AliasedRelationTargetContextExt<'input>> for StreamTableTargetContext<'input>{
	fn borrow(&self) -> &AliasedRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<AliasedRelationTargetContextExt<'input>> for StreamTableTargetContext<'input>{
	fn borrow_mut(&mut self) -> &mut AliasedRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> AliasedRelationTargetContextAttrs<'input> for StreamTableTargetContext<'input> {}

impl<'input> StreamTableTargetContextExt<'input>{
	fn new(ctx: &dyn AliasedRelationTargetContextAttrs<'input>) -> Rc<AliasedRelationTargetContextAll<'input>>  {
		Rc::new(
			AliasedRelationTargetContextAll::StreamTableTargetContext(
				BaseParserRuleContext::copy_from(ctx,StreamTableTargetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionTableDefaultContext<'input> = BaseParserRuleContext<'input,FunctionTableDefaultContextExt<'input>>;

pub trait FunctionTableDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn tableFunctionCall(&self) -> Option<Rc<TableFunctionCallContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token STREAM
	/// Returns `None` if there is no child corresponding to token STREAM
	fn STREAM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(STREAM, 0)
	}
}

impl<'input> FunctionTableDefaultContextAttrs<'input> for FunctionTableDefaultContext<'input>{}

pub struct FunctionTableDefaultContextExt<'input>{
	base:AliasedRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionTableDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for FunctionTableDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FunctionTableDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionTableDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_functionTableDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FunctionTableDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_functionTableDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionTableDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}

impl<'input> Borrow<AliasedRelationTargetContextExt<'input>> for FunctionTableDefaultContext<'input>{
	fn borrow(&self) -> &AliasedRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<AliasedRelationTargetContextExt<'input>> for FunctionTableDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut AliasedRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> AliasedRelationTargetContextAttrs<'input> for FunctionTableDefaultContext<'input> {}

impl<'input> FunctionTableDefaultContextExt<'input>{
	fn new(ctx: &dyn AliasedRelationTargetContextAttrs<'input>) -> Rc<AliasedRelationTargetContextAll<'input>>  {
		Rc::new(
			AliasedRelationTargetContextAll::FunctionTableDefaultContext(
				BaseParserRuleContext::copy_from(ctx,FunctionTableDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SampledRelationDefaultContext<'input> = BaseParserRuleContext<'input,SampledRelationDefaultContextExt<'input>>;

pub trait SampledRelationDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn sampledRelation(&self) -> Option<Rc<SampledRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SampledRelationDefaultContextAttrs<'input> for SampledRelationDefaultContext<'input>{}

pub struct SampledRelationDefaultContextExt<'input>{
	base:AliasedRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampledRelationDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SampledRelationDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SampledRelationDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampledRelationDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_sampledRelationDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SampledRelationDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_sampledRelationDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampledRelationDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}

impl<'input> Borrow<AliasedRelationTargetContextExt<'input>> for SampledRelationDefaultContext<'input>{
	fn borrow(&self) -> &AliasedRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<AliasedRelationTargetContextExt<'input>> for SampledRelationDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut AliasedRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> AliasedRelationTargetContextAttrs<'input> for SampledRelationDefaultContext<'input> {}

impl<'input> SampledRelationDefaultContextExt<'input>{
	fn new(ctx: &dyn AliasedRelationTargetContextAttrs<'input>) -> Rc<AliasedRelationTargetContextAll<'input>>  {
		Rc::new(
			AliasedRelationTargetContextAll::SampledRelationDefaultContext(
				BaseParserRuleContext::copy_from(ctx,SampledRelationDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InlineTableDefaultContext<'input> = BaseParserRuleContext<'input,InlineTableDefaultContextExt<'input>>;

pub trait InlineTableDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn inlineTable(&self) -> Option<Rc<InlineTableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InlineTableDefaultContextAttrs<'input> for InlineTableDefaultContext<'input>{}

pub struct InlineTableDefaultContextExt<'input>{
	base:AliasedRelationTargetContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InlineTableDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InlineTableDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InlineTableDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inlineTableDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_inlineTableDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InlineTableDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_inlineTableDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelationTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelationTarget }
}

impl<'input> Borrow<AliasedRelationTargetContextExt<'input>> for InlineTableDefaultContext<'input>{
	fn borrow(&self) -> &AliasedRelationTargetContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<AliasedRelationTargetContextExt<'input>> for InlineTableDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut AliasedRelationTargetContextExt<'input> { &mut self.base }
}

impl<'input> AliasedRelationTargetContextAttrs<'input> for InlineTableDefaultContext<'input> {}

impl<'input> InlineTableDefaultContextExt<'input>{
	fn new(ctx: &dyn AliasedRelationTargetContextAttrs<'input>) -> Rc<AliasedRelationTargetContextAll<'input>>  {
		Rc::new(
			AliasedRelationTargetContextAll::InlineTableDefaultContext(
				BaseParserRuleContext::copy_from(ctx,InlineTableDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aliasedRelationTarget(&mut self,)
	-> Result<Rc<AliasedRelationTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AliasedRelationTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 294, RULE_aliasedRelationTarget);
        let mut _localctx: Rc<AliasedRelationTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2638);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(349,&mut recog.base)? {
				1 =>{
					let tmp = StreamTableTargetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2625);
					recog.base.match_token(STREAM,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(2626);
					recog.identifierReference()?;

					}
				}
			,
				2 =>{
					let tmp = StreamTableTargetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2627);
					recog.base.match_token(STREAM,&mut recog.err_handler)?;

					recog.base.set_state(2628);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(2629);
					recog.identifierReference()?;

					recog.base.set_state(2630);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = SampledRelationDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule sampledRelation*/
					recog.base.set_state(2632);
					recog.sampledRelation()?;

					}
				}
			,
				4 =>{
					let tmp = InlineTableDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule inlineTable*/
					recog.base.set_state(2633);
					recog.inlineTable()?;

					}
				}
			,
				5 =>{
					let tmp = FunctionTableDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(2635);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(348,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2634);
							recog.base.match_token(STREAM,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule tableFunctionCall*/
					recog.base.set_state(2637);
					recog.tableFunctionCall()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- temporalClause ----------------
pub type TemporalClauseContextAll<'input> = TemporalClauseContext<'input>;


pub type TemporalClauseContext<'input> = BaseParserRuleContext<'input,TemporalClauseContextExt<'input>>;

#[derive(Clone)]
pub struct TemporalClauseContextExt<'input>{
	pub timestamp: Option<Rc<ValueExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TemporalClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TemporalClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_temporalClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_temporalClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TemporalClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_temporalClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for TemporalClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_temporalClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_temporalClause }
}
antlr_rust::tid!{TemporalClauseContextExt<'a>}

impl<'input> TemporalClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TemporalClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TemporalClauseContextExt{
				timestamp: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TemporalClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TemporalClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
fn version(&self) -> Option<Rc<VersionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_VERSION
/// Returns `None` if there is no child corresponding to token SYSTEM_VERSION
fn SYSTEM_VERSION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TemporalClauseContextAttrs<'input> for TemporalClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn temporalClause(&mut self,)
	-> Result<Rc<TemporalClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TemporalClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 296, RULE_temporalClause);
        let mut _localctx: Rc<TemporalClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2654);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(352,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2641);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(2640);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2643);
					_la = recog.base.input.la(1);
					if { !(_la==SYSTEM_VERSION || _la==VERSION) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2644);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(2645);
					recog.base.match_token(OF,&mut recog.err_handler)?;

					/*InvokeRule version*/
					recog.base.set_state(2646);
					recog.version()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2648);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(2647);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2650);
					_la = recog.base.input.la(1);
					if { !(_la==SYSTEM_TIME || _la==TIMESTAMP) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2651);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(2652);
					recog.base.match_token(OF,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2653);
					let tmp = recog.valueExpression_rec(0)?;
					 cast_mut::<_,TemporalClauseContext >(&mut _localctx).timestamp = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- version ----------------
pub type VersionContextAll<'input> = VersionContext<'input>;


pub type VersionContext<'input> = BaseParserRuleContext<'input,VersionContextExt<'input>>;

#[derive(Clone)]
pub struct VersionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for VersionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for VersionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_version(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_version(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for VersionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_version(self);
	}
}

impl<'input> CustomRuleContext<'input> for VersionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_version }
	//fn type_rule_index() -> usize where Self: Sized { RULE_version }
}
antlr_rust::tid!{VersionContextExt<'a>}

impl<'input> VersionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VersionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VersionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VersionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<VersionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> VersionContextAttrs<'input> for VersionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn version(&mut self,)
	-> Result<Rc<VersionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VersionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 298, RULE_version);
        let mut _localctx: Rc<VersionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2658);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INTEGER_VALUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2656);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}

			 STRING | DOUBLEQUOTED_STRING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule string*/
					recog.base.set_state(2657);
					recog.string()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aliasedRelation ----------------
pub type AliasedRelationContextAll<'input> = AliasedRelationContext<'input>;


pub type AliasedRelationContext<'input> = BaseParserRuleContext<'input,AliasedRelationContextExt<'input>>;

#[derive(Clone)]
pub struct AliasedRelationContextExt<'input>{
	pub alias: Option<Rc<StrictIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for AliasedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AliasedRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aliasedRelation(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_aliasedRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AliasedRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_aliasedRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for AliasedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasedRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasedRelation }
}
antlr_rust::tid!{AliasedRelationContextExt<'a>}

impl<'input> AliasedRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AliasedRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AliasedRelationContextExt{
				alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AliasedRelationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<AliasedRelationContextExt<'input>>{

fn aliasedRelationTarget(&self) -> Option<Rc<AliasedRelationTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AliasedRelationContextAttrs<'input> for AliasedRelationContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aliasedRelation(&mut self,)
	-> Result<Rc<AliasedRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AliasedRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 300, RULE_aliasedRelation);
        let mut _localctx: Rc<AliasedRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule aliasedRelationTarget*/
			recog.base.set_state(2660);
			recog.aliasedRelationTarget()?;

			recog.base.set_state(2668);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(356,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2662);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(354,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2661);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule strictIdentifier*/
					recog.base.set_state(2664);
					let tmp = recog.strictIdentifier()?;
					 cast_mut::<_,AliasedRelationContext >(&mut _localctx).alias = Some(tmp.clone());
					  

					recog.base.set_state(2666);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(355,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule columnAliases*/
							recog.base.set_state(2665);
							recog.columnAliases()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnAliases ----------------
pub type ColumnAliasesContextAll<'input> = ColumnAliasesContext<'input>;


pub type ColumnAliasesContext<'input> = BaseParserRuleContext<'input,ColumnAliasesContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnAliasesContextExt<'input>{
	pub tail: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ColumnAliasesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnAliasesContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnAliases(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_columnAliases(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnAliasesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnAliases(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnAliasesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnAliases }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnAliases }
}
antlr_rust::tid!{ColumnAliasesContextExt<'a>}

impl<'input> ColumnAliasesContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnAliasesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnAliasesContextExt{
				tail: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnAliasesContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ColumnAliasesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}

}

impl<'input> ColumnAliasesContextAttrs<'input> for ColumnAliasesContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnAliases(&mut self,)
	-> Result<Rc<ColumnAliasesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnAliasesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 302, RULE_columnAliases);
        let mut _localctx: Rc<ColumnAliasesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2670);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifierSeq*/
			recog.base.set_state(2671);
			recog.identifierSeq()?;

			recog.base.set_state(2673);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2672);
				let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnAliasesContext >(&mut _localctx).tail = Some(tmp);
				  

				}
			}

			recog.base.set_state(2675);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relationPrimary ----------------
#[derive(Debug)]
pub enum RelationPrimaryContextAll<'input>{
	SubqueryRelationContext(SubqueryRelationContext<'input>),
	ParenthesizedRelationContext(ParenthesizedRelationContext<'input>),
	TableNameContext(TableNameContext<'input>),
Error(RelationPrimaryContext<'input>)
}
antlr_rust::tid!{RelationPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RelationPrimaryContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for RelationPrimaryContextAll<'input>{}

impl<'input> Deref for RelationPrimaryContextAll<'input>{
	type Target = dyn RelationPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RelationPrimaryContextAll::*;
		match self{
			SubqueryRelationContext(inner) => inner,
			ParenthesizedRelationContext(inner) => inner,
			TableNameContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RelationPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RelationPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RelationPrimaryContext<'input> = BaseParserRuleContext<'input,RelationPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct RelationPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for RelationPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RelationPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RelationPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RelationPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}
antlr_rust::tid!{RelationPrimaryContextExt<'a>}

impl<'input> RelationPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationPrimaryContextAll<'input>> {
		Rc::new(
		RelationPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RelationPrimaryContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<RelationPrimaryContextExt<'input>>{


}

impl<'input> RelationPrimaryContextAttrs<'input> for RelationPrimaryContext<'input>{}

pub type SubqueryRelationContext<'input> = BaseParserRuleContext<'input,SubqueryRelationContextExt<'input>>;

pub trait SubqueryRelationContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> SubqueryRelationContextAttrs<'input> for SubqueryRelationContext<'input>{}

pub struct SubqueryRelationContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryRelationContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SubqueryRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SubqueryRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subqueryRelation(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_subqueryRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SubqueryRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_subqueryRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for SubqueryRelationContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for SubqueryRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for SubqueryRelationContext<'input> {}

impl<'input> SubqueryRelationContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::SubqueryRelationContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryRelationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ParenthesizedRelationContext<'input> = BaseParserRuleContext<'input,ParenthesizedRelationContextExt<'input>>;

pub trait ParenthesizedRelationContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn extensibleRelation(&self) -> Option<Rc<ExtensibleRelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ParenthesizedRelationContextAttrs<'input> for ParenthesizedRelationContext<'input>{}

pub struct ParenthesizedRelationContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	pub rel: Option<Rc<ExtensibleRelationContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ParenthesizedRelationContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ParenthesizedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ParenthesizedRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_parenthesizedRelation(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_parenthesizedRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ParenthesizedRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_parenthesizedRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParenthesizedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for ParenthesizedRelationContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for ParenthesizedRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for ParenthesizedRelationContext<'input> {}

impl<'input> ParenthesizedRelationContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::ParenthesizedRelationContext(
				BaseParserRuleContext::copy_from(ctx,ParenthesizedRelationContextExt{
        			rel:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableNameContext<'input> = BaseParserRuleContext<'input,TableNameContextExt<'input>>;

pub trait TableNameContextAttrs<'input>: DatabricksParserContext<'input>{
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn temporalClause(&self) -> Option<Rc<TemporalClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableNameContextAttrs<'input> for TableNameContext<'input>{}

pub struct TableNameContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	pub tableNameRef: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableNameContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TableNameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableNameContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableName(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_tableName(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableName(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for TableNameContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for TableNameContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for TableNameContext<'input> {}

impl<'input> TableNameContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::TableNameContext(
				BaseParserRuleContext::copy_from(ctx,TableNameContextExt{
        			tableNameRef:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relationPrimary(&mut self,)
	-> Result<Rc<RelationPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 304, RULE_relationPrimary);
        let mut _localctx: Rc<RelationPrimaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2692);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(360,&mut recog.base)? {
				1 =>{
					let tmp = TableNameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule identifierReference*/
					recog.base.set_state(2677);
					let tmp = recog.identifierReference()?;
					if let RelationPrimaryContextAll::TableNameContext(ctx) = cast_mut::<_,RelationPrimaryContextAll >(&mut _localctx){
					ctx.tableNameRef = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2679);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(358,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule temporalClause*/
							recog.base.set_state(2678);
							recog.temporalClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2682);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(359,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule optionsClause*/
							recog.base.set_state(2681);
							recog.optionsClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = SubqueryRelationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2684);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2685);
					recog.query()?;

					recog.base.set_state(2686);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = ParenthesizedRelationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2688);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule extensibleRelation*/
					recog.base.set_state(2689);
					let tmp = recog.extensibleRelation()?;
					if let RelationPrimaryContextAll::ParenthesizedRelationContext(ctx) = cast_mut::<_,RelationPrimaryContextAll >(&mut _localctx){
					ctx.rel = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2690);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionCall ----------------
#[derive(Debug)]
pub enum TableFunctionCallContextAll<'input>{
	DefaultTableFunctionCallContext(DefaultTableFunctionCallContext<'input>),
Error(TableFunctionCallContext<'input>)
}
antlr_rust::tid!{TableFunctionCallContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TableFunctionCallContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for TableFunctionCallContextAll<'input>{}

impl<'input> Deref for TableFunctionCallContextAll<'input>{
	type Target = dyn TableFunctionCallContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TableFunctionCallContextAll::*;
		match self{
			DefaultTableFunctionCallContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableFunctionCallContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableFunctionCallContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TableFunctionCallContext<'input> = BaseParserRuleContext<'input,TableFunctionCallContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionCallContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableFunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableFunctionCallContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableFunctionCallContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TableFunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionCall }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionCall }
}
antlr_rust::tid!{TableFunctionCallContextExt<'a>}

impl<'input> TableFunctionCallContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionCallContextAll<'input>> {
		Rc::new(
		TableFunctionCallContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionCallContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TableFunctionCallContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableFunctionCallContextExt<'input>>{


}

impl<'input> TableFunctionCallContextAttrs<'input> for TableFunctionCallContext<'input>{}

pub type DefaultTableFunctionCallContext<'input> = BaseParserRuleContext<'input,DefaultTableFunctionCallContextExt<'input>>;

pub trait DefaultTableFunctionCallContextAttrs<'input>: DatabricksParserContext<'input>{
	fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn tableFunctionArgument_all(&self) ->  Vec<Rc<TableFunctionArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn tableFunctionArgument(&self, i: usize) -> Option<Rc<TableFunctionArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> DefaultTableFunctionCallContextAttrs<'input> for DefaultTableFunctionCallContext<'input>{}

pub struct DefaultTableFunctionCallContextExt<'input>{
	base:TableFunctionCallContextExt<'input>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultTableFunctionCallContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DefaultTableFunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DefaultTableFunctionCallContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultTableFunctionCall(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_defaultTableFunctionCall(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DefaultTableFunctionCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_defaultTableFunctionCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultTableFunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionCall }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionCall }
}

impl<'input> Borrow<TableFunctionCallContextExt<'input>> for DefaultTableFunctionCallContext<'input>{
	fn borrow(&self) -> &TableFunctionCallContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableFunctionCallContextExt<'input>> for DefaultTableFunctionCallContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableFunctionCallContextExt<'input> { &mut self.base }
}

impl<'input> TableFunctionCallContextAttrs<'input> for DefaultTableFunctionCallContext<'input> {}

impl<'input> DefaultTableFunctionCallContextExt<'input>{
	fn new(ctx: &dyn TableFunctionCallContextAttrs<'input>) -> Rc<TableFunctionCallContextAll<'input>>  {
		Rc::new(
			TableFunctionCallContextAll::DefaultTableFunctionCallContext(
				BaseParserRuleContext::copy_from(ctx,DefaultTableFunctionCallContextExt{
					COMMA:None, 
        			tail:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionCall(&mut self,)
	-> Result<Rc<TableFunctionCallContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionCallContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 306, RULE_tableFunctionCall);
        let mut _localctx: Rc<TableFunctionCallContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = DefaultTableFunctionCallContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule functionName*/
			recog.base.set_state(2694);
			recog.functionName()?;

			recog.base.set_state(2695);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2707);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
				{
				/*InvokeRule tableFunctionArgument*/
				recog.base.set_state(2696);
				recog.tableFunctionArgument()?;

				recog.base.set_state(2701);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(361,&mut recog.base)?;
				while { _alt!=2 && _alt!=INVALID_ALT } {
					if _alt==1 {
						{
						{
						recog.base.set_state(2697);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule tableFunctionArgument*/
						recog.base.set_state(2698);
						recog.tableFunctionArgument()?;

						}
						} 
					}
					recog.base.set_state(2703);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(361,&mut recog.base)?;
				}
				recog.base.set_state(2705);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==COMMA {
					{
					recog.base.set_state(2704);
					let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
					if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
					ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

					let temp = if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
					ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let TableFunctionCallContextAll::DefaultTableFunctionCallContext(ctx) = cast_mut::<_,TableFunctionCallContextAll >(&mut _localctx){
					ctx.tail.push(temp); } else {unreachable!("cant cast");}  
					}
				}

				}
			}

			recog.base.set_state(2709);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionArgumentName ----------------
pub type TableFunctionArgumentNameContextAll<'input> = TableFunctionArgumentNameContext<'input>;


pub type TableFunctionArgumentNameContext<'input> = BaseParserRuleContext<'input,TableFunctionArgumentNameContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionArgumentNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableFunctionArgumentNameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableFunctionArgumentNameContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFunctionArgumentName(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_tableFunctionArgumentName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableFunctionArgumentNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionArgumentName(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionArgumentNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionArgumentName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionArgumentName }
}
antlr_rust::tid!{TableFunctionArgumentNameContextExt<'a>}

impl<'input> TableFunctionArgumentNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionArgumentNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionArgumentNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFunctionArgumentNameContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableFunctionArgumentNameContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableFunctionArgumentNameContextAttrs<'input> for TableFunctionArgumentNameContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionArgumentName(&mut self,)
	-> Result<Rc<TableFunctionArgumentNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionArgumentNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 308, RULE_tableFunctionArgumentName);
        let mut _localctx: Rc<TableFunctionArgumentNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(2711);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFunctionArgument ----------------
pub type TableFunctionArgumentContextAll<'input> = TableFunctionArgumentContext<'input>;


pub type TableFunctionArgumentContext<'input> = BaseParserRuleContext<'input,TableFunctionArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct TableFunctionArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableFunctionArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableFunctionArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFunctionArgument(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_tableFunctionArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableFunctionArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableFunctionArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFunctionArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFunctionArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFunctionArgument }
}
antlr_rust::tid!{TableFunctionArgumentContextExt<'a>}

impl<'input> TableFunctionArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFunctionArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFunctionArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFunctionArgumentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableFunctionArgumentContextExt<'input>>{

fn tableArgument(&self) -> Option<Rc<TableArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableFunctionArgumentName(&self) -> Option<Rc<TableFunctionArgumentNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableFunctionArgumentContextAttrs<'input> for TableFunctionArgumentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFunctionArgument(&mut self,)
	-> Result<Rc<TableFunctionArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFunctionArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 310, RULE_tableFunctionArgument);
        let mut _localctx: Rc<TableFunctionArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2716);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(364,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule tableFunctionArgumentName*/
					recog.base.set_state(2713);
					recog.tableFunctionArgumentName()?;

					recog.base.set_state(2714);
					recog.base.match_token(T__0,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			recog.base.set_state(2720);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(365,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule tableArgument*/
					recog.base.set_state(2718);
					recog.tableArgument()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule expression*/
					recog.base.set_state(2719);
					recog.expression()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableArgument ----------------
pub type TableArgumentContextAll<'input> = TableArgumentContext<'input>;


pub type TableArgumentContext<'input> = BaseParserRuleContext<'input,TableArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct TableArgumentContextExt<'input>{
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableArgument(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_tableArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgument }
}
antlr_rust::tid!{TableArgumentContextExt<'a>}

impl<'input> TableArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableArgumentContextExt{
				COMMA: None, 
				tail: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableArgumentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableArgumentContextExt<'input>>{

fn tableArgumentRelation(&self) -> Option<Rc<TableArgumentRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableArgumentContextAttrs<'input> for TableArgumentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableArgument(&mut self,)
	-> Result<Rc<TableArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 312, RULE_tableArgument);
        let mut _localctx: Rc<TableArgumentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableArgumentRelation*/
			recog.base.set_state(2722);
			recog.tableArgumentRelation()?;

			recog.base.set_state(2743);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PARTITION {
				{
				recog.base.set_state(2723);
				recog.base.match_token(PARTITION,&mut recog.err_handler)?;

				recog.base.set_state(2724);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(2741);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(369,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(2725);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(2737);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
							{
							/*InvokeRule expression*/
							recog.base.set_state(2726);
							recog.expression()?;

							recog.base.set_state(2731);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(366,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2727);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(2728);
									recog.expression()?;

									}
									} 
								}
								recog.base.set_state(2733);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(366,&mut recog.base)?;
							}
							recog.base.set_state(2735);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2734);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								 cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA = Some(tmp);
								  

								let temp =  cast_mut::<_,TableArgumentContext >(&mut _localctx).COMMA.clone().unwrap()
								 ;
								 cast_mut::<_,TableArgumentContext >(&mut _localctx).tail.push(temp);
								  
								}
							}

							}
						}

						recog.base.set_state(2739);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule expression*/
						recog.base.set_state(2740);
						recog.expression()?;

						}
					}

					_ => {}
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableArgumentRelation ----------------
#[derive(Debug)]
pub enum TableArgumentRelationContextAll<'input>{
	TableArgumentQueryContext(TableArgumentQueryContext<'input>),
	TableArgumentTableContext(TableArgumentTableContext<'input>),
Error(TableArgumentRelationContext<'input>)
}
antlr_rust::tid!{TableArgumentRelationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TableArgumentRelationContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for TableArgumentRelationContextAll<'input>{}

impl<'input> Deref for TableArgumentRelationContextAll<'input>{
	type Target = dyn TableArgumentRelationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TableArgumentRelationContextAll::*;
		match self{
			TableArgumentQueryContext(inner) => inner,
			TableArgumentTableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableArgumentRelationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableArgumentRelationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TableArgumentRelationContext<'input> = BaseParserRuleContext<'input,TableArgumentRelationContextExt<'input>>;

#[derive(Clone)]
pub struct TableArgumentRelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TableArgumentRelationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableArgumentRelationContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableArgumentRelationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TableArgumentRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}
antlr_rust::tid!{TableArgumentRelationContextExt<'a>}

impl<'input> TableArgumentRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableArgumentRelationContextAll<'input>> {
		Rc::new(
		TableArgumentRelationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableArgumentRelationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TableArgumentRelationContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TableArgumentRelationContextExt<'input>>{


}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentRelationContext<'input>{}

pub type TableArgumentQueryContext<'input> = BaseParserRuleContext<'input,TableArgumentQueryContextExt<'input>>;

pub trait TableArgumentQueryContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableArgumentQueryContextAttrs<'input> for TableArgumentQueryContext<'input>{}

pub struct TableArgumentQueryContextExt<'input>{
	base:TableArgumentRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableArgumentQueryContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TableArgumentQueryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableArgumentQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableArgumentQuery(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_tableArgumentQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableArgumentQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableArgumentQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}

impl<'input> Borrow<TableArgumentRelationContextExt<'input>> for TableArgumentQueryContext<'input>{
	fn borrow(&self) -> &TableArgumentRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableArgumentRelationContextExt<'input>> for TableArgumentQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableArgumentRelationContextExt<'input> { &mut self.base }
}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentQueryContext<'input> {}

impl<'input> TableArgumentQueryContextExt<'input>{
	fn new(ctx: &dyn TableArgumentRelationContextAttrs<'input>) -> Rc<TableArgumentRelationContextAll<'input>>  {
		Rc::new(
			TableArgumentRelationContextAll::TableArgumentQueryContext(
				BaseParserRuleContext::copy_from(ctx,TableArgumentQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableArgumentTableContext<'input> = BaseParserRuleContext<'input,TableArgumentTableContextExt<'input>>;

pub trait TableArgumentTableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn columnAliases(&self) -> Option<Rc<ColumnAliasesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableArgumentTableContextAttrs<'input> for TableArgumentTableContext<'input>{}

pub struct TableArgumentTableContextExt<'input>{
	base:TableArgumentRelationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableArgumentTableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TableArgumentTableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TableArgumentTableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableArgumentTable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_tableArgumentTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TableArgumentTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tableArgumentTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentRelation }
}

impl<'input> Borrow<TableArgumentRelationContextExt<'input>> for TableArgumentTableContext<'input>{
	fn borrow(&self) -> &TableArgumentRelationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TableArgumentRelationContextExt<'input>> for TableArgumentTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut TableArgumentRelationContextExt<'input> { &mut self.base }
}

impl<'input> TableArgumentRelationContextAttrs<'input> for TableArgumentTableContext<'input> {}

impl<'input> TableArgumentTableContextExt<'input>{
	fn new(ctx: &dyn TableArgumentRelationContextAttrs<'input>) -> Rc<TableArgumentRelationContextAll<'input>>  {
		Rc::new(
			TableArgumentRelationContextAll::TableArgumentTableContext(
				BaseParserRuleContext::copy_from(ctx,TableArgumentTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableArgumentRelation(&mut self,)
	-> Result<Rc<TableArgumentRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableArgumentRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 314, RULE_tableArgumentRelation);
        let mut _localctx: Rc<TableArgumentRelationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2771);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(377,&mut recog.base)? {
				1 =>{
					let tmp = TableArgumentTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2745);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(2746);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule qualifiedName*/
					recog.base.set_state(2747);
					recog.qualifiedName()?;

					recog.base.set_state(2748);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2756);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(373,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2750);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(371,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(2749);
									recog.base.match_token(AS,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							/*InvokeRule identifier*/
							recog.base.set_state(2752);
							recog.identifier()?;

							recog.base.set_state(2754);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==LPAREN {
								{
								/*InvokeRule columnAliases*/
								recog.base.set_state(2753);
								recog.columnAliases()?;

								}
							}

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = TableArgumentQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2758);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(2759);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2760);
					recog.query()?;

					recog.base.set_state(2761);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2769);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(376,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2763);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(374,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(2762);
									recog.base.match_token(AS,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							/*InvokeRule identifier*/
							recog.base.set_state(2765);
							recog.identifier()?;

							recog.base.set_state(2767);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==LPAREN {
								{
								/*InvokeRule columnAliases*/
								recog.base.set_state(2766);
								recog.columnAliases()?;

								}
							}

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expression ----------------
pub type ExpressionContextAll<'input> = ExpressionContext<'input>;


pub type ExpressionContext<'input> = BaseParserRuleContext<'input,ExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expression(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_expression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expression }
}
antlr_rust::tid!{ExpressionContextExt<'a>}

impl<'input> ExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ExpressionContextExt<'input>>{

fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionContextAttrs<'input> for ExpressionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expression(&mut self,)
	-> Result<Rc<ExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 316, RULE_expression);
        let mut _localctx: Rc<ExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule booleanExpression*/
			recog.base.set_state(2773);
			recog.booleanExpression_rec(0)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanExpression ----------------
#[derive(Debug)]
pub enum BooleanExpressionContextAll<'input>{
	DefaultBooleanExpressionContext(DefaultBooleanExpressionContext<'input>),
	LogicalNotContext(LogicalNotContext<'input>),
	OrContext(OrContext<'input>),
	PredicatedContext(PredicatedContext<'input>),
	AndContext(AndContext<'input>),
Error(BooleanExpressionContext<'input>)
}
antlr_rust::tid!{BooleanExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for BooleanExpressionContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for BooleanExpressionContextAll<'input>{}

impl<'input> Deref for BooleanExpressionContextAll<'input>{
	type Target = dyn BooleanExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use BooleanExpressionContextAll::*;
		match self{
			DefaultBooleanExpressionContext(inner) => inner,
			LogicalNotContext(inner) => inner,
			OrContext(inner) => inner,
			PredicatedContext(inner) => inner,
			AndContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BooleanExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BooleanExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type BooleanExpressionContext<'input> = BaseParserRuleContext<'input,BooleanExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for BooleanExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BooleanExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BooleanExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for BooleanExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}
antlr_rust::tid!{BooleanExpressionContextExt<'a>}

impl<'input> BooleanExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanExpressionContextAll<'input>> {
		Rc::new(
		BooleanExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait BooleanExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<BooleanExpressionContextExt<'input>>{


}

impl<'input> BooleanExpressionContextAttrs<'input> for BooleanExpressionContext<'input>{}

pub type DefaultBooleanExpressionContext<'input> = BaseParserRuleContext<'input,DefaultBooleanExpressionContextExt<'input>>;

pub trait DefaultBooleanExpressionContextAttrs<'input>: DatabricksParserContext<'input>{
	fn nonComparisonExpression(&self) -> Option<Rc<NonComparisonExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DefaultBooleanExpressionContextAttrs<'input> for DefaultBooleanExpressionContext<'input>{}

pub struct DefaultBooleanExpressionContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	pub left: Option<Rc<NonComparisonExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DefaultBooleanExpressionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DefaultBooleanExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DefaultBooleanExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_defaultBooleanExpression(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_defaultBooleanExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DefaultBooleanExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_defaultBooleanExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultBooleanExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for DefaultBooleanExpressionContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for DefaultBooleanExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for DefaultBooleanExpressionContext<'input> {}

impl<'input> DefaultBooleanExpressionContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::DefaultBooleanExpressionContext(
				BaseParserRuleContext::copy_from(ctx,DefaultBooleanExpressionContextExt{
        			left:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LogicalNotContext<'input> = BaseParserRuleContext<'input,LogicalNotContextExt<'input>>;

pub trait LogicalNotContextAttrs<'input>: DatabricksParserContext<'input>{
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BANG
	/// Returns `None` if there is no child corresponding to token BANG
	fn BANG(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BANG, 0)
	}
}

impl<'input> LogicalNotContextAttrs<'input> for LogicalNotContext<'input>{}

pub struct LogicalNotContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LogicalNotContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LogicalNotContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LogicalNotContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_logicalNot(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_logicalNot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LogicalNotContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_logicalNot(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalNotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for LogicalNotContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for LogicalNotContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for LogicalNotContext<'input> {}

impl<'input> LogicalNotContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::LogicalNotContext(
				BaseParserRuleContext::copy_from(ctx,LogicalNotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type OrContext<'input> = BaseParserRuleContext<'input,OrContextExt<'input>>;

pub trait OrContextAttrs<'input>: DatabricksParserContext<'input>{
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
}

impl<'input> OrContextAttrs<'input> for OrContext<'input>{}

pub struct OrContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OrContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for OrContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for OrContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_or(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_or(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for OrContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_or(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for OrContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for OrContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for OrContext<'input> {}

impl<'input> OrContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::OrContext(
				BaseParserRuleContext::copy_from(ctx,OrContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PredicatedContext<'input> = BaseParserRuleContext<'input,PredicatedContextExt<'input>>;

pub trait PredicatedContextAttrs<'input>: DatabricksParserContext<'input>{
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn comparisonPredicate(&self) -> Option<Rc<ComparisonPredicateContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PredicatedContextAttrs<'input> for PredicatedContext<'input>{}

pub struct PredicatedContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	pub left: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub pred: Option<Rc<ComparisonPredicateContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PredicatedContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PredicatedContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PredicatedContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_predicated(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_predicated(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PredicatedContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_predicated(self);
	}
}

impl<'input> CustomRuleContext<'input> for PredicatedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for PredicatedContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for PredicatedContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for PredicatedContext<'input> {}

impl<'input> PredicatedContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::PredicatedContext(
				BaseParserRuleContext::copy_from(ctx,PredicatedContextExt{
        			left:None, pred:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AndContext<'input> = BaseParserRuleContext<'input,AndContextExt<'input>>;

pub trait AndContextAttrs<'input>: DatabricksParserContext<'input>{
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
}

impl<'input> AndContextAttrs<'input> for AndContext<'input>{}

pub struct AndContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AndContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for AndContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AndContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_and(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_and(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AndContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_and(self);
	}
}

impl<'input> CustomRuleContext<'input> for AndContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for AndContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for AndContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for AndContext<'input> {}

impl<'input> AndContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::AndContext(
				BaseParserRuleContext::copy_from(ctx,AndContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  booleanExpression(&mut self,)
	-> Result<Rc<BooleanExpressionContextAll<'input>>,ANTLRError> {
		self.booleanExpression_rec(0)
	}

	fn booleanExpression_rec(&mut self, _p: isize)
	-> Result<Rc<BooleanExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = BooleanExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 318, RULE_booleanExpression, _p);
	    let mut _localctx: Rc<BooleanExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 318;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2779);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(378,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = DefaultBooleanExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					/*InvokeRule nonComparisonExpression*/
					recog.base.set_state(2776);
					let tmp = recog.nonComparisonExpression()?;
					if let BooleanExpressionContextAll::DefaultBooleanExpressionContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
					ctx.left = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					{
					let mut tmp = LogicalNotContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2777);
					_la = recog.base.input.la(1);
					if { !(_la==NOT || _la==BANG) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule booleanExpression*/
					recog.base.set_state(2778);
					recog.booleanExpression_rec(3)?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2791);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(380,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(2789);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(379,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = AndContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(2781);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(2782);
							recog.base.match_token(AND,&mut recog.err_handler)?;

							/*InvokeRule booleanExpression*/
							recog.base.set_state(2783);
							recog.booleanExpression_rec(3)?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = OrContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(2784);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(2785);
							recog.base.match_token(OR,&mut recog.err_handler)?;

							/*InvokeRule booleanExpression*/
							recog.base.set_state(2786);
							recog.booleanExpression_rec(2)?;

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = PredicatedContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let BooleanExpressionContextAll::PredicatedContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(2787);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							/*InvokeRule comparisonPredicate*/
							recog.base.set_state(2788);
							let tmp = recog.comparisonPredicate()?;
							if let BooleanExpressionContextAll::PredicatedContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
							ctx.pred = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(2793);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(380,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- comparisonPredicate ----------------
#[derive(Debug)]
pub enum ComparisonPredicateContextAll<'input>{
	ComparisonContext(ComparisonContext<'input>),
	QuantifiedComparisonContext(QuantifiedComparisonContext<'input>),
Error(ComparisonPredicateContext<'input>)
}
antlr_rust::tid!{ComparisonPredicateContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ComparisonPredicateContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for ComparisonPredicateContextAll<'input>{}

impl<'input> Deref for ComparisonPredicateContextAll<'input>{
	type Target = dyn ComparisonPredicateContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ComparisonPredicateContextAll::*;
		match self{
			ComparisonContext(inner) => inner,
			QuantifiedComparisonContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ComparisonPredicateContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ComparisonPredicateContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ComparisonPredicateContext<'input> = BaseParserRuleContext<'input,ComparisonPredicateContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonPredicateContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ComparisonPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ComparisonPredicateContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ComparisonPredicateContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ComparisonPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonPredicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonPredicate }
}
antlr_rust::tid!{ComparisonPredicateContextExt<'a>}

impl<'input> ComparisonPredicateContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonPredicateContextAll<'input>> {
		Rc::new(
		ComparisonPredicateContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonPredicateContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ComparisonPredicateContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ComparisonPredicateContextExt<'input>>{


}

impl<'input> ComparisonPredicateContextAttrs<'input> for ComparisonPredicateContext<'input>{}

pub type ComparisonContext<'input> = BaseParserRuleContext<'input,ComparisonContextExt<'input>>;

pub trait ComparisonContextAttrs<'input>: DatabricksParserContext<'input>{
	fn comparisonOperator(&self) -> Option<Rc<ComparisonOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ComparisonContextAttrs<'input> for ComparisonContext<'input>{}

pub struct ComparisonContextExt<'input>{
	base:ComparisonPredicateContextExt<'input>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ComparisonContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ComparisonContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ComparisonContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_comparison(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_comparison(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ComparisonContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_comparison(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonPredicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonPredicate }
}

impl<'input> Borrow<ComparisonPredicateContextExt<'input>> for ComparisonContext<'input>{
	fn borrow(&self) -> &ComparisonPredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ComparisonPredicateContextExt<'input>> for ComparisonContext<'input>{
	fn borrow_mut(&mut self) -> &mut ComparisonPredicateContextExt<'input> { &mut self.base }
}

impl<'input> ComparisonPredicateContextAttrs<'input> for ComparisonContext<'input> {}

impl<'input> ComparisonContextExt<'input>{
	fn new(ctx: &dyn ComparisonPredicateContextAttrs<'input>) -> Rc<ComparisonPredicateContextAll<'input>>  {
		Rc::new(
			ComparisonPredicateContextAll::ComparisonContext(
				BaseParserRuleContext::copy_from(ctx,ComparisonContextExt{
        			right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QuantifiedComparisonContext<'input> = BaseParserRuleContext<'input,QuantifiedComparisonContextExt<'input>>;

pub trait QuantifiedComparisonContextAttrs<'input>: DatabricksParserContext<'input>{
	fn comparisonOperator(&self) -> Option<Rc<ComparisonOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn comparisonQuantifier(&self) -> Option<Rc<ComparisonQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> QuantifiedComparisonContextAttrs<'input> for QuantifiedComparisonContext<'input>{}

pub struct QuantifiedComparisonContextExt<'input>{
	base:ComparisonPredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuantifiedComparisonContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for QuantifiedComparisonContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QuantifiedComparisonContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quantifiedComparison(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_quantifiedComparison(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QuantifiedComparisonContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_quantifiedComparison(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuantifiedComparisonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonPredicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonPredicate }
}

impl<'input> Borrow<ComparisonPredicateContextExt<'input>> for QuantifiedComparisonContext<'input>{
	fn borrow(&self) -> &ComparisonPredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ComparisonPredicateContextExt<'input>> for QuantifiedComparisonContext<'input>{
	fn borrow_mut(&mut self) -> &mut ComparisonPredicateContextExt<'input> { &mut self.base }
}

impl<'input> ComparisonPredicateContextAttrs<'input> for QuantifiedComparisonContext<'input> {}

impl<'input> QuantifiedComparisonContextExt<'input>{
	fn new(ctx: &dyn ComparisonPredicateContextAttrs<'input>) -> Rc<ComparisonPredicateContextAll<'input>>  {
		Rc::new(
			ComparisonPredicateContextAll::QuantifiedComparisonContext(
				BaseParserRuleContext::copy_from(ctx,QuantifiedComparisonContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonPredicate(&mut self,)
	-> Result<Rc<ComparisonPredicateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonPredicateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 320, RULE_comparisonPredicate);
        let mut _localctx: Rc<ComparisonPredicateContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2803);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(381,&mut recog.base)? {
				1 =>{
					let tmp = ComparisonContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule comparisonOperator*/
					recog.base.set_state(2794);
					recog.comparisonOperator()?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2795);
					let tmp = recog.valueExpression_rec(0)?;
					if let ComparisonPredicateContextAll::ComparisonContext(ctx) = cast_mut::<_,ComparisonPredicateContextAll >(&mut _localctx){
					ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = QuantifiedComparisonContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule comparisonOperator*/
					recog.base.set_state(2797);
					recog.comparisonOperator()?;

					/*InvokeRule comparisonQuantifier*/
					recog.base.set_state(2798);
					recog.comparisonQuantifier()?;

					recog.base.set_state(2799);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2800);
					recog.query()?;

					recog.base.set_state(2801);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonComparisonExpression ----------------
pub type NonComparisonExpressionContextAll<'input> = NonComparisonExpressionContext<'input>;


pub type NonComparisonExpressionContext<'input> = BaseParserRuleContext<'input,NonComparisonExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NonComparisonExpressionContextExt<'input>{
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub pred: Option<Rc<PredicateContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NonComparisonExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NonComparisonExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonComparisonExpression(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_nonComparisonExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NonComparisonExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_nonComparisonExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NonComparisonExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonComparisonExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonComparisonExpression }
}
antlr_rust::tid!{NonComparisonExpressionContextExt<'a>}

impl<'input> NonComparisonExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonComparisonExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonComparisonExpressionContextExt{
				left: None, pred: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NonComparisonExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NonComparisonExpressionContextExt<'input>>{

fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn predicate(&self) -> Option<Rc<PredicateContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NonComparisonExpressionContextAttrs<'input> for NonComparisonExpressionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonComparisonExpression(&mut self,)
	-> Result<Rc<NonComparisonExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonComparisonExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 322, RULE_nonComparisonExpression);
        let mut _localctx: Rc<NonComparisonExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule valueExpression*/
			recog.base.set_state(2805);
			let tmp = recog.valueExpression_rec(0)?;
			 cast_mut::<_,NonComparisonExpressionContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(2807);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(382,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule predicate*/
					recog.base.set_state(2806);
					let tmp = recog.predicate()?;
					 cast_mut::<_,NonComparisonExpressionContext >(&mut _localctx).pred = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- predicate ----------------
#[derive(Debug)]
pub enum PredicateContextAll<'input>{
	FalsePredicateContext(FalsePredicateContext<'input>),
	RegexpContext(RegexpContext<'input>),
	UnknownPredicateContext(UnknownPredicateContext<'input>),
	QuantifiedLikeContext(QuantifiedLikeContext<'input>),
	LikeContext(LikeContext<'input>),
	InSubqueryContext(InSubqueryContext<'input>),
	DistinctFromContext(DistinctFromContext<'input>),
	TruePredicateContext(TruePredicateContext<'input>),
	InListContext(InListContext<'input>),
	NullPredicateContext(NullPredicateContext<'input>),
	BetweenContext(BetweenContext<'input>),
Error(PredicateContext<'input>)
}
antlr_rust::tid!{PredicateContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PredicateContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PredicateContextAll<'input>{}

impl<'input> Deref for PredicateContextAll<'input>{
	type Target = dyn PredicateContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PredicateContextAll::*;
		match self{
			FalsePredicateContext(inner) => inner,
			RegexpContext(inner) => inner,
			UnknownPredicateContext(inner) => inner,
			QuantifiedLikeContext(inner) => inner,
			LikeContext(inner) => inner,
			InSubqueryContext(inner) => inner,
			DistinctFromContext(inner) => inner,
			TruePredicateContext(inner) => inner,
			InListContext(inner) => inner,
			NullPredicateContext(inner) => inner,
			BetweenContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PredicateContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PredicateContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PredicateContext<'input> = BaseParserRuleContext<'input,PredicateContextExt<'input>>;

#[derive(Clone)]
pub struct PredicateContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PredicateContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PredicateContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PredicateContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}
antlr_rust::tid!{PredicateContextExt<'a>}

impl<'input> PredicateContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PredicateContextAll<'input>> {
		Rc::new(
		PredicateContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PredicateContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PredicateContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PredicateContextExt<'input>>{


}

impl<'input> PredicateContextAttrs<'input> for PredicateContext<'input>{}

pub type FalsePredicateContext<'input> = BaseParserRuleContext<'input,FalsePredicateContextExt<'input>>;

pub trait FalsePredicateContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FALSE
	/// Returns `None` if there is no child corresponding to token FALSE
	fn FALSE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FALSE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> FalsePredicateContextAttrs<'input> for FalsePredicateContext<'input>{}

pub struct FalsePredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FalsePredicateContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for FalsePredicateContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FalsePredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_falsePredicate(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_falsePredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FalsePredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_falsePredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for FalsePredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for FalsePredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for FalsePredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for FalsePredicateContext<'input> {}

impl<'input> FalsePredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::FalsePredicateContext(
				BaseParserRuleContext::copy_from(ctx,FalsePredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RegexpContext<'input> = BaseParserRuleContext<'input,RegexpContextExt<'input>>;

pub trait RegexpContextAttrs<'input>: DatabricksParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token REGEXP
	/// Returns `None` if there is no child corresponding to token REGEXP
	fn REGEXP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(REGEXP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RLIKE
	/// Returns `None` if there is no child corresponding to token RLIKE
	fn RLIKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RLIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> RegexpContextAttrs<'input> for RegexpContext<'input>{}

pub struct RegexpContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RegexpContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RegexpContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RegexpContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_regexp(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_regexp(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RegexpContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_regexp(self);
	}
}

impl<'input> CustomRuleContext<'input> for RegexpContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for RegexpContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for RegexpContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for RegexpContext<'input> {}

impl<'input> RegexpContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::RegexpContext(
				BaseParserRuleContext::copy_from(ctx,RegexpContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnknownPredicateContext<'input> = BaseParserRuleContext<'input,UnknownPredicateContextExt<'input>>;

pub trait UnknownPredicateContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UNKNOWN
	/// Returns `None` if there is no child corresponding to token UNKNOWN
	fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(UNKNOWN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> UnknownPredicateContextAttrs<'input> for UnknownPredicateContext<'input>{}

pub struct UnknownPredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnknownPredicateContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UnknownPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UnknownPredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unknownPredicate(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_unknownPredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UnknownPredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_unknownPredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnknownPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for UnknownPredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for UnknownPredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for UnknownPredicateContext<'input> {}

impl<'input> UnknownPredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::UnknownPredicateContext(
				BaseParserRuleContext::copy_from(ctx,UnknownPredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QuantifiedLikeContext<'input> = BaseParserRuleContext<'input,QuantifiedLikeContextExt<'input>>;

pub trait QuantifiedLikeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ALL
	/// Returns `None` if there is no child corresponding to token ALL
	fn ALL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ALL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ANY
	/// Returns `None` if there is no child corresponding to token ANY
	fn ANY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ANY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SOME
	/// Returns `None` if there is no child corresponding to token SOME
	fn SOME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SOME, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> QuantifiedLikeContextAttrs<'input> for QuantifiedLikeContext<'input>{}

pub struct QuantifiedLikeContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub valueExpression: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub pattern:Vec<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuantifiedLikeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for QuantifiedLikeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QuantifiedLikeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quantifiedLike(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_quantifiedLike(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QuantifiedLikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_quantifiedLike(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuantifiedLikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for QuantifiedLikeContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for QuantifiedLikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for QuantifiedLikeContext<'input> {}

impl<'input> QuantifiedLikeContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::QuantifiedLikeContext(
				BaseParserRuleContext::copy_from(ctx,QuantifiedLikeContextExt{
        			valueExpression:None, 
        			pattern:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LikeContext<'input> = BaseParserRuleContext<'input,LikeContextExt<'input>>;

pub trait LikeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ILIKE
	/// Returns `None` if there is no child corresponding to token ILIKE
	fn ILIKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ILIKE, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ESCAPE
	/// Returns `None` if there is no child corresponding to token ESCAPE
	fn ESCAPE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ESCAPE, 0)
	}
}

impl<'input> LikeContextAttrs<'input> for LikeContext<'input>{}

pub struct LikeContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub pattern: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub escape: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LikeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LikeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LikeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_like(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_like(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_like(self);
	}
}

impl<'input> CustomRuleContext<'input> for LikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for LikeContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for LikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for LikeContext<'input> {}

impl<'input> LikeContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::LikeContext(
				BaseParserRuleContext::copy_from(ctx,LikeContextExt{
        			pattern:None, escape:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InSubqueryContext<'input> = BaseParserRuleContext<'input,InSubqueryContextExt<'input>>;

pub trait InSubqueryContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> InSubqueryContextAttrs<'input> for InSubqueryContext<'input>{}

pub struct InSubqueryContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InSubqueryContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InSubqueryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InSubqueryContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inSubquery(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_inSubquery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InSubqueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_inSubquery(self);
	}
}

impl<'input> CustomRuleContext<'input> for InSubqueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for InSubqueryContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for InSubqueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for InSubqueryContext<'input> {}

impl<'input> InSubqueryContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::InSubqueryContext(
				BaseParserRuleContext::copy_from(ctx,InSubqueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DistinctFromContext<'input> = BaseParserRuleContext<'input,DistinctFromContextExt<'input>>;

pub trait DistinctFromContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DISTINCT
	/// Returns `None` if there is no child corresponding to token DISTINCT
	fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DISTINCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> DistinctFromContextAttrs<'input> for DistinctFromContext<'input>{}

pub struct DistinctFromContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DistinctFromContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DistinctFromContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DistinctFromContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_distinctFrom(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_distinctFrom(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DistinctFromContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_distinctFrom(self);
	}
}

impl<'input> CustomRuleContext<'input> for DistinctFromContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for DistinctFromContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for DistinctFromContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for DistinctFromContext<'input> {}

impl<'input> DistinctFromContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::DistinctFromContext(
				BaseParserRuleContext::copy_from(ctx,DistinctFromContextExt{
        			right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TruePredicateContext<'input> = BaseParserRuleContext<'input,TruePredicateContextExt<'input>>;

pub trait TruePredicateContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRUE
	/// Returns `None` if there is no child corresponding to token TRUE
	fn TRUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TRUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> TruePredicateContextAttrs<'input> for TruePredicateContext<'input>{}

pub struct TruePredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TruePredicateContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TruePredicateContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TruePredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_truePredicate(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_truePredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TruePredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_truePredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for TruePredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for TruePredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for TruePredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for TruePredicateContext<'input> {}

impl<'input> TruePredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::TruePredicateContext(
				BaseParserRuleContext::copy_from(ctx,TruePredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InListContext<'input> = BaseParserRuleContext<'input,InListContextExt<'input>>;

pub trait InListContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> InListContextAttrs<'input> for InListContext<'input>{}

pub struct InListContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InListContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for InListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for InListContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inList(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_inList(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for InListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_inList(self);
	}
}

impl<'input> CustomRuleContext<'input> for InListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for InListContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for InListContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for InListContext<'input> {}

impl<'input> InListContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::InListContext(
				BaseParserRuleContext::copy_from(ctx,InListContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NullPredicateContext<'input> = BaseParserRuleContext<'input,NullPredicateContextExt<'input>>;

pub trait NullPredicateContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> NullPredicateContextAttrs<'input> for NullPredicateContext<'input>{}

pub struct NullPredicateContextExt<'input>{
	base:PredicateContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NullPredicateContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for NullPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NullPredicateContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nullPredicate(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_nullPredicate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NullPredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_nullPredicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for NullPredicateContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for NullPredicateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for NullPredicateContext<'input> {}

impl<'input> NullPredicateContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::NullPredicateContext(
				BaseParserRuleContext::copy_from(ctx,NullPredicateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BetweenContext<'input> = BaseParserRuleContext<'input,BetweenContextExt<'input>>;

pub trait BetweenContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BETWEEN
	/// Returns `None` if there is no child corresponding to token BETWEEN
	fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BETWEEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
}

impl<'input> BetweenContextAttrs<'input> for BetweenContext<'input>{}

pub struct BetweenContextExt<'input>{
	base:PredicateContextExt<'input>,
	pub lower: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub upper: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BetweenContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for BetweenContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BetweenContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_between(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_between(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BetweenContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_between(self);
	}
}

impl<'input> CustomRuleContext<'input> for BetweenContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}

impl<'input> Borrow<PredicateContextExt<'input>> for BetweenContext<'input>{
	fn borrow(&self) -> &PredicateContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PredicateContextExt<'input>> for BetweenContext<'input>{
	fn borrow_mut(&mut self) -> &mut PredicateContextExt<'input> { &mut self.base }
}

impl<'input> PredicateContextAttrs<'input> for BetweenContext<'input> {}

impl<'input> BetweenContextExt<'input>{
	fn new(ctx: &dyn PredicateContextAttrs<'input>) -> Rc<PredicateContextAll<'input>>  {
		Rc::new(
			PredicateContextAll::BetweenContext(
				BaseParserRuleContext::copy_from(ctx,BetweenContextExt{
        			lower:None, upper:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn predicate(&mut self,)
	-> Result<Rc<PredicateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PredicateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 324, RULE_predicate);
        let mut _localctx: Rc<PredicateContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2900);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(398,&mut recog.base)? {
				1 =>{
					let tmp = BetweenContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2810);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2809);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2812);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2813);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::BetweenContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.lower = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2814);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2815);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::BetweenContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.upper = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = InListContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2818);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2817);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2820);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2821);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2822);
					recog.expression()?;

					recog.base.set_state(2827);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(385,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2823);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2824);
							recog.expression()?;

							}
							} 
						}
						recog.base.set_state(2829);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(385,&mut recog.base)?;
					}
					recog.base.set_state(2831);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2830);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PredicateContextAll::InListContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2833);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = InSubqueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2836);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2835);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2838);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					recog.base.set_state(2839);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2840);
					recog.query()?;

					recog.base.set_state(2841);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = RegexpContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(2844);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2843);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2846);
					_la = recog.base.input.la(1);
					if { !(_la==REGEXP || _la==RLIKE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2847);
					recog.valueExpression_rec(0)?;

					}
				}
			,
				5 =>{
					let tmp = QuantifiedLikeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(2849);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2848);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2851);
					recog.base.match_token(LIKE,&mut recog.err_handler)?;

					recog.base.set_state(2852);
					_la = recog.base.input.la(1);
					if { !(_la==ALL || _la==ANY || _la==SOME) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2853);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2854);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.valueExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.valueExpression.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.pattern.push(temp); } else {unreachable!("cant cast");}  
					recog.base.set_state(2859);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2855);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule valueExpression*/
						recog.base.set_state(2856);
						let tmp = recog.valueExpression_rec(0)?;
						if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.valueExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.valueExpression.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let PredicateContextAll::QuantifiedLikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
						ctx.pattern.push(temp); } else {unreachable!("cant cast");}  
						}
						}
						recog.base.set_state(2861);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2862);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					let tmp = LikeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(2865);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2864);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2867);
					_la = recog.base.input.la(1);
					if { !(_la==ILIKE || _la==LIKE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2868);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::LikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2871);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(392,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2869);
							recog.base.match_token(ESCAPE,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(2870);
							let tmp = recog.valueExpression_rec(0)?;
							if let PredicateContextAll::LikeContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
							ctx.escape = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				7 =>{
					let tmp = NullPredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(2873);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2875);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2874);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2877);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					let tmp = DistinctFromContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(2878);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2880);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2879);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2882);
					recog.base.match_token(DISTINCT,&mut recog.err_handler)?;

					recog.base.set_state(2883);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2884);
					let tmp = recog.valueExpression_rec(0)?;
					if let PredicateContextAll::DistinctFromContext(ctx) = cast_mut::<_,PredicateContextAll >(&mut _localctx){
					ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				9 =>{
					let tmp = TruePredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(2885);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2887);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2886);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2889);
					recog.base.match_token(TRUE,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					let tmp = FalsePredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(2890);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2892);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2891);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2894);
					recog.base.match_token(FALSE,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					let tmp = UnknownPredicateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(2895);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(2897);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==NOT {
						{
						recog.base.set_state(2896);
						recog.base.match_token(NOT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2899);
					recog.base.match_token(UNKNOWN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valueExpression ----------------
#[derive(Debug)]
pub enum ValueExpressionContextAll<'input>{
	ValueExpressionDefaultContext(ValueExpressionDefaultContext<'input>),
	ConcatenationContext(ConcatenationContext<'input>),
	ArithmeticBinaryContext(ArithmeticBinaryContext<'input>),
	ArithmeticUnaryContext(ArithmeticUnaryContext<'input>),
	AtTimeZoneContext(AtTimeZoneContext<'input>),
Error(ValueExpressionContext<'input>)
}
antlr_rust::tid!{ValueExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ValueExpressionContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for ValueExpressionContextAll<'input>{}

impl<'input> Deref for ValueExpressionContextAll<'input>{
	type Target = dyn ValueExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ValueExpressionContextAll::*;
		match self{
			ValueExpressionDefaultContext(inner) => inner,
			ConcatenationContext(inner) => inner,
			ArithmeticBinaryContext(inner) => inner,
			ArithmeticUnaryContext(inner) => inner,
			AtTimeZoneContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ValueExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ValueExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ValueExpressionContext<'input> = BaseParserRuleContext<'input,ValueExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ValueExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ValueExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ValueExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ValueExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ValueExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}
antlr_rust::tid!{ValueExpressionContextExt<'a>}

impl<'input> ValueExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValueExpressionContextAll<'input>> {
		Rc::new(
		ValueExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValueExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ValueExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ValueExpressionContextExt<'input>>{


}

impl<'input> ValueExpressionContextAttrs<'input> for ValueExpressionContext<'input>{}

pub type ValueExpressionDefaultContext<'input> = BaseParserRuleContext<'input,ValueExpressionDefaultContextExt<'input>>;

pub trait ValueExpressionDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ValueExpressionDefaultContextAttrs<'input> for ValueExpressionDefaultContext<'input>{}

pub struct ValueExpressionDefaultContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ValueExpressionDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ValueExpressionDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ValueExpressionDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_valueExpressionDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_valueExpressionDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ValueExpressionDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_valueExpressionDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for ValueExpressionDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ValueExpressionDefaultContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ValueExpressionDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ValueExpressionDefaultContext<'input> {}

impl<'input> ValueExpressionDefaultContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ValueExpressionDefaultContext(
				BaseParserRuleContext::copy_from(ctx,ValueExpressionDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ConcatenationContext<'input> = BaseParserRuleContext<'input,ConcatenationContextExt<'input>>;

pub trait ConcatenationContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CONCAT
	/// Returns `None` if there is no child corresponding to token CONCAT
	fn CONCAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CONCAT, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> ConcatenationContextAttrs<'input> for ConcatenationContext<'input>{}

pub struct ConcatenationContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ConcatenationContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ConcatenationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ConcatenationContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_concatenation(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_concatenation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ConcatenationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_concatenation(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConcatenationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ConcatenationContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ConcatenationContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ConcatenationContext<'input> {}

impl<'input> ConcatenationContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ConcatenationContext(
				BaseParserRuleContext::copy_from(ctx,ConcatenationContextExt{
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArithmeticBinaryContext<'input> = BaseParserRuleContext<'input,ArithmeticBinaryContextExt<'input>>;

pub trait ArithmeticBinaryContextAttrs<'input>: DatabricksParserContext<'input>{
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SLASH
	/// Returns `None` if there is no child corresponding to token SLASH
	fn SLASH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SLASH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PERCENT
	/// Returns `None` if there is no child corresponding to token PERCENT
	fn PERCENT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PERCENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DIV
	/// Returns `None` if there is no child corresponding to token DIV
	fn DIV(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DIV, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_SHIFT_LEFT
	/// Returns `None` if there is no child corresponding to token BITWISE_SHIFT_LEFT
	fn BITWISE_SHIFT_LEFT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_SHIFT_LEFT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_AND
	/// Returns `None` if there is no child corresponding to token BITWISE_AND
	fn BITWISE_AND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_AND, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_OR
	/// Returns `None` if there is no child corresponding to token BITWISE_OR
	fn BITWISE_OR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BITWISE_XOR
	/// Returns `None` if there is no child corresponding to token BITWISE_XOR
	fn BITWISE_XOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BITWISE_XOR, 0)
	}
}

impl<'input> ArithmeticBinaryContextAttrs<'input> for ArithmeticBinaryContext<'input>{}

pub struct ArithmeticBinaryContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub operator: Option<TokenType<'input>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArithmeticBinaryContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ArithmeticBinaryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ArithmeticBinaryContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arithmeticBinary(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_arithmeticBinary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ArithmeticBinaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_arithmeticBinary(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticBinaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ArithmeticBinaryContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ArithmeticBinaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ArithmeticBinaryContext<'input> {}

impl<'input> ArithmeticBinaryContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ArithmeticBinaryContext(
				BaseParserRuleContext::copy_from(ctx,ArithmeticBinaryContextExt{
					operator:None, 
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArithmeticUnaryContext<'input> = BaseParserRuleContext<'input,ArithmeticUnaryContextExt<'input>>;

pub trait ArithmeticUnaryContextAttrs<'input>: DatabricksParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token POSIX
	/// Returns `None` if there is no child corresponding to token POSIX
	fn POSIX(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(POSIX, 0)
	}
}

impl<'input> ArithmeticUnaryContextAttrs<'input> for ArithmeticUnaryContext<'input>{}

pub struct ArithmeticUnaryContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub operator: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArithmeticUnaryContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ArithmeticUnaryContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ArithmeticUnaryContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arithmeticUnary(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_arithmeticUnary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ArithmeticUnaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_arithmeticUnary(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticUnaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ArithmeticUnaryContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ArithmeticUnaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ArithmeticUnaryContext<'input> {}

impl<'input> ArithmeticUnaryContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ArithmeticUnaryContext(
				BaseParserRuleContext::copy_from(ctx,ArithmeticUnaryContextExt{
					operator:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AtTimeZoneContext<'input> = BaseParserRuleContext<'input,AtTimeZoneContextExt<'input>>;

pub trait AtTimeZoneContextAttrs<'input>: DatabricksParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AT
	/// Returns `None` if there is no child corresponding to token AT
	fn AT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AT, 0)
	}
	fn timeZoneSpecifier(&self) -> Option<Rc<TimeZoneSpecifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AtTimeZoneContextAttrs<'input> for AtTimeZoneContext<'input>{}

pub struct AtTimeZoneContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AtTimeZoneContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for AtTimeZoneContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AtTimeZoneContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_atTimeZone(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_atTimeZone(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AtTimeZoneContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_atTimeZone(self);
	}
}

impl<'input> CustomRuleContext<'input> for AtTimeZoneContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for AtTimeZoneContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for AtTimeZoneContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for AtTimeZoneContext<'input> {}

impl<'input> AtTimeZoneContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::AtTimeZoneContext(
				BaseParserRuleContext::copy_from(ctx,AtTimeZoneContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  valueExpression(&mut self,)
	-> Result<Rc<ValueExpressionContextAll<'input>>,ANTLRError> {
		self.valueExpression_rec(0)
	}

	fn valueExpression_rec(&mut self, _p: isize)
	-> Result<Rc<ValueExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = ValueExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 326, RULE_valueExpression, _p);
	    let mut _localctx: Rc<ValueExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 326;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2906);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(399,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = ValueExpressionDefaultContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					/*InvokeRule primaryExpression*/
					recog.base.set_state(2903);
					recog.primaryExpression_rec(0)?;

					}
				}
			,
				2 =>{
					{
					let mut tmp = ArithmeticUnaryContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2904);
					if let ValueExpressionContextAll::ArithmeticUnaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
					ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(((((_la - 401)) & !0x3f) == 0 && ((1usize << (_la - 401)) & ((1usize << (PLUS - 401)) | (1usize << (MINUS - 401)) | (1usize << (POSIX - 401)))) != 0)) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let ValueExpressionContextAll::ArithmeticUnaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
						ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(2905);
					recog.valueExpression_rec(6)?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2928);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(401,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(2926);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(400,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2908);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							recog.base.set_state(2909);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==DIV || ((((_la - 403)) & !0x3f) == 0 && ((1usize << (_la - 403)) & ((1usize << (ASTERISK - 403)) | (1usize << (SLASH - 403)) | (1usize << (PERCENT - 403)))) != 0)) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2910);
							let tmp = recog.valueExpression_rec(6)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2911);
							if !({recog.precpred(None, 4)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 4)".to_owned()), None))?;
							}
							recog.base.set_state(2912);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==PLUS || _la==MINUS) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2913);
							let tmp = recog.valueExpression_rec(5)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ConcatenationContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ConcatenationContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2914);
							if !({recog.precpred(None, 3)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 3)".to_owned()), None))?;
							}
							recog.base.set_state(2915);
							recog.base.match_token(CONCAT,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(2916);
							let tmp = recog.valueExpression_rec(4)?;
							if let ValueExpressionContextAll::ConcatenationContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						4 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2917);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(2918);
							let tmp = recog.base.match_token(BITWISE_SHIFT_LEFT,&mut recog.err_handler)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							/*InvokeRule valueExpression*/
							recog.base.set_state(2919);
							let tmp = recog.valueExpression_rec(3)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						5 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2920);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(2921);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(((((_la - 411)) & !0x3f) == 0 && ((1usize << (_la - 411)) & ((1usize << (BITWISE_AND - 411)) | (1usize << (BITWISE_OR - 411)) | (1usize << (BITWISE_XOR - 411)))) != 0)) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(2922);
							let tmp = recog.valueExpression_rec(2)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						6 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = AtTimeZoneContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(2923);
							if !({recog.precpred(None, 7)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 7)".to_owned()), None))?;
							}
							recog.base.set_state(2924);
							recog.base.match_token(AT,&mut recog.err_handler)?;

							/*InvokeRule timeZoneSpecifier*/
							recog.base.set_state(2925);
							recog.timeZoneSpecifier()?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(2930);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(401,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- primaryExpression ----------------
#[derive(Debug)]
pub enum PrimaryExpressionContextAll<'input>{
	DereferenceContext(DereferenceContext<'input>),
	StructConstructorContext(StructConstructorContext<'input>),
	AnyValueContext(AnyValueContext<'input>),
	DecodeContext(DecodeContext<'input>),
	SubstringContext(SubstringContext<'input>),
	CountStarContext(CountStarContext<'input>),
	PercentileContFunctionContext(PercentileContFunctionContext<'input>),
	CastContext(CastContext<'input>),
	NamedStructContext(NamedStructContext<'input>),
	LambdaContext(LambdaContext<'input>),
	ParenthesizedExpressionContext(ParenthesizedExpressionContext<'input>),
	TrimContext(TrimContext<'input>),
	ArrayContext(ArrayContext<'input>),
	TryCastOperatorContext(TryCastOperatorContext<'input>),
	ArraysZipContext(ArraysZipContext<'input>),
	CastOperatorContext(CastOperatorContext<'input>),
	SimpleCaseContext(SimpleCaseContext<'input>),
	CurrentLikeContext(CurrentLikeContext<'input>),
	ColumnReferenceContext(ColumnReferenceContext<'input>),
	RowConstructorContext(RowConstructorContext<'input>),
	LastContext(LastContext<'input>),
	OverlayContext(OverlayContext<'input>),
	SubscriptContext(SubscriptContext<'input>),
	SubqueryExpressionContext(SubqueryExpressionContext<'input>),
	CollateContext(CollateContext<'input>),
	JsonExtractContext(JsonExtractContext<'input>),
	ConstantDefaultContext(ConstantDefaultContext<'input>),
	ExtractContext(ExtractContext<'input>),
	MeasureContext(MeasureContext<'input>),
	ArrayConstructorContext(ArrayConstructorContext<'input>),
	FunctionCallContext(FunctionCallContext<'input>),
	VariableContext(VariableContext<'input>),
	ExistsContext(ExistsContext<'input>),
	FromJsonContext(FromJsonContext<'input>),
	PercentileDiscFunctionContext(PercentileDiscFunctionContext<'input>),
	PositionContext(PositionContext<'input>),
	ListaggContext(ListaggContext<'input>),
	SearchedCaseContext(SearchedCaseContext<'input>),
	MapFromEntriesContext(MapFromEntriesContext<'input>),
	ModeFunctionContext(ModeFunctionContext<'input>),
	FirstContext(FirstContext<'input>),
Error(PrimaryExpressionContext<'input>)
}
antlr_rust::tid!{PrimaryExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PrimaryExpressionContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PrimaryExpressionContextAll<'input>{}

impl<'input> Deref for PrimaryExpressionContextAll<'input>{
	type Target = dyn PrimaryExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PrimaryExpressionContextAll::*;
		match self{
			DereferenceContext(inner) => inner,
			StructConstructorContext(inner) => inner,
			AnyValueContext(inner) => inner,
			DecodeContext(inner) => inner,
			SubstringContext(inner) => inner,
			CountStarContext(inner) => inner,
			PercentileContFunctionContext(inner) => inner,
			CastContext(inner) => inner,
			NamedStructContext(inner) => inner,
			LambdaContext(inner) => inner,
			ParenthesizedExpressionContext(inner) => inner,
			TrimContext(inner) => inner,
			ArrayContext(inner) => inner,
			TryCastOperatorContext(inner) => inner,
			ArraysZipContext(inner) => inner,
			CastOperatorContext(inner) => inner,
			SimpleCaseContext(inner) => inner,
			CurrentLikeContext(inner) => inner,
			ColumnReferenceContext(inner) => inner,
			RowConstructorContext(inner) => inner,
			LastContext(inner) => inner,
			OverlayContext(inner) => inner,
			SubscriptContext(inner) => inner,
			SubqueryExpressionContext(inner) => inner,
			CollateContext(inner) => inner,
			JsonExtractContext(inner) => inner,
			ConstantDefaultContext(inner) => inner,
			ExtractContext(inner) => inner,
			MeasureContext(inner) => inner,
			ArrayConstructorContext(inner) => inner,
			FunctionCallContext(inner) => inner,
			VariableContext(inner) => inner,
			ExistsContext(inner) => inner,
			FromJsonContext(inner) => inner,
			PercentileDiscFunctionContext(inner) => inner,
			PositionContext(inner) => inner,
			ListaggContext(inner) => inner,
			SearchedCaseContext(inner) => inner,
			MapFromEntriesContext(inner) => inner,
			ModeFunctionContext(inner) => inner,
			FirstContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrimaryExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrimaryExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PrimaryExpressionContext<'input> = BaseParserRuleContext<'input,PrimaryExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrimaryExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PrimaryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrimaryExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrimaryExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PrimaryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}
antlr_rust::tid!{PrimaryExpressionContextExt<'a>}

impl<'input> PrimaryExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrimaryExpressionContextAll<'input>> {
		Rc::new(
		PrimaryExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrimaryExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PrimaryExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PrimaryExpressionContextExt<'input>>{


}

impl<'input> PrimaryExpressionContextAttrs<'input> for PrimaryExpressionContext<'input>{}

pub type DereferenceContext<'input> = BaseParserRuleContext<'input,DereferenceContextExt<'input>>;

pub trait DereferenceContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn columnNameComponent(&self) -> Option<Rc<ColumnNameComponentContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DereferenceContextAttrs<'input> for DereferenceContext<'input>{}

pub struct DereferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub base_: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub fieldName: Option<Rc<ColumnNameComponentContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DereferenceContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DereferenceContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DereferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dereference(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_dereference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DereferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_dereference(self);
	}
}

impl<'input> CustomRuleContext<'input> for DereferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for DereferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for DereferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for DereferenceContext<'input> {}

impl<'input> DereferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::DereferenceContext(
				BaseParserRuleContext::copy_from(ctx,DereferenceContextExt{
        			base_:None, fieldName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StructConstructorContext<'input> = BaseParserRuleContext<'input,StructConstructorContextExt<'input>>;

pub trait StructConstructorContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STRUCT
	/// Returns `None` if there is no child corresponding to token STRUCT
	fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(STRUCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn structItem_all(&self) ->  Vec<Rc<StructItemContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn structItem(&self, i: usize) -> Option<Rc<StructItemContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> StructConstructorContextAttrs<'input> for StructConstructorContext<'input>{}

pub struct StructConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub structItem: Option<Rc<StructItemContextAll<'input>>>,
	pub argument:Vec<Rc<StructItemContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StructConstructorContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StructConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StructConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_structConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_structConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StructConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_structConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for StructConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for StructConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for StructConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for StructConstructorContext<'input> {}

impl<'input> StructConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::StructConstructorContext(
				BaseParserRuleContext::copy_from(ctx,StructConstructorContextExt{
        			structItem:None, 
        			argument:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AnyValueContext<'input> = BaseParserRuleContext<'input,AnyValueContextExt<'input>>;

pub trait AnyValueContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ANY_VALUE
	/// Returns `None` if there is no child corresponding to token ANY_VALUE
	fn ANY_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ANY_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IGNORE
	/// Returns `None` if there is no child corresponding to token IGNORE
	fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IGNORE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULLS
	/// Returns `None` if there is no child corresponding to token NULLS
	fn NULLS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NULLS, 0)
	}
}

impl<'input> AnyValueContextAttrs<'input> for AnyValueContext<'input>{}

pub struct AnyValueContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AnyValueContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for AnyValueContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for AnyValueContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_anyValue(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_anyValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for AnyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_anyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for AnyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for AnyValueContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for AnyValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for AnyValueContext<'input> {}

impl<'input> AnyValueContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::AnyValueContext(
				BaseParserRuleContext::copy_from(ctx,AnyValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DecodeContext<'input> = BaseParserRuleContext<'input,DecodeContextExt<'input>>;

pub trait DecodeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DECODE
	/// Returns `None` if there is no child corresponding to token DECODE
	fn DECODE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DECODE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> DecodeContextAttrs<'input> for DecodeContext<'input>{}

pub struct DecodeContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DecodeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DecodeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DecodeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_decode(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_decode(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DecodeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_decode(self);
	}
}

impl<'input> CustomRuleContext<'input> for DecodeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for DecodeContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for DecodeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for DecodeContext<'input> {}

impl<'input> DecodeContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::DecodeContext(
				BaseParserRuleContext::copy_from(ctx,DecodeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubstringContext<'input> = BaseParserRuleContext<'input,SubstringContextExt<'input>>;

pub trait SubstringContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SUBSTRING
	/// Returns `None` if there is no child corresponding to token SUBSTRING
	fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SUBSTRING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SUBSTR
	/// Returns `None` if there is no child corresponding to token SUBSTR
	fn SUBSTR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SUBSTR, 0)
	}
}

impl<'input> SubstringContextAttrs<'input> for SubstringContext<'input>{}

pub struct SubstringContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubstringContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SubstringContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SubstringContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_substring(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_substring(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SubstringContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_substring(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubstringContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubstringContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubstringContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubstringContext<'input> {}

impl<'input> SubstringContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubstringContext(
				BaseParserRuleContext::copy_from(ctx,SubstringContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CountStarContext<'input> = BaseParserRuleContext<'input,CountStarContextExt<'input>>;

pub trait CountStarContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COUNT
	/// Returns `None` if there is no child corresponding to token COUNT
	fn COUNT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COUNT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn functionCallTail(&self) -> Option<Rc<FunctionCallTailContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CountStarContextAttrs<'input> for CountStarContext<'input>{}

pub struct CountStarContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CountStarContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CountStarContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CountStarContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_countStar(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_countStar(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CountStarContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_countStar(self);
	}
}

impl<'input> CustomRuleContext<'input> for CountStarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CountStarContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CountStarContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CountStarContext<'input> {}

impl<'input> CountStarContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CountStarContext(
				BaseParserRuleContext::copy_from(ctx,CountStarContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PercentileContFunctionContext<'input> = BaseParserRuleContext<'input,PercentileContFunctionContextExt<'input>>;

pub trait PercentileContFunctionContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PERCENTILE_CONT
	/// Returns `None` if there is no child corresponding to token PERCENTILE_CONT
	fn PERCENTILE_CONT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PERCENTILE_CONT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OVER
	/// Returns `None` if there is no child corresponding to token OVER
	fn OVER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OVER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ASC
	/// Returns `None` if there is no child corresponding to token ASC
	fn ASC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ASC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PercentileContFunctionContextAttrs<'input> for PercentileContFunctionContext<'input>{}

pub struct PercentileContFunctionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PercentileContFunctionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PercentileContFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PercentileContFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_percentileContFunction(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_percentileContFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PercentileContFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_percentileContFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for PercentileContFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for PercentileContFunctionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for PercentileContFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for PercentileContFunctionContext<'input> {}

impl<'input> PercentileContFunctionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::PercentileContFunctionContext(
				BaseParserRuleContext::copy_from(ctx,PercentileContFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CastContext<'input> = BaseParserRuleContext<'input,CastContextExt<'input>>;

pub trait CastContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CAST
	/// Returns `None` if there is no child corresponding to token CAST
	fn CAST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CAST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRY_CAST
	/// Returns `None` if there is no child corresponding to token TRY_CAST
	fn TRY_CAST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TRY_CAST, 0)
	}
}

impl<'input> CastContextAttrs<'input> for CastContext<'input>{}

pub struct CastContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CastContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CastContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CastContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_cast(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_cast(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CastContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_cast(self);
	}
}

impl<'input> CustomRuleContext<'input> for CastContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CastContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CastContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CastContext<'input> {}

impl<'input> CastContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CastContext(
				BaseParserRuleContext::copy_from(ctx,CastContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NamedStructContext<'input> = BaseParserRuleContext<'input,NamedStructContextExt<'input>>;

pub trait NamedStructContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NAMED_STRUCT
	/// Returns `None` if there is no child corresponding to token NAMED_STRUCT
	fn NAMED_STRUCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NAMED_STRUCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> NamedStructContextAttrs<'input> for NamedStructContext<'input>{}

pub struct NamedStructContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NamedStructContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for NamedStructContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NamedStructContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_namedStruct(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_namedStruct(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NamedStructContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_namedStruct(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedStructContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for NamedStructContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for NamedStructContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for NamedStructContext<'input> {}

impl<'input> NamedStructContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::NamedStructContext(
				BaseParserRuleContext::copy_from(ctx,NamedStructContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LambdaContext<'input> = BaseParserRuleContext<'input,LambdaContextExt<'input>>;

pub trait LambdaContextAttrs<'input>: DatabricksParserContext<'input>{
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> LambdaContextAttrs<'input> for LambdaContext<'input>{}

pub struct LambdaContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LambdaContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LambdaContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LambdaContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_lambda(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_lambda(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LambdaContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_lambda(self);
	}
}

impl<'input> CustomRuleContext<'input> for LambdaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for LambdaContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for LambdaContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for LambdaContext<'input> {}

impl<'input> LambdaContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::LambdaContext(
				BaseParserRuleContext::copy_from(ctx,LambdaContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ParenthesizedExpressionContext<'input> = BaseParserRuleContext<'input,ParenthesizedExpressionContextExt<'input>>;

pub trait ParenthesizedExpressionContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ParenthesizedExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input>{}

pub struct ParenthesizedExpressionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ParenthesizedExpressionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ParenthesizedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_parenthesizedExpression(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_parenthesizedExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_parenthesizedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParenthesizedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ParenthesizedExpressionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ParenthesizedExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input> {}

impl<'input> ParenthesizedExpressionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ParenthesizedExpressionContext(
				BaseParserRuleContext::copy_from(ctx,ParenthesizedExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TrimContext<'input> = BaseParserRuleContext<'input,TrimContextExt<'input>>;

pub trait TrimContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRIM
	/// Returns `None` if there is no child corresponding to token TRIM
	fn TRIM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TRIM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn trimsSpecification(&self) -> Option<Rc<TrimsSpecificationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> TrimContextAttrs<'input> for TrimContext<'input>{}

pub struct TrimContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub trimChar: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub trimSource: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TrimContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TrimContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TrimContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_trim(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_trim(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TrimContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_trim(self);
	}
}

impl<'input> CustomRuleContext<'input> for TrimContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TrimContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TrimContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TrimContext<'input> {}

impl<'input> TrimContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TrimContext(
				BaseParserRuleContext::copy_from(ctx,TrimContextExt{
					tail:None, 
        			trimChar:None, trimSource:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArrayContext<'input> = BaseParserRuleContext<'input,ArrayContextExt<'input>>;

pub trait ArrayContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ArrayContextAttrs<'input> for ArrayContext<'input>{}

pub struct ArrayContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArrayContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ArrayContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ArrayContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_array(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_array(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ArrayContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_array(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArrayContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ArrayContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ArrayContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ArrayContext<'input> {}

impl<'input> ArrayContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ArrayContext(
				BaseParserRuleContext::copy_from(ctx,ArrayContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TryCastOperatorContext<'input> = BaseParserRuleContext<'input,TryCastOperatorContextExt<'input>>;

pub trait TryCastOperatorContextAttrs<'input>: DatabricksParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TryCastOperatorContextAttrs<'input> for TryCastOperatorContext<'input>{}

pub struct TryCastOperatorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TryCastOperatorContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TryCastOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TryCastOperatorContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tryCastOperator(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_tryCastOperator(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TryCastOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tryCastOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for TryCastOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TryCastOperatorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TryCastOperatorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TryCastOperatorContext<'input> {}

impl<'input> TryCastOperatorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TryCastOperatorContext(
				BaseParserRuleContext::copy_from(ctx,TryCastOperatorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArraysZipContext<'input> = BaseParserRuleContext<'input,ArraysZipContextExt<'input>>;

pub trait ArraysZipContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAYS_ZIP
	/// Returns `None` if there is no child corresponding to token ARRAYS_ZIP
	fn ARRAYS_ZIP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ARRAYS_ZIP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ArraysZipContextAttrs<'input> for ArraysZipContext<'input>{}

pub struct ArraysZipContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArraysZipContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ArraysZipContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ArraysZipContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arraysZip(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_arraysZip(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ArraysZipContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_arraysZip(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArraysZipContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ArraysZipContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ArraysZipContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ArraysZipContext<'input> {}

impl<'input> ArraysZipContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ArraysZipContext(
				BaseParserRuleContext::copy_from(ctx,ArraysZipContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CastOperatorContext<'input> = BaseParserRuleContext<'input,CastOperatorContextExt<'input>>;

pub trait CastOperatorContextAttrs<'input>: DatabricksParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CastOperatorContextAttrs<'input> for CastOperatorContext<'input>{}

pub struct CastOperatorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CastOperatorContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CastOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CastOperatorContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_castOperator(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_castOperator(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CastOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_castOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for CastOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CastOperatorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CastOperatorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CastOperatorContext<'input> {}

impl<'input> CastOperatorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CastOperatorContext(
				BaseParserRuleContext::copy_from(ctx,CastOperatorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SimpleCaseContext<'input> = BaseParserRuleContext<'input,SimpleCaseContextExt<'input>>;

pub trait SimpleCaseContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CASE
	/// Returns `None` if there is no child corresponding to token CASE
	fn CASE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CASE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn whenClause_all(&self) ->  Vec<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn whenClause(&self, i: usize) -> Option<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
}

impl<'input> SimpleCaseContextAttrs<'input> for SimpleCaseContext<'input>{}

pub struct SimpleCaseContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub operand: Option<Rc<ExpressionContextAll<'input>>>,
	pub elseExpression: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SimpleCaseContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SimpleCaseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SimpleCaseContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_simpleCase(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_simpleCase(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SimpleCaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_simpleCase(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SimpleCaseContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SimpleCaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SimpleCaseContext<'input> {}

impl<'input> SimpleCaseContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SimpleCaseContext(
				BaseParserRuleContext::copy_from(ctx,SimpleCaseContextExt{
        			operand:None, elseExpression:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CurrentLikeContext<'input> = BaseParserRuleContext<'input,CurrentLikeContextExt<'input>>;

pub trait CurrentLikeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CURRENT_DATE
	/// Returns `None` if there is no child corresponding to token CURRENT_DATE
	fn CURRENT_DATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CURRENT_DATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CURRENT_TIMESTAMP
	/// Returns `None` if there is no child corresponding to token CURRENT_TIMESTAMP
	fn CURRENT_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CURRENT_TIMESTAMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CURRENT_USER
	/// Returns `None` if there is no child corresponding to token CURRENT_USER
	fn CURRENT_USER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CURRENT_USER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USER
	/// Returns `None` if there is no child corresponding to token USER
	fn USER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(USER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SESSION_USER
	/// Returns `None` if there is no child corresponding to token SESSION_USER
	fn SESSION_USER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SESSION_USER, 0)
	}
}

impl<'input> CurrentLikeContextAttrs<'input> for CurrentLikeContext<'input>{}

pub struct CurrentLikeContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub name: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CurrentLikeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CurrentLikeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CurrentLikeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_currentLike(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_currentLike(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CurrentLikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_currentLike(self);
	}
}

impl<'input> CustomRuleContext<'input> for CurrentLikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CurrentLikeContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CurrentLikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CurrentLikeContext<'input> {}

impl<'input> CurrentLikeContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CurrentLikeContext(
				BaseParserRuleContext::copy_from(ctx,CurrentLikeContextExt{
					name:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ColumnReferenceContext<'input> = BaseParserRuleContext<'input,ColumnReferenceContextExt<'input>>;

pub trait ColumnReferenceContextAttrs<'input>: DatabricksParserContext<'input>{
	fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ColumnReferenceContextAttrs<'input> for ColumnReferenceContext<'input>{}

pub struct ColumnReferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnReferenceContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ColumnReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ColumnReferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnReference(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_columnReference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ColumnReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_columnReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ColumnReferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ColumnReferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ColumnReferenceContext<'input> {}

impl<'input> ColumnReferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ColumnReferenceContext(
				BaseParserRuleContext::copy_from(ctx,ColumnReferenceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RowConstructorContext<'input> = BaseParserRuleContext<'input,RowConstructorContextExt<'input>>;

pub trait RowConstructorContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> RowConstructorContextAttrs<'input> for RowConstructorContext<'input>{}

pub struct RowConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowConstructorContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RowConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RowConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_rowConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RowConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rowConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for RowConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for RowConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for RowConstructorContext<'input> {}

impl<'input> RowConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::RowConstructorContext(
				BaseParserRuleContext::copy_from(ctx,RowConstructorContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LastContext<'input> = BaseParserRuleContext<'input,LastContextExt<'input>>;

pub trait LastContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LAST
	/// Returns `None` if there is no child corresponding to token LAST
	fn LAST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LAST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IGNORE
	/// Returns `None` if there is no child corresponding to token IGNORE
	fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IGNORE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULLS
	/// Returns `None` if there is no child corresponding to token NULLS
	fn NULLS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NULLS, 0)
	}
}

impl<'input> LastContextAttrs<'input> for LastContext<'input>{}

pub struct LastContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LastContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LastContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LastContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_last(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_last(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LastContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_last(self);
	}
}

impl<'input> CustomRuleContext<'input> for LastContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for LastContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for LastContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for LastContext<'input> {}

impl<'input> LastContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::LastContext(
				BaseParserRuleContext::copy_from(ctx,LastContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type OverlayContext<'input> = BaseParserRuleContext<'input,OverlayContextExt<'input>>;

pub trait OverlayContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token OVERLAY
	/// Returns `None` if there is no child corresponding to token OVERLAY
	fn OVERLAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OVERLAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLACING
	/// Returns `None` if there is no child corresponding to token PLACING
	fn PLACING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PLACING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
}

impl<'input> OverlayContextAttrs<'input> for OverlayContext<'input>{}

pub struct OverlayContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub input: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub replace: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub position: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub length: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OverlayContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for OverlayContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for OverlayContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_overlay(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_overlay(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for OverlayContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_overlay(self);
	}
}

impl<'input> CustomRuleContext<'input> for OverlayContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for OverlayContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for OverlayContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for OverlayContext<'input> {}

impl<'input> OverlayContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::OverlayContext(
				BaseParserRuleContext::copy_from(ctx,OverlayContextExt{
        			input:None, replace:None, position:None, length:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubscriptContext<'input> = BaseParserRuleContext<'input,SubscriptContextExt<'input>>;

pub trait SubscriptContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SubscriptContextAttrs<'input> for SubscriptContext<'input>{}

pub struct SubscriptContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub value: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub index: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubscriptContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SubscriptContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SubscriptContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subscript(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_subscript(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SubscriptContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_subscript(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubscriptContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubscriptContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubscriptContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubscriptContext<'input> {}

impl<'input> SubscriptContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubscriptContext(
				BaseParserRuleContext::copy_from(ctx,SubscriptContextExt{
        			value:None, index:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubqueryExpressionContext<'input> = BaseParserRuleContext<'input,SubqueryExpressionContextExt<'input>>;

pub trait SubqueryExpressionContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> SubqueryExpressionContextAttrs<'input> for SubqueryExpressionContext<'input>{}

pub struct SubqueryExpressionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryExpressionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SubqueryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SubqueryExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subqueryExpression(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_subqueryExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SubqueryExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_subqueryExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubqueryExpressionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubqueryExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubqueryExpressionContext<'input> {}

impl<'input> SubqueryExpressionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubqueryExpressionContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CollateContext<'input> = BaseParserRuleContext<'input,CollateContextExt<'input>>;

pub trait CollateContextAttrs<'input>: DatabricksParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn collateClause(&self) -> Option<Rc<CollateClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CollateContextAttrs<'input> for CollateContext<'input>{}

pub struct CollateContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CollateContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CollateContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CollateContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_collate(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_collate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CollateContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_collate(self);
	}
}

impl<'input> CustomRuleContext<'input> for CollateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CollateContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CollateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CollateContext<'input> {}

impl<'input> CollateContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CollateContext(
				BaseParserRuleContext::copy_from(ctx,CollateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type JsonExtractContext<'input> = BaseParserRuleContext<'input,JsonExtractContextExt<'input>>;

pub trait JsonExtractContextAttrs<'input>: DatabricksParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COLON
	/// Returns `None` if there is no child corresponding to token COLON
	fn COLON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COLON, 0)
	}
	fn jsonPath(&self) -> Option<Rc<JsonPathContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> JsonExtractContextAttrs<'input> for JsonExtractContext<'input>{}

pub struct JsonExtractContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{JsonExtractContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for JsonExtractContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JsonExtractContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_jsonExtract(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_jsonExtract(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JsonExtractContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_jsonExtract(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonExtractContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for JsonExtractContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for JsonExtractContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for JsonExtractContext<'input> {}

impl<'input> JsonExtractContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::JsonExtractContext(
				BaseParserRuleContext::copy_from(ctx,JsonExtractContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ConstantDefaultContext<'input> = BaseParserRuleContext<'input,ConstantDefaultContextExt<'input>>;

pub trait ConstantDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ConstantDefaultContextAttrs<'input> for ConstantDefaultContext<'input>{}

pub struct ConstantDefaultContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ConstantDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ConstantDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ConstantDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_constantDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_constantDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ConstantDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_constantDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConstantDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ConstantDefaultContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ConstantDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ConstantDefaultContext<'input> {}

impl<'input> ConstantDefaultContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ConstantDefaultContext(
				BaseParserRuleContext::copy_from(ctx,ConstantDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExtractContext<'input> = BaseParserRuleContext<'input,ExtractContextExt<'input>>;

pub trait ExtractContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXTRACT
	/// Returns `None` if there is no child corresponding to token EXTRACT
	fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXTRACT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ExtractContextAttrs<'input> for ExtractContext<'input>{}

pub struct ExtractContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExtractContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ExtractContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExtractContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_extract(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_extract(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExtractContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_extract(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtractContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ExtractContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ExtractContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ExtractContext<'input> {}

impl<'input> ExtractContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ExtractContext(
				BaseParserRuleContext::copy_from(ctx,ExtractContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MeasureContext<'input> = BaseParserRuleContext<'input,MeasureContextExt<'input>>;

pub trait MeasureContextAttrs<'input>: DatabricksParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MeasureContextAttrs<'input> for MeasureContext<'input>{}

pub struct MeasureContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MeasureContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for MeasureContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MeasureContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_measure(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_measure(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MeasureContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_measure(self);
	}
}

impl<'input> CustomRuleContext<'input> for MeasureContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for MeasureContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for MeasureContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for MeasureContext<'input> {}

impl<'input> MeasureContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::MeasureContext(
				BaseParserRuleContext::copy_from(ctx,MeasureContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArrayConstructorContext<'input> = BaseParserRuleContext<'input,ArrayConstructorContextExt<'input>>;

pub trait ArrayConstructorContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LBRACKET
	/// Returns `None` if there is no child corresponding to token LBRACKET
	fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LBRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RBRACKET
	/// Returns `None` if there is no child corresponding to token RBRACKET
	fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RBRACKET, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ArrayConstructorContextAttrs<'input> for ArrayConstructorContext<'input>{}

pub struct ArrayConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArrayConstructorContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ArrayConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ArrayConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arrayConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_arrayConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ArrayConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_arrayConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArrayConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ArrayConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ArrayConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ArrayConstructorContext<'input> {}

impl<'input> ArrayConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ArrayConstructorContext(
				BaseParserRuleContext::copy_from(ctx,ArrayConstructorContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionCallContext<'input> = BaseParserRuleContext<'input,FunctionCallContextExt<'input>>;

pub trait FunctionCallContextAttrs<'input>: DatabricksParserContext<'input>{
	fn functionCallHead(&self) -> Option<Rc<FunctionCallHeadContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn functionCallTail(&self) -> Option<Rc<FunctionCallTailContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn functionExtraArguments(&self) -> Option<Rc<FunctionExtraArgumentsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn callArgument_all(&self) ->  Vec<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn callArgument(&self, i: usize) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> FunctionCallContextAttrs<'input> for FunctionCallContext<'input>{}

pub struct FunctionCallContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionCallContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for FunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FunctionCallContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionCall(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_functionCall(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FunctionCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_functionCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FunctionCallContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FunctionCallContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FunctionCallContext<'input> {}

impl<'input> FunctionCallContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FunctionCallContext(
				BaseParserRuleContext::copy_from(ctx,FunctionCallContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type VariableContext<'input> = BaseParserRuleContext<'input,VariableContextExt<'input>>;

pub trait VariableContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token VARIABLE
	/// Returns `None` if there is no child corresponding to token VARIABLE
	fn VARIABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(VARIABLE, 0)
	}
}

impl<'input> VariableContextAttrs<'input> for VariableContext<'input>{}

pub struct VariableContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{VariableContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for VariableContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for VariableContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_variable(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_variable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for VariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_variable(self);
	}
}

impl<'input> CustomRuleContext<'input> for VariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for VariableContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for VariableContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for VariableContext<'input> {}

impl<'input> VariableContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::VariableContext(
				BaseParserRuleContext::copy_from(ctx,VariableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExistsContext<'input> = BaseParserRuleContext<'input,ExistsContextExt<'input>>;

pub trait ExistsContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> ExistsContextAttrs<'input> for ExistsContext<'input>{}

pub struct ExistsContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExistsContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ExistsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExistsContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_exists(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_exists(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExistsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_exists(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExistsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ExistsContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ExistsContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ExistsContext<'input> {}

impl<'input> ExistsContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ExistsContext(
				BaseParserRuleContext::copy_from(ctx,ExistsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FromJsonContext<'input> = BaseParserRuleContext<'input,FromJsonContextExt<'input>>;

pub trait FromJsonContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FROM_JSON
	/// Returns `None` if there is no child corresponding to token FROM_JSON
	fn FROM_JSON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FROM_JSON, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> FromJsonContextAttrs<'input> for FromJsonContext<'input>{}

pub struct FromJsonContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FromJsonContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for FromJsonContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FromJsonContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_fromJson(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_fromJson(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FromJsonContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_fromJson(self);
	}
}

impl<'input> CustomRuleContext<'input> for FromJsonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FromJsonContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FromJsonContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FromJsonContext<'input> {}

impl<'input> FromJsonContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FromJsonContext(
				BaseParserRuleContext::copy_from(ctx,FromJsonContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PercentileDiscFunctionContext<'input> = BaseParserRuleContext<'input,PercentileDiscFunctionContextExt<'input>>;

pub trait PercentileDiscFunctionContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PERCENTILE_DISC
	/// Returns `None` if there is no child corresponding to token PERCENTILE_DISC
	fn PERCENTILE_DISC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PERCENTILE_DISC, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OVER
	/// Returns `None` if there is no child corresponding to token OVER
	fn OVER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OVER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ASC
	/// Returns `None` if there is no child corresponding to token ASC
	fn ASC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ASC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PercentileDiscFunctionContextAttrs<'input> for PercentileDiscFunctionContext<'input>{}

pub struct PercentileDiscFunctionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PercentileDiscFunctionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PercentileDiscFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PercentileDiscFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_percentileDiscFunction(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_percentileDiscFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PercentileDiscFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_percentileDiscFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for PercentileDiscFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for PercentileDiscFunctionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for PercentileDiscFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for PercentileDiscFunctionContext<'input> {}

impl<'input> PercentileDiscFunctionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::PercentileDiscFunctionContext(
				BaseParserRuleContext::copy_from(ctx,PercentileDiscFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PositionContext<'input> = BaseParserRuleContext<'input,PositionContextExt<'input>>;

pub trait PositionContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token POSITION
	/// Returns `None` if there is no child corresponding to token POSITION
	fn POSITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(POSITION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> PositionContextAttrs<'input> for PositionContext<'input>{}

pub struct PositionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub needle: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub haystack: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PositionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PositionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PositionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_position(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_position(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PositionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_position(self);
	}
}

impl<'input> CustomRuleContext<'input> for PositionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for PositionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for PositionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for PositionContext<'input> {}

impl<'input> PositionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::PositionContext(
				BaseParserRuleContext::copy_from(ctx,PositionContextExt{
        			needle:None, haystack:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ListaggContext<'input> = BaseParserRuleContext<'input,ListaggContextExt<'input>>;

pub trait ListaggContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LISTAGG
	/// Returns `None` if there is no child corresponding to token LISTAGG
	fn LISTAGG(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LISTAGG, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OVER
	/// Returns `None` if there is no child corresponding to token OVER
	fn OVER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OVER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
}

impl<'input> ListaggContextAttrs<'input> for ListaggContext<'input>{}

pub struct ListaggContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub agg_exprs:Vec<Rc<ExpressionContextAll<'input>>>,
	pub agg_expr:Vec<Rc<ExpressionContextAll<'input>>>,
	pub COMMA: Option<TokenType<'input>>,
	pub tail:Vec<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ListaggContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ListaggContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ListaggContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_listagg(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_listagg(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ListaggContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_listagg(self);
	}
}

impl<'input> CustomRuleContext<'input> for ListaggContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ListaggContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ListaggContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ListaggContext<'input> {}

impl<'input> ListaggContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ListaggContext(
				BaseParserRuleContext::copy_from(ctx,ListaggContextExt{
					COMMA:None, 
        			tail:Vec::new(), 
        			expression:None, 
        			agg_exprs:Vec::new(), agg_expr:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SearchedCaseContext<'input> = BaseParserRuleContext<'input,SearchedCaseContextExt<'input>>;

pub trait SearchedCaseContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CASE
	/// Returns `None` if there is no child corresponding to token CASE
	fn CASE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CASE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn whenClause_all(&self) ->  Vec<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn whenClause(&self, i: usize) -> Option<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SearchedCaseContextAttrs<'input> for SearchedCaseContext<'input>{}

pub struct SearchedCaseContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub elseExpression: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SearchedCaseContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SearchedCaseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SearchedCaseContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_searchedCase(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_searchedCase(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SearchedCaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_searchedCase(self);
	}
}

impl<'input> CustomRuleContext<'input> for SearchedCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SearchedCaseContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SearchedCaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SearchedCaseContext<'input> {}

impl<'input> SearchedCaseContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SearchedCaseContext(
				BaseParserRuleContext::copy_from(ctx,SearchedCaseContextExt{
        			elseExpression:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MapFromEntriesContext<'input> = BaseParserRuleContext<'input,MapFromEntriesContextExt<'input>>;

pub trait MapFromEntriesContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MAP_FROM_ENTRIES
	/// Returns `None` if there is no child corresponding to token MAP_FROM_ENTRIES
	fn MAP_FROM_ENTRIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MAP_FROM_ENTRIES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn callArgument(&self) -> Option<Rc<CallArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> MapFromEntriesContextAttrs<'input> for MapFromEntriesContext<'input>{}

pub struct MapFromEntriesContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MapFromEntriesContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for MapFromEntriesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MapFromEntriesContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_mapFromEntries(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_mapFromEntries(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MapFromEntriesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_mapFromEntries(self);
	}
}

impl<'input> CustomRuleContext<'input> for MapFromEntriesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for MapFromEntriesContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for MapFromEntriesContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for MapFromEntriesContext<'input> {}

impl<'input> MapFromEntriesContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::MapFromEntriesContext(
				BaseParserRuleContext::copy_from(ctx,MapFromEntriesContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ModeFunctionContext<'input> = BaseParserRuleContext<'input,ModeFunctionContextExt<'input>>;

pub trait ModeFunctionContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MODE
	/// Returns `None` if there is no child corresponding to token MODE
	fn MODE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MODE, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
	fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
	fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
	fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
	fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OVER
	/// Returns `None` if there is no child corresponding to token OVER
	fn OVER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(OVER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ASC
	/// Returns `None` if there is no child corresponding to token ASC
	fn ASC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ASC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ModeFunctionContextAttrs<'input> for ModeFunctionContext<'input>{}

pub struct ModeFunctionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ModeFunctionContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ModeFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ModeFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_modeFunction(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_modeFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ModeFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_modeFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for ModeFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ModeFunctionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ModeFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ModeFunctionContext<'input> {}

impl<'input> ModeFunctionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ModeFunctionContext(
				BaseParserRuleContext::copy_from(ctx,ModeFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FirstContext<'input> = BaseParserRuleContext<'input,FirstContextExt<'input>>;

pub trait FirstContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FIRST
	/// Returns `None` if there is no child corresponding to token FIRST
	fn FIRST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FIRST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IGNORE
	/// Returns `None` if there is no child corresponding to token IGNORE
	fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IGNORE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULLS
	/// Returns `None` if there is no child corresponding to token NULLS
	fn NULLS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NULLS, 0)
	}
}

impl<'input> FirstContextAttrs<'input> for FirstContext<'input>{}

pub struct FirstContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FirstContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for FirstContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FirstContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_first(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_first(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FirstContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_first(self);
	}
}

impl<'input> CustomRuleContext<'input> for FirstContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FirstContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FirstContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FirstContext<'input> {}

impl<'input> FirstContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FirstContext(
				BaseParserRuleContext::copy_from(ctx,FirstContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  primaryExpression(&mut self,)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		self.primaryExpression_rec(0)
	}

	fn primaryExpression_rec(&mut self, _p: isize)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = PrimaryExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 328, RULE_primaryExpression, _p);
	    let mut _localctx: Rc<PrimaryExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 328;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3403);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(461,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = CurrentLikeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					recog.base.set_state(2932);
					if let PrimaryExpressionContextAll::CurrentLikeContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.name = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(((((_la - 70)) & !0x3f) == 0 && ((1usize << (_la - 70)) & ((1usize << (CURRENT_DATE - 70)) | (1usize << (CURRENT_TIMESTAMP - 70)) | (1usize << (CURRENT_USER - 70)))) != 0) || _la==SESSION_USER || _la==USER) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let PrimaryExpressionContextAll::CurrentLikeContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.name = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}
			,
				2 =>{
					{
					let mut tmp = ConstantDefaultContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule constant*/
					recog.base.set_state(2933);
					recog.constant()?;

					}
				}
			,
				3 =>{
					{
					let mut tmp = RowConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2934);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2935);
					recog.expression()?;

					recog.base.set_state(2938); 
					recog.err_handler.sync(&mut recog.base)?;
					_alt = 1;
					loop {
						match _alt {
						    x if x == 1=>
							{
							{
							recog.base.set_state(2936);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2937);
							recog.expression()?;

							}
							}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						recog.base.set_state(2940); 
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(402,&mut recog.base)?;
						if _alt==2 || _alt==INVALID_ALT { break }
					}
					recog.base.set_state(2943);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2942);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::RowConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(2945);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					{
					let mut tmp = StructConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2947);
					recog.base.match_token(STRUCT,&mut recog.err_handler)?;

					recog.base.set_state(2948);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2957);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
						{
						/*InvokeRule structItem*/
						recog.base.set_state(2949);
						let tmp = recog.structItem()?;
						if let PrimaryExpressionContextAll::StructConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.structItem = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let PrimaryExpressionContextAll::StructConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.structItem.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let PrimaryExpressionContextAll::StructConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.argument.push(temp); } else {unreachable!("cant cast");}  
						recog.base.set_state(2954);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(2950);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule structItem*/
							recog.base.set_state(2951);
							let tmp = recog.structItem()?;
							if let PrimaryExpressionContextAll::StructConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.structItem = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							let temp = if let PrimaryExpressionContextAll::StructConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.structItem.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let PrimaryExpressionContextAll::StructConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.argument.push(temp); } else {unreachable!("cant cast");}  
							}
							}
							recog.base.set_state(2956);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					recog.base.set_state(2959);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					{
					let mut tmp = PositionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2960);
					recog.base.match_token(POSITION,&mut recog.err_handler)?;

					recog.base.set_state(2961);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2962);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::PositionContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.needle = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2963);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2964);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::PositionContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.haystack = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2965);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					{
					let mut tmp = ListaggContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(2967);
					recog.base.match_token(LISTAGG,&mut recog.err_handler)?;

					recog.base.set_state(2968);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2970);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(406,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(2969);
							recog.setQuantifier()?;

							}
						}

						_ => {}
					}
					/*InvokeRule expression*/
					recog.base.set_state(2972);
					let tmp = recog.expression()?;
					if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.agg_exprs.push(temp); } else {unreachable!("cant cast");}  
					recog.base.set_state(2975);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(407,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2973);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2974);
							let tmp = recog.expression()?;
							if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							let temp = if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.agg_expr.push(temp); } else {unreachable!("cant cast");}  
							}
						}

						_ => {}
					}
					recog.base.set_state(2978);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(2977);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

						let temp = if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail.push(temp); } else {unreachable!("cant cast");}  
						}
					}

					recog.base.set_state(2980);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2999);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(411,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2981);
							recog.base.match_token(WITHIN,&mut recog.err_handler)?;

							recog.base.set_state(2982);
							recog.base.match_token(GROUP,&mut recog.err_handler)?;

							recog.base.set_state(2983);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(2984);
							recog.base.match_token(ORDER,&mut recog.err_handler)?;

							recog.base.set_state(2985);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule sortItem*/
							recog.base.set_state(2986);
							recog.sortItem()?;

							recog.base.set_state(2991);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(409,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(2987);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule sortItem*/
									recog.base.set_state(2988);
									recog.sortItem()?;

									}
									} 
								}
								recog.base.set_state(2993);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(409,&mut recog.base)?;
							}
							recog.base.set_state(2995);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2994);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.COMMA = Some(tmp); } else {unreachable!("cant cast");}  

								let temp = if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.COMMA.clone().unwrap() } else {unreachable!("cant cast");} ;
								if let PrimaryExpressionContextAll::ListaggContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.tail.push(temp); } else {unreachable!("cant cast");}  
								}
							}

							recog.base.set_state(2997);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3016);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(414,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3001);
							recog.base.match_token(OVER,&mut recog.err_handler)?;

							recog.base.set_state(3002);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(3013);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==PARTITION {
								{
								recog.base.set_state(3003);
								recog.base.match_token(PARTITION,&mut recog.err_handler)?;

								recog.base.set_state(3004);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3005);
								recog.expression()?;

								recog.base.set_state(3010);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(3006);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(3007);
									recog.expression()?;

									}
									}
									recog.base.set_state(3012);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							recog.base.set_state(3015);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				7 =>{
					{
					let mut tmp = ExistsContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3018);
					recog.base.match_token(EXISTS,&mut recog.err_handler)?;

					recog.base.set_state(3019);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(3020);
					recog.query()?;

					recog.base.set_state(3021);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					{
					let mut tmp = SimpleCaseContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3023);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3024);
					let tmp = recog.expression()?;
					if let PrimaryExpressionContextAll::SimpleCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.operand = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3026); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule whenClause*/
						recog.base.set_state(3025);
						recog.whenClause()?;

						}
						}
						recog.base.set_state(3028); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(3032);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(3030);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(3031);
						let tmp = recog.expression()?;
						if let PrimaryExpressionContextAll::SimpleCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.elseExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3034);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				9 =>{
					{
					let mut tmp = SearchedCaseContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3036);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					recog.base.set_state(3038); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule whenClause*/
						recog.base.set_state(3037);
						recog.whenClause()?;

						}
						}
						recog.base.set_state(3040); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(3044);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(3042);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(3043);
						let tmp = recog.expression()?;
						if let PrimaryExpressionContextAll::SearchedCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.elseExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3046);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					{
					let mut tmp = CastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3048);
					recog.base.match_token(CAST,&mut recog.err_handler)?;

					recog.base.set_state(3049);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3050);
					recog.expression()?;

					recog.base.set_state(3051);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(3052);
					recog.type_()?;

					recog.base.set_state(3053);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					{
					let mut tmp = CastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3055);
					recog.base.match_token(TRY_CAST,&mut recog.err_handler)?;

					recog.base.set_state(3056);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3057);
					recog.expression()?;

					recog.base.set_state(3058);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(3059);
					recog.type_()?;

					recog.base.set_state(3060);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3062);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(3063);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					{
					recog.base.set_state(3065);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(419,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule trimsSpecification*/
							recog.base.set_state(3064);
							recog.trimsSpecification()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3068);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(420,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule valueExpression*/
							recog.base.set_state(3067);
							let tmp = recog.valueExpression_rec(0)?;
							if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(3070);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(3072);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3073);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				13 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3075);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(3076);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3084);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(423,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule trimsSpecification*/
							recog.base.set_state(3077);
							recog.trimsSpecification()?;

							recog.base.set_state(3079);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(421,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule valueExpression*/
									recog.base.set_state(3078);
									let tmp = recog.valueExpression_rec(0)?;
									if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
									ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									}
								}

								_ => {}
							}
							recog.base.set_state(3082);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(422,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(3081);
									recog.base.match_token(FROM,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(3086);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3087);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				14 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3089);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(3090);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3091);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimSource = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3092);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3093);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.trimChar = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3095);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3094);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3097);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				15 =>{
					{
					let mut tmp = SubstringContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3099);
					recog.base.match_token(SUBSTRING,&mut recog.err_handler)?;

					recog.base.set_state(3100);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3101);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(3102);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3103);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(3106);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(3104);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						/*InvokeRule valueExpression*/
						recog.base.set_state(3105);
						recog.valueExpression_rec(0)?;

						}
					}

					recog.base.set_state(3108);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				16 =>{
					{
					let mut tmp = SubstringContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3110);
					recog.base.match_token(SUBSTR,&mut recog.err_handler)?;

					recog.base.set_state(3111);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3112);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(3113);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3114);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(3117);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(3115);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						/*InvokeRule valueExpression*/
						recog.base.set_state(3116);
						recog.valueExpression_rec(0)?;

						}
					}

					recog.base.set_state(3119);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				17 =>{
					{
					let mut tmp = ExtractContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3121);
					recog.base.match_token(EXTRACT,&mut recog.err_handler)?;

					recog.base.set_state(3122);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3123);
					recog.identifier()?;

					recog.base.set_state(3124);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3125);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(3126);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				18 =>{
					{
					let mut tmp = FirstContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3128);
					recog.base.match_token(FIRST,&mut recog.err_handler)?;

					recog.base.set_state(3129);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3130);
					recog.expression()?;

					recog.base.set_state(3133);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IGNORE {
						{
						recog.base.set_state(3131);
						recog.base.match_token(IGNORE,&mut recog.err_handler)?;

						recog.base.set_state(3132);
						recog.base.match_token(NULLS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3135);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				19 =>{
					{
					let mut tmp = AnyValueContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3137);
					recog.base.match_token(ANY_VALUE,&mut recog.err_handler)?;

					recog.base.set_state(3138);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3139);
					recog.expression()?;

					recog.base.set_state(3142);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IGNORE {
						{
						recog.base.set_state(3140);
						recog.base.match_token(IGNORE,&mut recog.err_handler)?;

						recog.base.set_state(3141);
						recog.base.match_token(NULLS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3144);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				20 =>{
					{
					let mut tmp = LastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3146);
					recog.base.match_token(LAST,&mut recog.err_handler)?;

					recog.base.set_state(3147);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3148);
					recog.expression()?;

					recog.base.set_state(3151);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IGNORE {
						{
						recog.base.set_state(3149);
						recog.base.match_token(IGNORE,&mut recog.err_handler)?;

						recog.base.set_state(3150);
						recog.base.match_token(NULLS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3153);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				21 =>{
					{
					let mut tmp = FromJsonContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3155);
					recog.base.match_token(FROM_JSON,&mut recog.err_handler)?;

					recog.base.set_state(3156);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3157);
					recog.expression()?;

					recog.base.set_state(3158);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(3159);
					recog.string()?;

					recog.base.set_state(3160);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				22 =>{
					{
					let mut tmp = NamedStructContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3162);
					recog.base.match_token(NAMED_STRUCT,&mut recog.err_handler)?;

					recog.base.set_state(3163);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3172);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
						{
						/*InvokeRule callArgument*/
						recog.base.set_state(3164);
						recog.callArgument()?;

						recog.base.set_state(3169);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(3165);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule callArgument*/
							recog.base.set_state(3166);
							recog.callArgument()?;

							}
							}
							recog.base.set_state(3171);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					recog.base.set_state(3174);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				23 =>{
					{
					let mut tmp = MapFromEntriesContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3175);
					recog.base.match_token(MAP_FROM_ENTRIES,&mut recog.err_handler)?;

					recog.base.set_state(3176);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule callArgument*/
					recog.base.set_state(3177);
					recog.callArgument()?;

					recog.base.set_state(3178);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				24 =>{
					{
					let mut tmp = ArraysZipContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3180);
					recog.base.match_token(ARRAYS_ZIP,&mut recog.err_handler)?;

					recog.base.set_state(3181);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3190);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
						{
						/*InvokeRule callArgument*/
						recog.base.set_state(3182);
						recog.callArgument()?;

						recog.base.set_state(3187);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(3183);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule callArgument*/
							recog.base.set_state(3184);
							recog.callArgument()?;

							}
							}
							recog.base.set_state(3189);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					recog.base.set_state(3192);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				25 =>{
					{
					let mut tmp = DecodeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3193);
					recog.base.match_token(DECODE,&mut recog.err_handler)?;

					recog.base.set_state(3194);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3204);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
						{
						/*InvokeRule callArgument*/
						recog.base.set_state(3195);
						recog.callArgument()?;

						recog.base.set_state(3196);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule callArgument*/
						recog.base.set_state(3197);
						recog.callArgument()?;

						recog.base.set_state(3200); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						loop {
							{
							{
							recog.base.set_state(3198);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule callArgument*/
							recog.base.set_state(3199);
							recog.callArgument()?;

							}
							}
							recog.base.set_state(3202); 
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if !(_la==COMMA) {break}
						}
						}
					}

					recog.base.set_state(3206);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				26 =>{
					{
					let mut tmp = CountStarContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3207);
					recog.base.match_token(COUNT,&mut recog.err_handler)?;

					recog.base.set_state(3208);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3209);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(3210);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule functionCallTail*/
					recog.base.set_state(3211);
					recog.functionCallTail()?;

					}
				}
			,
				27 =>{
					{
					let mut tmp = FunctionCallContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule functionCallHead*/
					recog.base.set_state(3212);
					recog.functionCallHead()?;

					/*InvokeRule functionName*/
					recog.base.set_state(3213);
					recog.functionName()?;

					recog.base.set_state(3214);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					{
					recog.base.set_state(3226);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (ASTERISK - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
						{
						recog.base.set_state(3216);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(436,&mut recog.base)? {
							x if x == 1=>{
								{
								/*InvokeRule setQuantifier*/
								recog.base.set_state(3215);
								recog.setQuantifier()?;

								}
							}

							_ => {}
						}
						/*InvokeRule callArgument*/
						recog.base.set_state(3218);
						recog.callArgument()?;

						recog.base.set_state(3223);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(3219);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule callArgument*/
							recog.base.set_state(3220);
							recog.callArgument()?;

							}
							}
							recog.base.set_state(3225);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					/*InvokeRule functionExtraArguments*/
					recog.base.set_state(3228);
					recog.functionExtraArguments()?;

					}
					recog.base.set_state(3230);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule functionCallTail*/
					recog.base.set_state(3231);
					recog.functionCallTail()?;

					}
				}
			,
				28 =>{
					{
					let mut tmp = MeasureContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(3233);
					recog.identifier()?;

					/*InvokeRule over*/
					recog.base.set_state(3234);
					recog.over()?;

					}
				}
			,
				29 =>{
					{
					let mut tmp = LambdaContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(3236);
					recog.identifier()?;

					recog.base.set_state(3237);
					recog.base.match_token(T__1,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3238);
					recog.expression()?;

					}
				}
			,
				30 =>{
					{
					let mut tmp = LambdaContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3240);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3249);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if ((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANTI - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CROSS - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCEPT - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FULL - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INNER - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERSECT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (JOIN - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LATERAL - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LEFT - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUS_KW - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NATURAL - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ON - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RIGHT - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEMI - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)) | (1usize << (UNION - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (USING - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0) || _la==IDENTIFIER || _la==BACKQUOTED_IDENTIFIER {
						{
						/*InvokeRule identifier*/
						recog.base.set_state(3241);
						recog.identifier()?;

						recog.base.set_state(3246);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(439,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(3242);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule identifier*/
								recog.base.set_state(3243);
								recog.identifier()?;

								}
								} 
							}
							recog.base.set_state(3248);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(439,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(3252);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3251);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::LambdaContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3254);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3255);
					recog.base.match_token(T__1,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3256);
					recog.expression()?;

					}
				}
			,
				31 =>{
					{
					let mut tmp = SubqueryExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3257);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(3258);
					recog.query()?;

					recog.base.set_state(3259);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				32 =>{
					{
					let mut tmp = ArrayConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3261);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(3262);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(3271);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(3263);
						recog.expression()?;

						recog.base.set_state(3268);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(442,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(3264);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3265);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(3270);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(442,&mut recog.base)?;
						}
						}
					}

					recog.base.set_state(3274);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3273);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let PrimaryExpressionContextAll::ArrayConstructorContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3276);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				33 =>{
					{
					let mut tmp = ColumnReferenceContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule columnName*/
					recog.base.set_state(3277);
					recog.columnName()?;

					}
				}
			,
				34 =>{
					{
					let mut tmp = ParenthesizedExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3278);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3279);
					recog.expression()?;

					recog.base.set_state(3280);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				35 =>{
					{
					let mut tmp = ArrayContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3282);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(3294);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANTI) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ARRAYS_ZIP) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << X_KW) | (1usize << BINDING) | (1usize << BOOLEAN) | (1usize << BOTH) | (1usize << BUCKET) | (1usize << BUCKETS))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)) | (1usize << (COMPUTE - 32)) | (1usize << (CONCATENATE - 32)) | (1usize << (CONSTRAINT - 32)) | (1usize << (CONTAINS - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COST - 64)) | (1usize << (COUNT - 64)) | (1usize << (CREATE - 64)) | (1usize << (CROSS - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DECODE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)) | (1usize << (DEFINER - 64)) | (1usize << (DELETE - 64)) | (1usize << (DELIMITED - 64)) | (1usize << (DESC - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (END - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCEPT - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXECUTE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTENDED - 96)) | (1usize << (EXTERNAL - 96)) | (1usize << (EXTRACT - 96)) | (1usize << (FALSE - 96)) | (1usize << (FETCH - 96)) | (1usize << (FIELDS - 96)) | (1usize << (FILTER - 96)) | (1usize << (FILEFORMAT - 96)) | (1usize << (FIRST - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (FLOAT - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FROM - 128)) | (1usize << (FROM_JSON - 128)) | (1usize << (FULL - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HAVING - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)) | (1usize << (IDENTIFIER_KW - 128)) | (1usize << (IDENTITY - 128)) | (1usize << (IF - 128)) | (1usize << (IGNORE - 128)) | (1usize << (IMMEDIATE - 128)) | (1usize << (IMPORT - 128)) | (1usize << (IN - 128)) | (1usize << (INCLUDE - 128)) | (1usize << (INDEX - 128)) | (1usize << (INDEXES - 128)) | (1usize << (INNER - 128)) | (1usize << (INPATH - 128)) | (1usize << (INPUT - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERSECT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ILIKE - 160)) | (1usize << (JOIN - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)) | (1usize << (LATERAL - 160)) | (1usize << (LAZY - 160)) | (1usize << (LEADING - 160)) | (1usize << (LEFT - 160)) | (1usize << (LIKE - 160)) | (1usize << (LIMIT - 160)) | (1usize << (LINES - 160)) | (1usize << (LIST - 160)) | (1usize << (LISTAGG - 160)) | (1usize << (LIVE - 160)) | (1usize << (LOAD - 160)) | (1usize << (LOCAL - 160)) | (1usize << (LOCATION - 160)) | (1usize << (LOCK - 160)) | (1usize << (LOCKS - 160)) | (1usize << (LOGICAL - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LONG - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MAP_FROM_ENTRIES - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MERGE - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUS_KW - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)) | (1usize << (MODE - 192)) | (1usize << (MODIFIES - 192)) | (1usize << (MONTH - 192)) | (1usize << (MONTHS - 192)) | (1usize << (MSCK - 192)) | (1usize << (NAME - 192)) | (1usize << (NAMESPACE - 192)) | (1usize << (NAMESPACES - 192)) | (1usize << (NAMED_STRUCT - 192)) | (1usize << (NANOSECOND - 192)) | (1usize << (NANOSECONDS - 192)) | (1usize << (NATURAL - 192)) | (1usize << (NO - 192)) | (1usize << (NONE - 192)) | (1usize << (NOT - 192)) | (1usize << (NULL - 192)) | (1usize << (NULLS - 192)) | (1usize << (NUMERIC - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ON - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTIMIZE - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)) | (1usize << (PARTITION - 224)) | (1usize << (PARTITIONED - 224)) | (1usize << (PARTITIONS - 224)) | (1usize << (PERCENT_KW - 224)) | (1usize << (PERCENTILE_CONT - 224)) | (1usize << (PERCENTILE_DISC - 224)) | (1usize << (PIVOT - 224)) | (1usize << (PLACING - 224)) | (1usize << (POSITION - 224)) | (1usize << (PRECEDING - 224)) | (1usize << (PRIMARY - 224)) | (1usize << (PRINCIPALS - 224)) | (1usize << (PROPERTIES - 224)) | (1usize << (PRUNE - 224)) | (1usize << (PURGE - 224)) | (1usize << (QUALIFY - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REGEXP - 256)) | (1usize << (REFERENCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEATABLE - 256)) | (1usize << (REPLACE - 256)) | (1usize << (RESET - 256)) | (1usize << (RESPECT - 256)) | (1usize << (RESTRICT - 256)) | (1usize << (RETURN - 256)) | (1usize << (RETURNS - 256)) | (1usize << (REVOKE - 256)) | (1usize << (RIGHT - 256)) | (1usize << (RLIKE - 256)) | (1usize << (ROLE - 256)) | (1usize << (ROLES - 256)) | (1usize << (ROLLBACK - 256)) | (1usize << (ROLLUP - 256)) | (1usize << (ROW - 256)) | (1usize << (ROWS - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)) | (1usize << (SKEWED - 288)) | (1usize << (SMALLINT - 288)) | (1usize << (SOME - 288)) | (1usize << (SORT - 288)) | (1usize << (SORTED - 288)) | (1usize << (SOURCE - 288)) | (1usize << (SPECIFIC - 288)) | (1usize << (SQL - 288)) | (1usize << (START - 288)) | (1usize << (STATISTICS - 288)) | (1usize << (STORED - 288)) | (1usize << (STRATIFY - 288)) | (1usize << (STREAM - 288)) | (1usize << (STREAMING - 288)) | (1usize << (STRUCT - 288)) | (1usize << (SUBSTR - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMP - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (STRING_KW - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)) | (1usize << (TIMEDIFF - 320)) | (1usize << (TIMESTAMP - 320)) | (1usize << (TIMESTAMPADD - 320)) | (1usize << (TIMESTAMPDIFF - 320)) | (1usize << (TIMESTAMP_LTZ - 320)) | (1usize << (TIMESTAMP_NTZ - 320)) | (1usize << (TINYINT - 320)) | (1usize << (TO - 320)) | (1usize << (TOUCH - 320)) | (1usize << (TRAILING - 320)) | (1usize << (TRANSACTION - 320)) | (1usize << (TRANSACTIONS - 320)) | (1usize << (TRANSFORM - 320)) | (1usize << (TRIM - 320)) | (1usize << (TRUE - 320)) | (1usize << (TRUNCATE - 320)) | (1usize << (TRY_CAST - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNION - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)) | (1usize << (USING - 352)) | (1usize << (VALUES - 352)) | (1usize << (VAR - 352)) | (1usize << (VARCHAR - 352)) | (1usize << (VARIANT - 352)) | (1usize << (VERSION - 352)) | (1usize << (VIEW - 352)) | (1usize << (VIEWS - 352)) | (1usize << (VOID - 352)) | (1usize << (WEEK - 352)) | (1usize << (WEEKS - 352)) | (1usize << (WHEN - 352)) | (1usize << (WHERE - 352)) | (1usize << (WHILE - 352)) | (1usize << (WINDOW - 352)) | (1usize << (WITH - 352)) | (1usize << (WITHIN - 352)) | (1usize << (YEAR - 352)) | (1usize << (YEARS - 352)))) != 0) || ((((_la - 384)) & !0x3f) == 0 && ((1usize << (_la - 384)) & ((1usize << (ZONE - 384)) | (1usize << (LPAREN - 384)) | (1usize << (LBRACKET - 384)) | (1usize << (BANG - 384)) | (1usize << (PLUS - 384)) | (1usize << (MINUS - 384)) | (1usize << (QUESTION_MARK - 384)) | (1usize << (COLON - 384)) | (1usize << (POSIX - 384)))) != 0) || ((((_la - 417)) & !0x3f) == 0 && ((1usize << (_la - 417)) & ((1usize << (STRING - 417)) | (1usize << (DOUBLEQUOTED_STRING - 417)) | (1usize << (INTEGER_VALUE - 417)) | (1usize << (BIGINT_VALUE - 417)) | (1usize << (SMALLINT_VALUE - 417)) | (1usize << (TINYINT_VALUE - 417)) | (1usize << (EXPONENT_VALUE - 417)) | (1usize << (DECIMAL_VALUE - 417)) | (1usize << (FLOAT_VALUE - 417)) | (1usize << (DOUBLE_VALUE - 417)) | (1usize << (BIGDECIMAL_VALUE - 417)) | (1usize << (IDENTIFIER - 417)) | (1usize << (BACKQUOTED_IDENTIFIER - 417)) | (1usize << (VARIABLE - 417)))) != 0) {
						{
						/*InvokeRule expression*/
						recog.base.set_state(3283);
						recog.expression()?;

						recog.base.set_state(3288);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(445,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(3284);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3285);
								recog.expression()?;

								}
								} 
							}
							recog.base.set_state(3290);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(445,&mut recog.base)?;
						}
						recog.base.set_state(3292);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==COMMA {
							{
							recog.base.set_state(3291);
							let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
							if let PrimaryExpressionContextAll::ArrayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

							}
						}

						}
					}

					recog.base.set_state(3296);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				36 =>{
					{
					let mut tmp = VariableContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3297);
					recog.base.match_token(VARIABLE,&mut recog.err_handler)?;

					}
				}
			,
				37 =>{
					{
					let mut tmp = PercentileContFunctionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3298);
					recog.base.match_token(PERCENTILE_CONT,&mut recog.err_handler)?;

					recog.base.set_state(3299);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule number*/
					recog.base.set_state(3300);
					recog.number()?;

					recog.base.set_state(3301);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3302);
					recog.base.match_token(WITHIN,&mut recog.err_handler)?;

					recog.base.set_state(3303);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(3304);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3305);
					recog.base.match_token(ORDER,&mut recog.err_handler)?;

					recog.base.set_state(3306);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3307);
					recog.expression()?;

					recog.base.set_state(3309);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ASC || _la==DESC {
						{
						recog.base.set_state(3308);
						_la = recog.base.input.la(1);
						if { !(_la==ASC || _la==DESC) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(3311);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3327);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(451,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3312);
							recog.base.match_token(OVER,&mut recog.err_handler)?;

							recog.base.set_state(3313);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(3324);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==PARTITION {
								{
								recog.base.set_state(3314);
								recog.base.match_token(PARTITION,&mut recog.err_handler)?;

								recog.base.set_state(3315);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3316);
								recog.expression()?;

								recog.base.set_state(3321);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(3317);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(3318);
									recog.expression()?;

									}
									}
									recog.base.set_state(3323);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							recog.base.set_state(3326);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				38 =>{
					{
					let mut tmp = PercentileDiscFunctionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3329);
					recog.base.match_token(PERCENTILE_DISC,&mut recog.err_handler)?;

					recog.base.set_state(3330);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule number*/
					recog.base.set_state(3331);
					recog.number()?;

					recog.base.set_state(3332);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3333);
					recog.base.match_token(WITHIN,&mut recog.err_handler)?;

					recog.base.set_state(3334);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(3335);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3336);
					recog.base.match_token(ORDER,&mut recog.err_handler)?;

					recog.base.set_state(3337);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3338);
					recog.expression()?;

					recog.base.set_state(3340);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ASC || _la==DESC {
						{
						recog.base.set_state(3339);
						_la = recog.base.input.la(1);
						if { !(_la==ASC || _la==DESC) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(3342);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3358);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(455,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3343);
							recog.base.match_token(OVER,&mut recog.err_handler)?;

							recog.base.set_state(3344);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(3355);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==PARTITION {
								{
								recog.base.set_state(3345);
								recog.base.match_token(PARTITION,&mut recog.err_handler)?;

								recog.base.set_state(3346);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3347);
								recog.expression()?;

								recog.base.set_state(3352);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(3348);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(3349);
									recog.expression()?;

									}
									}
									recog.base.set_state(3354);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							recog.base.set_state(3357);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				39 =>{
					{
					let mut tmp = ModeFunctionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3360);
					recog.base.match_token(MODE,&mut recog.err_handler)?;

					recog.base.set_state(3361);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3362);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3363);
					recog.base.match_token(WITHIN,&mut recog.err_handler)?;

					recog.base.set_state(3364);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(3365);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3366);
					recog.base.match_token(ORDER,&mut recog.err_handler)?;

					recog.base.set_state(3367);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3368);
					recog.expression()?;

					recog.base.set_state(3370);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ASC || _la==DESC {
						{
						recog.base.set_state(3369);
						_la = recog.base.input.la(1);
						if { !(_la==ASC || _la==DESC) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(3372);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3388);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(459,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3373);
							recog.base.match_token(OVER,&mut recog.err_handler)?;

							recog.base.set_state(3374);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(3385);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==PARTITION {
								{
								recog.base.set_state(3375);
								recog.base.match_token(PARTITION,&mut recog.err_handler)?;

								recog.base.set_state(3376);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3377);
								recog.expression()?;

								recog.base.set_state(3382);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(3378);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(3379);
									recog.expression()?;

									}
									}
									recog.base.set_state(3384);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							recog.base.set_state(3387);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				40 =>{
					{
					let mut tmp = OverlayContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3390);
					recog.base.match_token(OVERLAY,&mut recog.err_handler)?;

					recog.base.set_state(3391);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3392);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::OverlayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.input = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3393);
					recog.base.match_token(PLACING,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3394);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::OverlayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.replace = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3395);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3396);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::OverlayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.position = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3399);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(3397);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						/*InvokeRule valueExpression*/
						recog.base.set_state(3398);
						let tmp = recog.valueExpression_rec(0)?;
						if let PrimaryExpressionContextAll::OverlayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.length = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3401);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(3426);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(463,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(3424);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(462,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = CollateContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3405);
							if !({recog.precpred(None, 35)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 35)".to_owned()), None))?;
							}
							/*InvokeRule collateClause*/
							recog.base.set_state(3406);
							recog.collateClause()?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = JsonExtractContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3407);
							if !({recog.precpred(None, 34)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 34)".to_owned()), None))?;
							}
							recog.base.set_state(3408);
							recog.base.match_token(COLON,&mut recog.err_handler)?;

							/*InvokeRule jsonPath*/
							recog.base.set_state(3409);
							recog.jsonPath()?;

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = TryCastOperatorContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3410);
							if !({recog.precpred(None, 12)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 12)".to_owned()), None))?;
							}
							recog.base.set_state(3411);
							recog.base.match_token(T__2,&mut recog.err_handler)?;

							/*InvokeRule type_*/
							recog.base.set_state(3412);
							recog.type_()?;

							}
						}
					,
						4 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = CastOperatorContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3413);
							if !({recog.precpred(None, 11)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 11)".to_owned()), None))?;
							}
							recog.base.set_state(3414);
							recog.base.match_token(T__3,&mut recog.err_handler)?;

							/*InvokeRule type_*/
							recog.base.set_state(3415);
							recog.type_()?;

							}
						}
					,
						5 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = SubscriptContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::SubscriptContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.value = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3416);
							if !({recog.precpred(None, 10)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 10)".to_owned()), None))?;
							}
							recog.base.set_state(3417);
							recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(3418);
							let tmp = recog.valueExpression_rec(0)?;
							if let PrimaryExpressionContextAll::SubscriptContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.index = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(3419);
							recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

							}
						}
					,
						6 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = DereferenceContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::DereferenceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.base_ = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(3421);
							if !({recog.precpred(None, 9)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 9)".to_owned()), None))?;
							}
							recog.base.set_state(3422);
							recog.base.match_token(DOT,&mut recog.err_handler)?;

							/*InvokeRule columnNameComponent*/
							recog.base.set_state(3423);
							let tmp = recog.columnNameComponent()?;
							if let PrimaryExpressionContextAll::DereferenceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.fieldName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(3428);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(463,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- functionCallHead ----------------
pub type FunctionCallHeadContextAll<'input> = FunctionCallHeadContext<'input>;


pub type FunctionCallHeadContext<'input> = BaseParserRuleContext<'input,FunctionCallHeadContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallHeadContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FunctionCallHeadContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FunctionCallHeadContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallHead(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_functionCallHead(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FunctionCallHeadContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_functionCallHead(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallHeadContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallHead }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallHead }
}
antlr_rust::tid!{FunctionCallHeadContextExt<'a>}

impl<'input> FunctionCallHeadContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallHeadContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallHeadContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallHeadContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FunctionCallHeadContextExt<'input>>{


}

impl<'input> FunctionCallHeadContextAttrs<'input> for FunctionCallHeadContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallHead(&mut self,)
	-> Result<Rc<FunctionCallHeadContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallHeadContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 330, RULE_functionCallHead);
        let mut _localctx: Rc<FunctionCallHeadContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallTail ----------------
pub type FunctionCallTailContextAll<'input> = FunctionCallTailContext<'input>;


pub type FunctionCallTailContext<'input> = BaseParserRuleContext<'input,FunctionCallTailContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallTailContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FunctionCallTailContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FunctionCallTailContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallTail(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_functionCallTail(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FunctionCallTailContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_functionCallTail(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallTailContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallTail }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallTail }
}
antlr_rust::tid!{FunctionCallTailContextExt<'a>}

impl<'input> FunctionCallTailContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallTailContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallTailContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallTailContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FunctionCallTailContextExt<'input>>{

fn filter(&self) -> Option<Rc<FilterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn nullTreatment(&self) -> Option<Rc<NullTreatmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn over(&self) -> Option<Rc<OverContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallTailContextAttrs<'input> for FunctionCallTailContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallTail(&mut self,)
	-> Result<Rc<FunctionCallTailContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallTailContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 332, RULE_functionCallTail);
        let mut _localctx: Rc<FunctionCallTailContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3432);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(464,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule filter*/
					recog.base.set_state(3431);
					recog.filter()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(3435);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(465,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule nullTreatment*/
					recog.base.set_state(3434);
					recog.nullTreatment()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(3438);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(466,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule over*/
					recog.base.set_state(3437);
					recog.over()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- callArgument ----------------
#[derive(Debug)]
pub enum CallArgumentContextAll<'input>{
	PositionalArgumentContext(PositionalArgumentContext<'input>),
	NamedArgumentContext(NamedArgumentContext<'input>),
	MultiArgumentContext(MultiArgumentContext<'input>),
Error(CallArgumentContext<'input>)
}
antlr_rust::tid!{CallArgumentContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for CallArgumentContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for CallArgumentContextAll<'input>{}

impl<'input> Deref for CallArgumentContextAll<'input>{
	type Target = dyn CallArgumentContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use CallArgumentContextAll::*;
		match self{
			PositionalArgumentContext(inner) => inner,
			NamedArgumentContext(inner) => inner,
			MultiArgumentContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CallArgumentContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CallArgumentContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type CallArgumentContext<'input> = BaseParserRuleContext<'input,CallArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct CallArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for CallArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CallArgumentContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CallArgumentContext<'input>{
}

impl<'input> CustomRuleContext<'input> for CallArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}
antlr_rust::tid!{CallArgumentContextExt<'a>}

impl<'input> CallArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CallArgumentContextAll<'input>> {
		Rc::new(
		CallArgumentContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CallArgumentContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait CallArgumentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<CallArgumentContextExt<'input>>{


}

impl<'input> CallArgumentContextAttrs<'input> for CallArgumentContext<'input>{}

pub type PositionalArgumentContext<'input> = BaseParserRuleContext<'input,PositionalArgumentContextExt<'input>>;

pub trait PositionalArgumentContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PositionalArgumentContextAttrs<'input> for PositionalArgumentContext<'input>{}

pub struct PositionalArgumentContextExt<'input>{
	base:CallArgumentContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PositionalArgumentContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PositionalArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PositionalArgumentContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_positionalArgument(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_positionalArgument(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PositionalArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_positionalArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for PositionalArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}

impl<'input> Borrow<CallArgumentContextExt<'input>> for PositionalArgumentContext<'input>{
	fn borrow(&self) -> &CallArgumentContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CallArgumentContextExt<'input>> for PositionalArgumentContext<'input>{
	fn borrow_mut(&mut self) -> &mut CallArgumentContextExt<'input> { &mut self.base }
}

impl<'input> CallArgumentContextAttrs<'input> for PositionalArgumentContext<'input> {}

impl<'input> PositionalArgumentContextExt<'input>{
	fn new(ctx: &dyn CallArgumentContextAttrs<'input>) -> Rc<CallArgumentContextAll<'input>>  {
		Rc::new(
			CallArgumentContextAll::PositionalArgumentContext(
				BaseParserRuleContext::copy_from(ctx,PositionalArgumentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NamedArgumentContext<'input> = BaseParserRuleContext<'input,NamedArgumentContextExt<'input>>;

pub trait NamedArgumentContextAttrs<'input>: DatabricksParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NamedArgumentContextAttrs<'input> for NamedArgumentContext<'input>{}

pub struct NamedArgumentContextExt<'input>{
	base:CallArgumentContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NamedArgumentContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for NamedArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NamedArgumentContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_namedArgument(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_namedArgument(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NamedArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_namedArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}

impl<'input> Borrow<CallArgumentContextExt<'input>> for NamedArgumentContext<'input>{
	fn borrow(&self) -> &CallArgumentContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CallArgumentContextExt<'input>> for NamedArgumentContext<'input>{
	fn borrow_mut(&mut self) -> &mut CallArgumentContextExt<'input> { &mut self.base }
}

impl<'input> CallArgumentContextAttrs<'input> for NamedArgumentContext<'input> {}

impl<'input> NamedArgumentContextExt<'input>{
	fn new(ctx: &dyn CallArgumentContextAttrs<'input>) -> Rc<CallArgumentContextAll<'input>>  {
		Rc::new(
			CallArgumentContextAll::NamedArgumentContext(
				BaseParserRuleContext::copy_from(ctx,NamedArgumentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MultiArgumentContext<'input> = BaseParserRuleContext<'input,MultiArgumentContextExt<'input>>;

pub trait MultiArgumentContextAttrs<'input>: DatabricksParserContext<'input>{
	fn multiSelect(&self) -> Option<Rc<MultiSelectContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> MultiArgumentContextAttrs<'input> for MultiArgumentContext<'input>{}

pub struct MultiArgumentContextExt<'input>{
	base:CallArgumentContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MultiArgumentContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for MultiArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for MultiArgumentContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_multiArgument(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_multiArgument(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for MultiArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_multiArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_callArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_callArgument }
}

impl<'input> Borrow<CallArgumentContextExt<'input>> for MultiArgumentContext<'input>{
	fn borrow(&self) -> &CallArgumentContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CallArgumentContextExt<'input>> for MultiArgumentContext<'input>{
	fn borrow_mut(&mut self) -> &mut CallArgumentContextExt<'input> { &mut self.base }
}

impl<'input> CallArgumentContextAttrs<'input> for MultiArgumentContext<'input> {}

impl<'input> MultiArgumentContextExt<'input>{
	fn new(ctx: &dyn CallArgumentContextAttrs<'input>) -> Rc<CallArgumentContextAll<'input>>  {
		Rc::new(
			CallArgumentContextAll::MultiArgumentContext(
				BaseParserRuleContext::copy_from(ctx,MultiArgumentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn callArgument(&mut self,)
	-> Result<Rc<CallArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CallArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 334, RULE_callArgument);
        let mut _localctx: Rc<CallArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3446);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(467,&mut recog.base)? {
				1 =>{
					let tmp = PositionalArgumentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(3440);
					recog.expression()?;

					}
				}
			,
				2 =>{
					let tmp = NamedArgumentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3441);
					recog.identifier()?;

					recog.base.set_state(3442);
					recog.base.match_token(T__0,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3443);
					recog.expression()?;

					}
				}
			,
				3 =>{
					let tmp = MultiArgumentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule multiSelect*/
					recog.base.set_state(3445);
					recog.multiSelect()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionExtraArguments ----------------
pub type FunctionExtraArgumentsContextAll<'input> = FunctionExtraArgumentsContext<'input>;


pub type FunctionExtraArgumentsContext<'input> = BaseParserRuleContext<'input,FunctionExtraArgumentsContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionExtraArgumentsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FunctionExtraArgumentsContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FunctionExtraArgumentsContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionExtraArguments(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_functionExtraArguments(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FunctionExtraArgumentsContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_functionExtraArguments(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionExtraArgumentsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionExtraArguments }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionExtraArguments }
}
antlr_rust::tid!{FunctionExtraArgumentsContextExt<'a>}

impl<'input> FunctionExtraArgumentsContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionExtraArgumentsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionExtraArgumentsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionExtraArgumentsContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FunctionExtraArgumentsContextExt<'input>>{


}

impl<'input> FunctionExtraArgumentsContextAttrs<'input> for FunctionExtraArgumentsContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionExtraArguments(&mut self,)
	-> Result<Rc<FunctionExtraArgumentsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionExtraArgumentsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 336, RULE_functionExtraArguments);
        let mut _localctx: Rc<FunctionExtraArgumentsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- constant ----------------
#[derive(Debug)]
pub enum ConstantContextAll<'input>{
	NullLiteralContext(NullLiteralContext<'input>),
	StringLiteralContext(StringLiteralContext<'input>),
	TypeConstructorContext(TypeConstructorContext<'input>),
	PosParameterLiteralContext(PosParameterLiteralContext<'input>),
	NamedParameterLiteralContext(NamedParameterLiteralContext<'input>),
	IntervalLiteralContext(IntervalLiteralContext<'input>),
	NumericLiteralContext(NumericLiteralContext<'input>),
	BooleanLiteralContext(BooleanLiteralContext<'input>),
	StringConcatinationContext(StringConcatinationContext<'input>),
Error(ConstantContext<'input>)
}
antlr_rust::tid!{ConstantContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ConstantContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for ConstantContextAll<'input>{}

impl<'input> Deref for ConstantContextAll<'input>{
	type Target = dyn ConstantContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ConstantContextAll::*;
		match self{
			NullLiteralContext(inner) => inner,
			StringLiteralContext(inner) => inner,
			TypeConstructorContext(inner) => inner,
			PosParameterLiteralContext(inner) => inner,
			NamedParameterLiteralContext(inner) => inner,
			IntervalLiteralContext(inner) => inner,
			NumericLiteralContext(inner) => inner,
			BooleanLiteralContext(inner) => inner,
			StringConcatinationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ConstantContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ConstantContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ConstantContext<'input> = BaseParserRuleContext<'input,ConstantContextExt<'input>>;

#[derive(Clone)]
pub struct ConstantContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ConstantContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ConstantContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ConstantContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ConstantContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}
antlr_rust::tid!{ConstantContextExt<'a>}

impl<'input> ConstantContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConstantContextAll<'input>> {
		Rc::new(
		ConstantContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConstantContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ConstantContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ConstantContextExt<'input>>{


}

impl<'input> ConstantContextAttrs<'input> for ConstantContext<'input>{}

pub type NullLiteralContext<'input> = BaseParserRuleContext<'input,NullLiteralContextExt<'input>>;

pub trait NullLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
}

impl<'input> NullLiteralContextAttrs<'input> for NullLiteralContext<'input>{}

pub struct NullLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NullLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for NullLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NullLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nullLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_nullLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NullLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_nullLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for NullLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for NullLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for NullLiteralContext<'input> {}

impl<'input> NullLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::NullLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NullLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StringLiteralContext<'input> = BaseParserRuleContext<'input,StringLiteralContextExt<'input>>;

pub trait StringLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StringLiteralContextAttrs<'input> for StringLiteralContext<'input>{}

pub struct StringLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StringLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_stringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_stringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_stringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for StringLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for StringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for StringLiteralContext<'input> {}

impl<'input> StringLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::StringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,StringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TypeConstructorContext<'input> = BaseParserRuleContext<'input,TypeConstructorContextExt<'input>>;

pub trait TypeConstructorContextAttrs<'input>: DatabricksParserContext<'input>{
	fn literalType(&self) -> Option<Rc<LiteralTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TypeConstructorContextAttrs<'input> for TypeConstructorContext<'input>{}

pub struct TypeConstructorContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TypeConstructorContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TypeConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TypeConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_typeConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_typeConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TypeConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_typeConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for TypeConstructorContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for TypeConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for TypeConstructorContext<'input> {}

impl<'input> TypeConstructorContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::TypeConstructorContext(
				BaseParserRuleContext::copy_from(ctx,TypeConstructorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PosParameterLiteralContext<'input> = BaseParserRuleContext<'input,PosParameterLiteralContextExt<'input>>;

pub trait PosParameterLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token QUESTION_MARK
	/// Returns `None` if there is no child corresponding to token QUESTION_MARK
	fn QUESTION_MARK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(QUESTION_MARK, 0)
	}
}

impl<'input> PosParameterLiteralContextAttrs<'input> for PosParameterLiteralContext<'input>{}

pub struct PosParameterLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PosParameterLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PosParameterLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PosParameterLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_posParameterLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_posParameterLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PosParameterLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_posParameterLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for PosParameterLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for PosParameterLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for PosParameterLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for PosParameterLiteralContext<'input> {}

impl<'input> PosParameterLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::PosParameterLiteralContext(
				BaseParserRuleContext::copy_from(ctx,PosParameterLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NamedParameterLiteralContext<'input> = BaseParserRuleContext<'input,NamedParameterLiteralContextExt<'input>>;

pub trait NamedParameterLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COLON
	/// Returns `None` if there is no child corresponding to token COLON
	fn COLON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COLON, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NamedParameterLiteralContextAttrs<'input> for NamedParameterLiteralContext<'input>{}

pub struct NamedParameterLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NamedParameterLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for NamedParameterLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NamedParameterLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_namedParameterLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_namedParameterLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NamedParameterLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_namedParameterLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedParameterLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for NamedParameterLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for NamedParameterLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for NamedParameterLiteralContext<'input> {}

impl<'input> NamedParameterLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::NamedParameterLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NamedParameterLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntervalLiteralContext<'input> = BaseParserRuleContext<'input,IntervalLiteralContextExt<'input>>;

pub trait IntervalLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IntervalLiteralContextAttrs<'input> for IntervalLiteralContext<'input>{}

pub struct IntervalLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntervalLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for IntervalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IntervalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_intervalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_intervalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IntervalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_intervalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for IntervalLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for IntervalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for IntervalLiteralContext<'input> {}

impl<'input> IntervalLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::IntervalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IntervalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NumericLiteralContext<'input> = BaseParserRuleContext<'input,NumericLiteralContextExt<'input>>;

pub trait NumericLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NumericLiteralContextAttrs<'input> for NumericLiteralContext<'input>{}

pub struct NumericLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NumericLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for NumericLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NumericLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_numericLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_numericLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NumericLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_numericLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NumericLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for NumericLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for NumericLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for NumericLiteralContext<'input> {}

impl<'input> NumericLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::NumericLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NumericLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BooleanLiteralContext<'input> = BaseParserRuleContext<'input,BooleanLiteralContextExt<'input>>;

pub trait BooleanLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	fn booleanValue(&self) -> Option<Rc<BooleanValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> BooleanLiteralContextAttrs<'input> for BooleanLiteralContext<'input>{}

pub struct BooleanLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BooleanLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for BooleanLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BooleanLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_booleanLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_booleanLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BooleanLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_booleanLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for BooleanLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for BooleanLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for BooleanLiteralContext<'input> {}

impl<'input> BooleanLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::BooleanLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BooleanLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StringConcatinationContext<'input> = BaseParserRuleContext<'input,StringConcatinationContextExt<'input>>;

pub trait StringConcatinationContextAttrs<'input>: DatabricksParserContext<'input>{
	fn string_all(&self) ->  Vec<Rc<StringContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn string(&self, i: usize) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> StringConcatinationContextAttrs<'input> for StringConcatinationContext<'input>{}

pub struct StringConcatinationContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StringConcatinationContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StringConcatinationContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StringConcatinationContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_stringConcatination(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_stringConcatination(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StringConcatinationContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_stringConcatination(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringConcatinationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for StringConcatinationContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for StringConcatinationContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for StringConcatinationContext<'input> {}

impl<'input> StringConcatinationContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::StringConcatinationContext(
				BaseParserRuleContext::copy_from(ctx,StringConcatinationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn constant(&mut self,)
	-> Result<Rc<ConstantContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConstantContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 338, RULE_constant);
        let mut _localctx: Rc<ConstantContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(3467);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(469,&mut recog.base)? {
				1 =>{
					let tmp = NullLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3450);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = PosParameterLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3451);
					recog.base.match_token(QUESTION_MARK,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = NamedParameterLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3452);
					recog.base.match_token(COLON,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3453);
					recog.identifier()?;

					}
				}
			,
				4 =>{
					let tmp = IntervalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule interval*/
					recog.base.set_state(3454);
					recog.interval()?;

					}
				}
			,
				5 =>{
					let tmp = TypeConstructorContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					/*InvokeRule literalType*/
					recog.base.set_state(3455);
					recog.literalType()?;

					/*InvokeRule string*/
					recog.base.set_state(3456);
					recog.string()?;

					}
				}
			,
				6 =>{
					let tmp = NumericLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					/*InvokeRule number*/
					recog.base.set_state(3458);
					recog.number()?;

					}
				}
			,
				7 =>{
					let tmp = BooleanLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					/*InvokeRule booleanValue*/
					recog.base.set_state(3459);
					recog.booleanValue()?;

					}
				}
			,
				8 =>{
					let tmp = StringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					/*InvokeRule string*/
					recog.base.set_state(3460);
					recog.string()?;

					}
				}
			,
				9 =>{
					let tmp = StringConcatinationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					/*InvokeRule string*/
					recog.base.set_state(3461);
					recog.string()?;

					recog.base.set_state(3463); 
					recog.err_handler.sync(&mut recog.base)?;
					_alt = 1;
					loop {
						match _alt {
						    x if x == 1=>
							{
							{
							/*InvokeRule string*/
							recog.base.set_state(3462);
							recog.string()?;

							}
							}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						recog.base.set_state(3465); 
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(468,&mut recog.base)?;
						if _alt==2 || _alt==INVALID_ALT { break }
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPath ----------------
pub type JsonPathContextAll<'input> = JsonPathContext<'input>;


pub type JsonPathContext<'input> = BaseParserRuleContext<'input,JsonPathContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPathContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for JsonPathContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JsonPathContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPath(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_jsonPath(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JsonPathContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_jsonPath(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPathContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPath }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPath }
}
antlr_rust::tid!{JsonPathContextExt<'a>}

impl<'input> JsonPathContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPathContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPathContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPathContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<JsonPathContextExt<'input>>{

fn jsonPathElement1(&self) -> Option<Rc<JsonPathElement1ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonPathElement2_all(&self) ->  Vec<Rc<JsonPathElement2ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn jsonPathElement2(&self, i: usize) -> Option<Rc<JsonPathElement2ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> JsonPathContextAttrs<'input> for JsonPathContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPath(&mut self,)
	-> Result<Rc<JsonPathContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPathContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 340, RULE_jsonPath);
        let mut _localctx: Rc<JsonPathContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule jsonPathElement1*/
			recog.base.set_state(3469);
			recog.jsonPathElement1()?;

			recog.base.set_state(3473);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(470,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule jsonPathElement2*/
					recog.base.set_state(3470);
					recog.jsonPathElement2()?;

					}
					} 
				}
				recog.base.set_state(3475);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(470,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPathElement1 ----------------
pub type JsonPathElement1ContextAll<'input> = JsonPathElement1Context<'input>;


pub type JsonPathElement1Context<'input> = BaseParserRuleContext<'input,JsonPathElement1ContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPathElement1ContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for JsonPathElement1Context<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JsonPathElement1Context<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPathElement1(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_jsonPathElement1(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JsonPathElement1Context<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_jsonPathElement1(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPathElement1ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPathElement1 }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPathElement1 }
}
antlr_rust::tid!{JsonPathElement1ContextExt<'a>}

impl<'input> JsonPathElement1ContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPathElement1ContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPathElement1ContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPathElement1ContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<JsonPathElement1ContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LBRACKET
/// Returns `None` if there is no child corresponding to token LBRACKET
fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LBRACKET, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RBRACKET
/// Returns `None` if there is no child corresponding to token RBRACKET
fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}

}

impl<'input> JsonPathElement1ContextAttrs<'input> for JsonPathElement1Context<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPathElement1(&mut self,)
	-> Result<Rc<JsonPathElement1ContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPathElement1ContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 342, RULE_jsonPathElement1);
        let mut _localctx: Rc<JsonPathElement1ContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3487);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(471,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3476);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3477);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(3478);
					recog.string()?;

					recog.base.set_state(3479);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3481);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(3482);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(3483);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3484);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(3485);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					recog.base.set_state(3486);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPathElement2 ----------------
pub type JsonPathElement2ContextAll<'input> = JsonPathElement2Context<'input>;


pub type JsonPathElement2Context<'input> = BaseParserRuleContext<'input,JsonPathElement2ContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPathElement2ContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for JsonPathElement2Context<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for JsonPathElement2Context<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPathElement2(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_jsonPathElement2(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for JsonPathElement2Context<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_jsonPathElement2(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPathElement2ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPathElement2 }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPathElement2 }
}
antlr_rust::tid!{JsonPathElement2ContextExt<'a>}

impl<'input> JsonPathElement2ContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPathElement2ContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPathElement2ContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPathElement2ContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<JsonPathElement2ContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LBRACKET
/// Returns `None` if there is no child corresponding to token LBRACKET
fn LBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LBRACKET, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RBRACKET
/// Returns `None` if there is no child corresponding to token RBRACKET
fn RBRACKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}

}

impl<'input> JsonPathElement2ContextAttrs<'input> for JsonPathElement2Context<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPathElement2(&mut self,)
	-> Result<Rc<JsonPathElement2ContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPathElement2ContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 344, RULE_jsonPathElement2);
        let mut _localctx: Rc<JsonPathElement2ContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3501);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(472,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3489);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3490);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3491);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(3492);
					recog.string()?;

					recog.base.set_state(3493);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3495);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(3496);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(3497);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3498);
					recog.base.match_token(LBRACKET,&mut recog.err_handler)?;

					recog.base.set_state(3499);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					recog.base.set_state(3500);
					recog.base.match_token(RBRACKET,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionName ----------------
pub type FunctionNameContextAll<'input> = FunctionNameContext<'input>;


pub type FunctionNameContext<'input> = BaseParserRuleContext<'input,FunctionNameContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionNameContextExt<'input>{
	pub identFunc: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FunctionNameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FunctionNameContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionName(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_functionName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FunctionNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_functionName(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionName }
}
antlr_rust::tid!{FunctionNameContextExt<'a>}

impl<'input> FunctionNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionNameContextExt{
				identFunc: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionNameContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FunctionNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token REGEXP
/// Returns `None` if there is no child corresponding to token REGEXP
fn REGEXP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REGEXP, 0)
}

}

impl<'input> FunctionNameContextAttrs<'input> for FunctionNameContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionName(&mut self,)
	-> Result<Rc<FunctionNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 346, RULE_functionName);
        let mut _localctx: Rc<FunctionNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3514);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(473,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3503);
					recog.base.match_token(IDENTIFIER_KW,&mut recog.err_handler)?;

					recog.base.set_state(3504);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3505);
					recog.expression()?;

					recog.base.set_state(3506);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3508);
					let tmp = recog.base.match_token(IDENTIFIER_KW,&mut recog.err_handler)?;
					 cast_mut::<_,FunctionNameContext >(&mut _localctx).identFunc = Some(tmp);
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(3509);
					recog.qualifiedName()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3510);
					recog.base.match_token(FILTER,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3511);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(3512);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(3513);
					recog.base.match_token(REGEXP,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- field ----------------
pub type FieldContextAll<'input> = FieldContext<'input>;


pub type FieldContext<'input> = BaseParserRuleContext<'input,FieldContextExt<'input>>;

#[derive(Clone)]
pub struct FieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FieldContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FieldContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_field(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_field(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_field(self);
	}
}

impl<'input> CustomRuleContext<'input> for FieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_field }
	//fn type_rule_index() -> usize where Self: Sized { RULE_field }
}
antlr_rust::tid!{FieldContextExt<'a>}

impl<'input> FieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FieldContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FieldContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FieldContextAttrs<'input> for FieldContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn field(&mut self,)
	-> Result<Rc<FieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 348, RULE_field);
        let mut _localctx: Rc<FieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(3516);
			recog.expression()?;

			recog.base.set_state(3519);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(3517);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				/*InvokeRule identifier*/
				recog.base.set_state(3518);
				recog.identifier()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nullTreatment ----------------
pub type NullTreatmentContextAll<'input> = NullTreatmentContext<'input>;


pub type NullTreatmentContext<'input> = BaseParserRuleContext<'input,NullTreatmentContextExt<'input>>;

#[derive(Clone)]
pub struct NullTreatmentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NullTreatmentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NullTreatmentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nullTreatment(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_nullTreatment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NullTreatmentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_nullTreatment(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullTreatmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nullTreatment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nullTreatment }
}
antlr_rust::tid!{NullTreatmentContextExt<'a>}

impl<'input> NullTreatmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NullTreatmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NullTreatmentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NullTreatmentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NullTreatmentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IGNORE
/// Returns `None` if there is no child corresponding to token IGNORE
fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token RESPECT
/// Returns `None` if there is no child corresponding to token RESPECT
fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RESPECT, 0)
}

}

impl<'input> NullTreatmentContextAttrs<'input> for NullTreatmentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nullTreatment(&mut self,)
	-> Result<Rc<NullTreatmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NullTreatmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 350, RULE_nullTreatment);
        let mut _localctx: Rc<NullTreatmentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3525);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IGNORE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3521);
					recog.base.match_token(IGNORE,&mut recog.err_handler)?;

					recog.base.set_state(3522);
					recog.base.match_token(NULLS,&mut recog.err_handler)?;

					}
				}

			 RESPECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3523);
					recog.base.match_token(RESPECT,&mut recog.err_handler)?;

					recog.base.set_state(3524);
					recog.base.match_token(NULLS,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- string ----------------
#[derive(Debug)]
pub enum StringContextAll<'input>{
	BasicStringLiteralContext(BasicStringLiteralContext<'input>),
	DoubleQuotedStringLiteralContext(DoubleQuotedStringLiteralContext<'input>),
Error(StringContext<'input>)
}
antlr_rust::tid!{StringContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StringContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for StringContextAll<'input>{}

impl<'input> Deref for StringContextAll<'input>{
	type Target = dyn StringContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StringContextAll::*;
		match self{
			BasicStringLiteralContext(inner) => inner,
			DoubleQuotedStringLiteralContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StringContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StringContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StringContext<'input> = BaseParserRuleContext<'input,StringContextExt<'input>>;

#[derive(Clone)]
pub struct StringContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StringContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StringContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StringContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StringContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}
antlr_rust::tid!{StringContextExt<'a>}

impl<'input> StringContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringContextAll<'input>> {
		Rc::new(
		StringContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StringContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StringContextExt<'input>>{


}

impl<'input> StringContextAttrs<'input> for StringContext<'input>{}

pub type BasicStringLiteralContext<'input> = BaseParserRuleContext<'input,BasicStringLiteralContextExt<'input>>;

pub trait BasicStringLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STRING
	/// Returns `None` if there is no child corresponding to token STRING
	fn STRING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(STRING, 0)
	}
}

impl<'input> BasicStringLiteralContextAttrs<'input> for BasicStringLiteralContext<'input>{}

pub struct BasicStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BasicStringLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for BasicStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BasicStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_basicStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_basicStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BasicStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_basicStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BasicStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for BasicStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for BasicStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for BasicStringLiteralContext<'input> {}

impl<'input> BasicStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::BasicStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BasicStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DoubleQuotedStringLiteralContext<'input> = BaseParserRuleContext<'input,DoubleQuotedStringLiteralContextExt<'input>>;

pub trait DoubleQuotedStringLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOUBLEQUOTED_STRING
	/// Returns `None` if there is no child corresponding to token DOUBLEQUOTED_STRING
	fn DOUBLEQUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DOUBLEQUOTED_STRING, 0)
	}
}

impl<'input> DoubleQuotedStringLiteralContextAttrs<'input> for DoubleQuotedStringLiteralContext<'input>{}

pub struct DoubleQuotedStringLiteralContextExt<'input>{
	base:StringContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DoubleQuotedStringLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DoubleQuotedStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DoubleQuotedStringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_doubleQuotedStringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_doubleQuotedStringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DoubleQuotedStringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_doubleQuotedStringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DoubleQuotedStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_string }
	//fn type_rule_index() -> usize where Self: Sized { RULE_string }
}

impl<'input> Borrow<StringContextExt<'input>> for DoubleQuotedStringLiteralContext<'input>{
	fn borrow(&self) -> &StringContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StringContextExt<'input>> for DoubleQuotedStringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StringContextExt<'input> { &mut self.base }
}

impl<'input> StringContextAttrs<'input> for DoubleQuotedStringLiteralContext<'input> {}

impl<'input> DoubleQuotedStringLiteralContextExt<'input>{
	fn new(ctx: &dyn StringContextAttrs<'input>) -> Rc<StringContextAll<'input>>  {
		Rc::new(
			StringContextAll::DoubleQuotedStringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DoubleQuotedStringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn string(&mut self,)
	-> Result<Rc<StringContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 352, RULE_string);
        let mut _localctx: Rc<StringContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3529);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 STRING 
				=> {
					let tmp = BasicStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3527);
					recog.base.match_token(STRING,&mut recog.err_handler)?;

					}
				}

			 DOUBLEQUOTED_STRING 
				=> {
					let tmp = DoubleQuotedStringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3528);
					recog.base.match_token(DOUBLEQUOTED_STRING,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- timeZoneSpecifier ----------------
pub type TimeZoneSpecifierContextAll<'input> = TimeZoneSpecifierContext<'input>;


pub type TimeZoneSpecifierContext<'input> = BaseParserRuleContext<'input,TimeZoneSpecifierContextExt<'input>>;

#[derive(Clone)]
pub struct TimeZoneSpecifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TimeZoneSpecifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TimeZoneSpecifierContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_timeZoneSpecifier(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_timeZoneSpecifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TimeZoneSpecifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_timeZoneSpecifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for TimeZoneSpecifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_timeZoneSpecifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_timeZoneSpecifier }
}
antlr_rust::tid!{TimeZoneSpecifierContextExt<'a>}

impl<'input> TimeZoneSpecifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TimeZoneSpecifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TimeZoneSpecifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TimeZoneSpecifierContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TimeZoneSpecifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token ZONE
/// Returns `None` if there is no child corresponding to token ZONE
fn ZONE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ZONE, 0)
}
fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TimeZoneSpecifierContextAttrs<'input> for TimeZoneSpecifierContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn timeZoneSpecifier(&mut self,)
	-> Result<Rc<TimeZoneSpecifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TimeZoneSpecifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 354, RULE_timeZoneSpecifier);
        let mut _localctx: Rc<TimeZoneSpecifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3537);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(477,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3531);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(3532);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					/*InvokeRule interval*/
					recog.base.set_state(3533);
					recog.interval()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3534);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(3535);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					/*InvokeRule string*/
					recog.base.set_state(3536);
					recog.string()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comparisonOperator ----------------
pub type ComparisonOperatorContextAll<'input> = ComparisonOperatorContext<'input>;


pub type ComparisonOperatorContext<'input> = BaseParserRuleContext<'input,ComparisonOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ComparisonOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ComparisonOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comparisonOperator(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_comparisonOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ComparisonOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_comparisonOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonOperator }
}
antlr_rust::tid!{ComparisonOperatorContextExt<'a>}

impl<'input> ComparisonOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComparisonOperatorContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ComparisonOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
/// Retrieves first TerminalNode corresponding to token NEQ
/// Returns `None` if there is no child corresponding to token NEQ
fn NEQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NEQ, 0)
}
/// Retrieves first TerminalNode corresponding to token LT
/// Returns `None` if there is no child corresponding to token LT
fn LT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LT, 0)
}
/// Retrieves first TerminalNode corresponding to token LTE
/// Returns `None` if there is no child corresponding to token LTE
fn LTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LTE, 0)
}
/// Retrieves first TerminalNode corresponding to token GT
/// Returns `None` if there is no child corresponding to token GT
fn GT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GT, 0)
}
/// Retrieves first TerminalNode corresponding to token GTE
/// Returns `None` if there is no child corresponding to token GTE
fn GTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GTE, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE_EQ
/// Returns `None` if there is no child corresponding to token DOUBLE_EQ
fn DOUBLE_EQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE_EQ, 0)
}
/// Retrieves first TerminalNode corresponding to token NSEQ
/// Returns `None` if there is no child corresponding to token NSEQ
fn NSEQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NSEQ, 0)
}

}

impl<'input> ComparisonOperatorContextAttrs<'input> for ComparisonOperatorContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonOperator(&mut self,)
	-> Result<Rc<ComparisonOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 356, RULE_comparisonOperator);
        let mut _localctx: Rc<ComparisonOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3539);
			_la = recog.base.input.la(1);
			if { !(((((_la - 390)) & !0x3f) == 0 && ((1usize << (_la - 390)) & ((1usize << (EQ - 390)) | (1usize << (DOUBLE_EQ - 390)) | (1usize << (NSEQ - 390)) | (1usize << (NEQ - 390)) | (1usize << (LT - 390)) | (1usize << (LTE - 390)) | (1usize << (GT - 390)) | (1usize << (GTE - 390)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comparisonQuantifier ----------------
pub type ComparisonQuantifierContextAll<'input> = ComparisonQuantifierContext<'input>;


pub type ComparisonQuantifierContext<'input> = BaseParserRuleContext<'input,ComparisonQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for ComparisonQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ComparisonQuantifierContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comparisonQuantifier(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_comparisonQuantifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ComparisonQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_comparisonQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonQuantifier }
}
antlr_rust::tid!{ComparisonQuantifierContextExt<'a>}

impl<'input> ComparisonQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonQuantifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonQuantifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComparisonQuantifierContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<ComparisonQuantifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token SOME
/// Returns `None` if there is no child corresponding to token SOME
fn SOME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}

}

impl<'input> ComparisonQuantifierContextAttrs<'input> for ComparisonQuantifierContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonQuantifier(&mut self,)
	-> Result<Rc<ComparisonQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 358, RULE_comparisonQuantifier);
        let mut _localctx: Rc<ComparisonQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3541);
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==ANY || _la==SOME) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanValue ----------------
pub type BooleanValueContextAll<'input> = BooleanValueContext<'input>;


pub type BooleanValueContext<'input> = BaseParserRuleContext<'input,BooleanValueContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for BooleanValueContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BooleanValueContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_booleanValue(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_booleanValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BooleanValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_booleanValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanValue }
}
antlr_rust::tid!{BooleanValueContextExt<'a>}

impl<'input> BooleanValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BooleanValueContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<BooleanValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}

}

impl<'input> BooleanValueContextAttrs<'input> for BooleanValueContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn booleanValue(&mut self,)
	-> Result<Rc<BooleanValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BooleanValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 360, RULE_booleanValue);
        let mut _localctx: Rc<BooleanValueContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3543);
			_la = recog.base.input.la(1);
			if { !(_la==FALSE || _la==TRUE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneInterval ----------------
pub type StandaloneIntervalContextAll<'input> = StandaloneIntervalContext<'input>;


pub type StandaloneIntervalContext<'input> = BaseParserRuleContext<'input,StandaloneIntervalContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneIntervalContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StandaloneIntervalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StandaloneIntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneInterval(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_standaloneInterval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StandaloneIntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_standaloneInterval(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneIntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneInterval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneInterval }
}
antlr_rust::tid!{StandaloneIntervalContextExt<'a>}

impl<'input> StandaloneIntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneIntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneIntervalContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneIntervalContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StandaloneIntervalContextExt<'input>>{

fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneIntervalContextAttrs<'input> for StandaloneIntervalContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneInterval(&mut self,)
	-> Result<Rc<StandaloneIntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneIntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 362, RULE_standaloneInterval);
        let mut _localctx: Rc<StandaloneIntervalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule interval*/
			recog.base.set_state(3545);
			recog.interval()?;

			recog.base.set_state(3546);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- interval ----------------
pub type IntervalContextAll<'input> = IntervalContext<'input>;


pub type IntervalContext<'input> = BaseParserRuleContext<'input,IntervalContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IntervalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_interval(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_interval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_interval(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_interval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_interval }
}
antlr_rust::tid!{IntervalContextExt<'a>}

impl<'input> IntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IntervalContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
fn intervalValue_all(&self) ->  Vec<Rc<IntervalValueContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn intervalValue(&self, i: usize) -> Option<Rc<IntervalValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn intervalValueField_all(&self) ->  Vec<Rc<IntervalValueFieldContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn intervalValueField(&self, i: usize) -> Option<Rc<IntervalValueFieldContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> IntervalContextAttrs<'input> for IntervalContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn interval(&mut self,)
	-> Result<Rc<IntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 364, RULE_interval);
        let mut _localctx: Rc<IntervalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3548);
			recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

			recog.base.set_state(3552); 
			recog.err_handler.sync(&mut recog.base)?;
			_alt = 1;
			loop {
				match _alt {
				    x if x == 1=>
					{
					{
					/*InvokeRule intervalValue*/
					recog.base.set_state(3549);
					recog.intervalValue()?;

					/*InvokeRule intervalValueField*/
					recog.base.set_state(3550);
					recog.intervalValueField()?;

					}
					}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				recog.base.set_state(3554); 
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(478,&mut recog.base)?;
				if _alt==2 || _alt==INVALID_ALT { break }
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalValue ----------------
pub type IntervalValueContextAll<'input> = IntervalValueContext<'input>;


pub type IntervalValueContext<'input> = BaseParserRuleContext<'input,IntervalValueContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IntervalValueContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IntervalValueContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalValue(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_intervalValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IntervalValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_intervalValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalValue }
}
antlr_rust::tid!{IntervalValueContextExt<'a>}

impl<'input> IntervalValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalValueContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IntervalValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL_VALUE, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}

}

impl<'input> IntervalValueContextAttrs<'input> for IntervalValueContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalValue(&mut self,)
	-> Result<Rc<IntervalValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 366, RULE_intervalValue);
        let mut _localctx: Rc<IntervalValueContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3557);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PLUS || _la==MINUS {
				{
				recog.base.set_state(3556);
				_la = recog.base.input.la(1);
				if { !(_la==PLUS || _la==MINUS) } {
					recog.err_handler.recover_inline(&mut recog.base)?;

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			recog.base.set_state(3562);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INTEGER_VALUE 
				=> {
					{
					recog.base.set_state(3559);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}

			 DECIMAL_VALUE 
				=> {
					{
					recog.base.set_state(3560);
					recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}

			 STRING | DOUBLEQUOTED_STRING 
				=> {
					{
					/*InvokeRule string*/
					recog.base.set_state(3561);
					recog.string()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalValueField ----------------
pub type IntervalValueFieldContextAll<'input> = IntervalValueFieldContext<'input>;


pub type IntervalValueFieldContext<'input> = BaseParserRuleContext<'input,IntervalValueFieldContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalValueFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IntervalValueFieldContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IntervalValueFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalValueField(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_intervalValueField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IntervalValueFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_intervalValueField(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalValueFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalValueField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalValueField }
}
antlr_rust::tid!{IntervalValueFieldContextExt<'a>}

impl<'input> IntervalValueFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalValueFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalValueFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalValueFieldContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IntervalValueFieldContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECOND
/// Returns `None` if there is no child corresponding to token NANOSECOND
fn NANOSECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NANOSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token YEARS
/// Returns `None` if there is no child corresponding to token YEARS
fn YEARS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(YEARS, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTHS
/// Returns `None` if there is no child corresponding to token MONTHS
fn MONTHS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MONTHS, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEKS
/// Returns `None` if there is no child corresponding to token WEEKS
fn WEEKS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WEEKS, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYS
/// Returns `None` if there is no child corresponding to token DAYS
fn DAYS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token HOURS
/// Returns `None` if there is no child corresponding to token HOURS
fn HOURS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HOURS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTES
/// Returns `None` if there is no child corresponding to token MINUTES
fn MINUTES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MINUTES, 0)
}
/// Retrieves first TerminalNode corresponding to token SECONDS
/// Returns `None` if there is no child corresponding to token SECONDS
fn SECONDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECONDS
/// Returns `None` if there is no child corresponding to token MILLISECONDS
fn MILLISECONDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MILLISECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECONDS
/// Returns `None` if there is no child corresponding to token MICROSECONDS
fn MICROSECONDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MICROSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECONDS
/// Returns `None` if there is no child corresponding to token NANOSECONDS
fn NANOSECONDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NANOSECONDS, 0)
}

}

impl<'input> IntervalValueFieldContextAttrs<'input> for IntervalValueFieldContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalValueField(&mut self,)
	-> Result<Rc<IntervalValueFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalValueFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 368, RULE_intervalValueField);
        let mut _localctx: Rc<IntervalValueFieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3564);
			_la = recog.base.input.la(1);
			if { !(_la==DAY || _la==DAYS || _la==HOUR || _la==HOURS || ((((_la - 199)) & !0x3f) == 0 && ((1usize << (_la - 199)) & ((1usize << (MICROSECOND - 199)) | (1usize << (MICROSECONDS - 199)) | (1usize << (MILLISECOND - 199)) | (1usize << (MILLISECONDS - 199)) | (1usize << (MINUTE - 199)) | (1usize << (MINUTES - 199)) | (1usize << (MONTH - 199)) | (1usize << (MONTHS - 199)) | (1usize << (NANOSECOND - 199)) | (1usize << (NANOSECONDS - 199)))) != 0) || _la==SECOND || _la==SECONDS || ((((_la - 374)) & !0x3f) == 0 && ((1usize << (_la - 374)) & ((1usize << (WEEK - 374)) | (1usize << (WEEKS - 374)) | (1usize << (YEAR - 374)) | (1usize << (YEARS - 374)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalTypeField ----------------
pub type IntervalTypeFieldContextAll<'input> = IntervalTypeFieldContext<'input>;


pub type IntervalTypeFieldContext<'input> = BaseParserRuleContext<'input,IntervalTypeFieldContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalTypeFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IntervalTypeFieldContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IntervalTypeFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalTypeField(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_intervalTypeField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IntervalTypeFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_intervalTypeField(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalTypeFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalTypeField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalTypeField }
}
antlr_rust::tid!{IntervalTypeFieldContextExt<'a>}

impl<'input> IntervalTypeFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalTypeFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalTypeFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalTypeFieldContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IntervalTypeFieldContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}

}

impl<'input> IntervalTypeFieldContextAttrs<'input> for IntervalTypeFieldContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalTypeField(&mut self,)
	-> Result<Rc<IntervalTypeFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalTypeFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 370, RULE_intervalTypeField);
        let mut _localctx: Rc<IntervalTypeFieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3566);
			_la = recog.base.input.la(1);
			if { !(_la==DAY || _la==HOUR || _la==MINUTE || _la==MONTH || _la==SECOND || _la==YEAR) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- typeIdentifier ----------------
pub type TypeIdentifierContextAll<'input> = TypeIdentifierContext<'input>;


pub type TypeIdentifierContext<'input> = BaseParserRuleContext<'input,TypeIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct TypeIdentifierContextExt<'input>{
	pub unsupportedType: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TypeIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TypeIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_typeIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_typeIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TypeIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_typeIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_typeIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_typeIdentifier }
}
antlr_rust::tid!{TypeIdentifierContextExt<'a>}

impl<'input> TypeIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TypeIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TypeIdentifierContextExt{
				unsupportedType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TypeIdentifierContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TypeIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BOOLEAN
/// Returns `None` if there is no child corresponding to token BOOLEAN
fn BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token TINYINT
/// Returns `None` if there is no child corresponding to token TINYINT
fn TINYINT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TINYINT, 0)
}
/// Retrieves first TerminalNode corresponding to token BYTE
/// Returns `None` if there is no child corresponding to token BYTE
fn BYTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BYTE, 0)
}
/// Retrieves first TerminalNode corresponding to token SMALLINT
/// Returns `None` if there is no child corresponding to token SMALLINT
fn SMALLINT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SMALLINT, 0)
}
/// Retrieves first TerminalNode corresponding to token SHORT
/// Returns `None` if there is no child corresponding to token SHORT
fn SHORT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SHORT, 0)
}
/// Retrieves first TerminalNode corresponding to token INT
/// Returns `None` if there is no child corresponding to token INT
fn INT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER
/// Returns `None` if there is no child corresponding to token INTEGER
fn INTEGER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER, 0)
}
/// Retrieves first TerminalNode corresponding to token BIGINT
/// Returns `None` if there is no child corresponding to token BIGINT
fn BIGINT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BIGINT, 0)
}
/// Retrieves first TerminalNode corresponding to token LONG
/// Returns `None` if there is no child corresponding to token LONG
fn LONG(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LONG, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOAT
/// Returns `None` if there is no child corresponding to token FLOAT
fn FLOAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token REAL
/// Returns `None` if there is no child corresponding to token REAL
fn REAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_NTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_NTZ
fn TIMESTAMP_NTZ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_NTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_LTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_LTZ
fn TIMESTAMP_LTZ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_LTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token STRING_KW
/// Returns `None` if there is no child corresponding to token STRING_KW
fn STRING_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STRING_KW, 0)
}
fn collateClause(&self) -> Option<Rc<CollateClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CHARACTER
/// Returns `None` if there is no child corresponding to token CHARACTER
fn CHARACTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CHARACTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CHAR
/// Returns `None` if there is no child corresponding to token CHAR
fn CHAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token VARCHAR
/// Returns `None` if there is no child corresponding to token VARCHAR
fn VARCHAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VARCHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY
/// Returns `None` if there is no child corresponding to token BINARY
fn BINARY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL
/// Returns `None` if there is no child corresponding to token DECIMAL
fn DECIMAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DEC
/// Returns `None` if there is no child corresponding to token DEC
fn DEC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DEC, 0)
}
/// Retrieves first TerminalNode corresponding to token NUMERIC
/// Returns `None` if there is no child corresponding to token NUMERIC
fn NUMERIC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NUMERIC, 0)
}
/// Retrieves first TerminalNode corresponding to token VOID
/// Returns `None` if there is no child corresponding to token VOID
fn VOID(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VOID, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIANT
/// Returns `None` if there is no child corresponding to token VARIANT
fn VARIANT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VARIANT, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAY
/// Returns `None` if there is no child corresponding to token ARRAY
fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token STRUCT
/// Returns `None` if there is no child corresponding to token STRUCT
fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TypeIdentifierContextAttrs<'input> for TypeIdentifierContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn typeIdentifier(&mut self,)
	-> Result<Rc<TypeIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TypeIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 372, RULE_typeIdentifier);
        let mut _localctx: Rc<TypeIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3602);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(482,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3568);
					recog.base.match_token(BOOLEAN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3569);
					recog.base.match_token(TINYINT,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3570);
					recog.base.match_token(BYTE,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3571);
					recog.base.match_token(SMALLINT,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3572);
					recog.base.match_token(SHORT,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(3573);
					recog.base.match_token(INT,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(3574);
					recog.base.match_token(INTEGER,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(3575);
					recog.base.match_token(BIGINT,&mut recog.err_handler)?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(3576);
					recog.base.match_token(LONG,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					recog.base.set_state(3577);
					recog.base.match_token(FLOAT,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					recog.base.set_state(3578);
					recog.base.match_token(REAL,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					recog.base.set_state(3579);
					recog.base.match_token(DOUBLE,&mut recog.err_handler)?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					recog.base.set_state(3580);
					recog.base.match_token(DATE,&mut recog.err_handler)?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					recog.base.set_state(3581);
					recog.base.match_token(TIMESTAMP,&mut recog.err_handler)?;

					}
				}
			,
				15 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					recog.base.set_state(3582);
					recog.base.match_token(TIMESTAMP_NTZ,&mut recog.err_handler)?;

					}
				}
			,
				16 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					recog.base.set_state(3583);
					recog.base.match_token(TIMESTAMP_LTZ,&mut recog.err_handler)?;

					}
				}
			,
				17 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					recog.base.set_state(3584);
					recog.base.match_token(STRING_KW,&mut recog.err_handler)?;

					recog.base.set_state(3586);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(481,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule collateClause*/
							recog.base.set_state(3585);
							recog.collateClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				18 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 18);
					recog.base.enter_outer_alt(None, 18);
					{
					recog.base.set_state(3588);
					recog.base.match_token(CHARACTER,&mut recog.err_handler)?;

					}
				}
			,
				19 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 19);
					recog.base.enter_outer_alt(None, 19);
					{
					recog.base.set_state(3589);
					recog.base.match_token(CHAR,&mut recog.err_handler)?;

					}
				}
			,
				20 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 20);
					recog.base.enter_outer_alt(None, 20);
					{
					recog.base.set_state(3590);
					recog.base.match_token(VARCHAR,&mut recog.err_handler)?;

					}
				}
			,
				21 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 21);
					recog.base.enter_outer_alt(None, 21);
					{
					recog.base.set_state(3591);
					recog.base.match_token(BINARY,&mut recog.err_handler)?;

					}
				}
			,
				22 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 22);
					recog.base.enter_outer_alt(None, 22);
					{
					recog.base.set_state(3592);
					recog.base.match_token(DECIMAL,&mut recog.err_handler)?;

					}
				}
			,
				23 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 23);
					recog.base.enter_outer_alt(None, 23);
					{
					recog.base.set_state(3593);
					recog.base.match_token(DEC,&mut recog.err_handler)?;

					}
				}
			,
				24 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 24);
					recog.base.enter_outer_alt(None, 24);
					{
					recog.base.set_state(3594);
					recog.base.match_token(NUMERIC,&mut recog.err_handler)?;

					}
				}
			,
				25 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 25);
					recog.base.enter_outer_alt(None, 25);
					{
					recog.base.set_state(3595);
					recog.base.match_token(VOID,&mut recog.err_handler)?;

					}
				}
			,
				26 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 26);
					recog.base.enter_outer_alt(None, 26);
					{
					recog.base.set_state(3596);
					recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

					}
				}
			,
				27 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 27);
					recog.base.enter_outer_alt(None, 27);
					{
					recog.base.set_state(3597);
					recog.base.match_token(VARIANT,&mut recog.err_handler)?;

					}
				}
			,
				28 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 28);
					recog.base.enter_outer_alt(None, 28);
					{
					recog.base.set_state(3598);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					}
				}
			,
				29 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 29);
					recog.base.enter_outer_alt(None, 29);
					{
					recog.base.set_state(3599);
					recog.base.match_token(STRUCT,&mut recog.err_handler)?;

					}
				}
			,
				30 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 30);
					recog.base.enter_outer_alt(None, 30);
					{
					recog.base.set_state(3600);
					recog.base.match_token(MAP,&mut recog.err_handler)?;

					}
				}
			,
				31 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 31);
					recog.base.enter_outer_alt(None, 31);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3601);
					let tmp = recog.identifier()?;
					 cast_mut::<_,TypeIdentifierContext >(&mut _localctx).unsupportedType = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- collateClause ----------------
pub type CollateClauseContextAll<'input> = CollateClauseContext<'input>;


pub type CollateClauseContext<'input> = BaseParserRuleContext<'input,CollateClauseContextExt<'input>>;

#[derive(Clone)]
pub struct CollateClauseContextExt<'input>{
	pub collationName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for CollateClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CollateClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_collateClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_collateClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CollateClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_collateClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for CollateClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_collateClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_collateClause }
}
antlr_rust::tid!{CollateClauseContextExt<'a>}

impl<'input> CollateClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CollateClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CollateClauseContextExt{
				collationName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CollateClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<CollateClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLLATE
/// Returns `None` if there is no child corresponding to token COLLATE
fn COLLATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COLLATE, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CollateClauseContextAttrs<'input> for CollateClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn collateClause(&mut self,)
	-> Result<Rc<CollateClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CollateClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 374, RULE_collateClause);
        let mut _localctx: Rc<CollateClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3604);
			recog.base.match_token(COLLATE,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(3605);
			let tmp = recog.identifier()?;
			 cast_mut::<_,CollateClauseContext >(&mut _localctx).collationName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- type_ ----------------
#[derive(Debug)]
pub enum Type_ContextAll<'input>{
	TypeNotNullContext(TypeNotNullContext<'input>),
	TypeNullContext(TypeNullContext<'input>),
Error(Type_Context<'input>)
}
antlr_rust::tid!{Type_ContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for Type_ContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for Type_ContextAll<'input>{}

impl<'input> Deref for Type_ContextAll<'input>{
	type Target = dyn Type_ContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use Type_ContextAll::*;
		match self{
			TypeNotNullContext(inner) => inner,
			TypeNullContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for Type_ContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for Type_ContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type Type_Context<'input> = BaseParserRuleContext<'input,Type_ContextExt<'input>>;

#[derive(Clone)]
pub struct Type_ContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for Type_Context<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for Type_Context<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for Type_Context<'input>{
}

impl<'input> CustomRuleContext<'input> for Type_ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}
antlr_rust::tid!{Type_ContextExt<'a>}

impl<'input> Type_ContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Type_ContextAll<'input>> {
		Rc::new(
		Type_ContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Type_ContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait Type_ContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<Type_ContextExt<'input>>{


}

impl<'input> Type_ContextAttrs<'input> for Type_Context<'input>{}

pub type TypeNotNullContext<'input> = BaseParserRuleContext<'input,TypeNotNullContextExt<'input>>;

pub trait TypeNotNullContextAttrs<'input>: DatabricksParserContext<'input>{
	fn nonnullableType(&self) -> Option<Rc<NonnullableTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
}

impl<'input> TypeNotNullContextAttrs<'input> for TypeNotNullContext<'input>{}

pub struct TypeNotNullContextExt<'input>{
	base:Type_ContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TypeNotNullContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TypeNotNullContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TypeNotNullContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_typeNotNull(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_typeNotNull(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TypeNotNullContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_typeNotNull(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeNotNullContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for TypeNotNullContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for TypeNotNullContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for TypeNotNullContext<'input> {}

impl<'input> TypeNotNullContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::TypeNotNullContext(
				BaseParserRuleContext::copy_from(ctx,TypeNotNullContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TypeNullContext<'input> = BaseParserRuleContext<'input,TypeNullContextExt<'input>>;

pub trait TypeNullContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
}

impl<'input> TypeNullContextAttrs<'input> for TypeNullContext<'input>{}

pub struct TypeNullContextExt<'input>{
	base:Type_ContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TypeNullContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TypeNullContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TypeNullContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_typeNull(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_typeNull(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TypeNullContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_typeNull(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeNullContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type_ }
}

impl<'input> Borrow<Type_ContextExt<'input>> for TypeNullContext<'input>{
	fn borrow(&self) -> &Type_ContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<Type_ContextExt<'input>> for TypeNullContext<'input>{
	fn borrow_mut(&mut self) -> &mut Type_ContextExt<'input> { &mut self.base }
}

impl<'input> Type_ContextAttrs<'input> for TypeNullContext<'input> {}

impl<'input> TypeNullContextExt<'input>{
	fn new(ctx: &dyn Type_ContextAttrs<'input>) -> Rc<Type_ContextAll<'input>>  {
		Rc::new(
			Type_ContextAll::TypeNullContext(
				BaseParserRuleContext::copy_from(ctx,TypeNullContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn type_(&mut self,)
	-> Result<Rc<Type_ContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Type_ContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 376, RULE_type_);
        let mut _localctx: Rc<Type_ContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3613);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(484,&mut recog.base)? {
				1 =>{
					let tmp = TypeNotNullContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule nonnullableType*/
					recog.base.set_state(3607);
					recog.nonnullableType()?;

					recog.base.set_state(3610);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(483,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3608);
							recog.base.match_token(NOT,&mut recog.err_handler)?;

							recog.base.set_state(3609);
							recog.base.match_token(NULL,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = TypeNullContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3612);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonnullableType ----------------
#[derive(Debug)]
pub enum NonnullableTypeContextAll<'input>{
	RowTypeContext(RowTypeContext<'input>),
	LambdaTypeContext(LambdaTypeContext<'input>),
	IntervalTypeContext(IntervalTypeContext<'input>),
	FunctionSignatureGenericTypeContext(FunctionSignatureGenericTypeContext<'input>),
	LegacyArrayTypeContext(LegacyArrayTypeContext<'input>),
	PrimitiveTypeContext(PrimitiveTypeContext<'input>),
	LegacyMapTypeContext(LegacyMapTypeContext<'input>),
Error(NonnullableTypeContext<'input>)
}
antlr_rust::tid!{NonnullableTypeContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for NonnullableTypeContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for NonnullableTypeContextAll<'input>{}

impl<'input> Deref for NonnullableTypeContextAll<'input>{
	type Target = dyn NonnullableTypeContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use NonnullableTypeContextAll::*;
		match self{
			RowTypeContext(inner) => inner,
			LambdaTypeContext(inner) => inner,
			IntervalTypeContext(inner) => inner,
			FunctionSignatureGenericTypeContext(inner) => inner,
			LegacyArrayTypeContext(inner) => inner,
			PrimitiveTypeContext(inner) => inner,
			LegacyMapTypeContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NonnullableTypeContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NonnullableTypeContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type NonnullableTypeContext<'input> = BaseParserRuleContext<'input,NonnullableTypeContextExt<'input>>;

#[derive(Clone)]
pub struct NonnullableTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NonnullableTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NonnullableTypeContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NonnullableTypeContext<'input>{
}

impl<'input> CustomRuleContext<'input> for NonnullableTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}
antlr_rust::tid!{NonnullableTypeContextExt<'a>}

impl<'input> NonnullableTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonnullableTypeContextAll<'input>> {
		Rc::new(
		NonnullableTypeContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonnullableTypeContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait NonnullableTypeContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NonnullableTypeContextExt<'input>>{


}

impl<'input> NonnullableTypeContextAttrs<'input> for NonnullableTypeContext<'input>{}

pub type RowTypeContext<'input> = BaseParserRuleContext<'input,RowTypeContextExt<'input>>;

pub trait RowTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STRUCT
	/// Returns `None` if there is no child corresponding to token STRUCT
	fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(STRUCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	fn rowField_all(&self) ->  Vec<Rc<RowFieldContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowField(&self, i: usize) -> Option<Rc<RowFieldContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NEQ
	/// Returns `None` if there is no child corresponding to token NEQ
	fn NEQ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(NEQ, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> RowTypeContextAttrs<'input> for RowTypeContext<'input>{}

pub struct RowTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RowTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RowTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_rowType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RowTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rowType(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for RowTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for RowTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for RowTypeContext<'input> {}

impl<'input> RowTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::RowTypeContext(
				BaseParserRuleContext::copy_from(ctx,RowTypeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LambdaTypeContext<'input> = BaseParserRuleContext<'input,LambdaTypeContextExt<'input>>;

pub trait LambdaTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn type__all(&self) ->  Vec<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn type_(&self, i: usize) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> LambdaTypeContextAttrs<'input> for LambdaTypeContext<'input>{}

pub struct LambdaTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LambdaTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LambdaTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LambdaTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_lambdaType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_lambdaType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LambdaTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_lambdaType(self);
	}
}

impl<'input> CustomRuleContext<'input> for LambdaTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for LambdaTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for LambdaTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for LambdaTypeContext<'input> {}

impl<'input> LambdaTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::LambdaTypeContext(
				BaseParserRuleContext::copy_from(ctx,LambdaTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntervalTypeContext<'input> = BaseParserRuleContext<'input,IntervalTypeContextExt<'input>>;

pub trait IntervalTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTERVAL
	/// Returns `None` if there is no child corresponding to token INTERVAL
	fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTERVAL, 0)
	}
	fn intervalTypeField_all(&self) ->  Vec<Rc<IntervalTypeFieldContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn intervalTypeField(&self, i: usize) -> Option<Rc<IntervalTypeFieldContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
}

impl<'input> IntervalTypeContextAttrs<'input> for IntervalTypeContext<'input>{}

pub struct IntervalTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	pub from: Option<Rc<IntervalTypeFieldContextAll<'input>>>,
	pub to: Option<Rc<IntervalTypeFieldContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntervalTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for IntervalTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IntervalTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_intervalType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_intervalType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IntervalTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_intervalType(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for IntervalTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for IntervalTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for IntervalTypeContext<'input> {}

impl<'input> IntervalTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::IntervalTypeContext(
				BaseParserRuleContext::copy_from(ctx,IntervalTypeContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionSignatureGenericTypeContext<'input> = BaseParserRuleContext<'input,FunctionSignatureGenericTypeContextExt<'input>>;

pub trait FunctionSignatureGenericTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOLLAR
	/// Returns `None` if there is no child corresponding to token DOLLAR
	fn DOLLAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DOLLAR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
}

impl<'input> FunctionSignatureGenericTypeContextAttrs<'input> for FunctionSignatureGenericTypeContext<'input>{}

pub struct FunctionSignatureGenericTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionSignatureGenericTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for FunctionSignatureGenericTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FunctionSignatureGenericTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionSignatureGenericType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_functionSignatureGenericType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FunctionSignatureGenericTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_functionSignatureGenericType(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionSignatureGenericTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for FunctionSignatureGenericTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for FunctionSignatureGenericTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for FunctionSignatureGenericTypeContext<'input> {}

impl<'input> FunctionSignatureGenericTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::FunctionSignatureGenericTypeContext(
				BaseParserRuleContext::copy_from(ctx,FunctionSignatureGenericTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LegacyArrayTypeContext<'input> = BaseParserRuleContext<'input,LegacyArrayTypeContextExt<'input>>;

pub trait LegacyArrayTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
}

impl<'input> LegacyArrayTypeContextAttrs<'input> for LegacyArrayTypeContext<'input>{}

pub struct LegacyArrayTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LegacyArrayTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LegacyArrayTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LegacyArrayTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_legacyArrayType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_legacyArrayType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LegacyArrayTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_legacyArrayType(self);
	}
}

impl<'input> CustomRuleContext<'input> for LegacyArrayTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for LegacyArrayTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for LegacyArrayTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for LegacyArrayTypeContext<'input> {}

impl<'input> LegacyArrayTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::LegacyArrayTypeContext(
				BaseParserRuleContext::copy_from(ctx,LegacyArrayTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrimitiveTypeContext<'input> = BaseParserRuleContext<'input,PrimitiveTypeContextExt<'input>>;

pub trait PrimitiveTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	fn typeIdentifier(&self) -> Option<Rc<TypeIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn typeParameter_all(&self) ->  Vec<Rc<TypeParameterContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn typeParameter(&self, i: usize) -> Option<Rc<TypeParameterContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PrimitiveTypeContextAttrs<'input> for PrimitiveTypeContext<'input>{}

pub struct PrimitiveTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrimitiveTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PrimitiveTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrimitiveTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_primitiveType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_primitiveType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrimitiveTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_primitiveType(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrimitiveTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for PrimitiveTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for PrimitiveTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for PrimitiveTypeContext<'input> {}

impl<'input> PrimitiveTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::PrimitiveTypeContext(
				BaseParserRuleContext::copy_from(ctx,PrimitiveTypeContextExt{
					tail:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LegacyMapTypeContext<'input> = BaseParserRuleContext<'input,LegacyMapTypeContextExt<'input>>;

pub trait LegacyMapTypeContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MAP
	/// Returns `None` if there is no child corresponding to token MAP
	fn MAP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MAP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
	fn type__all(&self) ->  Vec<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn type_(&self, i: usize) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> LegacyMapTypeContextAttrs<'input> for LegacyMapTypeContext<'input>{}

pub struct LegacyMapTypeContextExt<'input>{
	base:NonnullableTypeContextExt<'input>,
	pub keyType: Option<Rc<Type_ContextAll<'input>>>,
	pub valueType: Option<Rc<Type_ContextAll<'input>>>,
	pub tail: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LegacyMapTypeContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for LegacyMapTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for LegacyMapTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_legacyMapType(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_legacyMapType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for LegacyMapTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_legacyMapType(self);
	}
}

impl<'input> CustomRuleContext<'input> for LegacyMapTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonnullableType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonnullableType }
}

impl<'input> Borrow<NonnullableTypeContextExt<'input>> for LegacyMapTypeContext<'input>{
	fn borrow(&self) -> &NonnullableTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NonnullableTypeContextExt<'input>> for LegacyMapTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut NonnullableTypeContextExt<'input> { &mut self.base }
}

impl<'input> NonnullableTypeContextAttrs<'input> for LegacyMapTypeContext<'input> {}

impl<'input> LegacyMapTypeContextExt<'input>{
	fn new(ctx: &dyn NonnullableTypeContextAttrs<'input>) -> Rc<NonnullableTypeContextAll<'input>>  {
		Rc::new(
			NonnullableTypeContextAll::LegacyMapTypeContext(
				BaseParserRuleContext::copy_from(ctx,LegacyMapTypeContextExt{
					tail:None, 
        			keyType:None, valueType:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonnullableType(&mut self,)
	-> Result<Rc<NonnullableTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonnullableTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 378, RULE_nonnullableType);
        let mut _localctx: Rc<NonnullableTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(3685);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(494,&mut recog.base)? {
				1 =>{
					let tmp = FunctionSignatureGenericTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3615);
					recog.base.match_token(DOLLAR,&mut recog.err_handler)?;

					recog.base.set_state(3616);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = RowTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3617);
					recog.base.match_token(STRUCT,&mut recog.err_handler)?;

					recog.base.set_state(3633);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 LT 
						=> {
							{
							recog.base.set_state(3618);
							recog.base.match_token(LT,&mut recog.err_handler)?;

							/*InvokeRule rowField*/
							recog.base.set_state(3619);
							recog.rowField()?;

							recog.base.set_state(3624);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(485,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(3620);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule rowField*/
									recog.base.set_state(3621);
									recog.rowField()?;

									}
									} 
								}
								recog.base.set_state(3626);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(485,&mut recog.base)?;
							}
							recog.base.set_state(3628);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(3627);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let NonnullableTypeContextAll::RowTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							recog.base.set_state(3630);
							recog.base.match_token(GT,&mut recog.err_handler)?;

							}
						}

					 NEQ 
						=> {
							{
							recog.base.set_state(3632);
							recog.base.match_token(NEQ,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}
			,
				3 =>{
					let tmp = IntervalTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3635);
					recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

					/*InvokeRule intervalTypeField*/
					recog.base.set_state(3636);
					let tmp = recog.intervalTypeField()?;
					if let NonnullableTypeContextAll::IntervalTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3639);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(488,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3637);
							recog.base.match_token(TO,&mut recog.err_handler)?;

							/*InvokeRule intervalTypeField*/
							recog.base.set_state(3638);
							let tmp = recog.intervalTypeField()?;
							if let NonnullableTypeContextAll::IntervalTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
							ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				4 =>{
					let tmp = LegacyMapTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3641);
					recog.base.match_token(MAP,&mut recog.err_handler)?;

					recog.base.set_state(3642);
					recog.base.match_token(LT,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(3643);
					let tmp = recog.type_()?;
					if let NonnullableTypeContextAll::LegacyMapTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
					ctx.keyType = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3644);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(3645);
					let tmp = recog.type_()?;
					if let NonnullableTypeContextAll::LegacyMapTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
					ctx.valueType = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3647);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3646);
						let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
						if let NonnullableTypeContextAll::LegacyMapTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
						ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3649);
					recog.base.match_token(GT,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = LegacyArrayTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(3651);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(3652);
					recog.base.match_token(LT,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(3653);
					recog.type_()?;

					recog.base.set_state(3654);
					recog.base.match_token(GT,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					let tmp = LambdaTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(3656);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(3657);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule type_*/
					recog.base.set_state(3658);
					recog.type_()?;

					recog.base.set_state(3663);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3659);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule type_*/
						recog.base.set_state(3660);
						recog.type_()?;

						}
						}
						recog.base.set_state(3665);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(3666);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = PrimitiveTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					/*InvokeRule typeIdentifier*/
					recog.base.set_state(3668);
					recog.typeIdentifier()?;

					recog.base.set_state(3683);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(493,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3669);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule typeParameter*/
							recog.base.set_state(3670);
							recog.typeParameter()?;

							recog.base.set_state(3675);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(491,&mut recog.base)?;
							while { _alt!=2 && _alt!=INVALID_ALT } {
								if _alt==1 {
									{
									{
									recog.base.set_state(3671);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule typeParameter*/
									recog.base.set_state(3672);
									recog.typeParameter()?;

									}
									} 
								}
								recog.base.set_state(3677);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(491,&mut recog.base)?;
							}
							recog.base.set_state(3679);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(3678);
								let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
								if let NonnullableTypeContextAll::PrimitiveTypeContext(ctx) = cast_mut::<_,NonnullableTypeContextAll >(&mut _localctx){
								ctx.tail = Some(tmp); } else {unreachable!("cant cast");}  

								}
							}

							recog.base.set_state(3681);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowField ----------------
pub type RowFieldContextAll<'input> = RowFieldContext<'input>;


pub type RowFieldContext<'input> = BaseParserRuleContext<'input,RowFieldContextExt<'input>>;

#[derive(Clone)]
pub struct RowFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for RowFieldContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RowFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowField(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_rowField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RowFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rowField(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowField }
}
antlr_rust::tid!{RowFieldContextExt<'a>}

impl<'input> RowFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowFieldContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<RowFieldContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RowFieldContextAttrs<'input> for RowFieldContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowField(&mut self,)
	-> Result<Rc<RowFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 380, RULE_rowField);
        let mut _localctx: Rc<RowFieldContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3687);
			recog.identifier()?;

			recog.base.set_state(3689);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COLON {
				{
				recog.base.set_state(3688);
				recog.base.match_token(COLON,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule type_*/
			recog.base.set_state(3691);
			recog.type_()?;

			recog.base.set_state(3694);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==NOT {
				{
				recog.base.set_state(3692);
				recog.base.match_token(NOT,&mut recog.err_handler)?;

				recog.base.set_state(3693);
				recog.base.match_token(NULL,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(3697);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMENT {
				{
				/*InvokeRule commentSpec*/
				recog.base.set_state(3696);
				recog.commentSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- commentSpec ----------------
pub type CommentSpecContextAll<'input> = CommentSpecContext<'input>;


pub type CommentSpecContext<'input> = BaseParserRuleContext<'input,CommentSpecContextExt<'input>>;

#[derive(Clone)]
pub struct CommentSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for CommentSpecContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CommentSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_commentSpec(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_commentSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CommentSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_commentSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommentSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_commentSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_commentSpec }
}
antlr_rust::tid!{CommentSpecContextExt<'a>}

impl<'input> CommentSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CommentSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CommentSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CommentSpecContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<CommentSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
fn string(&self) -> Option<Rc<StringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CommentSpecContextAttrs<'input> for CommentSpecContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn commentSpec(&mut self,)
	-> Result<Rc<CommentSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CommentSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 382, RULE_commentSpec);
        let mut _localctx: Rc<CommentSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3699);
			recog.base.match_token(COMMENT,&mut recog.err_handler)?;

			/*InvokeRule string*/
			recog.base.set_state(3700);
			recog.string()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- typeParameter ----------------
pub type TypeParameterContextAll<'input> = TypeParameterContext<'input>;


pub type TypeParameterContext<'input> = BaseParserRuleContext<'input,TypeParameterContextExt<'input>>;

#[derive(Clone)]
pub struct TypeParameterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for TypeParameterContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TypeParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_typeParameter(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_typeParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TypeParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_typeParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_typeParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_typeParameter }
}
antlr_rust::tid!{TypeParameterContextExt<'a>}

impl<'input> TypeParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TypeParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TypeParameterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TypeParameterContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<TypeParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TypeParameterContextAttrs<'input> for TypeParameterContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn typeParameter(&mut self,)
	-> Result<Rc<TypeParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TypeParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 384, RULE_typeParameter);
        let mut _localctx: Rc<TypeParameterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3704);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INTEGER_VALUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3702);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}

			 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
			 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
			 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
			 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
			 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
			 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
			 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
			 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
			 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
			 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
			 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
			 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
			 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
			 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT | EXTENDED |
			 EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT | FIRST |
			 FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM | FROM_JSON |
			 FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT | GROUP | GROUPING |
			 HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY | IF | IGNORE | IMMEDIATE |
			 IMPORT | IN | INCLUDE | INDEX | INDEXES | INNER | INPATH | INPUT | INPUTFORMAT |
			 INSERT | INTERSECT | INTERVAL | INT | INTEGER | INTO | INVOKER | IS |
			 ITEMS | ILIKE | JOIN | KEY | KEYS | LANGUAGE | LAST | LATERAL | LAZY |
			 LEADING | LEFT | LIKE | LIMIT | LINES | LIST | LISTAGG | LIVE | LOAD |
			 LOCAL | LOCATION | LOCK | LOCKS | LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES |
			 MATCHED | MATERIALIZED | MERGE | MICROSECOND | MICROSECONDS | MILLISECOND |
			 MILLISECONDS | MINUS_KW | MINUTE | MINUTES | MODE | MODIFIES | MONTH |
			 MONTHS | MSCK | NAME | NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND |
			 NANOSECONDS | NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF |
			 OFFSET | ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT |
			 OUTER | OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
			 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
			 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
			 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL | RECORDREADER |
			 RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP | REFERENCE | REFERENCES |
			 REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE | RESET | RESPECT |
			 RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE | ROLE | ROLES |
			 ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES | SESSION_USER |
			 SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT | SOME | SORT |
			 SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS | STORED | STRATIFY |
			 STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING | SYNC | SYSTEM_TIME |
			 SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE | TARGET | TBLPROPERTIES |
			 TEMP | TEMPORARY | TERMINATED | STRING_KW | THEN | TIME | TIMEDIFF |
			 TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF | TIMESTAMP_LTZ | TIMESTAMP_NTZ |
			 TINYINT | TO | TOUCH | TRAILING | TRANSACTION | TRANSACTIONS | TRANSFORM |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE | UNARCHIVE | UNBOUNDED | UNCACHE |
			 UNION | UNIQUE | UNKNOWN | UNLOCK | UNPIVOT | UNSET | UPDATE | USE |
			 USER | USING | VALUES | VAR | VARCHAR | VARIANT | VERSION | VIEW | VIEWS |
			 VOID | WEEK | WEEKS | WHEN | WHERE | WHILE | WINDOW | WITH | WITHIN |
			 YEAR | YEARS | ZONE | DOLLAR | IDENTIFIER | BACKQUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule type_*/
					recog.base.set_state(3703);
					recog.type_()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenClause ----------------
pub type WhenClauseContextAll<'input> = WhenClauseContext<'input>;


pub type WhenClauseContext<'input> = BaseParserRuleContext<'input,WhenClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhenClauseContextExt<'input>{
	pub condition: Option<Rc<ExpressionContextAll<'input>>>,
	pub result: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for WhenClauseContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for WhenClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenClause(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_whenClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for WhenClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_whenClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhenClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenClause }
}
antlr_rust::tid!{WhenClauseContextExt<'a>}

impl<'input> WhenClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenClauseContextExt{
				condition: None, result: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenClauseContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<WhenClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> WhenClauseContextAttrs<'input> for WhenClauseContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenClause(&mut self,)
	-> Result<Rc<WhenClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 386, RULE_whenClause);
        let mut _localctx: Rc<WhenClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3706);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3707);
			let tmp = recog.expression()?;
			 cast_mut::<_,WhenClauseContext >(&mut _localctx).condition = Some(tmp.clone());
			  

			recog.base.set_state(3708);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3709);
			let tmp = recog.expression()?;
			 cast_mut::<_,WhenClauseContext >(&mut _localctx).result = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- filter ----------------
pub type FilterContextAll<'input> = FilterContext<'input>;


pub type FilterContext<'input> = BaseParserRuleContext<'input,FilterContextExt<'input>>;

#[derive(Clone)]
pub struct FilterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FilterContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FilterContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_filter(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_filter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FilterContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_filter(self);
	}
}

impl<'input> CustomRuleContext<'input> for FilterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_filter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_filter }
}
antlr_rust::tid!{FilterContextExt<'a>}

impl<'input> FilterContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FilterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FilterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FilterContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FilterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> FilterContextAttrs<'input> for FilterContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn filter(&mut self,)
	-> Result<Rc<FilterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FilterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 388, RULE_filter);
        let mut _localctx: Rc<FilterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3711);
			recog.base.match_token(FILTER,&mut recog.err_handler)?;

			recog.base.set_state(3712);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(3713);
			recog.base.match_token(WHERE,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(3714);
			recog.booleanExpression_rec(0)?;

			recog.base.set_state(3715);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- over ----------------
pub type OverContextAll<'input> = OverContext<'input>;


pub type OverContext<'input> = BaseParserRuleContext<'input,OverContextExt<'input>>;

#[derive(Clone)]
pub struct OverContextExt<'input>{
	pub windowName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for OverContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for OverContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_over(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_over(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for OverContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_over(self);
	}
}

impl<'input> CustomRuleContext<'input> for OverContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_over }
	//fn type_rule_index() -> usize where Self: Sized { RULE_over }
}
antlr_rust::tid!{OverContextExt<'a>}

impl<'input> OverContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OverContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OverContextExt{
				windowName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait OverContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<OverContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OVER
/// Returns `None` if there is no child corresponding to token OVER
fn OVER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn windowSpecification(&self) -> Option<Rc<WindowSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> OverContextAttrs<'input> for OverContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn over(&mut self,)
	-> Result<Rc<OverContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OverContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 390, RULE_over);
        let mut _localctx: Rc<OverContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3717);
			recog.base.match_token(OVER,&mut recog.err_handler)?;

			recog.base.set_state(3723);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
			 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
			 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
			 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
			 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
			 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
			 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
			 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
			 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
			 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
			 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
			 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
			 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
			 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT | EXTENDED |
			 EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT | FIRST |
			 FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM | FROM_JSON |
			 FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT | GROUP | GROUPING |
			 HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY | IF | IGNORE | IMMEDIATE |
			 IMPORT | IN | INCLUDE | INDEX | INDEXES | INNER | INPATH | INPUT | INPUTFORMAT |
			 INSERT | INTERSECT | INTERVAL | INT | INTEGER | INTO | INVOKER | IS |
			 ITEMS | ILIKE | JOIN | KEY | KEYS | LANGUAGE | LAST | LATERAL | LAZY |
			 LEADING | LEFT | LIKE | LIMIT | LINES | LIST | LISTAGG | LIVE | LOAD |
			 LOCAL | LOCATION | LOCK | LOCKS | LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES |
			 MATCHED | MATERIALIZED | MERGE | MICROSECOND | MICROSECONDS | MILLISECOND |
			 MILLISECONDS | MINUS_KW | MINUTE | MINUTES | MODE | MODIFIES | MONTH |
			 MONTHS | MSCK | NAME | NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND |
			 NANOSECONDS | NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF |
			 OFFSET | ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT |
			 OUTER | OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
			 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
			 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
			 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL | RECORDREADER |
			 RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP | REFERENCE | REFERENCES |
			 REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE | RESET | RESPECT |
			 RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE | ROLE | ROLES |
			 ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES | SESSION_USER |
			 SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT | SOME | SORT |
			 SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS | STORED | STRATIFY |
			 STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING | SYNC | SYSTEM_TIME |
			 SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE | TARGET | TBLPROPERTIES |
			 TEMP | TEMPORARY | TERMINATED | STRING_KW | THEN | TIME | TIMEDIFF |
			 TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF | TIMESTAMP_LTZ | TIMESTAMP_NTZ |
			 TINYINT | TO | TOUCH | TRAILING | TRANSACTION | TRANSACTIONS | TRANSFORM |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE | UNARCHIVE | UNBOUNDED | UNCACHE |
			 UNION | UNIQUE | UNKNOWN | UNLOCK | UNPIVOT | UNSET | UPDATE | USE |
			 USER | USING | VALUES | VAR | VARCHAR | VARIANT | VERSION | VIEW | VIEWS |
			 VOID | WEEK | WEEKS | WHEN | WHERE | WHILE | WINDOW | WITH | WITHIN |
			 YEAR | YEARS | ZONE | IDENTIFIER | BACKQUOTED_IDENTIFIER 
				=> {
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3718);
					let tmp = recog.identifier()?;
					 cast_mut::<_,OverContext >(&mut _localctx).windowName = Some(tmp.clone());
					  

					}
				}

			 LPAREN 
				=> {
					{
					recog.base.set_state(3719);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule windowSpecification*/
					recog.base.set_state(3720);
					recog.windowSpecification()?;

					recog.base.set_state(3721);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowFrame ----------------
pub type WindowFrameContextAll<'input> = WindowFrameContext<'input>;


pub type WindowFrameContext<'input> = BaseParserRuleContext<'input,WindowFrameContextExt<'input>>;

#[derive(Clone)]
pub struct WindowFrameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for WindowFrameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for WindowFrameContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowFrame(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_windowFrame(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for WindowFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_windowFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowFrame }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowFrame }
}
antlr_rust::tid!{WindowFrameContextExt<'a>}

impl<'input> WindowFrameContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowFrameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowFrameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowFrameContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<WindowFrameContextExt<'input>>{

fn frameExtent(&self) -> Option<Rc<FrameExtentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WindowFrameContextAttrs<'input> for WindowFrameContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowFrame(&mut self,)
	-> Result<Rc<WindowFrameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowFrameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 392, RULE_windowFrame);
        let mut _localctx: Rc<WindowFrameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule frameExtent*/
			recog.base.set_state(3725);
			recog.frameExtent()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- frameExtent ----------------
pub type FrameExtentContextAll<'input> = FrameExtentContext<'input>;


pub type FrameExtentContext<'input> = BaseParserRuleContext<'input,FrameExtentContextExt<'input>>;

#[derive(Clone)]
pub struct FrameExtentContextExt<'input>{
	pub frameType: Option<TokenType<'input>>,
	pub start: Option<Rc<FrameBoundContextAll<'input>>>,
	pub end: Option<Rc<FrameBoundContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FrameExtentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FrameExtentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_frameExtent(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_frameExtent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FrameExtentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_frameExtent(self);
	}
}

impl<'input> CustomRuleContext<'input> for FrameExtentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameExtent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameExtent }
}
antlr_rust::tid!{FrameExtentContextExt<'a>}

impl<'input> FrameExtentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FrameExtentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FrameExtentContextExt{
				frameType: None, 
				start: None, end: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FrameExtentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FrameExtentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
fn frameBound_all(&self) ->  Vec<Rc<FrameBoundContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn frameBound(&self, i: usize) -> Option<Rc<FrameBoundContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}

}

impl<'input> FrameExtentContextAttrs<'input> for FrameExtentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn frameExtent(&mut self,)
	-> Result<Rc<FrameExtentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FrameExtentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 394, RULE_frameExtent);
        let mut _localctx: Rc<FrameExtentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3743);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(500,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3727);
					let tmp = recog.base.match_token(RANGE,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(3728);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3729);
					let tmp = recog.base.match_token(ROWS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(3730);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3731);
					let tmp = recog.base.match_token(RANGE,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					recog.base.set_state(3732);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3733);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(3734);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3735);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3737);
					let tmp = recog.base.match_token(ROWS,&mut recog.err_handler)?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).frameType = Some(tmp);
					  

					recog.base.set_state(3738);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3739);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(3740);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(3741);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,FrameExtentContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- frameBound ----------------
#[derive(Debug)]
pub enum FrameBoundContextAll<'input>{
	BoundedFrameContext(BoundedFrameContext<'input>),
	UnboundedFrameContext(UnboundedFrameContext<'input>),
	CurrentRowBoundContext(CurrentRowBoundContext<'input>),
Error(FrameBoundContext<'input>)
}
antlr_rust::tid!{FrameBoundContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for FrameBoundContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for FrameBoundContextAll<'input>{}

impl<'input> Deref for FrameBoundContextAll<'input>{
	type Target = dyn FrameBoundContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use FrameBoundContextAll::*;
		match self{
			BoundedFrameContext(inner) => inner,
			UnboundedFrameContext(inner) => inner,
			CurrentRowBoundContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FrameBoundContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FrameBoundContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type FrameBoundContext<'input> = BaseParserRuleContext<'input,FrameBoundContextExt<'input>>;

#[derive(Clone)]
pub struct FrameBoundContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for FrameBoundContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FrameBoundContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FrameBoundContext<'input>{
}

impl<'input> CustomRuleContext<'input> for FrameBoundContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}
antlr_rust::tid!{FrameBoundContextExt<'a>}

impl<'input> FrameBoundContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FrameBoundContextAll<'input>> {
		Rc::new(
		FrameBoundContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FrameBoundContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait FrameBoundContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<FrameBoundContextExt<'input>>{


}

impl<'input> FrameBoundContextAttrs<'input> for FrameBoundContext<'input>{}

pub type BoundedFrameContext<'input> = BaseParserRuleContext<'input,BoundedFrameContextExt<'input>>;

pub trait BoundedFrameContextAttrs<'input>: DatabricksParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECEDING
	/// Returns `None` if there is no child corresponding to token PRECEDING
	fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PRECEDING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOLLOWING
	/// Returns `None` if there is no child corresponding to token FOLLOWING
	fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FOLLOWING, 0)
	}
}

impl<'input> BoundedFrameContextAttrs<'input> for BoundedFrameContext<'input>{}

pub struct BoundedFrameContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	pub boundType: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BoundedFrameContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for BoundedFrameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BoundedFrameContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_boundedFrame(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_boundedFrame(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BoundedFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_boundedFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for BoundedFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for BoundedFrameContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for BoundedFrameContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for BoundedFrameContext<'input> {}

impl<'input> BoundedFrameContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::BoundedFrameContext(
				BaseParserRuleContext::copy_from(ctx,BoundedFrameContextExt{
					boundType:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnboundedFrameContext<'input> = BaseParserRuleContext<'input,UnboundedFrameContextExt<'input>>;

pub trait UnboundedFrameContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNBOUNDED
	/// Returns `None` if there is no child corresponding to token UNBOUNDED
	fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(UNBOUNDED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PRECEDING
	/// Returns `None` if there is no child corresponding to token PRECEDING
	fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(PRECEDING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FOLLOWING
	/// Returns `None` if there is no child corresponding to token FOLLOWING
	fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FOLLOWING, 0)
	}
}

impl<'input> UnboundedFrameContextAttrs<'input> for UnboundedFrameContext<'input>{}

pub struct UnboundedFrameContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	pub boundType: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnboundedFrameContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UnboundedFrameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UnboundedFrameContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unboundedFrame(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_unboundedFrame(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UnboundedFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_unboundedFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnboundedFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for UnboundedFrameContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for UnboundedFrameContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for UnboundedFrameContext<'input> {}

impl<'input> UnboundedFrameContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::UnboundedFrameContext(
				BaseParserRuleContext::copy_from(ctx,UnboundedFrameContextExt{
					boundType:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CurrentRowBoundContext<'input> = BaseParserRuleContext<'input,CurrentRowBoundContextExt<'input>>;

pub trait CurrentRowBoundContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CURRENT
	/// Returns `None` if there is no child corresponding to token CURRENT
	fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(CURRENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
}

impl<'input> CurrentRowBoundContextAttrs<'input> for CurrentRowBoundContext<'input>{}

pub struct CurrentRowBoundContextExt<'input>{
	base:FrameBoundContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CurrentRowBoundContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for CurrentRowBoundContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for CurrentRowBoundContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_currentRowBound(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_currentRowBound(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for CurrentRowBoundContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_currentRowBound(self);
	}
}

impl<'input> CustomRuleContext<'input> for CurrentRowBoundContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}

impl<'input> Borrow<FrameBoundContextExt<'input>> for CurrentRowBoundContext<'input>{
	fn borrow(&self) -> &FrameBoundContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FrameBoundContextExt<'input>> for CurrentRowBoundContext<'input>{
	fn borrow_mut(&mut self) -> &mut FrameBoundContextExt<'input> { &mut self.base }
}

impl<'input> FrameBoundContextAttrs<'input> for CurrentRowBoundContext<'input> {}

impl<'input> CurrentRowBoundContextExt<'input>{
	fn new(ctx: &dyn FrameBoundContextAttrs<'input>) -> Rc<FrameBoundContextAll<'input>>  {
		Rc::new(
			FrameBoundContextAll::CurrentRowBoundContext(
				BaseParserRuleContext::copy_from(ctx,CurrentRowBoundContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn frameBound(&mut self,)
	-> Result<Rc<FrameBoundContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FrameBoundContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 396, RULE_frameBound);
        let mut _localctx: Rc<FrameBoundContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3754);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(501,&mut recog.base)? {
				1 =>{
					let tmp = UnboundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3745);
					recog.base.match_token(UNBOUNDED,&mut recog.err_handler)?;

					recog.base.set_state(3746);
					let tmp = recog.base.match_token(PRECEDING,&mut recog.err_handler)?;
					if let FrameBoundContextAll::UnboundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = UnboundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3747);
					recog.base.match_token(UNBOUNDED,&mut recog.err_handler)?;

					recog.base.set_state(3748);
					let tmp = recog.base.match_token(FOLLOWING,&mut recog.err_handler)?;
					if let FrameBoundContextAll::UnboundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
				}
			,
				3 =>{
					let tmp = CurrentRowBoundContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3749);
					recog.base.match_token(CURRENT,&mut recog.err_handler)?;

					recog.base.set_state(3750);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = BoundedFrameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(3751);
					recog.expression()?;

					recog.base.set_state(3752);
					if let FrameBoundContextAll::BoundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
					ctx.boundType = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==FOLLOWING || _la==PRECEDING) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let FrameBoundContextAll::BoundedFrameContext(ctx) = cast_mut::<_,FrameBoundContextAll >(&mut _localctx){
						ctx.boundType = Some(tmp); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privilege ----------------
pub type PrivilegeContextAll<'input> = PrivilegeContext<'input>;


pub type PrivilegeContext<'input> = BaseParserRuleContext<'input,PrivilegeContextExt<'input>>;

#[derive(Clone)]
pub struct PrivilegeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PrivilegeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrivilegeContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privilege(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_privilege(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrivilegeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_privilege(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrivilegeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privilege }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privilege }
}
antlr_rust::tid!{PrivilegeContextExt<'a>}

impl<'input> PrivilegeContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivilegeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivilegeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivilegeContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PrivilegeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}

}

impl<'input> PrivilegeContextAttrs<'input> for PrivilegeContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privilege(&mut self,)
	-> Result<Rc<PrivilegeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivilegeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 398, RULE_privilege);
        let mut _localctx: Rc<PrivilegeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3756);
			_la = recog.base.input.la(1);
			if { !(_la==CREATE || _la==DELETE || _la==INSERT || _la==SELECT || _la==UPDATE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- qualifiedName ----------------
#[derive(Debug)]
pub enum QualifiedNameContextAll<'input>{
	QualifiedNameDefaultContext(QualifiedNameDefaultContext<'input>),
Error(QualifiedNameContext<'input>)
}
antlr_rust::tid!{QualifiedNameContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QualifiedNameContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for QualifiedNameContextAll<'input>{}

impl<'input> Deref for QualifiedNameContextAll<'input>{
	type Target = dyn QualifiedNameContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QualifiedNameContextAll::*;
		match self{
			QualifiedNameDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QualifiedNameContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QualifiedNameContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QualifiedNameContext<'input> = BaseParserRuleContext<'input,QualifiedNameContextExt<'input>>;

#[derive(Clone)]
pub struct QualifiedNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QualifiedNameContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QualifiedNameContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QualifiedNameContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QualifiedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedName }
}
antlr_rust::tid!{QualifiedNameContextExt<'a>}

impl<'input> QualifiedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QualifiedNameContextAll<'input>> {
		Rc::new(
		QualifiedNameContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QualifiedNameContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QualifiedNameContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QualifiedNameContextExt<'input>>{


}

impl<'input> QualifiedNameContextAttrs<'input> for QualifiedNameContext<'input>{}

pub type QualifiedNameDefaultContext<'input> = BaseParserRuleContext<'input,QualifiedNameDefaultContextExt<'input>>;

pub trait QualifiedNameDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
	fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
	/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
	fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DOT, i)
	}
	fn pathComponent_all(&self) ->  Vec<Rc<PathComponentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn pathComponent(&self, i: usize) -> Option<Rc<PathComponentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> QualifiedNameDefaultContextAttrs<'input> for QualifiedNameDefaultContext<'input>{}

pub struct QualifiedNameDefaultContextExt<'input>{
	base:QualifiedNameContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QualifiedNameDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for QualifiedNameDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QualifiedNameDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_qualifiedNameDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_qualifiedNameDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QualifiedNameDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_qualifiedNameDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QualifiedNameDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedName }
}

impl<'input> Borrow<QualifiedNameContextExt<'input>> for QualifiedNameDefaultContext<'input>{
	fn borrow(&self) -> &QualifiedNameContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QualifiedNameContextExt<'input>> for QualifiedNameDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QualifiedNameContextExt<'input> { &mut self.base }
}

impl<'input> QualifiedNameContextAttrs<'input> for QualifiedNameDefaultContext<'input> {}

impl<'input> QualifiedNameDefaultContextExt<'input>{
	fn new(ctx: &dyn QualifiedNameContextAttrs<'input>) -> Rc<QualifiedNameContextAll<'input>>  {
		Rc::new(
			QualifiedNameContextAll::QualifiedNameDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QualifiedNameDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn qualifiedName(&mut self,)
	-> Result<Rc<QualifiedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QualifiedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 400, RULE_qualifiedName);
        let mut _localctx: Rc<QualifiedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			let tmp = QualifiedNameDefaultContextExt::new(&**_localctx);
			recog.base.enter_outer_alt(Some(tmp.clone()), 1);
			_localctx = tmp;
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3758);
			recog.identifier()?;

			recog.base.set_state(3763);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(502,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3759);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule pathComponent*/
					recog.base.set_state(3760);
					recog.pathComponent()?;

					}
					} 
				}
				recog.base.set_state(3765);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(502,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pathExpression ----------------
pub type PathExpressionContextAll<'input> = PathExpressionContext<'input>;


pub type PathExpressionContext<'input> = BaseParserRuleContext<'input,PathExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PathExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PathExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PathExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pathExpression(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_pathExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PathExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pathExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for PathExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pathExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pathExpression }
}
antlr_rust::tid!{PathExpressionContextExt<'a>}

impl<'input> PathExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PathExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PathExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PathExpressionContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PathExpressionContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PathExpressionContextAttrs<'input> for PathExpressionContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pathExpression(&mut self,)
	-> Result<Rc<PathExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PathExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 402, RULE_pathExpression);
        let mut _localctx: Rc<PathExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(3766);
			recog.qualifiedName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryPeriod ----------------
pub type QueryPeriodContextAll<'input> = QueryPeriodContext<'input>;


pub type QueryPeriodContext<'input> = BaseParserRuleContext<'input,QueryPeriodContextExt<'input>>;

#[derive(Clone)]
pub struct QueryPeriodContextExt<'input>{
	pub end: Option<Rc<ValueExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QueryPeriodContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QueryPeriodContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryPeriod(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_queryPeriod(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QueryPeriodContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_queryPeriod(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryPeriodContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPeriod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPeriod }
}
antlr_rust::tid!{QueryPeriodContextExt<'a>}

impl<'input> QueryPeriodContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryPeriodContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryPeriodContextExt{
				end: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryPeriodContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QueryPeriodContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
fn rangeType(&self) -> Option<Rc<RangeTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryPeriodContextAttrs<'input> for QueryPeriodContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryPeriod(&mut self,)
	-> Result<Rc<QueryPeriodContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryPeriodContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 404, RULE_queryPeriod);
        let mut _localctx: Rc<QueryPeriodContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3768);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule rangeType*/
			recog.base.set_state(3769);
			recog.rangeType()?;

			recog.base.set_state(3770);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(3771);
			recog.base.match_token(OF,&mut recog.err_handler)?;

			/*InvokeRule valueExpression*/
			recog.base.set_state(3772);
			let tmp = recog.valueExpression_rec(0)?;
			 cast_mut::<_,QueryPeriodContext >(&mut _localctx).end = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rangeType ----------------
pub type RangeTypeContextAll<'input> = RangeTypeContext<'input>;


pub type RangeTypeContext<'input> = BaseParserRuleContext<'input,RangeTypeContextExt<'input>>;

#[derive(Clone)]
pub struct RangeTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for RangeTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RangeTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rangeType(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_rangeType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RangeTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rangeType(self);
	}
}

impl<'input> CustomRuleContext<'input> for RangeTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rangeType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rangeType }
}
antlr_rust::tid!{RangeTypeContextExt<'a>}

impl<'input> RangeTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RangeTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RangeTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RangeTypeContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<RangeTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}

}

impl<'input> RangeTypeContextAttrs<'input> for RangeTypeContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rangeType(&mut self,)
	-> Result<Rc<RangeTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RangeTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 406, RULE_rangeType);
        let mut _localctx: Rc<RangeTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3774);
			_la = recog.base.input.la(1);
			if { !(_la==TIMESTAMP || _la==VERSION) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- principal ----------------
#[derive(Debug)]
pub enum PrincipalContextAll<'input>{
	UnspecifiedPrincipalContext(UnspecifiedPrincipalContext<'input>),
	UserPrincipalContext(UserPrincipalContext<'input>),
	RolePrincipalContext(RolePrincipalContext<'input>),
Error(PrincipalContext<'input>)
}
antlr_rust::tid!{PrincipalContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PrincipalContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PrincipalContextAll<'input>{}

impl<'input> Deref for PrincipalContextAll<'input>{
	type Target = dyn PrincipalContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PrincipalContextAll::*;
		match self{
			UnspecifiedPrincipalContext(inner) => inner,
			UserPrincipalContext(inner) => inner,
			RolePrincipalContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrincipalContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrincipalContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PrincipalContext<'input> = BaseParserRuleContext<'input,PrincipalContextExt<'input>>;

#[derive(Clone)]
pub struct PrincipalContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrincipalContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrincipalContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}
antlr_rust::tid!{PrincipalContextExt<'a>}

impl<'input> PrincipalContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrincipalContextAll<'input>> {
		Rc::new(
		PrincipalContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrincipalContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PrincipalContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PrincipalContextExt<'input>>{


}

impl<'input> PrincipalContextAttrs<'input> for PrincipalContext<'input>{}

pub type UnspecifiedPrincipalContext<'input> = BaseParserRuleContext<'input,UnspecifiedPrincipalContextExt<'input>>;

pub trait UnspecifiedPrincipalContextAttrs<'input>: DatabricksParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnspecifiedPrincipalContextAttrs<'input> for UnspecifiedPrincipalContext<'input>{}

pub struct UnspecifiedPrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnspecifiedPrincipalContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UnspecifiedPrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UnspecifiedPrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unspecifiedPrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_unspecifiedPrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UnspecifiedPrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_unspecifiedPrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnspecifiedPrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for UnspecifiedPrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for UnspecifiedPrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for UnspecifiedPrincipalContext<'input> {}

impl<'input> UnspecifiedPrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::UnspecifiedPrincipalContext(
				BaseParserRuleContext::copy_from(ctx,UnspecifiedPrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UserPrincipalContext<'input> = BaseParserRuleContext<'input,UserPrincipalContextExt<'input>>;

pub trait UserPrincipalContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token USER
	/// Returns `None` if there is no child corresponding to token USER
	fn USER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(USER, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UserPrincipalContextAttrs<'input> for UserPrincipalContext<'input>{}

pub struct UserPrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UserPrincipalContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UserPrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UserPrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_userPrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_userPrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UserPrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_userPrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for UserPrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for UserPrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for UserPrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for UserPrincipalContext<'input> {}

impl<'input> UserPrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::UserPrincipalContext(
				BaseParserRuleContext::copy_from(ctx,UserPrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RolePrincipalContext<'input> = BaseParserRuleContext<'input,RolePrincipalContextExt<'input>>;

pub trait RolePrincipalContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROLE
	/// Returns `None` if there is no child corresponding to token ROLE
	fn ROLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROLE, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RolePrincipalContextAttrs<'input> for RolePrincipalContext<'input>{}

pub struct RolePrincipalContextExt<'input>{
	base:PrincipalContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RolePrincipalContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for RolePrincipalContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for RolePrincipalContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rolePrincipal(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_rolePrincipal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for RolePrincipalContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_rolePrincipal(self);
	}
}

impl<'input> CustomRuleContext<'input> for RolePrincipalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principal }
}

impl<'input> Borrow<PrincipalContextExt<'input>> for RolePrincipalContext<'input>{
	fn borrow(&self) -> &PrincipalContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrincipalContextExt<'input>> for RolePrincipalContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrincipalContextExt<'input> { &mut self.base }
}

impl<'input> PrincipalContextAttrs<'input> for RolePrincipalContext<'input> {}

impl<'input> RolePrincipalContextExt<'input>{
	fn new(ctx: &dyn PrincipalContextAttrs<'input>) -> Rc<PrincipalContextAll<'input>>  {
		Rc::new(
			PrincipalContextAll::RolePrincipalContext(
				BaseParserRuleContext::copy_from(ctx,RolePrincipalContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn principal(&mut self,)
	-> Result<Rc<PrincipalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrincipalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 408, RULE_principal);
        let mut _localctx: Rc<PrincipalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3781);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(503,&mut recog.base)? {
				1 =>{
					let tmp = UnspecifiedPrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3776);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					let tmp = UserPrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3777);
					recog.base.match_token(USER,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3778);
					recog.identifier()?;

					}
				}
			,
				3 =>{
					let tmp = RolePrincipalContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3779);
					recog.base.match_token(ROLE,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3780);
					recog.identifier()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifier ----------------
#[derive(Debug)]
pub enum IdentifierContextAll<'input>{
	StrictNonReservedIdentifierContext(StrictNonReservedIdentifierContext<'input>),
	StrictIdentifierDefaultContext(StrictIdentifierDefaultContext<'input>),
Error(IdentifierContext<'input>)
}
antlr_rust::tid!{IdentifierContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for IdentifierContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for IdentifierContextAll<'input>{}

impl<'input> Deref for IdentifierContextAll<'input>{
	type Target = dyn IdentifierContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use IdentifierContextAll::*;
		match self{
			StrictNonReservedIdentifierContext(inner) => inner,
			StrictIdentifierDefaultContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentifierContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentifierContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type IdentifierContext<'input> = BaseParserRuleContext<'input,IdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentifierContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentifierContext<'input>{
}

impl<'input> CustomRuleContext<'input> for IdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}
antlr_rust::tid!{IdentifierContextExt<'a>}

impl<'input> IdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierContextAll<'input>> {
		Rc::new(
		IdentifierContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait IdentifierContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IdentifierContextExt<'input>>{


}

impl<'input> IdentifierContextAttrs<'input> for IdentifierContext<'input>{}

pub type StrictNonReservedIdentifierContext<'input> = BaseParserRuleContext<'input,StrictNonReservedIdentifierContextExt<'input>>;

pub trait StrictNonReservedIdentifierContextAttrs<'input>: DatabricksParserContext<'input>{
	fn strictNonReserved(&self) -> Option<Rc<StrictNonReservedContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StrictNonReservedIdentifierContextAttrs<'input> for StrictNonReservedIdentifierContext<'input>{}

pub struct StrictNonReservedIdentifierContextExt<'input>{
	base:IdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StrictNonReservedIdentifierContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StrictNonReservedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StrictNonReservedIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_strictNonReservedIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_strictNonReservedIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StrictNonReservedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_strictNonReservedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for StrictNonReservedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}

impl<'input> Borrow<IdentifierContextExt<'input>> for StrictNonReservedIdentifierContext<'input>{
	fn borrow(&self) -> &IdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IdentifierContextExt<'input>> for StrictNonReservedIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut IdentifierContextExt<'input> { &mut self.base }
}

impl<'input> IdentifierContextAttrs<'input> for StrictNonReservedIdentifierContext<'input> {}

impl<'input> StrictNonReservedIdentifierContextExt<'input>{
	fn new(ctx: &dyn IdentifierContextAttrs<'input>) -> Rc<IdentifierContextAll<'input>>  {
		Rc::new(
			IdentifierContextAll::StrictNonReservedIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,StrictNonReservedIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StrictIdentifierDefaultContext<'input> = BaseParserRuleContext<'input,StrictIdentifierDefaultContextExt<'input>>;

pub trait StrictIdentifierDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StrictIdentifierDefaultContextAttrs<'input> for StrictIdentifierDefaultContext<'input>{}

pub struct StrictIdentifierDefaultContextExt<'input>{
	base:IdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StrictIdentifierDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for StrictIdentifierDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StrictIdentifierDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_strictIdentifierDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_strictIdentifierDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StrictIdentifierDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_strictIdentifierDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for StrictIdentifierDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}

impl<'input> Borrow<IdentifierContextExt<'input>> for StrictIdentifierDefaultContext<'input>{
	fn borrow(&self) -> &IdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IdentifierContextExt<'input>> for StrictIdentifierDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut IdentifierContextExt<'input> { &mut self.base }
}

impl<'input> IdentifierContextAttrs<'input> for StrictIdentifierDefaultContext<'input> {}

impl<'input> StrictIdentifierDefaultContextExt<'input>{
	fn new(ctx: &dyn IdentifierContextAttrs<'input>) -> Rc<IdentifierContextAll<'input>>  {
		Rc::new(
			IdentifierContextAll::StrictIdentifierDefaultContext(
				BaseParserRuleContext::copy_from(ctx,StrictIdentifierDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifier(&mut self,)
	-> Result<Rc<IdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 410, RULE_identifier);
        let mut _localctx: Rc<IdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3785);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANY | ANY_VALUE |
			 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
			 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
			 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
			 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
			 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
			 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CUBE | CURRENT | CURRENT_DATE |
			 CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY | DAYS | DAYOFYEAR |
			 DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD | DATEDIFF |
			 DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE | DEFAULT |
			 DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE | DETERMINISTIC |
			 DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE | DIV | DO | DOUBLE |
			 DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION | EXCHANGE | EXCLUDE |
			 EXECUTE | EXISTS | EXPLAIN | EXPORT | EXTENDED | EXTERNAL | EXTRACT |
			 FALSE | FETCH | FIELDS | FILTER | FILEFORMAT | FIRST | FLOAT | FOLLOWING |
			 FOR | FOREIGN | FORMAT | FORMATTED | FROM | FROM_JSON | FUNCTION | FUNCTIONS |
			 GENERATED | GLOBAL | GRANT | GROUP | GROUPING | HAVING | HOUR | HOURS |
			 IDENTIFIER_KW | IDENTITY | IF | IGNORE | IMMEDIATE | IMPORT | IN | INCLUDE |
			 INDEX | INDEXES | INPATH | INPUT | INPUTFORMAT | INSERT | INTERVAL |
			 INT | INTEGER | INTO | INVOKER | IS | ITEMS | ILIKE | KEY | KEYS | LANGUAGE |
			 LAST | LAZY | LEADING | LIKE | LIMIT | LINES | LIST | LISTAGG | LIVE |
			 LOAD | LOCAL | LOCATION | LOCK | LOCKS | LOGICAL | LONG | MACRO | MAP |
			 MAP_FROM_ENTRIES | MATCHED | MATERIALIZED | MERGE | MICROSECOND | MICROSECONDS |
			 MILLISECOND | MILLISECONDS | MINUTE | MINUTES | MODE | MODIFIES | MONTH |
			 MONTHS | MSCK | NAME | NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND |
			 NANOSECONDS | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF | OFFSET |
			 ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT | OUTER | OUTPUTFORMAT |
			 OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION | PARTITIONED | PARTITIONS |
			 PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC | PIVOT | PLACING | POSITION |
			 PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES | PRUNE | PURGE | QUALIFY |
			 QUARTER | QUERY | RANGE | READS | REAL | RECORDREADER | RECORDWRITER |
			 RECOVER | RECURSIVE | REDUCE | REGEXP | REFERENCE | REFERENCES | REFRESH |
			 RENAME | REPAIR | REPEATABLE | REPLACE | RESET | RESPECT | RESTRICT |
			 RETURN | RETURNS | REVOKE | RLIKE | ROLE | ROLES | ROLLBACK | ROLLUP |
			 ROW | ROWS | SECOND | SECONDS | SCHEMA | SCHEMAS | SECURITY | SELECT |
			 SEPARATED | SERDE | SERDEPROPERTIES | SESSION_USER | SET | SETS | SHORT |
			 SHOW | SINGLE | SKEWED | SMALLINT | SOME | SORT | SORTED | SOURCE | SPECIFIC |
			 SQL | START | STATISTICS | STORED | STRATIFY | STREAM | STREAMING | STRUCT |
			 SUBSTR | SUBSTRING | SYNC | SYSTEM_TIME | SYSTEM_VERSION | TABLE | TABLES |
			 TABLESAMPLE | TARGET | TBLPROPERTIES | TEMP | TEMPORARY | TERMINATED |
			 STRING_KW | THEN | TIME | TIMEDIFF | TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF |
			 TIMESTAMP_LTZ | TIMESTAMP_NTZ | TINYINT | TO | TOUCH | TRAILING | TRANSACTION |
			 TRANSACTIONS | TRANSFORM | TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE |
			 UNARCHIVE | UNBOUNDED | UNCACHE | UNIQUE | UNKNOWN | UNLOCK | UNPIVOT |
			 UNSET | UPDATE | USE | USER | VALUES | VAR | VARCHAR | VARIANT | VERSION |
			 VIEW | VIEWS | VOID | WEEK | WEEKS | WHEN | WHERE | WHILE | WINDOW |
			 WITH | WITHIN | YEAR | YEARS | ZONE | IDENTIFIER | BACKQUOTED_IDENTIFIER 
				=> {
					let tmp = StrictIdentifierDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule strictIdentifier*/
					recog.base.set_state(3783);
					recog.strictIdentifier()?;

					}
				}

			 ANTI | CROSS | EXCEPT | FULL | INNER | INTERSECT | JOIN | LATERAL | LEFT |
			 MINUS_KW | NATURAL | ON | RIGHT | SEMI | UNION | USING 
				=> {
					let tmp = StrictNonReservedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule strictNonReserved*/
					recog.base.set_state(3784);
					recog.strictNonReserved()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- strictIdentifier ----------------
#[derive(Debug)]
pub enum StrictIdentifierContextAll<'input>{
	QuotedIdentifierDefaultContext(QuotedIdentifierDefaultContext<'input>),
	BackQuotedIdentifierContext(BackQuotedIdentifierContext<'input>),
	UnquotedIdentifierContext(UnquotedIdentifierContext<'input>),
Error(StrictIdentifierContext<'input>)
}
antlr_rust::tid!{StrictIdentifierContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StrictIdentifierContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for StrictIdentifierContextAll<'input>{}

impl<'input> Deref for StrictIdentifierContextAll<'input>{
	type Target = dyn StrictIdentifierContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StrictIdentifierContextAll::*;
		match self{
			QuotedIdentifierDefaultContext(inner) => inner,
			BackQuotedIdentifierContext(inner) => inner,
			UnquotedIdentifierContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StrictIdentifierContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StrictIdentifierContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StrictIdentifierContext<'input> = BaseParserRuleContext<'input,StrictIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct StrictIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StrictIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StrictIdentifierContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StrictIdentifierContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StrictIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictIdentifier }
}
antlr_rust::tid!{StrictIdentifierContextExt<'a>}

impl<'input> StrictIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StrictIdentifierContextAll<'input>> {
		Rc::new(
		StrictIdentifierContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StrictIdentifierContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StrictIdentifierContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StrictIdentifierContextExt<'input>>{


}

impl<'input> StrictIdentifierContextAttrs<'input> for StrictIdentifierContext<'input>{}

pub type QuotedIdentifierDefaultContext<'input> = BaseParserRuleContext<'input,QuotedIdentifierDefaultContextExt<'input>>;

pub trait QuotedIdentifierDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn quotedIdentifier(&self) -> Option<Rc<QuotedIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QuotedIdentifierDefaultContextAttrs<'input> for QuotedIdentifierDefaultContext<'input>{}

pub struct QuotedIdentifierDefaultContextExt<'input>{
	base:StrictIdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuotedIdentifierDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for QuotedIdentifierDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QuotedIdentifierDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quotedIdentifierDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_quotedIdentifierDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QuotedIdentifierDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_quotedIdentifierDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuotedIdentifierDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictIdentifier }
}

impl<'input> Borrow<StrictIdentifierContextExt<'input>> for QuotedIdentifierDefaultContext<'input>{
	fn borrow(&self) -> &StrictIdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StrictIdentifierContextExt<'input>> for QuotedIdentifierDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut StrictIdentifierContextExt<'input> { &mut self.base }
}

impl<'input> StrictIdentifierContextAttrs<'input> for QuotedIdentifierDefaultContext<'input> {}

impl<'input> QuotedIdentifierDefaultContextExt<'input>{
	fn new(ctx: &dyn StrictIdentifierContextAttrs<'input>) -> Rc<StrictIdentifierContextAll<'input>>  {
		Rc::new(
			StrictIdentifierContextAll::QuotedIdentifierDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QuotedIdentifierDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BackQuotedIdentifierContext<'input> = BaseParserRuleContext<'input,BackQuotedIdentifierContextExt<'input>>;

pub trait BackQuotedIdentifierContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BACKQUOTED_IDENTIFIER
	/// Returns `None` if there is no child corresponding to token BACKQUOTED_IDENTIFIER
	fn BACKQUOTED_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BACKQUOTED_IDENTIFIER, 0)
	}
}

impl<'input> BackQuotedIdentifierContextAttrs<'input> for BackQuotedIdentifierContext<'input>{}

pub struct BackQuotedIdentifierContextExt<'input>{
	base:StrictIdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BackQuotedIdentifierContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for BackQuotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BackQuotedIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_backQuotedIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_backQuotedIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BackQuotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_backQuotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for BackQuotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictIdentifier }
}

impl<'input> Borrow<StrictIdentifierContextExt<'input>> for BackQuotedIdentifierContext<'input>{
	fn borrow(&self) -> &StrictIdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StrictIdentifierContextExt<'input>> for BackQuotedIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut StrictIdentifierContextExt<'input> { &mut self.base }
}

impl<'input> StrictIdentifierContextAttrs<'input> for BackQuotedIdentifierContext<'input> {}

impl<'input> BackQuotedIdentifierContextExt<'input>{
	fn new(ctx: &dyn StrictIdentifierContextAttrs<'input>) -> Rc<StrictIdentifierContextAll<'input>>  {
		Rc::new(
			StrictIdentifierContextAll::BackQuotedIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,BackQuotedIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnquotedIdentifierContext<'input> = BaseParserRuleContext<'input,UnquotedIdentifierContextExt<'input>>;

pub trait UnquotedIdentifierContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IDENTIFIER
	/// Returns `None` if there is no child corresponding to token IDENTIFIER
	fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(IDENTIFIER, 0)
	}
	fn nonReserved(&self) -> Option<Rc<NonReservedContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnquotedIdentifierContextAttrs<'input> for UnquotedIdentifierContext<'input>{}

pub struct UnquotedIdentifierContextExt<'input>{
	base:StrictIdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnquotedIdentifierContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for UnquotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for UnquotedIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unquotedIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_unquotedIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for UnquotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_unquotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnquotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictIdentifier }
}

impl<'input> Borrow<StrictIdentifierContextExt<'input>> for UnquotedIdentifierContext<'input>{
	fn borrow(&self) -> &StrictIdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StrictIdentifierContextExt<'input>> for UnquotedIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut StrictIdentifierContextExt<'input> { &mut self.base }
}

impl<'input> StrictIdentifierContextAttrs<'input> for UnquotedIdentifierContext<'input> {}

impl<'input> UnquotedIdentifierContextExt<'input>{
	fn new(ctx: &dyn StrictIdentifierContextAttrs<'input>) -> Rc<StrictIdentifierContextAll<'input>>  {
		Rc::new(
			StrictIdentifierContextAll::UnquotedIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,UnquotedIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn strictIdentifier(&mut self,)
	-> Result<Rc<StrictIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StrictIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 412, RULE_strictIdentifier);
        let mut _localctx: Rc<StrictIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3791);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(505,&mut recog.base)? {
				1 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3787);
					recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = QuotedIdentifierDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule quotedIdentifier*/
					recog.base.set_state(3788);
					recog.quotedIdentifier()?;

					}
				}
			,
				3 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule nonReserved*/
					recog.base.set_state(3789);
					recog.nonReserved()?;

					}
				}
			,
				4 =>{
					let tmp = BackQuotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3790);
					recog.base.match_token(BACKQUOTED_IDENTIFIER,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- quotedIdentifier ----------------
pub type QuotedIdentifierContextAll<'input> = QuotedIdentifierContext<'input>;


pub type QuotedIdentifierContext<'input> = BaseParserRuleContext<'input,QuotedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct QuotedIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for QuotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for QuotedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_quotedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_quotedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for QuotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_quotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_quotedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_quotedIdentifier }
}
antlr_rust::tid!{QuotedIdentifierContextExt<'a>}

impl<'input> QuotedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuotedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuotedIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QuotedIdentifierContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<QuotedIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BACKQUOTED_IDENTIFIER
/// Returns `None` if there is no child corresponding to token BACKQUOTED_IDENTIFIER
fn BACKQUOTED_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BACKQUOTED_IDENTIFIER, 0)
}

}

impl<'input> QuotedIdentifierContextAttrs<'input> for QuotedIdentifierContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn quotedIdentifier(&mut self,)
	-> Result<Rc<QuotedIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuotedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 414, RULE_quotedIdentifier);
        let mut _localctx: Rc<QuotedIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3793);
			recog.base.match_token(BACKQUOTED_IDENTIFIER,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pathComponent ----------------
pub type PathComponentContextAll<'input> = PathComponentContext<'input>;


pub type PathComponentContext<'input> = BaseParserRuleContext<'input,PathComponentContextExt<'input>>;

#[derive(Clone)]
pub struct PathComponentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PathComponentContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PathComponentContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pathComponent(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_pathComponent(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PathComponentContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_pathComponent(self);
	}
}

impl<'input> CustomRuleContext<'input> for PathComponentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pathComponent }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pathComponent }
}
antlr_rust::tid!{PathComponentContextExt<'a>}

impl<'input> PathComponentContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PathComponentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PathComponentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PathComponentContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PathComponentContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PathComponentContextAttrs<'input> for PathComponentContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pathComponent(&mut self,)
	-> Result<Rc<PathComponentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PathComponentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 416, RULE_pathComponent);
        let mut _localctx: Rc<PathComponentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3795);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- standaloneIdentifier ----------------
pub type StandaloneIdentifierContextAll<'input> = StandaloneIdentifierContext<'input>;


pub type StandaloneIdentifierContext<'input> = BaseParserRuleContext<'input,StandaloneIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct StandaloneIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StandaloneIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StandaloneIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_standaloneIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_standaloneIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StandaloneIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_standaloneIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for StandaloneIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_standaloneIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_standaloneIdentifier }
}
antlr_rust::tid!{StandaloneIdentifierContextExt<'a>}

impl<'input> StandaloneIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StandaloneIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StandaloneIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StandaloneIdentifierContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StandaloneIdentifierContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> StandaloneIdentifierContextAttrs<'input> for StandaloneIdentifierContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn standaloneIdentifier(&mut self,)
	-> Result<Rc<StandaloneIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StandaloneIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 418, RULE_standaloneIdentifier);
        let mut _localctx: Rc<StandaloneIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3797);
			recog.identifier()?;

			recog.base.set_state(3798);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierList ----------------
pub type IdentifierListContextAll<'input> = IdentifierListContext<'input>;


pub type IdentifierListContext<'input> = BaseParserRuleContext<'input,IdentifierListContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IdentifierListContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentifierListContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierList(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_identifierList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentifierListContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_identifierList(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierList }
}
antlr_rust::tid!{IdentifierListContextExt<'a>}

impl<'input> IdentifierListContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierListContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IdentifierListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> IdentifierListContextAttrs<'input> for IdentifierListContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierList(&mut self,)
	-> Result<Rc<IdentifierListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 420, RULE_identifierList);
        let mut _localctx: Rc<IdentifierListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3800);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifierSeq*/
			recog.base.set_state(3801);
			recog.identifierSeq()?;

			recog.base.set_state(3802);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierSeq ----------------
pub type IdentifierSeqContextAll<'input> = IdentifierSeqContext<'input>;


pub type IdentifierSeqContext<'input> = BaseParserRuleContext<'input,IdentifierSeqContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierSeqContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for IdentifierSeqContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IdentifierSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierSeq(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_identifierSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IdentifierSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_identifierSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierSeq }
}
antlr_rust::tid!{IdentifierSeqContextExt<'a>}

impl<'input> IdentifierSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierSeqContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierSeqContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<IdentifierSeqContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> IdentifierSeqContextAttrs<'input> for IdentifierSeqContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierSeq(&mut self,)
	-> Result<Rc<IdentifierSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 422, RULE_identifierSeq);
        let mut _localctx: Rc<IdentifierSeqContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3804);
			recog.identifier()?;

			recog.base.set_state(3809);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(506,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3805);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(3806);
					recog.identifier()?;

					}
					} 
				}
				recog.base.set_state(3811);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(506,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- number ----------------
#[derive(Debug)]
pub enum NumberContextAll<'input>{
	DecimalLiteralContext(DecimalLiteralContext<'input>),
	BigIntLiteralContext(BigIntLiteralContext<'input>),
	TinyIntLiteralContext(TinyIntLiteralContext<'input>),
	BigDecimalLiteralContext(BigDecimalLiteralContext<'input>),
	DoubleLiteralContext(DoubleLiteralContext<'input>),
	ExponentLiteralContext(ExponentLiteralContext<'input>),
	IntegerLiteralContext(IntegerLiteralContext<'input>),
	FloatLiteralContext(FloatLiteralContext<'input>),
	SmallIntLiteralContext(SmallIntLiteralContext<'input>),
Error(NumberContext<'input>)
}
antlr_rust::tid!{NumberContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for NumberContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for NumberContextAll<'input>{}

impl<'input> Deref for NumberContextAll<'input>{
	type Target = dyn NumberContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use NumberContextAll::*;
		match self{
			DecimalLiteralContext(inner) => inner,
			BigIntLiteralContext(inner) => inner,
			TinyIntLiteralContext(inner) => inner,
			BigDecimalLiteralContext(inner) => inner,
			DoubleLiteralContext(inner) => inner,
			ExponentLiteralContext(inner) => inner,
			IntegerLiteralContext(inner) => inner,
			FloatLiteralContext(inner) => inner,
			SmallIntLiteralContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NumberContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NumberContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type NumberContext<'input> = BaseParserRuleContext<'input,NumberContextExt<'input>>;

#[derive(Clone)]
pub struct NumberContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NumberContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NumberContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NumberContext<'input>{
}

impl<'input> CustomRuleContext<'input> for NumberContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}
antlr_rust::tid!{NumberContextExt<'a>}

impl<'input> NumberContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NumberContextAll<'input>> {
		Rc::new(
		NumberContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NumberContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait NumberContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NumberContextExt<'input>>{


}

impl<'input> NumberContextAttrs<'input> for NumberContext<'input>{}

pub type DecimalLiteralContext<'input> = BaseParserRuleContext<'input,DecimalLiteralContextExt<'input>>;

pub trait DecimalLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
	fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> DecimalLiteralContextAttrs<'input> for DecimalLiteralContext<'input>{}

pub struct DecimalLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DecimalLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DecimalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DecimalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_decimalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_decimalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DecimalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_decimalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DecimalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for DecimalLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for DecimalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for DecimalLiteralContext<'input> {}

impl<'input> DecimalLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::DecimalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DecimalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigIntLiteralContext<'input> = BaseParserRuleContext<'input,BigIntLiteralContextExt<'input>>;

pub trait BigIntLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BIGINT_VALUE
	/// Returns `None` if there is no child corresponding to token BIGINT_VALUE
	fn BIGINT_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BIGINT_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> BigIntLiteralContextAttrs<'input> for BigIntLiteralContext<'input>{}

pub struct BigIntLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigIntLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for BigIntLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BigIntLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigIntLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_bigIntLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BigIntLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_bigIntLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigIntLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for BigIntLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for BigIntLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for BigIntLiteralContext<'input> {}

impl<'input> BigIntLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::BigIntLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BigIntLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TinyIntLiteralContext<'input> = BaseParserRuleContext<'input,TinyIntLiteralContextExt<'input>>;

pub trait TinyIntLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TINYINT_VALUE
	/// Returns `None` if there is no child corresponding to token TINYINT_VALUE
	fn TINYINT_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(TINYINT_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> TinyIntLiteralContextAttrs<'input> for TinyIntLiteralContext<'input>{}

pub struct TinyIntLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TinyIntLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for TinyIntLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for TinyIntLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tinyIntLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_tinyIntLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for TinyIntLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_tinyIntLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for TinyIntLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for TinyIntLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for TinyIntLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for TinyIntLiteralContext<'input> {}

impl<'input> TinyIntLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::TinyIntLiteralContext(
				BaseParserRuleContext::copy_from(ctx,TinyIntLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigDecimalLiteralContext<'input> = BaseParserRuleContext<'input,BigDecimalLiteralContextExt<'input>>;

pub trait BigDecimalLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BIGDECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token BIGDECIMAL_VALUE
	fn BIGDECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(BIGDECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> BigDecimalLiteralContextAttrs<'input> for BigDecimalLiteralContext<'input>{}

pub struct BigDecimalLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigDecimalLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for BigDecimalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for BigDecimalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigDecimalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_bigDecimalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for BigDecimalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_bigDecimalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigDecimalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for BigDecimalLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for BigDecimalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for BigDecimalLiteralContext<'input> {}

impl<'input> BigDecimalLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::BigDecimalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BigDecimalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DoubleLiteralContext<'input> = BaseParserRuleContext<'input,DoubleLiteralContextExt<'input>>;

pub trait DoubleLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOUBLE_VALUE
	/// Returns `None` if there is no child corresponding to token DOUBLE_VALUE
	fn DOUBLE_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(DOUBLE_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> DoubleLiteralContextAttrs<'input> for DoubleLiteralContext<'input>{}

pub struct DoubleLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DoubleLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for DoubleLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for DoubleLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_doubleLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_doubleLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for DoubleLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_doubleLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DoubleLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for DoubleLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for DoubleLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for DoubleLiteralContext<'input> {}

impl<'input> DoubleLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::DoubleLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DoubleLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExponentLiteralContext<'input> = BaseParserRuleContext<'input,ExponentLiteralContextExt<'input>>;

pub trait ExponentLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXPONENT_VALUE
	/// Returns `None` if there is no child corresponding to token EXPONENT_VALUE
	fn EXPONENT_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(EXPONENT_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> ExponentLiteralContextAttrs<'input> for ExponentLiteralContext<'input>{}

pub struct ExponentLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExponentLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for ExponentLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for ExponentLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_exponentLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_exponentLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for ExponentLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_exponentLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExponentLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for ExponentLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for ExponentLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for ExponentLiteralContext<'input> {}

impl<'input> ExponentLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::ExponentLiteralContext(
				BaseParserRuleContext::copy_from(ctx,ExponentLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntegerLiteralContext<'input> = BaseParserRuleContext<'input,IntegerLiteralContextExt<'input>>;

pub trait IntegerLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> IntegerLiteralContextAttrs<'input> for IntegerLiteralContext<'input>{}

pub struct IntegerLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntegerLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for IntegerLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for IntegerLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_integerLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_integerLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for IntegerLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_integerLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntegerLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for IntegerLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for IntegerLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for IntegerLiteralContext<'input> {}

impl<'input> IntegerLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::IntegerLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IntegerLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FloatLiteralContext<'input> = BaseParserRuleContext<'input,FloatLiteralContextExt<'input>>;

pub trait FloatLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FLOAT_VALUE
	/// Returns `None` if there is no child corresponding to token FLOAT_VALUE
	fn FLOAT_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FLOAT_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> FloatLiteralContextAttrs<'input> for FloatLiteralContext<'input>{}

pub struct FloatLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FloatLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for FloatLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for FloatLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_floatLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_floatLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for FloatLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_floatLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for FloatLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for FloatLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for FloatLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for FloatLiteralContext<'input> {}

impl<'input> FloatLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::FloatLiteralContext(
				BaseParserRuleContext::copy_from(ctx,FloatLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SmallIntLiteralContext<'input> = BaseParserRuleContext<'input,SmallIntLiteralContextExt<'input>>;

pub trait SmallIntLiteralContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SMALLINT_VALUE
	/// Returns `None` if there is no child corresponding to token SMALLINT_VALUE
	fn SMALLINT_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(SMALLINT_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> SmallIntLiteralContextAttrs<'input> for SmallIntLiteralContext<'input>{}

pub struct SmallIntLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SmallIntLiteralContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for SmallIntLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for SmallIntLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_smallIntLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_smallIntLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for SmallIntLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_smallIntLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for SmallIntLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for SmallIntLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for SmallIntLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for SmallIntLiteralContext<'input> {}

impl<'input> SmallIntLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::SmallIntLiteralContext(
				BaseParserRuleContext::copy_from(ctx,SmallIntLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn number(&mut self,)
	-> Result<Rc<NumberContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NumberContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 424, RULE_number);
        let mut _localctx: Rc<NumberContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3848);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(516,&mut recog.base)? {
				1 =>{
					let tmp = DecimalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3813);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3812);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3815);
					recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = DoubleLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3817);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3816);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3819);
					recog.base.match_token(DOUBLE_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = IntegerLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3821);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3820);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3823);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = ExponentLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3825);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3824);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3827);
					recog.base.match_token(EXPONENT_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = BigIntLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(3829);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3828);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3831);
					recog.base.match_token(BIGINT_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					let tmp = SmallIntLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(3833);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3832);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3835);
					recog.base.match_token(SMALLINT_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = TinyIntLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(3837);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3836);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3839);
					recog.base.match_token(TINYINT_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					let tmp = FloatLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(3841);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3840);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3843);
					recog.base.match_token(FLOAT_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				9 =>{
					let tmp = BigDecimalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(3845);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(3844);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3847);
					recog.base.match_token(BIGDECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- prestoShowFunctionType ----------------
#[derive(Debug)]
pub enum PrestoShowFunctionTypeContextAll<'input>{
	PrestoFunctionArgumentLambdaContext(PrestoFunctionArgumentLambdaContext<'input>),
	PrestoFunctionArgumentIntegerContext(PrestoFunctionArgumentIntegerContext<'input>),
	PrestoFunctionArgumentStructContext(PrestoFunctionArgumentStructContext<'input>),
	PrestoFunctionArgumentDefaultContext(PrestoFunctionArgumentDefaultContext<'input>),
	PrestoFunctionArgumentMapContext(PrestoFunctionArgumentMapContext<'input>),
	PrestoFunctionArgumentArrayContext(PrestoFunctionArgumentArrayContext<'input>),
Error(PrestoShowFunctionTypeContext<'input>)
}
antlr_rust::tid!{PrestoShowFunctionTypeContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PrestoShowFunctionTypeContextAll<'input>{}

impl<'input> DatabricksParserContext<'input> for PrestoShowFunctionTypeContextAll<'input>{}

impl<'input> Deref for PrestoShowFunctionTypeContextAll<'input>{
	type Target = dyn PrestoShowFunctionTypeContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PrestoShowFunctionTypeContextAll::*;
		match self{
			PrestoFunctionArgumentLambdaContext(inner) => inner,
			PrestoFunctionArgumentIntegerContext(inner) => inner,
			PrestoFunctionArgumentStructContext(inner) => inner,
			PrestoFunctionArgumentDefaultContext(inner) => inner,
			PrestoFunctionArgumentMapContext(inner) => inner,
			PrestoFunctionArgumentArrayContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoShowFunctionTypeContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoShowFunctionTypeContextAll<'input>{
    fn enter(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn DatabricksListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PrestoShowFunctionTypeContext<'input> = BaseParserRuleContext<'input,PrestoShowFunctionTypeContextExt<'input>>;

#[derive(Clone)]
pub struct PrestoShowFunctionTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PrestoShowFunctionTypeContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoShowFunctionTypeContext<'input>{
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoShowFunctionTypeContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PrestoShowFunctionTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionType }
}
antlr_rust::tid!{PrestoShowFunctionTypeContextExt<'a>}

impl<'input> PrestoShowFunctionTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrestoShowFunctionTypeContextAll<'input>> {
		Rc::new(
		PrestoShowFunctionTypeContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrestoShowFunctionTypeContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PrestoShowFunctionTypeContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PrestoShowFunctionTypeContextExt<'input>>{


}

impl<'input> PrestoShowFunctionTypeContextAttrs<'input> for PrestoShowFunctionTypeContext<'input>{}

pub type PrestoFunctionArgumentLambdaContext<'input> = BaseParserRuleContext<'input,PrestoFunctionArgumentLambdaContextExt<'input>>;

pub trait PrestoFunctionArgumentLambdaContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn prestoShowFunctionType_all(&self) ->  Vec<Rc<PrestoShowFunctionTypeContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn prestoShowFunctionType(&self, i: usize) -> Option<Rc<PrestoShowFunctionTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PrestoFunctionArgumentLambdaContextAttrs<'input> for PrestoFunctionArgumentLambdaContext<'input>{}

pub struct PrestoFunctionArgumentLambdaContextExt<'input>{
	base:PrestoShowFunctionTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrestoFunctionArgumentLambdaContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PrestoFunctionArgumentLambdaContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoFunctionArgumentLambdaContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_prestoFunctionArgumentLambda(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_prestoFunctionArgumentLambda(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoFunctionArgumentLambdaContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_prestoFunctionArgumentLambda(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrestoFunctionArgumentLambdaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionType }
}

impl<'input> Borrow<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentLambdaContext<'input>{
	fn borrow(&self) -> &PrestoShowFunctionTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentLambdaContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrestoShowFunctionTypeContextExt<'input> { &mut self.base }
}

impl<'input> PrestoShowFunctionTypeContextAttrs<'input> for PrestoFunctionArgumentLambdaContext<'input> {}

impl<'input> PrestoFunctionArgumentLambdaContextExt<'input>{
	fn new(ctx: &dyn PrestoShowFunctionTypeContextAttrs<'input>) -> Rc<PrestoShowFunctionTypeContextAll<'input>>  {
		Rc::new(
			PrestoShowFunctionTypeContextAll::PrestoFunctionArgumentLambdaContext(
				BaseParserRuleContext::copy_from(ctx,PrestoFunctionArgumentLambdaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrestoFunctionArgumentIntegerContext<'input> = BaseParserRuleContext<'input,PrestoFunctionArgumentIntegerContextExt<'input>>;

pub trait PrestoFunctionArgumentIntegerContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTEGER
	/// Returns `None` if there is no child corresponding to token INTEGER
	fn INTEGER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(INTEGER, 0)
	}
}

impl<'input> PrestoFunctionArgumentIntegerContextAttrs<'input> for PrestoFunctionArgumentIntegerContext<'input>{}

pub struct PrestoFunctionArgumentIntegerContextExt<'input>{
	base:PrestoShowFunctionTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrestoFunctionArgumentIntegerContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PrestoFunctionArgumentIntegerContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoFunctionArgumentIntegerContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_prestoFunctionArgumentInteger(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_prestoFunctionArgumentInteger(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoFunctionArgumentIntegerContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_prestoFunctionArgumentInteger(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrestoFunctionArgumentIntegerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionType }
}

impl<'input> Borrow<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentIntegerContext<'input>{
	fn borrow(&self) -> &PrestoShowFunctionTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentIntegerContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrestoShowFunctionTypeContextExt<'input> { &mut self.base }
}

impl<'input> PrestoShowFunctionTypeContextAttrs<'input> for PrestoFunctionArgumentIntegerContext<'input> {}

impl<'input> PrestoFunctionArgumentIntegerContextExt<'input>{
	fn new(ctx: &dyn PrestoShowFunctionTypeContextAttrs<'input>) -> Rc<PrestoShowFunctionTypeContextAll<'input>>  {
		Rc::new(
			PrestoShowFunctionTypeContextAll::PrestoFunctionArgumentIntegerContext(
				BaseParserRuleContext::copy_from(ctx,PrestoFunctionArgumentIntegerContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrestoFunctionArgumentStructContext<'input> = BaseParserRuleContext<'input,PrestoFunctionArgumentStructContextExt<'input>>;

pub trait PrestoFunctionArgumentStructContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn prestoShowFunctionRowField_all(&self) ->  Vec<Rc<PrestoShowFunctionRowFieldContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn prestoShowFunctionRowField(&self, i: usize) -> Option<Rc<PrestoShowFunctionRowFieldContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> PrestoFunctionArgumentStructContextAttrs<'input> for PrestoFunctionArgumentStructContext<'input>{}

pub struct PrestoFunctionArgumentStructContextExt<'input>{
	base:PrestoShowFunctionTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrestoFunctionArgumentStructContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PrestoFunctionArgumentStructContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoFunctionArgumentStructContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_prestoFunctionArgumentStruct(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_prestoFunctionArgumentStruct(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoFunctionArgumentStructContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_prestoFunctionArgumentStruct(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrestoFunctionArgumentStructContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionType }
}

impl<'input> Borrow<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentStructContext<'input>{
	fn borrow(&self) -> &PrestoShowFunctionTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentStructContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrestoShowFunctionTypeContextExt<'input> { &mut self.base }
}

impl<'input> PrestoShowFunctionTypeContextAttrs<'input> for PrestoFunctionArgumentStructContext<'input> {}

impl<'input> PrestoFunctionArgumentStructContextExt<'input>{
	fn new(ctx: &dyn PrestoShowFunctionTypeContextAttrs<'input>) -> Rc<PrestoShowFunctionTypeContextAll<'input>>  {
		Rc::new(
			PrestoShowFunctionTypeContextAll::PrestoFunctionArgumentStructContext(
				BaseParserRuleContext::copy_from(ctx,PrestoFunctionArgumentStructContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrestoFunctionArgumentDefaultContext<'input> = BaseParserRuleContext<'input,PrestoFunctionArgumentDefaultContextExt<'input>>;

pub trait PrestoFunctionArgumentDefaultContextAttrs<'input>: DatabricksParserContext<'input>{
	fn type_(&self) -> Option<Rc<Type_ContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PrestoFunctionArgumentDefaultContextAttrs<'input> for PrestoFunctionArgumentDefaultContext<'input>{}

pub struct PrestoFunctionArgumentDefaultContextExt<'input>{
	base:PrestoShowFunctionTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrestoFunctionArgumentDefaultContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PrestoFunctionArgumentDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoFunctionArgumentDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_prestoFunctionArgumentDefault(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_prestoFunctionArgumentDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoFunctionArgumentDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_prestoFunctionArgumentDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrestoFunctionArgumentDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionType }
}

impl<'input> Borrow<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentDefaultContext<'input>{
	fn borrow(&self) -> &PrestoShowFunctionTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrestoShowFunctionTypeContextExt<'input> { &mut self.base }
}

impl<'input> PrestoShowFunctionTypeContextAttrs<'input> for PrestoFunctionArgumentDefaultContext<'input> {}

impl<'input> PrestoFunctionArgumentDefaultContextExt<'input>{
	fn new(ctx: &dyn PrestoShowFunctionTypeContextAttrs<'input>) -> Rc<PrestoShowFunctionTypeContextAll<'input>>  {
		Rc::new(
			PrestoShowFunctionTypeContextAll::PrestoFunctionArgumentDefaultContext(
				BaseParserRuleContext::copy_from(ctx,PrestoFunctionArgumentDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrestoFunctionArgumentMapContext<'input> = BaseParserRuleContext<'input,PrestoFunctionArgumentMapContextExt<'input>>;

pub trait PrestoFunctionArgumentMapContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MAP
	/// Returns `None` if there is no child corresponding to token MAP
	fn MAP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(MAP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
	fn prestoShowFunctionType_all(&self) ->  Vec<Rc<PrestoShowFunctionTypeContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn prestoShowFunctionType(&self, i: usize) -> Option<Rc<PrestoShowFunctionTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> PrestoFunctionArgumentMapContextAttrs<'input> for PrestoFunctionArgumentMapContext<'input>{}

pub struct PrestoFunctionArgumentMapContextExt<'input>{
	base:PrestoShowFunctionTypeContextExt<'input>,
	pub key: Option<Rc<PrestoShowFunctionTypeContextAll<'input>>>,
	pub value: Option<Rc<PrestoShowFunctionTypeContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrestoFunctionArgumentMapContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PrestoFunctionArgumentMapContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoFunctionArgumentMapContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_prestoFunctionArgumentMap(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_prestoFunctionArgumentMap(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoFunctionArgumentMapContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_prestoFunctionArgumentMap(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrestoFunctionArgumentMapContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionType }
}

impl<'input> Borrow<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentMapContext<'input>{
	fn borrow(&self) -> &PrestoShowFunctionTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentMapContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrestoShowFunctionTypeContextExt<'input> { &mut self.base }
}

impl<'input> PrestoShowFunctionTypeContextAttrs<'input> for PrestoFunctionArgumentMapContext<'input> {}

impl<'input> PrestoFunctionArgumentMapContextExt<'input>{
	fn new(ctx: &dyn PrestoShowFunctionTypeContextAttrs<'input>) -> Rc<PrestoShowFunctionTypeContextAll<'input>>  {
		Rc::new(
			PrestoShowFunctionTypeContextAll::PrestoFunctionArgumentMapContext(
				BaseParserRuleContext::copy_from(ctx,PrestoFunctionArgumentMapContextExt{
        			key:None, value:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrestoFunctionArgumentArrayContext<'input> = BaseParserRuleContext<'input,PrestoFunctionArgumentArrayContextExt<'input>>;

pub trait PrestoFunctionArgumentArrayContextAttrs<'input>: DatabricksParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LPAREN
	/// Returns `None` if there is no child corresponding to token LPAREN
	fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(LPAREN, 0)
	}
	fn prestoShowFunctionType(&self) -> Option<Rc<PrestoShowFunctionTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RPAREN
	/// Returns `None` if there is no child corresponding to token RPAREN
	fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
		self.get_token(RPAREN, 0)
	}
}

impl<'input> PrestoFunctionArgumentArrayContextAttrs<'input> for PrestoFunctionArgumentArrayContext<'input>{}

pub struct PrestoFunctionArgumentArrayContextExt<'input>{
	base:PrestoShowFunctionTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrestoFunctionArgumentArrayContextExt<'a>}

impl<'input> DatabricksParserContext<'input> for PrestoFunctionArgumentArrayContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoFunctionArgumentArrayContext<'input>{
	fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_prestoFunctionArgumentArray(self);
	}
	fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
		listener.exit_prestoFunctionArgumentArray(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoFunctionArgumentArrayContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_prestoFunctionArgumentArray(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrestoFunctionArgumentArrayContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionType }
}

impl<'input> Borrow<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentArrayContext<'input>{
	fn borrow(&self) -> &PrestoShowFunctionTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrestoShowFunctionTypeContextExt<'input>> for PrestoFunctionArgumentArrayContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrestoShowFunctionTypeContextExt<'input> { &mut self.base }
}

impl<'input> PrestoShowFunctionTypeContextAttrs<'input> for PrestoFunctionArgumentArrayContext<'input> {}

impl<'input> PrestoFunctionArgumentArrayContextExt<'input>{
	fn new(ctx: &dyn PrestoShowFunctionTypeContextAttrs<'input>) -> Rc<PrestoShowFunctionTypeContextAll<'input>>  {
		Rc::new(
			PrestoShowFunctionTypeContextAll::PrestoFunctionArgumentArrayContext(
				BaseParserRuleContext::copy_from(ctx,PrestoFunctionArgumentArrayContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn prestoShowFunctionType(&mut self,)
	-> Result<Rc<PrestoShowFunctionTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrestoShowFunctionTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 426, RULE_prestoShowFunctionType);
        let mut _localctx: Rc<PrestoShowFunctionTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3888);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(519,&mut recog.base)? {
				1 =>{
					let tmp = PrestoFunctionArgumentStructContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3850);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					recog.base.set_state(3851);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule prestoShowFunctionRowField*/
					recog.base.set_state(3852);
					recog.prestoShowFunctionRowField()?;

					recog.base.set_state(3857);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3853);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule prestoShowFunctionRowField*/
						recog.base.set_state(3854);
						recog.prestoShowFunctionRowField()?;

						}
						}
						recog.base.set_state(3859);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(3860);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = PrestoFunctionArgumentMapContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3862);
					recog.base.match_token(MAP,&mut recog.err_handler)?;

					recog.base.set_state(3863);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule prestoShowFunctionType*/
					recog.base.set_state(3864);
					let tmp = recog.prestoShowFunctionType()?;
					if let PrestoShowFunctionTypeContextAll::PrestoFunctionArgumentMapContext(ctx) = cast_mut::<_,PrestoShowFunctionTypeContextAll >(&mut _localctx){
					ctx.key = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3865);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule prestoShowFunctionType*/
					recog.base.set_state(3866);
					let tmp = recog.prestoShowFunctionType()?;
					if let PrestoShowFunctionTypeContextAll::PrestoFunctionArgumentMapContext(ctx) = cast_mut::<_,PrestoShowFunctionTypeContextAll >(&mut _localctx){
					ctx.value = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3867);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = PrestoFunctionArgumentArrayContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3869);
					recog.base.match_token(ARRAY,&mut recog.err_handler)?;

					recog.base.set_state(3870);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule prestoShowFunctionType*/
					recog.base.set_state(3871);
					recog.prestoShowFunctionType()?;

					recog.base.set_state(3872);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = PrestoFunctionArgumentLambdaContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3874);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(3875);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule prestoShowFunctionType*/
					recog.base.set_state(3876);
					recog.prestoShowFunctionType()?;

					recog.base.set_state(3881);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3877);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule prestoShowFunctionType*/
						recog.base.set_state(3878);
						recog.prestoShowFunctionType()?;

						}
						}
						recog.base.set_state(3883);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(3884);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = PrestoFunctionArgumentIntegerContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(3886);
					recog.base.match_token(INTEGER,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					let tmp = PrestoFunctionArgumentDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					/*InvokeRule type_*/
					recog.base.set_state(3887);
					recog.type_()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- prestoShowFunctionRowField ----------------
pub type PrestoShowFunctionRowFieldContextAll<'input> = PrestoShowFunctionRowFieldContext<'input>;


pub type PrestoShowFunctionRowFieldContext<'input> = BaseParserRuleContext<'input,PrestoShowFunctionRowFieldContextExt<'input>>;

#[derive(Clone)]
pub struct PrestoShowFunctionRowFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PrestoShowFunctionRowFieldContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoShowFunctionRowFieldContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_prestoShowFunctionRowField(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_prestoShowFunctionRowField(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoShowFunctionRowFieldContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_prestoShowFunctionRowField(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrestoShowFunctionRowFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionRowField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionRowField }
}
antlr_rust::tid!{PrestoShowFunctionRowFieldContextExt<'a>}

impl<'input> PrestoShowFunctionRowFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrestoShowFunctionRowFieldContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrestoShowFunctionRowFieldContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrestoShowFunctionRowFieldContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PrestoShowFunctionRowFieldContextExt<'input>>{

fn prestoShowFunctionType(&self) -> Option<Rc<PrestoShowFunctionTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrestoShowFunctionRowFieldContextAttrs<'input> for PrestoShowFunctionRowFieldContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn prestoShowFunctionRowField(&mut self,)
	-> Result<Rc<PrestoShowFunctionRowFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrestoShowFunctionRowFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 428, RULE_prestoShowFunctionRowField);
        let mut _localctx: Rc<PrestoShowFunctionRowFieldContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3894);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(520,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule prestoShowFunctionType*/
					recog.base.set_state(3890);
					recog.prestoShowFunctionType()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3891);
					recog.identifier()?;

					/*InvokeRule prestoShowFunctionType*/
					recog.base.set_state(3892);
					recog.prestoShowFunctionType()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- prestoShowFunctionTypes ----------------
pub type PrestoShowFunctionTypesContextAll<'input> = PrestoShowFunctionTypesContext<'input>;


pub type PrestoShowFunctionTypesContext<'input> = BaseParserRuleContext<'input,PrestoShowFunctionTypesContextExt<'input>>;

#[derive(Clone)]
pub struct PrestoShowFunctionTypesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for PrestoShowFunctionTypesContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for PrestoShowFunctionTypesContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_prestoShowFunctionTypes(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_prestoShowFunctionTypes(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for PrestoShowFunctionTypesContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_prestoShowFunctionTypes(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrestoShowFunctionTypesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prestoShowFunctionTypes }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prestoShowFunctionTypes }
}
antlr_rust::tid!{PrestoShowFunctionTypesContextExt<'a>}

impl<'input> PrestoShowFunctionTypesContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrestoShowFunctionTypesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrestoShowFunctionTypesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrestoShowFunctionTypesContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<PrestoShowFunctionTypesContextExt<'input>>{

fn prestoShowFunctionType_all(&self) ->  Vec<Rc<PrestoShowFunctionTypeContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn prestoShowFunctionType(&self, i: usize) -> Option<Rc<PrestoShowFunctionTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,DatabricksParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> PrestoShowFunctionTypesContextAttrs<'input> for PrestoShowFunctionTypesContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn prestoShowFunctionTypes(&mut self,)
	-> Result<Rc<PrestoShowFunctionTypesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrestoShowFunctionTypesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 430, RULE_prestoShowFunctionTypes);
        let mut _localctx: Rc<PrestoShowFunctionTypesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3905);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ADD | AFTER | ALL | ALTER | ALWAYS | ANALYZE | AND | ANTI | ANY | ANY_VALUE |
			 ARCHIVE | ARRAY | ARRAYS_ZIP | AS | ASC | AT | AUTHORIZATION | BEGIN |
			 BETWEEN | BIGINT | BINARY | X_KW | BINDING | BOOLEAN | BOTH | BUCKET |
			 BUCKETS | BY | BYTE | CACHE | CALLED | CASCADE | CASE | CAST | CATALOG |
			 CATALOGS | CHANGE | CHAR | CHARACTER | CHECK | CLEAR | CLUSTER | CLUSTERED |
			 CODEGEN | COLLATE | COLLATION | COLLECTION | COLUMN | COLUMNS | COMMENT |
			 COMMIT | COMPACT | COMPACTIONS | COMPENSATION | COMPUTE | CONCATENATE |
			 CONSTRAINT | CONTAINS | COST | COUNT | CREATE | CROSS | CUBE | CURRENT |
			 CURRENT_DATE | CURRENT_TIME | CURRENT_TIMESTAMP | CURRENT_USER | DAY |
			 DAYS | DAYOFYEAR | DATA | DATE | DATABASE | DATABASES | DATEADD | DATE_ADD |
			 DATEDIFF | DATE_DIFF | DBPROPERTIES | DEC | DECIMAL | DECLARE | DECODE |
			 DEFAULT | DEFINED | DEFINER | DELETE | DELIMITED | DESC | DESCRIBE |
			 DETERMINISTIC | DFS | DIRECTORIES | DIRECTORY | DISTINCT | DISTRIBUTE |
			 DIV | DO | DOUBLE | DROP | ELSE | END | ESCAPE | ESCAPED | EVOLUTION |
			 EXCEPT | EXCHANGE | EXCLUDE | EXECUTE | EXISTS | EXPLAIN | EXPORT | EXTENDED |
			 EXTERNAL | EXTRACT | FALSE | FETCH | FIELDS | FILTER | FILEFORMAT | FIRST |
			 FLOAT | FOLLOWING | FOR | FOREIGN | FORMAT | FORMATTED | FROM | FROM_JSON |
			 FULL | FUNCTION | FUNCTIONS | GENERATED | GLOBAL | GRANT | GROUP | GROUPING |
			 HAVING | HOUR | HOURS | IDENTIFIER_KW | IDENTITY | IF | IGNORE | IMMEDIATE |
			 IMPORT | IN | INCLUDE | INDEX | INDEXES | INNER | INPATH | INPUT | INPUTFORMAT |
			 INSERT | INTERSECT | INTERVAL | INT | INTEGER | INTO | INVOKER | IS |
			 ITEMS | ILIKE | JOIN | KEY | KEYS | LANGUAGE | LAST | LATERAL | LAZY |
			 LEADING | LEFT | LIKE | LIMIT | LINES | LIST | LISTAGG | LIVE | LOAD |
			 LOCAL | LOCATION | LOCK | LOCKS | LOGICAL | LONG | MACRO | MAP | MAP_FROM_ENTRIES |
			 MATCHED | MATERIALIZED | MERGE | MICROSECOND | MICROSECONDS | MILLISECOND |
			 MILLISECONDS | MINUS_KW | MINUTE | MINUTES | MODE | MODIFIES | MONTH |
			 MONTHS | MSCK | NAME | NAMESPACE | NAMESPACES | NAMED_STRUCT | NANOSECOND |
			 NANOSECONDS | NATURAL | NO | NONE | NOT | NULL | NULLS | NUMERIC | OF |
			 OFFSET | ON | ONLY | OPTIMIZE | OPTION | OPTIONS | OR | ORDER | OUT |
			 OUTER | OUTPUTFORMAT | OVER | OVERLAPS | OVERLAY | OVERWRITE | PARTITION |
			 PARTITIONED | PARTITIONS | PERCENT_KW | PERCENTILE_CONT | PERCENTILE_DISC |
			 PIVOT | PLACING | POSITION | PRECEDING | PRIMARY | PRINCIPALS | PROPERTIES |
			 PRUNE | PURGE | QUALIFY | QUARTER | QUERY | RANGE | READS | REAL | RECORDREADER |
			 RECORDWRITER | RECOVER | RECURSIVE | REDUCE | REGEXP | REFERENCE | REFERENCES |
			 REFRESH | RENAME | REPAIR | REPEATABLE | REPLACE | RESET | RESPECT |
			 RESTRICT | RETURN | RETURNS | REVOKE | RIGHT | RLIKE | ROLE | ROLES |
			 ROLLBACK | ROLLUP | ROW | ROWS | SECOND | SECONDS | SCHEMA | SCHEMAS |
			 SECURITY | SELECT | SEMI | SEPARATED | SERDE | SERDEPROPERTIES | SESSION_USER |
			 SET | SETS | SHORT | SHOW | SINGLE | SKEWED | SMALLINT | SOME | SORT |
			 SORTED | SOURCE | SPECIFIC | SQL | START | STATISTICS | STORED | STRATIFY |
			 STREAM | STREAMING | STRUCT | SUBSTR | SUBSTRING | SYNC | SYSTEM_TIME |
			 SYSTEM_VERSION | TABLE | TABLES | TABLESAMPLE | TARGET | TBLPROPERTIES |
			 TEMP | TEMPORARY | TERMINATED | STRING_KW | THEN | TIME | TIMEDIFF |
			 TIMESTAMP | TIMESTAMPADD | TIMESTAMPDIFF | TIMESTAMP_LTZ | TIMESTAMP_NTZ |
			 TINYINT | TO | TOUCH | TRAILING | TRANSACTION | TRANSACTIONS | TRANSFORM |
			 TRIM | TRUE | TRUNCATE | TRY_CAST | TYPE | UNARCHIVE | UNBOUNDED | UNCACHE |
			 UNION | UNIQUE | UNKNOWN | UNLOCK | UNPIVOT | UNSET | UPDATE | USE |
			 USER | USING | VALUES | VAR | VARCHAR | VARIANT | VERSION | VIEW | VIEWS |
			 VOID | WEEK | WEEKS | WHEN | WHERE | WHILE | WINDOW | WITH | WITHIN |
			 YEAR | YEARS | ZONE | DOLLAR | IDENTIFIER | BACKQUOTED_IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule prestoShowFunctionType*/
					recog.base.set_state(3896);
					recog.prestoShowFunctionType()?;

					recog.base.set_state(3901);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3897);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule prestoShowFunctionType*/
						recog.base.set_state(3898);
						recog.prestoShowFunctionType()?;

						}
						}
						recog.base.set_state(3903);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

			 EOF 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3904);
					recog.base.match_token(EOF,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- strictNonReserved ----------------
pub type StrictNonReservedContextAll<'input> = StrictNonReservedContext<'input>;


pub type StrictNonReservedContext<'input> = BaseParserRuleContext<'input,StrictNonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct StrictNonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for StrictNonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for StrictNonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_strictNonReserved(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_strictNonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for StrictNonReservedContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_strictNonReserved(self);
	}
}

impl<'input> CustomRuleContext<'input> for StrictNonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictNonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictNonReserved }
}
antlr_rust::tid!{StrictNonReservedContextExt<'a>}

impl<'input> StrictNonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StrictNonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StrictNonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StrictNonReservedContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<StrictNonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ANTI
/// Returns `None` if there is no child corresponding to token ANTI
fn ANTI(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ANTI, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSS
/// Returns `None` if there is no child corresponding to token CROSS
fn CROSS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CROSS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}
/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
/// Retrieves first TerminalNode corresponding to token JOIN
/// Returns `None` if there is no child corresponding to token JOIN
fn JOIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(JOIN, 0)
}
/// Retrieves first TerminalNode corresponding to token LATERAL
/// Returns `None` if there is no child corresponding to token LATERAL
fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LATERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS_KW
/// Returns `None` if there is no child corresponding to token MINUS_KW
fn MINUS_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MINUS_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token NATURAL
/// Returns `None` if there is no child corresponding to token NATURAL
fn NATURAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NATURAL, 0)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token SEMI
/// Returns `None` if there is no child corresponding to token SEMI
fn SEMI(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}

}

impl<'input> StrictNonReservedContextAttrs<'input> for StrictNonReservedContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn strictNonReserved(&mut self,)
	-> Result<Rc<StrictNonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StrictNonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 432, RULE_strictNonReserved);
        let mut _localctx: Rc<StrictNonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3907);
			_la = recog.base.input.la(1);
			if { !(_la==ANTI || _la==CROSS || _la==EXCEPT || _la==FULL || ((((_la - 157)) & !0x3f) == 0 && ((1usize << (_la - 157)) & ((1usize << (INNER - 157)) | (1usize << (INTERSECT - 157)) | (1usize << (JOIN - 157)) | (1usize << (LATERAL - 157)) | (1usize << (LEFT - 157)))) != 0) || ((((_la - 203)) & !0x3f) == 0 && ((1usize << (_la - 203)) & ((1usize << (MINUS_KW - 203)) | (1usize << (NATURAL - 203)) | (1usize << (ON - 203)))) != 0) || _la==RIGHT || _la==SEMI || _la==UNION || _la==USING) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonReserved ----------------
pub type NonReservedContextAll<'input> = NonReservedContext<'input>;


pub type NonReservedContext<'input> = BaseParserRuleContext<'input,NonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct NonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> DatabricksParserContext<'input> for NonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn DatabricksListener<'input> + 'a> for NonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonReserved(self);
		}
		fn exit(&self,listener: &mut (dyn DatabricksListener<'input> + 'a)) {
			listener.exit_nonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn DatabricksVisitor<'input> + 'a> for NonReservedContext<'input>{
	fn accept(&self,visitor: &mut (dyn DatabricksVisitor<'input> + 'a)) {
		visitor.visit_nonReserved(self);
	}
}

impl<'input> CustomRuleContext<'input> for NonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = DatabricksParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonReserved }
}
antlr_rust::tid!{NonReservedContextExt<'a>}

impl<'input> NonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn DatabricksParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NonReservedContextAttrs<'input>: DatabricksParserContext<'input> + BorrowMut<NonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ADD
/// Returns `None` if there is no child corresponding to token ADD
fn ADD(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token AFTER
/// Returns `None` if there is no child corresponding to token AFTER
fn AFTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AFTER, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token ALTER
/// Returns `None` if there is no child corresponding to token ALTER
fn ALTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token ALWAYS
/// Returns `None` if there is no child corresponding to token ALWAYS
fn ALWAYS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ALWAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token ANALYZE
/// Returns `None` if there is no child corresponding to token ANALYZE
fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ANALYZE, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY_VALUE
/// Returns `None` if there is no child corresponding to token ANY_VALUE
fn ANY_VALUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ANY_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token ARCHIVE
/// Returns `None` if there is no child corresponding to token ARCHIVE
fn ARCHIVE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAY
/// Returns `None` if there is no child corresponding to token ARRAY
fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAYS_ZIP
/// Returns `None` if there is no child corresponding to token ARRAYS_ZIP
fn ARRAYS_ZIP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ARRAYS_ZIP, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token AT
/// Returns `None` if there is no child corresponding to token AT
fn AT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AT, 0)
}
/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
/// Returns `None` if there is no child corresponding to token AUTHORIZATION
fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(AUTHORIZATION, 0)
}
/// Retrieves first TerminalNode corresponding to token BEGIN
/// Returns `None` if there is no child corresponding to token BEGIN
fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BEGIN, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token BIGINT
/// Returns `None` if there is no child corresponding to token BIGINT
fn BIGINT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BIGINT, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY
/// Returns `None` if there is no child corresponding to token BINARY
fn BINARY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token BINDING
/// Returns `None` if there is no child corresponding to token BINDING
fn BINDING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BINDING, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOLEAN
/// Returns `None` if there is no child corresponding to token BOOLEAN
fn BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token BOTH
/// Returns `None` if there is no child corresponding to token BOTH
fn BOTH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BOTH, 0)
}
/// Retrieves first TerminalNode corresponding to token BUCKET
/// Returns `None` if there is no child corresponding to token BUCKET
fn BUCKET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BUCKET, 0)
}
/// Retrieves first TerminalNode corresponding to token BUCKETS
/// Returns `None` if there is no child corresponding to token BUCKETS
fn BUCKETS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BUCKETS, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token BYTE
/// Returns `None` if there is no child corresponding to token BYTE
fn BYTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(BYTE, 0)
}
/// Retrieves first TerminalNode corresponding to token CACHE
/// Returns `None` if there is no child corresponding to token CACHE
fn CACHE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token CALLED
/// Returns `None` if there is no child corresponding to token CALLED
fn CALLED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CALLED, 0)
}
/// Retrieves first TerminalNode corresponding to token CASCADE
/// Returns `None` if there is no child corresponding to token CASCADE
fn CASCADE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CASCADE, 0)
}
/// Retrieves first TerminalNode corresponding to token CASE
/// Returns `None` if there is no child corresponding to token CASE
fn CASE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CASE, 0)
}
/// Retrieves first TerminalNode corresponding to token CAST
/// Returns `None` if there is no child corresponding to token CAST
fn CAST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token CATALOG
/// Returns `None` if there is no child corresponding to token CATALOG
fn CATALOG(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CATALOG, 0)
}
/// Retrieves first TerminalNode corresponding to token CATALOGS
/// Returns `None` if there is no child corresponding to token CATALOGS
fn CATALOGS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CATALOGS, 0)
}
/// Retrieves first TerminalNode corresponding to token CHANGE
/// Returns `None` if there is no child corresponding to token CHANGE
fn CHANGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CHANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token CHAR
/// Returns `None` if there is no child corresponding to token CHAR
fn CHAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token CHARACTER
/// Returns `None` if there is no child corresponding to token CHARACTER
fn CHARACTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CHARACTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CHECK
/// Returns `None` if there is no child corresponding to token CHECK
fn CHECK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CHECK, 0)
}
/// Retrieves first TerminalNode corresponding to token CLEAR
/// Returns `None` if there is no child corresponding to token CLEAR
fn CLEAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CLEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTERED
/// Returns `None` if there is no child corresponding to token CLUSTERED
fn CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CLUSTERED, 0)
}
/// Retrieves first TerminalNode corresponding to token CODEGEN
/// Returns `None` if there is no child corresponding to token CODEGEN
fn CODEGEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CODEGEN, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLATE
/// Returns `None` if there is no child corresponding to token COLLATE
fn COLLATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COLLATE, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLATION
/// Returns `None` if there is no child corresponding to token COLLATION
fn COLLATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COLLATION, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLECTION
/// Returns `None` if there is no child corresponding to token COLLECTION
fn COLLECTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COLLECTION, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMN
/// Returns `None` if there is no child corresponding to token COLUMN
fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMNS
/// Returns `None` if there is no child corresponding to token COLUMNS
fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMIT
/// Returns `None` if there is no child corresponding to token COMMIT
fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPACT
/// Returns `None` if there is no child corresponding to token COMPACT
fn COMPACT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMPACT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPACTIONS
/// Returns `None` if there is no child corresponding to token COMPACTIONS
fn COMPACTIONS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMPACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPENSATION
/// Returns `None` if there is no child corresponding to token COMPENSATION
fn COMPENSATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMPENSATION, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPUTE
/// Returns `None` if there is no child corresponding to token COMPUTE
fn COMPUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COMPUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token CONCATENATE
/// Returns `None` if there is no child corresponding to token CONCATENATE
fn CONCATENATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CONCATENATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CONSTRAINT
/// Returns `None` if there is no child corresponding to token CONSTRAINT
fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTAINS
/// Returns `None` if there is no child corresponding to token CONTAINS
fn CONTAINS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CONTAINS, 0)
}
/// Retrieves first TerminalNode corresponding to token COST
/// Returns `None` if there is no child corresponding to token COST
fn COST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COST, 0)
}
/// Retrieves first TerminalNode corresponding to token COUNT
/// Returns `None` if there is no child corresponding to token COUNT
fn COUNT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(COUNT, 0)
}
/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CUBE
/// Returns `None` if there is no child corresponding to token CUBE
fn CUBE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CUBE, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT
/// Returns `None` if there is no child corresponding to token CURRENT
fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_DATE
/// Returns `None` if there is no child corresponding to token CURRENT_DATE
fn CURRENT_DATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_TIME
/// Returns `None` if there is no child corresponding to token CURRENT_TIME
fn CURRENT_TIME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_TIMESTAMP
/// Returns `None` if there is no child corresponding to token CURRENT_TIMESTAMP
fn CURRENT_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_USER
/// Returns `None` if there is no child corresponding to token CURRENT_USER
fn CURRENT_USER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_USER, 0)
}
/// Retrieves first TerminalNode corresponding to token DATA
/// Returns `None` if there is no child corresponding to token DATA
fn DATA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASES
/// Returns `None` if there is no child corresponding to token DATABASES
fn DATABASES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATABASES, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATEADD
/// Returns `None` if there is no child corresponding to token DATEADD
fn DATEADD(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATEADD, 0)
}
/// Retrieves first TerminalNode corresponding to token DATEDIFF
/// Returns `None` if there is no child corresponding to token DATEDIFF
fn DATEDIFF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATEDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE_ADD
/// Returns `None` if there is no child corresponding to token DATE_ADD
fn DATE_ADD(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATE_ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE_DIFF
/// Returns `None` if there is no child corresponding to token DATE_DIFF
fn DATE_DIFF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DATE_DIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYOFYEAR
/// Returns `None` if there is no child corresponding to token DAYOFYEAR
fn DAYOFYEAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DAYOFYEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYS
/// Returns `None` if there is no child corresponding to token DAYS
fn DAYS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token DBPROPERTIES
/// Returns `None` if there is no child corresponding to token DBPROPERTIES
fn DBPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DBPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token DEC
/// Returns `None` if there is no child corresponding to token DEC
fn DEC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DEC, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL
/// Returns `None` if there is no child corresponding to token DECIMAL
fn DECIMAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token DECODE
/// Returns `None` if there is no child corresponding to token DECODE
fn DECODE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DECODE, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINED
/// Returns `None` if there is no child corresponding to token DEFINED
fn DEFINED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DEFINED, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINER
/// Returns `None` if there is no child corresponding to token DEFINER
fn DEFINER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DEFINER, 0)
}
/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITED
/// Returns `None` if there is no child corresponding to token DELIMITED
fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DELIMITED, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESCRIBE
/// Returns `None` if there is no child corresponding to token DESCRIBE
fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DESCRIBE, 0)
}
/// Retrieves first TerminalNode corresponding to token DETERMINISTIC
/// Returns `None` if there is no child corresponding to token DETERMINISTIC
fn DETERMINISTIC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DETERMINISTIC, 0)
}
/// Retrieves first TerminalNode corresponding to token DFS
/// Returns `None` if there is no child corresponding to token DFS
fn DFS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DFS, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORIES
/// Returns `None` if there is no child corresponding to token DIRECTORIES
fn DIRECTORIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORIES, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORY
/// Returns `None` if there is no child corresponding to token DIRECTORY
fn DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORY, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTRIBUTE
/// Returns `None` if there is no child corresponding to token DISTRIBUTE
fn DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DISTRIBUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token DIV
/// Returns `None` if there is no child corresponding to token DIV
fn DIV(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DIV, 0)
}
/// Retrieves first TerminalNode corresponding to token DO
/// Returns `None` if there is no child corresponding to token DO
fn DO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DO, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DROP
/// Returns `None` if there is no child corresponding to token DROP
fn DROP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token ELSE
/// Returns `None` if there is no child corresponding to token ELSE
fn ELSE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ELSE, 0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
/// Retrieves first TerminalNode corresponding to token ESCAPE
/// Returns `None` if there is no child corresponding to token ESCAPE
fn ESCAPE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ESCAPE, 0)
}
/// Retrieves first TerminalNode corresponding to token ESCAPED
/// Returns `None` if there is no child corresponding to token ESCAPED
fn ESCAPED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ESCAPED, 0)
}
/// Retrieves first TerminalNode corresponding to token EVOLUTION
/// Returns `None` if there is no child corresponding to token EVOLUTION
fn EVOLUTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EVOLUTION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCHANGE
/// Returns `None` if there is no child corresponding to token EXCHANGE
fn EXCHANGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXCHANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXECUTE
/// Returns `None` if there is no child corresponding to token EXECUTE
fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXECUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXISTS
/// Returns `None` if there is no child corresponding to token EXISTS
fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXISTS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPLAIN
/// Returns `None` if there is no child corresponding to token EXPLAIN
fn EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXPLAIN, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPORT
/// Returns `None` if there is no child corresponding to token EXPORT
fn EXPORT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTENDED
/// Returns `None` if there is no child corresponding to token EXTENDED
fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXTENDED, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTERNAL
/// Returns `None` if there is no child corresponding to token EXTERNAL
fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXTERNAL, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTRACT
/// Returns `None` if there is no child corresponding to token EXTRACT
fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(EXTRACT, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}
/// Retrieves first TerminalNode corresponding to token FETCH
/// Returns `None` if there is no child corresponding to token FETCH
fn FETCH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FETCH, 0)
}
/// Retrieves first TerminalNode corresponding to token FIELDS
/// Returns `None` if there is no child corresponding to token FIELDS
fn FIELDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FIELDS, 0)
}
/// Retrieves first TerminalNode corresponding to token FILEFORMAT
/// Returns `None` if there is no child corresponding to token FILEFORMAT
fn FILEFORMAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FILEFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOAT
/// Returns `None` if there is no child corresponding to token FLOAT
fn FLOAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FOLLOWING
/// Returns `None` if there is no child corresponding to token FOLLOWING
fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FOLLOWING, 0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token FOREIGN
/// Returns `None` if there is no child corresponding to token FOREIGN
fn FOREIGN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FOREIGN, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMAT
/// Returns `None` if there is no child corresponding to token FORMAT
fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMATTED
/// Returns `None` if there is no child corresponding to token FORMATTED
fn FORMATTED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FORMATTED, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM_JSON
/// Returns `None` if there is no child corresponding to token FROM_JSON
fn FROM_JSON(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FROM_JSON, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTION
/// Returns `None` if there is no child corresponding to token FUNCTION
fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FUNCTION, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTIONS
/// Returns `None` if there is no child corresponding to token FUNCTIONS
fn FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(FUNCTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token GENERATED
/// Returns `None` if there is no child corresponding to token GENERATED
fn GENERATED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GENERATED, 0)
}
/// Retrieves first TerminalNode corresponding to token GLOBAL
/// Returns `None` if there is no child corresponding to token GLOBAL
fn GLOBAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GLOBAL, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANT
/// Returns `None` if there is no child corresponding to token GRANT
fn GRANT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GRANT, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUP
/// Returns `None` if there is no child corresponding to token GROUP
fn GROUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}
/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token HOURS
/// Returns `None` if there is no child corresponding to token HOURS
fn HOURS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(HOURS, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTITY
/// Returns `None` if there is no child corresponding to token IDENTITY
fn IDENTITY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IDENTITY, 0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
/// Retrieves first TerminalNode corresponding to token IGNORE
/// Returns `None` if there is no child corresponding to token IGNORE
fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token ILIKE
/// Returns `None` if there is no child corresponding to token ILIKE
fn ILIKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ILIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMMEDIATE
/// Returns `None` if there is no child corresponding to token IMMEDIATE
fn IMMEDIATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IMMEDIATE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMPORT
/// Returns `None` if there is no child corresponding to token IMPORT
fn IMPORT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IMPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token INDEX
/// Returns `None` if there is no child corresponding to token INDEX
fn INDEX(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INDEX, 0)
}
/// Retrieves first TerminalNode corresponding to token INDEXES
/// Returns `None` if there is no child corresponding to token INDEXES
fn INDEXES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INDEXES, 0)
}
/// Retrieves first TerminalNode corresponding to token INPATH
/// Returns `None` if there is no child corresponding to token INPATH
fn INPATH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INPATH, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUT
/// Returns `None` if there is no child corresponding to token INPUT
fn INPUT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUTFORMAT
/// Returns `None` if there is no child corresponding to token INPUTFORMAT
fn INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token INT
/// Returns `None` if there is no child corresponding to token INT
fn INT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER
/// Returns `None` if there is no child corresponding to token INTEGER
fn INTEGER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTEGER, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token INTO
/// Returns `None` if there is no child corresponding to token INTO
fn INTO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token INVOKER
/// Returns `None` if there is no child corresponding to token INVOKER
fn INVOKER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(INVOKER, 0)
}
/// Retrieves first TerminalNode corresponding to token IS
/// Returns `None` if there is no child corresponding to token IS
fn IS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(IS, 0)
}
/// Retrieves first TerminalNode corresponding to token ITEMS
/// Returns `None` if there is no child corresponding to token ITEMS
fn ITEMS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ITEMS, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEYS
/// Returns `None` if there is no child corresponding to token KEYS
fn KEYS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(KEYS, 0)
}
/// Retrieves first TerminalNode corresponding to token LANGUAGE
/// Returns `None` if there is no child corresponding to token LANGUAGE
fn LANGUAGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LANGUAGE, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}
/// Retrieves first TerminalNode corresponding to token LAZY
/// Returns `None` if there is no child corresponding to token LAZY
fn LAZY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LAZY, 0)
}
/// Retrieves first TerminalNode corresponding to token LEADING
/// Returns `None` if there is no child corresponding to token LEADING
fn LEADING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LEADING, 0)
}
/// Retrieves first TerminalNode corresponding to token LIKE
/// Returns `None` if there is no child corresponding to token LIKE
fn LIKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token LINES
/// Returns `None` if there is no child corresponding to token LINES
fn LINES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LINES, 0)
}
/// Retrieves first TerminalNode corresponding to token LIST
/// Returns `None` if there is no child corresponding to token LIST
fn LIST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LIST, 0)
}
/// Retrieves first TerminalNode corresponding to token LISTAGG
/// Returns `None` if there is no child corresponding to token LISTAGG
fn LISTAGG(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LISTAGG, 0)
}
/// Retrieves first TerminalNode corresponding to token LIVE
/// Returns `None` if there is no child corresponding to token LIVE
fn LIVE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token LOAD
/// Returns `None` if there is no child corresponding to token LOAD
fn LOAD(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCAL
/// Returns `None` if there is no child corresponding to token LOCAL
fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LOCAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCK
/// Returns `None` if there is no child corresponding to token LOCK
fn LOCK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCKS
/// Returns `None` if there is no child corresponding to token LOCKS
fn LOCKS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LOCKS, 0)
}
/// Retrieves first TerminalNode corresponding to token LOGICAL
/// Returns `None` if there is no child corresponding to token LOGICAL
fn LOGICAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LOGICAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LONG
/// Returns `None` if there is no child corresponding to token LONG
fn LONG(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(LONG, 0)
}
/// Retrieves first TerminalNode corresponding to token MACRO
/// Returns `None` if there is no child corresponding to token MACRO
fn MACRO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MACRO, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP_FROM_ENTRIES
/// Returns `None` if there is no child corresponding to token MAP_FROM_ENTRIES
fn MAP_FROM_ENTRIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MAP_FROM_ENTRIES, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token MATERIALIZED
/// Returns `None` if there is no child corresponding to token MATERIALIZED
fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token MERGE
/// Returns `None` if there is no child corresponding to token MERGE
fn MERGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MERGE, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECONDS
/// Returns `None` if there is no child corresponding to token MICROSECONDS
fn MICROSECONDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MICROSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECONDS
/// Returns `None` if there is no child corresponding to token MILLISECONDS
fn MILLISECONDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MILLISECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTES
/// Returns `None` if there is no child corresponding to token MINUTES
fn MINUTES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MINUTES, 0)
}
/// Retrieves first TerminalNode corresponding to token MODE
/// Returns `None` if there is no child corresponding to token MODE
fn MODE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MODE, 0)
}
/// Retrieves first TerminalNode corresponding to token MODIFIES
/// Returns `None` if there is no child corresponding to token MODIFIES
fn MODIFIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MODIFIES, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTHS
/// Returns `None` if there is no child corresponding to token MONTHS
fn MONTHS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MONTHS, 0)
}
/// Retrieves first TerminalNode corresponding to token MSCK
/// Returns `None` if there is no child corresponding to token MSCK
fn MSCK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(MSCK, 0)
}
/// Retrieves first TerminalNode corresponding to token NAME
/// Returns `None` if there is no child corresponding to token NAME
fn NAME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NAME, 0)
}
/// Retrieves first TerminalNode corresponding to token NAMESPACE
/// Returns `None` if there is no child corresponding to token NAMESPACE
fn NAMESPACE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NAMESPACE, 0)
}
/// Retrieves first TerminalNode corresponding to token NAMESPACES
/// Returns `None` if there is no child corresponding to token NAMESPACES
fn NAMESPACES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NAMESPACES, 0)
}
/// Retrieves first TerminalNode corresponding to token NAMED_STRUCT
/// Returns `None` if there is no child corresponding to token NAMED_STRUCT
fn NAMED_STRUCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NAMED_STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECOND
/// Returns `None` if there is no child corresponding to token NANOSECOND
fn NANOSECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NANOSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECONDS
/// Returns `None` if there is no child corresponding to token NANOSECONDS
fn NANOSECONDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NANOSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token NO
/// Returns `None` if there is no child corresponding to token NO
fn NO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NO, 0)
}
/// Retrieves first TerminalNode corresponding to token NONE
/// Returns `None` if there is no child corresponding to token NONE
fn NONE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NONE, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token NUMERIC
/// Returns `None` if there is no child corresponding to token NUMERIC
fn NUMERIC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(NUMERIC, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
/// Retrieves first TerminalNode corresponding to token ONLY
/// Returns `None` if there is no child corresponding to token ONLY
fn ONLY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ONLY, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTIMIZE
/// Returns `None` if there is no child corresponding to token OPTIMIZE
fn OPTIMIZE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OPTIMIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTION
/// Returns `None` if there is no child corresponding to token OPTION
fn OPTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONS
/// Returns `None` if there is no child corresponding to token OPTIONS
fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token OR
/// Returns `None` if there is no child corresponding to token OR
fn OR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OR, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token OUT
/// Returns `None` if there is no child corresponding to token OUT
fn OUT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OUT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token OUTPUTFORMAT
fn OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OUTPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token OVER
/// Returns `None` if there is no child corresponding to token OVER
fn OVER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERLAPS
/// Returns `None` if there is no child corresponding to token OVERLAPS
fn OVERLAPS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OVERLAPS, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERLAY
/// Returns `None` if there is no child corresponding to token OVERLAY
fn OVERLAY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OVERLAY, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERWRITE
/// Returns `None` if there is no child corresponding to token OVERWRITE
fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(OVERWRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONED
/// Returns `None` if there is no child corresponding to token PARTITIONED
fn PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONS
/// Returns `None` if there is no child corresponding to token PARTITIONS
fn PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENTILE_CONT
/// Returns `None` if there is no child corresponding to token PERCENTILE_CONT
fn PERCENTILE_CONT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PERCENTILE_CONT, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENTILE_DISC
/// Returns `None` if there is no child corresponding to token PERCENTILE_DISC
fn PERCENTILE_DISC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PERCENTILE_DISC, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENT_KW
/// Returns `None` if there is no child corresponding to token PERCENT_KW
fn PERCENT_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PERCENT_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token PIVOT
/// Returns `None` if there is no child corresponding to token PIVOT
fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token PLACING
/// Returns `None` if there is no child corresponding to token PLACING
fn PLACING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PLACING, 0)
}
/// Retrieves first TerminalNode corresponding to token POSITION
/// Returns `None` if there is no child corresponding to token POSITION
fn POSITION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(POSITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PRECEDING
/// Returns `None` if there is no child corresponding to token PRECEDING
fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PRECEDING, 0)
}
/// Retrieves first TerminalNode corresponding to token PRIMARY
/// Returns `None` if there is no child corresponding to token PRIMARY
fn PRIMARY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PRIMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token PRINCIPALS
/// Returns `None` if there is no child corresponding to token PRINCIPALS
fn PRINCIPALS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PRINCIPALS, 0)
}
/// Retrieves first TerminalNode corresponding to token PROPERTIES
/// Returns `None` if there is no child corresponding to token PROPERTIES
fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token PRUNE
/// Returns `None` if there is no child corresponding to token PRUNE
fn PRUNE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PRUNE, 0)
}
/// Retrieves first TerminalNode corresponding to token PURGE
/// Returns `None` if there is no child corresponding to token PURGE
fn PURGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(PURGE, 0)
}
/// Retrieves first TerminalNode corresponding to token QUALIFY
/// Returns `None` if there is no child corresponding to token QUALIFY
fn QUALIFY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(QUALIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token QUARTER
/// Returns `None` if there is no child corresponding to token QUARTER
fn QUARTER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token QUERY
/// Returns `None` if there is no child corresponding to token QUERY
fn QUERY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(QUERY, 0)
}
/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token READS
/// Returns `None` if there is no child corresponding to token READS
fn READS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(READS, 0)
}
/// Retrieves first TerminalNode corresponding to token REAL
/// Returns `None` if there is no child corresponding to token REAL
fn REAL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDREADER
/// Returns `None` if there is no child corresponding to token RECORDREADER
fn RECORDREADER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RECORDREADER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDWRITER
/// Returns `None` if there is no child corresponding to token RECORDWRITER
fn RECORDWRITER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RECORDWRITER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECOVER
/// Returns `None` if there is no child corresponding to token RECOVER
fn RECOVER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RECOVER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECURSIVE
/// Returns `None` if there is no child corresponding to token RECURSIVE
fn RECURSIVE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RECURSIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token REDUCE
/// Returns `None` if there is no child corresponding to token REDUCE
fn REDUCE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REDUCE, 0)
}
/// Retrieves first TerminalNode corresponding to token REFERENCE
/// Returns `None` if there is no child corresponding to token REFERENCE
fn REFERENCE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REFERENCE, 0)
}
/// Retrieves first TerminalNode corresponding to token REFERENCES
/// Returns `None` if there is no child corresponding to token REFERENCES
fn REFERENCES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REFERENCES, 0)
}
/// Retrieves first TerminalNode corresponding to token REFRESH
/// Returns `None` if there is no child corresponding to token REFRESH
fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REFRESH, 0)
}
/// Retrieves first TerminalNode corresponding to token REGEXP
/// Returns `None` if there is no child corresponding to token REGEXP
fn REGEXP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REGEXP, 0)
}
/// Retrieves first TerminalNode corresponding to token RENAME
/// Returns `None` if there is no child corresponding to token RENAME
fn RENAME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token REPAIR
/// Returns `None` if there is no child corresponding to token REPAIR
fn REPAIR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REPAIR, 0)
}
/// Retrieves first TerminalNode corresponding to token REPEATABLE
/// Returns `None` if there is no child corresponding to token REPEATABLE
fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REPEATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token RESET
/// Returns `None` if there is no child corresponding to token RESET
fn RESET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RESET, 0)
}
/// Retrieves first TerminalNode corresponding to token RESPECT
/// Returns `None` if there is no child corresponding to token RESPECT
fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RESPECT, 0)
}
/// Retrieves first TerminalNode corresponding to token RESTRICT
/// Returns `None` if there is no child corresponding to token RESTRICT
fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURN
/// Returns `None` if there is no child corresponding to token RETURN
fn RETURN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RETURN, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURNS
/// Returns `None` if there is no child corresponding to token RETURNS
fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RETURNS, 0)
}
/// Retrieves first TerminalNode corresponding to token REVOKE
/// Returns `None` if there is no child corresponding to token REVOKE
fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(REVOKE, 0)
}
/// Retrieves first TerminalNode corresponding to token RLIKE
/// Returns `None` if there is no child corresponding to token RLIKE
fn RLIKE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(RLIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLE
/// Returns `None` if there is no child corresponding to token ROLE
fn ROLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLES
/// Returns `None` if there is no child corresponding to token ROLES
fn ROLES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ROLES, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLBACK
/// Returns `None` if there is no child corresponding to token ROLLBACK
fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ROLLBACK, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLUP
/// Returns `None` if there is no child corresponding to token ROLLUP
fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token ROW
/// Returns `None` if there is no child corresponding to token ROW
fn ROW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMA
/// Returns `None` if there is no child corresponding to token SCHEMA
fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SCHEMA, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMAS
/// Returns `None` if there is no child corresponding to token SCHEMAS
fn SCHEMAS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SCHEMAS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token SECONDS
/// Returns `None` if there is no child corresponding to token SECONDS
fn SECONDS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECURITY
/// Returns `None` if there is no child corresponding to token SECURITY
fn SECURITY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SECURITY, 0)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves first TerminalNode corresponding to token SEPARATED
/// Returns `None` if there is no child corresponding to token SEPARATED
fn SEPARATED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SEPARATED, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDE
/// Returns `None` if there is no child corresponding to token SERDE
fn SERDE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SERDE, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SERDEPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token SESSION_USER
/// Returns `None` if there is no child corresponding to token SESSION_USER
fn SESSION_USER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SESSION_USER, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token SETS
/// Returns `None` if there is no child corresponding to token SETS
fn SETS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SETS, 0)
}
/// Retrieves first TerminalNode corresponding to token SHORT
/// Returns `None` if there is no child corresponding to token SHORT
fn SHORT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SHORT, 0)
}
/// Retrieves first TerminalNode corresponding to token SHOW
/// Returns `None` if there is no child corresponding to token SHOW
fn SHOW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token SINGLE
/// Returns `None` if there is no child corresponding to token SINGLE
fn SINGLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SINGLE, 0)
}
/// Retrieves first TerminalNode corresponding to token SKEWED
/// Returns `None` if there is no child corresponding to token SKEWED
fn SKEWED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token SMALLINT
/// Returns `None` if there is no child corresponding to token SMALLINT
fn SMALLINT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SMALLINT, 0)
}
/// Retrieves first TerminalNode corresponding to token SOME
/// Returns `None` if there is no child corresponding to token SOME
fn SOME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token SORT
/// Returns `None` if there is no child corresponding to token SORT
fn SORT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SORT, 0)
}
/// Retrieves first TerminalNode corresponding to token SORTED
/// Returns `None` if there is no child corresponding to token SORTED
fn SORTED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SORTED, 0)
}
/// Retrieves first TerminalNode corresponding to token SOURCE
/// Returns `None` if there is no child corresponding to token SOURCE
fn SOURCE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token SPECIFIC
/// Returns `None` if there is no child corresponding to token SPECIFIC
fn SPECIFIC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SPECIFIC, 0)
}
/// Retrieves first TerminalNode corresponding to token SQL
/// Returns `None` if there is no child corresponding to token SQL
fn SQL(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SQL, 0)
}
/// Retrieves first TerminalNode corresponding to token START
/// Returns `None` if there is no child corresponding to token START
fn START(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(START, 0)
}
/// Retrieves first TerminalNode corresponding to token STATISTICS
/// Returns `None` if there is no child corresponding to token STATISTICS
fn STATISTICS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STATISTICS, 0)
}
/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token STRATIFY
/// Returns `None` if there is no child corresponding to token STRATIFY
fn STRATIFY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STRATIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token STREAM
/// Returns `None` if there is no child corresponding to token STREAM
fn STREAM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STREAM, 0)
}
/// Retrieves first TerminalNode corresponding to token STREAMING
/// Returns `None` if there is no child corresponding to token STREAMING
fn STREAMING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STREAMING, 0)
}
/// Retrieves first TerminalNode corresponding to token STRING_KW
/// Returns `None` if there is no child corresponding to token STRING_KW
fn STRING_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STRING_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token STRUCT
/// Returns `None` if there is no child corresponding to token STRUCT
fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSTR
/// Returns `None` if there is no child corresponding to token SUBSTR
fn SUBSTR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SUBSTR, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSTRING
/// Returns `None` if there is no child corresponding to token SUBSTRING
fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SUBSTRING, 0)
}
/// Retrieves first TerminalNode corresponding to token SYNC
/// Returns `None` if there is no child corresponding to token SYNC
fn SYNC(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SYNC, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_VERSION
/// Returns `None` if there is no child corresponding to token SYSTEM_VERSION
fn SYSTEM_VERSION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLES
/// Returns `None` if there is no child corresponding to token TABLES
fn TABLES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TABLES, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TARGET
/// Returns `None` if there is no child corresponding to token TARGET
fn TARGET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TARGET, 0)
}
/// Retrieves first TerminalNode corresponding to token TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token TBLPROPERTIES
fn TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TBLPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMP
/// Returns `None` if there is no child corresponding to token TEMP
fn TEMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TEMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMPORARY
/// Returns `None` if there is no child corresponding to token TEMPORARY
fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token TERMINATED
/// Returns `None` if there is no child corresponding to token TERMINATED
fn TERMINATED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMEDIFF
/// Returns `None` if there is no child corresponding to token TIMEDIFF
fn TIMEDIFF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMEDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMPADD
/// Returns `None` if there is no child corresponding to token TIMESTAMPADD
fn TIMESTAMPADD(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMPADD, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMPDIFF
/// Returns `None` if there is no child corresponding to token TIMESTAMPDIFF
fn TIMESTAMPDIFF(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMPDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_LTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_LTZ
fn TIMESTAMP_LTZ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_LTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_NTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_NTZ
fn TIMESTAMP_NTZ(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_NTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TINYINT
/// Returns `None` if there is no child corresponding to token TINYINT
fn TINYINT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TINYINT, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token TOUCH
/// Returns `None` if there is no child corresponding to token TOUCH
fn TOUCH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TOUCH, 0)
}
/// Retrieves first TerminalNode corresponding to token TRAILING
/// Returns `None` if there is no child corresponding to token TRAILING
fn TRAILING(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRAILING, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTION
/// Returns `None` if there is no child corresponding to token TRANSACTION
fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTIONS
/// Returns `None` if there is no child corresponding to token TRANSACTIONS
fn TRANSACTIONS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSFORM
/// Returns `None` if there is no child corresponding to token TRANSFORM
fn TRANSFORM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRANSFORM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRIM
/// Returns `None` if there is no child corresponding to token TRIM
fn TRIM(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRIM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUNCATE
/// Returns `None` if there is no child corresponding to token TRUNCATE
fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRUNCATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRY_CAST
/// Returns `None` if there is no child corresponding to token TRY_CAST
fn TRY_CAST(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TRY_CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNARCHIVE
/// Returns `None` if there is no child corresponding to token UNARCHIVE
fn UNARCHIVE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNBOUNDED
/// Returns `None` if there is no child corresponding to token UNBOUNDED
fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNBOUNDED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNCACHE
/// Returns `None` if there is no child corresponding to token UNCACHE
fn UNCACHE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNCACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNIQUE
/// Returns `None` if there is no child corresponding to token UNIQUE
fn UNIQUE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNIQUE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNKNOWN
/// Returns `None` if there is no child corresponding to token UNKNOWN
fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNKNOWN, 0)
}
/// Retrieves first TerminalNode corresponding to token UNLOCK
/// Returns `None` if there is no child corresponding to token UNLOCK
fn UNLOCK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNLOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token UNPIVOT
/// Returns `None` if there is no child corresponding to token UNPIVOT
fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNPIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token UNSET
/// Returns `None` if there is no child corresponding to token UNSET
fn UNSET(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UNSET, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token USE
/// Returns `None` if there is no child corresponding to token USE
fn USE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(USE, 0)
}
/// Retrieves first TerminalNode corresponding to token USER
/// Returns `None` if there is no child corresponding to token USER
fn USER(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(USER, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
/// Retrieves first TerminalNode corresponding to token VAR
/// Returns `None` if there is no child corresponding to token VAR
fn VAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VAR, 0)
}
/// Retrieves first TerminalNode corresponding to token VARCHAR
/// Returns `None` if there is no child corresponding to token VARCHAR
fn VARCHAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VARCHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIANT
/// Returns `None` if there is no child corresponding to token VARIANT
fn VARIANT(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VARIANT, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEWS
/// Returns `None` if there is no child corresponding to token VIEWS
fn VIEWS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VIEWS, 0)
}
/// Retrieves first TerminalNode corresponding to token VOID
/// Returns `None` if there is no child corresponding to token VOID
fn VOID(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(VOID, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEKS
/// Returns `None` if there is no child corresponding to token WEEKS
fn WEEKS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WEEKS, 0)
}
/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
/// Retrieves first TerminalNode corresponding to token WHILE
/// Returns `None` if there is no child corresponding to token WHILE
fn WHILE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WHILE, 0)
}
/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHIN
/// Returns `None` if there is no child corresponding to token WITHIN
fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(WITHIN, 0)
}
/// Retrieves first TerminalNode corresponding to token X_KW
/// Returns `None` if there is no child corresponding to token X_KW
fn X_KW(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(X_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token YEARS
/// Returns `None` if there is no child corresponding to token YEARS
fn YEARS(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(YEARS, 0)
}
/// Retrieves first TerminalNode corresponding to token ZONE
/// Returns `None` if there is no child corresponding to token ZONE
fn ZONE(&self) -> Option<Rc<TerminalNode<'input,DatabricksParserContextType>>> where Self:Sized{
	self.get_token(ZONE, 0)
}

}

impl<'input> NonReservedContextAttrs<'input> for NonReservedContext<'input>{}

impl<'input, I, H> DatabricksParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonReserved(&mut self,)
	-> Result<Rc<NonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 434, RULE_nonReserved);
        let mut _localctx: Rc<NonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3909);
			_la = recog.base.input.la(1);
			if { !(((((_la - 5)) & !0x3f) == 0 && ((1usize << (_la - 5)) & ((1usize << (ADD - 5)) | (1usize << (AFTER - 5)) | (1usize << (ALL - 5)) | (1usize << (ALTER - 5)) | (1usize << (ALWAYS - 5)) | (1usize << (ANALYZE - 5)) | (1usize << (AND - 5)) | (1usize << (ANY - 5)) | (1usize << (ANY_VALUE - 5)) | (1usize << (ARCHIVE - 5)) | (1usize << (ARRAY - 5)) | (1usize << (ARRAYS_ZIP - 5)) | (1usize << (AS - 5)) | (1usize << (ASC - 5)) | (1usize << (AT - 5)) | (1usize << (AUTHORIZATION - 5)) | (1usize << (BEGIN - 5)) | (1usize << (BETWEEN - 5)) | (1usize << (BIGINT - 5)) | (1usize << (BINARY - 5)) | (1usize << (X_KW - 5)) | (1usize << (BINDING - 5)) | (1usize << (BOOLEAN - 5)) | (1usize << (BOTH - 5)) | (1usize << (BUCKET - 5)) | (1usize << (BUCKETS - 5)) | (1usize << (BY - 5)) | (1usize << (BYTE - 5)) | (1usize << (CACHE - 5)) | (1usize << (CALLED - 5)) | (1usize << (CASCADE - 5)))) != 0) || ((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CASE - 37)) | (1usize << (CAST - 37)) | (1usize << (CATALOG - 37)) | (1usize << (CATALOGS - 37)) | (1usize << (CHANGE - 37)) | (1usize << (CHAR - 37)) | (1usize << (CHARACTER - 37)) | (1usize << (CHECK - 37)) | (1usize << (CLEAR - 37)) | (1usize << (CLUSTER - 37)) | (1usize << (CLUSTERED - 37)) | (1usize << (CODEGEN - 37)) | (1usize << (COLLATE - 37)) | (1usize << (COLLATION - 37)) | (1usize << (COLLECTION - 37)) | (1usize << (COLUMN - 37)) | (1usize << (COLUMNS - 37)) | (1usize << (COMMENT - 37)) | (1usize << (COMMIT - 37)) | (1usize << (COMPACT - 37)) | (1usize << (COMPACTIONS - 37)) | (1usize << (COMPENSATION - 37)) | (1usize << (COMPUTE - 37)) | (1usize << (CONCATENATE - 37)) | (1usize << (CONSTRAINT - 37)) | (1usize << (CONTAINS - 37)) | (1usize << (COST - 37)) | (1usize << (COUNT - 37)) | (1usize << (CREATE - 37)) | (1usize << (CUBE - 37)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (CURRENT - 69)) | (1usize << (CURRENT_DATE - 69)) | (1usize << (CURRENT_TIME - 69)) | (1usize << (CURRENT_TIMESTAMP - 69)) | (1usize << (CURRENT_USER - 69)) | (1usize << (DAY - 69)) | (1usize << (DAYS - 69)) | (1usize << (DAYOFYEAR - 69)) | (1usize << (DATA - 69)) | (1usize << (DATE - 69)) | (1usize << (DATABASE - 69)) | (1usize << (DATABASES - 69)) | (1usize << (DATEADD - 69)) | (1usize << (DATE_ADD - 69)) | (1usize << (DATEDIFF - 69)) | (1usize << (DATE_DIFF - 69)) | (1usize << (DBPROPERTIES - 69)) | (1usize << (DEC - 69)) | (1usize << (DECIMAL - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DECODE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DEFINED - 69)) | (1usize << (DEFINER - 69)) | (1usize << (DELETE - 69)) | (1usize << (DELIMITED - 69)) | (1usize << (DESC - 69)) | (1usize << (DESCRIBE - 69)) | (1usize << (DETERMINISTIC - 69)) | (1usize << (DFS - 69)) | (1usize << (DIRECTORIES - 69)) | (1usize << (DIRECTORY - 69)))) != 0) || ((((_la - 101)) & !0x3f) == 0 && ((1usize << (_la - 101)) & ((1usize << (DISTINCT - 101)) | (1usize << (DISTRIBUTE - 101)) | (1usize << (DIV - 101)) | (1usize << (DO - 101)) | (1usize << (DOUBLE - 101)) | (1usize << (DROP - 101)) | (1usize << (ELSE - 101)) | (1usize << (END - 101)) | (1usize << (ESCAPE - 101)) | (1usize << (ESCAPED - 101)) | (1usize << (EVOLUTION - 101)) | (1usize << (EXCHANGE - 101)) | (1usize << (EXCLUDE - 101)) | (1usize << (EXECUTE - 101)) | (1usize << (EXISTS - 101)) | (1usize << (EXPLAIN - 101)) | (1usize << (EXPORT - 101)) | (1usize << (EXTENDED - 101)) | (1usize << (EXTERNAL - 101)) | (1usize << (EXTRACT - 101)) | (1usize << (FALSE - 101)) | (1usize << (FETCH - 101)) | (1usize << (FIELDS - 101)) | (1usize << (FILTER - 101)) | (1usize << (FILEFORMAT - 101)) | (1usize << (FIRST - 101)) | (1usize << (FLOAT - 101)) | (1usize << (FOLLOWING - 101)) | (1usize << (FOR - 101)) | (1usize << (FOREIGN - 101)) | (1usize << (FORMAT - 101)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (FORMATTED - 133)) | (1usize << (FROM - 133)) | (1usize << (FROM_JSON - 133)) | (1usize << (FUNCTION - 133)) | (1usize << (FUNCTIONS - 133)) | (1usize << (GENERATED - 133)) | (1usize << (GLOBAL - 133)) | (1usize << (GRANT - 133)) | (1usize << (GROUP - 133)) | (1usize << (GROUPING - 133)) | (1usize << (HAVING - 133)) | (1usize << (HOUR - 133)) | (1usize << (HOURS - 133)) | (1usize << (IDENTIFIER_KW - 133)) | (1usize << (IDENTITY - 133)) | (1usize << (IF - 133)) | (1usize << (IGNORE - 133)) | (1usize << (IMMEDIATE - 133)) | (1usize << (IMPORT - 133)) | (1usize << (IN - 133)) | (1usize << (INCLUDE - 133)) | (1usize << (INDEX - 133)) | (1usize << (INDEXES - 133)) | (1usize << (INPATH - 133)) | (1usize << (INPUT - 133)) | (1usize << (INPUTFORMAT - 133)) | (1usize << (INSERT - 133)) | (1usize << (INTERVAL - 133)) | (1usize << (INT - 133)))) != 0) || ((((_la - 165)) & !0x3f) == 0 && ((1usize << (_la - 165)) & ((1usize << (INTEGER - 165)) | (1usize << (INTO - 165)) | (1usize << (INVOKER - 165)) | (1usize << (IS - 165)) | (1usize << (ITEMS - 165)) | (1usize << (ILIKE - 165)) | (1usize << (KEY - 165)) | (1usize << (KEYS - 165)) | (1usize << (LANGUAGE - 165)) | (1usize << (LAST - 165)) | (1usize << (LAZY - 165)) | (1usize << (LEADING - 165)) | (1usize << (LIKE - 165)) | (1usize << (LIMIT - 165)) | (1usize << (LINES - 165)) | (1usize << (LIST - 165)) | (1usize << (LISTAGG - 165)) | (1usize << (LIVE - 165)) | (1usize << (LOAD - 165)) | (1usize << (LOCAL - 165)) | (1usize << (LOCATION - 165)) | (1usize << (LOCK - 165)) | (1usize << (LOCKS - 165)) | (1usize << (LOGICAL - 165)) | (1usize << (LONG - 165)) | (1usize << (MACRO - 165)) | (1usize << (MAP - 165)) | (1usize << (MAP_FROM_ENTRIES - 165)) | (1usize << (MATCHED - 165)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (MATERIALIZED - 197)) | (1usize << (MERGE - 197)) | (1usize << (MICROSECOND - 197)) | (1usize << (MICROSECONDS - 197)) | (1usize << (MILLISECOND - 197)) | (1usize << (MILLISECONDS - 197)) | (1usize << (MINUTE - 197)) | (1usize << (MINUTES - 197)) | (1usize << (MODE - 197)) | (1usize << (MODIFIES - 197)) | (1usize << (MONTH - 197)) | (1usize << (MONTHS - 197)) | (1usize << (MSCK - 197)) | (1usize << (NAME - 197)) | (1usize << (NAMESPACE - 197)) | (1usize << (NAMESPACES - 197)) | (1usize << (NAMED_STRUCT - 197)) | (1usize << (NANOSECOND - 197)) | (1usize << (NANOSECONDS - 197)) | (1usize << (NO - 197)) | (1usize << (NONE - 197)) | (1usize << (NOT - 197)) | (1usize << (NULL - 197)) | (1usize << (NULLS - 197)) | (1usize << (NUMERIC - 197)) | (1usize << (OF - 197)) | (1usize << (OFFSET - 197)) | (1usize << (ONLY - 197)) | (1usize << (OPTIMIZE - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (OPTION - 229)) | (1usize << (OPTIONS - 229)) | (1usize << (OR - 229)) | (1usize << (ORDER - 229)) | (1usize << (OUT - 229)) | (1usize << (OUTER - 229)) | (1usize << (OUTPUTFORMAT - 229)) | (1usize << (OVER - 229)) | (1usize << (OVERLAPS - 229)) | (1usize << (OVERLAY - 229)) | (1usize << (OVERWRITE - 229)) | (1usize << (PARTITION - 229)) | (1usize << (PARTITIONED - 229)) | (1usize << (PARTITIONS - 229)) | (1usize << (PERCENT_KW - 229)) | (1usize << (PERCENTILE_CONT - 229)) | (1usize << (PERCENTILE_DISC - 229)) | (1usize << (PIVOT - 229)) | (1usize << (PLACING - 229)) | (1usize << (POSITION - 229)) | (1usize << (PRECEDING - 229)) | (1usize << (PRIMARY - 229)) | (1usize << (PRINCIPALS - 229)) | (1usize << (PROPERTIES - 229)) | (1usize << (PRUNE - 229)) | (1usize << (PURGE - 229)) | (1usize << (QUALIFY - 229)) | (1usize << (QUARTER - 229)) | (1usize << (QUERY - 229)) | (1usize << (RANGE - 229)) | (1usize << (READS - 229)) | (1usize << (REAL - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (RECORDREADER - 261)) | (1usize << (RECORDWRITER - 261)) | (1usize << (RECOVER - 261)) | (1usize << (RECURSIVE - 261)) | (1usize << (REDUCE - 261)) | (1usize << (REGEXP - 261)) | (1usize << (REFERENCE - 261)) | (1usize << (REFERENCES - 261)) | (1usize << (REFRESH - 261)) | (1usize << (RENAME - 261)) | (1usize << (REPAIR - 261)) | (1usize << (REPEATABLE - 261)) | (1usize << (REPLACE - 261)) | (1usize << (RESET - 261)) | (1usize << (RESPECT - 261)) | (1usize << (RESTRICT - 261)) | (1usize << (RETURN - 261)) | (1usize << (RETURNS - 261)) | (1usize << (REVOKE - 261)) | (1usize << (RLIKE - 261)) | (1usize << (ROLE - 261)) | (1usize << (ROLES - 261)) | (1usize << (ROLLBACK - 261)) | (1usize << (ROLLUP - 261)) | (1usize << (ROW - 261)) | (1usize << (ROWS - 261)) | (1usize << (SECOND - 261)) | (1usize << (SECONDS - 261)) | (1usize << (SCHEMA - 261)) | (1usize << (SCHEMAS - 261)) | (1usize << (SECURITY - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (SELECT - 293)) | (1usize << (SEPARATED - 293)) | (1usize << (SERDE - 293)) | (1usize << (SERDEPROPERTIES - 293)) | (1usize << (SESSION_USER - 293)) | (1usize << (SET - 293)) | (1usize << (SETS - 293)) | (1usize << (SHORT - 293)) | (1usize << (SHOW - 293)) | (1usize << (SINGLE - 293)) | (1usize << (SKEWED - 293)) | (1usize << (SMALLINT - 293)) | (1usize << (SOME - 293)) | (1usize << (SORT - 293)) | (1usize << (SORTED - 293)) | (1usize << (SOURCE - 293)) | (1usize << (SPECIFIC - 293)) | (1usize << (SQL - 293)) | (1usize << (START - 293)) | (1usize << (STATISTICS - 293)) | (1usize << (STORED - 293)) | (1usize << (STRATIFY - 293)) | (1usize << (STREAM - 293)) | (1usize << (STREAMING - 293)) | (1usize << (STRUCT - 293)) | (1usize << (SUBSTR - 293)) | (1usize << (SUBSTRING - 293)) | (1usize << (SYNC - 293)) | (1usize << (SYSTEM_TIME - 293)) | (1usize << (SYSTEM_VERSION - 293)) | (1usize << (TABLE - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (TABLES - 325)) | (1usize << (TABLESAMPLE - 325)) | (1usize << (TARGET - 325)) | (1usize << (TBLPROPERTIES - 325)) | (1usize << (TEMP - 325)) | (1usize << (TEMPORARY - 325)) | (1usize << (TERMINATED - 325)) | (1usize << (STRING_KW - 325)) | (1usize << (THEN - 325)) | (1usize << (TIME - 325)) | (1usize << (TIMEDIFF - 325)) | (1usize << (TIMESTAMP - 325)) | (1usize << (TIMESTAMPADD - 325)) | (1usize << (TIMESTAMPDIFF - 325)) | (1usize << (TIMESTAMP_LTZ - 325)) | (1usize << (TIMESTAMP_NTZ - 325)) | (1usize << (TINYINT - 325)) | (1usize << (TO - 325)) | (1usize << (TOUCH - 325)) | (1usize << (TRAILING - 325)) | (1usize << (TRANSACTION - 325)) | (1usize << (TRANSACTIONS - 325)) | (1usize << (TRANSFORM - 325)) | (1usize << (TRIM - 325)) | (1usize << (TRUE - 325)) | (1usize << (TRUNCATE - 325)) | (1usize << (TRY_CAST - 325)) | (1usize << (TYPE - 325)) | (1usize << (UNARCHIVE - 325)) | (1usize << (UNBOUNDED - 325)) | (1usize << (UNCACHE - 325)))) != 0) || ((((_la - 357)) & !0x3f) == 0 && ((1usize << (_la - 357)) & ((1usize << (UNIQUE - 357)) | (1usize << (UNKNOWN - 357)) | (1usize << (UNLOCK - 357)) | (1usize << (UNPIVOT - 357)) | (1usize << (UNSET - 357)) | (1usize << (UPDATE - 357)) | (1usize << (USE - 357)) | (1usize << (USER - 357)) | (1usize << (VALUES - 357)) | (1usize << (VAR - 357)) | (1usize << (VARCHAR - 357)) | (1usize << (VARIANT - 357)) | (1usize << (VERSION - 357)) | (1usize << (VIEW - 357)) | (1usize << (VIEWS - 357)) | (1usize << (VOID - 357)) | (1usize << (WEEK - 357)) | (1usize << (WEEKS - 357)) | (1usize << (WHEN - 357)) | (1usize << (WHERE - 357)) | (1usize << (WHILE - 357)) | (1usize << (WINDOW - 357)) | (1usize << (WITH - 357)) | (1usize << (WITHIN - 357)) | (1usize << (YEAR - 357)) | (1usize << (YEARS - 357)) | (1usize << (ZONE - 357)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}

thread_local! {
    static _ATN: Rc<ATN> =
        Rc::new(ATNDeserializer::new(None).deserialize(_serializedATN.chars()));
    static _decision_to_DFA: Rc<Vec<RefCell<DFA>>> = {
        let mut dfa = Vec::new();
        let size = _ATN.with(|atn| atn.decision_to_state.len());
        for i in 0..size {
            dfa.push(DFA::new(_ATN.with(|atn| atn.clone()), _ATN.with(|atn| atn
            .get_decision_state(i)), i as isize).into())
        }
        Rc::new(dfa)
    };
}



const _serializedATN:&'static str =
	"\x03\u{608b}\u{a72a}\u{8133}\u{b9ed}\u{417c}\u{3be7}\u{7786}\u{5964}\x03\
	\u{1b6}\u{f4a}\x04\x02\x09\x02\x04\x03\x09\x03\x04\x04\x09\x04\x04\x05\x09\
	\x05\x04\x06\x09\x06\x04\x07\x09\x07\x04\x08\x09\x08\x04\x09\x09\x09\x04\
	\x0a\x09\x0a\x04\x0b\x09\x0b\x04\x0c\x09\x0c\x04\x0d\x09\x0d\x04\x0e\x09\
	\x0e\x04\x0f\x09\x0f\x04\x10\x09\x10\x04\x11\x09\x11\x04\x12\x09\x12\x04\
	\x13\x09\x13\x04\x14\x09\x14\x04\x15\x09\x15\x04\x16\x09\x16\x04\x17\x09\
	\x17\x04\x18\x09\x18\x04\x19\x09\x19\x04\x1a\x09\x1a\x04\x1b\x09\x1b\x04\
	\x1c\x09\x1c\x04\x1d\x09\x1d\x04\x1e\x09\x1e\x04\x1f\x09\x1f\x04\x20\x09\
	\x20\x04\x21\x09\x21\x04\x22\x09\x22\x04\x23\x09\x23\x04\x24\x09\x24\x04\
	\x25\x09\x25\x04\x26\x09\x26\x04\x27\x09\x27\x04\x28\x09\x28\x04\x29\x09\
	\x29\x04\x2a\x09\x2a\x04\x2b\x09\x2b\x04\x2c\x09\x2c\x04\x2d\x09\x2d\x04\
	\x2e\x09\x2e\x04\x2f\x09\x2f\x04\x30\x09\x30\x04\x31\x09\x31\x04\x32\x09\
	\x32\x04\x33\x09\x33\x04\x34\x09\x34\x04\x35\x09\x35\x04\x36\x09\x36\x04\
	\x37\x09\x37\x04\x38\x09\x38\x04\x39\x09\x39\x04\x3a\x09\x3a\x04\x3b\x09\
	\x3b\x04\x3c\x09\x3c\x04\x3d\x09\x3d\x04\x3e\x09\x3e\x04\x3f\x09\x3f\x04\
	\x40\x09\x40\x04\x41\x09\x41\x04\x42\x09\x42\x04\x43\x09\x43\x04\x44\x09\
	\x44\x04\x45\x09\x45\x04\x46\x09\x46\x04\x47\x09\x47\x04\x48\x09\x48\x04\
	\x49\x09\x49\x04\x4a\x09\x4a\x04\x4b\x09\x4b\x04\x4c\x09\x4c\x04\x4d\x09\
	\x4d\x04\x4e\x09\x4e\x04\x4f\x09\x4f\x04\x50\x09\x50\x04\x51\x09\x51\x04\
	\x52\x09\x52\x04\x53\x09\x53\x04\x54\x09\x54\x04\x55\x09\x55\x04\x56\x09\
	\x56\x04\x57\x09\x57\x04\x58\x09\x58\x04\x59\x09\x59\x04\x5a\x09\x5a\x04\
	\x5b\x09\x5b\x04\x5c\x09\x5c\x04\x5d\x09\x5d\x04\x5e\x09\x5e\x04\x5f\x09\
	\x5f\x04\x60\x09\x60\x04\x61\x09\x61\x04\x62\x09\x62\x04\x63\x09\x63\x04\
	\x64\x09\x64\x04\x65\x09\x65\x04\x66\x09\x66\x04\x67\x09\x67\x04\x68\x09\
	\x68\x04\x69\x09\x69\x04\x6a\x09\x6a\x04\x6b\x09\x6b\x04\x6c\x09\x6c\x04\
	\x6d\x09\x6d\x04\x6e\x09\x6e\x04\x6f\x09\x6f\x04\x70\x09\x70\x04\x71\x09\
	\x71\x04\x72\x09\x72\x04\x73\x09\x73\x04\x74\x09\x74\x04\x75\x09\x75\x04\
	\x76\x09\x76\x04\x77\x09\x77\x04\x78\x09\x78\x04\x79\x09\x79\x04\x7a\x09\
	\x7a\x04\x7b\x09\x7b\x04\x7c\x09\x7c\x04\x7d\x09\x7d\x04\x7e\x09\x7e\x04\
	\x7f\x09\x7f\x04\u{80}\x09\u{80}\x04\u{81}\x09\u{81}\x04\u{82}\x09\u{82}\
	\x04\u{83}\x09\u{83}\x04\u{84}\x09\u{84}\x04\u{85}\x09\u{85}\x04\u{86}\x09\
	\u{86}\x04\u{87}\x09\u{87}\x04\u{88}\x09\u{88}\x04\u{89}\x09\u{89}\x04\u{8a}\
	\x09\u{8a}\x04\u{8b}\x09\u{8b}\x04\u{8c}\x09\u{8c}\x04\u{8d}\x09\u{8d}\x04\
	\u{8e}\x09\u{8e}\x04\u{8f}\x09\u{8f}\x04\u{90}\x09\u{90}\x04\u{91}\x09\u{91}\
	\x04\u{92}\x09\u{92}\x04\u{93}\x09\u{93}\x04\u{94}\x09\u{94}\x04\u{95}\x09\
	\u{95}\x04\u{96}\x09\u{96}\x04\u{97}\x09\u{97}\x04\u{98}\x09\u{98}\x04\u{99}\
	\x09\u{99}\x04\u{9a}\x09\u{9a}\x04\u{9b}\x09\u{9b}\x04\u{9c}\x09\u{9c}\x04\
	\u{9d}\x09\u{9d}\x04\u{9e}\x09\u{9e}\x04\u{9f}\x09\u{9f}\x04\u{a0}\x09\u{a0}\
	\x04\u{a1}\x09\u{a1}\x04\u{a2}\x09\u{a2}\x04\u{a3}\x09\u{a3}\x04\u{a4}\x09\
	\u{a4}\x04\u{a5}\x09\u{a5}\x04\u{a6}\x09\u{a6}\x04\u{a7}\x09\u{a7}\x04\u{a8}\
	\x09\u{a8}\x04\u{a9}\x09\u{a9}\x04\u{aa}\x09\u{aa}\x04\u{ab}\x09\u{ab}\x04\
	\u{ac}\x09\u{ac}\x04\u{ad}\x09\u{ad}\x04\u{ae}\x09\u{ae}\x04\u{af}\x09\u{af}\
	\x04\u{b0}\x09\u{b0}\x04\u{b1}\x09\u{b1}\x04\u{b2}\x09\u{b2}\x04\u{b3}\x09\
	\u{b3}\x04\u{b4}\x09\u{b4}\x04\u{b5}\x09\u{b5}\x04\u{b6}\x09\u{b6}\x04\u{b7}\
	\x09\u{b7}\x04\u{b8}\x09\u{b8}\x04\u{b9}\x09\u{b9}\x04\u{ba}\x09\u{ba}\x04\
	\u{bb}\x09\u{bb}\x04\u{bc}\x09\u{bc}\x04\u{bd}\x09\u{bd}\x04\u{be}\x09\u{be}\
	\x04\u{bf}\x09\u{bf}\x04\u{c0}\x09\u{c0}\x04\u{c1}\x09\u{c1}\x04\u{c2}\x09\
	\u{c2}\x04\u{c3}\x09\u{c3}\x04\u{c4}\x09\u{c4}\x04\u{c5}\x09\u{c5}\x04\u{c6}\
	\x09\u{c6}\x04\u{c7}\x09\u{c7}\x04\u{c8}\x09\u{c8}\x04\u{c9}\x09\u{c9}\x04\
	\u{ca}\x09\u{ca}\x04\u{cb}\x09\u{cb}\x04\u{cc}\x09\u{cc}\x04\u{cd}\x09\u{cd}\
	\x04\u{ce}\x09\u{ce}\x04\u{cf}\x09\u{cf}\x04\u{d0}\x09\u{d0}\x04\u{d1}\x09\
	\u{d1}\x04\u{d2}\x09\u{d2}\x04\u{d3}\x09\u{d3}\x04\u{d4}\x09\u{d4}\x04\u{d5}\
	\x09\u{d5}\x04\u{d6}\x09\u{d6}\x04\u{d7}\x09\u{d7}\x04\u{d8}\x09\u{d8}\x04\
	\u{d9}\x09\u{d9}\x04\u{da}\x09\u{da}\x04\u{db}\x09\u{db}\x03\x02\x05\x02\
	\u{1b8}\x0a\x02\x03\x02\x03\x02\x05\x02\u{1bc}\x0a\x02\x07\x02\u{1be}\x0a\
	\x02\x0c\x02\x0e\x02\u{1c1}\x0b\x02\x03\x02\x03\x02\x03\x03\x05\x03\u{1c6}\
	\x0a\x03\x03\x03\x05\x03\u{1c9}\x0a\x03\x03\x03\x03\x03\x03\x04\x03\x04\
	\x03\x04\x03\x05\x03\x05\x03\x05\x03\x06\x03\x06\x03\x06\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x05\x07\u{1e2}\x0a\x07\x03\x07\x03\x07\x07\x07\u{1e6}\x0a\x07\x0c\
	\x07\x0e\x07\u{1e9}\x0b\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\
	\x07\u{202}\x0a\x07\x03\x07\x05\x07\u{205}\x0a\x07\x03\x07\x05\x07\u{208}\
	\x0a\x07\x03\x07\x05\x07\u{20b}\x0a\x07\x03\x07\x05\x07\u{20e}\x0a\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{214}\x0a\x07\x03\x07\x03\x07\x05\
	\x07\u{218}\x0a\x07\x03\x07\x03\x07\x05\x07\u{21c}\x0a\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x05\x07\u{222}\x0a\x07\x03\x07\x03\x07\x05\x07\u{226}\x0a\
	\x07\x03\x07\x05\x07\u{229}\x0a\x07\x03\x07\x03\x07\x05\x07\u{22d}\x0a\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{233}\x0a\x07\x03\x07\x05\x07\
	\u{236}\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{23c}\x0a\x07\x03\
	\x07\x03\x07\x05\x07\u{240}\x0a\x07\x03\x07\x03\x07\x05\x07\u{244}\x0a\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{24a}\x0a\x07\x03\x07\x03\x07\
	\x05\x07\u{24e}\x0a\x07\x03\x07\x05\x07\u{251}\x0a\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{25a}\x0a\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{265}\
	\x0a\x07\x0c\x07\x0e\x07\u{268}\x0b\x07\x03\x07\x05\x07\u{26b}\x0a\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{271}\x0a\x07\x03\x07\x05\x07\u{274}\
	\x0a\x07\x03\x07\x05\x07\u{277}\x0a\x07\x03\x07\x05\x07\u{27a}\x0a\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{280}\x0a\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x07\x07\u{287}\x0a\x07\x0c\x07\x0e\x07\u{28a}\x0b\x07\
	\x03\x07\x05\x07\u{28d}\x0a\x07\x03\x07\x03\x07\x05\x07\u{291}\x0a\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{29b}\
	\x0a\x07\x0c\x07\x0e\x07\u{29e}\x0b\x07\x03\x07\x03\x07\x05\x07\u{2a2}\x0a\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x05\x07\u{2ad}\x0a\x07\x03\x07\x05\x07\u{2b0}\x0a\x07\x03\x07\x03\x07\
	\x07\x07\u{2b4}\x0a\x07\x0c\x07\x0e\x07\u{2b7}\x0b\x07\x03\x07\x03\x07\x07\
	\x07\u{2bb}\x0a\x07\x0c\x07\x0e\x07\u{2be}\x0b\x07\x03\x07\x03\x07\x07\x07\
	\u{2c2}\x0a\x07\x0c\x07\x0e\x07\u{2c5}\x0b\x07\x03\x07\x03\x07\x03\x07\x05\
	\x07\u{2ca}\x0a\x07\x03\x07\x03\x07\x07\x07\u{2ce}\x0a\x07\x0c\x07\x0e\x07\
	\u{2d1}\x0b\x07\x03\x07\x03\x07\x07\x07\u{2d5}\x0a\x07\x0c\x07\x0e\x07\u{2d8}\
	\x0b\x07\x03\x07\x03\x07\x07\x07\u{2dc}\x0a\x07\x0c\x07\x0e\x07\u{2df}\x0b\
	\x07\x03\x07\x03\x07\x07\x07\u{2e3}\x0a\x07\x0c\x07\x0e\x07\u{2e6}\x0b\x07\
	\x03\x07\x03\x07\x07\x07\u{2ea}\x0a\x07\x0c\x07\x0e\x07\u{2ed}\x0b\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{2f3}\x0a\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{2fe}\x0a\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{306}\x0a\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{30e}\x0a\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{315}\x0a\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{31f}\
	\x0a\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{326}\x0a\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{32e}\x0a\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{350}\x0a\x07\x0c\x07\
	\x0e\x07\u{353}\x0b\x07\x05\x07\u{355}\x0a\x07\x03\x07\x05\x07\u{358}\x0a\
	\x07\x03\x07\x05\x07\u{35b}\x0a\x07\x03\x07\x03\x07\x05\x07\u{35f}\x0a\x07\
	\x03\x07\x03\x07\x07\x07\u{363}\x0a\x07\x0c\x07\x0e\x07\u{366}\x0b\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x07\x07\u{379}\
	\x0a\x07\x0c\x07\x0e\x07\u{37c}\x0b\x07\x03\x07\x03\x07\x07\x07\u{380}\x0a\
	\x07\x0c\x07\x0e\x07\u{383}\x0b\x07\x03\x07\x03\x07\x07\x07\u{387}\x0a\x07\
	\x0c\x07\x0e\x07\u{38a}\x0b\x07\x03\x07\x03\x07\x05\x07\u{38e}\x0a\x07\x03\
	\x07\x03\x07\x03\x07\x07\x07\u{393}\x0a\x07\x0c\x07\x0e\x07\u{396}\x0b\x07\
	\x03\x07\x03\x07\x07\x07\u{39a}\x0a\x07\x0c\x07\x0e\x07\u{39d}\x0b\x07\x03\
	\x07\x03\x07\x07\x07\u{3a1}\x0a\x07\x0c\x07\x0e\x07\u{3a4}\x0b\x07\x03\x07\
	\x03\x07\x07\x07\u{3a8}\x0a\x07\x0c\x07\x0e\x07\u{3ab}\x0b\x07\x03\x07\x03\
	\x07\x07\x07\u{3af}\x0a\x07\x0c\x07\x0e\x07\u{3b2}\x0b\x07\x03\x07\x03\x07\
	\x07\x07\u{3b6}\x0a\x07\x0c\x07\x0e\x07\u{3b9}\x0b\x07\x03\x07\x03\x07\x03\
	\x07\x07\x07\u{3be}\x0a\x07\x0c\x07\x0e\x07\u{3c1}\x0b\x07\x03\x07\x03\x07\
	\x03\x07\x07\x07\u{3c6}\x0a\x07\x0c\x07\x0e\x07\u{3c9}\x0b\x07\x03\x07\x03\
	\x07\x07\x07\u{3cd}\x0a\x07\x0c\x07\x0e\x07\u{3d0}\x0b\x07\x03\x07\x03\x07\
	\x07\x07\u{3d4}\x0a\x07\x0c\x07\x0e\x07\u{3d7}\x0b\x07\x03\x07\x03\x07\x07\
	\x07\u{3db}\x0a\x07\x0c\x07\x0e\x07\u{3de}\x0b\x07\x05\x07\u{3e0}\x0a\x07\
	\x03\x08\x03\x08\x03\x08\x07\x08\u{3e5}\x0a\x08\x0c\x08\x0e\x08\u{3e8}\x0b\
	\x08\x03\x09\x03\x09\x03\x09\x03\x09\x03\x09\x03\x09\x05\x09\u{3f0}\x0a\
	\x09\x03\x0a\x03\x0a\x03\x0a\x03\x0a\x07\x0a\u{3f6}\x0a\x0a\x0c\x0a\x0e\
	\x0a\u{3f9}\x0b\x0a\x03\x0a\x03\x0a\x03\x0b\x03\x0b\x05\x0b\u{3ff}\x0a\x0b\
	\x03\x0c\x03\x0c\x03\x0c\x03\x0c\x03\x0c\x03\x0c\x03\x0c\x05\x0c\u{408}\
	\x0a\x0c\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\
	\x07\x0d\u{412}\x0a\x0d\x0c\x0d\x0e\x0d\u{415}\x0b\x0d\x03\x0d\x03\x0d\x03\
	\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x07\
	\x0d\u{422}\x0a\x0d\x0c\x0d\x0e\x0d\u{425}\x0b\x0d\x03\x0e\x03\x0e\x03\x0e\
	\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x07\x0e\u{431}\
	\x0a\x0e\x0c\x0e\x0e\x0e\u{434}\x0b\x0e\x03\x0e\x03\x0e\x05\x0e\u{438}\x0a\
	\x0e\x03\x0f\x03\x0f\x05\x0f\u{43c}\x0a\x0f\x03\x10\x03\x10\x03\x10\x03\
	\x10\x03\x10\x03\x10\x07\x10\u{444}\x0a\x10\x0c\x10\x0e\x10\u{447}\x0b\x10\
	\x03\x10\x03\x10\x05\x10\u{44b}\x0a\x10\x03\x11\x03\x11\x05\x11\u{44f}\x0a\
	\x11\x03\x12\x03\x12\x03\x12\x03\x12\x05\x12\u{455}\x0a\x12\x03\x12\x05\
	\x12\u{458}\x0a\x12\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x05\
	\x13\u{460}\x0a\x13\x03\x13\x03\x13\x03\x13\x05\x13\u{465}\x0a\x13\x03\x14\
	\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x07\x14\u{46d}\x0a\x14\x0c\x14\
	\x0e\x14\u{470}\x0b\x14\x03\x14\x03\x14\x03\x15\x03\x15\x03\x15\x03\x15\
	\x03\x15\x03\x15\x03\x15\x03\x15\x07\x15\u{47c}\x0a\x15\x0c\x15\x0e\x15\
	\u{47f}\x0b\x15\x05\x15\u{481}\x0a\x15\x03\x15\x03\x15\x03\x15\x03\x15\x03\
	\x16\x03\x16\x03\x16\x03\x16\x07\x16\u{48b}\x0a\x16\x0c\x16\x0e\x16\u{48e}\
	\x0b\x16\x03\x16\x03\x16\x03\x17\x03\x17\x03\x17\x03\x17\x07\x17\u{496}\
	\x0a\x17\x0c\x17\x0e\x17\u{499}\x0b\x17\x03\x17\x03\x17\x03\x18\x03\x18\
	\x03\x18\x03\x18\x03\x18\x03\x18\x03\x18\x05\x18\u{4a4}\x0a\x18\x03\x18\
	\x03\x18\x03\x18\x03\x18\x03\x18\x03\x18\x03\x18\x03\x18\x03\x18\x03\x18\
	\x05\x18\u{4b0}\x0a\x18\x05\x18\u{4b2}\x0a\x18\x03\x18\x03\x18\x03\x18\x03\
	\x18\x03\x18\x05\x18\u{4b9}\x0a\x18\x03\x18\x03\x18\x03\x18\x03\x18\x03\
	\x18\x05\x18\u{4c0}\x0a\x18\x03\x18\x03\x18\x03\x18\x03\x18\x05\x18\u{4c6}\
	\x0a\x18\x03\x18\x03\x18\x03\x18\x03\x18\x05\x18\u{4cc}\x0a\x18\x05\x18\
	\u{4ce}\x0a\x18\x03\x19\x03\x19\x03\x19\x03\x19\x03\x19\x03\x19\x05\x19\
	\u{4d6}\x0a\x19\x03\x1a\x03\x1a\x03\x1a\x03\x1a\x03\x1a\x03\x1a\x05\x1a\
	\u{4de}\x0a\x1a\x03\x1b\x03\x1b\x03\x1b\x03\x1b\x05\x1b\u{4e4}\x0a\x1b\x03\
	\x1c\x03\x1c\x03\x1c\x03\x1d\x03\x1d\x03\x1d\x03\x1d\x03\x1d\x03\x1d\x03\
	\x1d\x05\x1d\u{4f0}\x0a\x1d\x03\x1e\x03\x1e\x03\x1e\x03\x1e\x03\x1e\x03\
	\x1e\x06\x1e\u{4f8}\x0a\x1e\x0d\x1e\x0e\x1e\u{4f9}\x03\x1e\x03\x1e\x03\x1e\
	\x03\x1e\x03\x1e\x05\x1e\u{501}\x0a\x1e\x03\x1e\x03\x1e\x03\x1e\x03\x1e\
	\x03\x1e\x05\x1e\u{508}\x0a\x1e\x03\x1e\x03\x1e\x03\x1e\x03\x1e\x05\x1e\
	\u{50e}\x0a\x1e\x03\x1e\x03\x1e\x03\x1e\x03\x1e\x03\x1e\x03\x1e\x03\x1e\
	\x03\x1e\x03\x1e\x05\x1e\u{519}\x0a\x1e\x03\x1e\x03\x1e\x03\x1e\x03\x1e\
	\x07\x1e\u{51f}\x0a\x1e\x0c\x1e\x0e\x1e\u{522}\x0b\x1e\x03\x1e\x07\x1e\u{525}\
	\x0a\x1e\x0c\x1e\x0e\x1e\u{528}\x0b\x1e\x03\x1e\x07\x1e\u{52b}\x0a\x1e\x0c\
	\x1e\x0e\x1e\u{52e}\x0b\x1e\x05\x1e\u{530}\x0a\x1e\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x07\x1f\u{536}\x0a\x1f\x0c\x1f\x0e\x1f\u{539}\x0b\x1f\x03\x20\x03\
	\x20\x03\x20\x05\x20\u{53e}\x0a\x20\x03\x20\x03\x20\x05\x20\u{542}\x0a\x20\
	\x03\x20\x03\x20\x03\x20\x03\x20\x05\x20\u{548}\x0a\x20\x05\x20\u{54a}\x0a\
	\x20\x03\x20\x03\x20\x03\x20\x05\x20\u{54f}\x0a\x20\x03\x20\x03\x20\x03\
	\x20\x05\x20\u{554}\x0a\x20\x03\x20\x03\x20\x05\x20\u{558}\x0a\x20\x03\x20\
	\x05\x20\u{55b}\x0a\x20\x03\x20\x03\x20\x03\x20\x05\x20\u{560}\x0a\x20\x03\
	\x20\x03\x20\x03\x20\x05\x20\u{565}\x0a\x20\x03\x20\x03\x20\x03\x20\x05\
	\x20\u{56a}\x0a\x20\x03\x20\x03\x20\x05\x20\u{56e}\x0a\x20\x03\x20\x03\x20\
	\x03\x20\x03\x20\x03\x20\x03\x20\x05\x20\u{576}\x0a\x20\x03\x20\x03\x20\
	\x03\x20\x05\x20\u{57b}\x0a\x20\x03\x20\x05\x20\u{57e}\x0a\x20\x03\x20\x03\
	\x20\x03\x20\x05\x20\u{583}\x0a\x20\x03\x20\x03\x20\x05\x20\u{587}\x0a\x20\
	\x03\x20\x03\x20\x03\x20\x05\x20\u{58c}\x0a\x20\x05\x20\u{58e}\x0a\x20\x03\
	\x21\x03\x21\x03\x21\x03\x22\x05\x22\u{594}\x0a\x22\x03\x22\x03\x22\x05\
	\x22\u{598}\x0a\x22\x05\x22\u{59a}\x0a\x22\x03\x23\x03\x23\x03\x23\x03\x24\
	\x03\x24\x03\x24\x03\x25\x03\x25\x03\x25\x03\x25\x05\x25\u{5a6}\x0a\x25\
	\x03\x25\x03\x25\x03\x25\x03\x26\x03\x26\x03\x26\x03\x26\x03\x26\x05\x26\
	\u{5b0}\x0a\x26\x03\x26\x03\x26\x05\x26\u{5b4}\x0a\x26\x03\x26\x03\x26\x03\
	\x26\x03\x27\x03\x27\x03\x27\x03\x27\x03\x27\x03\x27\x03\x27\x05\x27\u{5c0}\
	\x0a\x27\x03\x27\x03\x27\x03\x27\x03\x28\x03\x28\x03\x28\x03\x29\x03\x29\
	\x03\x29\x03\x29\x03\x29\x07\x29\u{5cd}\x0a\x29\x0c\x29\x0e\x29\u{5d0}\x0b\
	\x29\x03\x29\x03\x29\x03\x2a\x03\x2a\x03\x2a\x05\x2a\u{5d7}\x0a\x2a\x03\
	\x2a\x03\x2a\x05\x2a\u{5db}\x0a\x2a\x03\x2a\x03\x2a\x05\x2a\u{5df}\x0a\x2a\
	\x03\x2b\x03\x2b\x05\x2b\u{5e3}\x0a\x2b\x03\x2b\x03\x2b\x03\x2b\x03\x2b\
	\x07\x2b\u{5e9}\x0a\x2b\x0c\x2b\x0e\x2b\u{5ec}\x0b\x2b\x03\x2b\x05\x2b\u{5ef}\
	\x0a\x2b\x03\x2b\x05\x2b\u{5f2}\x0a\x2b\x03\x2b\x05\x2b\u{5f5}\x0a\x2b\x03\
	\x2b\x05\x2b\u{5f8}\x0a\x2b\x03\x2b\x03\x2b\x05\x2b\u{5fc}\x0a\x2b\x03\x2c\
	\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x07\x2c\u{603}\x0a\x2c\x0c\x2c\x0e\x2c\
	\u{606}\x0b\x2c\x05\x2c\u{608}\x0a\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\
	\x2c\x07\x2c\u{60f}\x0a\x2c\x0c\x2c\x0e\x2c\u{612}\x0b\x2c\x05\x2c\u{614}\
	\x0a\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x07\x2c\u{61b}\x0a\x2c\
	\x0c\x2c\x0e\x2c\u{61e}\x0b\x2c\x05\x2c\u{620}\x0a\x2c\x03\x2c\x03\x2c\x03\
	\x2c\x03\x2c\x03\x2c\x07\x2c\u{627}\x0a\x2c\x0c\x2c\x0e\x2c\u{62a}\x0b\x2c\
	\x05\x2c\u{62c}\x0a\x2c\x03\x2c\x05\x2c\u{62f}\x0a\x2c\x03\x2c\x03\x2c\x03\
	\x2c\x05\x2c\u{634}\x0a\x2c\x05\x2c\u{636}\x0a\x2c\x03\x2c\x03\x2c\x05\x2c\
	\u{63a}\x0a\x2c\x03\x2d\x03\x2d\x03\x2d\x07\x2d\u{63f}\x0a\x2d\x0c\x2d\x0e\
	\x2d\u{642}\x0b\x2d\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2f\x03\x2f\x03\
	\x2f\x03\x2f\x03\x2f\x03\x2f\x03\x2f\x05\x2f\u{64f}\x0a\x2f\x03\x30\x03\
	\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\
	\x30\x07\x30\u{65c}\x0a\x30\x0c\x30\x0e\x30\u{65f}\x0b\x30\x03\x30\x03\x30\
	\x05\x30\u{663}\x0a\x30\x03\x31\x03\x31\x03\x31\x03\x31\x05\x31\u{669}\x0a\
	\x31\x03\x32\x03\x32\x03\x32\x05\x32\u{66e}\x0a\x32\x03\x32\x03\x32\x03\
	\x32\x03\x32\x05\x32\u{674}\x0a\x32\x03\x33\x03\x33\x03\x33\x07\x33\u{679}\
	\x0a\x33\x0c\x33\x0e\x33\u{67c}\x0b\x33\x03\x34\x03\x34\x05\x34\u{680}\x0a\
	\x34\x03\x34\x03\x34\x05\x34\u{684}\x0a\x34\x05\x34\u{686}\x0a\x34\x03\x35\
	\x03\x35\x03\x35\x03\x36\x03\x36\x03\x36\x03\x36\x05\x36\u{68f}\x0a\x36\
	\x03\x36\x03\x36\x03\x36\x03\x36\x03\x36\x05\x36\u{696}\x0a\x36\x03\x36\
	\x03\x36\x03\x36\x05\x36\u{69b}\x0a\x36\x03\x36\x05\x36\u{69e}\x0a\x36\x03\
	\x36\x05\x36\u{6a1}\x0a\x36\x03\x36\x03\x36\x05\x36\u{6a5}\x0a\x36\x03\x36\
	\x03\x36\x03\x36\x03\x36\x03\x36\x03\x36\x03\x36\x03\x36\x05\x36\u{6af}\
	\x0a\x36\x03\x36\x03\x36\x05\x36\u{6b3}\x0a\x36\x05\x36\u{6b5}\x0a\x36\x03\
	\x36\x05\x36\u{6b8}\x0a\x36\x03\x36\x03\x36\x05\x36\u{6bc}\x0a\x36\x03\x37\
	\x03\x37\x07\x37\u{6c0}\x0a\x37\x0c\x37\x0e\x37\u{6c3}\x0b\x37\x03\x37\x05\
	\x37\u{6c6}\x0a\x37\x03\x37\x03\x37\x03\x38\x03\x38\x03\x38\x03\x39\x03\
	\x39\x03\x39\x07\x39\u{6d0}\x0a\x39\x0c\x39\x0e\x39\u{6d3}\x0b\x39\x03\x3a\
	\x03\x3a\x03\x3a\x07\x3a\u{6d8}\x0a\x3a\x0c\x3a\x0e\x3a\u{6db}\x0b\x3a\x03\
	\x3b\x03\x3b\x03\x3b\x07\x3b\u{6e0}\x0a\x3b\x0c\x3b\x0e\x3b\u{6e3}\x0b\x3b\
	\x03\x3c\x03\x3c\x03\x3c\x05\x3c\u{6e8}\x0a\x3c\x03\x3c\x07\x3c\u{6eb}\x0a\
	\x3c\x0c\x3c\x0e\x3c\u{6ee}\x0b\x3c\x03\x3c\x03\x3c\x03\x3d\x03\x3d\x03\
	\x3d\x03\x3d\x03\x3d\x03\x3d\x07\x3d\u{6f8}\x0a\x3d\x0c\x3d\x0e\x3d\u{6fb}\
	\x0b\x3d\x03\x3d\x03\x3d\x05\x3d\u{6ff}\x0a\x3d\x03\x3e\x05\x3e\u{702}\x0a\
	\x3e\x03\x3e\x03\x3e\x03\x3f\x03\x3f\x03\x3f\x03\x3f\x07\x3f\u{70a}\x0a\
	\x3f\x0c\x3f\x0e\x3f\u{70d}\x0b\x3f\x03\x40\x03\x40\x06\x40\u{711}\x0a\x40\
	\x0d\x40\x0e\x40\u{712}\x03\x40\x05\x40\u{716}\x0a\x40\x03\x41\x03\x41\x05\
	\x41\u{71a}\x0a\x41\x03\x41\x03\x41\x03\x41\x03\x41\x03\x41\x03\x41\x03\
	\x41\x03\x41\x03\x41\x05\x41\u{725}\x0a\x41\x05\x41\u{727}\x0a\x41\x03\x42\
	\x03\x42\x03\x43\x03\x43\x05\x43\u{72d}\x0a\x43\x03\x43\x03\x43\x05\x43\
	\u{731}\x0a\x43\x03\x44\x03\x44\x03\x44\x07\x44\u{736}\x0a\x44\x0c\x44\x0e\
	\x44\u{739}\x0b\x44\x03\x44\x05\x44\u{73c}\x0a\x44\x03\x45\x03\x45\x03\x45\
	\x03\x46\x03\x46\x03\x47\x03\x47\x03\x48\x03\x48\x07\x48\u{747}\x0a\x48\
	\x0c\x48\x0e\x48\u{74a}\x0b\x48\x03\x49\x03\x49\x03\x49\x03\x49\x03\x49\
	\x05\x49\u{751}\x0a\x49\x03\x4a\x03\x4a\x03\x4a\x03\x4a\x03\x4a\x03\x4a\
	\x03\x4a\x03\x4a\x05\x4a\u{75b}\x0a\x4a\x03\x4b\x03\x4b\x03\x4b\x03\x4c\
	\x03\x4c\x03\x4c\x07\x4c\u{763}\x0a\x4c\x0c\x4c\x0e\x4c\u{766}\x0b\x4c\x03\
	\x4c\x05\x4c\u{769}\x0a\x4c\x03\x4d\x03\x4d\x03\x4d\x03\x4d\x03\x4e\x03\
	\x4e\x03\x4f\x03\x4f\x05\x4f\u{773}\x0a\x4f\x03\x4f\x03\x4f\x03\x50\x03\
	\x50\x03\x50\x07\x50\u{77a}\x0a\x50\x0c\x50\x0e\x50\u{77d}\x0b\x50\x03\x50\
	\x05\x50\u{780}\x0a\x50\x03\x51\x03\x51\x03\x51\x03\x51\x07\x51\u{786}\x0a\
	\x51\x0c\x51\x0e\x51\u{789}\x0b\x51\x03\x51\x03\x51\x03\x51\x03\x51\x03\
	\x51\x03\x51\x05\x51\u{791}\x0a\x51\x03\x52\x03\x52\x05\x52\u{795}\x0a\x52\
	\x03\x53\x03\x53\x03\x53\x05\x53\u{79a}\x0a\x53\x03\x54\x03\x54\x03\x55\
	\x03\x55\x03\x55\x03\x55\x05\x55\u{7a2}\x0a\x55\x05\x55\u{7a4}\x0a\x55\x03\
	\x55\x03\x55\x05\x55\u{7a8}\x0a\x55\x03\x56\x03\x56\x05\x56\u{7ac}\x0a\x56\
	\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x07\x56\u{7b3}\x0a\x56\x0c\x56\
	\x0e\x56\u{7b6}\x0b\x56\x05\x56\u{7b8}\x0a\x56\x03\x56\x03\x56\x03\x56\x03\
	\x56\x03\x56\x07\x56\u{7bf}\x0a\x56\x0c\x56\x0e\x56\u{7c2}\x0b\x56\x05\x56\
	\u{7c4}\x0a\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x07\x56\u{7cb}\x0a\
	\x56\x0c\x56\x0e\x56\u{7ce}\x0b\x56\x05\x56\u{7d0}\x0a\x56\x03\x56\x05\x56\
	\u{7d3}\x0a\x56\x03\x57\x03\x57\x03\x57\x03\x57\x07\x57\u{7d9}\x0a\x57\x0c\
	\x57\x0e\x57\u{7dc}\x0b\x57\x03\x58\x03\x58\x03\x59\x03\x59\x03\x5a\x03\
	\x5a\x03\x5b\x03\x5b\x03\x5b\x03\x5b\x07\x5b\u{7e8}\x0a\x5b\x0c\x5b\x0e\
	\x5b\u{7eb}\x0b\x5b\x03\x5c\x03\x5c\x05\x5c\u{7ef}\x0a\x5c\x03\x5d\x03\x5d\
	\x03\x5d\x03\x5d\x07\x5d\u{7f5}\x0a\x5d\x0c\x5d\x0e\x5d\u{7f8}\x0b\x5d\x03\
	\x5e\x03\x5e\x05\x5e\u{7fc}\x0a\x5e\x03\x5f\x03\x5f\x03\x60\x03\x60\x03\
	\x60\x03\x60\x07\x60\u{804}\x0a\x60\x0c\x60\x0e\x60\u{807}\x0b\x60\x03\x60\
	\x05\x60\u{80a}\x0a\x60\x03\x61\x03\x61\x03\x61\x03\x61\x03\x61\x03\x61\
	\x03\x61\x03\x61\x05\x61\u{814}\x0a\x61\x03\x62\x03\x62\x05\x62\u{818}\x0a\
	\x62\x03\x62\x03\x62\x05\x62\u{81c}\x0a\x62\x03\x63\x03\x63\x05\x63\u{820}\
	\x0a\x63\x03\x63\x03\x63\x03\x63\x05\x63\u{825}\x0a\x63\x03\x63\x03\x63\
	\x05\x63\u{829}\x0a\x63\x03\x63\x05\x63\u{82c}\x0a\x63\x03\x63\x03\x63\x05\
	\x63\u{830}\x0a\x63\x03\x63\x03\x63\x05\x63\u{834}\x0a\x63\x03\x63\x03\x63\
	\x03\x63\x03\x63\x07\x63\u{83a}\x0a\x63\x0c\x63\x0e\x63\u{83d}\x0b\x63\x03\
	\x63\x05\x63\u{840}\x0a\x63\x05\x63\u{842}\x0a\x63\x03\x64\x03\x64\x03\x64\
	\x07\x64\u{847}\x0a\x64\x0c\x64\x0e\x64\u{84a}\x0b\x64\x03\x64\x05\x64\u{84d}\
	\x0a\x64\x03\x65\x03\x65\x03\x65\x03\x65\x03\x66\x03\x66\x03\x66\x03\x66\
	\x07\x66\u{857}\x0a\x66\x0c\x66\x0e\x66\u{85a}\x0b\x66\x03\x66\x03\x66\x03\
	\x66\x07\x66\u{85f}\x0a\x66\x0c\x66\x0e\x66\u{862}\x0b\x66\x03\x66\x03\x66\
	\x03\x66\x05\x66\u{867}\x0a\x66\x03\x67\x03\x67\x05\x67\u{86b}\x0a\x67\x03\
	\x68\x03\x68\x03\x68\x03\x68\x03\x68\x07\x68\u{872}\x0a\x68\x0c\x68\x0e\
	\x68\u{875}\x0b\x68\x03\x68\x03\x68\x03\x68\x03\x68\x03\x68\x03\x68\x03\
	\x68\x03\x68\x07\x68\u{87f}\x0a\x68\x0c\x68\x0e\x68\u{882}\x0b\x68\x03\x68\
	\x03\x68\x05\x68\u{886}\x0a\x68\x03\x69\x03\x69\x05\x69\u{88a}\x0a\x69\x03\
	\x6a\x03\x6a\x03\x6a\x03\x6a\x07\x6a\u{890}\x0a\x6a\x0c\x6a\x0e\x6a\u{893}\
	\x0b\x6a\x05\x6a\u{895}\x0a\x6a\x03\x6a\x05\x6a\u{898}\x0a\x6a\x03\x6a\x03\
	\x6a\x05\x6a\u{89c}\x0a\x6a\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\
	\x6b\x03\x6c\x05\x6c\u{8a5}\x0a\x6c\x03\x6c\x05\x6c\u{8a8}\x0a\x6c\x03\x6c\
	\x05\x6c\u{8ab}\x0a\x6c\x03\x6c\x05\x6c\u{8ae}\x0a\x6c\x03\x6d\x03\x6d\x03\
	\x6d\x03\x6d\x03\x6d\x07\x6d\u{8b5}\x0a\x6d\x0c\x6d\x0e\x6d\u{8b8}\x0b\x6d\
	\x03\x6d\x05\x6d\u{8bb}\x0a\x6d\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\
	\x03\x6e\x07\x6e\u{8c3}\x0a\x6e\x0c\x6e\x0e\x6e\u{8c6}\x0b\x6e\x03\x6e\x05\
	\x6e\u{8c9}\x0a\x6e\x05\x6e\u{8cb}\x0a\x6e\x03\x6f\x03\x6f\x05\x6f\u{8cf}\
	\x0a\x6f\x03\x6f\x05\x6f\u{8d2}\x0a\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\
	\x03\x70\x03\x70\x05\x70\u{8da}\x0a\x70\x03\x71\x03\x71\x05\x71\u{8de}\x0a\
	\x71\x03\x71\x05\x71\u{8e1}\x0a\x71\x03\x71\x05\x71\u{8e4}\x0a\x71\x03\x72\
	\x03\x72\x05\x72\u{8e8}\x0a\x72\x03\x72\x05\x72\u{8eb}\x0a\x72\x03\x72\x05\
	\x72\u{8ee}\x0a\x72\x03\x73\x03\x73\x03\x73\x03\x73\x03\x73\x03\x73\x05\
	\x73\u{8f6}\x0a\x73\x03\x74\x03\x74\x03\x74\x03\x74\x03\x74\x03\x74\x03\
	\x74\x03\x74\x03\x74\x05\x74\u{901}\x0a\x74\x03\x75\x03\x75\x03\x76\x05\
	\x76\u{906}\x0a\x76\x03\x76\x03\x76\x03\x76\x05\x76\u{90b}\x0a\x76\x03\x76\
	\x05\x76\u{90e}\x0a\x76\x03\x76\x03\x76\x03\x76\x05\x76\u{913}\x0a\x76\x03\
	\x76\x03\x76\x05\x76\u{917}\x0a\x76\x03\x76\x05\x76\u{91a}\x0a\x76\x03\x76\
	\x05\x76\u{91d}\x0a\x76\x03\x77\x03\x77\x03\x77\x03\x77\x03\x77\x03\x77\
	\x03\x77\x07\x77\u{926}\x0a\x77\x0c\x77\x0e\x77\u{929}\x0b\x77\x03\x77\x05\
	\x77\u{92c}\x0a\x77\x03\x77\x03\x77\x05\x77\u{930}\x0a\x77\x03\x78\x03\x78\
	\x03\x79\x03\x79\x05\x79\u{936}\x0a\x79\x03\x7a\x03\x7a\x03\x7a\x05\x7a\
	\u{93b}\x0a\x7a\x03\x7a\x03\x7a\x03\x7a\x03\x7a\x03\x7a\x05\x7a\u{942}\x0a\
	\x7a\x03\x7b\x03\x7b\x03\x7b\x05\x7b\u{947}\x0a\x7b\x03\x7b\x03\x7b\x03\
	\x7b\x03\x7b\x03\x7b\x05\x7b\u{94e}\x0a\x7b\x03\x7c\x05\x7c\u{951}\x0a\x7c\
	\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7c\
	\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x05\x7c\u{963}\
	\x0a\x7c\x05\x7c\u{965}\x0a\x7c\x03\x7c\x05\x7c\u{968}\x0a\x7c\x03\x7d\x03\
	\x7d\x03\x7e\x03\x7e\x03\x7e\x03\x7e\x03\x7f\x03\x7f\x03\u{80}\x03\u{80}\
	\x05\u{80}\u{974}\x0a\u{80}\x03\u{81}\x03\u{81}\x03\u{81}\x03\u{81}\x07\
	\u{81}\u{97a}\x0a\u{81}\x0c\u{81}\x0e\u{81}\u{97d}\x0b\u{81}\x03\u{81}\x03\
	\u{81}\x07\u{81}\u{981}\x0a\u{81}\x0c\u{81}\x0e\u{81}\u{984}\x0b\u{81}\x03\
	\u{82}\x03\u{82}\x05\u{82}\u{988}\x0a\u{82}\x03\u{83}\x03\u{83}\x05\u{83}\
	\u{98c}\x0a\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x07\u{83}\u{992}\
	\x0a\u{83}\x0c\u{83}\x0e\u{83}\u{995}\x0b\u{83}\x03\u{84}\x03\u{84}\x05\
	\u{84}\u{999}\x0a\u{84}\x03\u{85}\x03\u{85}\x03\u{85}\x05\u{85}\u{99e}\x0a\
	\u{85}\x03\u{85}\x03\u{85}\x05\u{85}\u{9a2}\x0a\u{85}\x03\u{85}\x03\u{85}\
	\x03\u{85}\x03\u{85}\x05\u{85}\u{9a8}\x0a\u{85}\x03\u{85}\x03\u{85}\x05\
	\u{85}\u{9ac}\x0a\u{85}\x03\u{86}\x03\u{86}\x07\u{86}\u{9b0}\x0a\u{86}\x0c\
	\u{86}\x0e\u{86}\u{9b3}\x0b\u{86}\x03\u{87}\x03\u{87}\x03\u{88}\x03\u{88}\
	\x03\u{88}\x03\u{88}\x03\u{88}\x07\u{88}\u{9bc}\x0a\u{88}\x0c\u{88}\x0e\
	\u{88}\u{9bf}\x0b\u{88}\x03\u{88}\x03\u{88}\x05\u{88}\u{9c3}\x0a\u{88}\x03\
	\u{89}\x03\u{89}\x03\u{8a}\x05\u{8a}\u{9c8}\x0a\u{8a}\x03\u{8a}\x05\u{8a}\
	\u{9cb}\x0a\u{8a}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\
	\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8c}\x03\u{8c}\x05\u{8c}\u{9d7}\x0a\u{8c}\
	\x03\u{8c}\x05\u{8c}\u{9da}\x0a\u{8c}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x05\
	\u{8c}\u{9df}\x0a\u{8c}\x03\u{8c}\x05\u{8c}\u{9e2}\x0a\u{8c}\x07\u{8c}\u{9e4}\
	\x0a\u{8c}\x0c\u{8c}\x0e\u{8c}\u{9e7}\x0b\u{8c}\x03\u{8c}\x05\u{8c}\u{9ea}\
	\x0a\u{8c}\x03\u{8d}\x03\u{8d}\x03\u{8e}\x03\u{8e}\x03\u{8e}\x03\u{8e}\x03\
	\u{8e}\x03\u{8e}\x03\u{8e}\x03\u{8e}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x03\u{8f}\
	\x07\u{8f}\u{9fa}\x0a\u{8f}\x0c\u{8f}\x0e\u{8f}\u{9fd}\x0b\u{8f}\x03\u{8f}\
	\x05\u{8f}\u{a00}\x0a\u{8f}\x03\u{8f}\x03\u{8f}\x03\u{90}\x03\u{90}\x03\
	\u{90}\x03\u{90}\x07\u{90}\u{a08}\x0a\u{90}\x0c\u{90}\x0e\u{90}\u{a0b}\x0b\
	\u{90}\x03\u{90}\x03\u{90}\x05\u{90}\u{a0f}\x0a\u{90}\x03\u{90}\x05\u{90}\
	\u{a12}\x0a\u{90}\x03\u{91}\x03\u{91}\x03\u{91}\x07\u{91}\u{a17}\x0a\u{91}\
	\x0c\u{91}\x0e\u{91}\u{a1a}\x0b\u{91}\x03\u{91}\x05\u{91}\u{a1d}\x0a\u{91}\
	\x03\u{92}\x03\u{92}\x05\u{92}\u{a21}\x0a\u{92}\x03\u{93}\x03\u{93}\x03\
	\u{93}\x07\u{93}\u{a26}\x0a\u{93}\x0c\u{93}\x0e\u{93}\u{a29}\x0b\u{93}\x03\
	\u{93}\x05\u{93}\u{a2c}\x0a\u{93}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\
	\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\
	\u{94}\x03\u{94}\x05\u{94}\u{a3b}\x0a\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\
	\x03\u{94}\x03\u{94}\x05\u{94}\u{a42}\x0a\u{94}\x03\u{95}\x03\u{95}\x03\
	\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\
	\x05\u{95}\u{a4e}\x0a\u{95}\x03\u{95}\x05\u{95}\u{a51}\x0a\u{95}\x03\u{96}\
	\x05\u{96}\u{a54}\x0a\u{96}\x03\u{96}\x03\u{96}\x03\u{96}\x03\u{96}\x03\
	\u{96}\x05\u{96}\u{a5b}\x0a\u{96}\x03\u{96}\x03\u{96}\x03\u{96}\x03\u{96}\
	\x05\u{96}\u{a61}\x0a\u{96}\x03\u{97}\x03\u{97}\x05\u{97}\u{a65}\x0a\u{97}\
	\x03\u{98}\x03\u{98}\x05\u{98}\u{a69}\x0a\u{98}\x03\u{98}\x03\u{98}\x05\
	\u{98}\u{a6d}\x0a\u{98}\x05\u{98}\u{a6f}\x0a\u{98}\x03\u{99}\x03\u{99}\x03\
	\u{99}\x05\u{99}\u{a74}\x0a\u{99}\x03\u{99}\x03\u{99}\x03\u{9a}\x03\u{9a}\
	\x05\u{9a}\u{a7a}\x0a\u{9a}\x03\u{9a}\x05\u{9a}\u{a7d}\x0a\u{9a}\x03\u{9a}\
	\x03\u{9a}\x03\u{9a}\x03\u{9a}\x03\u{9a}\x03\u{9a}\x03\u{9a}\x03\u{9a}\x05\
	\u{9a}\u{a87}\x0a\u{9a}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\
	\x07\u{9b}\u{a8e}\x0a\u{9b}\x0c\u{9b}\x0e\u{9b}\u{a91}\x0b\u{9b}\x03\u{9b}\
	\x05\u{9b}\u{a94}\x0a\u{9b}\x05\u{9b}\u{a96}\x0a\u{9b}\x03\u{9b}\x03\u{9b}\
	\x03\u{9c}\x03\u{9c}\x03\u{9d}\x03\u{9d}\x03\u{9d}\x05\u{9d}\u{a9f}\x0a\
	\u{9d}\x03\u{9d}\x03\u{9d}\x05\u{9d}\u{aa3}\x0a\u{9d}\x03\u{9e}\x03\u{9e}\
	\x03\u{9e}\x03\u{9e}\x03\u{9e}\x03\u{9e}\x03\u{9e}\x07\u{9e}\u{aac}\x0a\
	\u{9e}\x0c\u{9e}\x0e\u{9e}\u{aaf}\x0b\u{9e}\x03\u{9e}\x05\u{9e}\u{ab2}\x0a\
	\u{9e}\x05\u{9e}\u{ab4}\x0a\u{9e}\x03\u{9e}\x03\u{9e}\x05\u{9e}\u{ab8}\x0a\
	\u{9e}\x05\u{9e}\u{aba}\x0a\u{9e}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x03\u{9f}\
	\x03\u{9f}\x05\u{9f}\u{ac1}\x0a\u{9f}\x03\u{9f}\x03\u{9f}\x05\u{9f}\u{ac5}\
	\x0a\u{9f}\x05\u{9f}\u{ac7}\x0a\u{9f}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x03\
	\u{9f}\x03\u{9f}\x05\u{9f}\u{ace}\x0a\u{9f}\x03\u{9f}\x03\u{9f}\x05\u{9f}\
	\u{ad2}\x0a\u{9f}\x05\u{9f}\u{ad4}\x0a\u{9f}\x05\u{9f}\u{ad6}\x0a\u{9f}\
	\x03\u{a0}\x03\u{a0}\x03\u{a1}\x03\u{a1}\x03\u{a1}\x03\u{a1}\x05\u{a1}\u{ade}\
	\x0a\u{a1}\x03\u{a1}\x03\u{a1}\x03\u{a1}\x03\u{a1}\x03\u{a1}\x03\u{a1}\x03\
	\u{a1}\x03\u{a1}\x07\u{a1}\u{ae8}\x0a\u{a1}\x0c\u{a1}\x0e\u{a1}\u{aeb}\x0b\
	\u{a1}\x03\u{a2}\x03\u{a2}\x03\u{a2}\x03\u{a2}\x03\u{a2}\x03\u{a2}\x03\u{a2}\
	\x03\u{a2}\x03\u{a2}\x05\u{a2}\u{af6}\x0a\u{a2}\x03\u{a3}\x03\u{a3}\x05\
	\u{a3}\u{afa}\x0a\u{a3}\x03\u{a4}\x05\u{a4}\u{afd}\x0a\u{a4}\x03\u{a4}\x03\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x05\u{a4}\u{b05}\x0a\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x07\u{a4}\u{b0c}\x0a\
	\u{a4}\x0c\u{a4}\x0e\u{a4}\u{b0f}\x0b\u{a4}\x03\u{a4}\x05\u{a4}\u{b12}\x0a\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x05\u{a4}\u{b17}\x0a\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x05\u{a4}\u{b1f}\x0a\
	\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x05\u{a4}\u{b24}\x0a\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x07\u{a4}\u{b2c}\x0a\
	\u{a4}\x0c\u{a4}\x0e\u{a4}\u{b2f}\x0b\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x05\u{a4}\u{b34}\x0a\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\x05\
	\u{a4}\u{b3a}\x0a\u{a4}\x03\u{a4}\x03\u{a4}\x05\u{a4}\u{b3e}\x0a\u{a4}\x03\
	\u{a4}\x03\u{a4}\x03\u{a4}\x05\u{a4}\u{b43}\x0a\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a4}\x05\u{a4}\u{b4a}\x0a\u{a4}\x03\u{a4}\x03\
	\u{a4}\x03\u{a4}\x05\u{a4}\u{b4f}\x0a\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x05\u{a4}\u{b54}\x0a\u{a4}\x03\u{a4}\x05\u{a4}\u{b57}\x0a\u{a4}\x03\u{a5}\
	\x03\u{a5}\x03\u{a5}\x03\u{a5}\x05\u{a5}\u{b5d}\x0a\u{a5}\x03\u{a5}\x03\
	\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\
	\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\x03\
	\u{a5}\x03\u{a5}\x07\u{a5}\u{b71}\x0a\u{a5}\x0c\u{a5}\x0e\u{a5}\u{b74}\x0b\
	\u{a5}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x06\u{a6}\u{b7d}\x0a\u{a6}\x0d\u{a6}\x0e\u{a6}\u{b7e}\x03\u{a6}\x05\u{a6}\
	\u{b82}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x07\u{a6}\u{b8b}\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{b8e}\x0b\
	\u{a6}\x05\u{a6}\u{b90}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\
	\u{a6}\u{b9d}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{ba2}\x0a\
	\u{a6}\x03\u{a6}\x05\u{a6}\u{ba5}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{bb0}\
	\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{bb3}\x0b\u{a6}\x03\u{a6}\x05\u{a6}\u{bb6}\
	\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{bba}\x0a\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{bc3}\
	\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{bc6}\x0b\u{a6}\x05\u{a6}\u{bc8}\x0a\u{a6}\
	\x03\u{a6}\x05\u{a6}\u{bcb}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x06\u{a6}\u{bd5}\x0a\u{a6}\
	\x0d\u{a6}\x0e\u{a6}\u{bd6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{bdb}\x0a\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x06\u{a6}\u{be1}\x0a\u{a6}\x0d\
	\u{a6}\x0e\u{a6}\u{be2}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{be7}\x0a\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{bfc}\x0a\u{a6}\x03\u{a6}\
	\x05\u{a6}\u{bff}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{c0a}\x0a\u{a6}\
	\x03\u{a6}\x05\u{a6}\u{c0d}\x0a\u{a6}\x05\u{a6}\u{c0f}\x0a\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x05\u{a6}\u{c1a}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{c25}\x0a\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{c30}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{c40}\x0a\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\
	\u{c49}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x05\u{a6}\u{c52}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{c62}\x0a\u{a6}\x0c\u{a6}\
	\x0e\u{a6}\u{c65}\x0b\u{a6}\x05\u{a6}\u{c67}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x07\u{a6}\u{c74}\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{c77}\x0b\
	\u{a6}\x05\u{a6}\u{c79}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x06\u{a6}\u{c83}\x0a\u{a6}\x0d\
	\u{a6}\x0e\u{a6}\u{c84}\x05\u{a6}\u{c87}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x05\u{a6}\u{c93}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{c98}\
	\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{c9b}\x0b\u{a6}\x05\u{a6}\u{c9d}\x0a\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x07\u{a6}\u{caf}\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{cb2}\x0b\u{a6}\
	\x05\u{a6}\u{cb4}\x0a\u{a6}\x03\u{a6}\x05\u{a6}\u{cb7}\x0a\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{cc5}\x0a\u{a6}\x0c\u{a6}\
	\x0e\u{a6}\u{cc8}\x0b\u{a6}\x05\u{a6}\u{cca}\x0a\u{a6}\x03\u{a6}\x05\u{a6}\
	\u{ccd}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{cd9}\x0a\u{a6}\
	\x0c\u{a6}\x0e\u{a6}\u{cdc}\x0b\u{a6}\x03\u{a6}\x05\u{a6}\u{cdf}\x0a\u{a6}\
	\x05\u{a6}\u{ce1}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x05\u{a6}\u{cf0}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{cfa}\x0a\u{a6}\
	\x0c\u{a6}\x0e\u{a6}\u{cfd}\x0b\u{a6}\x05\u{a6}\u{cff}\x0a\u{a6}\x03\u{a6}\
	\x05\u{a6}\u{d02}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\
	\u{d0f}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{d19}\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\
	\u{d1c}\x0b\u{a6}\x05\u{a6}\u{d1e}\x0a\u{a6}\x03\u{a6}\x05\u{a6}\u{d21}\
	\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{d2d}\x0a\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\
	\u{a6}\u{d37}\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{d3a}\x0b\u{a6}\x05\u{a6}\u{d3c}\
	\x0a\u{a6}\x03\u{a6}\x05\u{a6}\u{d3f}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\
	\u{d4a}\x0a\u{a6}\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{d4e}\x0a\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{d63}\x0a\u{a6}\x0c\u{a6}\x0e\
	\u{a6}\u{d66}\x0b\u{a6}\x03\u{a7}\x03\u{a7}\x03\u{a8}\x05\u{a8}\u{d6b}\x0a\
	\u{a8}\x03\u{a8}\x05\u{a8}\u{d6e}\x0a\u{a8}\x03\u{a8}\x05\u{a8}\u{d71}\x0a\
	\u{a8}\x03\u{a9}\x03\u{a9}\x03\u{a9}\x03\u{a9}\x03\u{a9}\x03\u{a9}\x05\u{a9}\
	\u{d79}\x0a\u{a9}\x03\u{aa}\x03\u{aa}\x03\u{ab}\x03\u{ab}\x03\u{ab}\x03\
	\u{ab}\x03\u{ab}\x03\u{ab}\x03\u{ab}\x03\u{ab}\x03\u{ab}\x03\u{ab}\x03\u{ab}\
	\x03\u{ab}\x03\u{ab}\x06\u{ab}\u{d8a}\x0a\u{ab}\x0d\u{ab}\x0e\u{ab}\u{d8b}\
	\x05\u{ab}\u{d8e}\x0a\u{ab}\x03\u{ac}\x03\u{ac}\x07\u{ac}\u{d92}\x0a\u{ac}\
	\x0c\u{ac}\x0e\u{ac}\u{d95}\x0b\u{ac}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\
	\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\
	\x05\u{ad}\u{da2}\x0a\u{ad}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x03\
	\u{ae}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x03\u{ae}\
	\x05\u{ae}\u{db0}\x0a\u{ae}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\
	\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x05\u{af}\
	\u{dbd}\x0a\u{af}\x03\u{b0}\x03\u{b0}\x03\u{b0}\x05\u{b0}\u{dc2}\x0a\u{b0}\
	\x03\u{b1}\x03\u{b1}\x03\u{b1}\x03\u{b1}\x05\u{b1}\u{dc8}\x0a\u{b1}\x03\
	\u{b2}\x03\u{b2}\x05\u{b2}\u{dcc}\x0a\u{b2}\x03\u{b3}\x03\u{b3}\x03\u{b3}\
	\x03\u{b3}\x03\u{b3}\x03\u{b3}\x05\u{b3}\u{dd4}\x0a\u{b3}\x03\u{b4}\x03\
	\u{b4}\x03\u{b5}\x03\u{b5}\x03\u{b6}\x03\u{b6}\x03\u{b7}\x03\u{b7}\x03\u{b7}\
	\x03\u{b8}\x03\u{b8}\x03\u{b8}\x03\u{b8}\x06\u{b8}\u{de3}\x0a\u{b8}\x0d\
	\u{b8}\x0e\u{b8}\u{de4}\x03\u{b9}\x05\u{b9}\u{de8}\x0a\u{b9}\x03\u{b9}\x03\
	\u{b9}\x03\u{b9}\x05\u{b9}\u{ded}\x0a\u{b9}\x03\u{ba}\x03\u{ba}\x03\u{bb}\
	\x03\u{bb}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\
	\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\
	\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x05\u{bc}\u{e05}\x0a\u{bc}\x03\
	\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\
	\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x05\u{bc}\u{e15}\
	\x0a\u{bc}\x03\u{bd}\x03\u{bd}\x03\u{bd}\x03\u{be}\x03\u{be}\x03\u{be}\x05\
	\u{be}\u{e1d}\x0a\u{be}\x03\u{be}\x05\u{be}\u{e20}\x0a\u{be}\x03\u{bf}\x03\
	\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x07\u{bf}\u{e29}\
	\x0a\u{bf}\x0c\u{bf}\x0e\u{bf}\u{e2c}\x0b\u{bf}\x03\u{bf}\x05\u{bf}\u{e2f}\
	\x0a\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x05\u{bf}\u{e34}\x0a\u{bf}\x03\
	\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x05\u{bf}\u{e3a}\x0a\u{bf}\x03\u{bf}\
	\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x05\u{bf}\u{e42}\x0a\
	\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\
	\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x07\u{bf}\u{e50}\x0a\
	\u{bf}\x0c\u{bf}\x0e\u{bf}\u{e53}\x0b\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\
	\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x07\u{bf}\u{e5c}\x0a\u{bf}\x0c\
	\u{bf}\x0e\u{bf}\u{e5f}\x0b\u{bf}\x03\u{bf}\x05\u{bf}\u{e62}\x0a\u{bf}\x03\
	\u{bf}\x03\u{bf}\x05\u{bf}\u{e66}\x0a\u{bf}\x05\u{bf}\u{e68}\x0a\u{bf}\x03\
	\u{c0}\x03\u{c0}\x05\u{c0}\u{e6c}\x0a\u{c0}\x03\u{c0}\x03\u{c0}\x03\u{c0}\
	\x05\u{c0}\u{e71}\x0a\u{c0}\x03\u{c0}\x05\u{c0}\u{e74}\x0a\u{c0}\x03\u{c1}\
	\x03\u{c1}\x03\u{c1}\x03\u{c2}\x03\u{c2}\x05\u{c2}\u{e7b}\x0a\u{c2}\x03\
	\u{c3}\x03\u{c3}\x03\u{c3}\x03\u{c3}\x03\u{c3}\x03\u{c4}\x03\u{c4}\x03\u{c4}\
	\x03\u{c4}\x03\u{c4}\x03\u{c4}\x03\u{c5}\x03\u{c5}\x03\u{c5}\x03\u{c5}\x03\
	\u{c5}\x03\u{c5}\x05\u{c5}\u{e8e}\x0a\u{c5}\x03\u{c6}\x03\u{c6}\x03\u{c7}\
	\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\
	\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\
	\x05\u{c7}\u{ea2}\x0a\u{c7}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\
	\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x05\u{c8}\u{ead}\x0a\u{c8}\
	\x03\u{c9}\x03\u{c9}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x07\u{ca}\u{eb4}\x0a\
	\u{ca}\x0c\u{ca}\x0e\u{ca}\u{eb7}\x0b\u{ca}\x03\u{cb}\x03\u{cb}\x03\u{cc}\
	\x03\u{cc}\x03\u{cc}\x03\u{cc}\x03\u{cc}\x03\u{cc}\x03\u{cd}\x03\u{cd}\x03\
	\u{ce}\x03\u{ce}\x03\u{ce}\x03\u{ce}\x03\u{ce}\x05\u{ce}\u{ec8}\x0a\u{ce}\
	\x03\u{cf}\x03\u{cf}\x05\u{cf}\u{ecc}\x0a\u{cf}\x03\u{d0}\x03\u{d0}\x03\
	\u{d0}\x03\u{d0}\x05\u{d0}\u{ed2}\x0a\u{d0}\x03\u{d1}\x03\u{d1}\x03\u{d2}\
	\x03\u{d2}\x03\u{d3}\x03\u{d3}\x03\u{d3}\x03\u{d4}\x03\u{d4}\x03\u{d4}\x03\
	\u{d4}\x03\u{d5}\x03\u{d5}\x03\u{d5}\x07\u{d5}\u{ee2}\x0a\u{d5}\x0c\u{d5}\
	\x0e\u{d5}\u{ee5}\x0b\u{d5}\x03\u{d6}\x05\u{d6}\u{ee8}\x0a\u{d6}\x03\u{d6}\
	\x03\u{d6}\x05\u{d6}\u{eec}\x0a\u{d6}\x03\u{d6}\x03\u{d6}\x05\u{d6}\u{ef0}\
	\x0a\u{d6}\x03\u{d6}\x03\u{d6}\x05\u{d6}\u{ef4}\x0a\u{d6}\x03\u{d6}\x03\
	\u{d6}\x05\u{d6}\u{ef8}\x0a\u{d6}\x03\u{d6}\x03\u{d6}\x05\u{d6}\u{efc}\x0a\
	\u{d6}\x03\u{d6}\x03\u{d6}\x05\u{d6}\u{f00}\x0a\u{d6}\x03\u{d6}\x03\u{d6}\
	\x05\u{d6}\u{f04}\x0a\u{d6}\x03\u{d6}\x03\u{d6}\x05\u{d6}\u{f08}\x0a\u{d6}\
	\x03\u{d6}\x05\u{d6}\u{f0b}\x0a\u{d6}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\
	\u{d7}\x03\u{d7}\x07\u{d7}\u{f12}\x0a\u{d7}\x0c\u{d7}\x0e\u{d7}\u{f15}\x0b\
	\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\
	\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\
	\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x07\u{d7}\u{f2a}\x0a\u{d7}\
	\x0c\u{d7}\x0e\u{d7}\u{f2d}\x0b\u{d7}\x03\u{d7}\x03\u{d7}\x03\u{d7}\x03\
	\u{d7}\x05\u{d7}\u{f33}\x0a\u{d7}\x03\u{d8}\x03\u{d8}\x03\u{d8}\x03\u{d8}\
	\x05\u{d8}\u{f39}\x0a\u{d8}\x03\u{d9}\x03\u{d9}\x03\u{d9}\x07\u{d9}\u{f3e}\
	\x0a\u{d9}\x0c\u{d9}\x0e\u{d9}\u{f41}\x0b\u{d9}\x03\u{d9}\x05\u{d9}\u{f44}\
	\x0a\u{d9}\x03\u{da}\x03\u{da}\x03\u{db}\x03\u{db}\x03\u{db}\x02\x07\u{100}\
	\u{104}\u{140}\u{148}\u{14a}\u{dc}\x02\x04\x06\x08\x0a\x0c\x0e\x10\x12\x14\
	\x16\x18\x1a\x1c\x1e\x20\x22\x24\x26\x28\x2a\x2c\x2e\x30\x32\x34\x36\x38\
	\x3a\x3c\x3e\x40\x42\x44\x46\x48\x4a\x4c\x4e\x50\x52\x54\x56\x58\x5a\x5c\
	\x5e\x60\x62\x64\x66\x68\x6a\x6c\x6e\x70\x72\x74\x76\x78\x7a\x7c\x7e\u{80}\
	\u{82}\u{84}\u{86}\u{88}\u{8a}\u{8c}\u{8e}\u{90}\u{92}\u{94}\u{96}\u{98}\
	\u{9a}\u{9c}\u{9e}\u{a0}\u{a2}\u{a4}\u{a6}\u{a8}\u{aa}\u{ac}\u{ae}\u{b0}\
	\u{b2}\u{b4}\u{b6}\u{b8}\u{ba}\u{bc}\u{be}\u{c0}\u{c2}\u{c4}\u{c6}\u{c8}\
	\u{ca}\u{cc}\u{ce}\u{d0}\u{d2}\u{d4}\u{d6}\u{d8}\u{da}\u{dc}\u{de}\u{e0}\
	\u{e2}\u{e4}\u{e6}\u{e8}\u{ea}\u{ec}\u{ee}\u{f0}\u{f2}\u{f4}\u{f6}\u{f8}\
	\u{fa}\u{fc}\u{fe}\u{100}\u{102}\u{104}\u{106}\u{108}\u{10a}\u{10c}\u{10e}\
	\u{110}\u{112}\u{114}\u{116}\u{118}\u{11a}\u{11c}\u{11e}\u{120}\u{122}\u{124}\
	\u{126}\u{128}\u{12a}\u{12c}\u{12e}\u{130}\u{132}\u{134}\u{136}\u{138}\u{13a}\
	\u{13c}\u{13e}\u{140}\u{142}\u{144}\u{146}\u{148}\u{14a}\u{14c}\u{14e}\u{150}\
	\u{152}\u{154}\u{156}\u{158}\u{15a}\u{15c}\u{15e}\u{160}\u{162}\u{164}\u{166}\
	\u{168}\u{16a}\u{16c}\u{16e}\u{170}\u{172}\u{174}\u{176}\u{178}\u{17a}\u{17c}\
	\u{17e}\u{180}\u{182}\u{184}\u{186}\u{188}\u{18a}\u{18c}\u{18e}\u{190}\u{192}\
	\u{194}\u{196}\u{198}\u{19a}\u{19c}\u{19e}\u{1a0}\u{1a2}\u{1a4}\u{1a6}\u{1a8}\
	\u{1aa}\u{1ac}\u{1ae}\u{1b0}\u{1b2}\u{1b4}\x02\x21\x03\x02\u{19a}\u{19a}\
	\x03\x02\u{14b}\u{14c}\x06\x02\x32\x32\x42\x42\x79\x79\u{87}\u{87}\x04\x02\
	\x74\x74\u{9c}\u{9c}\x05\x02\x72\x72\u{cd}\u{cd}\u{166}\u{166}\x04\x02\x09\
	\x09\x67\x67\x04\x02\x15\x15\x61\x61\x04\x02\u{81}\u{81}\u{b1}\u{b1}\x04\
	\x02\x46\x46\u{11f}\u{11f}\x04\x02\u{1a6}\u{1a6}\u{1ab}\u{1ab}\x05\x02\x1f\
	\x1f\u{b4}\u{b4}\u{15a}\u{15a}\x04\x02\u{145}\u{145}\u{174}\u{174}\x04\x02\
	\u{144}\u{144}\u{152}\u{152}\x04\x02\u{de}\u{de}\u{18a}\u{18a}\x04\x02\u{10c}\
	\u{10c}\u{11b}\u{11b}\x05\x02\x09\x09\x0f\x0f\u{134}\u{134}\x04\x02\u{ac}\
	\u{ac}\u{b6}\u{b6}\x04\x02\u{193}\u{194}\u{1a1}\u{1a1}\x04\x02\x69\x69\u{195}\
	\u{197}\x03\x02\u{193}\u{194}\x03\x02\u{19d}\u{19f}\x06\x02\x48\x48\x4a\
	\x4b\u{12c}\u{12c}\u{16e}\u{16e}\x05\x02\u{188}\u{189}\u{18b}\u{18b}\u{18e}\
	\u{192}\x04\x02\x7c\x7c\u{15f}\u{15f}\x0b\x02\x4c\x4d\u{93}\u{94}\u{c9}\
	\u{cc}\u{ce}\u{cf}\u{d2}\u{d3}\u{d9}\u{da}\u{122}\u{123}\u{178}\u{179}\u{180}\
	\u{181}\x08\x02\x4c\x4c\u{93}\u{93}\u{ce}\u{ce}\u{d2}\u{d2}\u{122}\u{122}\
	\u{180}\u{180}\x04\x02\u{83}\u{83}\u{fb}\u{fb}\x07\x02\x44\x44\x5f\x5f\u{a3}\
	\u{a3}\u{127}\u{127}\u{16c}\u{16c}\x04\x02\u{152}\u{152}\u{174}\u{174}\x12\
	\x02\x0e\x0e\x45\x45\x72\x72\u{8a}\u{8a}\u{9f}\u{9f}\u{a4}\u{a4}\u{ad}\u{ad}\
	\u{b2}\u{b2}\u{b5}\u{b5}\u{cd}\u{cd}\u{db}\u{db}\u{e4}\u{e4}\u{11a}\u{11a}\
	\u{128}\u{128}\u{166}\u{166}\u{16f}\u{16f}\x14\x02\x07\x0d\x0f\x37\x39\x44\
	\x46\x71\x73\u{89}\u{8b}\u{9e}\u{a0}\u{a3}\u{a5}\u{ac}\u{ae}\u{b1}\u{b3}\
	\u{b4}\u{b6}\u{cc}\u{ce}\u{da}\u{dc}\u{e3}\u{e5}\u{119}\u{11b}\u{127}\u{129}\
	\u{165}\u{167}\u{16e}\u{170}\u{182}\x02\u{1159}\x02\u{1b7}\x03\x02\x02\x02\
	\x04\u{1c5}\x03\x02\x02\x02\x06\u{1cc}\x03\x02\x02\x02\x08\u{1cf}\x03\x02\
	\x02\x02\x0a\u{1d2}\x03\x02\x02\x02\x0c\u{3df}\x03\x02\x02\x02\x0e\u{3e1}\
	\x03\x02\x02\x02\x10\u{3ef}\x03\x02\x02\x02\x12\u{3f1}\x03\x02\x02\x02\x14\
	\u{3fc}\x03\x02\x02\x02\x16\u{400}\x03\x02\x02\x02\x18\u{423}\x03\x02\x02\
	\x02\x1a\u{426}\x03\x02\x02\x02\x1c\u{43b}\x03\x02\x02\x02\x1e\u{44a}\x03\
	\x02\x02\x02\x20\u{44e}\x03\x02\x02\x02\x22\u{450}\x03\x02\x02\x02\x24\u{459}\
	\x03\x02\x02\x02\x26\u{466}\x03\x02\x02\x02\x28\u{473}\x03\x02\x02\x02\x2a\
	\u{486}\x03\x02\x02\x02\x2c\u{491}\x03\x02\x02\x02\x2e\u{4cd}\x03\x02\x02\
	\x02\x30\u{4d5}\x03\x02\x02\x02\x32\u{4dd}\x03\x02\x02\x02\x34\u{4df}\x03\
	\x02\x02\x02\x36\u{4e5}\x03\x02\x02\x02\x38\u{4ef}\x03\x02\x02\x02\x3a\u{52f}\
	\x03\x02\x02\x02\x3c\u{531}\x03\x02\x02\x02\x3e\u{58d}\x03\x02\x02\x02\x40\
	\u{58f}\x03\x02\x02\x02\x42\u{599}\x03\x02\x02\x02\x44\u{59b}\x03\x02\x02\
	\x02\x46\u{59e}\x03\x02\x02\x02\x48\u{5a1}\x03\x02\x02\x02\x4a\u{5aa}\x03\
	\x02\x02\x02\x4c\u{5b8}\x03\x02\x02\x02\x4e\u{5c4}\x03\x02\x02\x02\x50\u{5c7}\
	\x03\x02\x02\x02\x52\u{5d3}\x03\x02\x02\x02\x54\u{5fb}\x03\x02\x02\x02\x56\
	\u{607}\x03\x02\x02\x02\x58\u{63b}\x03\x02\x02\x02\x5a\u{643}\x03\x02\x02\
	\x02\x5c\u{64e}\x03\x02\x02\x02\x5e\u{662}\x03\x02\x02\x02\x60\u{668}\x03\
	\x02\x02\x02\x62\u{673}\x03\x02\x02\x02\x64\u{675}\x03\x02\x02\x02\x66\u{67d}\
	\x03\x02\x02\x02\x68\u{687}\x03\x02\x02\x02\x6a\u{69d}\x03\x02\x02\x02\x6c\
	\u{6bd}\x03\x02\x02\x02\x6e\u{6c9}\x03\x02\x02\x02\x70\u{6cc}\x03\x02\x02\
	\x02\x72\u{6d4}\x03\x02\x02\x02\x74\u{6dc}\x03\x02\x02\x02\x76\u{6e4}\x03\
	\x02\x02\x02\x78\u{6fe}\x03\x02\x02\x02\x7a\u{701}\x03\x02\x02\x02\x7c\u{705}\
	\x03\x02\x02\x02\x7e\u{715}\x03\x02\x02\x02\u{80}\u{719}\x03\x02\x02\x02\
	\u{82}\u{728}\x03\x02\x02\x02\u{84}\u{72a}\x03\x02\x02\x02\u{86}\u{732}\
	\x03\x02\x02\x02\u{88}\u{73d}\x03\x02\x02\x02\u{8a}\u{740}\x03\x02\x02\x02\
	\u{8c}\u{742}\x03\x02\x02\x02\u{8e}\u{744}\x03\x02\x02\x02\u{90}\u{750}\
	\x03\x02\x02\x02\u{92}\u{752}\x03\x02\x02\x02\u{94}\u{75c}\x03\x02\x02\x02\
	\u{96}\u{75f}\x03\x02\x02\x02\u{98}\u{76a}\x03\x02\x02\x02\u{9a}\u{76e}\
	\x03\x02\x02\x02\u{9c}\u{770}\x03\x02\x02\x02\u{9e}\u{776}\x03\x02\x02\x02\
	\u{a0}\u{790}\x03\x02\x02\x02\u{a2}\u{794}\x03\x02\x02\x02\u{a4}\u{799}\
	\x03\x02\x02\x02\u{a6}\u{79b}\x03\x02\x02\x02\u{a8}\u{79d}\x03\x02\x02\x02\
	\u{aa}\u{7a9}\x03\x02\x02\x02\u{ac}\u{7d4}\x03\x02\x02\x02\u{ae}\u{7dd}\
	\x03\x02\x02\x02\u{b0}\u{7df}\x03\x02\x02\x02\u{b2}\u{7e1}\x03\x02\x02\x02\
	\u{b4}\u{7e3}\x03\x02\x02\x02\u{b6}\u{7ec}\x03\x02\x02\x02\u{b8}\u{7f0}\
	\x03\x02\x02\x02\u{ba}\u{7f9}\x03\x02\x02\x02\u{bc}\u{7fd}\x03\x02\x02\x02\
	\u{be}\u{7ff}\x03\x02\x02\x02\u{c0}\u{813}\x03\x02\x02\x02\u{c2}\u{815}\
	\x03\x02\x02\x02\u{c4}\u{81d}\x03\x02\x02\x02\u{c6}\u{843}\x03\x02\x02\x02\
	\u{c8}\u{84e}\x03\x02\x02\x02\u{ca}\u{866}\x03\x02\x02\x02\u{cc}\u{86a}\
	\x03\x02\x02\x02\u{ce}\u{885}\x03\x02\x02\x02\u{d0}\u{889}\x03\x02\x02\x02\
	\u{d2}\u{89b}\x03\x02\x02\x02\u{d4}\u{89d}\x03\x02\x02\x02\u{d6}\u{8a4}\
	\x03\x02\x02\x02\u{d8}\u{8af}\x03\x02\x02\x02\u{da}\u{8bc}\x03\x02\x02\x02\
	\u{dc}\u{8cc}\x03\x02\x02\x02\u{de}\u{8d9}\x03\x02\x02\x02\u{e0}\u{8e3}\
	\x03\x02\x02\x02\u{e2}\u{8ed}\x03\x02\x02\x02\u{e4}\u{8ef}\x03\x02\x02\x02\
	\u{e6}\u{900}\x03\x02\x02\x02\u{e8}\u{902}\x03\x02\x02\x02\u{ea}\u{91c}\
	\x03\x02\x02\x02\u{ec}\u{92f}\x03\x02\x02\x02\u{ee}\u{931}\x03\x02\x02\x02\
	\u{f0}\u{933}\x03\x02\x02\x02\u{f2}\u{937}\x03\x02\x02\x02\u{f4}\u{943}\
	\x03\x02\x02\x02\u{f6}\u{967}\x03\x02\x02\x02\u{f8}\u{969}\x03\x02\x02\x02\
	\u{fa}\u{96b}\x03\x02\x02\x02\u{fc}\u{96f}\x03\x02\x02\x02\u{fe}\u{971}\
	\x03\x02\x02\x02\u{100}\u{975}\x03\x02\x02\x02\u{102}\u{985}\x03\x02\x02\
	\x02\u{104}\u{989}\x03\x02\x02\x02\u{106}\u{998}\x03\x02\x02\x02\u{108}\
	\u{9ab}\x03\x02\x02\x02\u{10a}\u{9ad}\x03\x02\x02\x02\u{10c}\u{9b4}\x03\
	\x02\x02\x02\u{10e}\u{9c2}\x03\x02\x02\x02\u{110}\u{9c4}\x03\x02\x02\x02\
	\u{112}\u{9ca}\x03\x02\x02\x02\u{114}\u{9cc}\x03\x02\x02\x02\u{116}\u{9d4}\
	\x03\x02\x02\x02\u{118}\u{9eb}\x03\x02\x02\x02\u{11a}\u{9ed}\x03\x02\x02\
	\x02\u{11c}\u{9f5}\x03\x02\x02\x02\u{11e}\u{a03}\x03\x02\x02\x02\u{120}\
	\u{a13}\x03\x02\x02\x02\u{122}\u{a20}\x03\x02\x02\x02\u{124}\u{a22}\x03\
	\x02\x02\x02\u{126}\u{a41}\x03\x02\x02\x02\u{128}\u{a50}\x03\x02\x02\x02\
	\u{12a}\u{a60}\x03\x02\x02\x02\u{12c}\u{a64}\x03\x02\x02\x02\u{12e}\u{a66}\
	\x03\x02\x02\x02\u{130}\u{a70}\x03\x02\x02\x02\u{132}\u{a86}\x03\x02\x02\
	\x02\u{134}\u{a88}\x03\x02\x02\x02\u{136}\u{a99}\x03\x02\x02\x02\u{138}\
	\u{a9e}\x03\x02\x02\x02\u{13a}\u{aa4}\x03\x02\x02\x02\u{13c}\u{ad5}\x03\
	\x02\x02\x02\u{13e}\u{ad7}\x03\x02\x02\x02\u{140}\u{add}\x03\x02\x02\x02\
	\u{142}\u{af5}\x03\x02\x02\x02\u{144}\u{af7}\x03\x02\x02\x02\u{146}\u{b56}\
	\x03\x02\x02\x02\u{148}\u{b5c}\x03\x02\x02\x02\u{14a}\u{d4d}\x03\x02\x02\
	\x02\u{14c}\u{d67}\x03\x02\x02\x02\u{14e}\u{d6a}\x03\x02\x02\x02\u{150}\
	\u{d78}\x03\x02\x02\x02\u{152}\u{d7a}\x03\x02\x02\x02\u{154}\u{d8d}\x03\
	\x02\x02\x02\u{156}\u{d8f}\x03\x02\x02\x02\u{158}\u{da1}\x03\x02\x02\x02\
	\u{15a}\u{daf}\x03\x02\x02\x02\u{15c}\u{dbc}\x03\x02\x02\x02\u{15e}\u{dbe}\
	\x03\x02\x02\x02\u{160}\u{dc7}\x03\x02\x02\x02\u{162}\u{dcb}\x03\x02\x02\
	\x02\u{164}\u{dd3}\x03\x02\x02\x02\u{166}\u{dd5}\x03\x02\x02\x02\u{168}\
	\u{dd7}\x03\x02\x02\x02\u{16a}\u{dd9}\x03\x02\x02\x02\u{16c}\u{ddb}\x03\
	\x02\x02\x02\u{16e}\u{dde}\x03\x02\x02\x02\u{170}\u{de7}\x03\x02\x02\x02\
	\u{172}\u{dee}\x03\x02\x02\x02\u{174}\u{df0}\x03\x02\x02\x02\u{176}\u{e14}\
	\x03\x02\x02\x02\u{178}\u{e16}\x03\x02\x02\x02\u{17a}\u{e1f}\x03\x02\x02\
	\x02\u{17c}\u{e67}\x03\x02\x02\x02\u{17e}\u{e69}\x03\x02\x02\x02\u{180}\
	\u{e75}\x03\x02\x02\x02\u{182}\u{e7a}\x03\x02\x02\x02\u{184}\u{e7c}\x03\
	\x02\x02\x02\u{186}\u{e81}\x03\x02\x02\x02\u{188}\u{e87}\x03\x02\x02\x02\
	\u{18a}\u{e8f}\x03\x02\x02\x02\u{18c}\u{ea1}\x03\x02\x02\x02\u{18e}\u{eac}\
	\x03\x02\x02\x02\u{190}\u{eae}\x03\x02\x02\x02\u{192}\u{eb0}\x03\x02\x02\
	\x02\u{194}\u{eb8}\x03\x02\x02\x02\u{196}\u{eba}\x03\x02\x02\x02\u{198}\
	\u{ec0}\x03\x02\x02\x02\u{19a}\u{ec7}\x03\x02\x02\x02\u{19c}\u{ecb}\x03\
	\x02\x02\x02\u{19e}\u{ed1}\x03\x02\x02\x02\u{1a0}\u{ed3}\x03\x02\x02\x02\
	\u{1a2}\u{ed5}\x03\x02\x02\x02\u{1a4}\u{ed7}\x03\x02\x02\x02\u{1a6}\u{eda}\
	\x03\x02\x02\x02\u{1a8}\u{ede}\x03\x02\x02\x02\u{1aa}\u{f0a}\x03\x02\x02\
	\x02\u{1ac}\u{f32}\x03\x02\x02\x02\u{1ae}\u{f38}\x03\x02\x02\x02\u{1b0}\
	\u{f43}\x03\x02\x02\x02\u{1b2}\u{f45}\x03\x02\x02\x02\u{1b4}\u{f47}\x03\
	\x02\x02\x02\u{1b6}\u{1b8}\x05\x0c\x07\x02\u{1b7}\u{1b6}\x03\x02\x02\x02\
	\u{1b7}\u{1b8}\x03\x02\x02\x02\u{1b8}\u{1bf}\x03\x02\x02\x02\u{1b9}\u{1bb}\
	\x07\u{19a}\x02\x02\u{1ba}\u{1bc}\x05\x0c\x07\x02\u{1bb}\u{1ba}\x03\x02\
	\x02\x02\u{1bb}\u{1bc}\x03\x02\x02\x02\u{1bc}\u{1be}\x03\x02\x02\x02\u{1bd}\
	\u{1b9}\x03\x02\x02\x02\u{1be}\u{1c1}\x03\x02\x02\x02\u{1bf}\u{1bd}\x03\
	\x02\x02\x02\u{1bf}\u{1c0}\x03\x02\x02\x02\u{1c0}\u{1c2}\x03\x02\x02\x02\
	\u{1c1}\u{1bf}\x03\x02\x02\x02\u{1c2}\u{1c3}\x07\x02\x02\x03\u{1c3}\x03\
	\x03\x02\x02\x02\u{1c4}\u{1c6}\x05\x0c\x07\x02\u{1c5}\u{1c4}\x03\x02\x02\
	\x02\u{1c5}\u{1c6}\x03\x02\x02\x02\u{1c6}\u{1c8}\x03\x02\x02\x02\u{1c7}\
	\u{1c9}\x07\u{19a}\x02\x02\u{1c8}\u{1c7}\x03\x02\x02\x02\u{1c8}\u{1c9}\x03\
	\x02\x02\x02\u{1c9}\u{1ca}\x03\x02\x02\x02\u{1ca}\u{1cb}\x07\x02\x02\x03\
	\u{1cb}\x05\x03\x02\x02\x02\u{1cc}\u{1cd}\x05\u{13e}\u{a0}\x02\u{1cd}\u{1ce}\
	\x07\x02\x02\x03\u{1ce}\x07\x03\x02\x02\x02\u{1cf}\u{1d0}\x05\u{192}\u{ca}\
	\x02\u{1d0}\u{1d1}\x07\x02\x02\x03\u{1d1}\x09\x03\x02\x02\x02\u{1d2}\u{1d3}\
	\x05\u{17a}\u{be}\x02\u{1d3}\u{1d4}\x07\x02\x02\x03\u{1d4}\x0b\x03\x02\x02\
	\x02\u{1d5}\u{3e0}\x05\x7a\x3e\x02\u{1d6}\u{1d7}\x07\u{16d}\x02\x02\u{1d7}\
	\u{3e0}\x05\u{19c}\u{cf}\x02\u{1d8}\u{1d9}\x07\u{16d}\x02\x02\u{1d9}\u{1da}\
	\x05\u{19c}\u{cf}\x02\u{1da}\u{1db}\x07\u{187}\x02\x02\u{1db}\u{1dc}\x05\
	\u{19c}\u{cf}\x02\u{1dc}\u{3e0}\x03\x02\x02\x02\u{1dd}\u{1de}\x07\x6c\x02\
	\x02\u{1de}\u{1e1}\x07\u{124}\x02\x02\u{1df}\u{1e0}\x07\u{97}\x02\x02\u{1e0}\
	\u{1e2}\x07\x76\x02\x02\u{1e1}\u{1df}\x03\x02\x02\x02\u{1e1}\u{1e2}\x03\
	\x02\x02\x02\u{1e2}\u{1e3}\x03\x02\x02\x02\u{1e3}\u{1e7}\x05\u{192}\u{ca}\
	\x02\u{1e4}\u{1e6}\x0a\x02\x02\x02\u{1e5}\u{1e4}\x03\x02\x02\x02\u{1e6}\
	\u{1e9}\x03\x02\x02\x02\u{1e7}\u{1e5}\x03\x02\x02\x02\u{1e7}\u{1e8}\x03\
	\x02\x02\x02\u{1e8}\u{3e0}\x03\x02\x02\x02\u{1e9}\u{1e7}\x03\x02\x02\x02\
	\u{1ea}\u{1eb}\x07\x0a\x02\x02\u{1eb}\u{1ec}\x07\u{124}\x02\x02\u{1ec}\u{1ed}\
	\x05\u{192}\u{ca}\x02\u{1ed}\u{1ee}\x07\u{110}\x02\x02\u{1ee}\u{1ef}\x07\
	\u{158}\x02\x02\u{1ef}\u{1f0}\x05\u{19c}\u{cf}\x02\u{1f0}\u{3e0}\x03\x02\
	\x02\x02\u{1f1}\u{1f2}\x07\x0a\x02\x02\u{1f2}\u{1f3}\x07\u{124}\x02\x02\
	\u{1f3}\u{1f4}\x05\u{192}\u{ca}\x02\u{1f4}\u{1f5}\x07\u{12d}\x02\x02\u{1f5}\
	\u{1f6}\x07\x17\x02\x02\u{1f6}\u{1f7}\x05\u{19a}\u{ce}\x02\u{1f7}\u{3e0}\
	\x03\x02\x02\x02\u{1f8}\u{1f9}\x07\x6c\x02\x02\u{1f9}\u{1fa}\x07\u{146}\
	\x02\x02\u{1fa}\u{3e0}\x05\u{192}\u{ca}\x02\u{1fb}\u{1fc}\x07\x6c\x02\x02\
	\u{1fc}\u{1fd}\x07\u{175}\x02\x02\u{1fd}\u{3e0}\x05\u{192}\u{ca}\x02\u{1fe}\
	\u{201}\x07\x44\x02\x02\u{1ff}\u{200}\x07\u{e9}\x02\x02\u{200}\u{202}\x07\
	\u{10f}\x02\x02\u{201}\u{1ff}\x03\x02\x02\x02\u{201}\u{202}\x03\x02\x02\
	\x02\u{202}\u{204}\x03\x02\x02\x02\u{203}\u{205}\x09\x03\x02\x02\u{204}\
	\u{203}\x03\x02\x02\x02\u{204}\u{205}\x03\x02\x02\x02\u{205}\u{207}\x03\
	\x02\x02\x02\u{206}\u{208}\x07\x7a\x02\x02\u{207}\u{206}\x03\x02\x02\x02\
	\u{207}\u{208}\x03\x02\x02\x02\u{208}\u{20a}\x03\x02\x02\x02\u{209}\u{20b}\
	\x07\u{bb}\x02\x02\u{20a}\u{209}\x03\x02\x02\x02\u{20a}\u{20b}\x03\x02\x02\
	\x02\u{20b}\u{20d}\x03\x02\x02\x02\u{20c}\u{20e}\x07\u{13f}\x02\x02\u{20d}\
	\u{20c}\x03\x02\x02\x02\u{20d}\u{20e}\x03\x02\x02\x02\u{20e}\u{20f}\x03\
	\x02\x02\x02\u{20f}\u{213}\x07\u{146}\x02\x02\u{210}\u{211}\x07\u{97}\x02\
	\x02\u{211}\u{212}\x07\u{de}\x02\x02\u{212}\u{214}\x07\x76\x02\x02\u{213}\
	\u{210}\x03\x02\x02\x02\u{213}\u{214}\x03\x02\x02\x02\u{214}\u{21c}\x03\
	\x02\x02\x02\u{215}\u{216}\x07\x44\x02\x02\u{216}\u{218}\x07\u{e9}\x02\x02\
	\u{217}\u{215}\x03\x02\x02\x02\u{217}\u{218}\x03\x02\x02\x02\u{218}\u{219}\
	\x03\x02\x02\x02\u{219}\u{21a}\x07\u{113}\x02\x02\u{21a}\u{21c}\x07\u{146}\
	\x02\x02\u{21b}\u{1fe}\x03\x02\x02\x02\u{21b}\u{217}\x03\x02\x02\x02\u{21c}\
	\u{21d}\x03\x02\x02\x02\u{21d}\u{225}\x05\x10\x09\x02\u{21e}\u{21f}\x07\
	\u{183}\x02\x02\u{21f}\u{221}\x05\x0e\x08\x02\u{220}\u{222}\x07\x38\x02\
	\x02\u{221}\u{220}\x03\x02\x02\x02\u{221}\u{222}\x03\x02\x02\x02\u{222}\
	\u{223}\x03\x02\x02\x02\u{223}\u{224}\x07\u{184}\x02\x02\u{224}\u{226}\x03\
	\x02\x02\x02\u{225}\u{21e}\x03\x02\x02\x02\u{225}\u{226}\x03\x02\x02\x02\
	\u{226}\u{228}\x03\x02\x02\x02\u{227}\u{229}\x05\x1a\x0e\x02\u{228}\u{227}\
	\x03\x02\x02\x02\u{228}\u{229}\x03\x02\x02\x02\u{229}\u{22a}\x03\x02\x02\
	\x02\u{22a}\u{22c}\x05\x18\x0d\x02\u{22b}\u{22d}\x07\x14\x02\x02\u{22c}\
	\u{22b}\x03\x02\x02\x02\u{22c}\u{22d}\x03\x02\x02\x02\u{22d}\u{22e}\x03\
	\x02\x02\x02\u{22e}\u{22f}\x05\x7a\x3e\x02\u{22f}\u{3e0}\x03\x02\x02\x02\
	\u{230}\u{232}\x07\x44\x02\x02\u{231}\u{233}\x09\x03\x02\x02\u{232}\u{231}\
	\x03\x02\x02\x02\u{232}\u{233}\x03\x02\x02\x02\u{233}\u{235}\x03\x02\x02\
	\x02\u{234}\u{236}\x07\x7a\x02\x02\u{235}\u{234}\x03\x02\x02\x02\u{235}\
	\u{236}\x03\x02\x02\x02\u{236}\u{237}\x03\x02\x02\x02\u{237}\u{23b}\x07\
	\u{146}\x02\x02\u{238}\u{239}\x07\u{97}\x02\x02\u{239}\u{23a}\x07\u{de}\
	\x02\x02\u{23a}\u{23c}\x07\x76\x02\x02\u{23b}\u{238}\x03\x02\x02\x02\u{23b}\
	\u{23c}\x03\x02\x02\x02\u{23c}\u{244}\x03\x02\x02\x02\u{23d}\u{23e}\x07\
	\x44\x02\x02\u{23e}\u{240}\x07\u{e9}\x02\x02\u{23f}\u{23d}\x03\x02\x02\x02\
	\u{23f}\u{240}\x03\x02\x02\x02\u{240}\u{241}\x03\x02\x02\x02\u{241}\u{242}\
	\x07\u{113}\x02\x02\u{242}\u{244}\x07\u{146}\x02\x02\u{243}\u{230}\x03\x02\
	\x02\x02\u{243}\u{23f}\x03\x02\x02\x02\u{244}\u{245}\x03\x02\x02\x02\u{245}\
	\u{24d}\x05\x10\x09\x02\u{246}\u{247}\x07\u{183}\x02\x02\u{247}\u{249}\x05\
	\x0e\x08\x02\u{248}\u{24a}\x07\x38\x02\x02\u{249}\u{248}\x03\x02\x02\x02\
	\u{249}\u{24a}\x03\x02\x02\x02\u{24a}\u{24b}\x03\x02\x02\x02\u{24b}\u{24c}\
	\x07\u{184}\x02\x02\u{24c}\u{24e}\x03\x02\x02\x02\u{24d}\u{246}\x03\x02\
	\x02\x02\u{24d}\u{24e}\x03\x02\x02\x02\u{24e}\u{250}\x03\x02\x02\x02\u{24f}\
	\u{251}\x05\x1a\x0e\x02\u{250}\u{24f}\x03\x02\x02\x02\u{250}\u{251}\x03\
	\x02\x02\x02\u{251}\u{252}\x03\x02\x02\x02\u{252}\u{253}\x05\x18\x0d\x02\
	\u{253}\u{3e0}\x03\x02\x02\x02\u{254}\u{255}\x07\x44\x02\x02\u{255}\u{259}\
	\x07\u{146}\x02\x02\u{256}\u{257}\x07\u{97}\x02\x02\u{257}\u{258}\x07\u{de}\
	\x02\x02\u{258}\u{25a}\x07\x76\x02\x02\u{259}\u{256}\x03\x02\x02\x02\u{259}\
	\u{25a}\x03\x02\x02\x02\u{25a}\u{25b}\x03\x02\x02\x02\u{25b}\u{25c}\x05\
	\u{192}\u{ca}\x02\u{25c}\u{25d}\x07\u{b6}\x02\x02\u{25d}\u{266}\x05\u{192}\
	\u{ca}\x02\u{25e}\u{265}\x05\x1a\x0e\x02\u{25f}\u{265}\x05\x2e\x18\x02\u{260}\
	\u{265}\x05\x30\x19\x02\u{261}\u{265}\x05\x36\x1c\x02\u{262}\u{263}\x07\
	\u{14a}\x02\x02\u{263}\u{265}\x05\u{9c}\x4f\x02\u{264}\u{25e}\x03\x02\x02\
	\x02\u{264}\u{25f}\x03\x02\x02\x02\u{264}\u{260}\x03\x02\x02\x02\u{264}\
	\u{261}\x03\x02\x02\x02\u{264}\u{262}\x03\x02\x02\x02\u{265}\u{268}\x03\
	\x02\x02\x02\u{266}\u{264}\x03\x02\x02\x02\u{266}\u{267}\x03\x02\x02\x02\
	\u{267}\u{3e0}\x03\x02\x02\x02\u{268}\u{266}\x03\x02\x02\x02\u{269}\u{26b}\
	\x05\x3c\x1f\x02\u{26a}\u{269}\x03\x02\x02\x02\u{26a}\u{26b}\x03\x02\x02\
	\x02\u{26b}\u{26c}\x03\x02\x02\x02\u{26c}\u{3e0}\x05\x3a\x1e\x02\u{26d}\
	\u{270}\x07\x44\x02\x02\u{26e}\u{26f}\x07\u{e9}\x02\x02\u{26f}\u{271}\x07\
	\u{113}\x02\x02\u{270}\u{26e}\x03\x02\x02\x02\u{270}\u{271}\x03\x02\x02\
	\x02\u{271}\u{276}\x03\x02\x02\x02\u{272}\u{274}\x07\u{8e}\x02\x02\u{273}\
	\u{272}\x03\x02\x02\x02\u{273}\u{274}\x03\x02\x02\x02\u{274}\u{275}\x03\
	\x02\x02\x02\u{275}\u{277}\x09\x03\x02\x02\u{276}\u{273}\x03\x02\x02\x02\
	\u{276}\u{277}\x03\x02\x02\x02\u{277}\u{279}\x03\x02\x02\x02\u{278}\u{27a}\
	\x07\u{c7}\x02\x02\u{279}\u{278}\x03\x02\x02\x02\u{279}\u{27a}\x03\x02\x02\
	\x02\u{27a}\u{27b}\x03\x02\x02\x02\u{27b}\u{27f}\x07\u{175}\x02\x02\u{27c}\
	\u{27d}\x07\u{97}\x02\x02\u{27d}\u{27e}\x07\u{de}\x02\x02\u{27e}\u{280}\
	\x07\x76\x02\x02\u{27f}\u{27c}\x03\x02\x02\x02\u{27f}\u{280}\x03\x02\x02\
	\x02\u{280}\u{281}\x03\x02\x02\x02\u{281}\u{290}\x05\x10\x09\x02\u{282}\
	\u{283}\x07\u{183}\x02\x02\u{283}\u{288}\x05\u{84}\x43\x02\u{284}\u{285}\
	\x07\x38\x02\x02\u{285}\u{287}\x05\u{84}\x43\x02\u{286}\u{284}\x03\x02\x02\
	\x02\u{287}\u{28a}\x03\x02\x02\x02\u{288}\u{286}\x03\x02\x02\x02\u{288}\
	\u{289}\x03\x02\x02\x02\u{289}\u{28c}\x03\x02\x02\x02\u{28a}\u{288}\x03\
	\x02\x02\x02\u{28b}\u{28d}\x07\x38\x02\x02\u{28c}\u{28b}\x03\x02\x02\x02\
	\u{28c}\u{28d}\x03\x02\x02\x02\u{28d}\u{28e}\x03\x02\x02\x02\u{28e}\u{28f}\
	\x07\u{184}\x02\x02\u{28f}\u{291}\x03\x02\x02\x02\u{290}\u{282}\x03\x02\
	\x02\x02\u{290}\u{291}\x03\x02\x02\x02\u{291}\u{2a1}\x03\x02\x02\x02\u{292}\
	\u{2a2}\x05\x1a\x0e\x02\u{293}\u{29b}\x05\u{180}\u{c1}\x02\u{294}\u{29b}\
	\x05\x16\x0c\x02\u{295}\u{296}\x07\u{f3}\x02\x02\u{296}\u{297}\x07\u{e4}\
	\x02\x02\u{297}\u{29b}\x05\u{1a6}\u{d4}\x02\u{298}\u{299}\x07\u{14a}\x02\
	\x02\u{299}\u{29b}\x05\u{9c}\x4f\x02\u{29a}\u{293}\x03\x02\x02\x02\u{29a}\
	\u{294}\x03\x02\x02\x02\u{29a}\u{295}\x03\x02\x02\x02\u{29a}\u{298}\x03\
	\x02\x02\x02\u{29b}\u{29e}\x03\x02\x02\x02\u{29c}\u{29a}\x03\x02\x02\x02\
	\u{29c}\u{29d}\x03\x02\x02\x02\u{29d}\u{29f}\x03\x02\x02\x02\u{29e}\u{29c}\
	\x03\x02\x02\x02\u{29f}\u{2a0}\x07\x14\x02\x02\u{2a0}\u{2a2}\x05\x7a\x3e\
	\x02\u{2a1}\u{292}\x03\x02\x02\x02\u{2a1}\u{29c}\x03\x02\x02\x02\u{2a2}\
	\u{3e0}\x03\x02\x02\x02\u{2a3}\u{2a4}\x07\x62\x02\x02\u{2a4}\u{3e0}\x05\
	\u{192}\u{ca}\x02\u{2a5}\u{2a6}\x07\u{130}\x02\x02\u{2a6}\u{2a7}\x07\x37\
	\x02\x02\u{2a7}\u{2a8}\x07\u{88}\x02\x02\u{2a8}\u{3e0}\x05\u{192}\u{ca}\
	\x02\u{2a9}\u{2ac}\x07\x44\x02\x02\u{2aa}\u{2ab}\x07\u{e9}\x02\x02\u{2ab}\
	\u{2ad}\x07\u{113}\x02\x02\u{2ac}\u{2aa}\x03\x02\x02\x02\u{2ac}\u{2ad}\x03\
	\x02\x02\x02\u{2ad}\u{2af}\x03\x02\x02\x02\u{2ae}\u{2b0}\x07\x7a\x02\x02\
	\u{2af}\u{2ae}\x03\x02\x02\x02\u{2af}\u{2b0}\x03\x02\x02\x02\u{2b0}\u{2b1}\
	\x03\x02\x02\x02\u{2b1}\u{2b5}\x07\u{8b}\x02\x02\u{2b2}\u{2b4}\x0a\x02\x02\
	\x02\u{2b3}\u{2b2}\x03\x02\x02\x02\u{2b4}\u{2b7}\x03\x02\x02\x02\u{2b5}\
	\u{2b3}\x03\x02\x02\x02\u{2b5}\u{2b6}\x03\x02\x02\x02\u{2b6}\u{3e0}\x03\
	\x02\x02\x02\u{2b7}\u{2b5}\x03\x02\x02\x02\u{2b8}\u{2bc}\x07\u{c8}\x02\x02\
	\u{2b9}\u{2bb}\x0a\x02\x02\x02\u{2ba}\u{2b9}\x03\x02\x02\x02\u{2bb}\u{2be}\
	\x03\x02\x02\x02\u{2bc}\u{2ba}\x03\x02\x02\x02\u{2bc}\u{2bd}\x03\x02\x02\
	\x02\u{2bd}\u{3e0}\x03\x02\x02\x02\u{2be}\u{2bc}\x03\x02\x02\x02\u{2bf}\
	\u{2c3}\x07\u{12d}\x02\x02\u{2c0}\u{2c2}\x0a\x02\x02\x02\u{2c1}\u{2c0}\x03\
	\x02\x02\x02\u{2c2}\u{2c5}\x03\x02\x02\x02\u{2c3}\u{2c1}\x03\x02\x02\x02\
	\u{2c3}\u{2c4}\x03\x02\x02\x02\u{2c4}\u{3e0}\x03\x02\x02\x02\u{2c5}\u{2c3}\
	\x03\x02\x02\x02\u{2c6}\u{2c9}\x07\x44\x02\x02\u{2c7}\u{2c8}\x07\u{e9}\x02\
	\x02\u{2c8}\u{2ca}\x07\u{113}\x02\x02\u{2c9}\u{2c7}\x03\x02\x02\x02\u{2c9}\
	\u{2ca}\x03\x02\x02\x02\u{2ca}\u{2cb}\x03\x02\x02\x02\u{2cb}\u{2cf}\x07\
	\u{124}\x02\x02\u{2cc}\u{2ce}\x0a\x02\x02\x02\u{2cd}\u{2cc}\x03\x02\x02\
	\x02\u{2ce}\u{2d1}\x03\x02\x02\x02\u{2cf}\u{2cd}\x03\x02\x02\x02\u{2cf}\
	\u{2d0}\x03\x02\x02\x02\u{2d0}\u{3e0}\x03\x02\x02\x02\u{2d1}\u{2cf}\x03\
	\x02\x02\x02\u{2d2}\u{2d6}\x07\x6c\x02\x02\u{2d3}\u{2d5}\x0a\x02\x02\x02\
	\u{2d4}\u{2d3}\x03\x02\x02\x02\u{2d5}\u{2d8}\x03\x02\x02\x02\u{2d6}\u{2d4}\
	\x03\x02\x02\x02\u{2d6}\u{2d7}\x03\x02\x02\x02\u{2d7}\u{3e0}\x03\x02\x02\
	\x02\u{2d8}\u{2d6}\x03\x02\x02\x02\u{2d9}\u{2dd}\x07\x5f\x02\x02\u{2da}\
	\u{2dc}\x0a\x02\x02\x02\u{2db}\u{2da}\x03\x02\x02\x02\u{2dc}\u{2df}\x03\
	\x02\x02\x02\u{2dd}\u{2db}\x03\x02\x02\x02\u{2dd}\u{2de}\x03\x02\x02\x02\
	\u{2de}\u{3e0}\x03\x02\x02\x02\u{2df}\u{2dd}\x03\x02\x02\x02\u{2e0}\u{2e4}\
	\x07\u{160}\x02\x02\u{2e1}\u{2e3}\x0a\x02\x02\x02\u{2e2}\u{2e1}\x03\x02\
	\x02\x02\u{2e3}\u{2e6}\x03\x02\x02\x02\u{2e4}\u{2e2}\x03\x02\x02\x02\u{2e4}\
	\u{2e5}\x03\x02\x02\x02\u{2e5}\u{3e0}\x03\x02\x02\x02\u{2e6}\u{2e4}\x03\
	\x02\x02\x02\u{2e7}\u{2eb}\x07\x39\x02\x02\u{2e8}\u{2ea}\x0a\x02\x02\x02\
	\u{2e9}\u{2e8}\x03\x02\x02\x02\u{2ea}\u{2ed}\x03\x02\x02\x02\u{2eb}\u{2e9}\
	\x03\x02\x02\x02\u{2eb}\u{2ec}\x03\x02\x02\x02\u{2ec}\u{3e0}\x03\x02\x02\
	\x02\u{2ed}\u{2eb}\x03\x02\x02\x02\u{2ee}\u{2ef}\x07\x0a\x02\x02\u{2ef}\
	\u{2f2}\x07\u{146}\x02\x02\u{2f0}\u{2f1}\x07\u{97}\x02\x02\u{2f1}\u{2f3}\
	\x07\x76\x02\x02\u{2f2}\u{2f0}\x03\x02\x02\x02\u{2f2}\u{2f3}\x03\x02\x02\
	\x02\u{2f3}\u{2f4}\x03\x02\x02\x02\u{2f4}\u{2f5}\x05\u{192}\u{ca}\x02\u{2f5}\
	\u{2f6}\x07\u{110}\x02\x02\u{2f6}\u{2f7}\x07\u{158}\x02\x02\u{2f7}\u{2f8}\
	\x05\u{192}\u{ca}\x02\u{2f8}\u{3e0}\x03\x02\x02\x02\u{2f9}\u{2fa}\x07\x0a\
	\x02\x02\u{2fa}\u{2fd}\x07\u{146}\x02\x02\u{2fb}\u{2fc}\x07\u{97}\x02\x02\
	\u{2fc}\u{2fe}\x07\x76\x02\x02\u{2fd}\u{2fb}\x03\x02\x02\x02\u{2fd}\u{2fe}\
	\x03\x02\x02\x02\u{2fe}\u{2ff}\x03\x02\x02\x02\u{2ff}\u{300}\x05\u{192}\
	\u{ca}\x02\u{300}\u{301}\x07\x07\x02\x02\u{301}\u{305}\x07\x36\x02\x02\u{302}\
	\u{303}\x07\u{97}\x02\x02\u{303}\u{304}\x07\u{de}\x02\x02\u{304}\u{306}\
	\x07\x76\x02\x02\u{305}\u{302}\x03\x02\x02\x02\u{305}\u{306}\x03\x02\x02\
	\x02\u{306}\u{307}\x03\x02\x02\x02\u{307}\u{308}\x05\u{82}\x42\x02\u{308}\
	\u{3e0}\x03\x02\x02\x02\u{309}\u{30a}\x07\x0a\x02\x02\u{30a}\u{30d}\x07\
	\u{146}\x02\x02\u{30b}\u{30c}\x07\u{97}\x02\x02\u{30c}\u{30e}\x07\x76\x02\
	\x02\u{30d}\u{30b}\x03\x02\x02\x02\u{30d}\u{30e}\x03\x02\x02\x02\u{30e}\
	\u{30f}\x03\x02\x02\x02\u{30f}\u{310}\x05\u{192}\u{ca}\x02\u{310}\u{311}\
	\x07\u{110}\x02\x02\u{311}\u{314}\x07\x36\x02\x02\u{312}\u{313}\x07\u{97}\
	\x02\x02\u{313}\u{315}\x07\x76\x02\x02\u{314}\u{312}\x03\x02\x02\x02\u{314}\
	\u{315}\x03\x02\x02\x02\u{315}\u{316}\x03\x02\x02\x02\u{316}\u{317}\x05\
	\u{19c}\u{cf}\x02\u{317}\u{318}\x07\u{158}\x02\x02\u{318}\u{319}\x05\u{19c}\
	\u{cf}\x02\u{319}\u{3e0}\x03\x02\x02\x02\u{31a}\u{31b}\x07\x0a\x02\x02\u{31b}\
	\u{31e}\x07\u{146}\x02\x02\u{31c}\u{31d}\x07\u{97}\x02\x02\u{31d}\u{31f}\
	\x07\x76\x02\x02\u{31e}\u{31c}\x03\x02\x02\x02\u{31e}\u{31f}\x03\x02\x02\
	\x02\u{31f}\u{320}\x03\x02\x02\x02\u{320}\u{321}\x05\u{192}\u{ca}\x02\u{321}\
	\u{322}\x07\x6c\x02\x02\u{322}\u{325}\x07\x36\x02\x02\u{323}\u{324}\x07\
	\u{97}\x02\x02\u{324}\u{326}\x07\x76\x02\x02\u{325}\u{323}\x03\x02\x02\x02\
	\u{325}\u{326}\x03\x02\x02\x02\u{326}\u{327}\x03\x02\x02\x02\u{327}\u{328}\
	\x05\u{192}\u{ca}\x02\u{328}\u{3e0}\x03\x02\x02\x02\u{329}\u{32a}\x07\x0a\
	\x02\x02\u{32a}\u{32d}\x07\u{146}\x02\x02\u{32b}\u{32c}\x07\u{97}\x02\x02\
	\u{32c}\u{32e}\x07\x76\x02\x02\u{32d}\u{32b}\x03\x02\x02\x02\u{32d}\u{32e}\
	\x03\x02\x02\x02\u{32e}\u{32f}\x03\x02\x02\x02\u{32f}\u{330}\x05\u{192}\
	\u{ca}\x02\u{330}\u{331}\x07\x0a\x02\x02\u{331}\u{332}\x07\x36\x02\x02\u{332}\
	\u{333}\x05\u{19c}\u{cf}\x02\u{333}\u{334}\x07\u{12d}\x02\x02\u{334}\u{335}\
	\x07\x4f\x02\x02\u{335}\u{336}\x07\u{162}\x02\x02\u{336}\u{337}\x05\u{17a}\
	\u{be}\x02\u{337}\u{3e0}\x03\x02\x02\x02\u{338}\u{339}\x07\x0a\x02\x02\u{339}\
	\u{33a}\x07\u{146}\x02\x02\u{33a}\u{33b}\x05\u{192}\u{ca}\x02\u{33b}\u{33c}\
	\x07\u{12d}\x02\x02\u{33c}\u{33d}\x07\x17\x02\x02\u{33d}\u{33e}\x05\u{19a}\
	\u{ce}\x02\u{33e}\u{3e0}\x03\x02\x02\x02\u{33f}\u{340}\x07\x0a\x02\x02\u{340}\
	\u{341}\x07\u{146}\x02\x02\u{341}\u{342}\x05\u{192}\u{ca}\x02\u{342}\u{343}\
	\x07\u{12d}\x02\x02\u{343}\u{344}\x07\u{fe}\x02\x02\u{344}\u{345}\x05\u{9e}\
	\x50\x02\u{345}\u{3e0}\x03\x02\x02\x02\u{346}\u{347}\x07\x0a\x02\x02\u{347}\
	\u{348}\x07\u{146}\x02\x02\u{348}\u{349}\x05\u{192}\u{ca}\x02\u{349}\u{34a}\
	\x07\x75\x02\x02\u{34a}\u{35a}\x05\u{19c}\u{cf}\x02\u{34b}\u{354}\x07\u{183}\
	\x02\x02\u{34c}\u{351}\x05\u{150}\u{a9}\x02\u{34d}\u{34e}\x07\x38\x02\x02\
	\u{34e}\u{350}\x05\u{150}\u{a9}\x02\u{34f}\u{34d}\x03\x02\x02\x02\u{350}\
	\u{353}\x03\x02\x02\x02\u{351}\u{34f}\x03\x02\x02\x02\u{351}\u{352}\x03\
	\x02\x02\x02\u{352}\u{355}\x03\x02\x02\x02\u{353}\u{351}\x03\x02\x02\x02\
	\u{354}\u{34c}\x03\x02\x02\x02\u{354}\u{355}\x03\x02\x02\x02\u{355}\u{357}\
	\x03\x02\x02\x02\u{356}\u{358}\x07\x38\x02\x02\u{357}\u{356}\x03\x02\x02\
	\x02\u{357}\u{358}\x03\x02\x02\x02\u{358}\u{359}\x03\x02\x02\x02\u{359}\
	\u{35b}\x07\u{184}\x02\x02\u{35a}\u{34b}\x03\x02\x02\x02\u{35a}\u{35b}\x03\
	\x02\x02\x02\u{35b}\u{35e}\x03\x02\x02\x02\u{35c}\u{35d}\x07\u{17b}\x02\
	\x02\u{35d}\u{35f}\x05\u{140}\u{a1}\x02\u{35e}\u{35c}\x03\x02\x02\x02\u{35e}\
	\u{35f}\x03\x02\x02\x02\u{35f}\u{3e0}\x03\x02\x02\x02\u{360}\u{364}\x07\
	\x0c\x02\x02\u{361}\u{363}\x0a\x02\x02\x02\u{362}\u{361}\x03\x02\x02\x02\
	\u{363}\u{366}\x03\x02\x02\x02\u{364}\u{362}\x03\x02\x02\x02\u{364}\u{365}\
	\x03\x02\x02\x02\u{365}\u{3e0}\x03\x02\x02\x02\u{366}\u{364}\x03\x02\x02\
	\x02\u{367}\u{368}\x07\x0a\x02\x02\u{368}\u{369}\x07\u{175}\x02\x02\u{369}\
	\u{36a}\x05\u{192}\u{ca}\x02\u{36a}\u{36b}\x07\u{110}\x02\x02\u{36b}\u{36c}\
	\x07\u{158}\x02\x02\u{36c}\u{36d}\x05\u{192}\u{ca}\x02\u{36d}\u{3e0}\x03\
	\x02\x02\x02\u{36e}\u{36f}\x07\x0a\x02\x02\u{36f}\u{370}\x07\u{175}\x02\
	\x02\u{370}\u{371}\x05\u{192}\u{ca}\x02\u{371}\u{372}\x07\u{12d}\x02\x02\
	\u{372}\u{373}\x07\x17\x02\x02\u{373}\u{374}\x05\u{19a}\u{ce}\x02\u{374}\
	\u{3e0}\x03\x02\x02\x02\u{375}\u{376}\x07\x44\x02\x02\u{376}\u{37a}\x07\
	\u{11c}\x02\x02\u{377}\u{379}\x0a\x02\x02\x02\u{378}\u{377}\x03\x02\x02\
	\x02\u{379}\u{37c}\x03\x02\x02\x02\u{37a}\u{378}\x03\x02\x02\x02\u{37a}\
	\u{37b}\x03\x02\x02\x02\u{37b}\u{3e0}\x03\x02\x02\x02\u{37c}\u{37a}\x03\
	\x02\x02\x02\u{37d}\u{381}\x07\u{8f}\x02\x02\u{37e}\u{380}\x0a\x02\x02\x02\
	\u{37f}\u{37e}\x03\x02\x02\x02\u{380}\u{383}\x03\x02\x02\x02\u{381}\u{37f}\
	\x03\x02\x02\x02\u{381}\u{382}\x03\x02\x02\x02\u{382}\u{3e0}\x03\x02\x02\
	\x02\u{383}\u{381}\x03\x02\x02\x02\u{384}\u{388}\x07\u{119}\x02\x02\u{385}\
	\u{387}\x0a\x02\x02\x02\u{386}\u{385}\x03\x02\x02\x02\u{387}\u{38a}\x03\
	\x02\x02\x02\u{388}\u{386}\x03\x02\x02\x02\u{388}\u{389}\x03\x02\x02\x02\
	\u{389}\u{3e0}\x03\x02\x02\x02\u{38a}\u{388}\x03\x02\x02\x02\u{38b}\u{38d}\
	\x07\x77\x02\x02\u{38c}\u{38e}\x09\x04\x02\x02\u{38d}\u{38c}\x03\x02\x02\
	\x02\u{38d}\u{38e}\x03\x02\x02\x02\u{38e}\u{38f}\x03\x02\x02\x02\u{38f}\
	\u{3e0}\x05\x0c\x07\x02\u{390}\u{394}\x07\u{130}\x02\x02\u{391}\u{393}\x0a\
	\x02\x02\x02\u{392}\u{391}\x03\x02\x02\x02\u{393}\u{396}\x03\x02\x02\x02\
	\u{394}\u{392}\x03\x02\x02\x02\u{394}\u{395}\x03\x02\x02\x02\u{395}\u{3e0}\
	\x03\x02\x02\x02\u{396}\u{394}\x03\x02\x02\x02\u{397}\u{39b}\x07\u{114}\
	\x02\x02\u{398}\u{39a}\x0a\x02\x02\x02\u{399}\u{398}\x03\x02\x02\x02\u{39a}\
	\u{39d}\x03\x02\x02\x02\u{39b}\u{399}\x03\x02\x02\x02\u{39b}\u{39c}\x03\
	\x02\x02\x02\u{39c}\u{3e0}\x03\x02\x02\x02\u{39d}\u{39b}\x03\x02\x02\x02\
	\u{39e}\u{3a2}\x07\x3a\x02\x02\u{39f}\u{3a1}\x0a\x02\x02\x02\u{3a0}\u{39f}\
	\x03\x02\x02\x02\u{3a1}\u{3a4}\x03\x02\x02\x02\u{3a2}\u{3a0}\x03\x02\x02\
	\x02\u{3a2}\u{3a3}\x03\x02\x02\x02\u{3a3}\u{3e0}\x03\x02\x02\x02\u{3a4}\
	\u{3a2}\x03\x02\x02\x02\u{3a5}\u{3a9}\x07\u{11e}\x02\x02\u{3a6}\u{3a8}\x0a\
	\x02\x02\x02\u{3a7}\u{3a6}\x03\x02\x02\x02\u{3a8}\u{3ab}\x03\x02\x02\x02\
	\u{3a9}\u{3a7}\x03\x02\x02\x02\u{3a9}\u{3aa}\x03\x02\x02\x02\u{3aa}\u{3e0}\
	\x03\x02\x02\x02\u{3ab}\u{3a9}\x03\x02\x02\x02\u{3ac}\u{3b0}\x07\x75\x02\
	\x02\u{3ad}\u{3af}\x0a\x02\x02\x02\u{3ae}\u{3ad}\x03\x02\x02\x02\u{3af}\
	\u{3b2}\x03\x02\x02\x02\u{3b0}\u{3ae}\x03\x02\x02\x02\u{3b0}\u{3b1}\x03\
	\x02\x02\x02\u{3b1}\u{3e0}\x03\x02\x02\x02\u{3b2}\u{3b0}\x03\x02\x02\x02\
	\u{3b3}\u{3b7}\x07\u{16c}\x02\x02\u{3b4}\u{3b6}\x0a\x02\x02\x02\u{3b5}\u{3b4}\
	\x03\x02\x02\x02\u{3b6}\u{3b9}\x03\x02\x02\x02\u{3b7}\u{3b5}\x03\x02\x02\
	\x02\u{3b7}\u{3b8}\x03\x02\x02\x02\u{3b8}\u{3e0}\x03\x02\x02\x02\u{3b9}\
	\u{3b7}\x03\x02\x02\x02\u{3ba}\u{3bb}\x07\x44\x02\x02\u{3bb}\u{3bf}\x07\
	\x51\x02\x02\u{3bc}\u{3be}\x0a\x02\x02\x02\u{3bd}\u{3bc}\x03\x02\x02\x02\
	\u{3be}\u{3c1}\x03\x02\x02\x02\u{3bf}\u{3bd}\x03\x02\x02\x02\u{3bf}\u{3c0}\
	\x03\x02\x02\x02\u{3c0}\u{3e0}\x03\x02\x02\x02\u{3c1}\u{3bf}\x03\x02\x02\
	\x02\u{3c2}\u{3c3}\x07\x44\x02\x02\u{3c3}\u{3c7}\x07\x29\x02\x02\u{3c4}\
	\u{3c6}\x0a\x02\x02\x02\u{3c5}\u{3c4}\x03\x02\x02\x02\u{3c6}\u{3c9}\x03\
	\x02\x02\x02\u{3c7}\u{3c5}\x03\x02\x02\x02\u{3c7}\u{3c8}\x03\x02\x02\x02\
	\u{3c8}\u{3e0}\x03\x02\x02\x02\u{3c9}\u{3c7}\x03\x02\x02\x02\u{3ca}\u{3ce}\
	\x07\x0a\x02\x02\u{3cb}\u{3cd}\x0a\x02\x02\x02\u{3cc}\u{3cb}\x03\x02\x02\
	\x02\u{3cd}\u{3d0}\x03\x02\x02\x02\u{3ce}\u{3cc}\x03\x02\x02\x02\u{3ce}\
	\u{3cf}\x03\x02\x02\x02\u{3cf}\u{3e0}\x03\x02\x02\x02\u{3d0}\u{3ce}\x03\
	\x02\x02\x02\u{3d1}\u{3d5}\x07\u{16d}\x02\x02\u{3d2}\u{3d4}\x0a\x02\x02\
	\x02\u{3d3}\u{3d2}\x03\x02\x02\x02\u{3d4}\u{3d7}\x03\x02\x02\x02\u{3d5}\
	\u{3d3}\x03\x02\x02\x02\u{3d5}\u{3d6}\x03\x02\x02\x02\u{3d6}\u{3e0}\x03\
	\x02\x02\x02\u{3d7}\u{3d5}\x03\x02\x02\x02\u{3d8}\u{3dc}\x07\u{e6}\x02\x02\
	\u{3d9}\u{3db}\x0a\x02\x02\x02\u{3da}\u{3d9}\x03\x02\x02\x02\u{3db}\u{3de}\
	\x03\x02\x02\x02\u{3dc}\u{3da}\x03\x02\x02\x02\u{3dc}\u{3dd}\x03\x02\x02\
	\x02\u{3dd}\u{3e0}\x03\x02\x02\x02\u{3de}\u{3dc}\x03\x02\x02\x02\u{3df}\
	\u{1d5}\x03\x02\x02\x02\u{3df}\u{1d6}\x03\x02\x02\x02\u{3df}\u{1d8}\x03\
	\x02\x02\x02\u{3df}\u{1dd}\x03\x02\x02\x02\u{3df}\u{1ea}\x03\x02\x02\x02\
	\u{3df}\u{1f1}\x03\x02\x02\x02\u{3df}\u{1f8}\x03\x02\x02\x02\u{3df}\u{1fb}\
	\x03\x02\x02\x02\u{3df}\u{21b}\x03\x02\x02\x02\u{3df}\u{243}\x03\x02\x02\
	\x02\u{3df}\u{254}\x03\x02\x02\x02\u{3df}\u{26a}\x03\x02\x02\x02\u{3df}\
	\u{26d}\x03\x02\x02\x02\u{3df}\u{2a3}\x03\x02\x02\x02\u{3df}\u{2a5}\x03\
	\x02\x02\x02\u{3df}\u{2a9}\x03\x02\x02\x02\u{3df}\u{2b8}\x03\x02\x02\x02\
	\u{3df}\u{2bf}\x03\x02\x02\x02\u{3df}\u{2c6}\x03\x02\x02\x02\u{3df}\u{2d2}\
	\x03\x02\x02\x02\u{3df}\u{2d9}\x03\x02\x02\x02\u{3df}\u{2e0}\x03\x02\x02\
	\x02\u{3df}\u{2e7}\x03\x02\x02\x02\u{3df}\u{2ee}\x03\x02\x02\x02\u{3df}\
	\u{2f9}\x03\x02\x02\x02\u{3df}\u{309}\x03\x02\x02\x02\u{3df}\u{31a}\x03\
	\x02\x02\x02\u{3df}\u{329}\x03\x02\x02\x02\u{3df}\u{338}\x03\x02\x02\x02\
	\u{3df}\u{33f}\x03\x02\x02\x02\u{3df}\u{346}\x03\x02\x02\x02\u{3df}\u{360}\
	\x03\x02\x02\x02\u{3df}\u{367}\x03\x02\x02\x02\u{3df}\u{36e}\x03\x02\x02\
	\x02\u{3df}\u{375}\x03\x02\x02\x02\u{3df}\u{37d}\x03\x02\x02\x02\u{3df}\
	\u{384}\x03\x02\x02\x02\u{3df}\u{38b}\x03\x02\x02\x02\u{3df}\u{390}\x03\
	\x02\x02\x02\u{3df}\u{397}\x03\x02\x02\x02\u{3df}\u{39e}\x03\x02\x02\x02\
	\u{3df}\u{3a5}\x03\x02\x02\x02\u{3df}\u{3ac}\x03\x02\x02\x02\u{3df}\u{3b3}\
	\x03\x02\x02\x02\u{3df}\u{3ba}\x03\x02\x02\x02\u{3df}\u{3c2}\x03\x02\x02\
	\x02\u{3df}\u{3ca}\x03\x02\x02\x02\u{3df}\u{3d1}\x03\x02\x02\x02\u{3df}\
	\u{3d8}\x03\x02\x02\x02\u{3e0}\x0d\x03\x02\x02\x02\u{3e1}\u{3e6}\x05\x7e\
	\x40\x02\u{3e2}\u{3e3}\x07\x38\x02\x02\u{3e3}\u{3e5}\x05\x7e\x40\x02\u{3e4}\
	\u{3e2}\x03\x02\x02\x02\u{3e5}\u{3e8}\x03\x02\x02\x02\u{3e6}\u{3e4}\x03\
	\x02\x02\x02\u{3e6}\u{3e7}\x03\x02\x02\x02\u{3e7}\x0f\x03\x02\x02\x02\u{3e8}\
	\u{3e6}\x03\x02\x02\x02\u{3e9}\u{3ea}\x07\u{95}\x02\x02\u{3ea}\u{3eb}\x07\
	\u{183}\x02\x02\u{3eb}\u{3ec}\x05\u{13e}\u{a0}\x02\u{3ec}\u{3ed}\x07\u{184}\
	\x02\x02\u{3ed}\u{3f0}\x03\x02\x02\x02\u{3ee}\u{3f0}\x05\u{192}\u{ca}\x02\
	\u{3ef}\u{3e9}\x03\x02\x02\x02\u{3ef}\u{3ee}\x03\x02\x02\x02\u{3f0}\x11\
	\x03\x02\x02\x02\u{3f1}\u{3f2}\x07\u{183}\x02\x02\u{3f2}\u{3f7}\x05\x14\
	\x0b\x02\u{3f3}\u{3f4}\x07\x38\x02\x02\u{3f4}\u{3f6}\x05\x14\x0b\x02\u{3f5}\
	\u{3f3}\x03\x02\x02\x02\u{3f6}\u{3f9}\x03\x02\x02\x02\u{3f7}\u{3f5}\x03\
	\x02\x02\x02\u{3f7}\u{3f8}\x03\x02\x02\x02\u{3f8}\u{3fa}\x03\x02\x02\x02\
	\u{3f9}\u{3f7}\x03\x02\x02\x02\u{3fa}\u{3fb}\x07\u{184}\x02\x02\u{3fb}\x13\
	\x03\x02\x02\x02\u{3fc}\u{3fe}\x05\u{19c}\u{cf}\x02\u{3fd}\u{3ff}\x05\u{180}\
	\u{c1}\x02\u{3fe}\u{3fd}\x03\x02\x02\x02\u{3fe}\u{3ff}\x03\x02\x02\x02\u{3ff}\
	\x15\x03\x02\x02\x02\u{400}\u{401}\x07\u{17e}\x02\x02\u{401}\u{407}\x07\
	\u{124}\x02\x02\u{402}\u{408}\x07\x1d\x02\x02\u{403}\u{408}\x07\x3d\x02\
	\x02\u{404}\u{408}\x07\x71\x02\x02\u{405}\u{406}\x07\u{162}\x02\x02\u{406}\
	\u{408}\x07\x71\x02\x02\u{407}\u{402}\x03\x02\x02\x02\u{407}\u{403}\x03\
	\x02\x02\x02\u{407}\u{404}\x03\x02\x02\x02\u{407}\u{405}\x03\x02\x02\x02\
	\u{408}\x17\x03\x02\x02\x02\u{409}\u{40a}\x07\u{e8}\x02\x02\u{40a}\u{422}\
	\x05\u{9c}\x4f\x02\u{40b}\u{40c}\x07\u{f3}\x02\x02\u{40c}\u{40d}\x07\x22\
	\x02\x02\u{40d}\u{40e}\x07\u{183}\x02\x02\u{40e}\u{413}\x05\x1c\x0f\x02\
	\u{40f}\u{410}\x07\x38\x02\x02\u{410}\u{412}\x05\x1c\x0f\x02\u{411}\u{40f}\
	\x03\x02\x02\x02\u{412}\u{415}\x03\x02\x02\x02\u{413}\u{411}\x03\x02\x02\
	\x02\u{413}\u{414}\x03\x02\x02\x02\u{414}\u{416}\x03\x02\x02\x02\u{415}\
	\u{413}\x03\x02\x02\x02\u{416}\u{417}\x07\u{184}\x02\x02\u{417}\u{422}\x03\
	\x02\x02\x02\u{418}\u{422}\x05\x24\x13\x02\u{419}\u{422}\x05\x26\x14\x02\
	\u{41a}\u{422}\x05\x28\x15\x02\u{41b}\u{422}\x05\x2e\x18\x02\u{41c}\u{422}\
	\x05\x30\x19\x02\u{41d}\u{422}\x05\x36\x1c\x02\u{41e}\u{422}\x05\u{180}\
	\u{c1}\x02\u{41f}\u{420}\x07\u{14a}\x02\x02\u{420}\u{422}\x05\u{9c}\x4f\
	\x02\u{421}\u{409}\x03\x02\x02\x02\u{421}\u{40b}\x03\x02\x02\x02\u{421}\
	\u{418}\x03\x02\x02\x02\u{421}\u{419}\x03\x02\x02\x02\u{421}\u{41a}\x03\
	\x02\x02\x02\u{421}\u{41b}\x03\x02\x02\x02\u{421}\u{41c}\x03\x02\x02\x02\
	\u{421}\u{41d}\x03\x02\x02\x02\u{421}\u{41e}\x03\x02\x02\x02\u{421}\u{41f}\
	\x03\x02\x02\x02\u{422}\u{425}\x03\x02\x02\x02\u{423}\u{421}\x03\x02\x02\
	\x02\u{423}\u{424}\x03\x02\x02\x02\u{424}\x19\x03\x02\x02\x02\u{425}\u{423}\
	\x03\x02\x02\x02\u{426}\u{427}\x07\u{16f}\x02\x02\u{427}\u{437}\x05\u{192}\
	\u{ca}\x02\u{428}\u{429}\x07\u{e8}\x02\x02\u{429}\u{42a}\x07\u{183}\x02\
	\x02\u{42a}\u{42b}\x05\u{19c}\u{cf}\x02\u{42b}\u{432}\x07\u{1a4}\x02\x02\
	\u{42c}\u{42d}\x07\x38\x02\x02\u{42d}\u{42e}\x05\u{19c}\u{cf}\x02\u{42e}\
	\u{42f}\x07\u{1a4}\x02\x02\u{42f}\u{431}\x03\x02\x02\x02\u{430}\u{42c}\x03\
	\x02\x02\x02\u{431}\u{434}\x03\x02\x02\x02\u{432}\u{430}\x03\x02\x02\x02\
	\u{432}\u{433}\x03\x02\x02\x02\u{433}\u{435}\x03\x02\x02\x02\u{434}\u{432}\
	\x03\x02\x02\x02\u{435}\u{436}\x07\u{184}\x02\x02\u{436}\u{438}\x03\x02\
	\x02\x02\u{437}\u{428}\x03\x02\x02\x02\u{437}\u{438}\x03\x02\x02\x02\u{438}\
	\x1b\x03\x02\x02\x02\u{439}\u{43c}\x05\x1e\x10\x02\u{43a}\u{43c}\x05\x22\
	\x12\x02\u{43b}\u{439}\x03\x02\x02\x02\u{43b}\u{43a}\x03\x02\x02\x02\u{43c}\
	\x1d\x03\x02\x02\x02\u{43d}\u{44b}\x05\u{192}\u{ca}\x02\u{43e}\u{43f}\x05\
	\u{19c}\u{cf}\x02\u{43f}\u{440}\x07\u{183}\x02\x02\u{440}\u{445}\x05\x20\
	\x11\x02\u{441}\u{442}\x07\x38\x02\x02\u{442}\u{444}\x05\x20\x11\x02\u{443}\
	\u{441}\x03\x02\x02\x02\u{444}\u{447}\x03\x02\x02\x02\u{445}\u{443}\x03\
	\x02\x02\x02\u{445}\u{446}\x03\x02\x02\x02\u{446}\u{448}\x03\x02\x02\x02\
	\u{447}\u{445}\x03\x02\x02\x02\u{448}\u{449}\x07\u{184}\x02\x02\u{449}\u{44b}\
	\x03\x02\x02\x02\u{44a}\u{43d}\x03\x02\x02\x02\u{44a}\u{43e}\x03\x02\x02\
	\x02\u{44b}\x1f\x03\x02\x02\x02\u{44c}\u{44f}\x05\u{192}\u{ca}\x02\u{44d}\
	\u{44f}\x05\u{154}\u{ab}\x02\u{44e}\u{44c}\x03\x02\x02\x02\u{44e}\u{44d}\
	\x03\x02\x02\x02\u{44f}\x21\x03\x02\x02\x02\u{450}\u{451}\x05\u{19c}\u{cf}\
	\x02\u{451}\u{454}\x05\u{17a}\u{be}\x02\u{452}\u{453}\x07\u{de}\x02\x02\
	\u{453}\u{455}\x07\u{df}\x02\x02\u{454}\u{452}\x03\x02\x02\x02\u{454}\u{455}\
	\x03\x02\x02\x02\u{455}\u{457}\x03\x02\x02\x02\u{456}\u{458}\x05\u{180}\
	\u{c1}\x02\u{457}\u{456}\x03\x02\x02\x02\u{457}\u{458}\x03\x02\x02\x02\u{458}\
	\x23\x03\x02\x02\x02\u{459}\u{45a}\x07\u{132}\x02\x02\u{45a}\u{45b}\x07\
	\x22\x02\x02\u{45b}\u{45c}\x05\u{1a6}\u{d4}\x02\u{45c}\u{45f}\x07\u{e4}\
	\x02\x02\u{45d}\u{460}\x05\x2a\x16\x02\u{45e}\u{460}\x05\x2c\x17\x02\u{45f}\
	\u{45d}\x03\x02\x02\x02\u{45f}\u{45e}\x03\x02\x02\x02\u{460}\u{464}\x03\
	\x02\x02\x02\u{461}\u{462}\x07\u{13c}\x02\x02\u{462}\u{463}\x07\x14\x02\
	\x02\u{463}\u{465}\x07\x65\x02\x02\u{464}\u{461}\x03\x02\x02\x02\u{464}\
	\u{465}\x03\x02\x02\x02\u{465}\x25\x03\x02\x02\x02\u{466}\u{467}\x07\x30\
	\x02\x02\u{467}\u{468}\x07\x22\x02\x02\u{468}\u{469}\x07\u{183}\x02\x02\
	\u{469}\u{46e}\x05\u{192}\u{ca}\x02\u{46a}\u{46b}\x07\x38\x02\x02\u{46b}\
	\u{46d}\x05\u{192}\u{ca}\x02\u{46c}\u{46a}\x03\x02\x02\x02\u{46d}\u{470}\
	\x03\x02\x02\x02\u{46e}\u{46c}\x03\x02\x02\x02\u{46e}\u{46f}\x03\x02\x02\
	\x02\u{46f}\u{471}\x03\x02\x02\x02\u{470}\u{46e}\x03\x02\x02\x02\u{471}\
	\u{472}\x07\u{184}\x02\x02\u{472}\x27\x03\x02\x02\x02\u{473}\u{474}\x07\
	\x31\x02\x02\u{474}\u{475}\x07\x22\x02\x02\u{475}\u{480}\x05\u{1a6}\u{d4}\
	\x02\u{476}\u{477}\x07\u{136}\x02\x02\u{477}\u{478}\x07\x22\x02\x02\u{478}\
	\u{47d}\x05\u{c2}\x62\x02\u{479}\u{47a}\x07\x38\x02\x02\u{47a}\u{47c}\x05\
	\u{c2}\x62\x02\u{47b}\u{479}\x03\x02\x02\x02\u{47c}\u{47f}\x03\x02\x02\x02\
	\u{47d}\u{47b}\x03\x02\x02\x02\u{47d}\u{47e}\x03\x02\x02\x02\u{47e}\u{481}\
	\x03\x02\x02\x02\u{47f}\u{47d}\x03\x02\x02\x02\u{480}\u{476}\x03\x02\x02\
	\x02\u{480}\u{481}\x03\x02\x02\x02\u{481}\u{482}\x03\x02\x02\x02\u{482}\
	\u{483}\x07\u{a8}\x02\x02\u{483}\u{484}\x07\u{1a6}\x02\x02\u{484}\u{485}\
	\x07\x21\x02\x02\u{485}\x29\x03\x02\x02\x02\u{486}\u{487}\x07\u{183}\x02\
	\x02\u{487}\u{48c}\x05\u{154}\u{ab}\x02\u{488}\u{489}\x07\x38\x02\x02\u{489}\
	\u{48b}\x05\u{154}\u{ab}\x02\u{48a}\u{488}\x03\x02\x02\x02\u{48b}\u{48e}\
	\x03\x02\x02\x02\u{48c}\u{48a}\x03\x02\x02\x02\u{48c}\u{48d}\x03\x02\x02\
	\x02\u{48d}\u{48f}\x03\x02\x02\x02\u{48e}\u{48c}\x03\x02\x02\x02\u{48f}\
	\u{490}\x07\u{184}\x02\x02\u{490}\x2b\x03\x02\x02\x02\u{491}\u{492}\x07\
	\u{183}\x02\x02\u{492}\u{497}\x05\x2a\x16\x02\u{493}\u{494}\x07\x38\x02\
	\x02\u{494}\u{496}\x05\x2a\x16\x02\u{495}\u{493}\x03\x02\x02\x02\u{496}\
	\u{499}\x03\x02\x02\x02\u{497}\u{495}\x03\x02\x02\x02\u{497}\u{498}\x03\
	\x02\x02\x02\u{498}\u{49a}\x03\x02\x02\x02\u{499}\u{497}\x03\x02\x02\x02\
	\u{49a}\u{49b}\x07\u{184}\x02\x02\u{49b}\x2d\x03\x02\x02\x02\u{49c}\u{49d}\
	\x07\u{120}\x02\x02\u{49d}\u{49e}\x07\u{86}\x02\x02\u{49e}\u{49f}\x07\u{12a}\
	\x02\x02\u{49f}\u{4a3}\x05\u{162}\u{b2}\x02\u{4a0}\u{4a1}\x07\u{17e}\x02\
	\x02\u{4a1}\u{4a2}\x07\u{12b}\x02\x02\u{4a2}\u{4a4}\x05\u{9c}\x4f\x02\u{4a3}\
	\u{4a0}\x03\x02\x02\x02\u{4a3}\u{4a4}\x03\x02\x02\x02\u{4a4}\u{4ce}\x03\
	\x02\x02\x02\u{4a5}\u{4a6}\x07\u{120}\x02\x02\u{4a6}\u{4a7}\x07\u{86}\x02\
	\x02\u{4a7}\u{4b1}\x07\x60\x02\x02\u{4a8}\u{4a9}\x07\x7e\x02\x02\u{4a9}\
	\u{4aa}\x07\u{14d}\x02\x02\u{4aa}\u{4ab}\x07\x22\x02\x02\u{4ab}\u{4af}\x05\
	\u{162}\u{b2}\x02\u{4ac}\u{4ad}\x07\x70\x02\x02\u{4ad}\u{4ae}\x07\x22\x02\
	\x02\u{4ae}\u{4b0}\x05\u{162}\u{b2}\x02\u{4af}\u{4ac}\x03\x02\x02\x02\u{4af}\
	\u{4b0}\x03\x02\x02\x02\u{4b0}\u{4b2}\x03\x02\x02\x02\u{4b1}\u{4a8}\x03\
	\x02\x02\x02\u{4b1}\u{4b2}\x03\x02\x02\x02\u{4b2}\u{4b8}\x03\x02\x02\x02\
	\u{4b3}\u{4b4}\x07\x35\x02\x02\u{4b4}\u{4b5}\x07\u{ab}\x02\x02\u{4b5}\u{4b6}\
	\x07\u{14d}\x02\x02\u{4b6}\u{4b7}\x07\x22\x02\x02\u{4b7}\u{4b9}\x05\u{162}\
	\u{b2}\x02\u{4b8}\u{4b3}\x03\x02\x02\x02\u{4b8}\u{4b9}\x03\x02\x02\x02\u{4b9}\
	\u{4bf}\x03\x02\x02\x02\u{4ba}\u{4bb}\x07\u{c4}\x02\x02\u{4bb}\u{4bc}\x07\
	\u{af}\x02\x02\u{4bc}\u{4bd}\x07\u{14d}\x02\x02\u{4bd}\u{4be}\x07\x22\x02\
	\x02\u{4be}\u{4c0}\x05\u{162}\u{b2}\x02\u{4bf}\u{4ba}\x03\x02\x02\x02\u{4bf}\
	\u{4c0}\x03\x02\x02\x02\u{4c0}\u{4c5}\x03\x02\x02\x02\u{4c1}\u{4c2}\x07\
	\u{b8}\x02\x02\u{4c2}\u{4c3}\x07\u{14d}\x02\x02\u{4c3}\u{4c4}\x07\x22\x02\
	\x02\u{4c4}\u{4c6}\x05\u{162}\u{b2}\x02\u{4c5}\u{4c1}\x03\x02\x02\x02\u{4c5}\
	\u{4c6}\x03\x02\x02\x02\u{4c6}\u{4cb}\x03\x02\x02\x02\u{4c7}\u{4c8}\x07\
	\u{df}\x02\x02\u{4c8}\u{4c9}\x07\x5d\x02\x02\u{4c9}\u{4ca}\x07\x14\x02\x02\
	\u{4ca}\u{4cc}\x05\u{162}\u{b2}\x02\u{4cb}\u{4c7}\x03\x02\x02\x02\u{4cb}\
	\u{4cc}\x03\x02\x02\x02\u{4cc}\u{4ce}\x03\x02\x02\x02\u{4cd}\u{49c}\x03\
	\x02\x02\x02\u{4cd}\u{4a5}\x03\x02\x02\x02\u{4ce}\x2f\x03\x02\x02\x02\u{4cf}\
	\u{4d0}\x07\u{13c}\x02\x02\u{4d0}\u{4d1}\x07\x14\x02\x02\u{4d1}\u{4d6}\x05\
	\x32\x1a\x02\u{4d2}\u{4d3}\x07\u{13c}\x02\x02\u{4d3}\u{4d4}\x07\x22\x02\
	\x02\u{4d4}\u{4d6}\x05\x34\x1b\x02\u{4d5}\u{4cf}\x03\x02\x02\x02\u{4d5}\
	\u{4d2}\x03\x02\x02\x02\u{4d6}\x31\x03\x02\x02\x02\u{4d7}\u{4d8}\x07\u{a2}\
	\x02\x02\u{4d8}\u{4d9}\x05\u{162}\u{b2}\x02\u{4d9}\u{4da}\x07\u{ed}\x02\
	\x02\u{4da}\u{4db}\x05\u{162}\u{b2}\x02\u{4db}\u{4de}\x03\x02\x02\x02\u{4dc}\
	\u{4de}\x05\u{19c}\u{cf}\x02\u{4dd}\u{4d7}\x03\x02\x02\x02\u{4dd}\u{4dc}\
	\x03\x02\x02\x02\u{4de}\x33\x03\x02\x02\x02\u{4df}\u{4e3}\x05\u{162}\u{b2}\
	\x02\u{4e0}\u{4e1}\x07\u{17e}\x02\x02\u{4e1}\u{4e2}\x07\u{12b}\x02\x02\u{4e2}\
	\u{4e4}\x05\u{9c}\x4f\x02\u{4e3}\u{4e0}\x03\x02\x02\x02\u{4e3}\u{4e4}\x03\
	\x02\x02\x02\u{4e4}\x35\x03\x02\x02\x02\u{4e5}\u{4e6}\x07\u{be}\x02\x02\
	\u{4e6}\u{4e7}\x05\u{162}\u{b2}\x02\u{4e7}\x37\x03\x02\x02\x02\u{4e8}\u{4f0}\
	\x07\x50\x02\x02\u{4e9}\u{4f0}\x07\u{152}\x02\x02\u{4ea}\u{4f0}\x07\u{155}\
	\x02\x02\u{4eb}\u{4f0}\x07\u{156}\x02\x02\u{4ec}\u{4f0}\x07\u{a5}\x02\x02\
	\u{4ed}\u{4f0}\x07\x1c\x02\x02\u{4ee}\u{4f0}\x05\u{19c}\u{cf}\x02\u{4ef}\
	\u{4e8}\x03\x02\x02\x02\u{4ef}\u{4e9}\x03\x02\x02\x02\u{4ef}\u{4ea}\x03\
	\x02\x02\x02\u{4ef}\u{4eb}\x03\x02\x02\x02\u{4ef}\u{4ec}\x03\x02\x02\x02\
	\u{4ef}\u{4ed}\x03\x02\x02\x02\u{4ef}\u{4ee}\x03\x02\x02\x02\u{4f0}\x39\
	\x03\x02\x02\x02\u{4f1}\u{4f2}\x05\x3e\x20\x02\u{4f2}\u{4f3}\x05\x7a\x3e\
	\x02\u{4f3}\u{530}\x03\x02\x02\x02\u{4f4}\u{4f5}\x07\u{88}\x02\x02\u{4f5}\
	\u{4f7}\x05\u{e8}\x75\x02\u{4f6}\u{4f8}\x05\x40\x21\x02\u{4f7}\u{4f6}\x03\
	\x02\x02\x02\u{4f8}\u{4f9}\x03\x02\x02\x02\u{4f9}\u{4f7}\x03\x02\x02\x02\
	\u{4f9}\u{4fa}\x03\x02\x02\x02\u{4fa}\u{530}\x03\x02\x02\x02\u{4fb}\u{4fc}\
	\x07\x5f\x02\x02\u{4fc}\u{4fd}\x07\u{88}\x02\x02\u{4fd}\u{4fe}\x05\x10\x09\
	\x02\u{4fe}\u{500}\x05\x42\x22\x02\u{4ff}\u{501}\x05\x44\x23\x02\u{500}\
	\u{4ff}\x03\x02\x02\x02\u{500}\u{501}\x03\x02\x02\x02\u{501}\u{530}\x03\
	\x02\x02\x02\u{502}\u{503}\x07\u{16c}\x02\x02\u{503}\u{504}\x05\x10\x09\
	\x02\u{504}\u{505}\x05\x42\x22\x02\u{505}\u{507}\x05\x46\x24\x02\u{506}\
	\u{508}\x05\x44\x23\x02\u{507}\u{506}\x03\x02\x02\x02\u{507}\u{508}\x03\
	\x02\x02\x02\u{508}\u{530}\x03\x02\x02\x02\u{509}\u{50d}\x07\u{c8}\x02\x02\
	\u{50a}\u{50b}\x07\u{17e}\x02\x02\u{50b}\u{50c}\x07\u{124}\x02\x02\u{50c}\
	\u{50e}\x07\x71\x02\x02\u{50d}\u{50a}\x03\x02\x02\x02\u{50d}\u{50e}\x03\
	\x02\x02\x02\u{50e}\u{50f}\x03\x02\x02\x02\u{50f}\u{510}\x07\u{a8}\x02\x02\
	\u{510}\u{511}\x05\x10\x09\x02\u{511}\u{512}\x05\x42\x22\x02\u{512}\u{518}\
	\x07\u{16f}\x02\x02\u{513}\u{519}\x05\x10\x09\x02\u{514}\u{515}\x07\u{183}\
	\x02\x02\u{515}\u{516}\x05\x7a\x3e\x02\u{516}\u{517}\x07\u{184}\x02\x02\
	\u{517}\u{519}\x03\x02\x02\x02\u{518}\u{513}\x03\x02\x02\x02\u{518}\u{514}\
	\x03\x02\x02\x02\u{519}\u{51a}\x03\x02\x02\x02\u{51a}\u{51b}\x05\x42\x22\
	\x02\u{51b}\u{51c}\x07\u{e4}\x02\x02\u{51c}\u{520}\x05\u{140}\u{a1}\x02\
	\u{51d}\u{51f}\x05\x48\x25\x02\u{51e}\u{51d}\x03\x02\x02\x02\u{51f}\u{522}\
	\x03\x02\x02\x02\u{520}\u{51e}\x03\x02\x02\x02\u{520}\u{521}\x03\x02\x02\
	\x02\u{521}\u{526}\x03\x02\x02\x02\u{522}\u{520}\x03\x02\x02\x02\u{523}\
	\u{525}\x05\x4a\x26\x02\u{524}\u{523}\x03\x02\x02\x02\u{525}\u{528}\x03\
	\x02\x02\x02\u{526}\u{524}\x03\x02\x02\x02\u{526}\u{527}\x03\x02\x02\x02\
	\u{527}\u{52c}\x03\x02\x02\x02\u{528}\u{526}\x03\x02\x02\x02\u{529}\u{52b}\
	\x05\x4c\x27\x02\u{52a}\u{529}\x03\x02\x02\x02\u{52b}\u{52e}\x03\x02\x02\
	\x02\u{52c}\u{52a}\x03\x02\x02\x02\u{52c}\u{52d}\x03\x02\x02\x02\u{52d}\
	\u{530}\x03\x02\x02\x02\u{52e}\u{52c}\x03\x02\x02\x02\u{52f}\u{4f1}\x03\
	\x02\x02\x02\u{52f}\u{4f4}\x03\x02\x02\x02\u{52f}\u{4fb}\x03\x02\x02\x02\
	\u{52f}\u{502}\x03\x02\x02\x02\u{52f}\u{509}\x03\x02\x02\x02\u{530}\x3b\
	\x03\x02\x02\x02\u{531}\u{532}\x07\u{17e}\x02\x02\u{532}\u{537}\x05\u{dc}\
	\x6f\x02\u{533}\u{534}\x07\x38\x02\x02\u{534}\u{536}\x05\u{dc}\x6f\x02\u{535}\
	\u{533}\x03\x02\x02\x02\u{536}\u{539}\x03\x02\x02\x02\u{537}\u{535}\x03\
	\x02\x02\x02\u{537}\u{538}\x03\x02\x02\x02\u{538}\x3d\x03\x02\x02\x02\u{539}\
	\u{537}\x03\x02\x02\x02\u{53a}\u{53b}\x07\u{a3}\x02\x02\u{53b}\u{53d}\x07\
	\u{f1}\x02\x02\u{53c}\u{53e}\x07\u{146}\x02\x02\u{53d}\u{53c}\x03\x02\x02\
	\x02\u{53d}\u{53e}\x03\x02\x02\x02\u{53e}\u{53f}\x03\x02\x02\x02\u{53f}\
	\u{541}\x05\x10\x09\x02\u{540}\u{542}\x05\x4e\x28\x02\u{541}\u{540}\x03\
	\x02\x02\x02\u{541}\u{542}\x03\x02\x02\x02\u{542}\u{549}\x03\x02\x02\x02\
	\u{543}\u{547}\x05\x50\x29\x02\u{544}\u{545}\x07\u{97}\x02\x02\u{545}\u{546}\
	\x07\u{de}\x02\x02\u{546}\u{548}\x07\x76\x02\x02\u{547}\u{544}\x03\x02\x02\
	\x02\u{547}\u{548}\x03\x02\x02\x02\u{548}\u{54a}\x03\x02\x02\x02\u{549}\
	\u{543}\x03\x02\x02\x02\u{549}\u{54a}\x03\x02\x02\x02\u{54a}\u{54e}\x03\
	\x02\x02\x02\u{54b}\u{54c}\x07\x22\x02\x02\u{54c}\u{54f}\x07\u{d5}\x02\x02\
	\u{54d}\u{54f}\x05\u{1a6}\u{d4}\x02\u{54e}\u{54b}\x03\x02\x02\x02\u{54e}\
	\u{54d}\x03\x02\x02\x02\u{54e}\u{54f}\x03\x02\x02\x02\u{54f}\u{58e}\x03\
	\x02\x02\x02\u{550}\u{551}\x07\u{a3}\x02\x02\u{551}\u{553}\x07\u{a8}\x02\
	\x02\u{552}\u{554}\x07\u{146}\x02\x02\u{553}\u{552}\x03\x02\x02\x02\u{553}\
	\u{554}\x03\x02\x02\x02\u{554}\u{555}\x03\x02\x02\x02\u{555}\u{557}\x05\
	\x10\x09\x02\u{556}\u{558}\x05\x4e\x28\x02\u{557}\u{556}\x03\x02\x02\x02\
	\u{557}\u{558}\x03\x02\x02\x02\u{558}\u{55a}\x03\x02\x02\x02\u{559}\u{55b}\
	\x05\x50\x29\x02\u{55a}\u{559}\x03\x02\x02\x02\u{55a}\u{55b}\x03\x02\x02\
	\x02\u{55b}\u{55f}\x03\x02\x02\x02\u{55c}\u{55d}\x07\u{97}\x02\x02\u{55d}\
	\u{55e}\x07\u{de}\x02\x02\u{55e}\u{560}\x07\x76\x02\x02\u{55f}\u{55c}\x03\
	\x02\x02\x02\u{55f}\u{560}\x03\x02\x02\x02\u{560}\u{564}\x03\x02\x02\x02\
	\u{561}\u{562}\x07\x22\x02\x02\u{562}\u{565}\x07\u{d5}\x02\x02\u{563}\u{565}\
	\x05\u{1a6}\u{d4}\x02\u{564}\u{561}\x03\x02\x02\x02\u{564}\u{563}\x03\x02\
	\x02\x02\u{564}\u{565}\x03\x02\x02\x02\u{565}\u{58e}\x03\x02\x02\x02\u{566}\
	\u{567}\x07\u{a3}\x02\x02\u{567}\u{569}\x07\u{a8}\x02\x02\u{568}\u{56a}\
	\x07\u{146}\x02\x02\u{569}\u{568}\x03\x02\x02\x02\u{569}\u{56a}\x03\x02\
	\x02\x02\u{56a}\u{56b}\x03\x02\x02\x02\u{56b}\u{56d}\x05\x10\x09\x02\u{56c}\
	\u{56e}\x05\x4e\x28\x02\u{56d}\u{56c}\x03\x02\x02\x02\u{56d}\u{56e}\x03\
	\x02\x02\x02\u{56e}\u{56f}\x03\x02\x02\x02\u{56f}\u{570}\x07\u{113}\x02\
	\x02\u{570}\u{571}\x05\x44\x23\x02\u{571}\u{58e}\x03\x02\x02\x02\u{572}\
	\u{573}\x07\u{a3}\x02\x02\u{573}\u{575}\x07\u{f1}\x02\x02\u{574}\u{576}\
	\x07\u{bd}\x02\x02\u{575}\u{574}\x03\x02\x02\x02\u{575}\u{576}\x03\x02\x02\
	\x02\u{576}\u{577}\x03\x02\x02\x02\u{577}\u{578}\x07\x66\x02\x02\u{578}\
	\u{57a}\x05\u{162}\u{b2}\x02\u{579}\u{57b}\x05\x2e\x18\x02\u{57a}\u{579}\
	\x03\x02\x02\x02\u{57a}\u{57b}\x03\x02\x02\x02\u{57b}\u{57d}\x03\x02\x02\
	\x02\u{57c}\u{57e}\x05\x30\x19\x02\u{57d}\u{57c}\x03\x02\x02\x02\u{57d}\
	\u{57e}\x03\x02\x02\x02\u{57e}\u{58e}\x03\x02\x02\x02\u{57f}\u{580}\x07\
	\u{a3}\x02\x02\u{580}\u{582}\x07\u{f1}\x02\x02\u{581}\u{583}\x07\u{bd}\x02\
	\x02\u{582}\u{581}\x03\x02\x02\x02\u{582}\u{583}\x03\x02\x02\x02\u{583}\
	\u{584}\x03\x02\x02\x02\u{584}\u{586}\x07\x66\x02\x02\u{585}\u{587}\x05\
	\u{162}\u{b2}\x02\u{586}\u{585}\x03\x02\x02\x02\u{586}\u{587}\x03\x02\x02\
	\x02\u{587}\u{588}\x03\x02\x02\x02\u{588}\u{58b}\x05\x1a\x0e\x02\u{589}\
	\u{58a}\x07\u{e8}\x02\x02\u{58a}\u{58c}\x05\u{9c}\x4f\x02\u{58b}\u{589}\
	\x03\x02\x02\x02\u{58b}\u{58c}\x03\x02\x02\x02\u{58c}\u{58e}\x03\x02\x02\
	\x02\u{58d}\u{53a}\x03\x02\x02\x02\u{58d}\u{550}\x03\x02\x02\x02\u{58d}\
	\u{566}\x03\x02\x02\x02\u{58d}\u{572}\x03\x02\x02\x02\u{58d}\u{57f}\x03\
	\x02\x02\x02\u{58e}\x3f\x03\x02\x02\x02\u{58f}\u{590}\x05\x3e\x20\x02\u{590}\
	\u{591}\x05\x54\x2b\x02\u{591}\x41\x03\x02\x02\x02\u{592}\u{594}\x07\x14\
	\x02\x02\u{593}\u{592}\x03\x02\x02\x02\u{593}\u{594}\x03\x02\x02\x02\u{594}\
	\u{595}\x03\x02\x02\x02\u{595}\u{597}\x05\u{19e}\u{d0}\x02\u{596}\u{598}\
	\x05\u{1a6}\u{d4}\x02\u{597}\u{596}\x03\x02\x02\x02\u{597}\u{598}\x03\x02\
	\x02\x02\u{598}\u{59a}\x03\x02\x02\x02\u{599}\u{593}\x03\x02\x02\x02\u{599}\
	\u{59a}\x03\x02\x02\x02\u{59a}\x43\x03\x02\x02\x02\u{59b}\u{59c}\x07\u{17b}\
	\x02\x02\u{59c}\u{59d}\x05\u{140}\u{a1}\x02\u{59d}\x45\x03\x02\x02\x02\u{59e}\
	\u{59f}\x07\u{12d}\x02\x02\u{59f}\u{5a0}\x05\x58\x2d\x02\u{5a0}\x47\x03\
	\x02\x02\x02\u{5a1}\u{5a2}\x07\u{17a}\x02\x02\u{5a2}\u{5a5}\x07\u{c6}\x02\
	\x02\u{5a3}\u{5a4}\x07\x0d\x02\x02\u{5a4}\u{5a6}\x05\u{140}\u{a1}\x02\u{5a5}\
	\u{5a3}\x03\x02\x02\x02\u{5a5}\u{5a6}\x03\x02\x02\x02\u{5a6}\u{5a7}\x03\
	\x02\x02\x02\u{5a7}\u{5a8}\x07\u{14f}\x02\x02\u{5a8}\u{5a9}\x05\x5c\x2f\
	\x02\u{5a9}\x49\x03\x02\x02\x02\u{5aa}\u{5ab}\x07\u{17a}\x02\x02\u{5ab}\
	\u{5ac}\x07\u{de}\x02\x02\u{5ac}\u{5af}\x07\u{c6}\x02\x02\u{5ad}\u{5ae}\
	\x07\x22\x02\x02\u{5ae}\u{5b0}\x07\u{149}\x02\x02\u{5af}\u{5ad}\x03\x02\
	\x02\x02\u{5af}\u{5b0}\x03\x02\x02\x02\u{5b0}\u{5b3}\x03\x02\x02\x02\u{5b1}\
	\u{5b2}\x07\x0d\x02\x02\u{5b2}\u{5b4}\x05\u{140}\u{a1}\x02\u{5b3}\u{5b1}\
	\x03\x02\x02\x02\u{5b3}\u{5b4}\x03\x02\x02\x02\u{5b4}\u{5b5}\x03\x02\x02\
	\x02\u{5b5}\u{5b6}\x07\u{14f}\x02\x02\u{5b6}\u{5b7}\x05\x5e\x30\x02\u{5b7}\
	\x4b\x03\x02\x02\x02\u{5b8}\u{5b9}\x07\u{17a}\x02\x02\u{5b9}\u{5ba}\x07\
	\u{de}\x02\x02\u{5ba}\u{5bb}\x07\u{c6}\x02\x02\u{5bb}\u{5bc}\x07\x22\x02\
	\x02\u{5bc}\u{5bf}\x07\u{137}\x02\x02\u{5bd}\u{5be}\x07\x0d\x02\x02\u{5be}\
	\u{5c0}\x05\u{140}\u{a1}\x02\u{5bf}\u{5bd}\x03\x02\x02\x02\u{5bf}\u{5c0}\
	\x03\x02\x02\x02\u{5c0}\u{5c1}\x03\x02\x02\x02\u{5c1}\u{5c2}\x07\u{14f}\
	\x02\x02\u{5c2}\u{5c3}\x05\x60\x31\x02\u{5c3}\x4d\x03\x02\x02\x02\u{5c4}\
	\u{5c5}\x07\u{17e}\x02\x02\u{5c5}\u{5c6}\x05\u{9c}\x4f\x02\u{5c6}\x4f\x03\
	\x02\x02\x02\u{5c7}\u{5c8}\x07\u{f2}\x02\x02\u{5c8}\u{5c9}\x07\u{183}\x02\
	\x02\u{5c9}\u{5ce}\x05\x62\x32\x02\u{5ca}\u{5cb}\x07\x38\x02\x02\u{5cb}\
	\u{5cd}\x05\x62\x32\x02\u{5cc}\u{5ca}\x03\x02\x02\x02\u{5cd}\u{5d0}\x03\
	\x02\x02\x02\u{5ce}\u{5cc}\x03\x02\x02\x02\u{5ce}\u{5cf}\x03\x02\x02\x02\
	\u{5cf}\u{5d1}\x03\x02\x02\x02\u{5d0}\u{5ce}\x03\x02\x02\x02\u{5d1}\u{5d2}\
	\x07\u{184}\x02\x02\u{5d2}\x51\x03\x02\x02\x02\u{5d3}\u{5d4}\x07\u{b2}\x02\
	\x02\u{5d4}\u{5d6}\x07\u{175}\x02\x02\u{5d5}\u{5d7}\x07\u{ec}\x02\x02\u{5d6}\
	\u{5d5}\x03\x02\x02\x02\u{5d6}\u{5d7}\x03\x02\x02\x02\u{5d7}\u{5d8}\x03\
	\x02\x02\x02\u{5d8}\u{5da}\x05\u{134}\u{9b}\x02\u{5d9}\u{5db}\x05\u{19c}\
	\u{cf}\x02\u{5da}\u{5d9}\x03\x02\x02\x02\u{5da}\u{5db}\x03\x02\x02\x02\u{5db}\
	\u{5de}\x03\x02\x02\x02\u{5dc}\u{5dd}\x07\x14\x02\x02\u{5dd}\u{5df}\x05\
	\u{1a8}\u{d5}\x02\u{5de}\u{5dc}\x03\x02\x02\x02\u{5de}\u{5df}\x03\x02\x02\
	\x02\u{5df}\x53\x03\x02\x02\x02\u{5e0}\u{5e2}\x05\x6a\x36\x02\u{5e1}\u{5e3}\
	\x05\x44\x23\x02\u{5e2}\u{5e1}\x03\x02\x02\x02\u{5e2}\u{5e3}\x03\x02\x02\
	\x02\u{5e3}\u{5e4}\x03\x02\x02\x02\u{5e4}\u{5e5}\x05\x56\x2c\x02\u{5e5}\
	\u{5fc}\x03\x02\x02\x02\u{5e6}\u{5ea}\x05\x6c\x37\x02\u{5e7}\u{5e9}\x05\
	\x52\x2a\x02\u{5e8}\u{5e7}\x03\x02\x02\x02\u{5e9}\u{5ec}\x03\x02\x02\x02\
	\u{5ea}\u{5e8}\x03\x02\x02\x02\u{5ea}\u{5eb}\x03\x02\x02\x02\u{5eb}\u{5ee}\
	\x03\x02\x02\x02\u{5ec}\u{5ea}\x03\x02\x02\x02\u{5ed}\u{5ef}\x05\x44\x23\
	\x02\u{5ee}\u{5ed}\x03\x02\x02\x02\u{5ee}\u{5ef}\x03\x02\x02\x02\u{5ef}\
	\u{5f1}\x03\x02\x02\x02\u{5f0}\u{5f2}\x05\u{c8}\x65\x02\u{5f1}\u{5f0}\x03\
	\x02\x02\x02\u{5f1}\u{5f2}\x03\x02\x02\x02\u{5f2}\u{5f4}\x03\x02\x02\x02\
	\u{5f3}\u{5f5}\x05\x6e\x38\x02\u{5f4}\u{5f3}\x03\x02\x02\x02\u{5f4}\u{5f5}\
	\x03\x02\x02\x02\u{5f5}\u{5f7}\x03\x02\x02\x02\u{5f6}\u{5f8}\x05\u{ac}\x57\
	\x02\u{5f7}\u{5f6}\x03\x02\x02\x02\u{5f7}\u{5f8}\x03\x02\x02\x02\u{5f8}\
	\u{5f9}\x03\x02\x02\x02\u{5f9}\u{5fa}\x05\x56\x2c\x02\u{5fa}\u{5fc}\x03\
	\x02\x02\x02\u{5fb}\u{5e0}\x03\x02\x02\x02\u{5fb}\u{5e6}\x03\x02\x02\x02\
	\u{5fc}\x55\x03\x02\x02\x02\u{5fd}\u{5fe}\x07\u{ea}\x02\x02\u{5fe}\u{5ff}\
	\x07\x22\x02\x02\u{5ff}\u{604}\x05\u{c2}\x62\x02\u{600}\u{601}\x07\x38\x02\
	\x02\u{601}\u{603}\x05\u{c2}\x62\x02\u{602}\u{600}\x03\x02\x02\x02\u{603}\
	\u{606}\x03\x02\x02\x02\u{604}\u{602}\x03\x02\x02\x02\u{604}\u{605}\x03\
	\x02\x02\x02\u{605}\u{608}\x03\x02\x02\x02\u{606}\u{604}\x03\x02\x02\x02\
	\u{607}\u{5fd}\x03\x02\x02\x02\u{607}\u{608}\x03\x02\x02\x02\u{608}\u{613}\
	\x03\x02\x02\x02\u{609}\u{60a}\x07\x30\x02\x02\u{60a}\u{60b}\x07\x22\x02\
	\x02\u{60b}\u{610}\x05\u{13e}\u{a0}\x02\u{60c}\u{60d}\x07\x38\x02\x02\u{60d}\
	\u{60f}\x05\u{13e}\u{a0}\x02\u{60e}\u{60c}\x03\x02\x02\x02\u{60f}\u{612}\
	\x03\x02\x02\x02\u{610}\u{60e}\x03\x02\x02\x02\u{610}\u{611}\x03\x02\x02\
	\x02\u{611}\u{614}\x03\x02\x02\x02\u{612}\u{610}\x03\x02\x02\x02\u{613}\
	\u{609}\x03\x02\x02\x02\u{613}\u{614}\x03\x02\x02\x02\u{614}\u{61f}\x03\
	\x02\x02\x02\u{615}\u{616}\x07\x68\x02\x02\u{616}\u{617}\x07\x22\x02\x02\
	\u{617}\u{61c}\x05\u{13e}\u{a0}\x02\u{618}\u{619}\x07\x38\x02\x02\u{619}\
	\u{61b}\x05\u{13e}\u{a0}\x02\u{61a}\u{618}\x03\x02\x02\x02\u{61b}\u{61e}\
	\x03\x02\x02\x02\u{61c}\u{61a}\x03\x02\x02\x02\u{61c}\u{61d}\x03\x02\x02\
	\x02\u{61d}\u{620}\x03\x02\x02\x02\u{61e}\u{61c}\x03\x02\x02\x02\u{61f}\
	\u{615}\x03\x02\x02\x02\u{61f}\u{620}\x03\x02\x02\x02\u{620}\u{62b}\x03\
	\x02\x02\x02\u{621}\u{622}\x07\u{135}\x02\x02\u{622}\u{623}\x07\x22\x02\
	\x02\u{623}\u{628}\x05\u{c2}\x62\x02\u{624}\u{625}\x07\x38\x02\x02\u{625}\
	\u{627}\x05\u{c2}\x62\x02\u{626}\u{624}\x03\x02\x02\x02\u{627}\u{62a}\x03\
	\x02\x02\x02\u{628}\u{626}\x03\x02\x02\x02\u{628}\u{629}\x03\x02\x02\x02\
	\u{629}\u{62c}\x03\x02\x02\x02\u{62a}\u{628}\x03\x02\x02\x02\u{62b}\u{621}\
	\x03\x02\x02\x02\u{62b}\u{62c}\x03\x02\x02\x02\u{62c}\u{62e}\x03\x02\x02\
	\x02\u{62d}\u{62f}\x05\u{ac}\x57\x02\u{62e}\u{62d}\x03\x02\x02\x02\u{62e}\
	\u{62f}\x03\x02\x02\x02\u{62f}\u{635}\x03\x02\x02\x02\u{630}\u{633}\x07\
	\u{b7}\x02\x02\u{631}\u{634}\x07\x09\x02\x02\u{632}\u{634}\x05\u{13e}\u{a0}\
	\x02\u{633}\u{631}\x03\x02\x02\x02\u{633}\u{632}\x03\x02\x02\x02\u{634}\
	\u{636}\x03\x02\x02\x02\u{635}\u{630}\x03\x02\x02\x02\u{635}\u{636}\x03\
	\x02\x02\x02\u{636}\u{639}\x03\x02\x02\x02\u{637}\u{638}\x07\u{e3}\x02\x02\
	\u{638}\u{63a}\x05\u{13e}\u{a0}\x02\u{639}\u{637}\x03\x02\x02\x02\u{639}\
	\u{63a}\x03\x02\x02\x02\u{63a}\x57\x03\x02\x02\x02\u{63b}\u{640}\x05\x5a\
	\x2e\x02\u{63c}\u{63d}\x07\x38\x02\x02\u{63d}\u{63f}\x05\x5a\x2e\x02\u{63e}\
	\u{63c}\x03\x02\x02\x02\u{63f}\u{642}\x03\x02\x02\x02\u{640}\u{63e}\x03\
	\x02\x02\x02\u{640}\u{641}\x03\x02\x02\x02\u{641}\x59\x03\x02\x02\x02\u{642}\
	\u{640}\x03\x02\x02\x02\u{643}\u{644}\x05\u{192}\u{ca}\x02\u{644}\u{645}\
	\x07\u{188}\x02\x02\u{645}\u{646}\x05\u{13e}\u{a0}\x02\u{646}\x5b\x03\x02\
	\x02\x02\u{647}\u{64f}\x07\x5f\x02\x02\u{648}\u{649}\x07\u{16c}\x02\x02\
	\u{649}\u{64a}\x07\u{12d}\x02\x02\u{64a}\u{64f}\x07\u{195}\x02\x02\u{64b}\
	\u{64c}\x07\u{16c}\x02\x02\u{64c}\u{64d}\x07\u{12d}\x02\x02\u{64d}\u{64f}\
	\x05\x58\x2d\x02\u{64e}\u{647}\x03\x02\x02\x02\u{64e}\u{648}\x03\x02\x02\
	\x02\u{64e}\u{64b}\x03\x02\x02\x02\u{64f}\x5d\x03\x02\x02\x02\u{650}\u{651}\
	\x07\u{a3}\x02\x02\u{651}\u{663}\x07\u{195}\x02\x02\u{652}\u{653}\x07\u{a3}\
	\x02\x02\u{653}\u{654}\x07\u{183}\x02\x02\u{654}\u{655}\x05\x70\x39\x02\
	\u{655}\u{656}\x07\u{184}\x02\x02\u{656}\u{657}\x07\u{170}\x02\x02\u{657}\
	\u{658}\x07\u{183}\x02\x02\u{658}\u{65d}\x05\u{13e}\u{a0}\x02\u{659}\u{65a}\
	\x07\x38\x02\x02\u{65a}\u{65c}\x05\u{13e}\u{a0}\x02\u{65b}\u{659}\x03\x02\
	\x02\x02\u{65c}\u{65f}\x03\x02\x02\x02\u{65d}\u{65b}\x03\x02\x02\x02\u{65d}\
	\u{65e}\x03\x02\x02\x02\u{65e}\u{660}\x03\x02\x02\x02\u{65f}\u{65d}\x03\
	\x02\x02\x02\u{660}\u{661}\x07\u{184}\x02\x02\u{661}\u{663}\x03\x02\x02\
	\x02\u{662}\u{650}\x03\x02\x02\x02\u{662}\u{652}\x03\x02\x02\x02\u{663}\
	\x5f\x03\x02\x02\x02\u{664}\u{669}\x07\x5f\x02\x02\u{665}\u{666}\x07\u{16c}\
	\x02\x02\u{666}\u{667}\x07\u{12d}\x02\x02\u{667}\u{669}\x05\x58\x2d\x02\
	\u{668}\u{664}\x03\x02\x02\x02\u{668}\u{665}\x03\x02\x02\x02\u{669}\x61\
	\x03\x02\x02\x02\u{66a}\u{66d}\x05\u{19c}\u{cf}\x02\u{66b}\u{66c}\x07\u{188}\
	\x02\x02\u{66c}\u{66e}\x05\u{154}\u{ab}\x02\u{66d}\u{66b}\x03\x02\x02\x02\
	\u{66d}\u{66e}\x03\x02\x02\x02\u{66e}\u{674}\x03\x02\x02\x02\u{66f}\u{670}\
	\x05\u{19c}\u{cf}\x02\u{670}\u{671}\x07\u{188}\x02\x02\u{671}\u{672}\x07\
	\x5c\x02\x02\u{672}\u{674}\x03\x02\x02\x02\u{673}\u{66a}\x03\x02\x02\x02\
	\u{673}\u{66f}\x03\x02\x02\x02\u{674}\x63\x03\x02\x02\x02\u{675}\u{67a}\
	\x05\x66\x34\x02\u{676}\u{677}\x07\x38\x02\x02\u{677}\u{679}\x05\x66\x34\
	\x02\u{678}\u{676}\x03\x02\x02\x02\u{679}\u{67c}\x03\x02\x02\x02\u{67a}\
	\u{678}\x03\x02\x02\x02\u{67a}\u{67b}\x03\x02\x02\x02\u{67b}\x65\x03\x02\
	\x02\x02\u{67c}\u{67a}\x03\x02\x02\x02\u{67d}\u{685}\x05\u{13e}\u{a0}\x02\
	\u{67e}\u{680}\x07\x14\x02\x02\u{67f}\u{67e}\x03\x02\x02\x02\u{67f}\u{680}\
	\x03\x02\x02\x02\u{680}\u{683}\x03\x02\x02\x02\u{681}\u{684}\x05\u{19c}\
	\u{cf}\x02\u{682}\u{684}\x05\u{1a6}\u{d4}\x02\u{683}\u{681}\x03\x02\x02\
	\x02\u{683}\u{682}\x03\x02\x02\x02\u{684}\u{686}\x03\x02\x02\x02\u{685}\
	\u{67f}\x03\x02\x02\x02\u{685}\u{686}\x03\x02\x02\x02\u{686}\x67\x03\x02\
	\x02\x02\u{687}\u{688}\x09\x05\x02\x02\u{688}\u{689}\x07\u{e0}\x02\x02\u{689}\
	\x69\x03\x02\x02\x02\u{68a}\u{68b}\x07\u{127}\x02\x02\u{68b}\u{68c}\x07\
	\u{15d}\x02\x02\u{68c}\u{68e}\x07\u{183}\x02\x02\u{68d}\u{68f}\x05\u{bc}\
	\x5f\x02\u{68e}\u{68d}\x03\x02\x02\x02\u{68e}\u{68f}\x03\x02\x02\x02\u{68f}\
	\u{690}\x03\x02\x02\x02\u{690}\u{691}\x05\x72\x3a\x02\u{691}\u{692}\x07\
	\u{184}\x02\x02\u{692}\u{69e}\x03\x02\x02\x02\u{693}\u{695}\x07\u{c4}\x02\
	\x02\u{694}\u{696}\x05\u{bc}\x5f\x02\u{695}\u{694}\x03\x02\x02\x02\u{695}\
	\u{696}\x03\x02\x02\x02\u{696}\u{697}\x03\x02\x02\x02\u{697}\u{69e}\x05\
	\x72\x3a\x02\u{698}\u{69a}\x07\u{10b}\x02\x02\u{699}\u{69b}\x05\u{bc}\x5f\
	\x02\u{69a}\u{699}\x03\x02\x02\x02\u{69a}\u{69b}\x03\x02\x02\x02\u{69b}\
	\u{69c}\x03\x02\x02\x02\u{69c}\u{69e}\x05\x72\x3a\x02\u{69d}\u{68a}\x03\
	\x02\x02\x02\u{69d}\u{693}\x03\x02\x02\x02\u{69d}\u{698}\x03\x02\x02\x02\
	\u{69e}\u{6a0}\x03\x02\x02\x02\u{69f}\u{6a1}\x05\x2e\x18\x02\u{6a0}\u{69f}\
	\x03\x02\x02\x02\u{6a0}\u{6a1}\x03\x02\x02\x02\u{6a1}\u{6a4}\x03\x02\x02\
	\x02\u{6a2}\u{6a3}\x07\u{108}\x02\x02\u{6a3}\u{6a5}\x05\u{162}\u{b2}\x02\
	\u{6a4}\u{6a2}\x03\x02\x02\x02\u{6a4}\u{6a5}\x03\x02\x02\x02\u{6a5}\u{6a6}\
	\x03\x02\x02\x02\u{6a6}\u{6a7}\x07\u{16f}\x02\x02\u{6a7}\u{6b4}\x05\u{162}\
	\u{b2}\x02\u{6a8}\u{6b2}\x07\x14\x02\x02\u{6a9}\u{6b3}\x05\u{1a8}\u{d5}\
	\x02\u{6aa}\u{6b3}\x05\x74\x3b\x02\u{6ab}\u{6ae}\x07\u{183}\x02\x02\u{6ac}\
	\u{6af}\x05\u{1a8}\u{d5}\x02\u{6ad}\u{6af}\x05\x74\x3b\x02\u{6ae}\u{6ac}\
	\x03\x02\x02\x02\u{6ae}\u{6ad}\x03\x02\x02\x02\u{6af}\u{6b0}\x03\x02\x02\
	\x02\u{6b0}\u{6b1}\x07\u{184}\x02\x02\u{6b1}\u{6b3}\x03\x02\x02\x02\u{6b2}\
	\u{6a9}\x03\x02\x02\x02\u{6b2}\u{6aa}\x03\x02\x02\x02\u{6b2}\u{6ab}\x03\
	\x02\x02\x02\u{6b3}\u{6b5}\x03\x02\x02\x02\u{6b4}\u{6a8}\x03\x02\x02\x02\
	\u{6b4}\u{6b5}\x03\x02\x02\x02\u{6b5}\u{6b7}\x03\x02\x02\x02\u{6b6}\u{6b8}\
	\x05\x2e\x18\x02\u{6b7}\u{6b6}\x03\x02\x02\x02\u{6b7}\u{6b8}\x03\x02\x02\
	\x02\u{6b8}\u{6bb}\x03\x02\x02\x02\u{6b9}\u{6ba}\x07\u{107}\x02\x02\u{6ba}\
	\u{6bc}\x05\u{162}\u{b2}\x02\u{6bb}\u{6b9}\x03\x02\x02\x02\u{6bb}\u{6bc}\
	\x03\x02\x02\x02\u{6bc}\x6b\x03\x02\x02\x02\u{6bd}\u{6c1}\x07\u{127}\x02\
	\x02\u{6be}\u{6c0}\x05\x76\x3c\x02\u{6bf}\u{6be}\x03\x02\x02\x02\u{6c0}\
	\u{6c3}\x03\x02\x02\x02\u{6c1}\u{6bf}\x03\x02\x02\x02\u{6c1}\u{6c2}\x03\
	\x02\x02\x02\u{6c2}\u{6c5}\x03\x02\x02\x02\u{6c3}\u{6c1}\x03\x02\x02\x02\
	\u{6c4}\u{6c6}\x05\u{bc}\x5f\x02\u{6c5}\u{6c4}\x03\x02\x02\x02\u{6c5}\u{6c6}\
	\x03\x02\x02\x02\u{6c6}\u{6c7}\x03\x02\x02\x02\u{6c7}\u{6c8}\x05\x64\x33\
	\x02\u{6c8}\x6d\x03\x02\x02\x02\u{6c9}\u{6ca}\x07\u{92}\x02\x02\u{6ca}\u{6cb}\
	\x05\u{140}\u{a1}\x02\u{6cb}\x6f\x03\x02\x02\x02\u{6cc}\u{6d1}\x05\u{192}\
	\u{ca}\x02\u{6cd}\u{6ce}\x07\x38\x02\x02\u{6ce}\u{6d0}\x05\u{192}\u{ca}\
	\x02\u{6cf}\u{6cd}\x03\x02\x02\x02\u{6d0}\u{6d3}\x03\x02\x02\x02\u{6d1}\
	\u{6cf}\x03\x02\x02\x02\u{6d1}\u{6d2}\x03\x02\x02\x02\u{6d2}\x71\x03\x02\
	\x02\x02\u{6d3}\u{6d1}\x03\x02\x02\x02\u{6d4}\u{6d9}\x05\u{13e}\u{a0}\x02\
	\u{6d5}\u{6d6}\x07\x38\x02\x02\u{6d6}\u{6d8}\x05\u{13e}\u{a0}\x02\u{6d7}\
	\u{6d5}\x03\x02\x02\x02\u{6d8}\u{6db}\x03\x02\x02\x02\u{6d9}\u{6d7}\x03\
	\x02\x02\x02\u{6d9}\u{6da}\x03\x02\x02\x02\u{6da}\x73\x03\x02\x02\x02\u{6db}\
	\u{6d9}\x03\x02\x02\x02\u{6dc}\u{6e1}\x05\x22\x12\x02\u{6dd}\u{6de}\x07\
	\x38\x02\x02\u{6de}\u{6e0}\x05\x22\x12\x02\u{6df}\u{6dd}\x03\x02\x02\x02\
	\u{6e0}\u{6e3}\x03\x02\x02\x02\u{6e1}\u{6df}\x03\x02\x02\x02\u{6e1}\u{6e2}\
	\x03\x02\x02\x02\u{6e2}\x75\x03\x02\x02\x02\u{6e3}\u{6e1}\x03\x02\x02\x02\
	\u{6e4}\u{6e5}\x07\u{18c}\x02\x02\u{6e5}\u{6ec}\x05\x78\x3d\x02\u{6e6}\u{6e8}\
	\x07\x38\x02\x02\u{6e7}\u{6e6}\x03\x02\x02\x02\u{6e7}\u{6e8}\x03\x02\x02\
	\x02\u{6e8}\u{6e9}\x03\x02\x02\x02\u{6e9}\u{6eb}\x05\x78\x3d\x02\u{6ea}\
	\u{6e7}\x03\x02\x02\x02\u{6eb}\u{6ee}\x03\x02\x02\x02\u{6ec}\u{6ea}\x03\
	\x02\x02\x02\u{6ec}\u{6ed}\x03\x02\x02\x02\u{6ed}\u{6ef}\x03\x02\x02\x02\
	\u{6ee}\u{6ec}\x03\x02\x02\x02\u{6ef}\u{6f0}\x07\u{18d}\x02\x02\u{6f0}\x77\
	\x03\x02\x02\x02\u{6f1}\u{6ff}\x05\u{19c}\u{cf}\x02\u{6f2}\u{6f3}\x05\u{19c}\
	\u{cf}\x02\u{6f3}\u{6f4}\x07\u{183}\x02\x02\u{6f4}\u{6f9}\x05\u{14a}\u{a6}\
	\x02\u{6f5}\u{6f6}\x07\x38\x02\x02\u{6f6}\u{6f8}\x05\u{14a}\u{a6}\x02\u{6f7}\
	\u{6f5}\x03\x02\x02\x02\u{6f8}\u{6fb}\x03\x02\x02\x02\u{6f9}\u{6f7}\x03\
	\x02\x02\x02\u{6f9}\u{6fa}\x03\x02\x02\x02\u{6fa}\u{6fc}\x03\x02\x02\x02\
	\u{6fb}\u{6f9}\x03\x02\x02\x02\u{6fc}\u{6fd}\x07\u{184}\x02\x02\u{6fd}\u{6ff}\
	\x03\x02\x02\x02\u{6fe}\u{6f1}\x03\x02\x02\x02\u{6fe}\u{6f2}\x03\x02\x02\
	\x02\u{6ff}\x79\x03\x02\x02\x02\u{700}\u{702}\x05\x7c\x3f\x02\u{701}\u{700}\
	\x03\x02\x02\x02\u{701}\u{702}\x03\x02\x02\x02\u{702}\u{703}\x03\x02\x02\
	\x02\u{703}\u{704}\x05\u{a6}\x54\x02\u{704}\x7b\x03\x02\x02\x02\u{705}\u{706}\
	\x07\u{17e}\x02\x02\u{706}\u{70b}\x05\u{dc}\x6f\x02\u{707}\u{708}\x07\x38\
	\x02\x02\u{708}\u{70a}\x05\u{dc}\x6f\x02\u{709}\u{707}\x03\x02\x02\x02\u{70a}\
	\u{70d}\x03\x02\x02\x02\u{70b}\u{709}\x03\x02\x02\x02\u{70b}\u{70c}\x03\
	\x02\x02\x02\u{70c}\x7d\x03\x02\x02\x02\u{70d}\u{70b}\x03\x02\x02\x02\u{70e}\
	\u{716}\x05\u{82}\x42\x02\u{70f}\u{711}\x05\u{192}\u{ca}\x02\u{710}\u{70f}\
	\x03\x02\x02\x02\u{711}\u{712}\x03\x02\x02\x02\u{712}\u{710}\x03\x02\x02\
	\x02\u{712}\u{713}\x03\x02\x02\x02\u{713}\u{716}\x03\x02\x02\x02\u{714}\
	\u{716}\x05\u{80}\x41\x02\u{715}\u{70e}\x03\x02\x02\x02\u{715}\u{710}\x03\
	\x02\x02\x02\u{715}\u{714}\x03\x02\x02\x02\u{716}\x7f\x03\x02\x02\x02\u{717}\
	\u{718}\x07\x40\x02\x02\u{718}\u{71a}\x05\u{19c}\u{cf}\x02\u{719}\u{717}\
	\x03\x02\x02\x02\u{719}\u{71a}\x03\x02\x02\x02\u{71a}\u{726}\x03\x02\x02\
	\x02\u{71b}\u{71c}\x07\u{fc}\x02\x02\u{71c}\u{71d}\x07\u{ae}\x02\x02\u{71d}\
	\u{727}\x05\u{1a6}\u{d4}\x02\u{71e}\u{71f}\x07\u{85}\x02\x02\u{71f}\u{720}\
	\x07\u{ae}\x02\x02\u{720}\u{721}\x05\u{1a6}\u{d4}\x02\u{721}\u{722}\x07\
	\u{10e}\x02\x02\u{722}\u{724}\x05\u{192}\u{ca}\x02\u{723}\u{725}\x05\u{1a6}\
	\u{d4}\x02\u{724}\u{723}\x03\x02\x02\x02\u{724}\u{725}\x03\x02\x02\x02\u{725}\
	\u{727}\x03\x02\x02\x02\u{726}\u{71b}\x03\x02\x02\x02\u{726}\u{71e}\x03\
	\x02\x02\x02\u{727}\u{81}\x03\x02\x02\x02\u{728}\u{729}\x05\u{88}\x45\x02\
	\u{729}\u{83}\x03\x02\x02\x02\u{72a}\u{72c}\x05\u{8a}\x46\x02\u{72b}\u{72d}\
	\x05\u{17a}\u{be}\x02\u{72c}\u{72b}\x03\x02\x02\x02\u{72c}\u{72d}\x03\x02\
	\x02\x02\u{72d}\u{730}\x03\x02\x02\x02\u{72e}\u{72f}\x07\x39\x02\x02\u{72f}\
	\u{731}\x05\u{162}\u{b2}\x02\u{730}\u{72e}\x03\x02\x02\x02\u{730}\u{731}\
	\x03\x02\x02\x02\u{731}\u{85}\x03\x02\x02\x02\u{732}\u{737}\x05\u{88}\x45\
	\x02\u{733}\u{734}\x07\x38\x02\x02\u{734}\u{736}\x05\u{88}\x45\x02\u{735}\
	\u{733}\x03\x02\x02\x02\u{736}\u{739}\x03\x02\x02\x02\u{737}\u{735}\x03\
	\x02\x02\x02\u{737}\u{738}\x03\x02\x02\x02\u{738}\u{73b}\x03\x02\x02\x02\
	\u{739}\u{737}\x03\x02\x02\x02\u{73a}\u{73c}\x07\x38\x02\x02\u{73b}\u{73a}\
	\x03\x02\x02\x02\u{73b}\u{73c}\x03\x02\x02\x02\u{73c}\u{87}\x03\x02\x02\
	\x02\u{73d}\u{73e}\x05\u{8a}\x46\x02\u{73e}\u{73f}\x05\u{8e}\x48\x02\u{73f}\
	\u{89}\x03\x02\x02\x02\u{740}\u{741}\x05\u{19c}\u{cf}\x02\u{741}\u{8b}\x03\
	\x02\x02\x02\u{742}\u{743}\x05\u{8a}\x46\x02\u{743}\u{8d}\x03\x02\x02\x02\
	\u{744}\u{748}\x05\u{9a}\x4e\x02\u{745}\u{747}\x05\u{90}\x49\x02\u{746}\
	\u{745}\x03\x02\x02\x02\u{747}\u{74a}\x03\x02\x02\x02\u{748}\u{746}\x03\
	\x02\x02\x02\u{748}\u{749}\x03\x02\x02\x02\u{749}\u{8f}\x03\x02\x02\x02\
	\u{74a}\u{748}\x03\x02\x02\x02\u{74b}\u{74c}\x07\u{de}\x02\x02\u{74c}\u{751}\
	\x07\u{df}\x02\x02\u{74d}\u{751}\x05\u{94}\x4b\x02\u{74e}\u{751}\x05\u{92}\
	\x4a\x02\u{74f}\u{751}\x05\u{180}\u{c1}\x02\u{750}\u{74b}\x03\x02\x02\x02\
	\u{750}\u{74d}\x03\x02\x02\x02\u{750}\u{74e}\x03\x02\x02\x02\u{750}\u{74f}\
	\x03\x02\x02\x02\u{751}\u{91}\x03\x02\x02\x02\u{752}\u{753}\x07\u{8d}\x02\
	\x02\u{753}\u{754}\x07\x0b\x02\x02\u{754}\u{75a}\x07\x14\x02\x02\u{755}\
	\u{756}\x07\u{183}\x02\x02\u{756}\u{757}\x05\u{13e}\u{a0}\x02\u{757}\u{758}\
	\x07\u{184}\x02\x02\u{758}\u{75b}\x03\x02\x02\x02\u{759}\u{75b}\x07\u{96}\
	\x02\x02\u{75a}\u{755}\x03\x02\x02\x02\u{75a}\u{759}\x03\x02\x02\x02\u{75b}\
	\u{93}\x03\x02\x02\x02\u{75c}\u{75d}\x07\x5c\x02\x02\u{75d}\u{75e}\x05\u{13e}\
	\u{a0}\x02\u{75e}\u{95}\x03\x02\x02\x02\u{75f}\u{764}\x05\u{98}\x4d\x02\
	\u{760}\u{761}\x07\x38\x02\x02\u{761}\u{763}\x05\u{98}\x4d\x02\u{762}\u{760}\
	\x03\x02\x02\x02\u{763}\u{766}\x03\x02\x02\x02\u{764}\u{762}\x03\x02\x02\
	\x02\u{764}\u{765}\x03\x02\x02\x02\u{765}\u{768}\x03\x02\x02\x02\u{766}\
	\u{764}\x03\x02\x02\x02\u{767}\u{769}\x07\x38\x02\x02\u{768}\u{767}\x03\
	\x02\x02\x02\u{768}\u{769}\x03\x02\x02\x02\u{769}\u{97}\x03\x02\x02\x02\
	\u{76a}\u{76b}\x05\u{19c}\u{cf}\x02\u{76b}\u{76c}\x07\u{188}\x02\x02\u{76c}\
	\u{76d}\x05\u{13e}\u{a0}\x02\u{76d}\u{99}\x03\x02\x02\x02\u{76e}\u{76f}\
	\x05\u{17a}\u{be}\x02\u{76f}\u{9b}\x03\x02\x02\x02\u{770}\u{772}\x07\u{183}\
	\x02\x02\u{771}\u{773}\x05\u{9e}\x50\x02\u{772}\u{771}\x03\x02\x02\x02\u{772}\
	\u{773}\x03\x02\x02\x02\u{773}\u{774}\x03\x02\x02\x02\u{774}\u{775}\x07\
	\u{184}\x02\x02\u{775}\u{9d}\x03\x02\x02\x02\u{776}\u{77b}\x05\u{a0}\x51\
	\x02\u{777}\u{778}\x07\x38\x02\x02\u{778}\u{77a}\x05\u{a0}\x51\x02\u{779}\
	\u{777}\x03\x02\x02\x02\u{77a}\u{77d}\x03\x02\x02\x02\u{77b}\u{779}\x03\
	\x02\x02\x02\u{77b}\u{77c}\x03\x02\x02\x02\u{77c}\u{77f}\x03\x02\x02\x02\
	\u{77d}\u{77b}\x03\x02\x02\x02\u{77e}\u{780}\x07\x38\x02\x02\u{77f}\u{77e}\
	\x03\x02\x02\x02\u{77f}\u{780}\x03\x02\x02\x02\u{780}\u{9f}\x03\x02\x02\
	\x02\u{781}\u{782}\x05\u{a2}\x52\x02\u{782}\u{783}\x07\u{188}\x02\x02\u{783}\
	\u{787}\x07\u{183}\x02\x02\u{784}\u{786}\x05\u{a0}\x51\x02\u{785}\u{784}\
	\x03\x02\x02\x02\u{786}\u{789}\x03\x02\x02\x02\u{787}\u{785}\x03\x02\x02\
	\x02\u{787}\u{788}\x03\x02\x02\x02\u{788}\u{78a}\x03\x02\x02\x02\u{789}\
	\u{787}\x03\x02\x02\x02\u{78a}\u{78b}\x07\u{184}\x02\x02\u{78b}\u{791}\x03\
	\x02\x02\x02\u{78c}\u{78d}\x05\u{a2}\x52\x02\u{78d}\u{78e}\x07\u{188}\x02\
	\x02\u{78e}\u{78f}\x05\u{a4}\x53\x02\u{78f}\u{791}\x03\x02\x02\x02\u{790}\
	\u{781}\x03\x02\x02\x02\u{790}\u{78c}\x03\x02\x02\x02\u{791}\u{a1}\x03\x02\
	\x02\x02\u{792}\u{795}\x05\u{192}\u{ca}\x02\u{793}\u{795}\x05\u{162}\u{b2}\
	\x02\u{794}\u{792}\x03\x02\x02\x02\u{794}\u{793}\x03\x02\x02\x02\u{795}\
	\u{a3}\x03\x02\x02\x02\u{796}\u{79a}\x07\x5c\x02\x02\u{797}\u{79a}\x05\u{19c}\
	\u{cf}\x02\u{798}\u{79a}\x05\u{13e}\u{a0}\x02\u{799}\u{796}\x03\x02\x02\
	\x02\u{799}\u{797}\x03\x02\x02\x02\u{799}\u{798}\x03\x02\x02\x02\u{79a}\
	\u{a5}\x03\x02\x02\x02\u{79b}\u{79c}\x05\u{a8}\x55\x02\u{79c}\u{a7}\x03\
	\x02\x02\x02\u{79d}\u{7a3}\x05\u{aa}\x56\x02\u{79e}\u{7a1}\x07\u{b7}\x02\
	\x02\u{79f}\u{7a2}\x07\x09\x02\x02\u{7a0}\u{7a2}\x05\u{ae}\x58\x02\u{7a1}\
	\u{79f}\x03\x02\x02\x02\u{7a1}\u{7a0}\x03\x02\x02\x02\u{7a2}\u{7a4}\x03\
	\x02\x02\x02\u{7a3}\u{79e}\x03\x02\x02\x02\u{7a3}\u{7a4}\x03\x02\x02\x02\
	\u{7a4}\u{7a7}\x03\x02\x02\x02\u{7a5}\u{7a6}\x07\u{e3}\x02\x02\u{7a6}\u{7a8}\
	\x05\u{b0}\x59\x02\u{7a7}\u{7a5}\x03\x02\x02\x02\u{7a7}\u{7a8}\x03\x02\x02\
	\x02\u{7a8}\u{a9}\x03\x02\x02\x02\u{7a9}\u{7ab}\x05\u{b2}\x5a\x02\u{7aa}\
	\u{7ac}\x05\u{da}\x6e\x02\u{7ab}\u{7aa}\x03\x02\x02\x02\u{7ab}\u{7ac}\x03\
	\x02\x02\x02\u{7ac}\u{7b7}\x03\x02\x02\x02\u{7ad}\u{7ae}\x07\x30\x02\x02\
	\u{7ae}\u{7af}\x07\x22\x02\x02\u{7af}\u{7b4}\x05\u{13e}\u{a0}\x02\u{7b0}\
	\u{7b1}\x07\x38\x02\x02\u{7b1}\u{7b3}\x05\u{13e}\u{a0}\x02\u{7b2}\u{7b0}\
	\x03\x02\x02\x02\u{7b3}\u{7b6}\x03\x02\x02\x02\u{7b4}\u{7b2}\x03\x02\x02\
	\x02\u{7b4}\u{7b5}\x03\x02\x02\x02\u{7b5}\u{7b8}\x03\x02\x02\x02\u{7b6}\
	\u{7b4}\x03\x02\x02\x02\u{7b7}\u{7ad}\x03\x02\x02\x02\u{7b7}\u{7b8}\x03\
	\x02\x02\x02\u{7b8}\u{7c3}\x03\x02\x02\x02\u{7b9}\u{7ba}\x07\x68\x02\x02\
	\u{7ba}\u{7bb}\x07\x22\x02\x02\u{7bb}\u{7c0}\x05\u{13e}\u{a0}\x02\u{7bc}\
	\u{7bd}\x07\x38\x02\x02\u{7bd}\u{7bf}\x05\u{13e}\u{a0}\x02\u{7be}\u{7bc}\
	\x03\x02\x02\x02\u{7bf}\u{7c2}\x03\x02\x02\x02\u{7c0}\u{7be}\x03\x02\x02\
	\x02\u{7c0}\u{7c1}\x03\x02\x02\x02\u{7c1}\u{7c4}\x03\x02\x02\x02\u{7c2}\
	\u{7c0}\x03\x02\x02\x02\u{7c3}\u{7b9}\x03\x02\x02\x02\u{7c3}\u{7c4}\x03\
	\x02\x02\x02\u{7c4}\u{7cf}\x03\x02\x02\x02\u{7c5}\u{7c6}\x07\u{135}\x02\
	\x02\u{7c6}\u{7c7}\x07\x22\x02\x02\u{7c7}\u{7cc}\x05\u{c2}\x62\x02\u{7c8}\
	\u{7c9}\x07\x38\x02\x02\u{7c9}\u{7cb}\x05\u{c2}\x62\x02\u{7ca}\u{7c8}\x03\
	\x02\x02\x02\u{7cb}\u{7ce}\x03\x02\x02\x02\u{7cc}\u{7ca}\x03\x02\x02\x02\
	\u{7cc}\u{7cd}\x03\x02\x02\x02\u{7cd}\u{7d0}\x03\x02\x02\x02\u{7ce}\u{7cc}\
	\x03\x02\x02\x02\u{7cf}\u{7c5}\x03\x02\x02\x02\u{7cf}\u{7d0}\x03\x02\x02\
	\x02\u{7d0}\u{7d2}\x03\x02\x02\x02\u{7d1}\u{7d3}\x05\u{ac}\x57\x02\u{7d2}\
	\u{7d1}\x03\x02\x02\x02\u{7d2}\u{7d3}\x03\x02\x02\x02\u{7d3}\u{ab}\x03\x02\
	\x02\x02\u{7d4}\u{7d5}\x07\u{17d}\x02\x02\u{7d5}\u{7da}\x05\u{d4}\x6b\x02\
	\u{7d6}\u{7d7}\x07\x38\x02\x02\u{7d7}\u{7d9}\x05\u{d4}\x6b\x02\u{7d8}\u{7d6}\
	\x03\x02\x02\x02\u{7d9}\u{7dc}\x03\x02\x02\x02\u{7da}\u{7d8}\x03\x02\x02\
	\x02\u{7da}\u{7db}\x03\x02\x02\x02\u{7db}\u{ad}\x03\x02\x02\x02\u{7dc}\u{7da}\
	\x03\x02\x02\x02\u{7dd}\u{7de}\x05\u{b0}\x59\x02\u{7de}\u{af}\x03\x02\x02\
	\x02\u{7df}\u{7e0}\x05\u{13e}\u{a0}\x02\u{7e0}\u{b1}\x03\x02\x02\x02\u{7e1}\
	\u{7e2}\x05\u{b4}\x5b\x02\u{7e2}\u{b3}\x03\x02\x02\x02\u{7e3}\u{7e9}\x05\
	\u{b8}\x5d\x02\u{7e4}\u{7e5}\x05\u{b6}\x5c\x02\u{7e5}\u{7e6}\x05\u{b8}\x5d\
	\x02\u{7e6}\u{7e8}\x03\x02\x02\x02\u{7e7}\u{7e4}\x03\x02\x02\x02\u{7e8}\
	\u{7eb}\x03\x02\x02\x02\u{7e9}\u{7e7}\x03\x02\x02\x02\u{7e9}\u{7ea}\x03\
	\x02\x02\x02\u{7ea}\u{b5}\x03\x02\x02\x02\u{7eb}\u{7e9}\x03\x02\x02\x02\
	\u{7ec}\u{7ee}\x09\x06\x02\x02\u{7ed}\u{7ef}\x05\u{bc}\x5f\x02\u{7ee}\u{7ed}\
	\x03\x02\x02\x02\u{7ee}\u{7ef}\x03\x02\x02\x02\u{7ef}\u{b7}\x03\x02\x02\
	\x02\u{7f0}\u{7f6}\x05\u{c0}\x61\x02\u{7f1}\u{7f2}\x05\u{ba}\x5e\x02\u{7f2}\
	\u{7f3}\x05\u{c0}\x61\x02\u{7f3}\u{7f5}\x03\x02\x02\x02\u{7f4}\u{7f1}\x03\
	\x02\x02\x02\u{7f5}\u{7f8}\x03\x02\x02\x02\u{7f6}\u{7f4}\x03\x02\x02\x02\
	\u{7f6}\u{7f7}\x03\x02\x02\x02\u{7f7}\u{b9}\x03\x02\x02\x02\u{7f8}\u{7f6}\
	\x03\x02\x02\x02\u{7f9}\u{7fb}\x07\u{a4}\x02\x02\u{7fa}\u{7fc}\x05\u{bc}\
	\x5f\x02\u{7fb}\u{7fa}\x03\x02\x02\x02\u{7fb}\u{7fc}\x03\x02\x02\x02\u{7fc}\
	\u{bb}\x03\x02\x02\x02\u{7fd}\u{7fe}\x09\x07\x02\x02\u{7fe}\u{bd}\x03\x02\
	\x02\x02\u{7ff}\u{800}\x07\u{170}\x02\x02\u{800}\u{805}\x05\u{13e}\u{a0}\
	\x02\u{801}\u{802}\x07\x38\x02\x02\u{802}\u{804}\x05\u{13e}\u{a0}\x02\u{803}\
	\u{801}\x03\x02\x02\x02\u{804}\u{807}\x03\x02\x02\x02\u{805}\u{803}\x03\
	\x02\x02\x02\u{805}\u{806}\x03\x02\x02\x02\u{806}\u{809}\x03\x02\x02\x02\
	\u{807}\u{805}\x03\x02\x02\x02\u{808}\u{80a}\x07\x38\x02\x02\u{809}\u{808}\
	\x03\x02\x02\x02\u{809}\u{80a}\x03\x02\x02\x02\u{80a}\u{bf}\x03\x02\x02\
	\x02\u{80b}\u{814}\x05\u{c4}\x63\x02\u{80c}\u{80d}\x07\u{146}\x02\x02\u{80d}\
	\u{814}\x05\u{194}\u{cb}\x02\u{80e}\u{814}\x05\u{be}\x60\x02\u{80f}\u{810}\
	\x07\u{183}\x02\x02\u{810}\u{811}\x05\x7a\x3e\x02\u{811}\u{812}\x07\u{184}\
	\x02\x02\u{812}\u{814}\x03\x02\x02\x02\u{813}\u{80b}\x03\x02\x02\x02\u{813}\
	\u{80c}\x03\x02\x02\x02\u{813}\u{80e}\x03\x02\x02\x02\u{813}\u{80f}\x03\
	\x02\x02\x02\u{814}\u{c1}\x03\x02\x02\x02\u{815}\u{817}\x05\u{13e}\u{a0}\
	\x02\u{816}\u{818}\x09\x08\x02\x02\u{817}\u{816}\x03\x02\x02\x02\u{817}\
	\u{818}\x03\x02\x02\x02\u{818}\u{81b}\x03\x02\x02\x02\u{819}\u{81a}\x07\
	\u{e0}\x02\x02\u{81a}\u{81c}\x09\x09\x02\x02\u{81b}\u{819}\x03\x02\x02\x02\
	\u{81b}\u{81c}\x03\x02\x02\x02\u{81c}\u{c3}\x03\x02\x02\x02\u{81d}\u{81f}\
	\x07\u{127}\x02\x02\u{81e}\u{820}\x05\u{bc}\x5f\x02\u{81f}\u{81e}\x03\x02\
	\x02\x02\u{81f}\u{820}\x03\x02\x02\x02\u{820}\u{821}\x03\x02\x02\x02\u{821}\
	\u{824}\x05\u{c6}\x64\x02\u{822}\u{823}\x07\u{88}\x02\x02\u{823}\u{825}\
	\x05\u{e8}\x75\x02\u{824}\u{822}\x03\x02\x02\x02\u{824}\u{825}\x03\x02\x02\
	\x02\u{825}\u{828}\x03\x02\x02\x02\u{826}\u{827}\x07\u{17b}\x02\x02\u{827}\
	\u{829}\x05\u{140}\u{a1}\x02\u{828}\u{826}\x03\x02\x02\x02\u{828}\u{829}\
	\x03\x02\x02\x02\u{829}\u{82b}\x03\x02\x02\x02\u{82a}\u{82c}\x05\u{c8}\x65\
	\x02\u{82b}\u{82a}\x03\x02\x02\x02\u{82b}\u{82c}\x03\x02\x02\x02\u{82c}\
	\u{82f}\x03\x02\x02\x02\u{82d}\u{82e}\x07\u{92}\x02\x02\u{82e}\u{830}\x05\
	\u{140}\u{a1}\x02\u{82f}\u{82d}\x03\x02\x02\x02\u{82f}\u{830}\x03\x02\x02\
	\x02\u{830}\u{833}\x03\x02\x02\x02\u{831}\u{832}\x07\u{101}\x02\x02\u{832}\
	\u{834}\x05\u{140}\u{a1}\x02\u{833}\u{831}\x03\x02\x02\x02\u{833}\u{834}\
	\x03\x02\x02\x02\u{834}\u{841}\x03\x02\x02\x02\u{835}\u{836}\x07\u{17d}\
	\x02\x02\u{836}\u{83b}\x05\u{d4}\x6b\x02\u{837}\u{838}\x07\x38\x02\x02\u{838}\
	\u{83a}\x05\u{d4}\x6b\x02\u{839}\u{837}\x03\x02\x02\x02\u{83a}\u{83d}\x03\
	\x02\x02\x02\u{83b}\u{839}\x03\x02\x02\x02\u{83b}\u{83c}\x03\x02\x02\x02\
	\u{83c}\u{83f}\x03\x02\x02\x02\u{83d}\u{83b}\x03\x02\x02\x02\u{83e}\u{840}\
	\x07\x38\x02\x02\u{83f}\u{83e}\x03\x02\x02\x02\u{83f}\u{840}\x03\x02\x02\
	\x02\u{840}\u{842}\x03\x02\x02\x02\u{841}\u{835}\x03\x02\x02\x02\u{841}\
	\u{842}\x03\x02\x02\x02\u{842}\u{c5}\x03\x02\x02\x02\u{843}\u{848}\x05\u{e0}\
	\x71\x02\u{844}\u{845}\x07\x38\x02\x02\u{845}\u{847}\x05\u{e0}\x71\x02\u{846}\
	\u{844}\x03\x02\x02\x02\u{847}\u{84a}\x03\x02\x02\x02\u{848}\u{846}\x03\
	\x02\x02\x02\u{848}\u{849}\x03\x02\x02\x02\u{849}\u{84c}\x03\x02\x02\x02\
	\u{84a}\u{848}\x03\x02\x02\x02\u{84b}\u{84d}\x07\x38\x02\x02\u{84c}\u{84b}\
	\x03\x02\x02\x02\u{84c}\u{84d}\x03\x02\x02\x02\u{84d}\u{c7}\x03\x02\x02\
	\x02\u{84e}\u{84f}\x07\u{90}\x02\x02\u{84f}\u{850}\x07\x22\x02\x02\u{850}\
	\u{851}\x05\u{ca}\x66\x02\u{851}\u{c9}\x03\x02\x02\x02\u{852}\u{867}\x07\
	\x09\x02\x02\u{853}\u{858}\x05\u{cc}\x67\x02\u{854}\u{855}\x07\x38\x02\x02\
	\u{855}\u{857}\x05\u{cc}\x67\x02\u{856}\u{854}\x03\x02\x02\x02\u{857}\u{85a}\
	\x03\x02\x02\x02\u{858}\u{856}\x03\x02\x02\x02\u{858}\u{859}\x03\x02\x02\
	\x02\u{859}\u{867}\x03\x02\x02\x02\u{85a}\u{858}\x03\x02\x02\x02\u{85b}\
	\u{860}\x05\u{13e}\u{a0}\x02\u{85c}\u{85d}\x07\x38\x02\x02\u{85d}\u{85f}\
	\x05\u{13e}\u{a0}\x02\u{85e}\u{85c}\x03\x02\x02\x02\u{85f}\u{862}\x03\x02\
	\x02\x02\u{860}\u{85e}\x03\x02\x02\x02\u{860}\u{861}\x03\x02\x02\x02\u{861}\
	\u{863}\x03\x02\x02\x02\u{862}\u{860}\x03\x02\x02\x02\u{863}\u{864}\x07\
	\u{17e}\x02\x02\u{864}\u{865}\x09\x0a\x02\x02\u{865}\u{867}\x03\x02\x02\
	\x02\u{866}\u{852}\x03\x02\x02\x02\u{866}\u{853}\x03\x02\x02\x02\u{866}\
	\u{85b}\x03\x02\x02\x02\u{867}\u{cb}\x03\x02\x02\x02\u{868}\u{86b}\x05\u{ce}\
	\x68\x02\u{869}\u{86b}\x05\u{13e}\u{a0}\x02\u{86a}\u{868}\x03\x02\x02\x02\
	\u{86a}\u{869}\x03\x02\x02\x02\u{86b}\u{cd}\x03\x02\x02\x02\u{86c}\u{86d}\
	\x09\x0a\x02\x02\u{86d}\u{86e}\x07\u{183}\x02\x02\u{86e}\u{873}\x05\u{d2}\
	\x6a\x02\u{86f}\u{870}\x07\x38\x02\x02\u{870}\u{872}\x05\u{d2}\x6a\x02\u{871}\
	\u{86f}\x03\x02\x02\x02\u{872}\u{875}\x03\x02\x02\x02\u{873}\u{871}\x03\
	\x02\x02\x02\u{873}\u{874}\x03\x02\x02\x02\u{874}\u{876}\x03\x02\x02\x02\
	\u{875}\u{873}\x03\x02\x02\x02\u{876}\u{877}\x07\u{184}\x02\x02\u{877}\u{886}\
	\x03\x02\x02\x02\u{878}\u{879}\x07\u{91}\x02\x02\u{879}\u{87a}\x07\u{12e}\
	\x02\x02\u{87a}\u{87b}\x07\u{183}\x02\x02\u{87b}\u{880}\x05\u{d0}\x69\x02\
	\u{87c}\u{87d}\x07\x38\x02\x02\u{87d}\u{87f}\x05\u{d0}\x69\x02\u{87e}\u{87c}\
	\x03\x02\x02\x02\u{87f}\u{882}\x03\x02\x02\x02\u{880}\u{87e}\x03\x02\x02\
	\x02\u{880}\u{881}\x03\x02\x02\x02\u{881}\u{883}\x03\x02\x02\x02\u{882}\
	\u{880}\x03\x02\x02\x02\u{883}\u{884}\x07\u{184}\x02\x02\u{884}\u{886}\x03\
	\x02\x02\x02\u{885}\u{86c}\x03\x02\x02\x02\u{885}\u{878}\x03\x02\x02\x02\
	\u{886}\u{cf}\x03\x02\x02\x02\u{887}\u{88a}\x05\u{ce}\x68\x02\u{888}\u{88a}\
	\x05\u{d2}\x6a\x02\u{889}\u{887}\x03\x02\x02\x02\u{889}\u{888}\x03\x02\x02\
	\x02\u{88a}\u{d1}\x03\x02\x02\x02\u{88b}\u{894}\x07\u{183}\x02\x02\u{88c}\
	\u{891}\x05\u{13e}\u{a0}\x02\u{88d}\u{88e}\x07\x38\x02\x02\u{88e}\u{890}\
	\x05\u{13e}\u{a0}\x02\u{88f}\u{88d}\x03\x02\x02\x02\u{890}\u{893}\x03\x02\
	\x02\x02\u{891}\u{88f}\x03\x02\x02\x02\u{891}\u{892}\x03\x02\x02\x02\u{892}\
	\u{895}\x03\x02\x02\x02\u{893}\u{891}\x03\x02\x02\x02\u{894}\u{88c}\x03\
	\x02\x02\x02\u{894}\u{895}\x03\x02\x02\x02\u{895}\u{897}\x03\x02\x02\x02\
	\u{896}\u{898}\x07\x38\x02\x02\u{897}\u{896}\x03\x02\x02\x02\u{897}\u{898}\
	\x03\x02\x02\x02\u{898}\u{899}\x03\x02\x02\x02\u{899}\u{89c}\x07\u{184}\
	\x02\x02\u{89a}\u{89c}\x05\u{13e}\u{a0}\x02\u{89b}\u{88b}\x03\x02\x02\x02\
	\u{89b}\u{89a}\x03\x02\x02\x02\u{89c}\u{d3}\x03\x02\x02\x02\u{89d}\u{89e}\
	\x05\u{19c}\u{cf}\x02\u{89e}\u{89f}\x07\x14\x02\x02\u{89f}\u{8a0}\x07\u{183}\
	\x02\x02\u{8a0}\u{8a1}\x05\u{d6}\x6c\x02\u{8a1}\u{8a2}\x07\u{184}\x02\x02\
	\u{8a2}\u{d5}\x03\x02\x02\x02\u{8a3}\u{8a5}\x05\u{19c}\u{cf}\x02\u{8a4}\
	\u{8a3}\x03\x02\x02\x02\u{8a4}\u{8a5}\x03\x02\x02\x02\u{8a5}\u{8a7}\x03\
	\x02\x02\x02\u{8a6}\u{8a8}\x05\u{d8}\x6d\x02\u{8a7}\u{8a6}\x03\x02\x02\x02\
	\u{8a7}\u{8a8}\x03\x02\x02\x02\u{8a8}\u{8aa}\x03\x02\x02\x02\u{8a9}\u{8ab}\
	\x05\u{da}\x6e\x02\u{8aa}\u{8a9}\x03\x02\x02\x02\u{8aa}\u{8ab}\x03\x02\x02\
	\x02\u{8ab}\u{8ad}\x03\x02\x02\x02\u{8ac}\u{8ae}\x05\u{18a}\u{c6}\x02\u{8ad}\
	\u{8ac}\x03\x02\x02\x02\u{8ad}\u{8ae}\x03\x02\x02\x02\u{8ae}\u{d7}\x03\x02\
	\x02\x02\u{8af}\u{8b0}\x07\u{f2}\x02\x02\u{8b0}\u{8b1}\x07\x22\x02\x02\u{8b1}\
	\u{8b6}\x05\u{13e}\u{a0}\x02\u{8b2}\u{8b3}\x07\x38\x02\x02\u{8b3}\u{8b5}\
	\x05\u{13e}\u{a0}\x02\u{8b4}\u{8b2}\x03\x02\x02\x02\u{8b5}\u{8b8}\x03\x02\
	\x02\x02\u{8b6}\u{8b4}\x03\x02\x02\x02\u{8b6}\u{8b7}\x03\x02\x02\x02\u{8b7}\
	\u{8ba}\x03\x02\x02\x02\u{8b8}\u{8b6}\x03\x02\x02\x02\u{8b9}\u{8bb}\x07\
	\x38\x02\x02\u{8ba}\u{8b9}\x03\x02\x02\x02\u{8ba}\u{8bb}\x03\x02\x02\x02\
	\u{8bb}\u{d9}\x03\x02\x02\x02\u{8bc}\u{8bd}\x07\u{ea}\x02\x02\u{8bd}\u{8ca}\
	\x07\x22\x02\x02\u{8be}\u{8cb}\x07\x09\x02\x02\u{8bf}\u{8c4}\x05\u{c2}\x62\
	\x02\u{8c0}\u{8c1}\x07\x38\x02\x02\u{8c1}\u{8c3}\x05\u{c2}\x62\x02\u{8c2}\
	\u{8c0}\x03\x02\x02\x02\u{8c3}\u{8c6}\x03\x02\x02\x02\u{8c4}\u{8c2}\x03\
	\x02\x02\x02\u{8c4}\u{8c5}\x03\x02\x02\x02\u{8c5}\u{8c8}\x03\x02\x02\x02\
	\u{8c6}\u{8c4}\x03\x02\x02\x02\u{8c7}\u{8c9}\x07\x38\x02\x02\u{8c8}\u{8c7}\
	\x03\x02\x02\x02\u{8c8}\u{8c9}\x03\x02\x02\x02\u{8c9}\u{8cb}\x03\x02\x02\
	\x02\u{8ca}\u{8be}\x03\x02\x02\x02\u{8ca}\u{8bf}\x03\x02\x02\x02\u{8cb}\
	\u{db}\x03\x02\x02\x02\u{8cc}\u{8ce}\x05\u{19c}\u{cf}\x02\u{8cd}\u{8cf}\
	\x05\u{130}\u{99}\x02\u{8ce}\u{8cd}\x03\x02\x02\x02\u{8ce}\u{8cf}\x03\x02\
	\x02\x02\u{8cf}\u{8d1}\x03\x02\x02\x02\u{8d0}\u{8d2}\x07\x14\x02\x02\u{8d1}\
	\u{8d0}\x03\x02\x02\x02\u{8d1}\u{8d2}\x03\x02\x02\x02\u{8d2}\u{8d3}\x03\
	\x02\x02\x02\u{8d3}\u{8d4}\x07\u{183}\x02\x02\u{8d4}\u{8d5}\x05\x7a\x3e\
	\x02\u{8d5}\u{8d6}\x07\u{184}\x02\x02\u{8d6}\u{dd}\x03\x02\x02\x02\u{8d7}\
	\u{8da}\x05\u{19c}\u{cf}\x02\u{8d8}\u{8da}\x05\u{130}\u{99}\x02\u{8d9}\u{8d7}\
	\x03\x02\x02\x02\u{8d9}\u{8d8}\x03\x02\x02\x02\u{8da}\u{df}\x03\x02\x02\
	\x02\u{8db}\u{8e0}\x05\u{13e}\u{a0}\x02\u{8dc}\u{8de}\x07\x14\x02\x02\u{8dd}\
	\u{8dc}\x03\x02\x02\x02\u{8dd}\u{8de}\x03\x02\x02\x02\u{8de}\u{8df}\x03\
	\x02\x02\x02\u{8df}\u{8e1}\x05\u{de}\x70\x02\u{8e0}\u{8dd}\x03\x02\x02\x02\
	\u{8e0}\u{8e1}\x03\x02\x02\x02\u{8e1}\u{8e4}\x03\x02\x02\x02\u{8e2}\u{8e4}\
	\x05\u{e4}\x73\x02\u{8e3}\u{8db}\x03\x02\x02\x02\u{8e3}\u{8e2}\x03\x02\x02\
	\x02\u{8e4}\u{e1}\x03\x02\x02\x02\u{8e5}\u{8ea}\x05\u{13e}\u{a0}\x02\u{8e6}\
	\u{8e8}\x07\x14\x02\x02\u{8e7}\u{8e6}\x03\x02\x02\x02\u{8e7}\u{8e8}\x03\
	\x02\x02\x02\u{8e8}\u{8e9}\x03\x02\x02\x02\u{8e9}\u{8eb}\x05\u{19c}\u{cf}\
	\x02\u{8ea}\u{8e7}\x03\x02\x02\x02\u{8ea}\u{8eb}\x03\x02\x02\x02\u{8eb}\
	\u{8ee}\x03\x02\x02\x02\u{8ec}\u{8ee}\x05\u{e4}\x73\x02\u{8ed}\u{8e5}\x03\
	\x02\x02\x02\u{8ed}\u{8ec}\x03\x02\x02\x02\u{8ee}\u{e3}\x03\x02\x02\x02\
	\u{8ef}\u{8f5}\x05\u{e6}\x74\x02\u{8f0}\u{8f1}\x07\x72\x02\x02\u{8f1}\u{8f2}\
	\x07\u{183}\x02\x02\u{8f2}\u{8f3}\x05\x70\x39\x02\u{8f3}\u{8f4}\x07\u{184}\
	\x02\x02\u{8f4}\u{8f6}\x03\x02\x02\x02\u{8f5}\u{8f0}\x03\x02\x02\x02\u{8f5}\
	\u{8f6}\x03\x02\x02\x02\u{8f6}\u{e5}\x03\x02\x02\x02\u{8f7}\u{8f8}\x07\u{183}\
	\x02\x02\u{8f8}\u{8f9}\x05\u{e6}\x74\x02\u{8f9}\u{8fa}\x07\u{184}\x02\x02\
	\u{8fa}\u{901}\x03\x02\x02\x02\u{8fb}\u{8fc}\x05\u{14a}\u{a6}\x02\u{8fc}\
	\u{8fd}\x07\u{187}\x02\x02\u{8fd}\u{8fe}\x07\u{195}\x02\x02\u{8fe}\u{901}\
	\x03\x02\x02\x02\u{8ff}\u{901}\x07\u{195}\x02\x02\u{900}\u{8f7}\x03\x02\
	\x02\x02\u{900}\u{8fb}\x03\x02\x02\x02\u{900}\u{8ff}\x03\x02\x02\x02\u{901}\
	\u{e7}\x03\x02\x02\x02\u{902}\u{903}\x05\u{10a}\u{86}\x02\u{903}\u{e9}\x03\
	\x02\x02\x02\u{904}\u{906}\x07\u{9f}\x02\x02\u{905}\u{904}\x03\x02\x02\x02\
	\u{905}\u{906}\x03\x02\x02\x02\u{906}\u{91d}\x03\x02\x02\x02\u{907}\u{91d}\
	\x07\x45\x02\x02\u{908}\u{90a}\x07\u{b5}\x02\x02\u{909}\u{90b}\x07\u{ec}\
	\x02\x02\u{90a}\u{909}\x03\x02\x02\x02\u{90a}\u{90b}\x03\x02\x02\x02\u{90b}\
	\u{91d}\x03\x02\x02\x02\u{90c}\u{90e}\x07\u{b5}\x02\x02\u{90d}\u{90c}\x03\
	\x02\x02\x02\u{90d}\u{90e}\x03\x02\x02\x02\u{90e}\u{90f}\x03\x02\x02\x02\
	\u{90f}\u{91d}\x07\u{128}\x02\x02\u{910}\u{912}\x07\u{11a}\x02\x02\u{911}\
	\u{913}\x07\u{ec}\x02\x02\u{912}\u{911}\x03\x02\x02\x02\u{912}\u{913}\x03\
	\x02\x02\x02\u{913}\u{91d}\x03\x02\x02\x02\u{914}\u{916}\x07\u{8a}\x02\x02\
	\u{915}\u{917}\x07\u{ec}\x02\x02\u{916}\u{915}\x03\x02\x02\x02\u{916}\u{917}\
	\x03\x02\x02\x02\u{917}\u{91d}\x03\x02\x02\x02\u{918}\u{91a}\x07\u{b5}\x02\
	\x02\u{919}\u{918}\x03\x02\x02\x02\u{919}\u{91a}\x03\x02\x02\x02\u{91a}\
	\u{91b}\x03\x02\x02\x02\u{91b}\u{91d}\x07\x0e\x02\x02\u{91c}\u{905}\x03\
	\x02\x02\x02\u{91c}\u{907}\x03\x02\x02\x02\u{91c}\u{908}\x03\x02\x02\x02\
	\u{91c}\u{90d}\x03\x02\x02\x02\u{91c}\u{910}\x03\x02\x02\x02\u{91c}\u{914}\
	\x03\x02\x02\x02\u{91c}\u{919}\x03\x02\x02\x02\u{91d}\u{eb}\x03\x02\x02\
	\x02\u{91e}\u{91f}\x07\u{e4}\x02\x02\u{91f}\u{930}\x05\u{140}\u{a1}\x02\
	\u{920}\u{921}\x07\u{16f}\x02\x02\u{921}\u{922}\x07\u{183}\x02\x02\u{922}\
	\u{927}\x05\u{19c}\u{cf}\x02\u{923}\u{924}\x07\x38\x02\x02\u{924}\u{926}\
	\x05\u{19c}\u{cf}\x02\u{925}\u{923}\x03\x02\x02\x02\u{926}\u{929}\x03\x02\
	\x02\x02\u{927}\u{925}\x03\x02\x02\x02\u{927}\u{928}\x03\x02\x02\x02\u{928}\
	\u{92b}\x03\x02\x02\x02\u{929}\u{927}\x03\x02\x02\x02\u{92a}\u{92c}\x07\
	\x38\x02\x02\u{92b}\u{92a}\x03\x02\x02\x02\u{92b}\u{92c}\x03\x02\x02\x02\
	\u{92c}\u{92d}\x03\x02\x02\x02\u{92d}\u{92e}\x07\u{184}\x02\x02\u{92e}\u{930}\
	\x03\x02\x02\x02\u{92f}\u{91e}\x03\x02\x02\x02\u{92f}\u{920}\x03\x02\x02\
	\x02\u{930}\u{ed}\x03\x02\x02\x02\u{931}\u{932}\x05\u{132}\u{9a}\x02\u{932}\
	\u{ef}\x03\x02\x02\x02\u{933}\u{935}\x05\u{ee}\x78\x02\u{934}\u{936}\x05\
	\u{f2}\x7a\x02\u{935}\u{934}\x03\x02\x02\x02\u{935}\u{936}\x03\x02\x02\x02\
	\u{936}\u{f1}\x03\x02\x02\x02\u{937}\u{938}\x07\u{148}\x02\x02\u{938}\u{93a}\
	\x07\u{183}\x02\x02\u{939}\u{93b}\x05\u{f6}\x7c\x02\u{93a}\u{939}\x03\x02\
	\x02\x02\u{93a}\u{93b}\x03\x02\x02\x02\u{93b}\u{93c}\x03\x02\x02\x02\u{93c}\
	\u{941}\x07\u{184}\x02\x02\u{93d}\u{93e}\x07\u{112}\x02\x02\u{93e}\u{93f}\
	\x07\u{183}\x02\x02\u{93f}\u{940}\x07\u{1a6}\x02\x02\u{940}\u{942}\x07\u{184}\
	\x02\x02\u{941}\u{93d}\x03\x02\x02\x02\u{941}\u{942}\x03\x02\x02\x02\u{942}\
	\u{f3}\x03\x02\x02\x02\u{943}\u{944}\x07\u{148}\x02\x02\u{944}\u{946}\x07\
	\u{183}\x02\x02\u{945}\u{947}\x05\u{f6}\x7c\x02\u{946}\u{945}\x03\x02\x02\
	\x02\u{946}\u{947}\x03\x02\x02\x02\u{947}\u{948}\x03\x02\x02\x02\u{948}\
	\u{94d}\x07\u{184}\x02\x02\u{949}\u{94a}\x07\u{112}\x02\x02\u{94a}\u{94b}\
	\x07\u{183}\x02\x02\u{94b}\u{94c}\x07\u{1a6}\x02\x02\u{94c}\u{94e}\x07\u{184}\
	\x02\x02\u{94d}\u{949}\x03\x02\x02\x02\u{94d}\u{94e}\x03\x02\x02\x02\u{94e}\
	\u{f5}\x03\x02\x02\x02\u{94f}\u{951}\x07\u{194}\x02\x02\u{950}\u{94f}\x03\
	\x02\x02\x02\u{950}\u{951}\x03\x02\x02\x02\u{951}\u{952}\x03\x02\x02\x02\
	\u{952}\u{953}\x09\x0b\x02\x02\u{953}\u{968}\x07\u{f5}\x02\x02\u{954}\u{955}\
	\x05\u{13e}\u{a0}\x02\u{955}\u{956}\x07\u{121}\x02\x02\u{956}\u{968}\x03\
	\x02\x02\x02\u{957}\u{958}\x07\x20\x02\x02\u{958}\u{959}\x07\u{1a6}\x02\
	\x02\u{959}\u{95a}\x07\u{eb}\x02\x02\u{95a}\u{95b}\x07\u{e2}\x02\x02\u{95b}\
	\u{964}\x07\u{1a6}\x02\x02\u{95c}\u{962}\x07\u{e4}\x02\x02\u{95d}\u{963}\
	\x05\u{19c}\u{cf}\x02\u{95e}\u{95f}\x05\u{192}\u{ca}\x02\u{95f}\u{960}\x07\
	\u{183}\x02\x02\u{960}\u{961}\x07\u{184}\x02\x02\u{961}\u{963}\x03\x02\x02\
	\x02\u{962}\u{95d}\x03\x02\x02\x02\u{962}\u{95e}\x03\x02\x02\x02\u{963}\
	\u{965}\x03\x02\x02\x02\u{964}\u{95c}\x03\x02\x02\x02\u{964}\u{965}\x03\
	\x02\x02\x02\u{965}\u{968}\x03\x02\x02\x02\u{966}\u{968}\x05\u{13e}\u{a0}\
	\x02\u{967}\u{950}\x03\x02\x02\x02\u{967}\u{954}\x03\x02\x02\x02\u{967}\
	\u{957}\x03\x02\x02\x02\u{967}\u{966}\x03\x02\x02\x02\u{968}\u{f7}\x03\x02\
	\x02\x02\u{969}\u{96a}\x09\x0c\x02\x02\u{96a}\u{f9}\x03\x02\x02\x02\u{96b}\
	\u{96c}\x05\u{19c}\u{cf}\x02\u{96c}\u{96d}\x07\x14\x02\x02\u{96d}\u{96e}\
	\x05\u{13e}\u{a0}\x02\u{96e}\u{fb}\x03\x02\x02\x02\u{96f}\u{970}\x05\u{fe}\
	\u{80}\x02\u{970}\u{fd}\x03\x02\x02\x02\u{971}\u{973}\x05\u{100}\u{81}\x02\
	\u{972}\u{974}\x05\x52\x2a\x02\u{973}\u{972}\x03\x02\x02\x02\u{973}\u{974}\
	\x03\x02\x02\x02\u{974}\u{ff}\x03\x02\x02\x02\u{975}\u{976}\x08\u{81}\x01\
	\x02\u{976}\u{97b}\x05\u{102}\u{82}\x02\u{977}\u{978}\x07\x38\x02\x02\u{978}\
	\u{97a}\x05\u{102}\u{82}\x02\u{979}\u{977}\x03\x02\x02\x02\u{97a}\u{97d}\
	\x03\x02\x02\x02\u{97b}\u{979}\x03\x02\x02\x02\u{97b}\u{97c}\x03\x02\x02\
	\x02\u{97c}\u{982}\x03\x02\x02\x02\u{97d}\u{97b}\x03\x02\x02\x02\u{97e}\
	\u{97f}\x0c\x03\x02\x02\u{97f}\u{981}\x05\x52\x2a\x02\u{980}\u{97e}\x03\
	\x02\x02\x02\u{981}\u{984}\x03\x02\x02\x02\u{982}\u{980}\x03\x02\x02\x02\
	\u{982}\u{983}\x03\x02\x02\x02\u{983}\u{101}\x03\x02\x02\x02\u{984}\u{982}\
	\x03\x02\x02\x02\u{985}\u{987}\x05\u{104}\u{83}\x02\u{986}\u{988}\x05\u{106}\
	\u{84}\x02\u{987}\u{986}\x03\x02\x02\x02\u{987}\u{988}\x03\x02\x02\x02\u{988}\
	\u{103}\x03\x02\x02\x02\u{989}\u{98b}\x08\u{83}\x01\x02\u{98a}\u{98c}\x07\
	\u{b2}\x02\x02\u{98b}\u{98a}\x03\x02\x02\x02\u{98b}\u{98c}\x03\x02\x02\x02\
	\u{98c}\u{98d}\x03\x02\x02\x02\u{98d}\u{98e}\x05\u{12e}\u{98}\x02\u{98e}\
	\u{993}\x03\x02\x02\x02\u{98f}\u{990}\x0c\x03\x02\x02\u{990}\u{992}\x05\
	\u{106}\u{84}\x02\u{991}\u{98f}\x03\x02\x02\x02\u{992}\u{995}\x03\x02\x02\
	\x02\u{993}\u{991}\x03\x02\x02\x02\u{993}\u{994}\x03\x02\x02\x02\u{994}\
	\u{105}\x03\x02\x02\x02\u{995}\u{993}\x03\x02\x02\x02\u{996}\u{999}\x05\
	\u{108}\u{85}\x02\u{997}\u{999}\x05\u{126}\u{94}\x02\u{998}\u{996}\x03\x02\
	\x02\x02\u{998}\u{997}\x03\x02\x02\x02\u{999}\u{107}\x03\x02\x02\x02\u{99a}\
	\u{99b}\x05\u{ea}\x76\x02\u{99b}\u{99d}\x07\u{ad}\x02\x02\u{99c}\u{99e}\
	\x07\u{b2}\x02\x02\u{99d}\u{99c}\x03\x02\x02\x02\u{99d}\u{99e}\x03\x02\x02\
	\x02\u{99e}\u{99f}\x03\x02\x02\x02\u{99f}\u{9a1}\x05\u{12e}\u{98}\x02\u{9a0}\
	\u{9a2}\x05\u{ec}\x77\x02\u{9a1}\u{9a0}\x03\x02\x02\x02\u{9a1}\u{9a2}\x03\
	\x02\x02\x02\u{9a2}\u{9ac}\x03\x02\x02\x02\u{9a3}\u{9a4}\x07\u{db}\x02\x02\
	\u{9a4}\u{9a5}\x05\u{ea}\x76\x02\u{9a5}\u{9a7}\x07\u{ad}\x02\x02\u{9a6}\
	\u{9a8}\x07\u{b2}\x02\x02\u{9a7}\u{9a6}\x03\x02\x02\x02\u{9a7}\u{9a8}\x03\
	\x02\x02\x02\u{9a8}\u{9a9}\x03\x02\x02\x02\u{9a9}\u{9aa}\x05\u{12e}\u{98}\
	\x02\u{9aa}\u{9ac}\x03\x02\x02\x02\u{9ab}\u{99a}\x03\x02\x02\x02\u{9ab}\
	\u{9a3}\x03\x02\x02\x02\u{9ac}\u{109}\x03\x02\x02\x02\u{9ad}\u{9b1}\x05\
	\u{fc}\x7f\x02\u{9ae}\u{9b0}\x05\u{126}\u{94}\x02\u{9af}\u{9ae}\x03\x02\
	\x02\x02\u{9b0}\u{9b3}\x03\x02\x02\x02\u{9b1}\u{9af}\x03\x02\x02\x02\u{9b1}\
	\u{9b2}\x03\x02\x02\x02\u{9b2}\u{10b}\x03\x02\x02\x02\u{9b3}\u{9b1}\x03\
	\x02\x02\x02\u{9b4}\u{9b5}\x05\x64\x33\x02\u{9b5}\u{10d}\x03\x02\x02\x02\
	\u{9b6}\u{9c3}\x05\u{19c}\u{cf}\x02\u{9b7}\u{9b8}\x07\u{183}\x02\x02\u{9b8}\
	\u{9bd}\x05\u{19c}\u{cf}\x02\u{9b9}\u{9ba}\x07\x38\x02\x02\u{9ba}\u{9bc}\
	\x05\u{19c}\u{cf}\x02\u{9bb}\u{9b9}\x03\x02\x02\x02\u{9bc}\u{9bf}\x03\x02\
	\x02\x02\u{9bd}\u{9bb}\x03\x02\x02\x02\u{9bd}\u{9be}\x03\x02\x02\x02\u{9be}\
	\u{9c0}\x03\x02\x02\x02\u{9bf}\u{9bd}\x03\x02\x02\x02\u{9c0}\u{9c1}\x07\
	\u{184}\x02\x02\u{9c1}\u{9c3}\x03\x02\x02\x02\u{9c2}\u{9b6}\x03\x02\x02\
	\x02\u{9c2}\u{9b7}\x03\x02\x02\x02\u{9c3}\u{10f}\x03\x02\x02\x02\u{9c4}\
	\u{9c5}\x05\x66\x34\x02\u{9c5}\u{111}\x03\x02\x02\x02\u{9c6}\u{9c8}\x07\
	\x14\x02\x02\u{9c7}\u{9c6}\x03\x02\x02\x02\u{9c7}\u{9c8}\x03\x02\x02\x02\
	\u{9c8}\u{9c9}\x03\x02\x02\x02\u{9c9}\u{9cb}\x05\u{19c}\u{cf}\x02\u{9ca}\
	\u{9c7}\x03\x02\x02\x02\u{9ca}\u{9cb}\x03\x02\x02\x02\u{9cb}\u{113}\x03\
	\x02\x02\x02\u{9cc}\u{9cd}\x05\u{19c}\u{cf}\x02\u{9cd}\u{9ce}\x07\u{84}\
	\x02\x02\u{9ce}\u{9cf}\x05\u{19c}\u{cf}\x02\u{9cf}\u{9d0}\x07\u{9b}\x02\
	\x02\u{9d0}\u{9d1}\x07\u{183}\x02\x02\u{9d1}\u{9d2}\x05\u{116}\u{8c}\x02\
	\u{9d2}\u{9d3}\x07\u{184}\x02\x02\u{9d3}\u{115}\x03\x02\x02\x02\u{9d4}\u{9d9}\
	\x05\u{19c}\u{cf}\x02\u{9d5}\u{9d7}\x07\x14\x02\x02\u{9d6}\u{9d5}\x03\x02\
	\x02\x02\u{9d6}\u{9d7}\x03\x02\x02\x02\u{9d7}\u{9d8}\x03\x02\x02\x02\u{9d8}\
	\u{9da}\x05\u{118}\u{8d}\x02\u{9d9}\u{9d6}\x03\x02\x02\x02\u{9d9}\u{9da}\
	\x03\x02\x02\x02\u{9da}\u{9e5}\x03\x02\x02\x02\u{9db}\u{9dc}\x07\x38\x02\
	\x02\u{9dc}\u{9e1}\x05\u{19c}\u{cf}\x02\u{9dd}\u{9df}\x07\x14\x02\x02\u{9de}\
	\u{9dd}\x03\x02\x02\x02\u{9de}\u{9df}\x03\x02\x02\x02\u{9df}\u{9e0}\x03\
	\x02\x02\x02\u{9e0}\u{9e2}\x05\u{118}\u{8d}\x02\u{9e1}\u{9de}\x03\x02\x02\
	\x02\u{9e1}\u{9e2}\x03\x02\x02\x02\u{9e2}\u{9e4}\x03\x02\x02\x02\u{9e3}\
	\u{9db}\x03\x02\x02\x02\u{9e4}\u{9e7}\x03\x02\x02\x02\u{9e5}\u{9e3}\x03\
	\x02\x02\x02\u{9e5}\u{9e6}\x03\x02\x02\x02\u{9e6}\u{9e9}\x03\x02\x02\x02\
	\u{9e7}\u{9e5}\x03\x02\x02\x02\u{9e8}\u{9ea}\x07\x38\x02\x02\u{9e9}\u{9e8}\
	\x03\x02\x02\x02\u{9e9}\u{9ea}\x03\x02\x02\x02\u{9ea}\u{117}\x03\x02\x02\
	\x02\u{9eb}\u{9ec}\x05\u{19c}\u{cf}\x02\u{9ec}\u{119}\x03\x02\x02\x02\u{9ed}\
	\u{9ee}\x05\u{11c}\u{8f}\x02\u{9ee}\u{9ef}\x07\u{84}\x02\x02\u{9ef}\u{9f0}\
	\x05\u{19c}\u{cf}\x02\u{9f0}\u{9f1}\x07\u{9b}\x02\x02\u{9f1}\u{9f2}\x07\
	\u{183}\x02\x02\u{9f2}\u{9f3}\x05\u{120}\u{91}\x02\u{9f3}\u{9f4}\x07\u{184}\
	\x02\x02\u{9f4}\u{11b}\x03\x02\x02\x02\u{9f5}\u{9f6}\x07\u{183}\x02\x02\
	\u{9f6}\u{9fb}\x05\u{19c}\u{cf}\x02\u{9f7}\u{9f8}\x07\x38\x02\x02\u{9f8}\
	\u{9fa}\x05\u{19c}\u{cf}\x02\u{9f9}\u{9f7}\x03\x02\x02\x02\u{9fa}\u{9fd}\
	\x03\x02\x02\x02\u{9fb}\u{9f9}\x03\x02\x02\x02\u{9fb}\u{9fc}\x03\x02\x02\
	\x02\u{9fc}\u{9ff}\x03\x02\x02\x02\u{9fd}\u{9fb}\x03\x02\x02\x02\u{9fe}\
	\u{a00}\x07\x38\x02\x02\u{9ff}\u{9fe}\x03\x02\x02\x02\u{9ff}\u{a00}\x03\
	\x02\x02\x02\u{a00}\u{a01}\x03\x02\x02\x02\u{a01}\u{a02}\x07\u{184}\x02\
	\x02\u{a02}\u{11d}\x03\x02\x02\x02\u{a03}\u{a04}\x07\u{183}\x02\x02\u{a04}\
	\u{a09}\x05\u{19c}\u{cf}\x02\u{a05}\u{a06}\x07\x38\x02\x02\u{a06}\u{a08}\
	\x05\u{19c}\u{cf}\x02\u{a07}\u{a05}\x03\x02\x02\x02\u{a08}\u{a0b}\x03\x02\
	\x02\x02\u{a09}\u{a07}\x03\x02\x02\x02\u{a09}\u{a0a}\x03\x02\x02\x02\u{a0a}\
	\u{a0c}\x03\x02\x02\x02\u{a0b}\u{a09}\x03\x02\x02\x02\u{a0c}\u{a11}\x07\
	\u{184}\x02\x02\u{a0d}\u{a0f}\x07\x14\x02\x02\u{a0e}\u{a0d}\x03\x02\x02\
	\x02\u{a0e}\u{a0f}\x03\x02\x02\x02\u{a0f}\u{a10}\x03\x02\x02\x02\u{a10}\
	\u{a12}\x05\u{118}\u{8d}\x02\u{a11}\u{a0e}\x03\x02\x02\x02\u{a11}\u{a12}\
	\x03\x02\x02\x02\u{a12}\u{11f}\x03\x02\x02\x02\u{a13}\u{a18}\x05\u{11e}\
	\u{90}\x02\u{a14}\u{a15}\x07\x38\x02\x02\u{a15}\u{a17}\x05\u{11e}\u{90}\
	\x02\u{a16}\u{a14}\x03\x02\x02\x02\u{a17}\u{a1a}\x03\x02\x02\x02\u{a18}\
	\u{a16}\x03\x02\x02\x02\u{a18}\u{a19}\x03\x02\x02\x02\u{a19}\u{a1c}\x03\
	\x02\x02\x02\u{a1a}\u{a18}\x03\x02\x02\x02\u{a1b}\u{a1d}\x07\x38\x02\x02\
	\u{a1c}\u{a1b}\x03\x02\x02\x02\u{a1c}\u{a1d}\x03\x02\x02\x02\u{a1d}\u{121}\
	\x03\x02\x02\x02\u{a1e}\u{a21}\x05\u{114}\u{8b}\x02\u{a1f}\u{a21}\x05\u{11a}\
	\u{8e}\x02\u{a20}\u{a1e}\x03\x02\x02\x02\u{a20}\u{a1f}\x03\x02\x02\x02\u{a21}\
	\u{123}\x03\x02\x02\x02\u{a22}\u{a27}\x05\u{110}\u{89}\x02\u{a23}\u{a24}\
	\x07\x38\x02\x02\u{a24}\u{a26}\x05\u{110}\u{89}\x02\u{a25}\u{a23}\x03\x02\
	\x02\x02\u{a26}\u{a29}\x03\x02\x02\x02\u{a27}\u{a25}\x03\x02\x02\x02\u{a27}\
	\u{a28}\x03\x02\x02\x02\u{a28}\u{a2b}\x03\x02\x02\x02\u{a29}\u{a27}\x03\
	\x02\x02\x02\u{a2a}\u{a2c}\x07\x38\x02\x02\u{a2b}\u{a2a}\x03\x02\x02\x02\
	\u{a2b}\u{a2c}\x03\x02\x02\x02\u{a2c}\u{125}\x03\x02\x02\x02\u{a2d}\u{a2e}\
	\x07\u{f8}\x02\x02\u{a2e}\u{a2f}\x07\u{183}\x02\x02\u{a2f}\u{a30}\x05\u{10c}\
	\u{87}\x02\u{a30}\u{a31}\x07\u{84}\x02\x02\u{a31}\u{a32}\x05\u{10e}\u{88}\
	\x02\u{a32}\u{a33}\x07\u{9b}\x02\x02\u{a33}\u{a34}\x07\u{183}\x02\x02\u{a34}\
	\u{a35}\x05\u{124}\u{93}\x02\u{a35}\u{a36}\x07\u{184}\x02\x02\u{a36}\u{a37}\
	\x07\u{184}\x02\x02\u{a37}\u{a42}\x03\x02\x02\x02\u{a38}\u{a3a}\x07\u{16a}\
	\x02\x02\u{a39}\u{a3b}\x05\x68\x35\x02\u{a3a}\u{a39}\x03\x02\x02\x02\u{a3a}\
	\u{a3b}\x03\x02\x02\x02\u{a3b}\u{a3c}\x03\x02\x02\x02\u{a3c}\u{a3d}\x07\
	\u{183}\x02\x02\u{a3d}\u{a3e}\x05\u{122}\u{92}\x02\u{a3e}\u{a3f}\x07\u{184}\
	\x02\x02\u{a3f}\u{a40}\x05\u{112}\u{8a}\x02\u{a40}\u{a42}\x03\x02\x02\x02\
	\u{a41}\u{a2d}\x03\x02\x02\x02\u{a41}\u{a38}\x03\x02\x02\x02\u{a42}\u{127}\
	\x03\x02\x02\x02\u{a43}\u{a44}\x07\u{13e}\x02\x02\u{a44}\u{a51}\x05\x10\
	\x09\x02\u{a45}\u{a46}\x07\u{13e}\x02\x02\u{a46}\u{a47}\x07\u{183}\x02\x02\
	\u{a47}\u{a48}\x05\x10\x09\x02\u{a48}\u{a49}\x07\u{184}\x02\x02\u{a49}\u{a51}\
	\x03\x02\x02\x02\u{a4a}\u{a51}\x05\u{f0}\x79\x02\u{a4b}\u{a51}\x05\u{be}\
	\x60\x02\u{a4c}\u{a4e}\x07\u{13e}\x02\x02\u{a4d}\u{a4c}\x03\x02\x02\x02\
	\u{a4d}\u{a4e}\x03\x02\x02\x02\u{a4e}\u{a4f}\x03\x02\x02\x02\u{a4f}\u{a51}\
	\x05\u{134}\u{9b}\x02\u{a50}\u{a43}\x03\x02\x02\x02\u{a50}\u{a45}\x03\x02\
	\x02\x02\u{a50}\u{a4a}\x03\x02\x02\x02\u{a50}\u{a4b}\x03\x02\x02\x02\u{a50}\
	\u{a4d}\x03\x02\x02\x02\u{a51}\u{129}\x03\x02\x02\x02\u{a52}\u{a54}\x07\
	\u{84}\x02\x02\u{a53}\u{a52}\x03\x02\x02\x02\u{a53}\u{a54}\x03\x02\x02\x02\
	\u{a54}\u{a55}\x03\x02\x02\x02\u{a55}\u{a56}\x09\x0d\x02\x02\u{a56}\u{a57}\
	\x07\x14\x02\x02\u{a57}\u{a58}\x07\u{e2}\x02\x02\u{a58}\u{a61}\x05\u{12c}\
	\u{97}\x02\u{a59}\u{a5b}\x07\u{84}\x02\x02\u{a5a}\u{a59}\x03\x02\x02\x02\
	\u{a5a}\u{a5b}\x03\x02\x02\x02\u{a5b}\u{a5c}\x03\x02\x02\x02\u{a5c}\u{a5d}\
	\x09\x0e\x02\x02\u{a5d}\u{a5e}\x07\x14\x02\x02\u{a5e}\u{a5f}\x07\u{e2}\x02\
	\x02\u{a5f}\u{a61}\x05\u{148}\u{a5}\x02\u{a60}\u{a53}\x03\x02\x02\x02\u{a60}\
	\u{a5a}\x03\x02\x02\x02\u{a61}\u{12b}\x03\x02\x02\x02\u{a62}\u{a65}\x07\
	\u{1a6}\x02\x02\u{a63}\u{a65}\x05\u{162}\u{b2}\x02\u{a64}\u{a62}\x03\x02\
	\x02\x02\u{a64}\u{a63}\x03\x02\x02\x02\u{a65}\u{12d}\x03\x02\x02\x02\u{a66}\
	\u{a6e}\x05\u{128}\u{95}\x02\u{a67}\u{a69}\x07\x14\x02\x02\u{a68}\u{a67}\
	\x03\x02\x02\x02\u{a68}\u{a69}\x03\x02\x02\x02\u{a69}\u{a6a}\x03\x02\x02\
	\x02\u{a6a}\u{a6c}\x05\u{19e}\u{d0}\x02\u{a6b}\u{a6d}\x05\u{130}\u{99}\x02\
	\u{a6c}\u{a6b}\x03\x02\x02\x02\u{a6c}\u{a6d}\x03\x02\x02\x02\u{a6d}\u{a6f}\
	\x03\x02\x02\x02\u{a6e}\u{a68}\x03\x02\x02\x02\u{a6e}\u{a6f}\x03\x02\x02\
	\x02\u{a6f}\u{12f}\x03\x02\x02\x02\u{a70}\u{a71}\x07\u{183}\x02\x02\u{a71}\
	\u{a73}\x05\u{1a8}\u{d5}\x02\u{a72}\u{a74}\x07\x38\x02\x02\u{a73}\u{a72}\
	\x03\x02\x02\x02\u{a73}\u{a74}\x03\x02\x02\x02\u{a74}\u{a75}\x03\x02\x02\
	\x02\u{a75}\u{a76}\x07\u{184}\x02\x02\u{a76}\u{131}\x03\x02\x02\x02\u{a77}\
	\u{a79}\x05\x10\x09\x02\u{a78}\u{a7a}\x05\u{12a}\u{96}\x02\u{a79}\u{a78}\
	\x03\x02\x02\x02\u{a79}\u{a7a}\x03\x02\x02\x02\u{a7a}\u{a7c}\x03\x02\x02\
	\x02\u{a7b}\u{a7d}\x05\x4e\x28\x02\u{a7c}\u{a7b}\x03\x02\x02\x02\u{a7c}\
	\u{a7d}\x03\x02\x02\x02\u{a7d}\u{a87}\x03\x02\x02\x02\u{a7e}\u{a7f}\x07\
	\u{183}\x02\x02\u{a7f}\u{a80}\x05\x7a\x3e\x02\u{a80}\u{a81}\x07\u{184}\x02\
	\x02\u{a81}\u{a87}\x03\x02\x02\x02\u{a82}\u{a83}\x07\u{183}\x02\x02\u{a83}\
	\u{a84}\x05\u{102}\u{82}\x02\u{a84}\u{a85}\x07\u{184}\x02\x02\u{a85}\u{a87}\
	\x03\x02\x02\x02\u{a86}\u{a77}\x03\x02\x02\x02\u{a86}\u{a7e}\x03\x02\x02\
	\x02\u{a86}\u{a82}\x03\x02\x02\x02\u{a87}\u{133}\x03\x02\x02\x02\u{a88}\
	\u{a89}\x05\u{15c}\u{af}\x02\u{a89}\u{a95}\x07\u{183}\x02\x02\u{a8a}\u{a8f}\
	\x05\u{138}\u{9d}\x02\u{a8b}\u{a8c}\x07\x38\x02\x02\u{a8c}\u{a8e}\x05\u{138}\
	\u{9d}\x02\u{a8d}\u{a8b}\x03\x02\x02\x02\u{a8e}\u{a91}\x03\x02\x02\x02\u{a8f}\
	\u{a8d}\x03\x02\x02\x02\u{a8f}\u{a90}\x03\x02\x02\x02\u{a90}\u{a93}\x03\
	\x02\x02\x02\u{a91}\u{a8f}\x03\x02\x02\x02\u{a92}\u{a94}\x07\x38\x02\x02\
	\u{a93}\u{a92}\x03\x02\x02\x02\u{a93}\u{a94}\x03\x02\x02\x02\u{a94}\u{a96}\
	\x03\x02\x02\x02\u{a95}\u{a8a}\x03\x02\x02\x02\u{a95}\u{a96}\x03\x02\x02\
	\x02\u{a96}\u{a97}\x03\x02\x02\x02\u{a97}\u{a98}\x07\u{184}\x02\x02\u{a98}\
	\u{135}\x03\x02\x02\x02\u{a99}\u{a9a}\x05\u{19c}\u{cf}\x02\u{a9a}\u{137}\
	\x03\x02\x02\x02\u{a9b}\u{a9c}\x05\u{136}\u{9c}\x02\u{a9c}\u{a9d}\x07\x03\
	\x02\x02\u{a9d}\u{a9f}\x03\x02\x02\x02\u{a9e}\u{a9b}\x03\x02\x02\x02\u{a9e}\
	\u{a9f}\x03\x02\x02\x02\u{a9f}\u{aa2}\x03\x02\x02\x02\u{aa0}\u{aa3}\x05\
	\u{13a}\u{9e}\x02\u{aa1}\u{aa3}\x05\u{13e}\u{a0}\x02\u{aa2}\u{aa0}\x03\x02\
	\x02\x02\u{aa2}\u{aa1}\x03\x02\x02\x02\u{aa3}\u{139}\x03\x02\x02\x02\u{aa4}\
	\u{ab9}\x05\u{13c}\u{9f}\x02\u{aa5}\u{aa6}\x07\u{f2}\x02\x02\u{aa6}\u{ab7}\
	\x07\x22\x02\x02\u{aa7}\u{ab3}\x07\u{183}\x02\x02\u{aa8}\u{aad}\x05\u{13e}\
	\u{a0}\x02\u{aa9}\u{aaa}\x07\x38\x02\x02\u{aaa}\u{aac}\x05\u{13e}\u{a0}\
	\x02\u{aab}\u{aa9}\x03\x02\x02\x02\u{aac}\u{aaf}\x03\x02\x02\x02\u{aad}\
	\u{aab}\x03\x02\x02\x02\u{aad}\u{aae}\x03\x02\x02\x02\u{aae}\u{ab1}\x03\
	\x02\x02\x02\u{aaf}\u{aad}\x03\x02\x02\x02\u{ab0}\u{ab2}\x07\x38\x02\x02\
	\u{ab1}\u{ab0}\x03\x02\x02\x02\u{ab1}\u{ab2}\x03\x02\x02\x02\u{ab2}\u{ab4}\
	\x03\x02\x02\x02\u{ab3}\u{aa8}\x03\x02\x02\x02\u{ab3}\u{ab4}\x03\x02\x02\
	\x02\u{ab4}\u{ab5}\x03\x02\x02\x02\u{ab5}\u{ab8}\x07\u{184}\x02\x02\u{ab6}\
	\u{ab8}\x05\u{13e}\u{a0}\x02\u{ab7}\u{aa7}\x03\x02\x02\x02\u{ab7}\u{ab6}\
	\x03\x02\x02\x02\u{ab8}\u{aba}\x03\x02\x02\x02\u{ab9}\u{aa5}\x03\x02\x02\
	\x02\u{ab9}\u{aba}\x03\x02\x02\x02\u{aba}\u{13b}\x03\x02\x02\x02\u{abb}\
	\u{abc}\x07\u{146}\x02\x02\u{abc}\u{abd}\x07\u{183}\x02\x02\u{abd}\u{abe}\
	\x05\u{192}\u{ca}\x02\u{abe}\u{ac6}\x07\u{184}\x02\x02\u{abf}\u{ac1}\x07\
	\x14\x02\x02\u{ac0}\u{abf}\x03\x02\x02\x02\u{ac0}\u{ac1}\x03\x02\x02\x02\
	\u{ac1}\u{ac2}\x03\x02\x02\x02\u{ac2}\u{ac4}\x05\u{19c}\u{cf}\x02\u{ac3}\
	\u{ac5}\x05\u{130}\u{99}\x02\u{ac4}\u{ac3}\x03\x02\x02\x02\u{ac4}\u{ac5}\
	\x03\x02\x02\x02\u{ac5}\u{ac7}\x03\x02\x02\x02\u{ac6}\u{ac0}\x03\x02\x02\
	\x02\u{ac6}\u{ac7}\x03\x02\x02\x02\u{ac7}\u{ad6}\x03\x02\x02\x02\u{ac8}\
	\u{ac9}\x07\u{146}\x02\x02\u{ac9}\u{aca}\x07\u{183}\x02\x02\u{aca}\u{acb}\
	\x05\x7a\x3e\x02\u{acb}\u{ad3}\x07\u{184}\x02\x02\u{acc}\u{ace}\x07\x14\
	\x02\x02\u{acd}\u{acc}\x03\x02\x02\x02\u{acd}\u{ace}\x03\x02\x02\x02\u{ace}\
	\u{acf}\x03\x02\x02\x02\u{acf}\u{ad1}\x05\u{19c}\u{cf}\x02\u{ad0}\u{ad2}\
	\x05\u{130}\u{99}\x02\u{ad1}\u{ad0}\x03\x02\x02\x02\u{ad1}\u{ad2}\x03\x02\
	\x02\x02\u{ad2}\u{ad4}\x03\x02\x02\x02\u{ad3}\u{acd}\x03\x02\x02\x02\u{ad3}\
	\u{ad4}\x03\x02\x02\x02\u{ad4}\u{ad6}\x03\x02\x02\x02\u{ad5}\u{abb}\x03\
	\x02\x02\x02\u{ad5}\u{ac8}\x03\x02\x02\x02\u{ad6}\u{13d}\x03\x02\x02\x02\
	\u{ad7}\u{ad8}\x05\u{140}\u{a1}\x02\u{ad8}\u{13f}\x03\x02\x02\x02\u{ad9}\
	\u{ada}\x08\u{a1}\x01\x02\u{ada}\u{ade}\x05\u{144}\u{a3}\x02\u{adb}\u{adc}\
	\x09\x0f\x02\x02\u{adc}\u{ade}\x05\u{140}\u{a1}\x05\u{add}\u{ad9}\x03\x02\
	\x02\x02\u{add}\u{adb}\x03\x02\x02\x02\u{ade}\u{ae9}\x03\x02\x02\x02\u{adf}\
	\u{ae0}\x0c\x04\x02\x02\u{ae0}\u{ae1}\x07\x0d\x02\x02\u{ae1}\u{ae8}\x05\
	\u{140}\u{a1}\x05\u{ae2}\u{ae3}\x0c\x03\x02\x02\u{ae3}\u{ae4}\x07\u{e9}\
	\x02\x02\u{ae4}\u{ae8}\x05\u{140}\u{a1}\x04\u{ae5}\u{ae6}\x0c\x07\x02\x02\
	\u{ae6}\u{ae8}\x05\u{142}\u{a2}\x02\u{ae7}\u{adf}\x03\x02\x02\x02\u{ae7}\
	\u{ae2}\x03\x02\x02\x02\u{ae7}\u{ae5}\x03\x02\x02\x02\u{ae8}\u{aeb}\x03\
	\x02\x02\x02\u{ae9}\u{ae7}\x03\x02\x02\x02\u{ae9}\u{aea}\x03\x02\x02\x02\
	\u{aea}\u{141}\x03\x02\x02\x02\u{aeb}\u{ae9}\x03\x02\x02\x02\u{aec}\u{aed}\
	\x05\u{166}\u{b4}\x02\u{aed}\u{aee}\x05\u{148}\u{a5}\x02\u{aee}\u{af6}\x03\
	\x02\x02\x02\u{aef}\u{af0}\x05\u{166}\u{b4}\x02\u{af0}\u{af1}\x05\u{168}\
	\u{b5}\x02\u{af1}\u{af2}\x07\u{183}\x02\x02\u{af2}\u{af3}\x05\x7a\x3e\x02\
	\u{af3}\u{af4}\x07\u{184}\x02\x02\u{af4}\u{af6}\x03\x02\x02\x02\u{af5}\u{aec}\
	\x03\x02\x02\x02\u{af5}\u{aef}\x03\x02\x02\x02\u{af6}\u{143}\x03\x02\x02\
	\x02\u{af7}\u{af9}\x05\u{148}\u{a5}\x02\u{af8}\u{afa}\x05\u{146}\u{a4}\x02\
	\u{af9}\u{af8}\x03\x02\x02\x02\u{af9}\u{afa}\x03\x02\x02\x02\u{afa}\u{145}\
	\x03\x02\x02\x02\u{afb}\u{afd}\x07\u{de}\x02\x02\u{afc}\u{afb}\x03\x02\x02\
	\x02\u{afc}\u{afd}\x03\x02\x02\x02\u{afd}\u{afe}\x03\x02\x02\x02\u{afe}\
	\u{aff}\x07\x19\x02\x02\u{aff}\u{b00}\x05\u{148}\u{a5}\x02\u{b00}\u{b01}\
	\x07\x0d\x02\x02\u{b01}\u{b02}\x05\u{148}\u{a5}\x02\u{b02}\u{b57}\x03\x02\
	\x02\x02\u{b03}\u{b05}\x07\u{de}\x02\x02\u{b04}\u{b03}\x03\x02\x02\x02\u{b04}\
	\u{b05}\x03\x02\x02\x02\u{b05}\u{b06}\x03\x02\x02\x02\u{b06}\u{b07}\x07\
	\u{9b}\x02\x02\u{b07}\u{b08}\x07\u{183}\x02\x02\u{b08}\u{b0d}\x05\u{13e}\
	\u{a0}\x02\u{b09}\u{b0a}\x07\x38\x02\x02\u{b0a}\u{b0c}\x05\u{13e}\u{a0}\
	\x02\u{b0b}\u{b09}\x03\x02\x02\x02\u{b0c}\u{b0f}\x03\x02\x02\x02\u{b0d}\
	\u{b0b}\x03\x02\x02\x02\u{b0d}\u{b0e}\x03\x02\x02\x02\u{b0e}\u{b11}\x03\
	\x02\x02\x02\u{b0f}\u{b0d}\x03\x02\x02\x02\u{b10}\u{b12}\x07\x38\x02\x02\
	\u{b11}\u{b10}\x03\x02\x02\x02\u{b11}\u{b12}\x03\x02\x02\x02\u{b12}\u{b13}\
	\x03\x02\x02\x02\u{b13}\u{b14}\x07\u{184}\x02\x02\u{b14}\u{b57}\x03\x02\
	\x02\x02\u{b15}\u{b17}\x07\u{de}\x02\x02\u{b16}\u{b15}\x03\x02\x02\x02\u{b16}\
	\u{b17}\x03\x02\x02\x02\u{b17}\u{b18}\x03\x02\x02\x02\u{b18}\u{b19}\x07\
	\u{9b}\x02\x02\u{b19}\u{b1a}\x07\u{183}\x02\x02\u{b1a}\u{b1b}\x05\x7a\x3e\
	\x02\u{b1b}\u{b1c}\x07\u{184}\x02\x02\u{b1c}\u{b57}\x03\x02\x02\x02\u{b1d}\
	\u{b1f}\x07\u{de}\x02\x02\u{b1e}\u{b1d}\x03\x02\x02\x02\u{b1e}\u{b1f}\x03\
	\x02\x02\x02\u{b1f}\u{b20}\x03\x02\x02\x02\u{b20}\u{b21}\x09\x10\x02\x02\
	\u{b21}\u{b57}\x05\u{148}\u{a5}\x02\u{b22}\u{b24}\x07\u{de}\x02\x02\u{b23}\
	\u{b22}\x03\x02\x02\x02\u{b23}\u{b24}\x03\x02\x02\x02\u{b24}\u{b25}\x03\
	\x02\x02\x02\u{b25}\u{b26}\x07\u{b6}\x02\x02\u{b26}\u{b27}\x09\x11\x02\x02\
	\u{b27}\u{b28}\x07\u{183}\x02\x02\u{b28}\u{b2d}\x05\u{148}\u{a5}\x02\u{b29}\
	\u{b2a}\x07\x38\x02\x02\u{b2a}\u{b2c}\x05\u{148}\u{a5}\x02\u{b2b}\u{b29}\
	\x03\x02\x02\x02\u{b2c}\u{b2f}\x03\x02\x02\x02\u{b2d}\u{b2b}\x03\x02\x02\
	\x02\u{b2d}\u{b2e}\x03\x02\x02\x02\u{b2e}\u{b30}\x03\x02\x02\x02\u{b2f}\
	\u{b2d}\x03\x02\x02\x02\u{b30}\u{b31}\x07\u{184}\x02\x02\u{b31}\u{b57}\x03\
	\x02\x02\x02\u{b32}\u{b34}\x07\u{de}\x02\x02\u{b33}\u{b32}\x03\x02\x02\x02\
	\u{b33}\u{b34}\x03\x02\x02\x02\u{b34}\u{b35}\x03\x02\x02\x02\u{b35}\u{b36}\
	\x09\x12\x02\x02\u{b36}\u{b39}\x05\u{148}\u{a5}\x02\u{b37}\u{b38}\x07\x6f\
	\x02\x02\u{b38}\u{b3a}\x05\u{148}\u{a5}\x02\u{b39}\u{b37}\x03\x02\x02\x02\
	\u{b39}\u{b3a}\x03\x02\x02\x02\u{b3a}\u{b57}\x03\x02\x02\x02\u{b3b}\u{b3d}\
	\x07\u{aa}\x02\x02\u{b3c}\u{b3e}\x07\u{de}\x02\x02\u{b3d}\u{b3c}\x03\x02\
	\x02\x02\u{b3d}\u{b3e}\x03\x02\x02\x02\u{b3e}\u{b3f}\x03\x02\x02\x02\u{b3f}\
	\u{b57}\x07\u{df}\x02\x02\u{b40}\u{b42}\x07\u{aa}\x02\x02\u{b41}\u{b43}\
	\x07\u{de}\x02\x02\u{b42}\u{b41}\x03\x02\x02\x02\u{b42}\u{b43}\x03\x02\x02\
	\x02\u{b43}\u{b44}\x03\x02\x02\x02\u{b44}\u{b45}\x07\x67\x02\x02\u{b45}\
	\u{b46}\x07\u{88}\x02\x02\u{b46}\u{b57}\x05\u{148}\u{a5}\x02\u{b47}\u{b49}\
	\x07\u{aa}\x02\x02\u{b48}\u{b4a}\x07\u{de}\x02\x02\u{b49}\u{b48}\x03\x02\
	\x02\x02\u{b49}\u{b4a}\x03\x02\x02\x02\u{b4a}\u{b4b}\x03\x02\x02\x02\u{b4b}\
	\u{b57}\x07\u{15f}\x02\x02\u{b4c}\u{b4e}\x07\u{aa}\x02\x02\u{b4d}\u{b4f}\
	\x07\u{de}\x02\x02\u{b4e}\u{b4d}\x03\x02\x02\x02\u{b4e}\u{b4f}\x03\x02\x02\
	\x02\u{b4f}\u{b50}\x03\x02\x02\x02\u{b50}\u{b57}\x07\x7c\x02\x02\u{b51}\
	\u{b53}\x07\u{aa}\x02\x02\u{b52}\u{b54}\x07\u{de}\x02\x02\u{b53}\u{b52}\
	\x03\x02\x02\x02\u{b53}\u{b54}\x03\x02\x02\x02\u{b54}\u{b55}\x03\x02\x02\
	\x02\u{b55}\u{b57}\x07\u{168}\x02\x02\u{b56}\u{afc}\x03\x02\x02\x02\u{b56}\
	\u{b04}\x03\x02\x02\x02\u{b56}\u{b16}\x03\x02\x02\x02\u{b56}\u{b1e}\x03\
	\x02\x02\x02\u{b56}\u{b23}\x03\x02\x02\x02\u{b56}\u{b33}\x03\x02\x02\x02\
	\u{b56}\u{b3b}\x03\x02\x02\x02\u{b56}\u{b40}\x03\x02\x02\x02\u{b56}\u{b47}\
	\x03\x02\x02\x02\u{b56}\u{b4c}\x03\x02\x02\x02\u{b56}\u{b51}\x03\x02\x02\
	\x02\u{b57}\u{147}\x03\x02\x02\x02\u{b58}\u{b59}\x08\u{a5}\x01\x02\u{b59}\
	\u{b5d}\x05\u{14a}\u{a6}\x02\u{b5a}\u{b5b}\x09\x13\x02\x02\u{b5b}\u{b5d}\
	\x05\u{148}\u{a5}\x08\u{b5c}\u{b58}\x03\x02\x02\x02\u{b5c}\u{b5a}\x03\x02\
	\x02\x02\u{b5d}\u{b72}\x03\x02\x02\x02\u{b5e}\u{b5f}\x0c\x07\x02\x02\u{b5f}\
	\u{b60}\x09\x14\x02\x02\u{b60}\u{b71}\x05\u{148}\u{a5}\x08\u{b61}\u{b62}\
	\x0c\x06\x02\x02\u{b62}\u{b63}\x09\x15\x02\x02\u{b63}\u{b71}\x05\u{148}\
	\u{a5}\x07\u{b64}\u{b65}\x0c\x05\x02\x02\u{b65}\u{b66}\x07\u{198}\x02\x02\
	\u{b66}\u{b71}\x05\u{148}\u{a5}\x06\u{b67}\u{b68}\x0c\x04\x02\x02\u{b68}\
	\u{b69}\x07\u{1a0}\x02\x02\u{b69}\u{b71}\x05\u{148}\u{a5}\x05\u{b6a}\u{b6b}\
	\x0c\x03\x02\x02\u{b6b}\u{b6c}\x09\x16\x02\x02\u{b6c}\u{b71}\x05\u{148}\
	\u{a5}\x04\u{b6d}\u{b6e}\x0c\x09\x02\x02\u{b6e}\u{b6f}\x07\x16\x02\x02\u{b6f}\
	\u{b71}\x05\u{164}\u{b3}\x02\u{b70}\u{b5e}\x03\x02\x02\x02\u{b70}\u{b61}\
	\x03\x02\x02\x02\u{b70}\u{b64}\x03\x02\x02\x02\u{b70}\u{b67}\x03\x02\x02\
	\x02\u{b70}\u{b6a}\x03\x02\x02\x02\u{b70}\u{b6d}\x03\x02\x02\x02\u{b71}\
	\u{b74}\x03\x02\x02\x02\u{b72}\u{b70}\x03\x02\x02\x02\u{b72}\u{b73}\x03\
	\x02\x02\x02\u{b73}\u{149}\x03\x02\x02\x02\u{b74}\u{b72}\x03\x02\x02\x02\
	\u{b75}\u{b76}\x08\u{a6}\x01\x02\u{b76}\u{d4e}\x09\x17\x02\x02\u{b77}\u{d4e}\
	\x05\u{154}\u{ab}\x02\u{b78}\u{b79}\x07\u{183}\x02\x02\u{b79}\u{b7c}\x05\
	\u{13e}\u{a0}\x02\u{b7a}\u{b7b}\x07\x38\x02\x02\u{b7b}\u{b7d}\x05\u{13e}\
	\u{a0}\x02\u{b7c}\u{b7a}\x03\x02\x02\x02\u{b7d}\u{b7e}\x03\x02\x02\x02\u{b7e}\
	\u{b7c}\x03\x02\x02\x02\u{b7e}\u{b7f}\x03\x02\x02\x02\u{b7f}\u{b81}\x03\
	\x02\x02\x02\u{b80}\u{b82}\x07\x38\x02\x02\u{b81}\u{b80}\x03\x02\x02\x02\
	\u{b81}\u{b82}\x03\x02\x02\x02\u{b82}\u{b83}\x03\x02\x02\x02\u{b83}\u{b84}\
	\x07\u{184}\x02\x02\u{b84}\u{d4e}\x03\x02\x02\x02\u{b85}\u{b86}\x07\u{140}\
	\x02\x02\u{b86}\u{b8f}\x07\u{183}\x02\x02\u{b87}\u{b8c}\x05\u{e2}\x72\x02\
	\u{b88}\u{b89}\x07\x38\x02\x02\u{b89}\u{b8b}\x05\u{e2}\x72\x02\u{b8a}\u{b88}\
	\x03\x02\x02\x02\u{b8b}\u{b8e}\x03\x02\x02\x02\u{b8c}\u{b8a}\x03\x02\x02\
	\x02\u{b8c}\u{b8d}\x03\x02\x02\x02\u{b8d}\u{b90}\x03\x02\x02\x02\u{b8e}\
	\u{b8c}\x03\x02\x02\x02\u{b8f}\u{b87}\x03\x02\x02\x02\u{b8f}\u{b90}\x03\
	\x02\x02\x02\u{b90}\u{b91}\x03\x02\x02\x02\u{b91}\u{d4e}\x07\u{184}\x02\
	\x02\u{b92}\u{b93}\x07\u{fa}\x02\x02\u{b93}\u{b94}\x07\u{183}\x02\x02\u{b94}\
	\u{b95}\x05\u{148}\u{a5}\x02\u{b95}\u{b96}\x07\u{9b}\x02\x02\u{b96}\u{b97}\
	\x05\u{148}\u{a5}\x02\u{b97}\u{b98}\x07\u{184}\x02\x02\u{b98}\u{d4e}\x03\
	\x02\x02\x02\u{b99}\u{b9a}\x07\u{ba}\x02\x02\u{b9a}\u{b9c}\x07\u{183}\x02\
	\x02\u{b9b}\u{b9d}\x05\u{bc}\x5f\x02\u{b9c}\u{b9b}\x03\x02\x02\x02\u{b9c}\
	\u{b9d}\x03\x02\x02\x02\u{b9d}\u{b9e}\x03\x02\x02\x02\u{b9e}\u{ba1}\x05\
	\u{13e}\u{a0}\x02\u{b9f}\u{ba0}\x07\x38\x02\x02\u{ba0}\u{ba2}\x05\u{13e}\
	\u{a0}\x02\u{ba1}\u{b9f}\x03\x02\x02\x02\u{ba1}\u{ba2}\x03\x02\x02\x02\u{ba2}\
	\u{ba4}\x03\x02\x02\x02\u{ba3}\u{ba5}\x07\x38\x02\x02\u{ba4}\u{ba3}\x03\
	\x02\x02\x02\u{ba4}\u{ba5}\x03\x02\x02\x02\u{ba5}\u{ba6}\x03\x02\x02\x02\
	\u{ba6}\u{bb9}\x07\u{184}\x02\x02\u{ba7}\u{ba8}\x07\u{17f}\x02\x02\u{ba8}\
	\u{ba9}\x07\u{90}\x02\x02\u{ba9}\u{baa}\x07\u{183}\x02\x02\u{baa}\u{bab}\
	\x07\u{ea}\x02\x02\u{bab}\u{bac}\x07\x22\x02\x02\u{bac}\u{bb1}\x05\u{c2}\
	\x62\x02\u{bad}\u{bae}\x07\x38\x02\x02\u{bae}\u{bb0}\x05\u{c2}\x62\x02\u{baf}\
	\u{bad}\x03\x02\x02\x02\u{bb0}\u{bb3}\x03\x02\x02\x02\u{bb1}\u{baf}\x03\
	\x02\x02\x02\u{bb1}\u{bb2}\x03\x02\x02\x02\u{bb2}\u{bb5}\x03\x02\x02\x02\
	\u{bb3}\u{bb1}\x03\x02\x02\x02\u{bb4}\u{bb6}\x07\x38\x02\x02\u{bb5}\u{bb4}\
	\x03\x02\x02\x02\u{bb5}\u{bb6}\x03\x02\x02\x02\u{bb6}\u{bb7}\x03\x02\x02\
	\x02\u{bb7}\u{bb8}\x07\u{184}\x02\x02\u{bb8}\u{bba}\x03\x02\x02\x02\u{bb9}\
	\u{ba7}\x03\x02\x02\x02\u{bb9}\u{bba}\x03\x02\x02\x02\u{bba}\u{bca}\x03\
	\x02\x02\x02\u{bbb}\u{bbc}\x07\u{ee}\x02\x02\u{bbc}\u{bc7}\x07\u{183}\x02\
	\x02\u{bbd}\u{bbe}\x07\u{f2}\x02\x02\u{bbe}\u{bbf}\x07\x22\x02\x02\u{bbf}\
	\u{bc4}\x05\u{13e}\u{a0}\x02\u{bc0}\u{bc1}\x07\x38\x02\x02\u{bc1}\u{bc3}\
	\x05\u{13e}\u{a0}\x02\u{bc2}\u{bc0}\x03\x02\x02\x02\u{bc3}\u{bc6}\x03\x02\
	\x02\x02\u{bc4}\u{bc2}\x03\x02\x02\x02\u{bc4}\u{bc5}\x03\x02\x02\x02\u{bc5}\
	\u{bc8}\x03\x02\x02\x02\u{bc6}\u{bc4}\x03\x02\x02\x02\u{bc7}\u{bbd}\x03\
	\x02\x02\x02\u{bc7}\u{bc8}\x03\x02\x02\x02\u{bc8}\u{bc9}\x03\x02\x02\x02\
	\u{bc9}\u{bcb}\x07\u{184}\x02\x02\u{bca}\u{bbb}\x03\x02\x02\x02\u{bca}\u{bcb}\
	\x03\x02\x02\x02\u{bcb}\u{d4e}\x03\x02\x02\x02\u{bcc}\u{bcd}\x07\x76\x02\
	\x02\u{bcd}\u{bce}\x07\u{183}\x02\x02\u{bce}\u{bcf}\x05\x7a\x3e\x02\u{bcf}\
	\u{bd0}\x07\u{184}\x02\x02\u{bd0}\u{d4e}\x03\x02\x02\x02\u{bd1}\u{bd2}\x07\
	\x27\x02\x02\u{bd2}\u{bd4}\x05\u{13e}\u{a0}\x02\u{bd3}\u{bd5}\x05\u{184}\
	\u{c3}\x02\u{bd4}\u{bd3}\x03\x02\x02\x02\u{bd5}\u{bd6}\x03\x02\x02\x02\u{bd6}\
	\u{bd4}\x03\x02\x02\x02\u{bd6}\u{bd7}\x03\x02\x02\x02\u{bd7}\u{bda}\x03\
	\x02\x02\x02\u{bd8}\u{bd9}\x07\x6d\x02\x02\u{bd9}\u{bdb}\x05\u{13e}\u{a0}\
	\x02\u{bda}\u{bd8}\x03\x02\x02\x02\u{bda}\u{bdb}\x03\x02\x02\x02\u{bdb}\
	\u{bdc}\x03\x02\x02\x02\u{bdc}\u{bdd}\x07\x6e\x02\x02\u{bdd}\u{d4e}\x03\
	\x02\x02\x02\u{bde}\u{be0}\x07\x27\x02\x02\u{bdf}\u{be1}\x05\u{184}\u{c3}\
	\x02\u{be0}\u{bdf}\x03\x02\x02\x02\u{be1}\u{be2}\x03\x02\x02\x02\u{be2}\
	\u{be0}\x03\x02\x02\x02\u{be2}\u{be3}\x03\x02\x02\x02\u{be3}\u{be6}\x03\
	\x02\x02\x02\u{be4}\u{be5}\x07\x6d\x02\x02\u{be5}\u{be7}\x05\u{13e}\u{a0}\
	\x02\u{be6}\u{be4}\x03\x02\x02\x02\u{be6}\u{be7}\x03\x02\x02\x02\u{be7}\
	\u{be8}\x03\x02\x02\x02\u{be8}\u{be9}\x07\x6e\x02\x02\u{be9}\u{d4e}\x03\
	\x02\x02\x02\u{bea}\u{beb}\x07\x28\x02\x02\u{beb}\u{bec}\x07\u{183}\x02\
	\x02\u{bec}\u{bed}\x05\u{13e}\u{a0}\x02\u{bed}\u{bee}\x07\x14\x02\x02\u{bee}\
	\u{bef}\x05\u{17a}\u{be}\x02\u{bef}\u{bf0}\x07\u{184}\x02\x02\u{bf0}\u{d4e}\
	\x03\x02\x02\x02\u{bf1}\u{bf2}\x07\u{161}\x02\x02\u{bf2}\u{bf3}\x07\u{183}\
	\x02\x02\u{bf3}\u{bf4}\x05\u{13e}\u{a0}\x02\u{bf4}\u{bf5}\x07\x14\x02\x02\
	\u{bf5}\u{bf6}\x05\u{17a}\u{be}\x02\u{bf6}\u{bf7}\x07\u{184}\x02\x02\u{bf7}\
	\u{d4e}\x03\x02\x02\x02\u{bf8}\u{bf9}\x07\u{15e}\x02\x02\u{bf9}\u{bfb}\x07\
	\u{183}\x02\x02\u{bfa}\u{bfc}\x05\u{f8}\x7d\x02\u{bfb}\u{bfa}\x03\x02\x02\
	\x02\u{bfb}\u{bfc}\x03\x02\x02\x02\u{bfc}\u{bfe}\x03\x02\x02\x02\u{bfd}\
	\u{bff}\x05\u{148}\u{a5}\x02\u{bfe}\u{bfd}\x03\x02\x02\x02\u{bfe}\u{bff}\
	\x03\x02\x02\x02\u{bff}\u{c00}\x03\x02\x02\x02\u{c00}\u{c01}\x07\u{88}\x02\
	\x02\u{c01}\u{c02}\x03\x02\x02\x02\u{c02}\u{c03}\x05\u{148}\u{a5}\x02\u{c03}\
	\u{c04}\x07\u{184}\x02\x02\u{c04}\u{d4e}\x03\x02\x02\x02\u{c05}\u{c06}\x07\
	\u{15e}\x02\x02\u{c06}\u{c0e}\x07\u{183}\x02\x02\u{c07}\u{c09}\x05\u{f8}\
	\x7d\x02\u{c08}\u{c0a}\x05\u{148}\u{a5}\x02\u{c09}\u{c08}\x03\x02\x02\x02\
	\u{c09}\u{c0a}\x03\x02\x02\x02\u{c0a}\u{c0c}\x03\x02\x02\x02\u{c0b}\u{c0d}\
	\x07\u{88}\x02\x02\u{c0c}\u{c0b}\x03\x02\x02\x02\u{c0c}\u{c0d}\x03\x02\x02\
	\x02\u{c0d}\u{c0f}\x03\x02\x02\x02\u{c0e}\u{c07}\x03\x02\x02\x02\u{c0e}\
	\u{c0f}\x03\x02\x02\x02\u{c0f}\u{c10}\x03\x02\x02\x02\u{c10}\u{c11}\x05\
	\u{148}\u{a5}\x02\u{c11}\u{c12}\x07\u{184}\x02\x02\u{c12}\u{d4e}\x03\x02\
	\x02\x02\u{c13}\u{c14}\x07\u{15e}\x02\x02\u{c14}\u{c15}\x07\u{183}\x02\x02\
	\u{c15}\u{c16}\x05\u{148}\u{a5}\x02\u{c16}\u{c17}\x07\x38\x02\x02\u{c17}\
	\u{c19}\x05\u{148}\u{a5}\x02\u{c18}\u{c1a}\x07\x38\x02\x02\u{c19}\u{c18}\
	\x03\x02\x02\x02\u{c19}\u{c1a}\x03\x02\x02\x02\u{c1a}\u{c1b}\x03\x02\x02\
	\x02\u{c1b}\u{c1c}\x07\u{184}\x02\x02\u{c1c}\u{d4e}\x03\x02\x02\x02\u{c1d}\
	\u{c1e}\x07\u{142}\x02\x02\u{c1e}\u{c1f}\x07\u{183}\x02\x02\u{c1f}\u{c20}\
	\x05\u{148}\u{a5}\x02\u{c20}\u{c21}\x07\u{88}\x02\x02\u{c21}\u{c24}\x05\
	\u{148}\u{a5}\x02\u{c22}\u{c23}\x07\u{84}\x02\x02\u{c23}\u{c25}\x05\u{148}\
	\u{a5}\x02\u{c24}\u{c22}\x03\x02\x02\x02\u{c24}\u{c25}\x03\x02\x02\x02\u{c25}\
	\u{c26}\x03\x02\x02\x02\u{c26}\u{c27}\x07\u{184}\x02\x02\u{c27}\u{d4e}\x03\
	\x02\x02\x02\u{c28}\u{c29}\x07\u{141}\x02\x02\u{c29}\u{c2a}\x07\u{183}\x02\
	\x02\u{c2a}\u{c2b}\x05\u{148}\u{a5}\x02\u{c2b}\u{c2c}\x07\u{88}\x02\x02\
	\u{c2c}\u{c2f}\x05\u{148}\u{a5}\x02\u{c2d}\u{c2e}\x07\u{84}\x02\x02\u{c2e}\
	\u{c30}\x05\u{148}\u{a5}\x02\u{c2f}\u{c2d}\x03\x02\x02\x02\u{c2f}\u{c30}\
	\x03\x02\x02\x02\u{c30}\u{c31}\x03\x02\x02\x02\u{c31}\u{c32}\x07\u{184}\
	\x02\x02\u{c32}\u{d4e}\x03\x02\x02\x02\u{c33}\u{c34}\x07\x7b\x02\x02\u{c34}\
	\u{c35}\x07\u{183}\x02\x02\u{c35}\u{c36}\x05\u{19c}\u{cf}\x02\u{c36}\u{c37}\
	\x07\u{88}\x02\x02\u{c37}\u{c38}\x05\u{148}\u{a5}\x02\u{c38}\u{c39}\x07\
	\u{184}\x02\x02\u{c39}\u{d4e}\x03\x02\x02\x02\u{c3a}\u{c3b}\x07\u{81}\x02\
	\x02\u{c3b}\u{c3c}\x07\u{183}\x02\x02\u{c3c}\u{c3f}\x05\u{13e}\u{a0}\x02\
	\u{c3d}\u{c3e}\x07\u{98}\x02\x02\u{c3e}\u{c40}\x07\u{e0}\x02\x02\u{c3f}\
	\u{c3d}\x03\x02\x02\x02\u{c3f}\u{c40}\x03\x02\x02\x02\u{c40}\u{c41}\x03\
	\x02\x02\x02\u{c41}\u{c42}\x07\u{184}\x02\x02\u{c42}\u{d4e}\x03\x02\x02\
	\x02\u{c43}\u{c44}\x07\x10\x02\x02\u{c44}\u{c45}\x07\u{183}\x02\x02\u{c45}\
	\u{c48}\x05\u{13e}\u{a0}\x02\u{c46}\u{c47}\x07\u{98}\x02\x02\u{c47}\u{c49}\
	\x07\u{e0}\x02\x02\u{c48}\u{c46}\x03\x02\x02\x02\u{c48}\u{c49}\x03\x02\x02\
	\x02\u{c49}\u{c4a}\x03\x02\x02\x02\u{c4a}\u{c4b}\x07\u{184}\x02\x02\u{c4b}\
	\u{d4e}\x03\x02\x02\x02\u{c4c}\u{c4d}\x07\u{b1}\x02\x02\u{c4d}\u{c4e}\x07\
	\u{183}\x02\x02\u{c4e}\u{c51}\x05\u{13e}\u{a0}\x02\u{c4f}\u{c50}\x07\u{98}\
	\x02\x02\u{c50}\u{c52}\x07\u{e0}\x02\x02\u{c51}\u{c4f}\x03\x02\x02\x02\u{c51}\
	\u{c52}\x03\x02\x02\x02\u{c52}\u{c53}\x03\x02\x02\x02\u{c53}\u{c54}\x07\
	\u{184}\x02\x02\u{c54}\u{d4e}\x03\x02\x02\x02\u{c55}\u{c56}\x07\u{89}\x02\
	\x02\u{c56}\u{c57}\x07\u{183}\x02\x02\u{c57}\u{c58}\x05\u{13e}\u{a0}\x02\
	\u{c58}\u{c59}\x07\x38\x02\x02\u{c59}\u{c5a}\x05\u{162}\u{b2}\x02\u{c5a}\
	\u{c5b}\x07\u{184}\x02\x02\u{c5b}\u{d4e}\x03\x02\x02\x02\u{c5c}\u{c5d}\x07\
	\u{d8}\x02\x02\u{c5d}\u{c66}\x07\u{183}\x02\x02\u{c5e}\u{c63}\x05\u{150}\
	\u{a9}\x02\u{c5f}\u{c60}\x07\x38\x02\x02\u{c60}\u{c62}\x05\u{150}\u{a9}\
	\x02\u{c61}\u{c5f}\x03\x02\x02\x02\u{c62}\u{c65}\x03\x02\x02\x02\u{c63}\
	\u{c61}\x03\x02\x02\x02\u{c63}\u{c64}\x03\x02\x02\x02\u{c64}\u{c67}\x03\
	\x02\x02\x02\u{c65}\u{c63}\x03\x02\x02\x02\u{c66}\u{c5e}\x03\x02\x02\x02\
	\u{c66}\u{c67}\x03\x02\x02\x02\u{c67}\u{c68}\x03\x02\x02\x02\u{c68}\u{d4e}\
	\x07\u{184}\x02\x02\u{c69}\u{c6a}\x07\u{c5}\x02\x02\u{c6a}\u{c6b}\x07\u{183}\
	\x02\x02\u{c6b}\u{c6c}\x05\u{150}\u{a9}\x02\u{c6c}\u{c6d}\x07\u{184}\x02\
	\x02\u{c6d}\u{d4e}\x03\x02\x02\x02\u{c6e}\u{c6f}\x07\x13\x02\x02\u{c6f}\
	\u{c78}\x07\u{183}\x02\x02\u{c70}\u{c75}\x05\u{150}\u{a9}\x02\u{c71}\u{c72}\
	\x07\x38\x02\x02\u{c72}\u{c74}\x05\u{150}\u{a9}\x02\u{c73}\u{c71}\x03\x02\
	\x02\x02\u{c74}\u{c77}\x03\x02\x02\x02\u{c75}\u{c73}\x03\x02\x02\x02\u{c75}\
	\u{c76}\x03\x02\x02\x02\u{c76}\u{c79}\x03\x02\x02\x02\u{c77}\u{c75}\x03\
	\x02\x02\x02\u{c78}\u{c70}\x03\x02\x02\x02\u{c78}\u{c79}\x03\x02\x02\x02\
	\u{c79}\u{c7a}\x03\x02\x02\x02\u{c7a}\u{d4e}\x07\u{184}\x02\x02\u{c7b}\u{c7c}\
	\x07\x5b\x02\x02\u{c7c}\u{c86}\x07\u{183}\x02\x02\u{c7d}\u{c7e}\x05\u{150}\
	\u{a9}\x02\u{c7e}\u{c7f}\x07\x38\x02\x02\u{c7f}\u{c82}\x05\u{150}\u{a9}\
	\x02\u{c80}\u{c81}\x07\x38\x02\x02\u{c81}\u{c83}\x05\u{150}\u{a9}\x02\u{c82}\
	\u{c80}\x03\x02\x02\x02\u{c83}\u{c84}\x03\x02\x02\x02\u{c84}\u{c82}\x03\
	\x02\x02\x02\u{c84}\u{c85}\x03\x02\x02\x02\u{c85}\u{c87}\x03\x02\x02\x02\
	\u{c86}\u{c7d}\x03\x02\x02\x02\u{c86}\u{c87}\x03\x02\x02\x02\u{c87}\u{c88}\
	\x03\x02\x02\x02\u{c88}\u{d4e}\x07\u{184}\x02\x02\u{c89}\u{c8a}\x07\x43\
	\x02\x02\u{c8a}\u{c8b}\x07\u{183}\x02\x02\u{c8b}\u{c8c}\x07\u{195}\x02\x02\
	\u{c8c}\u{c8d}\x07\u{184}\x02\x02\u{c8d}\u{d4e}\x05\u{14e}\u{a8}\x02\u{c8e}\
	\u{c8f}\x05\u{14c}\u{a7}\x02\u{c8f}\u{c90}\x05\u{15c}\u{af}\x02\u{c90}\u{c9c}\
	\x07\u{183}\x02\x02\u{c91}\u{c93}\x05\u{bc}\x5f\x02\u{c92}\u{c91}\x03\x02\
	\x02\x02\u{c92}\u{c93}\x03\x02\x02\x02\u{c93}\u{c94}\x03\x02\x02\x02\u{c94}\
	\u{c99}\x05\u{150}\u{a9}\x02\u{c95}\u{c96}\x07\x38\x02\x02\u{c96}\u{c98}\
	\x05\u{150}\u{a9}\x02\u{c97}\u{c95}\x03\x02\x02\x02\u{c98}\u{c9b}\x03\x02\
	\x02\x02\u{c99}\u{c97}\x03\x02\x02\x02\u{c99}\u{c9a}\x03\x02\x02\x02\u{c9a}\
	\u{c9d}\x03\x02\x02\x02\u{c9b}\u{c99}\x03\x02\x02\x02\u{c9c}\u{c92}\x03\
	\x02\x02\x02\u{c9c}\u{c9d}\x03\x02\x02\x02\u{c9d}\u{c9e}\x03\x02\x02\x02\
	\u{c9e}\u{c9f}\x05\u{152}\u{aa}\x02\u{c9f}\u{ca0}\x03\x02\x02\x02\u{ca0}\
	\u{ca1}\x07\u{184}\x02\x02\u{ca1}\u{ca2}\x05\u{14e}\u{a8}\x02\u{ca2}\u{d4e}\
	\x03\x02\x02\x02\u{ca3}\u{ca4}\x05\u{19c}\u{cf}\x02\u{ca4}\u{ca5}\x05\u{188}\
	\u{c5}\x02\u{ca5}\u{d4e}\x03\x02\x02\x02\u{ca6}\u{ca7}\x05\u{19c}\u{cf}\
	\x02\u{ca7}\u{ca8}\x07\x04\x02\x02\u{ca8}\u{ca9}\x05\u{13e}\u{a0}\x02\u{ca9}\
	\u{d4e}\x03\x02\x02\x02\u{caa}\u{cb3}\x07\u{183}\x02\x02\u{cab}\u{cb0}\x05\
	\u{19c}\u{cf}\x02\u{cac}\u{cad}\x07\x38\x02\x02\u{cad}\u{caf}\x05\u{19c}\
	\u{cf}\x02\u{cae}\u{cac}\x03\x02\x02\x02\u{caf}\u{cb2}\x03\x02\x02\x02\u{cb0}\
	\u{cae}\x03\x02\x02\x02\u{cb0}\u{cb1}\x03\x02\x02\x02\u{cb1}\u{cb4}\x03\
	\x02\x02\x02\u{cb2}\u{cb0}\x03\x02\x02\x02\u{cb3}\u{cab}\x03\x02\x02\x02\
	\u{cb3}\u{cb4}\x03\x02\x02\x02\u{cb4}\u{cb6}\x03\x02\x02\x02\u{cb5}\u{cb7}\
	\x07\x38\x02\x02\u{cb6}\u{cb5}\x03\x02\x02\x02\u{cb6}\u{cb7}\x03\x02\x02\
	\x02\u{cb7}\u{cb8}\x03\x02\x02\x02\u{cb8}\u{cb9}\x07\u{184}\x02\x02\u{cb9}\
	\u{cba}\x07\x04\x02\x02\u{cba}\u{d4e}\x05\u{13e}\u{a0}\x02\u{cbb}\u{cbc}\
	\x07\u{183}\x02\x02\u{cbc}\u{cbd}\x05\x7a\x3e\x02\u{cbd}\u{cbe}\x07\u{184}\
	\x02\x02\u{cbe}\u{d4e}\x03\x02\x02\x02\u{cbf}\u{cc0}\x07\x12\x02\x02\u{cc0}\
	\u{cc9}\x07\u{185}\x02\x02\u{cc1}\u{cc6}\x05\u{13e}\u{a0}\x02\u{cc2}\u{cc3}\
	\x07\x38\x02\x02\u{cc3}\u{cc5}\x05\u{13e}\u{a0}\x02\u{cc4}\u{cc2}\x03\x02\
	\x02\x02\u{cc5}\u{cc8}\x03\x02\x02\x02\u{cc6}\u{cc4}\x03\x02\x02\x02\u{cc6}\
	\u{cc7}\x03\x02\x02\x02\u{cc7}\u{cca}\x03\x02\x02\x02\u{cc8}\u{cc6}\x03\
	\x02\x02\x02\u{cc9}\u{cc1}\x03\x02\x02\x02\u{cc9}\u{cca}\x03\x02\x02\x02\
	\u{cca}\u{ccc}\x03\x02\x02\x02\u{ccb}\u{ccd}\x07\x38\x02\x02\u{ccc}\u{ccb}\
	\x03\x02\x02\x02\u{ccc}\u{ccd}\x03\x02\x02\x02\u{ccd}\u{cce}\x03\x02\x02\
	\x02\u{cce}\u{d4e}\x07\u{186}\x02\x02\u{ccf}\u{d4e}\x05\u{8a}\x46\x02\u{cd0}\
	\u{cd1}\x07\u{183}\x02\x02\u{cd1}\u{cd2}\x05\u{13e}\u{a0}\x02\u{cd2}\u{cd3}\
	\x07\u{184}\x02\x02\u{cd3}\u{d4e}\x03\x02\x02\x02\u{cd4}\u{ce0}\x07\u{185}\
	\x02\x02\u{cd5}\u{cda}\x05\u{13e}\u{a0}\x02\u{cd6}\u{cd7}\x07\x38\x02\x02\
	\u{cd7}\u{cd9}\x05\u{13e}\u{a0}\x02\u{cd8}\u{cd6}\x03\x02\x02\x02\u{cd9}\
	\u{cdc}\x03\x02\x02\x02\u{cda}\u{cd8}\x03\x02\x02\x02\u{cda}\u{cdb}\x03\
	\x02\x02\x02\u{cdb}\u{cde}\x03\x02\x02\x02\u{cdc}\u{cda}\x03\x02\x02\x02\
	\u{cdd}\u{cdf}\x07\x38\x02\x02\u{cde}\u{cdd}\x03\x02\x02\x02\u{cde}\u{cdf}\
	\x03\x02\x02\x02\u{cdf}\u{ce1}\x03\x02\x02\x02\u{ce0}\u{cd5}\x03\x02\x02\
	\x02\u{ce0}\u{ce1}\x03\x02\x02\x02\u{ce1}\u{ce2}\x03\x02\x02\x02\u{ce2}\
	\u{d4e}\x07\u{186}\x02\x02\u{ce3}\u{d4e}\x07\u{1b1}\x02\x02\u{ce4}\u{ce5}\
	\x07\u{f6}\x02\x02\u{ce5}\u{ce6}\x07\u{183}\x02\x02\u{ce6}\u{ce7}\x05\u{1aa}\
	\u{d6}\x02\u{ce7}\u{ce8}\x07\u{184}\x02\x02\u{ce8}\u{ce9}\x07\u{17f}\x02\
	\x02\u{ce9}\u{cea}\x07\u{90}\x02\x02\u{cea}\u{ceb}\x07\u{183}\x02\x02\u{ceb}\
	\u{cec}\x07\u{ea}\x02\x02\u{cec}\u{ced}\x07\x22\x02\x02\u{ced}\u{cef}\x05\
	\u{13e}\u{a0}\x02\u{cee}\u{cf0}\x09\x08\x02\x02\u{cef}\u{cee}\x03\x02\x02\
	\x02\u{cef}\u{cf0}\x03\x02\x02\x02\u{cf0}\u{cf1}\x03\x02\x02\x02\u{cf1}\
	\u{d01}\x07\u{184}\x02\x02\u{cf2}\u{cf3}\x07\u{ee}\x02\x02\u{cf3}\u{cfe}\
	\x07\u{183}\x02\x02\u{cf4}\u{cf5}\x07\u{f2}\x02\x02\u{cf5}\u{cf6}\x07\x22\
	\x02\x02\u{cf6}\u{cfb}\x05\u{13e}\u{a0}\x02\u{cf7}\u{cf8}\x07\x38\x02\x02\
	\u{cf8}\u{cfa}\x05\u{13e}\u{a0}\x02\u{cf9}\u{cf7}\x03\x02\x02\x02\u{cfa}\
	\u{cfd}\x03\x02\x02\x02\u{cfb}\u{cf9}\x03\x02\x02\x02\u{cfb}\u{cfc}\x03\
	\x02\x02\x02\u{cfc}\u{cff}\x03\x02\x02\x02\u{cfd}\u{cfb}\x03\x02\x02\x02\
	\u{cfe}\u{cf4}\x03\x02\x02\x02\u{cfe}\u{cff}\x03\x02\x02\x02\u{cff}\u{d00}\
	\x03\x02\x02\x02\u{d00}\u{d02}\x07\u{184}\x02\x02\u{d01}\u{cf2}\x03\x02\
	\x02\x02\u{d01}\u{d02}\x03\x02\x02\x02\u{d02}\u{d4e}\x03\x02\x02\x02\u{d03}\
	\u{d04}\x07\u{f7}\x02\x02\u{d04}\u{d05}\x07\u{183}\x02\x02\u{d05}\u{d06}\
	\x05\u{1aa}\u{d6}\x02\u{d06}\u{d07}\x07\u{184}\x02\x02\u{d07}\u{d08}\x07\
	\u{17f}\x02\x02\u{d08}\u{d09}\x07\u{90}\x02\x02\u{d09}\u{d0a}\x07\u{183}\
	\x02\x02\u{d0a}\u{d0b}\x07\u{ea}\x02\x02\u{d0b}\u{d0c}\x07\x22\x02\x02\u{d0c}\
	\u{d0e}\x05\u{13e}\u{a0}\x02\u{d0d}\u{d0f}\x09\x08\x02\x02\u{d0e}\u{d0d}\
	\x03\x02\x02\x02\u{d0e}\u{d0f}\x03\x02\x02\x02\u{d0f}\u{d10}\x03\x02\x02\
	\x02\u{d10}\u{d20}\x07\u{184}\x02\x02\u{d11}\u{d12}\x07\u{ee}\x02\x02\u{d12}\
	\u{d1d}\x07\u{183}\x02\x02\u{d13}\u{d14}\x07\u{f2}\x02\x02\u{d14}\u{d15}\
	\x07\x22\x02\x02\u{d15}\u{d1a}\x05\u{13e}\u{a0}\x02\u{d16}\u{d17}\x07\x38\
	\x02\x02\u{d17}\u{d19}\x05\u{13e}\u{a0}\x02\u{d18}\u{d16}\x03\x02\x02\x02\
	\u{d19}\u{d1c}\x03\x02\x02\x02\u{d1a}\u{d18}\x03\x02\x02\x02\u{d1a}\u{d1b}\
	\x03\x02\x02\x02\u{d1b}\u{d1e}\x03\x02\x02\x02\u{d1c}\u{d1a}\x03\x02\x02\
	\x02\u{d1d}\u{d13}\x03\x02\x02\x02\u{d1d}\u{d1e}\x03\x02\x02\x02\u{d1e}\
	\u{d1f}\x03\x02\x02\x02\u{d1f}\u{d21}\x07\u{184}\x02\x02\u{d20}\u{d11}\x03\
	\x02\x02\x02\u{d20}\u{d21}\x03\x02\x02\x02\u{d21}\u{d4e}\x03\x02\x02\x02\
	\u{d22}\u{d23}\x07\u{d0}\x02\x02\u{d23}\u{d24}\x07\u{183}\x02\x02\u{d24}\
	\u{d25}\x07\u{184}\x02\x02\u{d25}\u{d26}\x07\u{17f}\x02\x02\u{d26}\u{d27}\
	\x07\u{90}\x02\x02\u{d27}\u{d28}\x07\u{183}\x02\x02\u{d28}\u{d29}\x07\u{ea}\
	\x02\x02\u{d29}\u{d2a}\x07\x22\x02\x02\u{d2a}\u{d2c}\x05\u{13e}\u{a0}\x02\
	\u{d2b}\u{d2d}\x09\x08\x02\x02\u{d2c}\u{d2b}\x03\x02\x02\x02\u{d2c}\u{d2d}\
	\x03\x02\x02\x02\u{d2d}\u{d2e}\x03\x02\x02\x02\u{d2e}\u{d3e}\x07\u{184}\
	\x02\x02\u{d2f}\u{d30}\x07\u{ee}\x02\x02\u{d30}\u{d3b}\x07\u{183}\x02\x02\
	\u{d31}\u{d32}\x07\u{f2}\x02\x02\u{d32}\u{d33}\x07\x22\x02\x02\u{d33}\u{d38}\
	\x05\u{13e}\u{a0}\x02\u{d34}\u{d35}\x07\x38\x02\x02\u{d35}\u{d37}\x05\u{13e}\
	\u{a0}\x02\u{d36}\u{d34}\x03\x02\x02\x02\u{d37}\u{d3a}\x03\x02\x02\x02\u{d38}\
	\u{d36}\x03\x02\x02\x02\u{d38}\u{d39}\x03\x02\x02\x02\u{d39}\u{d3c}\x03\
	\x02\x02\x02\u{d3a}\u{d38}\x03\x02\x02\x02\u{d3b}\u{d31}\x03\x02\x02\x02\
	\u{d3b}\u{d3c}\x03\x02\x02\x02\u{d3c}\u{d3d}\x03\x02\x02\x02\u{d3d}\u{d3f}\
	\x07\u{184}\x02\x02\u{d3e}\u{d2f}\x03\x02\x02\x02\u{d3e}\u{d3f}\x03\x02\
	\x02\x02\u{d3f}\u{d4e}\x03\x02\x02\x02\u{d40}\u{d41}\x07\u{f0}\x02\x02\u{d41}\
	\u{d42}\x07\u{183}\x02\x02\u{d42}\u{d43}\x05\u{148}\u{a5}\x02\u{d43}\u{d44}\
	\x07\u{f9}\x02\x02\u{d44}\u{d45}\x05\u{148}\u{a5}\x02\u{d45}\u{d46}\x07\
	\u{88}\x02\x02\u{d46}\u{d49}\x05\u{148}\u{a5}\x02\u{d47}\u{d48}\x07\u{84}\
	\x02\x02\u{d48}\u{d4a}\x05\u{148}\u{a5}\x02\u{d49}\u{d47}\x03\x02\x02\x02\
	\u{d49}\u{d4a}\x03\x02\x02\x02\u{d4a}\u{d4b}\x03\x02\x02\x02\u{d4b}\u{d4c}\
	\x07\u{184}\x02\x02\u{d4c}\u{d4e}\x03\x02\x02\x02\u{d4d}\u{b75}\x03\x02\
	\x02\x02\u{d4d}\u{b77}\x03\x02\x02\x02\u{d4d}\u{b78}\x03\x02\x02\x02\u{d4d}\
	\u{b85}\x03\x02\x02\x02\u{d4d}\u{b92}\x03\x02\x02\x02\u{d4d}\u{b99}\x03\
	\x02\x02\x02\u{d4d}\u{bcc}\x03\x02\x02\x02\u{d4d}\u{bd1}\x03\x02\x02\x02\
	\u{d4d}\u{bde}\x03\x02\x02\x02\u{d4d}\u{bea}\x03\x02\x02\x02\u{d4d}\u{bf1}\
	\x03\x02\x02\x02\u{d4d}\u{bf8}\x03\x02\x02\x02\u{d4d}\u{c05}\x03\x02\x02\
	\x02\u{d4d}\u{c13}\x03\x02\x02\x02\u{d4d}\u{c1d}\x03\x02\x02\x02\u{d4d}\
	\u{c28}\x03\x02\x02\x02\u{d4d}\u{c33}\x03\x02\x02\x02\u{d4d}\u{c3a}\x03\
	\x02\x02\x02\u{d4d}\u{c43}\x03\x02\x02\x02\u{d4d}\u{c4c}\x03\x02\x02\x02\
	\u{d4d}\u{c55}\x03\x02\x02\x02\u{d4d}\u{c5c}\x03\x02\x02\x02\u{d4d}\u{c69}\
	\x03\x02\x02\x02\u{d4d}\u{c6e}\x03\x02\x02\x02\u{d4d}\u{c7b}\x03\x02\x02\
	\x02\u{d4d}\u{c89}\x03\x02\x02\x02\u{d4d}\u{c8e}\x03\x02\x02\x02\u{d4d}\
	\u{ca3}\x03\x02\x02\x02\u{d4d}\u{ca6}\x03\x02\x02\x02\u{d4d}\u{caa}\x03\
	\x02\x02\x02\u{d4d}\u{cbb}\x03\x02\x02\x02\u{d4d}\u{cbf}\x03\x02\x02\x02\
	\u{d4d}\u{ccf}\x03\x02\x02\x02\u{d4d}\u{cd0}\x03\x02\x02\x02\u{d4d}\u{cd4}\
	\x03\x02\x02\x02\u{d4d}\u{ce3}\x03\x02\x02\x02\u{d4d}\u{ce4}\x03\x02\x02\
	\x02\u{d4d}\u{d03}\x03\x02\x02\x02\u{d4d}\u{d22}\x03\x02\x02\x02\u{d4d}\
	\u{d40}\x03\x02\x02\x02\u{d4e}\u{d64}\x03\x02\x02\x02\u{d4f}\u{d50}\x0c\
	\x25\x02\x02\u{d50}\u{d63}\x05\u{178}\u{bd}\x02\u{d51}\u{d52}\x0c\x24\x02\
	\x02\u{d52}\u{d53}\x07\u{19b}\x02\x02\u{d53}\u{d63}\x05\u{156}\u{ac}\x02\
	\u{d54}\u{d55}\x0c\x0e\x02\x02\u{d55}\u{d56}\x07\x05\x02\x02\u{d56}\u{d63}\
	\x05\u{17a}\u{be}\x02\u{d57}\u{d58}\x0c\x0d\x02\x02\u{d58}\u{d59}\x07\x06\
	\x02\x02\u{d59}\u{d63}\x05\u{17a}\u{be}\x02\u{d5a}\u{d5b}\x0c\x0c\x02\x02\
	\u{d5b}\u{d5c}\x07\u{185}\x02\x02\u{d5c}\u{d5d}\x05\u{148}\u{a5}\x02\u{d5d}\
	\u{d5e}\x07\u{186}\x02\x02\u{d5e}\u{d63}\x03\x02\x02\x02\u{d5f}\u{d60}\x0c\
	\x0b\x02\x02\u{d60}\u{d61}\x07\u{187}\x02\x02\u{d61}\u{d63}\x05\u{8c}\x47\
	\x02\u{d62}\u{d4f}\x03\x02\x02\x02\u{d62}\u{d51}\x03\x02\x02\x02\u{d62}\
	\u{d54}\x03\x02\x02\x02\u{d62}\u{d57}\x03\x02\x02\x02\u{d62}\u{d5a}\x03\
	\x02\x02\x02\u{d62}\u{d5f}\x03\x02\x02\x02\u{d63}\u{d66}\x03\x02\x02\x02\
	\u{d64}\u{d62}\x03\x02\x02\x02\u{d64}\u{d65}\x03\x02\x02\x02\u{d65}\u{14b}\
	\x03\x02\x02\x02\u{d66}\u{d64}\x03\x02\x02\x02\u{d67}\u{d68}\x03\x02\x02\
	\x02\u{d68}\u{14d}\x03\x02\x02\x02\u{d69}\u{d6b}\x05\u{186}\u{c4}\x02\u{d6a}\
	\u{d69}\x03\x02\x02\x02\u{d6a}\u{d6b}\x03\x02\x02\x02\u{d6b}\u{d6d}\x03\
	\x02\x02\x02\u{d6c}\u{d6e}\x05\u{160}\u{b1}\x02\u{d6d}\u{d6c}\x03\x02\x02\
	\x02\u{d6d}\u{d6e}\x03\x02\x02\x02\u{d6e}\u{d70}\x03\x02\x02\x02\u{d6f}\
	\u{d71}\x05\u{188}\u{c5}\x02\u{d70}\u{d6f}\x03\x02\x02\x02\u{d70}\u{d71}\
	\x03\x02\x02\x02\u{d71}\u{14f}\x03\x02\x02\x02\u{d72}\u{d79}\x05\u{13e}\
	\u{a0}\x02\u{d73}\u{d74}\x05\u{19c}\u{cf}\x02\u{d74}\u{d75}\x07\x03\x02\
	\x02\u{d75}\u{d76}\x05\u{13e}\u{a0}\x02\u{d76}\u{d79}\x03\x02\x02\x02\u{d77}\
	\u{d79}\x05\u{e4}\x73\x02\u{d78}\u{d72}\x03\x02\x02\x02\u{d78}\u{d73}\x03\
	\x02\x02\x02\u{d78}\u{d77}\x03\x02\x02\x02\u{d79}\u{151}\x03\x02\x02\x02\
	\u{d7a}\u{d7b}\x03\x02\x02\x02\u{d7b}\u{153}\x03\x02\x02\x02\u{d7c}\u{d8e}\
	\x07\u{df}\x02\x02\u{d7d}\u{d8e}\x07\u{199}\x02\x02\u{d7e}\u{d7f}\x07\u{19b}\
	\x02\x02\u{d7f}\u{d8e}\x05\u{19c}\u{cf}\x02\u{d80}\u{d8e}\x05\u{16e}\u{b8}\
	\x02\u{d81}\u{d82}\x05\x38\x1d\x02\u{d82}\u{d83}\x05\u{162}\u{b2}\x02\u{d83}\
	\u{d8e}\x03\x02\x02\x02\u{d84}\u{d8e}\x05\u{1aa}\u{d6}\x02\u{d85}\u{d8e}\
	\x05\u{16a}\u{b6}\x02\u{d86}\u{d8e}\x05\u{162}\u{b2}\x02\u{d87}\u{d89}\x05\
	\u{162}\u{b2}\x02\u{d88}\u{d8a}\x05\u{162}\u{b2}\x02\u{d89}\u{d88}\x03\x02\
	\x02\x02\u{d8a}\u{d8b}\x03\x02\x02\x02\u{d8b}\u{d89}\x03\x02\x02\x02\u{d8b}\
	\u{d8c}\x03\x02\x02\x02\u{d8c}\u{d8e}\x03\x02\x02\x02\u{d8d}\u{d7c}\x03\
	\x02\x02\x02\u{d8d}\u{d7d}\x03\x02\x02\x02\u{d8d}\u{d7e}\x03\x02\x02\x02\
	\u{d8d}\u{d80}\x03\x02\x02\x02\u{d8d}\u{d81}\x03\x02\x02\x02\u{d8d}\u{d84}\
	\x03\x02\x02\x02\u{d8d}\u{d85}\x03\x02\x02\x02\u{d8d}\u{d86}\x03\x02\x02\
	\x02\u{d8d}\u{d87}\x03\x02\x02\x02\u{d8e}\u{155}\x03\x02\x02\x02\u{d8f}\
	\u{d93}\x05\u{158}\u{ad}\x02\u{d90}\u{d92}\x05\u{15a}\u{ae}\x02\u{d91}\u{d90}\
	\x03\x02\x02\x02\u{d92}\u{d95}\x03\x02\x02\x02\u{d93}\u{d91}\x03\x02\x02\
	\x02\u{d93}\u{d94}\x03\x02\x02\x02\u{d94}\u{157}\x03\x02\x02\x02\u{d95}\
	\u{d93}\x03\x02\x02\x02\u{d96}\u{da2}\x05\u{19c}\u{cf}\x02\u{d97}\u{d98}\
	\x07\u{185}\x02\x02\u{d98}\u{d99}\x05\u{162}\u{b2}\x02\u{d99}\u{d9a}\x07\
	\u{186}\x02\x02\u{d9a}\u{da2}\x03\x02\x02\x02\u{d9b}\u{d9c}\x07\u{185}\x02\
	\x02\u{d9c}\u{d9d}\x07\u{195}\x02\x02\u{d9d}\u{da2}\x07\u{186}\x02\x02\u{d9e}\
	\u{d9f}\x07\u{185}\x02\x02\u{d9f}\u{da0}\x07\u{1a6}\x02\x02\u{da0}\u{da2}\
	\x07\u{186}\x02\x02\u{da1}\u{d96}\x03\x02\x02\x02\u{da1}\u{d97}\x03\x02\
	\x02\x02\u{da1}\u{d9b}\x03\x02\x02\x02\u{da1}\u{d9e}\x03\x02\x02\x02\u{da2}\
	\u{159}\x03\x02\x02\x02\u{da3}\u{da4}\x07\u{187}\x02\x02\u{da4}\u{db0}\x05\
	\u{19c}\u{cf}\x02\u{da5}\u{da6}\x07\u{185}\x02\x02\u{da6}\u{da7}\x05\u{162}\
	\u{b2}\x02\u{da7}\u{da8}\x07\u{186}\x02\x02\u{da8}\u{db0}\x03\x02\x02\x02\
	\u{da9}\u{daa}\x07\u{185}\x02\x02\u{daa}\u{dab}\x07\u{195}\x02\x02\u{dab}\
	\u{db0}\x07\u{186}\x02\x02\u{dac}\u{dad}\x07\u{185}\x02\x02\u{dad}\u{dae}\
	\x07\u{1a6}\x02\x02\u{dae}\u{db0}\x07\u{186}\x02\x02\u{daf}\u{da3}\x03\x02\
	\x02\x02\u{daf}\u{da5}\x03\x02\x02\x02\u{daf}\u{da9}\x03\x02\x02\x02\u{daf}\
	\u{dac}\x03\x02\x02\x02\u{db0}\u{15b}\x03\x02\x02\x02\u{db1}\u{db2}\x07\
	\u{95}\x02\x02\u{db2}\u{db3}\x07\u{183}\x02\x02\u{db3}\u{db4}\x05\u{13e}\
	\u{a0}\x02\u{db4}\u{db5}\x07\u{184}\x02\x02\u{db5}\u{dbd}\x03\x02\x02\x02\
	\u{db6}\u{dbd}\x07\u{95}\x02\x02\u{db7}\u{dbd}\x05\u{192}\u{ca}\x02\u{db8}\
	\u{dbd}\x07\x7f\x02\x02\u{db9}\u{dbd}\x07\u{b5}\x02\x02\u{dba}\u{dbd}\x07\
	\u{11a}\x02\x02\u{dbb}\u{dbd}\x07\u{10c}\x02\x02\u{dbc}\u{db1}\x03\x02\x02\
	\x02\u{dbc}\u{db6}\x03\x02\x02\x02\u{dbc}\u{db7}\x03\x02\x02\x02\u{dbc}\
	\u{db8}\x03\x02\x02\x02\u{dbc}\u{db9}\x03\x02\x02\x02\u{dbc}\u{dba}\x03\
	\x02\x02\x02\u{dbc}\u{dbb}\x03\x02\x02\x02\u{dbd}\u{15d}\x03\x02\x02\x02\
	\u{dbe}\u{dc1}\x05\u{13e}\u{a0}\x02\u{dbf}\u{dc0}\x07\x14\x02\x02\u{dc0}\
	\u{dc2}\x05\u{19c}\u{cf}\x02\u{dc1}\u{dbf}\x03\x02\x02\x02\u{dc1}\u{dc2}\
	\x03\x02\x02\x02\u{dc2}\u{15f}\x03\x02\x02\x02\u{dc3}\u{dc4}\x07\u{98}\x02\
	\x02\u{dc4}\u{dc8}\x07\u{e0}\x02\x02\u{dc5}\u{dc6}\x07\u{115}\x02\x02\u{dc6}\
	\u{dc8}\x07\u{e0}\x02\x02\u{dc7}\u{dc3}\x03\x02\x02\x02\u{dc7}\u{dc5}\x03\
	\x02\x02\x02\u{dc8}\u{161}\x03\x02\x02\x02\u{dc9}\u{dcc}\x07\u{1a3}\x02\
	\x02\u{dca}\u{dcc}\x07\u{1a4}\x02\x02\u{dcb}\u{dc9}\x03\x02\x02\x02\u{dcb}\
	\u{dca}\x03\x02\x02\x02\u{dcc}\u{163}\x03\x02\x02\x02\u{dcd}\u{dce}\x07\
	\u{150}\x02\x02\u{dce}\u{dcf}\x07\u{182}\x02\x02\u{dcf}\u{dd4}\x05\u{16e}\
	\u{b8}\x02\u{dd0}\u{dd1}\x07\u{150}\x02\x02\u{dd1}\u{dd2}\x07\u{182}\x02\
	\x02\u{dd2}\u{dd4}\x05\u{162}\u{b2}\x02\u{dd3}\u{dcd}\x03\x02\x02\x02\u{dd3}\
	\u{dd0}\x03\x02\x02\x02\u{dd4}\u{165}\x03\x02\x02\x02\u{dd5}\u{dd6}\x09\
	\x18\x02\x02\u{dd6}\u{167}\x03\x02\x02\x02\u{dd7}\u{dd8}\x09\x11\x02\x02\
	\u{dd8}\u{169}\x03\x02\x02\x02\u{dd9}\u{dda}\x09\x19\x02\x02\u{dda}\u{16b}\
	\x03\x02\x02\x02\u{ddb}\u{ddc}\x05\u{16e}\u{b8}\x02\u{ddc}\u{ddd}\x07\x02\
	\x02\x03\u{ddd}\u{16d}\x03\x02\x02\x02\u{dde}\u{de2}\x07\u{a5}\x02\x02\u{ddf}\
	\u{de0}\x05\u{170}\u{b9}\x02\u{de0}\u{de1}\x05\u{172}\u{ba}\x02\u{de1}\u{de3}\
	\x03\x02\x02\x02\u{de2}\u{ddf}\x03\x02\x02\x02\u{de3}\u{de4}\x03\x02\x02\
	\x02\u{de4}\u{de2}\x03\x02\x02\x02\u{de4}\u{de5}\x03\x02\x02\x02\u{de5}\
	\u{16f}\x03\x02\x02\x02\u{de6}\u{de8}\x09\x15\x02\x02\u{de7}\u{de6}\x03\
	\x02\x02\x02\u{de7}\u{de8}\x03\x02\x02\x02\u{de8}\u{dec}\x03\x02\x02\x02\
	\u{de9}\u{ded}\x07\u{1a6}\x02\x02\u{dea}\u{ded}\x07\u{1ab}\x02\x02\u{deb}\
	\u{ded}\x05\u{162}\u{b2}\x02\u{dec}\u{de9}\x03\x02\x02\x02\u{dec}\u{dea}\
	\x03\x02\x02\x02\u{dec}\u{deb}\x03\x02\x02\x02\u{ded}\u{171}\x03\x02\x02\
	\x02\u{dee}\u{def}\x09\x1a\x02\x02\u{def}\u{173}\x03\x02\x02\x02\u{df0}\
	\u{df1}\x09\x1b\x02\x02\u{df1}\u{175}\x03\x02\x02\x02\u{df2}\u{e15}\x07\
	\x1e\x02\x02\u{df3}\u{e15}\x07\u{157}\x02\x02\u{df4}\u{e15}\x07\x23\x02\
	\x02\u{df5}\u{e15}\x07\u{133}\x02\x02\u{df6}\u{e15}\x07\u{12f}\x02\x02\u{df7}\
	\u{e15}\x07\u{a6}\x02\x02\u{df8}\u{e15}\x07\u{a7}\x02\x02\u{df9}\u{e15}\
	\x07\x1a\x02\x02\u{dfa}\u{e15}\x07\u{c2}\x02\x02\u{dfb}\u{e15}\x07\u{82}\
	\x02\x02\u{dfc}\u{e15}\x07\u{106}\x02\x02\u{dfd}\u{e15}\x07\x6b\x02\x02\
	\u{dfe}\u{e15}\x07\x50\x02\x02\u{dff}\u{e15}\x07\u{152}\x02\x02\u{e00}\u{e15}\
	\x07\u{156}\x02\x02\u{e01}\u{e15}\x07\u{155}\x02\x02\u{e02}\u{e04}\x07\u{14e}\
	\x02\x02\u{e03}\u{e05}\x05\u{178}\u{bd}\x02\u{e04}\u{e03}\x03\x02\x02\x02\
	\u{e04}\u{e05}\x03\x02\x02\x02\u{e05}\u{e15}\x03\x02\x02\x02\u{e06}\u{e15}\
	\x07\x2d\x02\x02\u{e07}\u{e15}\x07\x2c\x02\x02\u{e08}\u{e15}\x07\u{172}\
	\x02\x02\u{e09}\u{e15}\x07\x1b\x02\x02\u{e0a}\u{e15}\x07\x59\x02\x02\u{e0b}\
	\u{e15}\x07\x58\x02\x02\u{e0c}\u{e15}\x07\u{e1}\x02\x02\u{e0d}\u{e15}\x07\
	\u{177}\x02\x02\u{e0e}\u{e15}\x07\u{a5}\x02\x02\u{e0f}\u{e15}\x07\u{173}\
	\x02\x02\u{e10}\u{e15}\x07\x12\x02\x02\u{e11}\u{e15}\x07\u{140}\x02\x02\
	\u{e12}\u{e15}\x07\u{c4}\x02\x02\u{e13}\u{e15}\x05\u{19c}\u{cf}\x02\u{e14}\
	\u{df2}\x03\x02\x02\x02\u{e14}\u{df3}\x03\x02\x02\x02\u{e14}\u{df4}\x03\
	\x02\x02\x02\u{e14}\u{df5}\x03\x02\x02\x02\u{e14}\u{df6}\x03\x02\x02\x02\
	\u{e14}\u{df7}\x03\x02\x02\x02\u{e14}\u{df8}\x03\x02\x02\x02\u{e14}\u{df9}\
	\x03\x02\x02\x02\u{e14}\u{dfa}\x03\x02\x02\x02\u{e14}\u{dfb}\x03\x02\x02\
	\x02\u{e14}\u{dfc}\x03\x02\x02\x02\u{e14}\u{dfd}\x03\x02\x02\x02\u{e14}\
	\u{dfe}\x03\x02\x02\x02\u{e14}\u{dff}\x03\x02\x02\x02\u{e14}\u{e00}\x03\
	\x02\x02\x02\u{e14}\u{e01}\x03\x02\x02\x02\u{e14}\u{e02}\x03\x02\x02\x02\
	\u{e14}\u{e06}\x03\x02\x02\x02\u{e14}\u{e07}\x03\x02\x02\x02\u{e14}\u{e08}\
	\x03\x02\x02\x02\u{e14}\u{e09}\x03\x02\x02\x02\u{e14}\u{e0a}\x03\x02\x02\
	\x02\u{e14}\u{e0b}\x03\x02\x02\x02\u{e14}\u{e0c}\x03\x02\x02\x02\u{e14}\
	\u{e0d}\x03\x02\x02\x02\u{e14}\u{e0e}\x03\x02\x02\x02\u{e14}\u{e0f}\x03\
	\x02\x02\x02\u{e14}\u{e10}\x03\x02\x02\x02\u{e14}\u{e11}\x03\x02\x02\x02\
	\u{e14}\u{e12}\x03\x02\x02\x02\u{e14}\u{e13}\x03\x02\x02\x02\u{e15}\u{177}\
	\x03\x02\x02\x02\u{e16}\u{e17}\x07\x33\x02\x02\u{e17}\u{e18}\x05\u{19c}\
	\u{cf}\x02\u{e18}\u{179}\x03\x02\x02\x02\u{e19}\u{e1c}\x05\u{17c}\u{bf}\
	\x02\u{e1a}\u{e1b}\x07\u{de}\x02\x02\u{e1b}\u{e1d}\x07\u{df}\x02\x02\u{e1c}\
	\u{e1a}\x03\x02\x02\x02\u{e1c}\u{e1d}\x03\x02\x02\x02\u{e1d}\u{e20}\x03\
	\x02\x02\x02\u{e1e}\u{e20}\x07\u{df}\x02\x02\u{e1f}\u{e19}\x03\x02\x02\x02\
	\u{e1f}\u{e1e}\x03\x02\x02\x02\u{e20}\u{17b}\x03\x02\x02\x02\u{e21}\u{e22}\
	\x07\u{19c}\x02\x02\u{e22}\u{e68}\x07\u{1a6}\x02\x02\u{e23}\u{e33}\x07\u{140}\
	\x02\x02\u{e24}\u{e25}\x07\u{18f}\x02\x02\u{e25}\u{e2a}\x05\u{17e}\u{c0}\
	\x02\u{e26}\u{e27}\x07\x38\x02\x02\u{e27}\u{e29}\x05\u{17e}\u{c0}\x02\u{e28}\
	\u{e26}\x03\x02\x02\x02\u{e29}\u{e2c}\x03\x02\x02\x02\u{e2a}\u{e28}\x03\
	\x02\x02\x02\u{e2a}\u{e2b}\x03\x02\x02\x02\u{e2b}\u{e2e}\x03\x02\x02\x02\
	\u{e2c}\u{e2a}\x03\x02\x02\x02\u{e2d}\u{e2f}\x07\x38\x02\x02\u{e2e}\u{e2d}\
	\x03\x02\x02\x02\u{e2e}\u{e2f}\x03\x02\x02\x02\u{e2f}\u{e30}\x03\x02\x02\
	\x02\u{e30}\u{e31}\x07\u{191}\x02\x02\u{e31}\u{e34}\x03\x02\x02\x02\u{e32}\
	\u{e34}\x07\u{18e}\x02\x02\u{e33}\u{e24}\x03\x02\x02\x02\u{e33}\u{e32}\x03\
	\x02\x02\x02\u{e34}\u{e68}\x03\x02\x02\x02\u{e35}\u{e36}\x07\u{a5}\x02\x02\
	\u{e36}\u{e39}\x05\u{174}\u{bb}\x02\u{e37}\u{e38}\x07\u{158}\x02\x02\u{e38}\
	\u{e3a}\x05\u{174}\u{bb}\x02\u{e39}\u{e37}\x03\x02\x02\x02\u{e39}\u{e3a}\
	\x03\x02\x02\x02\u{e3a}\u{e68}\x03\x02\x02\x02\u{e3b}\u{e3c}\x07\u{c4}\x02\
	\x02\u{e3c}\u{e3d}\x07\u{18f}\x02\x02\u{e3d}\u{e3e}\x05\u{17a}\u{be}\x02\
	\u{e3e}\u{e3f}\x07\x38\x02\x02\u{e3f}\u{e41}\x05\u{17a}\u{be}\x02\u{e40}\
	\u{e42}\x07\x38\x02\x02\u{e41}\u{e40}\x03\x02\x02\x02\u{e41}\u{e42}\x03\
	\x02\x02\x02\u{e42}\u{e43}\x03\x02\x02\x02\u{e43}\u{e44}\x07\u{191}\x02\
	\x02\u{e44}\u{e68}\x03\x02\x02\x02\u{e45}\u{e46}\x07\x12\x02\x02\u{e46}\
	\u{e47}\x07\u{18f}\x02\x02\u{e47}\u{e48}\x05\u{17a}\u{be}\x02\u{e48}\u{e49}\
	\x07\u{191}\x02\x02\u{e49}\u{e68}\x03\x02\x02\x02\u{e4a}\u{e4b}\x07\u{8b}\
	\x02\x02\u{e4b}\u{e4c}\x07\u{183}\x02\x02\u{e4c}\u{e51}\x05\u{17a}\u{be}\
	\x02\u{e4d}\u{e4e}\x07\x38\x02\x02\u{e4e}\u{e50}\x05\u{17a}\u{be}\x02\u{e4f}\
	\u{e4d}\x03\x02\x02\x02\u{e50}\u{e53}\x03\x02\x02\x02\u{e51}\u{e4f}\x03\
	\x02\x02\x02\u{e51}\u{e52}\x03\x02\x02\x02\u{e52}\u{e54}\x03\x02\x02\x02\
	\u{e53}\u{e51}\x03\x02\x02\x02\u{e54}\u{e55}\x07\u{184}\x02\x02\u{e55}\u{e68}\
	\x03\x02\x02\x02\u{e56}\u{e65}\x05\u{176}\u{bc}\x02\u{e57}\u{e58}\x07\u{183}\
	\x02\x02\u{e58}\u{e5d}\x05\u{182}\u{c2}\x02\u{e59}\u{e5a}\x07\x38\x02\x02\
	\u{e5a}\u{e5c}\x05\u{182}\u{c2}\x02\u{e5b}\u{e59}\x03\x02\x02\x02\u{e5c}\
	\u{e5f}\x03\x02\x02\x02\u{e5d}\u{e5b}\x03\x02\x02\x02\u{e5d}\u{e5e}\x03\
	\x02\x02\x02\u{e5e}\u{e61}\x03\x02\x02\x02\u{e5f}\u{e5d}\x03\x02\x02\x02\
	\u{e60}\u{e62}\x07\x38\x02\x02\u{e61}\u{e60}\x03\x02\x02\x02\u{e61}\u{e62}\
	\x03\x02\x02\x02\u{e62}\u{e63}\x03\x02\x02\x02\u{e63}\u{e64}\x07\u{184}\
	\x02\x02\u{e64}\u{e66}\x03\x02\x02\x02\u{e65}\u{e57}\x03\x02\x02\x02\u{e65}\
	\u{e66}\x03\x02\x02\x02\u{e66}\u{e68}\x03\x02\x02\x02\u{e67}\u{e21}\x03\
	\x02\x02\x02\u{e67}\u{e23}\x03\x02\x02\x02\u{e67}\u{e35}\x03\x02\x02\x02\
	\u{e67}\u{e3b}\x03\x02\x02\x02\u{e67}\u{e45}\x03\x02\x02\x02\u{e67}\u{e4a}\
	\x03\x02\x02\x02\u{e67}\u{e56}\x03\x02\x02\x02\u{e68}\u{17d}\x03\x02\x02\
	\x02\u{e69}\u{e6b}\x05\u{19c}\u{cf}\x02\u{e6a}\u{e6c}\x07\u{19b}\x02\x02\
	\u{e6b}\u{e6a}\x03\x02\x02\x02\u{e6b}\u{e6c}\x03\x02\x02\x02\u{e6c}\u{e6d}\
	\x03\x02\x02\x02\u{e6d}\u{e70}\x05\u{17a}\u{be}\x02\u{e6e}\u{e6f}\x07\u{de}\
	\x02\x02\u{e6f}\u{e71}\x07\u{df}\x02\x02\u{e70}\u{e6e}\x03\x02\x02\x02\u{e70}\
	\u{e71}\x03\x02\x02\x02\u{e71}\u{e73}\x03\x02\x02\x02\u{e72}\u{e74}\x05\
	\u{180}\u{c1}\x02\u{e73}\u{e72}\x03\x02\x02\x02\u{e73}\u{e74}\x03\x02\x02\
	\x02\u{e74}\u{17f}\x03\x02\x02\x02\u{e75}\u{e76}\x07\x39\x02\x02\u{e76}\
	\u{e77}\x05\u{162}\u{b2}\x02\u{e77}\u{181}\x03\x02\x02\x02\u{e78}\u{e7b}\
	\x07\u{1a6}\x02\x02\u{e79}\u{e7b}\x05\u{17a}\u{be}\x02\u{e7a}\u{e78}\x03\
	\x02\x02\x02\u{e7a}\u{e79}\x03\x02\x02\x02\u{e7b}\u{183}\x03\x02\x02\x02\
	\u{e7c}\u{e7d}\x07\u{17a}\x02\x02\u{e7d}\u{e7e}\x05\u{13e}\u{a0}\x02\u{e7e}\
	\u{e7f}\x07\u{14f}\x02\x02\u{e7f}\u{e80}\x05\u{13e}\u{a0}\x02\u{e80}\u{185}\
	\x03\x02\x02\x02\u{e81}\u{e82}\x07\x7f\x02\x02\u{e82}\u{e83}\x07\u{183}\
	\x02\x02\u{e83}\u{e84}\x07\u{17b}\x02\x02\u{e84}\u{e85}\x05\u{140}\u{a1}\
	\x02\u{e85}\u{e86}\x07\u{184}\x02\x02\u{e86}\u{187}\x03\x02\x02\x02\u{e87}\
	\u{e8d}\x07\u{ee}\x02\x02\u{e88}\u{e8e}\x05\u{19c}\u{cf}\x02\u{e89}\u{e8a}\
	\x07\u{183}\x02\x02\u{e8a}\u{e8b}\x05\u{d6}\x6c\x02\u{e8b}\u{e8c}\x07\u{184}\
	\x02\x02\u{e8c}\u{e8e}\x03\x02\x02\x02\u{e8d}\u{e88}\x03\x02\x02\x02\u{e8d}\
	\u{e89}\x03\x02\x02\x02\u{e8e}\u{189}\x03\x02\x02\x02\u{e8f}\u{e90}\x05\
	\u{18c}\u{c7}\x02\u{e90}\u{18b}\x03\x02\x02\x02\u{e91}\u{e92}\x07\u{104}\
	\x02\x02\u{e92}\u{ea2}\x05\u{18e}\u{c8}\x02\u{e93}\u{e94}\x07\u{121}\x02\
	\x02\u{e94}\u{ea2}\x05\u{18e}\u{c8}\x02\u{e95}\u{e96}\x07\u{104}\x02\x02\
	\u{e96}\u{e97}\x07\x19\x02\x02\u{e97}\u{e98}\x05\u{18e}\u{c8}\x02\u{e98}\
	\u{e99}\x07\x0d\x02\x02\u{e99}\u{e9a}\x05\u{18e}\u{c8}\x02\u{e9a}\u{ea2}\
	\x03\x02\x02\x02\u{e9b}\u{e9c}\x07\u{121}\x02\x02\u{e9c}\u{e9d}\x07\x19\
	\x02\x02\u{e9d}\u{e9e}\x05\u{18e}\u{c8}\x02\u{e9e}\u{e9f}\x07\x0d\x02\x02\
	\u{e9f}\u{ea0}\x05\u{18e}\u{c8}\x02\u{ea0}\u{ea2}\x03\x02\x02\x02\u{ea1}\
	\u{e91}\x03\x02\x02\x02\u{ea1}\u{e93}\x03\x02\x02\x02\u{ea1}\u{e95}\x03\
	\x02\x02\x02\u{ea1}\u{e9b}\x03\x02\x02\x02\u{ea2}\u{18d}\x03\x02\x02\x02\
	\u{ea3}\u{ea4}\x07\u{164}\x02\x02\u{ea4}\u{ead}\x07\u{fb}\x02\x02\u{ea5}\
	\u{ea6}\x07\u{164}\x02\x02\u{ea6}\u{ead}\x07\u{83}\x02\x02\u{ea7}\u{ea8}\
	\x07\x47\x02\x02\u{ea8}\u{ead}\x07\u{120}\x02\x02\u{ea9}\u{eaa}\x05\u{13e}\
	\u{a0}\x02\u{eaa}\u{eab}\x09\x1c\x02\x02\u{eab}\u{ead}\x03\x02\x02\x02\u{eac}\
	\u{ea3}\x03\x02\x02\x02\u{eac}\u{ea5}\x03\x02\x02\x02\u{eac}\u{ea7}\x03\
	\x02\x02\x02\u{eac}\u{ea9}\x03\x02\x02\x02\u{ead}\u{18f}\x03\x02\x02\x02\
	\u{eae}\u{eaf}\x09\x1d\x02\x02\u{eaf}\u{191}\x03\x02\x02\x02\u{eb0}\u{eb5}\
	\x05\u{19c}\u{cf}\x02\u{eb1}\u{eb2}\x07\u{187}\x02\x02\u{eb2}\u{eb4}\x05\
	\u{1a2}\u{d2}\x02\u{eb3}\u{eb1}\x03\x02\x02\x02\u{eb4}\u{eb7}\x03\x02\x02\
	\x02\u{eb5}\u{eb3}\x03\x02\x02\x02\u{eb5}\u{eb6}\x03\x02\x02\x02\u{eb6}\
	\u{193}\x03\x02\x02\x02\u{eb7}\u{eb5}\x03\x02\x02\x02\u{eb8}\u{eb9}\x05\
	\u{192}\u{ca}\x02\u{eb9}\u{195}\x03\x02\x02\x02\u{eba}\u{ebb}\x07\u{84}\
	\x02\x02\u{ebb}\u{ebc}\x05\u{198}\u{cd}\x02\u{ebc}\u{ebd}\x07\x14\x02\x02\
	\u{ebd}\u{ebe}\x07\u{e2}\x02\x02\u{ebe}\u{ebf}\x05\u{148}\u{a5}\x02\u{ebf}\
	\u{197}\x03\x02\x02\x02\u{ec0}\u{ec1}\x09\x1e\x02\x02\u{ec1}\u{199}\x03\
	\x02\x02\x02\u{ec2}\u{ec8}\x05\u{19c}\u{cf}\x02\u{ec3}\u{ec4}\x07\u{16e}\
	\x02\x02\u{ec4}\u{ec8}\x05\u{19c}\u{cf}\x02\u{ec5}\u{ec6}\x07\u{11c}\x02\
	\x02\u{ec6}\u{ec8}\x05\u{19c}\u{cf}\x02\u{ec7}\u{ec2}\x03\x02\x02\x02\u{ec7}\
	\u{ec3}\x03\x02\x02\x02\u{ec7}\u{ec5}\x03\x02\x02\x02\u{ec8}\u{19b}\x03\
	\x02\x02\x02\u{ec9}\u{ecc}\x05\u{19e}\u{d0}\x02\u{eca}\u{ecc}\x05\u{1b2}\
	\u{da}\x02\u{ecb}\u{ec9}\x03\x02\x02\x02\u{ecb}\u{eca}\x03\x02\x02\x02\u{ecc}\
	\u{19d}\x03\x02\x02\x02\u{ecd}\u{ed2}\x07\u{1af}\x02\x02\u{ece}\u{ed2}\x05\
	\u{1a0}\u{d1}\x02\u{ecf}\u{ed2}\x05\u{1b4}\u{db}\x02\u{ed0}\u{ed2}\x07\u{1b0}\
	\x02\x02\u{ed1}\u{ecd}\x03\x02\x02\x02\u{ed1}\u{ece}\x03\x02\x02\x02\u{ed1}\
	\u{ecf}\x03\x02\x02\x02\u{ed1}\u{ed0}\x03\x02\x02\x02\u{ed2}\u{19f}\x03\
	\x02\x02\x02\u{ed3}\u{ed4}\x07\u{1b0}\x02\x02\u{ed4}\u{1a1}\x03\x02\x02\
	\x02\u{ed5}\u{ed6}\x05\u{19c}\u{cf}\x02\u{ed6}\u{1a3}\x03\x02\x02\x02\u{ed7}\
	\u{ed8}\x05\u{19c}\u{cf}\x02\u{ed8}\u{ed9}\x07\x02\x02\x03\u{ed9}\u{1a5}\
	\x03\x02\x02\x02\u{eda}\u{edb}\x07\u{183}\x02\x02\u{edb}\u{edc}\x05\u{1a8}\
	\u{d5}\x02\u{edc}\u{edd}\x07\u{184}\x02\x02\u{edd}\u{1a7}\x03\x02\x02\x02\
	\u{ede}\u{ee3}\x05\u{19c}\u{cf}\x02\u{edf}\u{ee0}\x07\x38\x02\x02\u{ee0}\
	\u{ee2}\x05\u{19c}\u{cf}\x02\u{ee1}\u{edf}\x03\x02\x02\x02\u{ee2}\u{ee5}\
	\x03\x02\x02\x02\u{ee3}\u{ee1}\x03\x02\x02\x02\u{ee3}\u{ee4}\x03\x02\x02\
	\x02\u{ee4}\u{1a9}\x03\x02\x02\x02\u{ee5}\u{ee3}\x03\x02\x02\x02\u{ee6}\
	\u{ee8}\x07\u{194}\x02\x02\u{ee7}\u{ee6}\x03\x02\x02\x02\u{ee7}\u{ee8}\x03\
	\x02\x02\x02\u{ee8}\u{ee9}\x03\x02\x02\x02\u{ee9}\u{f0b}\x07\u{1ab}\x02\
	\x02\u{eea}\u{eec}\x07\u{194}\x02\x02\u{eeb}\u{eea}\x03\x02\x02\x02\u{eeb}\
	\u{eec}\x03\x02\x02\x02\u{eec}\u{eed}\x03\x02\x02\x02\u{eed}\u{f0b}\x07\
	\u{1ad}\x02\x02\u{eee}\u{ef0}\x07\u{194}\x02\x02\u{eef}\u{eee}\x03\x02\x02\
	\x02\u{eef}\u{ef0}\x03\x02\x02\x02\u{ef0}\u{ef1}\x03\x02\x02\x02\u{ef1}\
	\u{f0b}\x07\u{1a6}\x02\x02\u{ef2}\u{ef4}\x07\u{194}\x02\x02\u{ef3}\u{ef2}\
	\x03\x02\x02\x02\u{ef3}\u{ef4}\x03\x02\x02\x02\u{ef4}\u{ef5}\x03\x02\x02\
	\x02\u{ef5}\u{f0b}\x07\u{1aa}\x02\x02\u{ef6}\u{ef8}\x07\u{194}\x02\x02\u{ef7}\
	\u{ef6}\x03\x02\x02\x02\u{ef7}\u{ef8}\x03\x02\x02\x02\u{ef8}\u{ef9}\x03\
	\x02\x02\x02\u{ef9}\u{f0b}\x07\u{1a7}\x02\x02\u{efa}\u{efc}\x07\u{194}\x02\
	\x02\u{efb}\u{efa}\x03\x02\x02\x02\u{efb}\u{efc}\x03\x02\x02\x02\u{efc}\
	\u{efd}\x03\x02\x02\x02\u{efd}\u{f0b}\x07\u{1a8}\x02\x02\u{efe}\u{f00}\x07\
	\u{194}\x02\x02\u{eff}\u{efe}\x03\x02\x02\x02\u{eff}\u{f00}\x03\x02\x02\
	\x02\u{f00}\u{f01}\x03\x02\x02\x02\u{f01}\u{f0b}\x07\u{1a9}\x02\x02\u{f02}\
	\u{f04}\x07\u{194}\x02\x02\u{f03}\u{f02}\x03\x02\x02\x02\u{f03}\u{f04}\x03\
	\x02\x02\x02\u{f04}\u{f05}\x03\x02\x02\x02\u{f05}\u{f0b}\x07\u{1ac}\x02\
	\x02\u{f06}\u{f08}\x07\u{194}\x02\x02\u{f07}\u{f06}\x03\x02\x02\x02\u{f07}\
	\u{f08}\x03\x02\x02\x02\u{f08}\u{f09}\x03\x02\x02\x02\u{f09}\u{f0b}\x07\
	\u{1ae}\x02\x02\u{f0a}\u{ee7}\x03\x02\x02\x02\u{f0a}\u{eeb}\x03\x02\x02\
	\x02\u{f0a}\u{eef}\x03\x02\x02\x02\u{f0a}\u{ef3}\x03\x02\x02\x02\u{f0a}\
	\u{ef7}\x03\x02\x02\x02\u{f0a}\u{efb}\x03\x02\x02\x02\u{f0a}\u{eff}\x03\
	\x02\x02\x02\u{f0a}\u{f03}\x03\x02\x02\x02\u{f0a}\u{f07}\x03\x02\x02\x02\
	\u{f0b}\u{1ab}\x03\x02\x02\x02\u{f0c}\u{f0d}\x07\u{120}\x02\x02\u{f0d}\u{f0e}\
	\x07\u{183}\x02\x02\u{f0e}\u{f13}\x05\u{1ae}\u{d8}\x02\u{f0f}\u{f10}\x07\
	\x38\x02\x02\u{f10}\u{f12}\x05\u{1ae}\u{d8}\x02\u{f11}\u{f0f}\x03\x02\x02\
	\x02\u{f12}\u{f15}\x03\x02\x02\x02\u{f13}\u{f11}\x03\x02\x02\x02\u{f13}\
	\u{f14}\x03\x02\x02\x02\u{f14}\u{f16}\x03\x02\x02\x02\u{f15}\u{f13}\x03\
	\x02\x02\x02\u{f16}\u{f17}\x07\u{184}\x02\x02\u{f17}\u{f33}\x03\x02\x02\
	\x02\u{f18}\u{f19}\x07\u{c4}\x02\x02\u{f19}\u{f1a}\x07\u{183}\x02\x02\u{f1a}\
	\u{f1b}\x05\u{1ac}\u{d7}\x02\u{f1b}\u{f1c}\x07\x38\x02\x02\u{f1c}\u{f1d}\
	\x05\u{1ac}\u{d7}\x02\u{f1d}\u{f1e}\x07\u{184}\x02\x02\u{f1e}\u{f33}\x03\
	\x02\x02\x02\u{f1f}\u{f20}\x07\x12\x02\x02\u{f20}\u{f21}\x07\u{183}\x02\
	\x02\u{f21}\u{f22}\x05\u{1ac}\u{d7}\x02\u{f22}\u{f23}\x07\u{184}\x02\x02\
	\u{f23}\u{f33}\x03\x02\x02\x02\u{f24}\u{f25}\x07\u{8b}\x02\x02\u{f25}\u{f26}\
	\x07\u{183}\x02\x02\u{f26}\u{f2b}\x05\u{1ac}\u{d7}\x02\u{f27}\u{f28}\x07\
	\x38\x02\x02\u{f28}\u{f2a}\x05\u{1ac}\u{d7}\x02\u{f29}\u{f27}\x03\x02\x02\
	\x02\u{f2a}\u{f2d}\x03\x02\x02\x02\u{f2b}\u{f29}\x03\x02\x02\x02\u{f2b}\
	\u{f2c}\x03\x02\x02\x02\u{f2c}\u{f2e}\x03\x02\x02\x02\u{f2d}\u{f2b}\x03\
	\x02\x02\x02\u{f2e}\u{f2f}\x07\u{184}\x02\x02\u{f2f}\u{f33}\x03\x02\x02\
	\x02\u{f30}\u{f33}\x07\u{a7}\x02\x02\u{f31}\u{f33}\x05\u{17a}\u{be}\x02\
	\u{f32}\u{f0c}\x03\x02\x02\x02\u{f32}\u{f18}\x03\x02\x02\x02\u{f32}\u{f1f}\
	\x03\x02\x02\x02\u{f32}\u{f24}\x03\x02\x02\x02\u{f32}\u{f30}\x03\x02\x02\
	\x02\u{f32}\u{f31}\x03\x02\x02\x02\u{f33}\u{1ad}\x03\x02\x02\x02\u{f34}\
	\u{f39}\x05\u{1ac}\u{d7}\x02\u{f35}\u{f36}\x05\u{19c}\u{cf}\x02\u{f36}\u{f37}\
	\x05\u{1ac}\u{d7}\x02\u{f37}\u{f39}\x03\x02\x02\x02\u{f38}\u{f34}\x03\x02\
	\x02\x02\u{f38}\u{f35}\x03\x02\x02\x02\u{f39}\u{1af}\x03\x02\x02\x02\u{f3a}\
	\u{f3f}\x05\u{1ac}\u{d7}\x02\u{f3b}\u{f3c}\x07\x38\x02\x02\u{f3c}\u{f3e}\
	\x05\u{1ac}\u{d7}\x02\u{f3d}\u{f3b}\x03\x02\x02\x02\u{f3e}\u{f41}\x03\x02\
	\x02\x02\u{f3f}\u{f3d}\x03\x02\x02\x02\u{f3f}\u{f40}\x03\x02\x02\x02\u{f40}\
	\u{f44}\x03\x02\x02\x02\u{f41}\u{f3f}\x03\x02\x02\x02\u{f42}\u{f44}\x07\
	\x02\x02\x03\u{f43}\u{f3a}\x03\x02\x02\x02\u{f43}\u{f42}\x03\x02\x02\x02\
	\u{f44}\u{1b1}\x03\x02\x02\x02\u{f45}\u{f46}\x09\x1f\x02\x02\u{f46}\u{1b3}\
	\x03\x02\x02\x02\u{f47}\u{f48}\x09\x20\x02\x02\u{f48}\u{1b5}\x03\x02\x02\
	\x02\u{20d}\u{1b7}\u{1bb}\u{1bf}\u{1c5}\u{1c8}\u{1e1}\u{1e7}\u{201}\u{204}\
	\u{207}\u{20a}\u{20d}\u{213}\u{217}\u{21b}\u{221}\u{225}\u{228}\u{22c}\u{232}\
	\u{235}\u{23b}\u{23f}\u{243}\u{249}\u{24d}\u{250}\u{259}\u{264}\u{266}\u{26a}\
	\u{270}\u{273}\u{276}\u{279}\u{27f}\u{288}\u{28c}\u{290}\u{29a}\u{29c}\u{2a1}\
	\u{2ac}\u{2af}\u{2b5}\u{2bc}\u{2c3}\u{2c9}\u{2cf}\u{2d6}\u{2dd}\u{2e4}\u{2eb}\
	\u{2f2}\u{2fd}\u{305}\u{30d}\u{314}\u{31e}\u{325}\u{32d}\u{351}\u{354}\u{357}\
	\u{35a}\u{35e}\u{364}\u{37a}\u{381}\u{388}\u{38d}\u{394}\u{39b}\u{3a2}\u{3a9}\
	\u{3b0}\u{3b7}\u{3bf}\u{3c7}\u{3ce}\u{3d5}\u{3dc}\u{3df}\u{3e6}\u{3ef}\u{3f7}\
	\u{3fe}\u{407}\u{413}\u{421}\u{423}\u{432}\u{437}\u{43b}\u{445}\u{44a}\u{44e}\
	\u{454}\u{457}\u{45f}\u{464}\u{46e}\u{47d}\u{480}\u{48c}\u{497}\u{4a3}\u{4af}\
	\u{4b1}\u{4b8}\u{4bf}\u{4c5}\u{4cb}\u{4cd}\u{4d5}\u{4dd}\u{4e3}\u{4ef}\u{4f9}\
	\u{500}\u{507}\u{50d}\u{518}\u{520}\u{526}\u{52c}\u{52f}\u{537}\u{53d}\u{541}\
	\u{547}\u{549}\u{54e}\u{553}\u{557}\u{55a}\u{55f}\u{564}\u{569}\u{56d}\u{575}\
	\u{57a}\u{57d}\u{582}\u{586}\u{58b}\u{58d}\u{593}\u{597}\u{599}\u{5a5}\u{5af}\
	\u{5b3}\u{5bf}\u{5ce}\u{5d6}\u{5da}\u{5de}\u{5e2}\u{5ea}\u{5ee}\u{5f1}\u{5f4}\
	\u{5f7}\u{5fb}\u{604}\u{607}\u{610}\u{613}\u{61c}\u{61f}\u{628}\u{62b}\u{62e}\
	\u{633}\u{635}\u{639}\u{640}\u{64e}\u{65d}\u{662}\u{668}\u{66d}\u{673}\u{67a}\
	\u{67f}\u{683}\u{685}\u{68e}\u{695}\u{69a}\u{69d}\u{6a0}\u{6a4}\u{6ae}\u{6b2}\
	\u{6b4}\u{6b7}\u{6bb}\u{6c1}\u{6c5}\u{6d1}\u{6d9}\u{6e1}\u{6e7}\u{6ec}\u{6f9}\
	\u{6fe}\u{701}\u{70b}\u{712}\u{715}\u{719}\u{724}\u{726}\u{72c}\u{730}\u{737}\
	\u{73b}\u{748}\u{750}\u{75a}\u{764}\u{768}\u{772}\u{77b}\u{77f}\u{787}\u{790}\
	\u{794}\u{799}\u{7a1}\u{7a3}\u{7a7}\u{7ab}\u{7b4}\u{7b7}\u{7c0}\u{7c3}\u{7cc}\
	\u{7cf}\u{7d2}\u{7da}\u{7e9}\u{7ee}\u{7f6}\u{7fb}\u{805}\u{809}\u{813}\u{817}\
	\u{81b}\u{81f}\u{824}\u{828}\u{82b}\u{82f}\u{833}\u{83b}\u{83f}\u{841}\u{848}\
	\u{84c}\u{858}\u{860}\u{866}\u{86a}\u{873}\u{880}\u{885}\u{889}\u{891}\u{894}\
	\u{897}\u{89b}\u{8a4}\u{8a7}\u{8aa}\u{8ad}\u{8b6}\u{8ba}\u{8c4}\u{8c8}\u{8ca}\
	\u{8ce}\u{8d1}\u{8d9}\u{8dd}\u{8e0}\u{8e3}\u{8e7}\u{8ea}\u{8ed}\u{8f5}\u{900}\
	\u{905}\u{90a}\u{90d}\u{912}\u{916}\u{919}\u{91c}\u{927}\u{92b}\u{92f}\u{935}\
	\u{93a}\u{941}\u{946}\u{94d}\u{950}\u{962}\u{964}\u{967}\u{973}\u{97b}\u{982}\
	\u{987}\u{98b}\u{993}\u{998}\u{99d}\u{9a1}\u{9a7}\u{9ab}\u{9b1}\u{9bd}\u{9c2}\
	\u{9c7}\u{9ca}\u{9d6}\u{9d9}\u{9de}\u{9e1}\u{9e5}\u{9e9}\u{9fb}\u{9ff}\u{a09}\
	\u{a0e}\u{a11}\u{a18}\u{a1c}\u{a20}\u{a27}\u{a2b}\u{a3a}\u{a41}\u{a4d}\u{a50}\
	\u{a53}\u{a5a}\u{a60}\u{a64}\u{a68}\u{a6c}\u{a6e}\u{a73}\u{a79}\u{a7c}\u{a86}\
	\u{a8f}\u{a93}\u{a95}\u{a9e}\u{aa2}\u{aad}\u{ab1}\u{ab3}\u{ab7}\u{ab9}\u{ac0}\
	\u{ac4}\u{ac6}\u{acd}\u{ad1}\u{ad3}\u{ad5}\u{add}\u{ae7}\u{ae9}\u{af5}\u{af9}\
	\u{afc}\u{b04}\u{b0d}\u{b11}\u{b16}\u{b1e}\u{b23}\u{b2d}\u{b33}\u{b39}\u{b3d}\
	\u{b42}\u{b49}\u{b4e}\u{b53}\u{b56}\u{b5c}\u{b70}\u{b72}\u{b7e}\u{b81}\u{b8c}\
	\u{b8f}\u{b9c}\u{ba1}\u{ba4}\u{bb1}\u{bb5}\u{bb9}\u{bc4}\u{bc7}\u{bca}\u{bd6}\
	\u{bda}\u{be2}\u{be6}\u{bfb}\u{bfe}\u{c09}\u{c0c}\u{c0e}\u{c19}\u{c24}\u{c2f}\
	\u{c3f}\u{c48}\u{c51}\u{c63}\u{c66}\u{c75}\u{c78}\u{c84}\u{c86}\u{c92}\u{c99}\
	\u{c9c}\u{cb0}\u{cb3}\u{cb6}\u{cc6}\u{cc9}\u{ccc}\u{cda}\u{cde}\u{ce0}\u{cef}\
	\u{cfb}\u{cfe}\u{d01}\u{d0e}\u{d1a}\u{d1d}\u{d20}\u{d2c}\u{d38}\u{d3b}\u{d3e}\
	\u{d49}\u{d4d}\u{d62}\u{d64}\u{d6a}\u{d6d}\u{d70}\u{d78}\u{d8b}\u{d8d}\u{d93}\
	\u{da1}\u{daf}\u{dbc}\u{dc1}\u{dc7}\u{dcb}\u{dd3}\u{de4}\u{de7}\u{dec}\u{e04}\
	\u{e14}\u{e1c}\u{e1f}\u{e2a}\u{e2e}\u{e33}\u{e39}\u{e41}\u{e51}\u{e5d}\u{e61}\
	\u{e65}\u{e67}\u{e6b}\u{e70}\u{e73}\u{e7a}\u{e8d}\u{ea1}\u{eac}\u{eb5}\u{ec7}\
	\u{ecb}\u{ed1}\u{ee3}\u{ee7}\u{eeb}\u{eef}\u{ef3}\u{ef7}\u{efb}\u{eff}\u{f03}\
	\u{f07}\u{f0a}\u{f13}\u{f2b}\u{f32}\u{f38}\u{f3f}\u{f43}";

